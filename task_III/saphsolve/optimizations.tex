\section{SAPHSOLVE Optimizations}
\label{sec:saphsolve_optimizations}

\acrshort{saphsolve} was instrumented for profiling using the Intel VTune toolkit, which revealed major performance bottlenecks in two functions, \texttt{MergeInputs} and \texttt{InternalSetIntersectionEmpty}, respectively.

\subsection{Parallelization Hotspots}
\label{sec:saphsolve_opt}
The module containing the function \texttt{MergeInputs} was refactored to enable parallel execution through the \acrfull{dppl} \cite{Delphi}. Although some effort was made to merge these code changes upstream, substantial The ultimate decision to incorporate this enhancement lies with the \acrshort{saphire} development team.

\subsection{Using Machine-Native Word Size}
The function \texttt{InternalSetIntersectionEmpty} was ported from the now legacy 32-bit to 64-bit in order to enlarge the available address space, remove \textsf{DWORD} pointer arithmetic, improve cache alignment, and to simplify external \texttt{CALL}s with the new 64-bit \acrfull{abi}.

\subsection{Measuring Speedup}
We measure the speed-up by benchmarking against one fault tree (\texttt{ft\_310}) from our synthetic fault tree dataset. Running the test for a range of truncation sizes of the \acrshort{mcs} yields the results summarized in Table~\ref{tbl:setlib_speedup}.  On average, a speed-up of $\,\bar S = 1.43\,$ is achieved.

\input{task_III/saphsolve/tables/32_to_64_speedup}

Re-profiling with Intel VTune on the same fault tree shows the expected redistribution of CPU time. An immediate finding from Table~\ref{tbl:vTune_profile_combined} is that moving from a 32-bit to a 64-bit implementation shifts the performance profile in ways that are neither uniformly positive nor strictly predictable, yet the overall impact is largely beneficial. Examining the data at different truncation levels (16, 18, and 20) highlights both anticipated gains and unexpected regressions.

\input{task_III/saphsolve/tables/vtune_profile}

\subsection{Limitations and Outstanding Questions}
\label{sec:limitations_saphsolve}

\begin{enumerate}
    \item \textbf{Parallelization of \texttt{MergeInputs}}: The original plan called for parallelizing \texttt{MergeInputs} using \acrshort{dppl}. At present, the extent to which the parallelized code path remains active in the production \acrshort{saphsolve} is unclear, as is whether it has ever undergone comprehensive benchmarking beyond initial prototypes. Although the profiling data in Table~\ref{tbl:vTune_profile_combined} suggests changes in \texttt{MergeInputs} performance under 64-bit, more thorough tests are needed to confirm whether these results translate to large-scale or real-world deployments.
    
    \item \textbf{64-Bit Migration Scope}: Although the port of \texttt{InternalSetIntersectionEmpty} to 64-bit shows encouraging speedups in at least one fault tree, no definitive conclusions can be drawn about universal performance gains without broader benchmarking. The next step before merging these changes to the production branch is to test on additional workloads and architectures, ensuring that potential improvements in pointer arithmetic and cache alignment hold under varied conditions.

    \item \textbf{Interpreting Limited Results}: While the profiling comparisons at multiple truncation levels (16, 18, and 20) do consistently reveal certain patterns, the dataset remains relatively small in scope. Hence, these observations, though suggestive, should be treated with caution. Repeated gains at different truncation levels bolster confidence that 64-bit compilation addresses select bottlenecks; however, factors like varying data layouts, input sizes, and concurrency overhead require further investigation to confirm that these trends persist beyond the limited scenarios examined. Additional in-depth measurement and testing are thus warranted before generalizing the findings to broader settings or more diverse fault trees.
\end{enumerate}

Because these aspects remain only partially verified, the performance results reported herein should be interpreted as preliminary.  Future steps include a comprehensive validation campaign covering broader datasets, full integration testing, and source-level traceability.