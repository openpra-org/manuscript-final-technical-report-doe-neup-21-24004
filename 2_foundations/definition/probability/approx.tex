\subsection{Methods for Approximating Probabilities}
\subsubsection{The Rare-Event Approximation}
When each basic event (b) has a sufficiently small failure probability (p(b)), the likelihood of multiple minimal cut sets failing simultaneously is often negligible. Under these conditions, one may approximate the failure probability of the top event by treating each \acrlong{mcs} as though it fails independently. Specifically, let $\mathrm{MCS}(T)$ denote the set of all minimal cut sets that either have cardinality up to some \emph{truncation value} $(T)$ or exceed a chosen probability threshold. Then one replaces the exact summation over all $\mathrm{MCS}$ by summing only over $\mathrm{MCS}(T)$, yielding
\begin{equation}\label{eq:rare_event_approx}
\Pr\bigl[X_t=1\bigr]
\approx
\sum_{C \in \mathrm{MCS}(T)}
\prod_{b \in C} p(b).
\end{equation}
This approach is justified in highly reliable systems where multi-cut-set failures have low probability. Moreover, it reduces the computational burden by screening out higher-order or low-probability minimal cut sets. The choice of $(T)$ typically adheres to engineering practice: for example, in a system designed to tolerate any single failure (often referred to as $(N-1)$ redundancy), all minimal cut sets of size up to $(N-1)$ might be considered while larger cut sets, deemed improbable, are excluded.

\paragraph{Error Bound for Truncated Approximations}
A natural way to measure the quality of a truncated approximation is by comparing it to the exact probability of top-event failure. Denote the exact probability by
\[
\Pr\bigl[X_t = 1\bigr],
\]
and the truncated approximation, which sums only over the minimal cut sets in $\mathrm{MCS}(T)$, by
\[
\Pr_{T}\bigl[X_t = 1\bigr]
=
\sum_{C \in \mathrm{MCS}(T)} \prod_{b \in C} p(b).
\]
Then the \emph{error} associated with truncation up to $(T)$ is
\begin{equation}\label{eq:truncation_error_definition}
\Delta(T)
=
\Pr\bigl[X_t = 1\bigr]
-
\Pr_{T}\bigl[X_t = 1\bigr].
\end{equation}
Under the assumption that failures are sufficiently rare and interactions among higher-order minimal cut sets are negligible, an \emph{upper bound} for this error may be obtained by summing the omitted terms:
\begin{equation}\label{eq:truncation_error_bound}
\bigl|\Delta(T)\bigr|
\le
\sum_{C \in \mathrm{MCS}\setminus \mathrm{MCS}(T)}
\prod_{b \in C} p(b).
\end{equation}
In practice, computing $\Delta(T)$ or its bound usually requires identifying and evaluating all minimal cut sets outside $\mathrm{MCS}(T)$, which may still be tractable if the omitted sets are large, unlikely, or both. Consequently, choosing a suitable truncation parameter, $T$ (by size or probability threshold), ensures that the unaccounted failure modes contribute negligibly to the overall system unreliability.

\subsubsection{The Min-Cut Upper Bound}
Another method for bounding the probability of a top event interprets system failure as the union of all minimal cut set (MCS) failures. The most direct upper bound is obtained by applying the union bound (Boole's inequality), which states that the probability of the union of events is no greater than the sum of their individual probabilities. For a set of minimal cut sets $\mathcal{C} = \{C_1, C_2, \ldots, C_m\}$, where each $C_i$ is a set of basic events, the union bound yields:
\begin{equation}
\label{eq:union_bound}
\Pr\left[X_t = 1\right] \leq \sum_{C \in \mathrm{MCS}} \prod_{b \in C} p(b),
\end{equation}
where $p(b)$ is the probability of basic event $b$.

However, most modern PRA tools, including SAPHIRE \cite{saphire1}, implement a slightly tighter upper bound, known as the \emph{minimal cut set upper bound}, which is given by:
\begin{equation}
\label{eq:mcub}
\Pr\left[X_t = 1\right] \leq 1 - \prod_{C \in \mathrm{MCS}} \left[1 - \prod_{b \in C} p(b)\right].
\end{equation}
This expression accounts for the fact that the system fails if \emph{any} cut set fails, and thus computes the probability that at least one cut set occurs, assuming independence between cut sets. It is always at least as large as the true probability, and is generally less conservative than the simple union bound, especially when cut sets overlap.

The min-cut upper bound is exact if and only if all minimal cut sets are mutually disjoint (i.e., share no basic events). In practice, cut sets often overlap, leading to double counting of shared failure modes and thus a conservative overestimate. This bound remains valid regardless of the magnitude of the basic event probabilities, unlike the rare-event approximation, which assumes that cut set failures are nearly disjoint and probabilities are small.

For illustration, consider a fault tree with three minimal cut sets \cite{saphire_manual}: $C_1 = \{\text{A}, \text{B}\}$, $C_2 = \{\text{B}, \text{C}\}$, and $C_3 = \{\text{D}\}$, with $p(\text{A}) = p(\text{B}) = p(\text{C}) = 0.7$ and $p(\text{D}) = 0.5$. The min-cut upper bound is:
\begin{align}
\Pr(X) &\leq 1 - \left[1 - p(\text{A})p(\text{B})\right]\left[1 - p(\text{B})p(\text{C})\right]\left[1 - p(\text{D})\right] \\
&= 1 - (1 - 0.49)(1 - 0.49)(1 - 0.5) \\
&= 1 - (0.51)(0.51)(0.5) \\
&= 1 - 0.13005 = 0.86995.
\end{align}
This value is a conservative estimate of the true top event probability.

% \subsubsection{\color{green}{The Min-Max Method}}
% The \emph{Min-Max method}, also known as the inclusion-exclusion principle, provides an exact calculation of the probability of the union of minimal cut sets. This approach systematically accounts for all overlaps among cut sets, thereby eliminating the double counting inherent in the min-cut upper bound.

% For $m$ minimal cut sets $C_1, C_2, \ldots, C_m$, the probability that at least one cut set occurs is given by \cite{saphire_manual}:
% \begin{equation}
% \label{eq:inclusion_exclusion}
% \Pr\left[X_t = 1\right] = \sum_{i=1}^{m} P(C_i) - \sum_{1 \leq i < j \leq m} P(C_i \cap C_j) + \sum_{1 \leq i < j < k \leq m} P(C_i \cap C_j \cap C_k) - \cdots + (-1)^{m+1} P\left(\bigcap_{i=1}^{m} C_i\right),
% \end{equation}
% where $P(C_i)$ is the probability that all basic events in $C_i$ occur, and $P(C_i \cap C_j)$ is the probability that all basic events in both $C_i$ and $C_j$ occur, and so on. The alternating sum continues for all possible intersections of the cut sets.

% This method is exact, but its computational complexity grows exponentially with the number of cut sets, as it requires evaluating all $2^m - 1$ non-empty intersections. In practice, the number of terms can be reduced by exploiting the idempotent law of Boolean algebra ($A \cap A = A$) and by truncating the expansion after a fixed number of passes (i.e., limiting the order of intersections considered).

% For illustration, consider again the fault tree with cut sets $C_1 = \{\text{A}, \text{B}\}$, $C_2 = \{\text{B}, \text{C}\}$, $C_3 = \{\text{D}\}$. The basic event probabilities $p(\text{A}) = p(\text{B}) = p(\text{C}) = 0.7$, $p(\text{D}) = 0.5$. The inclusion-exclusion expansion is as follows:

% $P(C_1) = p(\text{A})p(\text{B}) = 0.49$, $P(C_2) = p(\text{B})p(\text{C}) = 0.49$, and $P(C_3) = p(\text{D}) = 0.5$.
% The pairwise intersections are $P(C_1 \cap C_2) = p(\text{A})p(\text{B})p(\text{C}) = 0.343$, $P(C_1 \cap C_3) = p(\text{A})p(\text{B})p(\text{D}) = 0.245$, and $P(C_2 \cap C_3) = p(\text{B})p(\text{C})p(\text{D}) = 0.245$.
% The triple intersection is $P(C_1 \cap C_2 \cap C_3) = p(\text{A})p(\text{B})p(\text{C})p(\text{D}) = 0.1715$.

% Substituting these values, the probability is $0.49 + 0.49 + 0.5 - (0.343 + 0.245 + 0.245) + 0.1715 = 1.48 - 0.833 + 0.1715 = 0.8185$.

% The Min-Max method yields the exact probability, as it fully accounts for all overlaps among cut sets. In the example above, the min-cut upper bound (Eq.~\ref{eq:mcub}) gives $0.87$, while the exact Min-Max result is $0.8185$. The difference arises from the double counting of shared basic events in the upper bound.

% In practice, the Min-Max method is computationally feasible only for systems with a modest number of cut sets. For large systems, the number of terms in the inclusion-exclusion expansion explodes, and approximate or bounding methods (such as the min-cut upper bound) are preferred. Some tools allow the user to specify the number of passes (i.e., the maximum order of intersections considered), trading off accuracy for computational efficiency.

\subsection{Probability Estimation using Monte Carlo Sampling}
Monte Carlo methods provide a versatile framework for approximating expectations, probabilities, and other quantities of interest by simulating random observations from an underlying distribution. At its core, a Monte Carlo estimator uses repeated random draws to approximate quantities such as
\begin{equation}
\label{eq:generic_monte_carlo_estimator}
\mathbb{E}[f(X)]
\;=\;
\int f(x)\,p(x)\,\mathrm{d}x
\;\;\approx\;\;
\frac{1}{N}\sum_{i=1}^N f\bigl(x^{(i)}\bigr),
\end{equation}
where \(x^{(1)},x^{(2)},\dots,x^{(N)}\) are \acrfull{iid} samples drawn from \(p\). The function \(f\) is a measurable function of the random variable \(X\). In reliability and \acrshort{pra} contexts, \(f\) might be an indicator of a particular event (e.g., a system failure), in which case \(\mathbb{E}[f(X)]\) becomes the probability of that event.

\subsubsection{Convergence and the Law of Large Numbers}
A central theoretical result underpinning Monte Carlo sampling is the \acrfull{lln}. In one of its classical forms, the Strong \acrshort{lln} states:
\begin{theorem}[Strong Law of Large Numbers]
\label{thm:SLLN}
Let \(X_1, X_2, \dots\) be a sequence of \acrshort{iid}\ random variables with finite expectation \(\mathbb{E}[X_1]\). Then, with probability 1,
\[
\lim_{N\to\infty}
\frac{1}{N}\sum_{i=1}^N X_i
\;=\;
\mathbb{E}[X_1].
\]
\end{theorem}
Applied to the sample estimator in Eq.~\eqref{eq:generic_monte_carlo_estimator}, the \acrshort{lln} implies that as the number of samples \(N\) grows large, the average of the function values \(f\bigl(x^{(i)}\bigr)\) converges to \(\mathbb{E}[f(X)]\). Thus, by simply drawing enough samples, one can approximate probabilities or expectations arbitrarily well (with probability~1).

\subsubsection{Central Limit Theorem and Error Analysis}
Another classical result is the \emph{\acrfull{clt}}, which indicates that the Monte Carlo estimator's distribution (around its true mean) approaches a normal distribution for large \(N\). Specifically,

\begin{theorem}[Central Limit Theorem]
\label{thm:CLT}
Suppose \(X_1, X_2,\dots\) are \acrshort{iid}\ random variables with mean \(\mu=\mathbb{E}[X_1]\) and variance \(\sigma^2=\mathbb{V}[X_1]<\infty\). Then the sample mean satisfies
\[
\sqrt{N}
\biggl(
 \frac{1}{N}\sum_{i=1}^N X_i - \mu
\biggr)
\;\;\xrightarrow{\mathrm{d}}\;\;
\mathcal{N}(0,\sigma^2),
\]
where \(\xrightarrow{\mathrm{d}}\) denotes convergence in distribution.
\end{theorem}

In practical terms, the \acrfull{clt} implies that for sufficiently large \(N\), the sampling fluctuations of the Monte Carlo estimator around the true mean are approximately normal. The variance of this normal distribution decreases with \(1/N\). Therefore, one can estimate confidence intervals, standard errors, and convergence rates by tracking empirical variance across the sample.

The above principles remain valid even when \(f\) is an indicator of a Boolean event or a composite system failure embedded in an event/fault tree. One need only be able to draw samples \(\bigl(x^{(i)}\bigr)\) from the system's joint distribution over basic events (or from any suitable representation of the \acrshort{pra} model) and then evaluate the function \(f\) to determine system success/failure for each sample. Subsequent chapters will expand on how these samples can be generated for event trees, fault trees, or more complex \acrshort{dag}-based representations.

\subsubsection{Generating Random Numbers}
Monte Carlo estimators rely on the ability to generate random realizations from a given distribution. Computers, however, do not typically provide true randomness; instead, they use \acrfull{prng}s to produce sequences of numbers that mimic realizations from a uniform distribution on \([0,1]\). From these \emph{uniform} samples, one can then derive samples from more general distributions using various transformations (e.g., the \emph{inverse transform} method, acceptance-rejection, composition methods, or specialized sampling algorithms).

A \acrshort{prng} is formally a deterministic function that, given an initial \emph{seed}, generates a long sequence of values in \((0,1)\). Popular choices include:
\begin{itemize}
\item \emph{Linear Congruential Generators (LCG)}, which use a recurrence of the form
\[
X_{n+1}
\;=\;
(a\,X_n + c)
\;\bmod\; m,
\]
then normalize \(\frac{X_{n+1}}{m}\) to produce a pseudo-random variate in \((0,1)\).
\item \emph{Mersenne Twister}, which generates high-quality pseudo-random numbers with a very long period (e.g., \(2^{19937}-1\)).
\item \emph{Philox} or other counter-based methods that deliver high performance and reproducible streams across parallel computations.
\end{itemize}

While these methods provide deterministic sequences, strong design ensures that the resulting outputs pass numerous statistical tests for randomness. If the seed is chosen randomly (or from a secure source), these methods can approximate uniformity closely enough for most Monte Carlo studies.

\paragraph{Random Variates via Transformations}
Given access to uniform samples \(U\sim \mathrm{Unif}(0,1)\), one can construct samples from many other distributions. Two widely used techniques are:

\begin{enumerate}
\item \textbf{Inverse Transform Sampling:}  
   Suppose a continuous variable \(X\) has \acrfull{cdf} \(F_X(x)\). If \(U\sim \mathrm{Unif}(0,1)\), then \(X=F_X^{-1}(U)\) follows the same distribution as \(X\). More precisely,
   \[
   P\bigl[X \le x\bigr]
   \;=\;
   P\bigl[F_X^{-1}(U)\le x\bigr]
   \;=\;
   P\bigl[U \le F_X(x)\bigr]
   \;=\;
   F_X(x),
   \]
   provided \(F_X\) is continuous and strictly increasing.  

\item \textbf{Acceptance-Rejection:}  
   For certain distributions where the inverse \acrshort{cdf} is not straightforward, one can sample from an easier \emph{proposal distribution} \(q(x)\) that bounds the targeted density \(p(x)\). Specifically, if \(p(x)\le M\,q(x)\) for all \(x\), then:
   \begin{enumerate}
   \item Draw \(Y\sim q(\cdot)\) and \(Z\sim \mathrm{Unif}(0,1)\).
   \item Accept \(Y\) if \(Z\le \frac{p(Y)}{M\,q(Y)}\). Otherwise, reject and repeat.
   \end{enumerate}
   The accepted sample \(Y\) follows distribution \(p(x)\).  
\end{enumerate}

\paragraph{Boolean Events as Discrete Random Variables}
Many variables are \emph{discrete}, often Bernoulli (success/failure) or categorical (e.g.\ multiple failure modes). Generating \(\{0,1\}\)-valued samples is then straightforward, since for each basic event \(b\),
\[
\Pr[b=1] \;=\; p(b),
\quad
\Pr[b=0] \;=\; 1-p(b).
\]
Given a uniform variate \(U\), one sets
\[
b
\;=\;
\begin{cases}
1, & U \le p(b),\\
0, & \text{otherwise}.
\end{cases}
\]
This approach naturally extends to multi-categorical events. More complex dependencies among events can also be captured by specifying appropriate conditional distributions.

\paragraph{Extending Boolean Events to Continuous Random Variables}
A \emph{continuous} random variable \(Y\) has a \acrfull{pdf} \(f_Y(y)\) on a continuous domain \(\mathcal{Y}\subseteq \mathbb{R}\). Common examples in reliability include:
\begin{itemize}
\item \textbf{Exponential Distribution}, often used to model times to failure under a constant hazard rate \(\lambda\). Its PDF is
\[
f_Y(y) \;=\; \lambda\, e^{-\lambda y},
\quad
y \ge 0.
\]
\item \textbf{Weibull Distribution}, with flexible shape parameter \(\beta>0\) and scale parameter \(\alpha>0\). Its PDF is
\[
f_Y(y)
\;=\;
\frac{\beta}{\alpha}
\Bigl(\frac{y}{\alpha}\Bigr)^{\!\beta -1}
\exp\!\biggl[-\bigl(y/\alpha\bigr)^{\!\beta}\biggr],
\quad
y\ge 0.
\]
\item \textbf{Lognormal Distribution}, where \(\log(Y)\) follows a normal distribution. This is sometimes employed for components whose lifetimes span multiple orders of magnitude.
\end{itemize}
Continuous random variables typically arise when modeling the \emph{time dimension}: for instance, the time until a valve sticks closed, or the moment when a pipe experiences a critical crack. One can then generate a Bernoulli indicator for whether the failure has occurred by time \(t\) using
\[
\Pr[Y \le t]
\;=\;
\int_{0}^{t} f_Y(y)\,\mathrm{d}y
\;=\;
F_Y(t),
\]
where \(F_Y\) is the \acrfull{cdf} of \(Y\). Evaluating this probability at each Monte Carlo trial and comparing against a uniform random variate yields a discrete failure indicator. Hence, continuous distributions can be mapped to discrete states at any chosen time horizon.




% \subsubsection{Ensuring Reliable Sampling in High-Dimensional Boolean Spaces}
% When dealing with large-scale \acrshort{pra} models or deeply nested Boolean structures (multiple fault trees and event trees), a careful approach to random variate generation is needed:
% \begin{itemize}
% \item \textbf{Reusable Streams:} Use a consistent seeding and PRNG strategy to ensure reproducibility of results, especially when comparing multiple system configurations.
% \item \textbf{Parallel and Distributed Simulations:} Avoid overlapping random streams (i.e., ensure different parallel processes use uncorrelated seeds).
% \item \textbf{Validation of Randomness:} Use standard test suites (e.g.\ TestU01, Diehard) if the model's accuracy depends on fine-scale statistical properties.
% \end{itemize}
% Once random variates for each basic event are generated, higher-level logical structures (e.g.\ gates in a fault tree or branches in an event tree) can be evaluated deterministically.  Subsequent sections will address how to form either a single \emph{global} sample of all events in the system or to \emph{factorize} the sampling process according to the structure of the DAG-based PRA model.