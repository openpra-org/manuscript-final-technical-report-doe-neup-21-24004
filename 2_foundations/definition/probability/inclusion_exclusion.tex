\subsection{Exact Methods for Calculating Probabilities}

Beyond describing which combinations of basic events can fail, most \acrfull{fta} requires a quantitative assessment of the \emph{likelihood} that the top event ultimately occurs. This section details how probabilities are embedded within the fault tree structure, how to compute the top event's failure probability (or system \emph{unreliability}), and some common methods for handling large or dependent fault trees.

\subsubsection{Assigning Probabilities to Basic Events}

Let \(\mathcal{B}=\{b_1, \dots, b_n\}\) be the set of basic events in the fault tree \(F\).  Each basic event \(b\) is associated with a \emph{failure probability} \(p(b)\in [0,1]\).  Interpreted as a Boolean random variable \(X_b\), event \(b\) takes value \(1\) (failure) with probability \(p(b)\) and value \(0\) (success) with probability \(1-p(b)\).  Thus, 
\[
\Pr\bigl[X_b = 1\bigr] \;=\; p(b), 
\quad
\Pr\bigl[X_b = 0\bigr] \;=\; 1-p(b).
\]

In the simplest \emph{single-time} analysis, each basic event is either failed or functioning for the entire time horizon under study, and no component recovers once it has failed.

\subsubsection{Event Probability Under Independence}

If we assume that all basic events fail independently, then for any set \(S \subseteq \mathcal{B}\) of failed basic events,
\[
\Pr\bigl[\text{basic events in }S\text{ fail and others succeed}\bigr]
\;=\;
\prod_{b \in S} p(b)\,\times\!\!\prod_{b \notin S} [1 - p(b)].
\]
Recall from Section~\ref{sec:fault_tree_definition} that the top event \(T\) (also called \(\mathrm{TE}\)) fails given \(S\) precisely if \(\pi_F(S, T)=1\).  Hence, the probability that the top event fails is the sum of these independent configurations \(S\) for which \(\pi_F(S,T)=1\):
\begin{equation}
\label{eq:top_event_probability}
\Pr\bigl[X_t=1\bigr]
\;=\;
\sum_{S\,\subseteq\,\mathcal{B}}
\Bigl[
    \pi_F(S,T)
    \prod_{b \in S} p(b)
    \prod_{b \notin S} \bigl[1 - p(b)\bigr]
\Bigr].
\end{equation}
A direct computation of \eqref{eq:top_event_probability} often becomes unwieldy for large FTs because of the exponential number of subsets \(S\).  However, if the fault tree is \emph{simple} (no shared subtrees) and each gate in \(\mathcal{G}\) has independent inputs, one may propagate probabilities \emph{bottom-up} through the DAG using basic probability rules:
\[
\begin{aligned}
\Pr[g=1] \;=\;& \prod_{x \in I(g)} \Pr[x=1],
&&\text{if gate \(g\) is AND,}\\[6pt]
\Pr[g=1] \;=\;& 1 \;-\; \prod_{x \in I(g)}\bigl[1-\Pr[x=1]\bigr],
&&\text{if gate \(g\) is OR,}\\[6pt]
\Pr[g=1] \;=\;& 1 \;-\; \Pr[x=1],
&&\text{if gate \(g\) is NOT (single input \(x\)),}\\[6pt]
\Pr[g=1] \;=\;& \displaystyle \sum_{j=k}^{\,|I(g)|}
\;\;\sum_{\substack{A\,\subseteq\,I(g)\\|A|=j}}
\;\;\prod_{x\in A}\Pr[x=1]\;\prod_{x\in I(g)\setminus A}\bigl[1-\Pr[x=1]\bigr],
&&\text{if gate \(g\) is \(\mathrm{VOT}(k/n)\),}\\[6pt]
\Pr[g=1] \;=\;& \displaystyle \sum_{\substack{A\,\subseteq\,I(g)\\\text{\(|A|\) is odd}}}
\;\;\prod_{x\in A}\Pr[x=1]\;\prod_{x\in I(g)\setminus A}\bigl[1-\Pr[x=1]\bigr],
&&\text{if gate \(g\) is XOR.}
\end{aligned}
\]

\subsubsection{Inclusion-Exclusion: Probability Computation under Independence}
When each \(X_i\) is modeled as a Bernoulli random variable taking the value \(1\) with probability
\[
p_i \;=\; P(X_i = 1),
\]
assumed independent of the other inputs, one can write for each \(k\)-element subset \(S \subseteq \{1,\ldots,n\}\):
\[
A_S \;=\;\bigwedge_{i \in S} \{X_i = 1\},
\quad
P\bigl(A_S\bigr) 
\;=\;
\prod_{i \in S} p_i.
\]
The event \(Y=1\) in Eq.~\eqref{eq:k_of_n_or_of_ands} is the union of all such events \(A_S\) for \(\lvert S\rvert = k\). Hence, in principle, to compute
\[
P\Bigl(Y = 1\Bigr)
\;=\;
P\Bigl(\bigvee_{\lvert S\rvert = k} A_S\Bigr),
\]
one may apply the inclusion-exclusion principle. Specifically:
\begin{equation}
\label{eq:union_inclusion_exclusion}
P\Bigl(\bigvee_{\lvert S\rvert = k} A_S\Bigr)
\;=\;
\sum_{\lvert S\rvert=k}P(A_S)
\;-\;\sum_{1\le \alpha_1<\alpha_2\le M}P\Bigl(A_{S_{\alpha_1}}\cap A_{S_{\alpha_2}}\Bigr)
\;+\;\dots
\end{equation}
where \(M=\sum_{j=k}^{n} \binom{n}{j}\) is the total number of events \(A_S\) of interest. Unfortunately, direct enumeration of these intersections can become infeasible for large \(n\).

\paragraph{Worst-Case Example using 3-of-5 Voting Logic}
\label{sec:3_of_5_voting_logic_example}

In many PRA tools, the \(\mathrm{VOT}(k/n)\) gate is provided as a built-in element. Internally, these tools may expand Eq.~\eqref{eq:k_of_n_or_of_ands} into an OR-of-ANDs or maintain a more compact representation. Under independence assumptions, standard failure-probability calculations proceed by summing over combinations of basic-event failures. However, an explicit expansion incurs the combinatorial factor
\[
\binom{n}{k} \;+\; \binom{n}{k+1} \;+\; \dots \;+\; \binom{n}{n},
\]
which can grow quickly as \(n\) increases. For example, consider the case where $k=3, n=5$. Using the notation from Section~\ref{sec:kn_voting_logic_definition}, the compressed form of the gate output is
\[
Y \;=\; \mathrm{VOT}(3/5)\bigl(X_1, X_2, X_3, X_4, X_5\bigr)
\;=\;
\bigl[\;X_1 + X_2 + X_3 + X_4 + X_5 \;\ge\; 3\bigr].
\]

\input{2_foundations/definition/ft/figs/ft_3_of_5}

Since ``at least 3 of 5'' means any subset of size 3, 4, or 5 suffices, an explicit OR-of-ANDs expansion has the following terms:
\begin{equation}
\begin{aligned}
Y \;=\;&
\underbrace{
  \resizebox{.90\hsize}{!}{$
    X_1 X_2 X_3 \;\lor\; X_1 X_2 X_4 \;\lor\; X_1 X_2 X_5 \;\lor\; X_1 X_3 X_4 \;\lor\; X_1 X_3 X_5 \;\lor\; X_1 X_4 X_5 \;\lor\; X_2 X_3 X_4 \;\lor\; X_2 X_3 X_5 \;\lor\; X_2 X_4 X_5 \;\lor\; X_3 X_4 X_5
  $}
}_{\text{subsets of size 3}}
\\
&\;\;\lor\;\;
\underbrace{
  \resizebox{.80\hsize}{!}{$
    X_1 X_2 X_3 X_4 \;\lor\; X_1 X_2 X_3 X_5 \;\lor\; X_1 X_2 X_4 X_5 \;\lor\; X_1 X_3 X_4 X_5 \;\lor\; X_2 X_3 X_4 X_5
  $}
}_{\text{subsets of size 4}}
\\
&\;\;\lor\;\;
\underbrace{X_1 X_2 X_3 X_4 X_5}_{\text{subset of size 5}}.
\end{aligned}
\end{equation}

Assume that each \(X_i\) is a Bernoulli random variable taking the value 1 with probability \(p_i\), independently of the others. Then
\[
p_i 
\;=\;
P\bigl(X_i = 1\bigr),
\quad
i = 1,2,3,4,5.
\]
We seek 
\(\displaystyle P(Y=1)\), i.e., the probability that at least three of the \(X_i\) are 1.  A convenient way to write this is to sum, for \(j=3,4,5\), the probabilities that exactly \(j\) of the inputs are 1:
\[
P\bigl(Y=1\bigr)
\;=\;
\sum_{j=3}^{5}
\;\sum_{\substack{S\,\subseteq\,\{1,2,3,4,5\}\\|S|=j}}
\;\prod_{i\in S} p_i\;
\prod_{i\notin S} (1 - p_i).
\]
Exactly three of the five inputs are 1 (there are \(\binom{5}{3} = 10\) such terms):
\[
\begin{aligned}
&\,p_1 p_2 p_3\,(1\!-\!p_4)\,(1\!-\!p_5)\;+\;
p_1 p_2 p_4\,(1\!-\!p_3)\,(1\!-\!p_5)\;+\;
p_1 p_2 p_5\,(1\!-\!p_3)\,(1\!-\!p_4)\;+\;
\\
&\;p_1 p_3 p_4\,(1\!-\!p_2)\,(1\!-\!p_5)\;+\;
p_1 p_3 p_5\,(1\!-\!p_2)\,(1\!-\!p_4)\;+\;
p_1 p_4 p_5\,(1\!-\!p_2)\,(1\!-\!p_3)\;+\;
\\
&\;p_2 p_3 p_4\,(1\!-\!p_1)\,(1\!-\!p_5)\;+\;
p_2 p_3 p_5\,(1\!-\!p_1)\,(1\!-\!p_4)\;+\;
p_2 p_4 p_5\,(1\!-\!p_1)\,(1\!-\!p_3)\;+\;
\\
&\;p_3 p_4 p_5\,(1\!-\!p_1)\,(1\!-\!p_2).
\end{aligned}
\]
Exactly four of the five inputs are 1 (there are \(\binom{5}{4}=5\) such terms):
\[
\begin{aligned}
&p_1 p_2 p_3 p_4\,(1\!-\!p_5)
\;+\;
p_1 p_2 p_3 p_5\,(1\!-\!p_4)
\;+\;
p_1 p_2 p_4 p_5\,(1\!-\!p_3)
\\
&\quad+\;
p_1 p_3 p_4 p_5\,(1\!-\!p_2)
\;+\;
p_2 p_3 p_4 p_5\,(1\!-\!p_1).
\end{aligned}
\]
All five inputs are 1 (there is \(\binom{5}{5}=1\) such term):
\[
p_1 p_2 p_3 p_4 p_5.
\]

Summing all of the above terms yields \(P(Y=1)\), the fully expanded probability of a 3-of-5 vote under independence.

\paragraph{Complexity of the Inclusion-Exclusion Approach}
Observe that the union in Eq.~\eqref{eq:union_inclusion_exclusion} comprises \(M\) events, where
\[
M \;=\;\sum_{j=k}^{n} \binom{n}{j}.
\]
The inclusion-exclusion principle for a union of \(M\) events involves sums of intersections of size \(r\), for \(r=1,\dots,M\). The total number of terms is
\[
\sum_{r=1}^{M} \binom{M}{r}
\;=\;
2^{M}-1,
\]
which implies a worst-case computational complexity on the order of
\[
\mathcal{O}\bigl(2^{M}\bigr).
\]
Moreover, for \(k\approx n/2\), the binomial coefficients \(\binom{n}{k}\) become largest, so \(M\) can itself grow exponentially in \(n\). Consequently, the inclusion-exclusion expansion may require up to \(\mathcal{O}\bigl(2^{2^{n}}\bigr)\) operations for moderately large \(n\).
