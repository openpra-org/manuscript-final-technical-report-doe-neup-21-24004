
@article{hoon_han_development_1988,
	title = {Development of an integrated fault tree analysis computer code {MODULE} by modularization technique},
	volume = {21},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183208890052X},
	doi = {10.1016/0951-8320(88)90052-X},
	language = {en},
	number = {2},
	urldate = {2025-04-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Hoon Han, Sang and Woon Kim, Tae and Joong Yoo, Kun},
	month = jan,
	year = {1988},
	pages = {145--154},
}

@article{wu_development_2015,
	title = {Development of reliability and probabilistic safety assessment program {RiskA}},
	volume = {83},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645491500153X},
	doi = {10.1016/j.anucene.2015.03.020},
	language = {en},
	urldate = {2025-04-16},
	journal = {Annals of Nuclear Energy},
	author = {Wu, Yican},
	month = sep,
	year = {2015},
	pages = {316--321},
}

@article{han_pc_1990,
	title = {{PC} {Workstation}-based level 1 {PRA} code package {KIKAP}},
	volume = {30},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209090101R},
	doi = {10.1016/0951-8320(90)90101-R},
	language = {en},
	number = {1-3},
	urldate = {2025-04-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Han, S.H. and Kim, T.W. and Jeong, K.S. and Yoo, K.J.},
	month = jan,
	year = {1990},
	pages = {313--322},
}

@inproceedings{earthperson_introducing_2023,
	address = {New Orleans, Louisiana, USA},
	title = {Introducing {OpenPRA}: {A} {Web}-{Based} {Framework} for {Collaborative} {Probabilistic} {Risk} {Assessment}},
	isbn = {978-0-7918-8770-7},
	shorttitle = {Introducing {OpenPRA}},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2023/87707/V013T15A014/1196307},
	doi = {10.1115/IMECE2023-111708},
	abstract = {Abstract
            Probabilistic Risk Assessment (PRA) tools are crucial in the nuclear, aerospace, maritime, and chemical industries. This paper presents OpenPRA, an innovative, open-source, web-based platform designed to address the limitations of current Probabilistic Risk Assessment (PRA) tools. OpenPRA offers a collaborative and flexible environment that supports a wide array of risk models and quantification engines, thereby enhancing the adaptability and efficiency of risk assessment processes. The platform offers unique features including support for various risk models such as event trees, fault trees, Markov chains, Bayesian networks, and error propagation models. It also allows users to choose from a variety of existing quantification engines, enabling them to tailor their risk assessment process to their specific needs. The paper discusses the design, development, and potential of OpenPRA to transform the field of PRA. It also delves into the platform’s technical architecture, technology stack, and the OpenPRA Model Exchange Format. The paper concludes by outlining the current development status of OpenPRA and laying out the foundation for future work.},
	urldate = {2024-04-02},
	booktitle = {Volume 13: {Research} {Posters}; {Safety} {Engineering}, {Risk} and {Reliability} {Analysis}},
	publisher = {American Society of Mechanical Engineers},
	author = {Earthperson, Arjun and Aras, Egemen M. and Farag, Asmaa S. and Diaconeasa, Mihai A.},
	month = oct,
	year = {2023},
	pages = {V013T15A014},
}

@article{rauzy_toward_2003,
	title = {Toward an efficient implementation of the {MOCUS} algorithm},
	volume = {52},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/1211108/},
	doi = {10.1109/TR.2003.813160},
	language = {en},
	number = {2},
	urldate = {2025-04-15},
	journal = {IEEE Transactions on Reliability},
	author = {Rauzy, A.},
	month = jun,
	year = {2003},
	pages = {175--180},
}

@book{carter_managing_1987,
	address = {Washington (D.C.)},
	title = {Managing nuclear operations},
	isbn = {978-0-8157-1314-2},
	language = {eng},
	publisher = {The Brookings Institution},
	author = {Carter, Ashton B. and Steinbruner, John D. and Zraket, Charles A.},
	year = {1987},
}

@book{wirtz_nuclear_2022,
	address = {Washington, DC},
	title = {Nuclear command, control, and communications: a primer on {US} systems and future challenges},
	isbn = {978-1-64712-244-7 978-1-64712-243-0},
	shorttitle = {Nuclear command, control, and communications},
	abstract = {"This volume provides an overview of the history, strategy, and technology associated with US nuclear command, control and communications (NC3). It also identifies how the introduction of modern digital technologies and concerns about cyber security complicate the contemporary NC3 setting. The contributors explain how the US military's NC3 works and how it might fail. Concerns about the security of nuclear forces and command and control systems are not new, but they are becoming more urgent. Bringing Cold-War analog systems into the digital age by modernizing hardware and software has the potential to introduce vulnerabilities and unintended consequences. Policymakers and nuclear theorists should consider that nuclear infrastructure and command networks could be penetrated, corrupted, destroyed, or spoofed, leading to a loss of positive control (the ability to fire weapons) or negative control (the ability to prevent unauthorized or accidental use). This volume explores the NC3 "weapons system," its vital role in ensuring effective deterrence, contemporary challenges posed by cyber threats, new weapons technologies, and the consensus across the nuclear enterprise of the need to modernize this Cold War-era system of systems"--},
	publisher = {Georgetown University Press},
	editor = {Wirtz, James J. and Larsen, Jeffrey Arthur},
	year = {2022},
	keywords = {Armed Forces Communication systems, Command and control systems, Deterrence (Strategy), Military policy, Nuclear weapons, United States},
}

@article{rasheeq_automated_nodate,
	title = {Automated {OpenPSA} {Model} {Generation} from {Reliability} {Diagrams} {Using} {Agentic} {Retrieval}-{Augmented} {Generation}: {A} {Case} {Study} on {MHTGR}},
	abstract = {Probabilistic risk assessment (PRA) is essential in providing a systematic approach to quantify risks and ensure safety through the evaluation of potential failure scenarios. Traditional modeling techniques, such as fault trees (FT) and event trees (ET), are fundamental in analyzing system failures, accident progression, and quantifying release frequencies. However, the complexity and intricate dependencies among system components of nuclear power plants make it challenging for students and junior risk analysts to identify all potential failure modes, resulting in an exceedingly cumbersome modeling process due to their limited expertise and knowledge. This knowledge gap often leads to incomplete models or inadvertent errors, compromising the accuracy and comprehensiveness of PRA models.},
	language = {en},
	author = {Rasheeq, Hasibul H and Aras, Egemen M and Earthperson, Arjun and Diaconeasa, Mihai A},
}

@article{rasheeq_design_nodate,
	title = {Design and {Implementation} of a {Distributed} {Queueing} {System} for {OpenPRA}},
	abstract = {Probabilistic Risk Assessment (PRA) tools are essential for evaluating the safety and reliability of nuclear power plants. However, existing PRA tools often face computational challenges when analyzing complex models, especially those involving multi-hazard scenarios or real-time decision support. This paper presents the design and implementation of a distributed queueing system integrated into the OpenPRA web-based platform, aiming to overcome these computational limitations and enhance the efficiency and scalability of PRA analyses.},
	language = {en},
	author = {Rasheeq, Hasibul H and Earthperson, Arjun and Aras, Egemen M and Diaconeasa, Mihai A},
}

@article{aras_synthetical_nodate,
	title = {Synthetical {Model} {Generator} for {Probabilistic} {Risk} {Assessment} {Tools}: {Enhancing} {Testing}, {Verifying} and {Learning}},
	abstract = {For this research, the Open-PSA is used as the model format, and SCRAM is used as the quantification engine for demonstration purposes. However, the methodology can be extended to support other model formats and quantification engines as needed.},
	language = {en},
	author = {Aras, Egemen M and Earthperson, Arjun and Rasheeq, Hasibul H and Wood, Stephen T and Boyce, Jordan T and Diaconeasa, Mihai A},
}

@article{aras_facilitating_nodate,
	title = {Facilitating {PRA} {Model} {Accessibility}: {Model} {Converter} {Utility} from {SAPHIRE} to {Open}-{PSA}},
	abstract = {Probabilistic risk assessment (PRA) tools have played a vital role for over three decades in assisting PRA practitioners and regulatory bodies in building nuclear power plant models, quantifying models, and supporting safety decisions at various project phases. However, most PRA tools are commercial, limiting the research community’s ability to contribute to their development. Researchers working on PRA model solvers, or quantification engines, often require established models to test and validate their improvements. Unfortunately, publicly available NPP models are scarce. In response, researchers typically generate synthetic models or seek methods to convert existing models into formats that can be leveraged for further updates and testing.},
	language = {en},
	author = {Aras, Egemen M and Earthperson, Arjun and Rasheeq, Hasibul H and Wood, Stephen T and Boyce, Jordan T and Diaconeasa, Mihai A},
}

@misc{brown_operator_2024,
	title = {Operator action event trees for the {Zion} 1 pressurized water reactor},
	author = {Brown, R.G. and VonHerrmann, J.L. and Quilliam, J.F. and {Wood-Leaver} and Associates, Inc., San Jose, CA (USA)},
	month = dec,
	year = {2024},
}

@article{carter_command_1985,
	title = {The {Command} and {Control} of {Nuclear} {War}: {Nuclear} weapons and strategic policy attract increasing public concern, but systems for command, control, communications and intelligence may be just as important in deterring nuclear attack and preventing escalation},
	volume = {252},
	issn = {0036-8733},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3fS8MwED50A9EX3VT8TXxwKtqta5t2e_DByUR8UIbV4ZPELFHBdbBuzD_fS5t2s5sw8aGhhJBc-yWX6-XuK4BtlU0joxNkVbIa59ieS89xbF4XaHjYTofiVxGnLOPbOU5SY2YGtVf-jTTWIdYqc_YPaKedYgXeI-ZYIupYzo27yvrQJKwqpS-KRY88A1z9JOKszfqTNmm0vKOQofT8Jp0G4bui3WiUVWBIEsjbiZPmajTjI5jRz1SkZcxM7MWsFIlqtKg1NQdiRRc7Jaf0b8y2HqbjMT2ciWaBoR2ZPzivM3tRGiHotj59nzrt0VPLbtDR8PHroSbeSooPvdv54IMLERjDcBHyKpMXtVn-tnl3_zzegy3XTOmW8aGW4FCLV_lVuKmz8MjE8NdgNeH6JpcxqgVYEEERViYoI4tQ0Mo4JCeaMfx0HUoIOtGgE3Vp0ElPEg06QdA34Py66V_dGIkALygl677Mfgv2JuSCXiC2gHDP9KRwWd2zheMy55Uym0qskcypViXfhqO5utyZs90uLI_n1x7kBv2h2EdpcGUeaAy-ASohQtk},
	doi = {10.1038/scientificamerican0185-32},
	language = {English},
	number = {1},
	journal = {Scientific American},
	author = {Carter, Ashton B.},
	year = {1985},
	note = {Publisher: Scientific American, Inc},
	keywords = {The Sciences},
	pages = {32},
}

@misc{noauthor_mathematical_nodate,
	title = {Mathematical model of the {QUENCH}-06 experiment with sensitivity and uncertainty analysis in hydrogen generation - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0017931022010225},
	urldate = {2024-12-21},
}

@book{allison_development_2019,
	title = {Development and {Preliminary} {Assessment} of the new {ASYST} - {ISA} {Integral} {Analysis} {BEPU} {Code} using the {PBF} {SFD}-{ST} {Bundle} {Heating} and {Melting} {Experiment}, a {Typical} {BWR} {Under} {Fukushima}-{Daiichi}-{Accident}-{Like} {Thermal} {Hydraulic} {Conditions} and {PWR} for a {Steam} {Line} {Break} in the {Containment}},
	abstract = {ASYST (Adaptive SYStem Thermal-hydraulics)-ISA (Integral Simulation and Analysis) is a new code being developed jointly under the direction of the organizations noted above that combines the capabilities of SCDAPSIM and SAMPSON. The thermal hydraulic module, ASYST-THA, replaces the original US NRC-developed RELAP5 code used in RELAP/SCDAPSIM/MOD3.x and THA used in SAMPSON with new system level hydrodynamic options that include multi-dimensional, multi fluid models originally developed by ISS and IAE. The ASYST reactor-specific modeling options include modules describing the behavior of (a) the core/fuel assembly structures, (b) late phase debris/melt relocation, (c) the containment including melt spreading and molten core-concrete interactions, and (d) fission product release and transport. The core/fuel assembly behavior module uses derivatives of the SCDAPSIM/MOD3.x models and correlations while the late phase debris/melt relocation module uses a combination of SCDAPSIM/MOD3.x (2D based) models and SAMPSON MCRA, DCA, DSA (3D-based) models. The fission product release and transport module uses combinations of models from SCDAPSIM/MOD3.x and SAMPSON. The core-concrete interaction module uses a SCDAPSIM-based porous media model in combination with SAMPSON's Debris-Concrete Interaction (DCRA) models and correlations. The reactor vessel, reactor coolant system and containment thermal hydraulic behavior is described by ASYST-THA in combination with the SAMPSON hydrogen combustion, hydrogen detonation and steam explosion modules, HYNA, DDOC and VESUVIUS, respectively. Funding and additional technical contributions for the development of ASYST comes from the contributors to the international SCDAP Development and Training Program (SDTP). The paper provides a brief overview and the status of the development of the ASYST code along with a preliminary assessment of the code using the PBF SFD-ST in-pile bundle heating and melting experiment along with benchmark calculations for a representative station blackout transient calculation for a typical BWR under Fukushima-like thermal hydraulic conditions and a PWR for a steam line break in the containment.},
	author = {Allison, C. and Hohorst, J. and Ezzidi, Alexandre and Naitoh, M and Pericas, R.},
	month = dec,
	year = {2019},
}

@article{vododokhov_asyst41_2023,
	title = {{ASYST4}.1 validation for gas cooled {SMR} applications using the {HTTF} experiment},
	volume = {414},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549323004922},
	doi = {10.1016/j.nucengdes.2023.112643},
	abstract = {Small Modular Reactors (SMRs) based on High Temperature Gas Cooled Reactors (HTGR) concepts are being considered for remote communities in Canada (power ∼ 5 MWe or less) and elsewhere. One such design is Micro-Modular Reactor (MMR) from USNC (Ultra-Safe Nuclear Corporation). It uses helium as primary coolant and molten salt as intermediate coolant and for thermal energy storage (TES). The molten salt can then be used to generate steam on-demand to match the local communities’ energy requirements. Reliable computational tools are needed for thermal hydraulic analysis of the integrated nuclear and molten salt systems. ASYST4.1 (Advanced SYStem Thermal system) is one such tool which has been recently validated for Solar Salt (40 \% NaNO3 + 60 \%KNO3) applications and has capability to simulate the helium coolant and reactor core behaviour. To enable the code to model the primary and intermediate loops of MMR there is a need to validate the code for helium coolants and its capabilities to simulate lateral conduction, natural circulation, and radiative heat transfer. The HTTF (High Temperature Test Facility) experiment PG-26, a Depressurized Conduction Cooldown transient, is used for this validation exercise. The results are compared with those of the experiment and those from RELAP5-3D calculations. The reference case and sensitivity analyses for the important parameters are presented. Mass flow rate and temperatures in the primary loop are compared for the steady-state and for the transient PG-26. For the initial assessment ASYST4.1 predictions are found in good agreement with RELAP5-3D, but these results deviate from the experiment. Significant improvement in simulation results is observed when simulations consider the entire trajectory of the warm-up period and of the experiment, indicating that the experiment was not in a steady-state condition at the time of the depressurization test. This is an important factor to be considered in all HTTF cases going forward.},
	urldate = {2024-09-13},
	journal = {Nuclear Engineering and Design},
	author = {Vododokhov, Nikolai and Trivedi, Anuj and Novog, David R.},
	month = dec,
	year = {2023},
	keywords = {Gas-cooled reactor, HTTF, Nodalization, Simulation, Thermal hydraulic, Validation},
	pages = {112643},
}

@techreport{noauthor_athlet-cd_2016,
	title = {{ATHLET}-{CD} 3.{1A} – {User}’s {Manual}. {GRS} {Report} {GRS}-{P}-4/{Vol}. 3 {Rev}. 1},
	month = jul,
	year = {2016},
}

@article{noauthor_state---art_nodate,
	title = {"{A} {State}-of-the-{Art} {Review} of {Past} {Programmes} {Devoted} to {Fuel} {Behaviour} {Under} {Loss}-of-{Coolant} {Conditions}. {Part} 3. {Cladding} {Oxidation}. {Resistance} to {Quench} and {Post}-{Quench} {Loads}".},
	abstract = {This report makes a detailed literature review of the knowledge gained from the experimental results relative to oxidation, resistance to quench and post quench loads of Zircaloy cladding under LOCA conditions.},
	language = {en},
}

@article{sanchez-mora_comparison_2024,
	title = {Comparison of the {QUENCH}-06 experiment between {ASYST} and {RELAP}/{SCDAPSIM} 3.4},
	volume = {428},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549324006174},
	doi = {10.1016/j.nucengdes.2024.113517},
	abstract = {The behavior of nuclear reactors during a severe accident is significantly affected by hydrogen generation. The QUENCH experiments are crucial for understanding the behavior of nuclear reactors during severe accidents, particularly focusing on hydrogen generation and the thermal–hydraulic responses under extreme conditions. Since an accurate prediction of hydrogen generation is crucial for severe accidents simulation codes, especially in the early phase of an accident, this paper presents a comparative analysis of the QUENCH-06 experiment using two prominent simulation codes, ASYST and RELAP/SCDAPSIM 3.4. The paper evaluates the capabilities of both simulation codes to accurately predict the thermohydraulic behavior and hydrogen production during the early phases of a reactor accident. Initial results from both codes are analyzed and discrepancies in hydrogen generation estimations are highlighted. This study aims to validate the improved oxidation models in ASYST/SCDAPSIM code using QUENCH-06 experiment by selecting appropriate oxidation models in ASYST/SCDAPSIM code, given the strong dependency of the dynamics on the hydrogen production rates, and to compare these results with those from RELAP/SCDAPSIM MOD 3.4 code using the same input deck.},
	urldate = {2024-09-16},
	journal = {Nuclear Engineering and Design},
	author = {Sánchez-Mora, Heriberto and Pericas, Raimon and Mustafa, Rawan and Vázquez-Rodríguez, Rodolfo},
	month = nov,
	year = {2024},
	keywords = {ASYST/SCDAPSIM, QUENCH-06, Thermal-hydraulic in Nuclear Reactors},
	pages = {113517},
}

@inproceedings{cm_allison_sdtpdeveloping_2005,
	title = {{SDTP}—{Developing} {Technology} for the {Nuclear} {Industry}},
	author = {{C.M Allison} and {J.K Hohorst}},
	month = may,
	year = {2005},
}

@misc{hagen_comparison_1996,
	title = {Comparison of the quench experiments {CORA}-12, {CORA}-13, {CORA}-17},
	url = {https://publikationen.bibliothek.kit.edu/270039707},
	language = {de},
	urldate = {2024-09-13},
	author = {Hagen, S. and Hofmann, P. and Noack, V. and Sepold, L. and Schanz, G. and Schumacher, G.},
	year = {1996},
	doi = {10.5445/IR/270039707},
}

@techreport{s_hagen_p_hofmann_v_noack_g_schanz_g_schumacher_l_sepold_dry_1995,
	title = {Dry {Core} {BWR} {Test} {CORA}-33: {Test} {Results}},
	url = {https://quench.forschung.kit.edu/84.php},
	number = {KITopen-ID: 270036903 Reportnummer: KFK-5261},
	author = {{S. Hagen, P. Hofmann, V. Noack, G. Schanz, G. Schumacher, L. Sepold}},
	year = {1995},
}

@article{stuckert_post-test_2019,
	title = {Post-test analyses of the {CORA}-15 bundle test with the system codes {ATHLET}-{CD} and {SOCRAT}},
	volume = {342},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S002954931830606X},
	doi = {10.1016/j.nucengdes.2018.12.015},
	abstract = {Analyses of the CORA-15 bundle test have been performed with the system codes ATHLET-CD (GRS) and SOCRAT (IBRAE). In the test, the behaviour of a PWR type fuel bundle, composed of 23 fuel rods and 2 absorber rods, was investigated under severe accident conditions. An important feature of the experiment different from all other CORA tests was the pressurization of fuel rods to 6.0 MPa. As a result, the fuel rods underwent ballooning and burst. In general, both codes adequately reproduced the cladding temperatures histories, the ballooning and rupture, and blockage formation due to melt relocation. The hydrogen release has been calculated within the uncertainty of the measured data.},
	urldate = {2024-09-13},
	journal = {Nuclear Engineering and Design},
	author = {Stuckert, J. and Austregesilo, H. and Bals, Ch. and Hollands, Th. and Kiselev, A. and Tomashchik, D. and Yudina, T.},
	month = feb,
	year = {2019},
	keywords = {Ballooning and burst, Cladding oxidation, Severe accident, System code},
	pages = {320--335},
}

@book{bolshov_socrat_2006,
	title = {{SOCRAT}: {The} {System} of {Codes} for {Realistic} {Analysis} of {Severe} {Accidents}},
	volume = {2006},
	shorttitle = {{SOCRAT}},
	abstract = {For a long time in the Russian Federation the computer code for analysis of severe accidents is being developed. The main peculiarity of this code from the known computer codes for analysis of severe accidents at NPP such as MELCOR and ASTEC, is a consequent realization of the mechanistic approach for modeling of the melt progression processes, including beyond design basis accidents with the severe core damage. The motivation of the development is defined by the new design requirements to the safety of nuclear power plants with the improved economic factors, by the modernization of existing NPPs, by the development of instructions to the accident management and emergency planning. The realistic assessments of Nuclear power plants safety require usage of the best estimate codes allowing description of the melt progression processes accompanying severe accident at the nuclear installation and behavior of the containment under abnormal condition (in particular, rates of the steam and hydrogen release, relocation of molten materials to the concrete cavity after failure of the reactor vessel). The developed computer codes were used for the safety justification of NPP with the new generation of VVER type reactor such as Tyanvan NPP in China and Kudamkulam NPP in India. In particular using this code system the justification of the system for hydrogen safety, analysis of core degradation and relocation of the molten core to the core catcher used for the guarantied localization of the melt and prevention of the ex-vessel melt progression. The considered system of codes got recently name SOCRAT provides the self consistent analysis of in-vessel processes and processes, running in the containment, including melt localization device. In the paper the structure of the computer code SOCRAT is presented, functionality of the separate parts of the code is described, results of verification of different models of the code are also considered. (authors)},
	author = {Bolshov, Leonid and Strizhov, Valery},
	month = jul,
	year = {2006},
	note = {Journal Abbreviation: Proceedings of the 2006 International Congress on Advances in Nuclear Power Plants, ICAPP'06
Publication Title: Proceedings of the 2006 International Congress on Advances in Nuclear Power Plants, ICAPP'06},
}

@techreport{hagen_out--pile_1987,
	address = {Germany},
	title = {Out-of-pile bundle experiments for severe fuel damage investigations ({CORA}): {Experiment} {B} with {Al2O3} pellets},
	shorttitle = {Out-of-pile bundle experiments for severe fuel damage investigations ({CORA})},
	abstract = {The power input was increased in a way to reach a temperature rise of 050C in the
hottest parts of the bundle The maximum power was 80 kW With this power input a temperature
of 20000C was reached This heatup resulted in a nearly complete melting of the middle
bundle region The molten material refroze in the lower end of the bundle Similar as
for the UO2/Zry system we got the dissolution of the ceramic component in contact
with the Zry far below the melting temperature of Al2O3 Zry takes oxygen from Al2O3
resulting in metallic aluminium The melt formation in this system is much more pronounced
than for UO2/Zry Thus our first preliminary results are in good agreement with the
experience in the TMI 2 core Also there in the surrounding of the burnable poison
rods a pronounced damage was found (orig/DG)},
	author = {Hagen, S. and Hain, K. and Butzer, W. and Gruenhagen, A. and Hanauer, J. and Harbauer, G. and Hering, W. and Lange, W. and Leiling, W. and Malauschek, H. and Paroth, N. and Sepold, L. and Schloss, F. and Vollmer, T. and Wallenfels, K.P. and Vogel, K. and Benz, H. and Giessmann, H. and Heil, O. and Roetzel, W. and Roehling, H.J. and Pfann, P.},
	year = {1987},
	note = {KFK--4100
INIS Reference Number: 19068770},
	pages = {4200--28--4200--52},
}

@incollection{petrangeli_appendix_2020,
	title = {Appendix 1 - {The} {Chernobyl} {Accident}},
	isbn = {978-0-12-818326-7},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128183267000354},
	urldate = {2024-09-13},
	booktitle = {Nuclear {Safety} ({Second} {Edition})},
	publisher = {Butterworth-Heinemann},
	editor = {Petrangeli, Gianni},
	month = jan,
	year = {2020},
	doi = {10.1016/B978-0-12-818326-7.00035-4},
	pages = {335--341},
}

@article{dobashi_fire_2014,
	title = {Fire and explosion disasters occurred due to the {Great} {East} {Japan} {Earthquake} ({March} 11, 2011)},
	volume = {31},
	issn = {0950-4230},
	url = {https://www.sciencedirect.com/science/article/pii/S0950423014000394},
	doi = {10.1016/j.jlp.2014.03.001},
	abstract = {The Great East Japan Earthquake (magnitude 9.0 Mw: the moment magnitude scale, based on the seismic moment of the earthquake) occurred at 14:46, March 11, 2011. It triggered huge tsunami waves (seismic sea waves) that reached heights of up to about 20 m. In this paper, the fire and explosion disasters occurred due to the Great East Japan Earthquake are reported shortly. Some fires occurred in seacoast areas after tsunami attacks and some of them were spreading very widely to the tsunami flooded areas. It is important to study the mechanisms of such fires (tsunami fires) for preparing huge tsunami. After the earthquake, a very severe accident happened in the Fukushima Daiichi nuclear power plant. Three reactors experienced full meltdown. During this disaster, hydrogen explosions occurred and made the situation more serious. It has to be realized once again that the countermeasures for hydrogen explosions is indispensable. Also Large scale BLEVEs (Boiling Liquid Expanding Vapor Explosions) happened at LPG storage area in an oil refinery in Chiba Prefecture. This accident started from the falling down of an LPG storage tank by earthquake motions. The tank was heavier than usual, as it was filled with water (1.7 times heavier than LPG) for periodic inspection. Considering these disasters, we have to think about how we prepare the accident of low probability and of very severe consequence. Recently, the risk based approach is widely utilized. However, for such disasters it seems not enough to perform safety management only by risk based approach. Not only probabilistic approach (Risk), but also deterministic approach (Emergency plan, Mitigation technique) should be taken in account.},
	urldate = {2024-09-13},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {Dobashi, Ritsu},
	month = sep,
	year = {2014},
	keywords = {BLEVE, Deterministic approach, Hydrodynamic explosion, The Great East Japan Earthquake, Tsunami fire},
	pages = {121--126},
}

@article{di_marcello_validation_2016,
	title = {Validation and application of the system code {ATHLET}-{CD} for {BWR} severe accident analyses},
	volume = {307},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549316302230},
	doi = {10.1016/j.nucengdes.2016.07.013},
	abstract = {This paper is aimed at the validation and application of the system code ATHLET-CD for the simulation of severe accident phenomena in Boiling Water Reactors (BWR). The corresponding models for core degradation behaviour e.g., oxidation, melting and relocation of core structural components are validated against experimental data available from the CORA-16 and -17 bundle tests. Model weaknesses are discussed along with needs for further code improvements. With the validated ATHLET-CD code, calculations are performed to assess the code capabilities for the prediction of in-vessel late phase core behaviour and reflooding of damaged fuel rods. For this purpose, a small break LOCA scenario for a generic German BWR with postulated multiple failures of the safety systems was selected. In the analysis, accident management measures represented by cold water injection into the damaged reactor core are addressed to investigate the efficacy in avoiding or delaying the failure of the reactor pressure vessel. Results show that ATHLET-CD is applicable to the description of BWR plant behaviour with reliable physical models and numerical methods adopted for the description of key in-vessel phenomena.},
	urldate = {2024-08-30},
	journal = {Nuclear Engineering and Design},
	author = {Di Marcello, Valentino and Imke, Uwe and Sanchez, Victor},
	month = oct,
	year = {2016},
	pages = {284--298},
}

@article{fischer_planning_1981,
	title = {Planning for large-scale accidents: {Learning} from the {Three} {Mile} {Island} accident},
	volume = {6},
	issn = {0360-5442},
	shorttitle = {Planning for large-scale accidents},
	url = {https://www.sciencedirect.com/science/article/pii/0360544281901067},
	doi = {10.1016/0360-5442(81)90106-7},
	abstract = {In this paper, we explore decision-making issues raised at the Three Mile Island nuclear accident in Pennsylvania. The organizations involved, their interconnections, and decisions are described. The underlying issues bearing on allocation of effort to pre-accident planning and actual accident responses are also noted. Finally, a framework from this effort is used for guiding the planning of operations for future accidents.},
	number = {1},
	urldate = {2024-09-13},
	journal = {Energy},
	author = {Fischer, David W.},
	month = jan,
	year = {1981},
	pages = {93--108},
}

@misc{sepold_behavior_2009,
	title = {Behavior of {BWR}-type fuel elements with {B}₄{C}/steel absorber tested under severe fuel damage conditions in the {CORA} facility},
	url = {https://publikationen.bibliothek.kit.edu/270074440},
	language = {de},
	urldate = {2024-09-03},
	author = {Sepold, L. and Hagen, S. and Hofmann, P. and Schanz, G.},
	year = {2009},
	doi = {10.5445/IR/270074440},
}

@article{okawa_three-dimensional_2019,
	title = {A three-dimensional approach for simulating {BWR} core melt progression – {A} validation against {CORA}-{BWR} experimental series},
	volume = {132},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454919303603},
	doi = {10.1016/j.anucene.2019.06.041},
	abstract = {A three-dimensional simulation code has been developed for a Boiling Water Reactor (BWR) to perform two missions: realistic simulation of the phenomena induced in in-vessel core melt progression and evaluation of the composition and condition of molten materials/debris. The current stage of the code development focuses on simulation of the core melt progression from increase in cladding temperature to molten materials relocation, in order to decrease the computational uncertainties. To simulate the core melt progression more realistically, the code has several features: (i) a multi-phase, multi-component and multi-velocity-field, (ii) a three-dimensional geometrical configuration of complicated internal components in the core and lower plenum zones in a reactor pressure vessel of BWR, and detailed modelling of (iii) multiple core materials melt and chemical interactions, (iv) a candling phenomenon and (v) melt blockage in narrow zones. Subsequently to the previous qualitative validation of these physical models, more detailed validation was conducted in the present study for the CORA-BWR experimental series. In the validation, the code has semi-quantitatively simulated the temperature escalation and maximum temperature, the melt progression, the post-test configuration of relocated materials and the hydrogen generation of CORA-16 as the reference case first. Furthermore, the CORA-18, CORA-28 and CORA-33 have been evaluated in terms of the effects of scale (18 versus 48 fuel-rod mockup), pre-oxidation and wet/dry core condition. Additionally, through the CORA-16 and -18 validation, the code showed the capability for predicting the post-test configuration of relocated materials visually by comparing the photos.},
	urldate = {2024-08-30},
	journal = {Annals of Nuclear Energy},
	author = {Okawa, Tsuyoshi},
	month = oct,
	year = {2019},
	keywords = {BWR, CORA experiment, Code validation, Core melt progression, Three-dimensional simulation},
	pages = {512--525},
}

@article{steinbruck_influence_2014,
	title = {Influence of boron carbide on core degradation during severe accidents in {LWRs}},
	volume = {64},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454913004970},
	doi = {10.1016/j.anucene.2013.09.027},
	abstract = {Boron carbide (B4C) is widely used as neutron absorbing control rod material in light water reactors (LWRs). It was also applied in all units of the Fukushima Dai-ichi nuclear power plant. Although the melting temperature of B4C is 2450°C, it initiates local, but significant melt formation in the core at temperatures around 1250°C due to eutectic interactions with the surrounding steel structures. The B4C containing melt relocates and hence transports material and energy to lower parts of the fuel bundle. It is chemically aggressive and may attack other structure materials. Furthermore, the absorber melt is oxidized by steam very rapidly and thus contributes to the hydrogen source term in the early phase of a severe accident. After failure of the control rod cladding B4C reacts with the oxidizing atmosphere. This reaction produces CO, CO2, boron oxide and boric acids, as well as significant amount of hydrogen. It is strongly exothermic, thus causing considerable release of energy. No or only insignificant formation of methane was observed in all experiments with boron carbide. The paper will summarize the current knowledge on boron carbide behavior during severe accidents mainly based on experiments performed at KIT, and will try, also in the light of the Fukushima accidents, to draw some common conclusions on the behavior of B4C during severe accidents with the main focus on the consequences for core degradation and hydrogen source term.},
	urldate = {2024-08-30},
	journal = {Annals of Nuclear Energy},
	author = {Steinbrück, Martin},
	month = feb,
	year = {2014},
	keywords = {Boron carbide, Chemical reactions, LWR, Oxidation, Severe accident},
	pages = {43--49},
}

@article{costa_icone23-2082_2015,
	title = {{ICONE23}-2082 {VALIDATION} {OF} {THE} {SAMPSON}/{MCRA} {CODE} {AGAINST} {CORA}-18 {EXPERIMENT}},
	volume = {2015.23},
	doi = {10.1299/jsmeicone.2015.23._ICONE23-2_31},
	abstract = {The Fukushima-Daiichi nuclear accident has highlighted the importance of analyzing the meltdown of a Boiling Water Reactor (BWR). The core melting in a nuclear reactor is affected by different phenomena, whose the most substantial are the chemical reactions and the interactions between the core materials; these can lead to a temperature escalation and bring forward the melt progression. Moreover it has to be considered that the geometry of a BWR complicates the core modeling. The existence of channel boxes and control blades represents a significant challenge for the heat transfer calculation, in particular as regards the thermal radiation. The CORA-18 has been selected as the validation test to provide information on the damage progression of a BWR fuel element. A model has been built in SAMPSON/MCRA and a simulation of CORA-18 experiment has been performed. The zirconium oxidation assumes noteworthy importance after the temperature has reached values close to 1300 K and leads to a considerable heat release. The temperature trends appear to be similar to those in the experiment CORA-18; the hydrogen production, however, is approximately the double of the experimental data. The melting of the structures occurs at the end of the computed transient and portions of the debris are deposited on the rods under the form of crust.},
	journal = {The Proceedings of the International Conference on Nuclear Engineering (ICONE)},
	author = {Costa, Alessandro and Pellegrini, Marco and Mizouchi, Hideo and Suzuki, Hiroaki and Naitoh, Masanori and Ninokata, Hisashi and Ricotti, M.E.},
	month = may,
	year = {2015},
	pages = {\_ICONE23--2},
}

@book{villarino_neutronic_2021,
	title = {{NEUTRONIC} {AND} {THERMALHYDRAULIC} {COUPLED} {UNCERTAINTIES} {ANALYSIS} {IN} {THE} {RESEARCH} {REACTOR}},
	abstract = {The development of a nuclear research reactor core requires a great capability of modelling for a safety analysis, performance, reliability and cost optimization of the systems involved; and essential components for modelling these systems are nuclear data, engineering data with their uncertainties and a proper set of validated design tools and set of calculation procedures. The design process of the core of a research reactor has two engineering areas, with a strong interaction: Neutronic and Thermal-hydraulics. Both engineering areas have uncertainties treatment, and some of them come from the same sources, like; geometrical, and process uncertainties. The INVAP methodology used for the calculation of neutronic and thermal-hydraulic coupled calculation including the uncertainty treatment in both engineering area using total Monte Carlo method is described and applied to the OPAL reactor core as a practical example of this novel implementation. 1. Introduction New [1] and redesigned [2] research reactors already in operation are more demanding in terms of safety and operating conditions. These demands require optimized designs based upon more precise computational tools and models reducing some level of conservatism used in the design. Improved fidelity of modeling capability will help to address simultaneously safety analysis, performance, reliability and cost optimization of the systems involved. There are different sources for the uncertainties; it can be mentioned the engineering tolerances (geometry and materials), nuclear data uncertainties, process uncertainties, modelling criteria and user effect uncertainties [3]. INVAP is planning to use uncertainties analysis in a production way during the design stage and for this reason decided to implement uncertainties analysis using Total Monte Carlo Method in the production calculation line to minimize two sources of the mentioned uncertainties: modelling and user-effect uncertainties [4]. This minimization is carried out through the utilization of the INVAP calculation methodology and the proper set of procedures during the design process. The core design of a research reactor has two engineering areas, with a strong interaction: Neutronic and Thermal-hydraulics. The thermal-hydraulic design takes care of all the uncertainties in a statistical way. The present work uses another approach where the neutronic code can perform the thermal-hydraulic design verification with the proper core state (power and burnup distribution, control rod position, irradiation facilities loading, etc.) including the thermal-hydraulic feedback to the neutronic analysis [5], focusing on the utilization of the INVAP calculation lines capability to deal with geometrical, material, nuclear data and process uncertainties including this treatment, not only in the neutronic analysis but, also, in the thermal hydraulic design, partially eliminating the statistical treatment. The methodology used for the calculation of neutronic and thermal-hydraulic coupled calculation including the uncertainty treatment in both engineering area is described and applied to the OPAL reactor core [6] as a practical example of this novel implementation. 2. Design Methodology INVAP's design methodology is presented in Figure 1 with the following concepts: 1},
	author = {Villarino, Eduardo and Doval, Alicia},
	month = sep,
	year = {2021},
}

@inproceedings{naitoh_overview_2006,
	address = {Japan},
	title = {Overview of {SAMPSON} code development for {LWR} severe accident analysis},
	abstract = {The Nuclear Power Engineering Corporation (NUPEC) has developed a severe accident
analysis code 'SAMPSON' SAMPSON's distinguishing features include inter-connected
hierarchical modules and mechanistic models covering a wide spectrum of scenarios
ranging from normal operation to hypothetical severe accident events Each module included
in the SAMPSON also runs independently for analysis of specific phenomena assigned
The OECD International Standard Problems (ISP-45 and 46) were solved by the SAMPSON
for code verifications The analysis results showed fairly good agreement with the
test results Then, severe accident phenomena in typical PWR and BWR plants were analyzed
The PWR analysis result showed 56 hours as the containment vessel failure timing,
which was 9 hours later than one calculated by MELCOR code The BWR analysis result
showed no containment vessel failure during whole accident events, whereas the MELCOR
result showed 108 hours These differences were mainly due to consideration of heat
release from the containment vessel wall to atmosphere in the SAMPSON code Another
PWR analysis with water injection as an accident management was performed The analysis
result showed that earlier water injection before the time when the fuel surface temperature
reached 1,750 K was effective to prevent further core melt Since fuel surface and
fluid temperatures had spatial distribution, a careful consideration shall be required
to determine the suitable location for temperature measurement as an index for the
pump restart for water injection The SAMPSON code was applied to the accident analysis
of the Hamaoka-1 BWR plant, where the pipe ruptured due to hydrogen detonation The
SAMPSON had initially been developed to run on a parallel computer Considering remarkable
progress of computer hardware performance, as another version of the SAMPSON code,
it has recently been modified so as to run on a single processor The improvements
of physical models, numerical analysis methods and man-machine interface are ongoing
works (author)},
	author = {Naitoh, Masanori .},
	year = {2006},
	note = {INIS Reference Number: 39019909},
	pages = {614},
}

@article{nagase_chemical_1997,
	title = {Chemical interactions between {B4C} and stainless steel at hightemperatures},
	volume = {245},
	issn = {0022-3115},
	url = {https://www.sciencedirect.com/science/article/pii/S0022311596007477},
	doi = {10.1016/S0022-3115(96)00747-7},
	abstract = {With a view to investigating the chemical interactions between B4C and type 304 stainless steel, the reaction couples ofthese two materials were isothermally annealed in the temperature range between 1073 and 1623 K. As a result of the chemical interactions, complicated reaction layers were formed at the interface of the reaction couple. To evaluate the reaction kinetics, the decrease in the thickness of stainless steel and the reaction layer growth were measured as a function of temperature and time. The overall reaction generally obeyed the parabolic rate law. Both a parabolic rate law constant and an apparent activation energy were determined. A discontinuity in the temperature dependence of the parabolic rate constants was found in the temperature range between 1473 and 1498 K. This corresponds to the formation of the liquid phase at the reaction interface.},
	number = {1},
	urldate = {2024-08-30},
	journal = {Journal of Nuclear Materials},
	author = {Nagase, F. and Uetsuka, H. and Otomo, T.},
	month = may,
	year = {1997},
	pages = {52--59},
}

@inproceedings{dupleac_development_2021,
	address = {Bucharest, Romania},
	title = {Development of the {ASYST} {VER} 3.x {LWR}/{HPWR} {Best} {Estimate} {Integral} {Code}},
	isbn = {978-1-6654-4584-9},
	url = {https://ieeexplore.ieee.org/document/9614801/},
	doi = {10.1109/CIEM52821.2021.9614801},
	abstract = {ASYST (Adaptive SYStem Thermal-hydraulics) is a new BEPU integral code being developed through an international collaborative project, ADTP (ASYST Development and Training Program). ASYST VER 3, designed to support the analysis of LWRs/HPWRs, is intended to address some of the outstanding safety analysis issues identified in the Fukushima Daiichi R\&D activities. VER 3 also includes the integrated uncertainty analysis (IUA) option developed originally for RELAP/SCDAPSIM as well as several options for integrated desktop simulator GUI environments including GRAPE, Adv3DGUI, and RHYS developed by 3rd parties from Japan, Mexico, and the US. ASYST is also backwards I/O compatible with RELAP/SCDAPSIM so existing RELAP5 and RELAP/SCDAPSIM input models will run with little or no changes. ASYST VER 3.7, with advanced HPWR fuel channel and Fukushima-Daiichi related modeling improvements, planned for release over the coming year, will incorporate the latest modeling options developed for SCDAPSIM/MOD3.7.},
	language = {en},
	urldate = {2023-12-11},
	booktitle = {2021 10th {International} {Conference} on {ENERGY} and {ENVIRONMENT} ({CIEM})},
	publisher = {IEEE},
	author = {Dupleac, Daniel and Nistor-Vlad, Roxana-Mihaela and Allison, Chris and Hohorst, Judith and Perez-Ferragut, Marina},
	month = oct,
	year = {2021},
	pages = {1--5},
}

@inproceedings{c_m_allison_quench-06_2018,
	address = {London, England.},
	title = {{QUENCH}-06 {Experiment} {Post}-test {Calculations} and {Integrated} {Uncertainty} {Analysis} with {RELAP}/{SCDAPSIM}/{MOD3}.4 and {MOD3}.5},
	booktitle = {the 2018 26th {International} {Conference} on {Nuclear} {Engineering}},
	author = {{C. M. Allison} and {B. T. Le} and {G. Gerova} and {I. Spasov} and {M. Perez- Ferragut} and {J. K. Hohorst}},
	month = jul,
	year = {2018},
}

@misc{hagen_large_1998,
	title = {Large bundle {BWR} test {CORA}-18: test results},
	shorttitle = {Large bundle {BWR} test {CORA}-18},
	url = {https://publikationen.bibliothek.kit.edu/270042668},
	language = {de},
	urldate = {2023-12-08},
	author = {Hagen, S. and Hofmann, P. and Noack, V. and Sepold, L. and Schanz, G. and Schumacher, G.},
	year = {1998},
	doi = {10.5445/IR/270042668},
}

@inproceedings{c_m_allison_integrated_2017,
	address = {Karlsruhe, Germany},
	title = {Integrated uncertainty analysis of {CORA} {BWR} experiments using {RELAP}/{SCDAPSIM}},
	doi = {10.5445/IR/1000076201},
	author = {{C. M. Allison} and {R. Mustafa} and {H. Sánchez-Mora}},
	month = oct,
	year = {2017},
}

@techreport{inel_relap5mod33_1995,
	title = {{RELAP5}/{MOD3}.3 {Code} {Manual} {Volume} {I}: {Code} {Structure}, {System} {Models}, and {Solution} {Methods}},
	url = {https://www.nrc.gov/docs/ML1103/ML110330200.pdf},
	number = {INEL-95/0174},
	institution = {NRC},
	author = {{INEL}},
	month = aug,
	year = {1995},
}

@misc{burbach_results_1994,
	title = {Results of {SEM}/{EDX} {Microrange} {Analyses} of the {CORA}-16 {Bundle} {Melting} {Experiment} {Performed} in a {Boiling} {Water} {Reactor} ({BWR})},
	url = {https://publikationen.bibliothek.kit.edu/270035610},
	language = {de},
	urldate = {2023-12-06},
	author = {Burbach, J.},
	year = {1994},
	doi = {10.5445/IR/270035610},
}

@misc{hagen_pre-oxidised_1997,
	title = {Pre-oxidised {BWR} test {CORA}-28: test results},
	shorttitle = {Pre-oxidised {BWR} test {CORA}-28},
	url = {https://publikationen.bibliothek.kit.edu/270041480},
	language = {de},
	urldate = {2023-12-06},
	author = {Hagen, S. and Hofmann, P. and Noack, V. and Sepold, L. and Schanz, G. and Schumacher, G.},
	year = {1997},
	doi = {10.5445/IR/270041480},
}

@article{schanz_information_1992,
	title = {Information on the evolution of severe {LWR} fuel element damage obtained in the {CORA} program},
	volume = {188},
	issn = {0022-3115},
	url = {https://www.sciencedirect.com/science/article/pii/002231159290462T},
	doi = {10.1016/0022-3115(92)90462-T},
	abstract = {In the CORA program a series of out-of-pile experiments on LWR severe accidental situations is being performed, in which test bundles of LWR typical components and arrangements (PWR, BWR) are exposed to temperature transients up to about 2400°C under flowing steam. The individual features of the facility, the test conduct, and the evaluation will be presented. In the frame of the international cooperation in severe fuel damage (SFD) programs the CORA tests are contributing confirmatory and complementary informations to the results from the limited number of in-pile tests. The identification of basic phenomena of the fuel element destruction, observed as a function of temperature, is supported by separate-effects test results. Most important mechanisms are the steam oxidation of the Zircaloy cladding, which determines the temperature escalation, the chemical interaction between UO2 fuel and cladding, which dominates fuel liquefaction, relocation and resulting blockage formation, as well as chemical interactions with Inconel spacer grids and absorber units ((Ag, In, Cd) alloy or B4C), which are leading to extensive low-temperature melt formation around 1200°C. Interrelations between those basic phenomena, resulting for example in cladding deformation (“flowering”) and the dramatic hydrogen formation in response to the fast cooling of a hot bundle by cold water (“quenching”) are determining the evolution paths of fuel element destruction, which are to be identified. A further important task is the abstraction from mechanistic and microstructural details in order to get a rough classification of damage regimes (temperature and extent), a practicable analytical treatment of the materials behaviour, and a basis for decisions in accident mitigation and management procedures.},
	urldate = {2023-12-06},
	journal = {Journal of Nuclear Materials},
	author = {Schanz, G. and Hagen, S. and Hofmann, P. and Schumacher, G. and Sepold, L.},
	month = jun,
	year = {1992},
	pages = {131--145},
}

@article{mustafa_highlights_2019,
	title = {Highlights of the {Integrated} {Uncertainty} {Analysis} of the {Cora} 28 {Bwr} {Experiment} {Using} {Relap}/{Scdapsim}/{Mod3}.4 with {Iua}},
	volume = {2019.27},
	doi = {10.1299/jsmeicone.2019.27.1738},
	abstract = {RELAP/SCDAPSIM, a detailed system thermal hydraulic code with best estimate fuel behavior and severe accident models and correlations, is being developed by Innovative Systems Software with support from an international group of users, universities and research organizations that are part of the SCDAP Development and Training Program (SDTP). The activities of this program have been supported by more than 100 organizations in 30 countries. MOD3.4, the most widely used production version, and MOD3.5, an advanced experimental version, have been used to analyze several historic and recent integral TH/SA experiments as part of a systematic reassessment of the RELAP/SCDAPSIM models and correlations. Reassessment results published in the open literature include the analysis of nuclear and electrically heated experiments. The experiments used for the reassessment were performed in the German CORA and QUENCH facilities, the French PHEBUS facility and the LOFT and PBF facilities at the Idaho National Laboratory in the United States. The reassessment publications available include (a) the use of MOD3.5 to re-analyze the PHEBUS FTP-3 experiment which included irradiated fuel rods and a B4C control rod to assess the impact of recent improvements to the B4C control rod model and several other new and improved models in the code, and (b) the use of MOD3.4 and 3.5 to re-analyze the German CORA-18 and QUENCH-6 electrically heated experiments to assess recent improvements to the electrically heated fuel rod simulator and shroud component models (MOD3.5). The Integrated Uncertainty Analysis (IUA) option has been implemented in both MOD3.4 and MOD3.5. This paper presents a detailed analysis of the CORA-28 BWR experiment using RELAP/SCDAPSIM/MOD3.4, which uses models and correlations most like those used in the original calculations performed in the early 1990s. MOD3.5 calculations will be published in the future. This experiment was performed at the Karlsruhe Institute of Technology, formerly known as Forshungzentrum, Karlsruhe (FzK), in the 1980s as part of a series of CORA BWR specific experiments. CORA-28 was unique in the series and looked at the influence of the preoxidation of the cladding material prior to a bundle heating and melting transient. The results include detailed comparisons with measured results as well as the results of representative uncertainty calculations using the IUA option. Where appropriate, the implications for the uncertainties in calculated results for Fukushima-Daiichi-like conditions will be included.},
	journal = {Proceedings of the ... International Conference on Nuclear Engineering. Book of abstracts : ICONE},
	author = {Mustafa, R. and Bảo, T. Lê and Allison, C. and Hohorst, J.},
	year = {2019},
	pages = {1738},
}

@techreport{the_relap5_development_team_relap5mod3_2001,
	title = {{RELAP5}/{MOD3} {Code} {Manual}: {Code} {Structure}, {System} {Models}, and {Solution} {Methods}},
	url = {https://www.nrc.gov/docs/ML1103/ML110330200.pdf},
	language = {English},
	number = {Vol 1-8},
	institution = {INL},
	author = {{The RELAP5 Development Team}},
	year = {2001},
	pages = {418},
}

@article{allison_role_2010,
	title = {Role of {RELAP}/{SCDAPSIM} in {Nuclear} {Safety}},
	volume = {2010},
	issn = {1687-6075},
	url = {https://www.hindawi.com/journals/stni/2010/425658/},
	doi = {10.1155/2010/425658},
	abstract = {The RELAP/SCDAPSIM code, designed to predict the behaviour of reactor systems during normal and accident conditions, is being developed as part of the international SCDAP Development and Training Program (SDTP). SDTP consists of nearly 60 organizations in 28 countries supporting the development of technology, software, and training materials for the nuclear industry. The program members and licensed software users include universities, research organizations, regulatory organizations, vendors, and utilities located in Europe, Asia, Latin America, and the United States. Innovative Systems Software (ISS) is the administrator for the program. RELAP/SCDAPSIM is used by program members and licensed users to support a variety of activities. The paper provides a brief review of some of the more important activities including the analysis of research reactors and Nuclear Power Plants, design and analysis of experiments, and training.},
	language = {en},
	urldate = {2023-12-05},
	journal = {Science and Technology of Nuclear Installations},
	author = {Allison, C. M. and Hohorst, J. K.},
	month = apr,
	year = {2010},
	pages = {e425658},
}

@misc{noauthor_cora-13_nodate,
	title = {{CORA}-13, {Experiment} on severe fuel damage, core degradation and quench},
	url = {https://www.oecd-nea.org/tools/abstract/detail/csni1023},
	urldate = {2023-12-06},
}

@techreport{scdaprelap5_development_team_scdap_1998,
	title = {{SCDAP}/ {RELAP5}/{MOD3}.2 {Code} {Manual} - {NUREG}/{CR}-6150},
	number = {Vol. 1–5},
	institution = {INL},
	author = {{SCDAP/RELAP5 Development Team}},
	year = {1998},
}

@misc{noauthor_operating_nodate,
	title = {Operating {Experience} {Results} and {Databases}},
	url = {https://nrcoe.inl.gov/AvgPerf/},
	language = {en},
	urldate = {2023-12-15},
	journal = {NRC Web},
}

@book{zhu_transient_2013,
	title = {Transient {Analysis} of {Active} {Residual} {Heat} {Removal} {Process} for {HTR}-{PM}},
	abstract = {An active residual heat removal process is required by the gas-cooled reactor pebble-bed module plant being constructed in China, in order to improve the economical performance of the plant by shortening the restart duration. This process makes use of steam generator and start-up loop as heat sink, whose structure may suffer cold/heat shock while the sudden load of coolant or hot helium at the beginning. To achieve safety and reliability, transient analysis was carried out based on a one-dimensional mathematical model for steam generator and steam pipe of start-up loop. The calculation results show that steam generator should be discharged and pre-cooled; otherwise, boiling will arise and introduce a cold shock to the boiling tubes and tube sheet when coolant began to circulate prior to the helium. Additionally, in avoiding heat shock caused by the sudden load of helium, the helium circulation should be restricted to start with an extreme low flow rate; meanwhile, the coolant of steam generator (water) should have flow rate as large as possible. Finally, a four-step procedure with pre-cooling process of steam generator was recommended; sensitive study for the main parameters was conducted.},
	author = {Zhu, H. and Yang, Xingtuan and Ju, Huaiming and Jiang, Shengyao},
	month = jul,
	year = {2013},
	doi = {10.1115/ICONE21-15448},
}

@inproceedings{european_commission_joint_research_centre_high_2017,
	address = {LU},
	title = {The high temperature gas-cooled reactor :: safety considerations of the ({V}){HTR} modul.},
	shorttitle = {The high temperature gas-cooled reactor},
	url = {https://data.europa.eu/doi/10.2760/270321},
	doi = {10.2760/270321},
	abstract = {Semantic Scholar extracted view of "The High Temperature Gas-cooled Reactor: Safety considerations of the (V)HTR-Modul" by Kugeler Kurt et al.},
	language = {eng},
	urldate = {2023-12-15},
	publisher = {Publications Office},
	author = {{European Commission. Joint Research Centre.}},
	year = {2017},
}

@article{zuying_thermal_2002,
	title = {Thermal hydraulic transient analysis of the {HTR}-10},
	volume = {218},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549302001991},
	doi = {10.1016/S0029-5493(02)00199-1},
	abstract = {The HTR-10 is the first high temperature gas-cooled test module reactor built in China. In the accident analysis, typical design basis accident and beyond design basis accident (BDBA), including the reactivity accident, the loss of external power ATWS, the air ingress accident and water ingress accident into the primary system are selected and detailed analyzed. The results show that the HTR-10 has inherent safety properties. The maximum fuel element temperature will not exceed the limit value 1230°C. The total amount of graphite corrosion maintains no more than 320 kg, the exposure ratio of first coated particles is less than 2.4\% in the BDBA. The released radioactivity is limited at a low level and the ability of fuel particles to retain fission products is not corrupted. Even the consequence of the severest hypothetical accident has no safety danger to the reactor. The reactor can shut itself down via its negative temperature coefficient of reactivity in heat-up conditions.},
	number = {1},
	urldate = {2023-12-14},
	journal = {Nuclear Engineering and Design},
	author = {Zuying, Gao and Lei, Shi},
	month = oct,
	year = {2002},
	pages = {65--80},
}

@article{ekariansyah_analysis_2021,
	title = {The {Analysis} of {Loss} of {Forced} {Flow} {Event} on the {HTGR} {Type} {Experimental} {Power} {Reactor}},
	volume = {10},
	doi = {10.18517/ijaseit.10.5.10817},
	abstract = {Since 2014, Indonesia's National Atomic Energy Agency (BATAN) has been launching a plan to construct a 10 MWt Experimental Power Reactor (Reaktor Daya Eksperimental / RDE). The RDE design is based on the small-sized pebble-bed high-temperature gas-cooled reactor (HTGR) technology with TRISO fuels. By concept, HTR-10 design, which was developed by the INET of China, is used as the reference design. During the development process, a safety analysis report (SAR) of RDE design has to be prepared to be evaluated by the Indonesia Nuclear Regulatory Agency (BAPETEN). The report contains, among others the description of the RDE accident sequences, which can be only provided by simulations using a certain code. This paper emphasizes the transient analysis, which is simulated using RELAP5/SCDAP/Mod3.4 , which is a thermal-hydraulic code specified for light water coolant systems. The simulated event is the loss of primary coolant mass flow, which is caused by the failure of the primary gas blower motor. The methodology of simulation is first by modelling the RDE nuclear steam supply system to verify steady-state operational parameter of the RDE design. The second step is to simulate the event of loss of flow, which is followed by the failure to shut down the reactor. The simulation results in the decrease of the fuel pebble temperature during the event due to the negative fuel temperature reactivity coefficient and the core heat removal by the cavity cooling. Overall, the RELAP5 code has a limitation in the RDE simulation to define two different non-condensable gases, which reduces the accuracy of the simulation results.},
	journal = {International Journal on Advanced Science Engineering and Information Technology},
	author = {Ekariansyah, Andi and Widodo, Surip and Sudarmono, Sudarmono and Susyadi, Susyadi and Isnaini, Muhammad and Dwijayanto, R Andika},
	month = jan,
	year = {2021},
	pages = {1986--1991},
}

@article{zheng_thermohydraulic_2009,
	title = {Thermohydraulic transient studies of the {Chinese} {200MWe} {HTR}-{PM} for loss of forced cooling accidents},
	volume = {36},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454909000395},
	doi = {10.1016/j.anucene.2009.02.007},
	abstract = {Pressurized and Depressurized Loss Of Forced Cooling (PLOFC and DLOFC) are two important design basis accidents for high temperature gas-cooled reactors. Analysis of the reactor characteristic behaviors during LOFC can provide useful reference to the physics, thermohydraulic and structure designs of the reactor core, and can also verify the design of the Residual Heat Removal System (RHRS). The 200MWe High Temperature gas-cooled Reactor Pebble-bed Module project (HTR-PM), designed by the Institute of Nuclear and New Energy Technology (INET) of Tsinghua University in China, is characterized by its inherent safety features, such as shutdown ability via negative temperature coefficients of reactivity, passive mechanism of decay heat removal and so on. In this paper, two cases of loss of forced cooling accidents have been analyzed by using THERMIX code based on the preliminary design of the HTR-PM. With respect to the DLOFC, the effects of related key parameters on the maximum temperatures of fuel element and the reactor pressure vessel (RPV), as well as the decay heat removal by the RHRS are studied in detail. From the calculation results, it is shown that, in the LOFC accidents, the maximum temperatures of the fuel element and the RPV are below the safety limits and the RHRS can effectively remove the decay heat from the core, so as to keep the reactor in a safe state. As compared with the PLOFC accident, the DLOFC accident will lead to a much higher fuel element temperature but lower RPV temperatures and RHRS heat load. The analyses also illustrate that the decay heat level, the emissivity of RPV and water-cooling panel, and the average temperature of the water-cooling panel, play important roles in the DLOFC accident.},
	number = {6},
	urldate = {2023-11-20},
	journal = {Annals of Nuclear Energy},
	author = {Zheng, Yanhua and Shi, Lei and Dong, Yujie},
	month = jun,
	year = {2009},
	pages = {742--751},
}

@inproceedings{zhou_ke-feng_simulation_2014,
	address = {Weihai, China},
	title = {Simulation of {Thermal}-hydraulic {Process} in {Reactor} of {HTR}-{PM}},
	url = {https://nucleus.iaea.org/sites/htgr-kb/HTR2014/Paper%20list/Track6/HTR2014-61303.pdf},
	booktitle = {Proceedings of the {HTR} 2014},
	author = {{ZHOU Ke-feng} and {ZHOU Yang-ping} and {SUI Zhe} and {MA Yuanle}},
	month = oct,
	year = {2014},
}

@article{roberto_scaling_2020,
	title = {Scaling {Analysis} of {Reactor} {Cavity} {Cooling} {System} in {HTR}},
	volume = {206},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2019.1666603},
	doi = {10.1080/00295450.2019.1666603},
	language = {en},
	number = {4},
	urldate = {2023-11-20},
	journal = {Nuclear Technology},
	author = {Roberto, Thiago D. and Lapa, Celso M. F. and Alvim, Antonio C. M.},
	month = apr,
	year = {2020},
	pages = {527--543},
}

@article{chen_solving_2023,
	title = {Solving the issue of reliability data for {FOAK} equipment in an innovative nuclear energy system},
	volume = {163},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197023002524},
	doi = {10.1016/j.pnucene.2023.104817},
	abstract = {There is a demand for the improved safety and economics of advanced nuclear energy systems. The world's first high-temperature gas-cooled reactor pebble-bed module nuclear power plant (HTR-PM Demo Project) is about to be completed in China. This power plant achieved initial full power at the end of 2022. The success of the HTR-PM Demo Project shows the importance of risk-informed initiatives throughout the project with solid support from comprehensive risk assessment. This paper focuses on a technical issue that needs to be solved when conducting risk-informed initiatives for HTR-PM, namely the issue of reliability data for first-of-a-kind (FOAK) equipment. In short, no data for the FOAK equipment are available in existing reliability databases. On the basis of the HTR-PM pilot experience, this paper proposes a process of estimating the required data for the reliability parameters of FOAK equipment. The process has five steps: (1) identification of key parts and assemblies, (2) preliminary determination of the reliability parameters and the associated reference values for the key parts and assemblies, (3) analysis of maintenance management tactics, (4) estimation of reliability parameters for the FOAK equipment using a Bayesian network, and (5) Bayesian updating with operational data. The helium circulator of HTR-PM is taken as an example to demonstrate the feasibility of the proposed process. A lack of reliability data is a common issue for innovative nuclear energy systems. The proposed process is supposed to be universal to all types of innovative design.},
	urldate = {2023-11-20},
	journal = {Progress in Nuclear Energy},
	author = {Chen, Pu and Tong, Jiejuan and Liu, Tao},
	month = sep,
	year = {2023},
	keywords = {Bayesian network, Bayesian updating, Effects and criticality analysis, Failure mode, Helium circulator, Reliability centered maintenance},
	pages = {104817},
}

@inproceedings{j_wolters_g_breitbach_r_moormann_air_nodate,
	address = {Juelich, Federal Republic of Germany},
	title = {Air and {Water} {Ingress} {Accidents} {In} {An} {HTR}-{Modul} of {Side}-{By}-{Side} {Concept}},
	url = {https://art.inl.gov/NGNP/Water%20Ingress%20Assessment%20Review%20Material/INL%20Published%20Material/Air%20and%20Water%20Ingress%20Accidents%20in%20a%20HTR-Modul%20of%20Side-by-Side%20Concept.pdf},
	publisher = {Institut ftir Nukleare Sicherheitsforschung, Kernforschungsanlage Jillich G.m.b.H.,},
	author = {{J. WOLTERS, G. BREITBACH, R. MOORMANN}},
	pages = {13},
}

@inproceedings{yanfei_sun_design_2014,
	address = {China},
	title = {Design on {Hygrometry} {System} of {Primary} {Coolant} {Circuit} of {HTR}-{PM}},
	isbn = {978-7-89395-349-1},
	url = {http://inis.iaea.org/search/search.aspx?orig_q=RN:48076828},
	abstract = {Helium is the primary coolant in HTR-PM If vapor get into the helium in primary coolant circuit because of some special reasons, such as the broken of steam-generator tube, chemical reaction will take effect between the graphite in reactor core and vapor in primary coolant circuit, and the safety of the reactor operation will be influenced So the humidity of the helium in primary coolant circuit is one key parameter of HTR-PM to be monitored in-line Once the humidity is too high, trigger signal of turning off the reactor must be issued The hygrometry system of HTR-PM is consisting of filter, cooler, hygrometry sensor, flow meter, and some valves and tube Helium with temperature of 250℃ is lead into the hygrometry system from the outlet of the main helium blower After measuring, the helium is re-injected back to the primary circuit No helium loses in this processing, and no other pump is needed Key factors and calculations in design on hygrometry system of HTR-PM are described A sample instrument has been made Results of experiments proves that this hygrometry system is suitable for monitoring the humidity of the primary coolant of HTR-PM (author)},
	booktitle = {7th {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology}: {The} modular {HTR} is advancing towards reality {Papers} and {Presentations}},
	publisher = {Tsinghua University},
	author = {{Yanfei, Sun} and {Shuoping, Zhong} and {Xiaojin, Huang}},
	year = {2014},
}

@article{sriyono_analysis_2018,
	title = {Analysis of helium purification system capability during water ingress accident in {RDE}},
	volume = {962},
	doi = {10.1088/1742-6596/962/1/012034},
	abstract = {The water ingress accident caused by steam generator tube rupture (SGTR) in RDE (Experimental Power Reactor) must be anticipated. During the accident, steam from secondary system diffused and mixed with helium gas in the primary coolant. To avoid graphite corrosion in the core, steam will be removed by Helium purification system (HPS). There are two trains in HPS, first train for normal operation and the second for the regeneration and accident. The second train is responsible to clean the coolant during accident condition. The second train is equipped with additional component, i.e. water cooler, post accident blower, and water separator to remove this mixture gas. During water ingress, the water release from rupture tube is mixed with helium gas. The water cooler acts as a steam condenser, where the steam will be separated by water separator from the helium gas. This paper analyses capability of HPS during water ingress accident. The goal of the research is to determine the time consumed by HPS to remove the total amount of water ingress. The method used is modelling and simulation of the HPS by using ChemCAD software. The BDBA and DBA scenarios will be simulated. In BDBA scenario, up to 110 kg of water is assumed to infiltrate to primary coolant while DBA is up to 35 kg. By using ChemCAD simulation, the second train will purify steam ingress maximum in 0.5 hours. The HPS of RDE has a capability to anticipate the water ingress accident.},
	journal = {Journal of Physics: Conference Series},
	author = {Sriyono, Sriyono and Kusumastuti, Rahayu and Bakhri, Syaiful and Sunaryo, Geni},
	month = feb,
	year = {2018},
	pages = {012034},
}

@inproceedings{li_design_2013,
	address = {Chengdu, China},
	title = {Design and {Development} of {HTR}-{PM} {Reactor} {Protection} {System}},
	isbn = {978-0-7918-5582-9},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE21/55829/Chengdu,%20China/251118},
	doi = {10.1115/ICONE21-16706},
	abstract = {High Temperature gas-cooled Reactor-Pebble bed Module (HTR-PM) Reactor Protection System (RPS) is a dedicated system to be designed and developed according to HTR-PM Nuclear Power Plant reactor protection specifications. HTR-PM RPS has the framework of four redundant channels and has two independent and diverse subsystem x and subsystem y to perform different protection functions, which would decrease the potential common cause failure caused by software and increase the system reliability.},
	urldate = {2023-11-19},
	booktitle = {Volume 5: {Fuel} {Cycle}, {Radioactive} {Waste} {Management} and {Decommissioning}; {Reactor} {Physics} and {Transport} {Theory}; {Nuclear} {Education}, {Public} {Acceptance} and {Related} {Issues}; {Instrumentation} and {Controls}; {Fusion} {Engineering}},
	publisher = {American Society of Mechanical Engineers},
	author = {Li, Duo and Xiong, Huasheng and Guo, Chao},
	month = jul,
	year = {2013},
	pages = {V005T13A030},
}

@article{wu_design_2002,
	title = {The design features of the {HTR}-10},
	abstract = {The 10 MW High Temperature Gas-cooled Test Reactor (HTR-10) is a modular pebble bed type reactor. This paper brieﬂy introduces the main design features and safety concept of the HTR-10. The design features of the pebble bed reactor core, the pressure boundary of the primary circuit, the decay heat removal system and the two independent reactor shutdown systems and the barrier of conﬁnement are described in this paper. © 2002 Elsevier Science B.V. All rights reserved.},
	language = {en},
	journal = {Nuclear Engineering and Design},
	author = {Wu, Zongxin and Lin, Dengcai and Zhong, Daxin},
	year = {2002},
}

@article{ernst_use_1983,
	title = {Use of {PRA} and safety goals in nuclear power plant regulation},
	volume = {75},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/0029549383900110},
	doi = {10.1016/0029-5493(83)90011-0},
	abstract = {Probabilistic risk assessments (PRAs) have been performed on a number of nuclear power plants, both by the NRC and industry. The NRC has used risk perspectives gained from PRAs, both in an absolute as well as a relative sense, as an aid in making decisions on plant-specific as well as generic safety issues. However, substantial uncertainties pervade present-day risk assessments, which makes the application of the results of such analyses difficult at best in the regulation of nuclear power. Nonetheless, the Commission approved in January 1983 a policy statement on safety goals for public comment and a two year evaluation period. These safety goals include quantitative design objectives which could serve in the future as risk benchmarks for use by the NRC as part of the decision making process on matters relating to nuclear safety. While the Commission's policy statement explicitly excludes the safety goals from use both in licensing cases and in regulation for the two year evaluation period, PRA will be used generically and on a plant-specific basis more and more to assess the importance of new safety issues, prioritize resources within the agency, and test the adequacy of (or in some instances the need for) NRC's regulations.},
	number = {3},
	urldate = {2023-11-07},
	journal = {Nuclear Engineering and Design},
	author = {Ernst, Malcolm L.},
	month = jun,
	year = {1983},
	pages = {453--462},
}

@techreport{southern_company_high_2018,
	type = {Project},
	title = {High {Temperature}, {Gas}-{Cooled} {Pebble} {Bed} {Reactor} licensing {Modernization} {Project} {Demonstration}},
	url = {https://www.nrc.gov/docs/ML1822/ML18228A779.pdf},
	language = {English},
	number = {SC-29980-200 Rev 0},
	urldate = {2023-10-07},
	institution = {Southern Company},
	author = {Southern Company},
	month = aug,
	year = {2018},
	pages = {42},
}

@article{fleming_probabilistic_1981,
	title = {Probabilistic risk assessment of {HTGRs}},
	volume = {2},
	issn = {0143-8174},
	url = {https://www.sciencedirect.com/science/article/pii/0143817481900251},
	doi = {10.1016/0143-8174(81)90025-1},
	abstract = {Probabilistic risk assessment (PRA) methods have been applied to gas-cooled reactors for more than a decade and to HTGRs for more than six years in the programmes sponsored by the US Department of Energy. Significant advancements to the development of PRA methodology in these programmes are summarized as are the specific applications of the methods to HTGRs. Emphasis here is on PRA as a tool for evaluating HTGR design options. Current work and future directions are also discussed.},
	number = {1},
	urldate = {2023-10-06},
	journal = {Reliability Engineering},
	author = {Fleming, K. N. and Houghton, W. J. and Hannaman, G. W. and Joksimovic, V.},
	month = jan,
	year = {1981},
	pages = {17--25},
}

@incollection{mizokami_event_2015,
	address = {Cham},
	title = {Event {Sequence} of the {Fukushima} {Daiichi} {Accident}},
	isbn = {978-3-319-12090-4},
	url = {https://doi.org/10.1007/978-3-319-12090-4_2},
	abstract = {On March 11, 2011, the Great East Japan Earthquake and subsequent tsunami hit Fukushima Daiichi Nuclear Power Station. Flooding by the tsunami induced loss of AC and/or DC power for reactor cooling, hence the reactor water level decreased and fuel was exposed. Water reacting with high temperature fuel metal covering resulted in hydrogen generation and hydrogen explosion of reactor buildings. This accident caused radioactive release to the environment. In this chapter, an attempt has been made to understand in detail the mechanism of the accident progression for Units 1–3 that were in operation by utilizing results of computer simulations. It should be noted that, due to limited information and capability of the state-of-the-art severe-accident simulation tools, there are still unanswered questions, which should be tackled by academic research for improving and enhancing safety for the nuclear industry now and in the future.},
	language = {en},
	urldate = {2023-11-06},
	booktitle = {Reflections on the {Fukushima} {Daiichi} {Nuclear} {Accident}: {Toward} {Social}-{Scientific} {Literacy} and {Engineering} {Resilience}},
	publisher = {Springer International Publishing},
	author = {Mizokami, Shinya and Kumagai, Yuji},
	editor = {Ahn, Joonhong and Carson, Cathryn and Jensen, Mikael and Juraku, Kohta and Nagasaki, Shinya and Tanaka, Satoru},
	year = {2015},
	doi = {10.1007/978-3-319-12090-4_2},
	keywords = {Accident progression, Fukushima Daiichi nuclear power station, Great East Japan earthquake, MAAP simulation, Severe accident},
	pages = {21--50},
}

@article{tong_development_2012,
	series = {5th {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology} ({HTR} 2010)},
	title = {Development of {Probabilistic} {Safety} {Assessment} with respect to the first demonstration nuclear power plant of high temperature gas cooled reactor in {China}},
	volume = {251},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549311008491},
	doi = {10.1016/j.nucengdes.2011.09.055},
	abstract = {Due to the unique concept of HTR-PM (High Temperature Gas Cooled Reactor-Pebble Bed Module) design, Chinese nuclear authority has anticipated that HTR-PM will bring challenge to the present regulation. The pilot use of PSA (Probabilistic Safety Assessment) during HTR-PM design and safety review is deemed to be the necessary and efficient tool to tackle the problem, and is actively encouraged as indicated in the authority's specific policy statement on HTR-PM project. The paper summarizes the policy statement to set up the base of PSA development and application activities. The up-to-date status of HTR-PM PSA development and the risk-informed application activities are introduced in this paper as the follow-up response to the policy statement. For open discussion, the paper hereafter puts forward several technical issues which have been encountered during HTR-PM PSA development. Since HTR-PM PSA development experience has the general conclusion that many of the PSA elements can be and have been implemented successfully by the traditional PSA techniques, only the issues which extra innovative efforts may be needed are highlighted in this paper. They are safety goal and risk metrics, PSA modeling framework for the non-water reactors, passive system reliability evaluation, initiating events frequencies and component reliability data estimation techniques for the new reactors and so on. The paper presents the way in which the encountered technical issues were or will be solved, although the proposed way may not be the ultimate best solution. The paper intends to express the standpoint that although the PSA of new reactor has the inherent weakness due to the insufficient information and larger data uncertainty, the problem of component reliability data is much less severe than people have conceived. The unique design conception and functional features of the reactors can influence the results more significantly than the component reliability data. What we are benefited from PSA is indeed the systematic way which PSA follows. This is more important especially for the new reactors.},
	urldate = {2023-10-05},
	journal = {Nuclear Engineering and Design},
	author = {Tong, Jiejuan and Zhao, Jun and Liu, Tao and Xue, Dazhi},
	month = oct,
	year = {2012},
	pages = {385--390},
}

@techreport{iaea_high_2011,
	address = {Vienna},
	type = {Status {Report}},
	title = {High {Temperature} {Gas} {Cooled} {Reactor} - {Pebble}-{Bed} {Module} ({HTR}-{PM})},
	url = {https://aris.iaea.org/PDF/HTR-PM.pdf},
	language = {English},
	number = {96},
	urldate = {2023-09-25},
	institution = {International Atomic Energy Agency},
	author = {IAEA},
	year = {2011},
	pages = {11},
}

@techreport{iaea_implementation_2020,
	address = {Vienna},
	type = {Technical {Report}},
	title = {Implementation and {Effectiveness} of {Actions} {Taken} at {Nuclear} {Power} {Plants} {Following} the {Fukushima} {Daiichi} {Accident}},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/TE-1930web.pdf},
	language = {English},
	number = {1930},
	institution = {IAEA},
	author = {{IAEA}},
	year = {2020},
	pages = {214},
}

@misc{noauthor_fukushima_nodate,
	title = {Fukushima {Daiichi} {Accident} - {World} {Nuclear} {Association}},
	url = {https://world-nuclear.org/information-library/safety-and-security/safety-of-plants/fukushima-daiichi-accident.aspx},
	urldate = {2023-11-06},
}

@article{mercier_simplified_2021,
	title = {A simplified analysis of the {Chernobyl} accident},
	volume = {7},
	copyright = {© B. Mercier et al., published by EDP Sciences, 2021},
	issn = {2491-9292},
	url = {https://www.epj-n.org/articles/epjn/abs/2021/01/epjn200018/epjn200018.html},
	doi = {10.1051/epjn/2020021},
	abstract = {We show with simplified numerical models, that for the kind of RBMK operated in Chernobyl: The core was unstable due to its large size and to its weak power counter-reaction coefficient, so that the power of the reactor was not easy to control even with an automatic system. Xenon oscillations could easily be activated. When there was xenon poisoning in the upper half of the core, the safety rods were designed in such a way that, at least initially, they were increasing (and not decreasing) the core reactivity. This reactivity increase has been sufficient to lead to a very high pressure increase in a significant amount of liquid water in the fuel channels thus inducing a strong propagating shock wave leading to a failure of half the pressure tubes at their junction with the drum separators. The depressurization phase (flash evaporation) following this failure has produced, after one second, a significant decrease of the water density in half the pressure tubes and then a strong reactivity accident due to the positive void effect reactivity coefficient. We evaluate the fission energy released by the accident},
	language = {en},
	urldate = {2023-11-06},
	journal = {EPJ Nuclear Sciences \& Technologies},
	author = {Mercier, Bertrand and Yang, Di and Zhuang, Ziyue and Liang, Jiajie},
	year = {2021},
	note = {Publisher: EDP Sciences},
	pages = {1},
}

@book{noauthor_chernobyl_1992,
	address = {Vienna},
	series = {{INSAG} {Series}},
	title = {The {Chernobyl} {Accident}: {Updating} of {INSAG}-1},
	isbn = {92-0-104692-8},
	url = {https://www.iaea.org/publications/3786/the-chernobyl-accident-updating-of-insag-1},
	number = {7},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {1992},
}

@techreport{the_international_nuclear_safety_advisory_group_chernobyl_nodate,
	title = {The {Chernobyl} {Accident}: {Updating} {Of} {INSAG}-1},
	author = {{The International Nuclear Safety Advisory Group}},
}

@techreport{iaea_ines_2013,
	type = {Text},
	title = {{INES}: {The} {International} {Nuclear} and {Radiological} {Event} {Scale} {User}'s {Manual}},
	shorttitle = {{INES}},
	url = {https://www.iaea.org/publications/10508/ines-the-international-nuclear-and-radiological-event-scale-users-manual},
	language = {en},
	urldate = {2023-11-05},
	institution = {International Atomic Energy Agency},
	author = {{IAEA}},
	year = {2013},
	note = {Publication Title: INES: The International Nuclear and Radiological Event Scale User\&\#039;s Manual},
	pages = {1--206},
}

@book{oecd_chernobyl_2003,
	title = {Chernobyl: {Assessment} of {Radiological} and {Health} {Impacts}: 2002 {Update} of {Chernobyl}: {Ten} {Years} {On}},
	isbn = {978-92-64-18487-9},
	shorttitle = {Chernobyl},
	url = {https://www.oecd-ilibrary.org/nuclear-energy/chernobyl-assessment-of-radiological-and-health-impacts_9789264184879-en},
	language = {en},
	urldate = {2023-11-05},
	publisher = {OECD},
	author = {{OECD} and {Nuclear Energy Agency}},
	month = mar,
	year = {2003},
	doi = {10.1787/9789264184879-en},
}

@misc{nrc_guidance_2016,
	title = {Guidance on {Making} {Changes} to {Emergency} {Plans} for {Nuclear} {Power} {Reactor}, {Rev} 1.0},
	language = {en},
	author = {NRC},
	month = jul,
	year = {2016},
}

@techreport{grabaskas_regulatory_2016,
	title = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}: {Mechanistic} {Source} {Term} – {Trial} {Calculation}},
	shorttitle = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}},
	url = {http://www.osti.gov/servlets/purl/1334189/},
	language = {en},
	number = {ANL-ART--49-Vol1-Vol2, 1334189},
	urldate = {2024-08-15},
	author = {Grabaskas, David and Bucknor, Matthew and Jerden, James and Brunett, Acacia J. and Denman, Matthew and Clark, Andrew and Denning, Richard S. and {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)}},
	month = oct,
	year = {2016},
	doi = {10.2172/1334189},
	pages = {ANL--ART--49--Vol1--Vol2, 1334189},
}

@techreport{vedros_probabilistic_2020,
	title = {Probabilistic {Risk} {Assessment} of a {Light} {Water} {Reactor} {Coupled} with a {High} {Temperature} {Electrolysis} {Hydrogen} {Production} {Plant}},
	url = {https://www.osti.gov/biblio/1691486},
	abstract = {Two generic probabilistic risk assessments (PRA) for the addition of a heat extraction system (HES) addition to a light water reactor (LWR) are performed, one for a pressurized water reactor (PWR) and one for a boiling water reactor (BWR). The results investigate the applicability of the potential licensing approaches which do not require a full U.S. Nuclear Regulatory Commission (NRC) licensing review. The PRAs are generic, and some assumptions are made. Many conservative assumptions from a the preliminary PWR PRA report were eliminated using design data for both the HES and the high temperature electrolysis facility (HTEF). The results of the PRA indicate that the 10 CFR 50.59 licensing approach is justified due to the minimal increase in initiating event frequencies for all DBAs, none exceeding 5.6\%. The PRA results for CDF and LERF support the use of RG 1.174 as further risk information that supports a change without a full LAR. Further insights provided through hazard analysis and sensitivity studies confirm with high confidence that the safety case for licensing an HES addition and a HTEF sited at 1.0 km from the NPP is strong and that the placement of a HTEF at 0.5 km is a viable case. Site specific information can alter these conclusions.},
	language = {English},
	number = {INL/EXT-20-60104-Rev000},
	urldate = {2024-08-14},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Vedros, Kurt G. and Christian, Robby and Rabiti, Cristian},
	month = oct,
	year = {2020},
	doi = {10.2172/1691486},
}

@article{de_la_rosa_blul_determination_2021,
	title = {Determination of {Emergency} {Planning} {Zones} distances and scaling-based comparison criteria for downsized {Nuclear} {Power} {Plants}},
	volume = {382},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549321003198},
	doi = {10.1016/j.nucengdes.2021.111367},
	abstract = {Nuclear Small Modular Reactors (SMR) present innovative features in design and safety compared to existing Nuclear Power Plants (NPP). Some of these features may turn into a reduction in radioactive releases –both in magnitude and frequency. It seems reasonable to think that smaller plants, i.e. featuring lower power levels, should present lower radioactive releases and offsite consequences. However, how small is small enough cannot be addressed through direct comparison. Furthermore, since multiple nuclear sites to compensate for the same amount of power provided by a single, large nuclear site, might be needed, such direct comparison is ill-conceived. Scaling-based criteria to facilitate comparison of radioactive releases between plants of different size –i.e. power– are proposed. Such criteria set limits to radioactive releases and offsite radioactive risk for SMRs so that offsite consequences of replacing large NPPs by a wider set of SMR sites are not exceeded when assessed globally, i.e. in terms of power generation. The first, deterministic-oriented criterion looks at the radioactive source strength of the SMR based on the maximum size of the SMR Emergency Planning Zone (EPZ) in order not to exceed the EPZ of another NPP when normalizing the EPZ to the power generating unit. The second, risk-informed criterion, looks at the sum of the radioactive harm caused by any event considered under probabilistic analysis application weighted by its frequency, i.e. standard definition of risk. Aside from these two scaling-based criteria for offsite nuclear hazard comparison between nuclear sites of different size, this paper presents two different methods for the determination of EPZ distances. The first method is straightforward based on plant-specific data for dose-consequence calculation, whereas the second, inverse method, builds on extrapolating the EPZ distance of a reference, large NPP down to the SMR. The scaling-based criteria and the methods for the determination of the EPZ distance are put into practice in an application exercise for an integral Pressurized Water Reactor (PWR) SMR.},
	urldate = {2024-08-15},
	journal = {Nuclear Engineering and Design},
	author = {de la Rosa Blul, Juan Carlos},
	month = oct,
	year = {2021},
	keywords = {Dose calculation, Emergency Planning Zone, Nuclear Safety, Radioactive releases, Small Modular Reactor},
	pages = {111367},
}

@inproceedings{curtis_l_smith_separation_2006,
	address = {Reno, NV USA},
	title = {Separation {Requirements} for a {Hydrogen} {Production} {Plant} and {High}-{Temperature} {Nuclear} {Reactor}},
	url = {https://www.researchgate.net/publication/255944846_Separation_Requirements_for_a_Hydrogen_Production_Plant_and_High-Temperature_Nuclear_Reactor},
	urldate = {2024-08-14},
	author = {{Curtis L. Smith} and {Scott Beck} and {William Galyean}},
	month = jun,
	year = {2006},
}

@misc{steven_r_sherman_nuclear_2007,
	series = {{INL}/{CON}},
	title = {Nuclear {Plant}/{Hydrogen} {Plant} {Safety}: {Issues} and {Approaches} - {CORE}},
	copyright = {Idaho National Laboratory},
	url = {https://core.ac.uk/outputs/71313119/?utm_source=pdf&utm_medium=banner&utm_campaign=pdf-decoration-v1},
	number = {06-12053},
	urldate = {2024-08-14},
	author = {{Steven R. Sherman}},
	month = jun,
	year = {2007},
}

@article{sherman_nuclear_nodate,
	title = {{NUCLEAR} {PLANT}/{HYDROGEN} {PLANT} {SAFETY}: {ISSUES} {AND} {APPROACHES}},
	abstract = {The U.S. Department of Energy, through its agents the Next Generation Nuclear Plant Project and the Nuclear Hydrogen Initiative, is working on developing the technologies to enable the large scale production of hydrogen using nuclear power. A very important consideration in the design of a co-located and connected nuclear plant/hydrogen plant facility is safety. This study provides an overview of the safety issues associated with a combined plant and discusses approaches for categorizing, quantifying, and addressing the safety risks.},
	language = {en},
	author = {Sherman, Steven R},
}

@techreport{reckley_nuclear_2010,
	address = {Paris},
	title = {Nuclear safety and regulatory considerations for nuclear hydrogen production},
	url = {https://www.oecd-ilibrary.org/nuclear-energy/nuclear-production-of-hydrogen/nuclear-safety-and-regulatory-considerations-for-nuclear-hydrogen-production_9789264087156-41-en},
	abstract = {The use of a nuclear power plant to produce hydrogen or for other process heat applications will present challenges to the licensing process. Potential safety and regulatory issues have been evaluated to identify possible research needs, policy concerns and licensing approaches. A brief description of nuclear power plant licensing in the United States and a discussion of specific issues for using nuclear power plants for process heat applications are presented.},
	language = {en},
	urldate = {2024-08-14},
	institution = {OECD},
	author = {Reckley, William},
	month = jun,
	year = {2010},
	doi = {10.1787/9789264087156-41-en},
	pages = {355--361},
}

@misc{noauthor_part_nodate,
	title = {{PART} 52—{LICENSES}, {CERTIFICATIONS}, {AND} {APPROVALS} {FOR} {NUCLEAR} {POWER} {PLANTS}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part052/full-text.html},
	abstract = {PART 52—LICENSES, CERTIFICATIONS, AND APPROVALS FOR NUCLEAR POWER PLANTS},
	language = {en-US},
	urldate = {2024-08-14},
	journal = {NRC Web},
}

@book{oecd_nuclear_2010,
	address = {Paris},
	title = {Nuclear {Production} of {Hydrogen}: {Fourth} {Information} {Exchange} {Meeting}, {Oakbrook}, {Illinois}, {USA} , 14-16 {April} 2009},
	shorttitle = {Nuclear {Production} of {Hydrogen}},
	url = {https://www.oecd-ilibrary.org/nuclear-energy/nuclear-production-of-hydrogen_9789264087156-en},
	abstract = {This report describes the scientific and technical challenges associated with the production of hydrogen using heat and/or electricity from nuclear power plants, with special emphasis on recent developments in high-temperature electrolysis and the...},
	language = {en},
	urldate = {2024-08-14},
	publisher = {Organisation for Economic Co-operation and Development},
	author = {{OECD}},
	year = {2010},
}

@article{scarlat_preliminary_2012,
	series = {5th {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology} ({HTR} 2010)},
	title = {Preliminary safety analysis of a {PBMR} supplying process heat to a co-located ethylene production plant},
	volume = {251},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549311010582},
	doi = {10.1016/j.nucengdes.2011.10.069},
	abstract = {This paper considers the safety analysis and licensing approach for co-locating a pebble bed modular reactor (PBMR) to provide process heat to an ethylene production unit. The PBMR is an advanced nuclear reactor design that provides 400MW of thermal energy. Ethylene production is an energy intensive process that utilizes large gas furnaces to provide the heat for the process. Coupling a PBMR with an ethylene production plant would open a new market for nuclear power, and would provide the chemical industry with a cleaner power source, helping to achieve the Clean Air Act standards, and eliminating the 0.5ton of CO2 emissions per ton of produced ethylene. Our analysis uses the Chevron Phillips chemical plant in Sweeney, TX as a prototypical site. The plant has four ethylene production trains, with a total power consumption of 2.4GW, for an ethylene output of 3.7milliontons per year, 4\% of the global ethylene production capacity. This paper proposes replacement of the gas furnaces by low-emission PBMR modules, and presents the safety concerns and risk mitigation and management options for this coupled system. Two coupling design options are proposed, and the necessary changes to the design basis events and severe accidents for the PBMR licensing application are discussed. A joint effort between the chemical and the nuclear entities to optimize the coupling design, establish preventive maintenance procedures, and develop emergency response plans for both of the units is recommended.},
	urldate = {2024-07-11},
	journal = {Nuclear Engineering and Design},
	author = {Scarlat, Raluca O. and Cisneros, Anselmo T. and Koutchesfahani, Tawni and Hong, Rada and Peterson, Per F.},
	month = oct,
	year = {2012},
	pages = {53--59},
}

@article{agyekum_evaluating_2024,
	title = {Evaluating the linkages between hydrogen production and nuclear power plants – {A} systematic review of two decades of research},
	volume = {65},
	issn = {0360-3199},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319924013636},
	doi = {10.1016/j.ijhydene.2024.04.102},
	abstract = {The need for clean energy to meet the world's increasing energy needs has compelled global leaders to identify other sources of energy generation. Since fossil fuels must be replaced in the energy sector to combat climate change, hydrogen may be the best possible low-emitting alternative energy source. Currently, three energy sources are used worldwide to produce hydrogen: renewable, nuclear, and fossil fuels. Using a bibliometric approach, this study examines how nuclear energy or power has been used to produce hydrogen over the past 20 years. Biblioshiny, a package in R-studio, and VOSviewer were the tools used for the analysis. With an annual growth rate of 7.81\%, research on the topic of study has advanced significantly over the years. Over the years, 999 individuals have contributed to the research, using a total of 668 keywords for their studies. Countries with operational nuclear power plants are more interested in nuclear hydrogen production research, potentially due to their quest to diversify their energy use compared to those planning to add nuclear energy. Similarly, studies on how to reduce impact of accidents at such facilities have gained interest since 2010–2023, indicating a growing interest in how to reduce such incidences. The study also identified the trend and evolution of nuclear hydrogen production during the period of study.},
	urldate = {2024-07-05},
	journal = {International Journal of Hydrogen Energy},
	author = {Agyekum, Ephraim Bonah},
	month = may,
	year = {2024},
	keywords = {Bibliometric analysis, Copper-chlorine cycle, Hydrogen economy, Nuclear hydrogen production, Nuclear power plants},
	pages = {606--625},
}

@techreport{vedros_expansion_2023,
	title = {Expansion of {Hazards} and {Probabilistic} {Risk} {Assessments} of a {Light}-{Water} {Reactor} {Coupled} with {Electrolysis} {Hydrogen} {Production} {Plants}},
	url = {https://www.osti.gov/biblio/1998560},
	abstract = {This report builds upon the body of work sponsored by the Department of Energy (DOE) Light-Water Reactor Sustainability (LWRS) Flexible Power Operation and Generation (FPOG) program that presented generic probabilistic risk assessments (PRAs) for the addition of a heat extraction system (HES) to light-water reactors to support the co-location of a high temperature hydrogen electrolysis facility (HTEF). Probabilistic and deterministic hazards assessments and risk analyses are leveraged throughout this report. Several improvements and new analyses are included in this report. First, higher amounts of detail in the specifications of the generic HTEFs are used to produce scaled results for a 100, 500, and 1000 MW nominal hydrogen production facility. An additional hazard assessment of 1000 kg of hydrogen storage is performed. The facility hazards and footprint are assessed to determine the safe distance required for placement near the nuclear power plant (NPP). Second, specific designs for corresponding HESs for the different levels of support required by the HTEFs are analyzed in the PRA model. Third, a hazards analysis of the specified HTEFs leads not only to effects of the quantified risk assessment for the NPP, but also qualitative hazards assessment for the community. Finally, a seismic analysis and a high winds analysis have each been added to the PRA. The results investigate the applicability of the potential licensing approaches which do not require a full United States (U.S.) Nuclear Regulatory Commission (NRC) licensing review. The PRAs are generic and include listed assumptions. The HTEF design built for this project has further eliminated many conservative assumptions from the prior PRAs in this series. The PRA results indicate that the 10 CFR 50.59 licensing approach is justified due to the minimal increase in initiating event frequencies for all design basis accidents, with none exceeding 7.7\%. The PRA results for core damage frequency and large early release frequency support the use of NRC Regulation Guide 1.174 as further risk information that supports a change without a full licensing amendment review. The hazard analyses and PRA confirm the need for engineered blast barriers of storage tanks and the common production header leaving the HTEF. The hazards analyses and PRA also confirm with high confidence that using the assumptions of design in this report that the safety case for licensing an HES addition and an HTEF sited with its unprotected high-pressure stage components 187 meters from the NPP’s transmission towers (the most fragile structure, system, and component) is strong.},
	language = {English},
	number = {INL/RPT-23-74319-Rev000},
	urldate = {2024-07-05},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Vedros, Kurt G. and Christian, Robby and Yang Hui Otani, Courtney Mariko},
	month = aug,
	year = {2023},
	doi = {10.2172/1998560},
}

@article{khan_using_2019,
	title = {Using next generation nuclear power reactors for development of a techno-economic model for hydrogen production},
	volume = {43},
	copyright = {© 2019 John Wiley \& Sons, Ltd.},
	issn = {1099-114X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/er.4683},
	doi = {10.1002/er.4683},
	abstract = {Nuclear and hydrogen are considered to be the most promising alternatives energy sources in terms of meeting future demand and providing a CO₂-free environment, and interest in the development of more cost-effective hydrogen production plants is increasing—and nuclear-powered hydrogen generation plants may be a viable alternative. This paper is a report on investigating the application of new generation nuclear power plants to hydrogen production and development of an associated techno-economic model. In this paper, theoretical and computational assessments of generations II, III+, and IV nuclear power plants for hydrogen generation scenarios have been reported. Technical analyses were conducted on each reactor type—in terms of the design standard, fuel specification, overnight capital cost, and hydrogen generation. In addition, a theoretical model was developed for calculating various hydrogen generation parameters, and it was then extended to include an economic assessment of nuclear power plant-based hydrogen generation. The Hydrogen Economic Evaluation Program originally developed by the International Atomic Energy Agency was used for calculating various parameters, including hydrogen production and storage costs, as well as equity, operation and maintenance (O\&M), and capital costs. The results from each nuclear reactor type were compared against reactor parameters, and the ideal candidate reactor was identified. The simulation results also verified theoretically proven results. The main objective of the research was to conduct a prequalification assessment for a cogeneration plant, by developing a model that could be used for technical and economic analysis of nuclear hydrogen plant options. It was assessed that high-temperature gas-cooled reactors (HTGR-PM and PBR200) represented the most economical and viable plant options for hydrogen production. This research has helped identify the way forward for the development of a commercially viable, nuclear power-driven, hydrogen generation plant.},
	language = {en},
	number = {13},
	urldate = {2024-07-05},
	journal = {International Journal of Energy Research},
	author = {Khan, Salah Ud-Din},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/er.4683},
	keywords = {commercially viable plant, comparative analysis, hydrogen generation, nuclear power plants, simulation, techno-economic model, theoretical model},
	pages = {6827--6839},
}

@incollection{oecd_nuclear_2010-1,
	title = {Nuclear safety and regulatory considerations for nuclear hydrogen production},
	isbn = {978-92-64-08713-2 978-92-64-08715-6},
	url = {https://www.oecd-ilibrary.org/nuclear-energy/nuclear-production-of-hydrogen/nuclear-safety-and-regulatory-considerations-for-nuclear-hydrogen-production_9789264087156-41-en},
	abstract = {The use of a nuclear power plant to produce hydrogen or for other process heat applications will present challenges to the licensing process. Potential safety and regulatory issues have been evaluated to identify possible research needs, policy concerns and licensing approaches. A brief description of nuclear power plant licensing in the United States and a discussion of specific issues for using nuclear power plants for process heat applications are presented.},
	language = {en},
	urldate = {2024-08-14},
	booktitle = {Nuclear {Production} of {Hydrogen}},
	publisher = {OECD},
	collaborator = {{OECD}},
	month = jun,
	year = {2010},
	doi = {10.1787/9789264087156-41-en},
	note = {Series Title: Nuclear Science},
	pages = {355--361},
}

@article{marques_naoh_2018,
	title = {{NaOH} thermochemical water splitting cycle: {A} new approach in hydrogen production based on sodium cooled fast reactor},
	volume = {43},
	issn = {0360-3199},
	shorttitle = {{NaOH} thermochemical water splitting cycle},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319918307572},
	doi = {10.1016/j.ijhydene.2018.03.027},
	abstract = {Currently, the main energy options employed to maintain essential living standards, such as electricity, hot water and refrigeration, come from fossil fuels whose burning contributes to high environmental impacts like global warming. Then, the development of clean fuels is an important step towards sustainability. Hydrogen (H2) can achieve such goal because its combustion mainly releases water. It can be obtained in different ways, including thermochemical cycles that consist of a sequence of chemical reactions to split water molecules into hydrogen and oxygen through a heat source at specific temperature conditions. Some traditional thermochemical processes available in the literature, like the cycles S-I (sulfur-iodine) and Cu-Cl (copper-chlorine) require temperature limits near to 900 °C and 550 °C, respectively. Additionally, the Mg-Cl (magnesium-chlorine) cycle can operate at temperatures about 450 °C while the U-Eu-Br (uranium-europium-bromium) cycle has its maximum operational temperature of 300 °C. In contrast to Cu-Cl, Mg-Cl and U-Eu-Br processes, which have relatively low and viable temperature ranges, there are thermochemical cycles that demand temperatures higher than 1000 °C. The low temperature requirement of a thermochemical process facilitates hydrogen production because it allows the use of many different heat sources like solar, nuclear and waste heat. In this line of reason, in a past work, it was proposed a new set of chemical reactions able to produce hydrogen, as a thermochemical process, which basic elements are sodium (Na), oxygen (O) and hydrogen (H). This system is named in this work as NaOH cycle and has potential to operate at temperatures about 400–500 °C or even below 400 °C. So, the aim of the paper is to present and evaluate a theoretical hydrogen production plant based on the NaOH cycle considering a Sodium Cooled Fast Reactor (SFR) as the heat source. The system was modeled in the Engineering Equation Solver (EES) software according to mass balances in addition to the first and second laws of thermodynamics. In this way, it was possible, for the first time, to estimate the amount of hydrogen obtained in this process. According to the results, the system can produce 1.321 kg/s of H2, equivalent to 114 ton/day. This is a theoretical maximized value, because some aproximations were considered in the calculations. Additionally, the NaOH system has the potential for improvements through more research because it is in the initial stage of development.},
	number = {16},
	urldate = {2024-07-05},
	journal = {International Journal of Hydrogen Energy},
	author = {Marques, João G. O. and Costa, Antonella L. and Pereira, Claubia},
	month = apr,
	year = {2018},
	keywords = {Hydrogen production, Low temperature, Na-O-H cycle, Thermochemical cycles, Thermodynamics},
	pages = {7738--7753},
}

@article{pinsky_comparative_2020,
	title = {Comparative review of hydrogen production technologies for nuclear hybrid energy systems},
	volume = {123},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S014919702030069X},
	doi = {10.1016/j.pnucene.2020.103317},
	abstract = {Nuclear hybrid energy systems (NHES) have potential to capitalize on (1) producing multiple commodities, i.e. electricity and hydrogen as well as (2) allowing for electricity grid load following, with hydrogen production during low electricity prices. Using nuclear thermal energy and electricity (from the reactor itself) makes hydrogen production an economically attractive option. The reactor can continuously operate at full capacity, sending excess heat and electricity towards hydrogen production, which could either be sold or converted back to electricity using fuel cells at high price times. Several hydrogen production technologies exist, but in this study the focus is on processes that require heat and electricity. These candidates include alkaline water electrolysis, proton exchange membrane (PEM) electrolysis, solid oxide electrolysis cells (SOEC), thermochemical sulfur–iodine (S–I), calcium-bromide (Ca-Br) cycles, hybrid sulfur (HyS) and copper–chlorine (Cu–Cl) cycles. Each have different minimum temperature requirements which can be coupled to Generation III and IV reactor outlet temperatures: low (¡300 °C), medium (¡750 °C), and high (¡950 °C). Energy input and material process flow diagrams were created for all technologies at compatible reactor temperatures and compared to the most common commercially operating hydrogen production method: steam methane reforming (SMR). Technology readiness levels (TRLs) and costs were also compared. The TRL of most systems is still below commercial development, and hydrogen productions costs are still too high to be economic without additional policy and/or other developments.},
	urldate = {2024-07-05},
	journal = {Progress in Nuclear Energy},
	author = {Pinsky, Roxanne and Sabharwall, Piyush and Hartvigsen, Jeremy and O’Brien, James},
	month = may,
	year = {2020},
	keywords = {Electrolysis, Hybrid water splitting, Hydrogen production, Nuclear hybrid energy systems (NHES), Steam methane reforming, Thermochemical water splitting},
	pages = {103317},
}

@article{bhattacharyya_assessing_2023,
	title = {Assessing techno-economic uncertainties in nuclear power-to-{X} processes: {The} case of nuclear hydrogen production via water electrolysis},
	volume = {48},
	issn = {0360-3199},
	shorttitle = {Assessing techno-economic uncertainties in nuclear power-to-{X} processes},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319922056543},
	doi = {10.1016/j.ijhydene.2022.11.315},
	abstract = {Nuclear assisted low carbon hydrogen production by water electrolysis represents a potential application of nuclear cogeneration towards deep decarbonization of several fossil fuel-dependent industrial sectors. This work builds a probabilistic techno-commercial model of a water electrolysis plant coupled to an existing nuclear reactor for base load operations. The objective is to perform discounted cash flow (DCF) calculations for levelized nuclear hydrogen production cost under input parameter uncertainty. The probability distributions of inputs are used with the Monte Carlo-Latin Hypercube (MC-LH) sampling technique to generate 105 input scenarios and corresponding distribution of the levelized or life cycle hydrogen production cost instead of deterministic point values. Based on current techno-economic conditions, the levelized production costs of electrolytic hydrogen using electricity from large water-cooled nuclear reactors are determined to be US \$ 12.205 ± 1.342, 8.384 ± 1.148 and 6.385 ± 1.051/kg H2 respectively at rated alkaline water electrolyser capacities of 1.25 MW(e), 2.5 MW(e) and 5 MW(e). The corresponding values for PEM water electrolysers are US \$ 13.162 ± 1.356, 8.891 ± 1.141 and 6.663 ± 1.057/kg H2. The potential for flexible nuclear reactor operation and management of power demand uncertainties through nuclear hydrogen cogeneration is also examined through a case study.},
	number = {38},
	urldate = {2024-07-05},
	journal = {International Journal of Hydrogen Energy},
	author = {Bhattacharyya, Rupsha and Singh, K. K. and Bhanja, K. and Grover, R. B.},
	month = may,
	year = {2023},
	keywords = {Discounted cash flows, Hydrogen energy, Levelized cost, Monte Carlo simulations, Nuclear cogeneration, Uncertainty analysis},
	pages = {14149--14169},
}

@article{karaca_life_2020,
	title = {Life cycle assessment study on nuclear based sustainable hydrogen production options},
	volume = {45},
	issn = {0360-3199},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319920321674},
	doi = {10.1016/j.ijhydene.2020.06.030},
	abstract = {Hydrogen is considered an important energy carrier and fuel within the context of sustainable energy technologies. However, finding the ways to produce hydrogen in a more nature-friendly manner is vital while increasing the use of hydrogen in energy applications. In the current study, environmental impacts of five different hydrogen production options via nuclear energy are comparatively assessed through a life cycle assessment (LCA) technique in five impact categories; abiotic depletion potential (ADP), acidification potential (AP), global warming potential (GWP), ozone depletion potential (ODP), and human toxicity potential (HTP). Required thermal and electrical energy for production processes are supplied from nuclear power plants (NPPs). Energy and material inputs for production processes are defined. For the extensive LCA calculations, a powerful software is employed. According to the LCA study results, the GWPs of employed hydrogen production methods, namely high temperature electrolysis (HTE), conventional electrolysis (CE), 3-,4-, and 5-step Cu–Cl cycles, are 0.4768, 0.7071, 1.320, 1.201, and 1.346 kg CO2 eq per kg of hydrogen respectively.},
	number = {41},
	urldate = {2024-07-05},
	journal = {International Journal of Hydrogen Energy},
	author = {Karaca, Ali Erdogan and Dincer, Ibrahim and Gu, Junjie},
	month = aug,
	year = {2020},
	keywords = {Efficiency, Environmental impact, Global warming, Hydrogen production, Life cycle assessment, Nuclear power},
	pages = {22148--22159},
}

@article{milewski_hydrogen_2021,
	series = {Special {Issue} on {HYPOTHESIS} {XV}},
	title = {Hydrogen production in solid oxide electrolyzers coupled with nuclear reactors},
	volume = {46},
	issn = {0360-3199},
	url = {https://www.sciencedirect.com/science/article/pii/S0360319920344670},
	doi = {10.1016/j.ijhydene.2020.11.217},
	abstract = {In this study, two types of high temperature electrolyzers (O=SOE and H+SOE) were investigated for hydrogen generation in relation to nuclear power plant operations. The analysis encompasses the thermal integration of proton and ion conducting solid oxide electrolyzers, which are fed with steam generated in the nuclear plant. Under consideration in the study was the steam turbine cycle of an AP1000 nuclear power plant. The main parameters of electrolysis were tailored to match the typical operating temperature of the electrolyzers, and the water utilization factor was set at the same value for the two technologies under consideration. There are some advantages to applying high temperature electrolysis to the deaerator steam feed: first, there is almost no modification of the nuclear steam turbine cycle; second, flexibility of the nuclear power plant rises by 20\% with almost constant thermal load of the nuclear reactor; and third, high pressure hydrogen is obtained for commercial purposes. The analysis concludes that hydrogen can be produced in electrolyzers integrated with nuclear plants at an energy cost of 38.83 and 37.55 kWh kgH2−1 for protonic and ionic solid oxide electrolyzers, respectively.},
	number = {72},
	urldate = {2024-07-05},
	journal = {International Journal of Hydrogen Energy},
	author = {Milewski, Jarosław and Kupecki, Jakub and Szczęśniak, Arkadiusz and Uzunow, Nikołaj},
	month = oct,
	year = {2021},
	keywords = {Electrolysis, High temperature electrolysis, Nuclear energy, Oxygen ion conducting, Proton conducting, Solid oxide electrolysis},
	pages = {35765--35776},
}

@book{pearl_causality_2009,
	edition = {2},
	title = {Causality: {Models}, {Reasoning}, and {Inference}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-0-511-80316-1 978-0-521-89560-6 978-0-521-74919-0},
	shorttitle = {Causality},
	url = {https://www.cambridge.org/core/product/identifier/9780511803161/type/book},
	abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.},
	urldate = {2025-01-28},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	month = sep,
	year = {2009},
	doi = {10.1017/CBO9780511803161},
}

@book{dias_elicitation_2018,
	address = {Cham},
	edition = {1st ed. 2018},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Elicitation: {The} {Science} and {Art} of {Structuring} {Judgement}},
	isbn = {978-3-319-65052-4},
	shorttitle = {Elicitation},
	abstract = {This book is about elicitation: the facilitation of the quantitative expression of subjective judgement about matters of fact, interacting with subject experts, or about matters of value, interacting with decision makers or stakeholders. It offers an integrated presentation of procedures and processes that allow analysts and experts to think clearly about numbers, particularly the inputs for decision support systems and models. This presentation encompasses research originating in the communities of structured probability elicitation/calibration and multi-criteria decision analysis, often unaware of each other's developments. Chapters 2 through 9 focus on processes to elicit uncertainty from experts, including the Classical Method for aggregating judgements from multiple experts concerning probability distributions; the issue of validation in the Classical Method; the Sheffield elicitation framework; the IDEA protocol; approaches following the Bayesian perspective; the main elements of structured expert processes for dependence elicitation; and how mathematical methods can incorporate correlations between experts. Chapters 10 through 14 focus on processes to elicit preferences from stakeholders or decision makers, including two chapters on problems under uncertainty (utility functions), and three chapters that address elicitation of preferences independently of, or in absence of, any uncertainty elicitation (value functions and ELECTRE). Two chapters then focus on cross-cutting issues for elicitation of uncertainties and elicitation of preferences: biases and selection of experts. Finally, the last group of chapters illustrates how some of the presented approaches are applied in practice, including a food security case in the UK; expert elicitation in health care decision making; an expert judgement based method to elicit nuclear threat risks in US ports; risk assessment in a pulp and paper manufacturer in the Nordic countries; and elicitation of preferences for crop planning in a Greek region},
	number = {261},
	publisher = {Springer International Publishing : Imprint: Springer},
	editor = {Dias, Luis C. and Morton, Alec and Quigley, John},
	year = {2018},
	doi = {10.1007/978-3-319-65052-4},
	keywords = {Decision making, Management science, Operations Management, Operations Research, Management Science, Operations Research/Decision Theory, Operations research, Production management},
}

@book{pearl_causal_2016,
	address = {Chichester, West Sussex},
	title = {Causal inference in statistics: a primer},
	isbn = {978-1-119-18684-7},
	shorttitle = {Causal inference in statistics},
	publisher = {Wiley},
	author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
	year = {2016},
	keywords = {Causation, Mathematical statistics, Probabilities},
}

@misc{noauthor_addressing_2024,
	title = {Addressing {Uncertainties} {Across} {All} {Design} {Stages} of {Advanced} {Reactors} {Development}},
	url = {https://www.researchgate.net/publication/383935140_Addressing_Uncertainties_Across_All_Design_Stages_of_Advanced_Reactors_Development},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2025-01-24},
	journal = {ResearchGate},
	month = oct,
	year = {2024},
}

@techreport{r_m_cooke_procedures_2000,
	title = {Procedures guide for structured expert judgment},
	url = {https://op.europa.eu/en/publication-detail/-/publication/7faaedf8-d59b-465e-a9c1-23cce34ee2b4},
	institution = {European Commission},
	author = {{R. M. Cooke} and {L. J. H. Goossens}},
	year = {2000},
}

@misc{noauthor_recommendations_nodate,
	title = {Recommendations for {Probabilistic} {Seismic} {Hazard} {Analysis}: {Guidance} on {Uncertainty} and {Use} of {Expert}},
	shorttitle = {Recommendations for {Probabilistic} {Seismic} {Hazard} {Analysis}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6372/vol1/index.html},
	abstract = {Recommendations for Probabilistic Seismic Hazard Analysis: Guidance on Uncertainty and Use of Expert},
	language = {en-US},
	urldate = {2025-01-24},
	journal = {NRC Web},
}

@techreport{mosleh_methods_1987,
	title = {Methods for the elicitation and use of expert opinion in risk assessment: {Phase} 1, {A} critical evaluation and directions for future research},
	shorttitle = {Methods for the elicitation and use of expert opinion in risk assessment},
	url = {https://www.osti.gov/biblio/6345547},
	abstract = {The purpose of this work is to critically review and evaluate the elicitation and use of expert opinion in probabilistic risk assessment (PRA) in light of the available empirical and theoretical results on expert opinion use. PRA practice is represented by five case studies selected to represent a variety of aspects of the problem: assessments of component failure rates and maintenance data; recent assessments of seismic hazard rates; assessments of containment phenomenology; assessments of human error rates; and accident precursor studies. The review has yielded mixed results. On the negative side, there appears to be little reliance on normative expertise in structuring the process of expert opinion elicitation and use; most applications instead rely primarily on the common sense of the experts involved in the analysis, which is not always an adequate guide. On the positive side, however, there is evidence that expert opinions can in fact be used well in practical settings. Suggestions are given for Phase II work to enhance the applicability and use of appropriate expert opinion methods.},
	language = {English},
	number = {NUREG/CR-4962; PLG-0533},
	urldate = {2025-01-24},
	institution = {Pickard, Lowe and Garrick, Inc., Newport Beach, CA (USA); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Accident Analysis},
	author = {Mosleh, A. and Bier, V. M. and Apostolakis, G.},
	month = aug,
	year = {1987},
}

@misc{noauthor_guidance_nodate,
	title = {Guidance for {Conducting} {Expert} {Elicitation} in {Risk}-{Informed} {Decisionmaking} {Activities} ({NUREG}-2255)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr2255/index.html},
	abstract = {Guidance for Conducting Expert Elicitation in Risk-Informed Decisionmaking Activities (NUREG-2255)},
	language = {en-US},
	urldate = {2025-01-24},
	journal = {NRC Web},
}

@book{meyer_eliciting_2001,
	title = {Eliciting and {Analyzing} {Expert} {Judgment}: {A} {Practical} {Guide}},
	isbn = {978-0-89871-474-6 978-0-89871-848-5},
	shorttitle = {Eliciting and {Analyzing} {Expert} {Judgment}},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898718485},
	language = {en},
	urldate = {2025-01-24},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Meyer, Mary A. and Booker, Jane M.},
	month = jan,
	year = {2001},
	doi = {10.1137/1.9780898718485},
}

@article{apostolakis_data_1980,
	title = {Data specialization for plant specific risk studies},
	volume = {56},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549380901338},
	doi = {10.1016/0029-5493(80)90133-8},
	abstract = {Semantic Scholar extracted view of "Data specialization for plant specific risk studies" by G. Apostolakis et al.},
	language = {en},
	number = {2},
	urldate = {2024-01-28},
	journal = {Nuclear Engineering and Design},
	author = {Apostolakis, G. and Kaplan, S. and Garrick, B.J. and Duphily, R.J.},
	month = feb,
	year = {1980},
	pages = {321--329},
}

@techreport{kerr_irans_2018,
	title = {Iran's {Nuclear} {Program}: {Status}},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrEwxNTEFHlSWmgCZ2TC2S0lLNLQzS0iwSTVMMU1PBN7Qgje0gbv5KyUwH3Z2BNMULWV2TWJRtpQ9s6xob6uemliSmJINOjbE0N9JnZmA2Bl1xyw5UmVoBW9QMrizcBBnYIK1aIQam1DwRBjlPYHWgXqzgBzo5OLFIIQCyIspKAdTOKy0WZbB2cw1x9tCFGhUPdUwRdFw9HpQE4oEuiQc7JB7FIQZiDLyJoDXqeSXgvWwpEgwKZqYmiZaWpinAGt3YxDzNPDE1zcwCWIOD7n0xBoaQJIMJOVZJkadNmoELWPmD1z4YWsowsKYBk3uqLAMLaOsAAPxthfw},
	abstract = {This report looks at the background of Iran's nuclear policy including the current status of Iran's nuclear facilities, and current controversy surrounding them, as well as the effects of international sanctions on Iran, recent sabotages on the Iran Enrichment Program, an estimated timeline of Iran's nuclear weapon capabilities, and whether or not Iran even has a nuclear weapons program.},
	language = {English},
	institution = {Library of Congress. Congressional Research Service},
	author = {Kerr, Paul K.},
	year = {2018},
	note = {Report},
	keywords = {Foreign relations, Nuclear energy, Nuclear weapons},
}

@techreport{congressional_research_service_irans_2025,
	title = {Iran's {Nuclear} {Program}: {Tehran}'s {Compliance} with {International} {Obligations}. {CRS} {Report}},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LSwMxEB60vQhCfeKb3Dxtu6_YtNfFoghaa-lNwqabVdD2kG1_hP_azMTgtp7tbWACOx9Mkp3JzDcASdwOg7UzIUo5UpXlBT7scKFK3RVhWYqcF5HWNKGlltuBV98aY2PCN-MJKtr-sHS9DnVVB_Po-OYb2HDfq1zP99RU1hViHpDAedzbhiaSwtv90Jw8jIbPf45hulsGLfjyZlBJCQ4yqNfWd4jPkEgsPHfjv5m8Bwe_s3eZvX-WKOzDlp4fwuTeXmvXFXtEBuTcsKGr7OqzsX53mozK09GNGKZ32Uq2kT2pT6LzQDdn2eiFuX__IzCD23F2F3gMcsV-agiqpDNZ1tbM1tYhTmlxSotT1nFKC08iTicgzuQYdnMs7Z8vqAWwOAGmEp7HkQ1skrRMdah6OppyESqthYpU9-YUPjZo4dlGv3YOO-QIIU7zvoDGwiz1JTTQBa9-vPcbq4ou4g},
	language = {English},
	author = {{Congressional Research Service}},
	year = {2025},
	note = {Report},
	keywords = {Arms control \& disarmament, Construction industry, International cooperation, International law, Iran, Law enforcement, Nuclear power plants, Nuclear reactors, Uranium},
}

@misc{schmitt_wishbone_nodate,
	title = {Wishbone {Github} {Repository}},
	url = {https://github.com/boschmitt/wishbone/blob/master/README.md},
	abstract = {VHDL Implementation. Contribute to boschmitt/wishbone development by creating an account on GitHub.},
	language = {en},
	urldate = {2025-03-06},
	journal = {GitHub},
	author = {schmitt, Bruno},
}

@techreport{atwood_handbook_2003,
	title = {Handbook of {Parameter} {Estimation} for {Probabilistic} {Risk} {Assessment}},
	url = {https://www.nrc.gov/docs/ML0329/ML032900131.pdf},
	number = {NUREG/CR-6823},
	institution = {Sandia National Lab.},
	author = {Atwood, C. L. and LaChance, J. and Martz, H. F. and Anderson, D. J. and Englehardt, M. and Whitehead, D. and Wheeler, T.},
	year = {2003},
}

@misc{rhodes_radiation_2023,
	title = {Radiation and microcontrollers},
	url = {https://www.neimagazine.com/analysis/radiation-and-microcontrollers-11263850/},
	abstract = {Microcontrollers are crucial microchips with a wide range of applications. They may be exposed to radiation, for instance, in power stations, while monitoring background radiation levels or in satellite systems where they can be exposed to cosmic radiation. What are the safe levels of gamma exposure for microcontrollers before they malfunction and how can they be shielded?},
	language = {en-US},
	urldate = {2025-03-06},
	journal = {Nuclear Engineering International},
	author = {Rhodes, Mark},
	month = nov,
	year = {2023},
}

@techreport{palomar_programmable_1993,
	title = {The {Programmable} {Logic} {Controller} and {Its} {Application} in {Nuclear} {Reactor} {Systems}},
	url = {https://www.nrc.gov/docs/ML0635/ML063530382.pdf},
	number = {NUREG/CR-6090},
	institution = {US  NRC},
	author = {Palomar, J. and Wyman, R.},
	month = sep,
	year = {1993},
}

@techreport{elks_development_nodate,
	title = {Development of a {Fault} {Injection}-{Based} {Dependability} {Assessment} {Methodology} for {Digital} {I}\&{C} {Systems} {Volume} 1},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr7151/index.html},
	language = {en},
	number = {NUREG/CR-7151, Vol. 1},
	institution = {US NRC},
	author = {Elks, C.R. and George, N.J. and Reynolds, M.A. and Miklo, M. and Berger, C. and Bingham, S. and Sekhar, M. and Johnson},
}

@techreport{bobrek_review_2010,
	type = {{NUREG}},
	title = {Review {Guidelines} for {Field}-{Programmable} {Gate} {Arrays} in {Nuclear} {Power} {Plant} {Safety} {Systems}},
	url = {https://www.nrc.gov/docs/ML1008/ML100880142.pdf},
	number = {NUREG/CR-7006},
	author = {Bobrek, M. and Bouldin, D. and Holcomb, D.E. and Kilough, S.M. and Smith, S.F. and Ward, C. and Wood, R.T.},
	month = jan,
	year = {2010},
}

@misc{noauthor_nuclear_2006,
	title = {Nuclear power plants {Instrumentation} and control systems important to safety {Software} aspects for computer-based systems performing category {A} functions},
	url = {https://webstore.iec.ch/en/publication/3795},
	month = may,
	year = {2006},
}

@misc{noauthor_nuclear_2021,
	title = {Nuclear power plants – {Instrumentation} and control important to safety {Hardware} requirements},
	url = {https://webstore.iec.ch/en/publication/64120},
	month = feb,
	year = {2021},
}

@techreport{white_microelectronics_2008,
	title = {Microelectronics {Reliability}: {Physics}-of-{Failure} {Based} {Modeling} and {Lifetime} {Evaluation}},
	url = {https://nepp.nasa.gov/files/16365/08_102_4_%20JPL_White.pdf},
	language = {en},
	institution = {Jet Propulsion Laboratory, NASA},
	author = {White, Mark and Bernstein, Joseph B},
	year = {2008},
}

@inproceedings{kerwin_smart_2013,
	address = {Marseille, France},
	title = {Smart {Sensor} {ASIC} for {Nuclear} {Power} {Monitoring}},
	isbn = {978-1-4799-1047-2 978-1-4799-1046-5},
	url = {http://ieeexplore.ieee.org/document/6728098/},
	doi = {10.1109/ANIMMA.2013.6728098},
	abstract = {Mixed-signal integrated circuits are used in a variety of applications where ionizing radiation is present, including satellites, space vehicles, nuclear reactor monitoring, medical imaging, and cancer therapy. While total ionizing radiation is present in each of these environments, the type of radiation (e.g. heavy ions vs. high-energy x-rays) and other environmental factors present unique challenges to the mixed-signal designer. This paper discusses a Smart Sensor radiation hardened, mixedsignal, application specific integrated circuit (ASIC) specifically designed for sensor monitoring in a nuclear reactor environment. Results after exposure to gamma rays, neutrons, and temperatures up to 200 °C are reported.},
	language = {en},
	urldate = {2025-03-06},
	booktitle = {2013 3rd {International} {Conference} on {Advancements} in {Nuclear} {Instrumentation}, {Measurement} {Methods} and their {Applications} ({ANIMMA})},
	publisher = {IEEE},
	author = {Kerwin, David B. and Merkel, Kenneth G. and Rouxel, Olivier},
	month = jun,
	year = {2013},
	pages = {1--4},
}

@article{marcos_farias_fpga-based_2016,
	title = {{FPGA}-{Based} {I}\&{C} {Systems} in {Nuclear} {Plants}},
	volume = {53},
	url = {https://doi.org/10.3303/CET1653048},
	doi = {10.3303/CET1653048},
	language = {en},
	urldate = {2025-03-06},
	journal = {Chemical Engineering Transactions},
	author = {{Marcos Farias} and {Roque H. S. Martins} and {Pamela I. N. Teixeira} and {Paulo Victor Carvalho}},
	month = sep,
	year = {2016},
	pages = {283--288},
}

@book{benso_fault_2010,
	title = {Fault {Injection} {Techniques} and {Tools} for {Embedded} {Systems} {Reliability} {Evaluation}},
	isbn = {1-4419-5391-4},
	url = {https://dl.acm.org/doi/book/10.5555/1965156},
	author = {Benso, Alfredo and Prinetto, Paolo},
	month = dec,
	year = {2010},
}

@article{nidhin_understanding_2017,
	title = {Understanding radiation effects in {SRAM}-based field programmable gate arrays for implementing instrumentation and control systems of nuclear power plants},
	volume = {49},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573317302723},
	doi = {10.1016/j.net.2017.09.002},
	abstract = {Field programmable gate arrays (FPGAs) are getting more attention in safety-related and safety-critical application development of nuclear power plant instrumentation and control systems. The high logic density and advancements in architectural features make static random access memory (SRAM)-based FPGAs suitable for complex design implementations. Devices deployed in the nuclear environment face radiation particle strike that causes transient and permanent failures. The major reasons for failures are total ionization dose effects, displacement damage dose effects, and single event effects. Different from the case of space applications, soft errors are the major concern in terrestrial applications. In this article, a review of radiation effects on FPGAs is presented, especially soft errors in SRAM-based FPGAs. Single event upset (SEU) shows a high probability of error in the dependable application development in FPGAs. This survey covers the main sources of radiation and its effects on FPGAs, with emphasis on SEUs as well as on the measurement of radiation upset sensitivity and irradiation experimental results at various facilities. This article also presents a comparison between the major SEU mitigation techniques in the conﬁguration memory and user logics of SRAM-based FPGAs.},
	language = {en},
	number = {8},
	urldate = {2025-03-06},
	journal = {Nuclear Engineering and Technology},
	author = {Nidhin, T.S. and Bhattacharyya, Anindya and Behera, R.P. and Jayanthi, T. and Velusamy, K.},
	month = dec,
	year = {2017},
	pages = {1589--1599},
}

@article{kim_evaluation_2019,
	title = {Evaluation of effectiveness of fault-tolerant techniques in a digital instrumentation and control system with a fault injection experiment},
	volume = {51},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573318307150},
	doi = {10.1016/j.net.2018.11.012},
	abstract = {Recently, instrumentation and control (I\&C) systems in nuclear power plants have undergone digitalization. Owing to the unique characteristics of digital I\&C systems, the reliability analysis of digital systems has become an important element of probabilistic safety assessment (PSA). In a reliability analysis of digital systems, fault-tolerant techniques and their effectiveness must be considered. A fault injection experiment was performed on a safety-critical digital I\&C system developed for nuclear power plants to evaluate the effectiveness of fault-tolerant techniques implemented in the target system. A softwareimplemented fault injection in which faults were injected into the memory area was used based on the assumption that all faults in the target system will be reﬂected in the faults in the memory. To reduce the number of required fault injection experiments, the memory assigned to the target software was analyzed. In addition, to observe the effect of the fault detection coverage of fault-tolerant techniques, a PSA model was developed. The analysis of the experimental result also can be used to identify weak points of fault-tolerant techniques for capability improvement of fault-tolerant techniques.},
	language = {en},
	number = {3},
	urldate = {2025-03-06},
	journal = {Nuclear Engineering and Technology},
	author = {Kim, Man Cheol and Seo, Jeongil and Jung, Wondea and Choi, Jong Gyun and Kang, Hyun Gook and Lee, Seung Jun},
	month = jun,
	year = {2019},
	pages = {692--701},
}

@article{eneyo_irans_2022,
	title = {{IRAN}’{S} {NUCLEAR} {POLICY}: {NATURE}, {AMBITION}, {AND} {STRATEGY}},
	volume = {8},
	issn = {1857-9760},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwnV3NTuMwEB4BvXBhWX5EdwHlxIlQx3bihMsqLWW3KBRUqASnKHEcJLRq2bLceY19PZ6EGSehhQOHvViRnShOvrHnJ5NvAAQ_Yu6HPUGYElWJJwyLWOZHJuO5NEVZEH17YSxZ_0Jsp4q_PdZZls0WafftYqopZN7hCk3tkKhifjz8camIFH1srStqLEOLCqpQhtc5T-YhF0VfqVjFtClRtP3OGTrMnDIpGSfzFDXG9Pc7DWWJ_N9Zny18bdlsQQmdfoH7Zr4294QqHiwm4Xcs8aFlu2hIHv__2dZhrTZVnbiSra-wZCYbsF4nzOFAvS1sghqM4uHL878rZzjuJf145FxeJIPe7bFTZVUcOvF5d0CxMDwanjhUp_m6__N2C8an_eveL7cuyOBqriLfDQSqMhkGMg8CFupA-zpCMDlTeRjlmUJYC89oxbzQoNmJrlTh-wK7mVLacCG2YWUynZgdcDxNvhj6foyX0tcyk14k0VzgumQlL3Qbti0Yab2kHlPilBBB0IaDBp30oSLkwKHUwpkuwtmGLmH3dhLxaNuO6ewurZdlKg06kFqWYYSmTCZZLrQQpQ4zUwQZemZt2G0gms9kjg8OW2l4uwlC-GTLI6so9Pxvn1_9HVY5_UxhYzq7sPJ39mT28A2h2OzDshp3qb3BthUnV8lg30qzbUevFAj6Cg},
	doi = {10.47305/JLIA2282202e},
	abstract = {Nuclear, chemical, and biological weapons represent the biggest danger to humanity. During the Cold War, the US and USSR provided ‘umbrella protection’ to convince allies not to acquire nuclear weapons. Most ‘newly’ independent nations never had such security during the Cold War since they were not part of a power bloc. During the Iran-Iraq conflict (1980-1988), the Islamic Republic of Iran was attacked with chemical weapons. Since Mujahedin-e-Khalq (MEK), an Iranian exile organization, exposed Iran's hidden nuclear program in 2002, the topic has gained worldwide attention. Iran's nuclear agenda has produced a worldwide catastrophe despite its NPT membership. Iran says its nuclear program is peaceful and respects Islamic values. Most US politicians and academics consider Iran a rough nation with political and strategic concerns, including regional hegemony, human rights, terrorism, WMD proliferation, and military operations beyond the border. This study examines Iran's nuclear policies to demonstrate its essence, goal, and strategy.},
	language = {English},
	number = {2},
	journal = {Journal of Liberty and International Affairs (Bitola)},
	author = {Eneyo, Violet B. and Talib, Jihad and Mbeh Attah, Frank and Etim Offiong, Eric},
	year = {2022},
	note = {Place: Bitola
Publisher: Institute for Research and European Studies - Bitola},
	keywords = {Academic staff, Ambition, Biological \& chemical weapons, Chemical and Biological Weapon, Cold War, Comparative politics, Environmental and Energy policy, Exile, Friedens- und Konfliktforschung, Geopolitics, Governance, Government/Political systems, Hegemony, History and theory of political science, Human rights, International relations/trade, Iran, Islam, Methodology and research technology, Military operations, Military policy, Nuclear Policy, Nuclear Weapon, Nuclear proliferation, Nuclear weapons, Peace and Conflict Studies, Political Sciences, Political Theory, Politics, Politics / Political Sciences, Politics and Identity, Politics and law, Politics and religion, Politics and society, Politics of History/Memory, Politikwissenschaft, Security and defense, Sicherheitspolitik, Terrorism, Weapons of mass destruction},
	pages = {202--222},
}

@article{bahgat_nuclear_2006,
	title = {Nuclear proliferation: {The} {Islamic} {Republic} of {Iran}},
	volume = {39},
	issn = {0021-0862},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwhV1LS8NAEB5sT158VqwvVhAPQmw2j-3Gm4hFL1JEz2Gz3QVBUqkp2H_vzG5S-sB6zyabnS-z38xOvgGIo9swWPEJaWGKTIm0yBBTimupqcPDSCSap1aFZjm3A1fNrzFUZenKBN2hPvKl4tP0cM8jILagJXktlz-PsZA--CZ5EWX-RNQcZJKcNoU3Egk7sSTJ60RKsxUtCZU2xYlrDtrtOoNdGDYTdMUm1OJgseq-55QOnbxFo-r438vswU7NQNm9h8w-bJnyADpeLmTGrhlp0SrX73d2CPEL6R2rCRtSdx9rPF7uGKKLOTR9aPZqvFY2G1v2jFtfB94Hj28PT0HdZyHQMU-rQFMMgl5Rqz4fEeNIdCbDyFqdZDI1EmNYJDEU_CRI70ySIOcRERdCpRhdjZL4CNrluDTHwJBeaKttgawBI0cl0ZWGlpKlMjSm6Isu3DRLnn95OY2cz1VKV-zThXDRKHnlchjWNxxZvzyvfqoupBuGxBse1XGWmU-qNksXLhsA5Pjd0WGKKs14-o33iZG7xZmQJ3-MPYVtn6-hgrQzaFeTqTnHlUKQXDjQ_gKMV-aJ},
	doi = {10.1080/00210860600808102},
	abstract = {Since the mid-1980s, Israel, thGawdat Bahgate United States, and other Western powers have accused Iran of pursuing nuclear weapons capability. Iranian officials have categorically denied these accusations and claimed that their nuclear program is designed for civilian purposes. This essay examines the history of Iran's nuclear program since the late 1950s and analyzes the forces that shape the country's nuclear policy. These forces include perception of security threats from Pakistan, Iraq, Israel, and the United States; domestic economic and political dynamics; and national pride. The following section will discuss the European and Russian stance on Iran's nuclear ambition as well as the International Atomic Energy Agency's efforts to reach a compromise that would satisfy the international community's concerns and Tehran's demands. The essay concludes with some predictions on how Iran's nuclear program is likely to evolve in the next few decades.;Since the mid-1980s, Israel, the United States, and other Western powers have accused Iran of pursuing nuclear weapons capability. Iranian officials have categorically denied these accusations and claimed that their nuclear program is designed for civilian purposes. This essay examines the history of Iran's nuclear program since the late 1950s and analyzes the forces that shape the country's nuclear policy. These forces include perception of security threats from Pakistan, Iraq, Israel, and the United States ; domestic economic and political dynamics; and national pride. The following section will discuss the European and Russian stance on Iran's nuclear ambition as well as the International Atomic Energy Agency's efforts to reach a compromise that would satisfy the international community's concerns and Tehran's demands. The essay concludes with some predictions on how Iran's nuclear program is likely to evolve in the next few decades. (Author abstract);},
	language = {English},
	number = {3},
	journal = {Iranian studies},
	author = {Bahgat, Gawdat},
	year = {2006},
	note = {Publisher: Routledge},
	keywords = {Ambition, European Union, International community, International cooperation, Missiles, Nuclear fuels, Nuclear nonproliferation, Nuclear power, Nuclear weapons, War},
	pages = {307--327},
}

@article{kerr_irans_2018-1,
	title = {{IRAN}'{S} {NUCLEAR} {PROGRAM}: {STATUS}},
	volume = {9},
	issn = {1939-5809},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9ISzYB1O2hXpqWRUaJBiolhqrFpoomJZZpJErAOTkQd24GMvxVDV1nCikhwuZ2SnwwaMtc3Ala7hsCC1cTQvqBQF3SJFGiyFXqjBjMDK-hCFdAKL18jH8SQi4kpsLoyh8wzW-qaWhhYYpTA4GrFTYAhC-YC8GoS0B0GyMvq9cFHGYLPr4Ad20i-awUZ-KGNTwVHSGoRYmBKzRNmEIWcFFKpoKYAOoY2EXzVb6UwgzjKYKECfNWcCIOcZ5Cjn3qwgl-os4-rY5BCQJC_e5Cjr5VCcIhjSGiwKIOym2uIs4cuzJHx0ARbHI9wobEYA0tefl6qBIOCoYUBMJaMzRINjRNNkoHlkUliWqplMjASLU2NzIySJBlk8JkkhV9amoEL2PqwgIxnyDCwlBSVpsoC7QaGsRwDs3mEkxwDq6NPsI-nHDgawaQ_mAwCACMPrrY},
	abstract = {Gas centrifuges can produce both low-enriched uranium (LEU), which can be used in nuclear power reactors, and weapons-grade highly enriched uranium (HEU), which is one of the two types of fissile material used in nuclear weapons. Construction of a U.S.supplied research reactor, called the Tehran Research Reactor (TRR), located in Tehran began in 1960; the reactor went critical in 1967.1 During the 1970s, Tehran pursued an ambitious nuclear power program; according to contemporaneous U.S. documents, Iran wanted to construct 10-20 nuclear power reactors and produce more than 20,000 megawatts of nuclear power by 1994.2 Iran also began constructing a light-water nuclear power reactor near the city of Bushehr and also considered obtaining uranium enrichment and reprocessing technology. [.]mid-1970s U.S. intelligence reports expressed concern that Iran might pursue a nuclear weapons program.3 Although Iran cancelled its nuclear program after its 1979 revolution, a 1981 Department of State draft paper argued that Iran might develop a nuclear weapons program in response to a then-suspected Iraqi nuclear weapons program, although Iran was not one of several countries of "near to medium term proliferation concern" to which the paper referred.4 Tehran "reinstituted" the nuclear program in 1982.5 According to International Atomic Energy Agency (IAEA) reports, Iran conducted experiments during the 1980s and early 1990s related to uranium conversion, heavy water production, and nuclear reactor fuel fabrication. According to official U.S. and Iranian sources, France agreed to construct the reactor during the 1970s, but ended the project after the 1979 revolution in Iran.11 President of the Atomic Energy Organization of Iran (AEOI) Ali Akbar Salehi stated in September 2016 that "we are almost about to sign a contract for designing" the reactor, "but it will take a rather long time.},
	language = {English},
	number = {1},
	journal = {Current politics and economics of the Middle East},
	author = {Kerr, Paul K.},
	year = {2018},
	note = {Place: Hauppauge
Publisher: Nova Science Publishers, Inc},
	keywords = {Carbon fibers, Councils, Exports, International relations, Nuclear reactors, Nuclear weapons, Pressure transducers, Sanctions, Uranium},
	pages = {151--250},
}

@article{sebenius_is_2012,
	title = {Is a {Nuclear} {Deal} with {Iran} {Possible}? {An} {Analytical} {Framework} for the {Iran} {Nuclear} {Negotiations}},
	volume = {37},
	issn = {0162-2889},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwlV3fb9MwED7R7YUXfgzGCqMyQjx2TXxuEvOCqtGKIuhA3R54Mm7ilCJoq6YDib-eO6fp0kkM7bHy2XV99t131_NnAJQnQfuaTdAOmWotDDLM6USFCTnOro5yiuuCNMFruR14WV2N4TzEyfdvZbi4WcuO0hyGNGCfgxcu4_p4Md5a3yjxT7oRkuFrx4muit0j2RmO-6fGchUXPyZZc0NlJSJ5l5-z9W4OZAd31q7Ye-8zuA9n1UR90Qk_dVCvvu94xkNPc1GxO_7nRz2AexsgKnplw0O44-YH8GQnQSi2lXIH0Phgfz-Cr8NCWDFiDmS7Em8JZApO5IoheTzxacHn64d781r05sKznfhEuRhUBWCCELIgxFnKV8OM3HSxLndI8RguBv3z03ftzRsN7TRGtW7LLI9tFmaYTSa5UpM8VLGTISapci6yAX1IAh0oZ3U8Ieyo0XZzCoOCtBtb0j0ewt58MXdHINI8TawOHZkUrRJHw0qMuxZTjPM8TF0TXlUqM8uSisP4ECaSpq7aJhx6fW6FVMgkS7FqwgtSoNkc0uIfnfWOzKxw6S-MZ2iQkJiSRhIoom4m0ObPbOnbr_q2a1vnaoxStWZMzoWCTyY4Qw-1m3Bcba7apAgxkWEl00rT3TbTmec_cuzcLS5JhlAarTHK5CYZybScqNQNMvzmK-FJpO_q8-Y2djorlmt_16swXKNsSv5ealqspobcLK8aYhhVorQeHgazc0iwCb36OKW1vuUYT2-5jM_gLqFYWebFjmFvvbp0z2lX0SFsQSM-_9zyrM8t2H_fH519aXl78RdOfmPl},
	doi = {10.1162/ISEC_a_00108},
	abstract = {Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a "negotiation analytic" framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a "zone of possible agreement" exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. [PUBLICATION ABSTRACT];Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a 'negotiation analytic' framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a 'zone of possible agreement' exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. Adapted from the source document.;Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a "negotiation analytic" framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a "zone of possible agreement" exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal—one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran—requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement.;Since assuming the presidency of the United States in January 2009, Barack Obama has tried both outreach and sanctions in an effort to halt Iran's progress toward a nuclear weapons capability. Yet neither President Obama's personal diplomacy nor several rounds of talks between Iran and the five permanent members of the United Nations Security Council-China, France, Russia, the United Kingdom, and the United States-plus Germany (the "P5+1") nor escalating sanctions have deterred Tehran. Iran has not only continued but accelerated its nuclear progress, accumulating sufficient low-enriched uranium that, if further enriched, would be sufficient for five nuclear weapons. Consequently, as Iran makes major advances in its nuclear capabilities, speculation has increased that Israel or a United States-led coalition may be nearing the decision to conduct a military strike to disable Iran's nuclear program.;Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a 'negotiation analytic' framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a 'zone of possible agreement' exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. Adapted from the source document. Reprinted by permission of the MIT Press;},
	language = {English},
	number = {3},
	journal = {International security},
	author = {Sebenius, James K. and Singh, Michael K.},
	year = {2012},
	note = {Place: One Rogers Street, Cambridge, MA 02142-1209, USA
Publisher: MIT Press},
	keywords = {Agreements, Armed conflict, Coalitions, Conflict, Cost efficiency, Cost incentives, Credible threats, Diplomacy, Diplomatic relations, Hostility, Influence, International agreements, International relations, Iran, Military, Military sanctions, NEGOTIATION, NUCLEAR WEAPONS, National security, Negotiations, Nuclear diplomacy, Nuclear proliferation, Nuclear strategy, POLITICS AND GOVERNMENT, Space Technology, Unit costs, Uranium, Zone of possible agreement},
	pages = {52--91},
}

@article{sebenius_is_2012-1,
	title = {Is a {Nuclear} {Deal} with {Iran} {Possible}? {An} {Analytical} {Framework} for the {Iran} {Nuclear} {Negotiations}},
	volume = {37},
	issn = {0162-2889},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwlV1LbxMxEB6R9sKFR6EQKJER4phm1_a-uKCoJCIIUlDaAyfj3fWGRW0SZVOQ-PXM2Nl0F4miHiOPHccez3wzGX8GEPzY6_9lE3wvTgnsapFmVgc0eo7E54i-dS7iop3bgVf11RjKQxz_-O7Cxe1aDmRCYUgH9il4oTKuT-eznfUNY_ukGyIZunYcJ3Wxe8gHk9noRGmq4qLHJBtuyFUione5LDftHEgLdzau2FvvM74Pp_VEbdEJPXXQrL4fWMZDS3NRszv-50c9gHtbIMqGruEh3DGLA3jSShCyXaXcAXQ-6l-P4NukYppNiQNZr9k7BJmMErlsgh6PfV7S-bowb9-w4YJZthObKGfjugCMIUJmiDidfD3M1MyXG6ch1WM4H4_OTt73t2809LNIyE2f50Wkcz8XeZoWUqaFLyPDfRFn0phQe_gh9hJPGp1EKWLHROigwDDIy4JIcy8Th7C3WC7MU2C55FxLkwaSo3zGdZKGWRjrXAZBIEK_C6_rLVMrR8WhbAgTctXc2i4c2v3cCUmfSJYi2YWXuIFqe0irf3ROWjJlZbKfIiqFEojEJFccQRF2U16ifpcr237dt99Qnesx3NaqGToXDD6J4ExYqN2Fo1q5GpNCxISGFU0rTnfXjGee_sjRC7O8QhlEabjGgsc3yXCi5RRS3iBDb74inhT4XSNSbqXnZbXa2LtelaIaZeX4e7FpuZ4rdLO0akL4YS2K62FhMDmHWHRh2BzHWetbjvHslsv4HO4iiuUuL3YEe5v1lXmBWoWHsAed6OxLz7I-92D_w2h6-rVn7cUfdqlitw},
	doi = {10.1162/ISEC_a_00108},
	abstract = {Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a "negotiation analytic" framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a "zone of possible agreement" exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. [PUBLICATION ABSTRACT];Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a 'negotiation analytic' framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a 'zone of possible agreement' exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. Adapted from the source document.;Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a "negotiation analytic" framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a "zone of possible agreement" exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal—one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran—requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement.;Since assuming the presidency of the United States in January 2009, Barack Obama has tried both outreach and sanctions in an effort to halt Iran's progress toward a nuclear weapons capability. Yet neither President Obama's personal diplomacy nor several rounds of talks between Iran and the five permanent members of the United Nations Security Council-China, France, Russia, the United Kingdom, and the United States-plus Germany (the "P5+1") nor escalating sanctions have deterred Tehran. Iran has not only continued but accelerated its nuclear progress, accumulating sufficient low-enriched uranium that, if further enriched, would be sufficient for five nuclear weapons. Consequently, as Iran makes major advances in its nuclear capabilities, speculation has increased that Israel or a United States-led coalition may be nearing the decision to conduct a military strike to disable Iran's nuclear program.;Varied diplomatic approaches by multiple negotiators over the past several years have failed to conclude a nuclear deal with Iran. Mutual hostility, misperception, and flawed diplomacy may be responsible. Yet, more fundamentally, no mutually acceptable deal may exist. To assess this possibility, a 'negotiation analytic' framework conceptually disentangles two issues: (1) whether a feasible deal exists; and (2) how to design the most promising process to achieve one. Focusing on whether a 'zone of possible agreement' exists, a graphical negotiation analysis precisely relates input assumptions about the parties' interests, their no-deal options, and possible deals. Under a plausible, mainstream set of such assumptions, the Iranian regime's no-deal options, at least through the fall of 2012, appear superior to potential nuclear agreements. If so, purely tactical and process-oriented initiatives will fail. Opening space for a mutually acceptable nuclear deal -- one that avoids both military conflict and a nuclear-armed or nuclear-capable Iran -- requires relentlessly and creatively worsening Iran's no-deal options while enhancing the value of a deal to the Iranian regime. Downplaying both coercive options and upside potential, as international negotiators have often done, works against this integrated strategy. If this approach opens a zone of possible agreement, sophisticated negotiation will be key to reaching a worthwhile agreement. Adapted from the source document. Reprinted by permission of the MIT Press;},
	language = {English},
	number = {3},
	journal = {International security},
	author = {Sebenius, James K. and Singh, Michael K.},
	year = {2012},
	note = {Place: One Rogers Street, Cambridge, MA 02142-1209, USA
Publisher: MIT Press},
	keywords = {Agreements, Armed conflict, Coalitions, Conflict, Cost efficiency, Cost incentives, Credible threats, Diplomacy, Diplomatic relations, Hostility, Influence, International agreements, International relations, Iran, Military, Military sanctions, NEGOTIATION, NUCLEAR WEAPONS, National security, Negotiations, Nuclear diplomacy, Nuclear proliferation, Nuclear strategy, POLITICS AND GOVERNMENT, Space Technology, Unit costs, Uranium, Zone of possible agreement},
	pages = {52--91},
}

@book{doyle_nuclear_2019,
	address = {Oxford, United Kingdom ; Cambridge, MA, United States},
	edition = {Second edition},
	title = {Nuclear safeguards, security and nonproliferation: achieving security with technology and policy},
	isbn = {978-0-12-803271-8},
	shorttitle = {Nuclear safeguards, security and nonproliferation},
	abstract = {This is a comprehensive reference that covers cutting-edge technologies used to trace, track, and safeguard nuclear material. Topics covered include the security of nuclear facilities and material, the illicit trafficking of nuclear materials, improvised nuclear devices and how to increase global nuclear transparency},
	publisher = {Butterworth-Heinemann, an imprint of Elsevier},
	editor = {Doyle, James E.},
	year = {2019},
	note = {OCLC: on1084316870},
	keywords = {Case studies, Gestion de l'approvisionnement, Industrie nucléaire, Installations nucléaires, Materials Management, Materials management, Non-prolifération nucléaire, Nuclear facilities, Nuclear industry, Nuclear nonproliferation, Nuclear terrorism, Nuclear weapons, Prevention, Proliferation, Security measures, Sécurité Mesures, Études de cas},
}

@techreport{bellis_probabilistic_1986,
	type = {Report},
	title = {Probabilistic {Risk} {Assessment} for the {Standard} {Modular} {High} {Temperature} {Gas}-{Cooled} {Reactor} {Vol}. 2},
	url = {https://digital.library.unt.edu/ark:/67531/metadc676259/},
	abstract = {This appendix provides the reliability data base utilized in
assessing accident frequencies described in Section 7 and Appendix C
of this document. Event trees are employed to quantify the frequency
of accident sequences Which may result in an unplanned radionuclide
release. Event tree nodal probabilities, describing the probability
of failure of a given system or component, are derived from fault tree
analysis. The base reliability data used in the fault tree analyses are
presented here.
Many data sources were compiled from operating experience in LWR or
nonnuclear applications as well as from HTGR operating experience and
risk analyses. Depending upon the operating environment of a particular
component, the most appropriate reliability data available were used.
In reference to HTGR data, considerable work was accomplished in compiling reliability estimates during the Accident Initiation and Program
Analysis (AIPA) (Ref. B-1) studies.},
	language = {English},
	urldate = {2020-10-28},
	author = {Bellis, E. A. and Vasquez, J.},
	month = jun,
	year = {1986},
	doi = {10.2172/455545},
	note = {Number: DOE/HTGR--86-011-Rev.1
Publisher: GA Technologies, Inc., San Diego, CA (United States)},
}

@techreport{bellis_probabilistic_1986-1,
	type = {Report},
	title = {Probabilistic {Risk} {Assessment} for the {Standard} {Modular} {High} {Temperature} {Gas}-{Cooled} {Reactor} {Vol}. 1},
	url = {https://digital.library.unt.edu/ark:/67531/metadc676259/},
	language = {English},
	urldate = {2020-10-28},
	author = {Bellis, E. A. and Vasquez, J.},
	month = jun,
	year = {1986},
	doi = {10.2172/455545},
	note = {Number: DOE/HTGR--86-011-Rev.1
Publisher: GA Technologies, Inc., San Diego, CA (United States)},
}

@techreport{torok_estimating_2010,
	title = {Estimating {Failure} {Rates} in {Highly} {Reliable} {Digital} {Systems}},
	url = {https://www.epri.com/research/products/000000000001021077},
	language = {en},
	number = {1021077},
	institution = {EPRI},
	author = {Torok, R},
	month = dec,
	year = {2010},
}

@techreport{blanchard_effects_2009,
	address = {Palo Alto, CA},
	title = {Effects of {Digital} {Instrumentation} and {Control} {Defense}-in-{Depth} and {Diversity} on {Risk} in {Nuclear} {Power} {Plants}},
	url = {https://www.epri.com/research/products/000000000001019183},
	language = {en},
	number = {1019183},
	institution = {EPRI},
	author = {Blanchard, D.},
	year = {2009},
}

@techreport{torok_modeling_2012,
	title = {Modeling of {Digital} {Instrumentation} and {Control} in {Nuclear} {Power} {Plant} {Probabilistic} {Risk} {Assessments}},
	url = {https://www.epri.com/research/products/000000000001025278},
	language = {en},
	institution = {EPRI},
	author = {Torok, R},
	year = {2012},
}

@techreport{zhang_sensitivity_nodate,
	title = {Sensitivity and {Importance} {Measure} {Analyses} for {Various} {Design} {Architectures} for {High} {Safety}-{Significant} {Safety}-{Related} {Digital} {Instrumentation} and {Control} {Systems} of {Nuclear} {Power} {Plants}},
	url = {https://inldigitallibrary.inl.gov/sites/sti/sti/Sort_65439.pdf},
	abstract = {A transition from analog instrumentation and control (I\&C) technologies to digital I\&C technologies is taking place for license renewals of existing nuclear power plants and for operating licenses of new advanced reactors. This transition necessitates research on risk and economic assessments of digital I\&C technologies to ensure the long-term safety and reliability of vital systems, reduce uncertainty in licensing costs in addition to timeline, support integration of digital I\&C systems in the plant, and find the most efficient technology upgrades. Adding redundancy within systems or components is a common means of improving design safety; however, redundant designs are more prone to common-cause failures (CCFs). Introducing diversity into redundant systems or components is a way to mitigate and possibly eliminate CCFs, but it also increases plant complexity and may be costly. The balance between redundancy and diversity remains a challenge for digital I\&C systems. This study performs sensitivity and importance measure analyses for four design architectures of two digital I\&C systems—the reactor-trip system and the engineered safety features actuation system. For each system, two architectures are examined, including a redundant, non-diverse configuration and a redundant, diverse configuration. The sensitivity analysis will provide insights on the impact of introducing diversity to system reliability. The importance measure results will help identify risk-significant and risksensitive components and failure modes, which may be good candidates for future design improvement.},
	language = {en},
	number = {INL/CON-23-71687-Revision-0},
	author = {Zhang, Sai and Shorthill, Tate and Park, Jooyoung and Chen, Edward},
}

@misc{noauthor_nuclear_2021-1,
	title = {Nuclear power plants - {Instrumentation}, control and electrical power systems important to safety - {Categorization} of functions and classification of systems},
	url = {https://webstore.iec.ch/en/publication/26644},
	month = jul,
	year = {2021},
}

@techreport{noauthor_us_2016,
	title = {U.{S}. {Nuclear} {Regulatory} {Commission} {Standard} {Review} {Plan} - {Chapter} 7},
	url = {https://www.nrc.gov/docs/ML1602/ML16020A049.pdf},
	number = {NUREG-800},
	month = aug,
	year = {2016},
}

@article{patecornell_warning_1985,
	title = {{WARNING} {SYSTEMS} {AND} {DEFENSE} {POLICY} - {A} {RELIABILITY} {MODEL} {FOR} {THE} {COMMAND} {AND} {CONTROL} {OF} {UNITED}-{STATES} {NUCLEAR}-{FORCES}},
	volume = {5},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwzV1LT4NAEJ4YvWiMb2N9NHPwZqiwFArHlW4tCY8GaExPhrpwrEZ78P_5x9xdQEmjSb0ZwgHCTrKw7Mz3ZeYbAJP0dG1lT7DzwuH6oHRL4nARQptFTgg38jwfWMaT0kxqcTvQ9BxrKCblEv5OMn1zSQ3lNHl9VkRiG9X9ivyqDpSORYOppWhwqext2I7TRF1NowS9EhQlA1WARGpt0zphyDJdzRYopydNKSJWEjrvPzo65dRG-_DRlAapXBbZQaGd1H-rhBSVekZLNPK_vasD2KtjaqTVT3AIG8XiCHZaSoviKvySp307huUDTSI_usd0lmYsTJFGQxyyEYtShpM48L0ZakgxYYFP7_zAz2YYxkMWoMDMmI0ZenEYykHy9OIoS-IA4xEKNC08gZZmNGMpRlMvYDTRxCCPpSdwM2KZN9baH-TxpVL7eFyZFjmF3VwWHyyWqkiRnwG6xpzYc4fbVp_353nhclf4fO70xcF1s-zA9TqmO2Cs85hXi7dL0YLl-XqmL2Bb3qi4o0vYKsXeVlzBplxSXYUkumpNfwI1oCAe},
	doi = {10.1111/j.1539-6924.1985.tb00160.x},
	language = {English},
	number = {2},
	journal = {Risk analysis},
	author = {PATECORNELL, ME and NEU, JE},
	year = {1985},
	note = {Place: NEW YORK
Publisher: PLENUM PUBL CORP},
	keywords = {Life Sciences \& Biomedicine, Mathematical Methods In Social Sciences, Mathematics, Mathematics, Interdisciplinary Applications, Physical Sciences, Public, Environmental \& Occupational Health, Science \& Technology, Social Sciences, Social Sciences, Mathematical Methods},
	pages = {121--138},
}

@article{patecornell_warning_1986,
	title = {{WARNING} {SYSTEMS} {IN} {RISK} {MANAGEMENT}},
	volume = {6},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwzV1bS8MwFD6IIijifVgvo4ivnW2Spu3jmJsW2ZB1Ij6NXB-n6P6hf8wkbbcyUOabL4U2bR6S9OR8X875DgBGnTBYsQmCZQkjcSh0qIVGVBNOGNeS2GO8xMXUNLgdqGuO1RST2xL-TjItuaSacnr6eHNEYhPV_Yj8ygqUKb2zx4_OeTKmPqJpWntddaGEsBQURYlLQEKVtmkVMBTjLKAG5XRsV46INSjL6l9vY-NNZFYc9Le9z-1zgwP4qrOFXHiLLarQjPO_ddqKTlCjoSP534bvEPYrN9vvlv_FEWyo2THsNsQXzd1woVj7eQLXL93xKB_d-8VrMekPCz8f-eO8ePSXJQ9O4XnQn_Qegqp-RCCIMWSBQUuhyDRHUrIoEYppLijmlAossYp1pLRUMdI0JgIzaVyfVERMI8xCnUnj3LRgj9k8g9nc5SPKM_B5aqyiUhlBhBJhsGukYmXj4JD5mIeJB61yMqfvpVrItJplD26ak7toXhkiD6J1XutVAu5WuGB-vl7XF7BjH5RxbpewpY19U1ewaddQ26GJtlvX9poPvgGXnCBA},
	doi = {10.1111/j.1539-6924.1986.tb00210.x},
	abstract = {A method is presented here that allows probabilistic evaluation and optimization of warning systems, and comparison of their performance and cost-effectiveness with those of other means of risk management. The model includes an assessment of the signals, and of human response, given the memory that people have kept of the quality of previous alerts. The trade-off between the rate of false alerts and the length of the lead time is studied to account for the long-term effects of "crying wolf" and the effectiveness of emergency actions. An explicit formulation of the system's benefits, including inputs from a signal model, a response model, and a consequence model, is given to allow optimization of the warning threshold and of the system's sensitivity.},
	language = {English},
	number = {2},
	journal = {Risk analysis},
	author = {PATECORNELL, ME},
	year = {1986},
	note = {Place: NEW YORK
Publisher: PLENUM PUBL CORP},
	keywords = {Attitude, Disaster Planning, Humans, Life Sciences \& Biomedicine, Mathematical Methods In Social Sciences, Mathematics, Mathematics, Interdisciplinary Applications, Memory, Models, Theoretical, Physical Sciences, Probability, Public, Environmental \& Occupational Health, Risk, Science \& Technology, Social Sciences, Social Sciences, Mathematical Methods, Stochastic Processes},
	pages = {223--234},
}

@phdthesis{nusbaumer_analytical_2007,
	address = {ZURICH},
	title = {Analytical {Solutions} of {Linked} {Fault} {Tree} {Probabilistic} {Risk} {Assessments} using {Binary} {Decision} {Diagrams} with {Emphasis} on {Nuclear} {Safety} {Applications}},
	url = {https://www.osti.gov/etdeweb/biblio/21229428},
	abstract = {This study is concerned with the quantification of Probabilistic Risk Assessment (PRA) using linked Fault Tree (FT) models. Probabilistic Risk assessment (PRA) of Nuclear Power Plants (NPPs) complements traditional deterministic analysis; it is widely recognized as a comprehensive and structured approach to identify accident scenarios and to derive numerical estimates of the associated risk levels. PRA models as found in the nuclear industry have evolved rapidly. Increasingly, they have been broadly applied to support numerous applications on various operational and regulatory matters. Regulatory bodies in many countries require that a PRA be performed for licensing purposes. PRA has reached the point where it can considerably influence the design and operation of nuclear power plants. However, most of the tools available for quantifying large PRA models are unable to produce analytically correct results. The algorithms of such quantifiers are designed to neglect sequences when their likelihood decreases below a predefined cutoff limit. In addition, the rare event approximation (e.g. Moivre's equation) is typically implemented for the first order, ignoring the success paths and the possibility that two or more events can occur simultaneously. This is only justified in assessments where the probabilities of the basic events are low. When the events in question are failures, the first order rare event approximation is always conservative, resulting in wrong interpretation of risk importance measures. Advanced NPP PRA models typically include human errors, common cause failure groups, seismic and phenomenological basic events, where the failure probabilities may approach unity, leading to questionable results. It is accepted that current quantification tools have reached their limits, and that new quantification techniques should be investigated. A novel approach using the mathematical concept of Binary Decision Diagram (BDD) is proposed to overcome these deficiencies. BDDs have the remarkable properties of having complexity that is not related to the number of prime implicants of the encoded Boolean formula and of having polynomial time complexity. Since a BDD analytically encodes a Boolean formula, the failure probability of the top event can be deduced without the need to resort to any numerical approximations. This approach is therefore an interesting technique for fault tree assessment. However, extended efforts are required when converting a given fault tree structure to its BDD form; the complexity associated with the conversion can be considerably reduced by optimizing the order of the basic events in the BDD. This optimization problem was proved to be of NP-complete complexity. Heuristics have been developed and investigated as a case study on the full scope PRA model of the Leibstadt Nuclear Power Plant. Several static and dynamic optimization techniques are proposed to optimize large problems. In order to evaluate these techniques in practice, a software tool (NeuralSpectrum) has been developed as part of this study. The software is an integrated fault tree / BDD tool that features a fault tree package, a BDD engine and a minimal cutset engine, with dedicated fault tree to BDD conversion and optimization routines. The optimization routines include global, static (preprocessing), dynamic and local (BDD objects) techniques. The combination of global, static, dynamic and local optimization techniques proved to be effective when dealing with large models. The Leibstadt PRA model was successfully converted to a BDD form of more than 1'500'000 nodes, for a total of about 3'650 basic events. The BDD covers a complete event tree sequence that includes reactor shutdown and reactor cooling with all Emergency Core Cooling Systems (including all support systems) of the Leibstadt Nuclear Power Plant. The impact of the different approximations used in the classical approach is evaluated using the Leibstadt PRA model, by comparing the approximated results to exact BDD results. The comparison shows that the classical approach produces accurate results for internal event assessments, but fails for external event assessments or Level 2 PRA, where the probability values are typically much higher. The analytical quantification of large linked fault tree models using BDDs requires complex algorithms and programming techniques, which have been evaluated for the first time on a fullscope PRA model in this study. This study demonstrated the feasibility of implementing BDDs for the analytical quantification of large fault tree models as found in the nuclear industry. The implementation of BDD turns out to be the most promising approach for analytical fault tree model solving. This important insight should be put in focus when considering the increasing demand on PRA related applications, such as risk-informed decision making in modern industries and services. (author)},
	language = {English},
	urldate = {2025-02-25},
	school = {SWISS FEDERAL INSTITUTE OF TECHNOLOG},
	author = {Nusbaumer, O. P. M.},
	month = jul,
	year = {2007},
}

@article{nrcres_nuregcr-7151_nodate,
	title = {{NUREG}/{CR}-7151, {Vol}. 2, "{Development} of a {Fault} {Injection}-{Based} {Dependability} {Assessment} {Methodology} for {Digital} {I}\&{C} {Systems}".},
	language = {en},
	author = {Nrc/Res, Univ of Virginia},
}

@article{nrcres_nuregcr-7151_nodate-1,
	title = {{NUREG}/{CR}-7151 {Vol}. 3, "{Development} of a {Fault} {Injection}-{Based} {Dependability} {Assessment} {Methodology} for {Digital} {I}\&{C} {Systems}."},
	language = {en},
	author = {Nrc/Res, Univ of Virginia},
}

@article{nrcres_nuregcr-7151_nodate-2,
	title = {{NUREG}/{CR}-7151 {Vol} 4, "{Development} of a {Fault} {Injection}-{Based} {Dependability} {Assessment} {Methodology} for {Digital} {I}\&{C} {Systems}".},
	language = {en},
	author = {Nrc/Res, Univ of Virginia},
}

@techreport{zgliczynski_htgr_1987,
	title = {{HTGR} {Plant} {Protection} and {Instrumentation} {System} {Design} {Description}},
	url = {https://www.osti.gov/servlets/purl/714027/},
	language = {en},
	number = {DOE/HTGR--86-047-Rev.1, HFD--33200-Rev.2, 714027},
	urldate = {2025-02-21},
	author = {Zgliczynski, J and Bauer, J},
	month = jul,
	year = {1987},
	doi = {10.2172/714027},
	pages = {DOE/HTGR--86--047--Rev.1, HFD--33200--Rev.2, 714027},
}

@article{gregory_hidden_1989,
	title = {The {Hidden} {Cost} of {Deterrence}: {Nuclear} {Weapons} {Accidents} 1950-88},
	volume = {20},
	issn = {0007-5035},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LTxsxEB414dILhVJEeAQfK6El9no3Nlx4BFCKEBUiVdXTyt713tggslHFf-HHMuONUVKqqKdeV5bWnhmPx55vvgGQ8SGP_vAJ2pj8KCnwvOel02liEmkdRkxlaqxRvvXh3NsOPIbSmJlAJ4eEssIJet9Nm50ep3uznGMPw3BFdxvKmXHPmnYyrR-y5vk7dNmgL5Svnj5QqjsngORzFMrdWrBCZx1ti_vzb8GVEzldU8PCVZRymYaqm7_-c-Fka8CNC2HrHFLMH15Xn-AlrNNjVqhTwjx4v-cJEz1LRiCH_J8yWYPVWVDMzhorXocPrvoMrRvzewNO0Y7ZkHhOKjYYT2o2LtkFQXh8leIxuyU-ZvPEfjpDWF92lufUJrWeMOo8G2n9BX5cXY4Gw2jW9SHKpRJ1hAGaFaZUGFsoUQiXC8P7hZPlkbS4lrhIZGyF1QW3fc2dlQVFeTFaorKFtbHchHY1rtwWsDh3iTLCFim3idWJLUuj0bnj5Rt_oUQHDoLGsseG3CMTgf_8nfw6sOmV-jY0wastwWQ7sB-0nOHmpIyLqdx4OslkH6OxVC8ZkaIsiAW3A19JnVlQ7pJ5bP_70B342GDi6MloF9r109TtoXjQwLrQUqO7LqxcX95-_9X1dv8K0IUU8w},
	doi = {10.1177/096701068902000101},
	abstract = {Reprinted from the forthcoming book, "The hidden cost of deterrence." Includes a chronological list of accidents by country, with brief descriptions.},
	language = {English},
	number = {1},
	journal = {Bulletin of peace proposals},
	author = {Gregory, Shaun and Edwards, Alistair},
	year = {1989},
	note = {Place: Thousand Oaks, CA
Publisher: SAGE Publications Ltd},
	keywords = {Accidents, Aircraft, Aircraft accidents, Atomic weapons, Bomber aircraft, Destroyers, Deterrence, Deterrence (strategy), Fire damage, Missiles, Nuclear accidents, Nuclear weapons, Radiation accidents, Submarines, Weapons},
	pages = {3--26},
}

@article{freudenburg_perceived_1988,
	title = {Perceived {Risk}, {Real} {Risk}: {Social} {Science} and the {Art} of {Probabilistic} {Risk} {Assessment}},
	volume = {242},
	issn = {0036-8075},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwhV1Bb9MwFLbYEBIXYGMTYVB8KNKQaJc4TZxyS6J1LStr1I4J7RIljjMhUIqa9sC_5z3b7bqhqJfntvlSOX7O8-fk-TMhLuvanUcxoeRl4eVMFjIAj_c81F3zBLOz3PZlwB892yHt9dIYzLJUaYLqpT7wpfy3PHM46tzBlGcvsJnO4mvU2TVqPlvrZLo4Yvpqe7f7gciEY52S2Ew21aAzeEmSdf1UrgnucLCddH-mhA6VusVa1HHXtbwiLwwBpaHuMQfkiawOyTO9JeXfQ3JgbvaanhpF6k-vyU2C6S8QFws6_Vn_-kynQC_Vxy9Ur--l5jSaVQUFTon_T-clTRYQLzD_FuWg1Rk03GiBHpHvg_PreNgxGzJ0hN_vLzHrn_Xzwglkr8yykgvOC9GzReEULOsVrgS6Jxw4AKTQkSIQtiekyF1gOb6QnnCPyX41r-QbQvFxE5Nl7vR7OEfjeekjeeJukBcSTrbI6do76R-tu5Gq-QrzU-PI1DjSIm30XopqFhWmywj9yCWFqseTNPS5C3NQZhH6EHaXreo6DS7GuyCj6GInZHKzEzK72oJ8NJByvlxkIjNrIaBtUI5rC9d-gLvTjv8fdqQ61n1L6V5lkZN1R05NaKpT5mDbQ6i2yIfNUYgp-KIoq-R8VafIAoG3BM0IF4gwiqU1I3ylZejbzQgO1NeH-YpFjvU9tqm-cezbhss6Ic-dfqBVifk7sr9crOR76Flw-7XIHv_BlY1a5GkYfY0HWI5n4xGW13Eyg6PReQzfouHwKsTychZOoRzGo8FtS8UTsJdRF-w3O1F2ipZNlFW_cG0RmXi3_wCIzXRG},
	doi = {10.1126/science.3175635},
	abstract = {Social science input is needed in risk assessment, an area commonly left to the physical and biological sciences. Social science can analyze and explain public responses to risk.;Risk assessment is commonly seen as the domain of physical and biological sciences, with social scientists focusing instead on risk management and communication. This division is unnecessary, and it may lead to errors in risk assessments. Social science input is needed for more accurate calculations of risk consequences and probabilities and for identifying potential biases created by certain risk assessment procedures, as well as in analyzing and explaining public responses to risk. Findings, moreover, suggest that the dichotomy between "real" and "perceived" risk is less "real" than is often assumed, particularly in cases involving controversial technologies.;It is argued that risk assessment, commonly seen as the domain of physical \& biological sciences, requires social science input for: making more accurate calculations of risk consequences \& probabilities; identifying potential biases created by certain risk assessment procedures; \& analyzing \& explaining public responses to risk. It is suggested that the dichotomy between real \& perceived risk is less real than is often assumed, particularly in cases involving controversial technologies. 1 Table. Modified HA;},
	language = {English},
	number = {4875},
	journal = {Science (American Association for the Advancement of Science)},
	author = {Freudenburg, William R.},
	year = {1988},
	note = {Place: United States
Publisher: The American Association for the Advancement of Science},
	keywords = {Accidents, Analysis, Assumption of risk, Combinatorial probabilities, Financial risk, Geometric probabilities, Human error, Humans, Methodological Problems, Methods, Nuclear power, Nuclear power industry, Nuclear power plants, Probabilities, Probability, Probability theory, Public opinion, Quantitative Methods, Risk, Risk Assessment, Risk analysis, Risk management, Risk-Taking, Science, Social Sciences, Social conditions \& trends, Social science research, Technology},
	pages = {44--49},
}

@article{noauthor_stein_1988,
	title = {Stein, {Peter} \& {Peter} {Feaver} 1987. '{Assuring} {Control} of {Nuclear} {Weapons}. {The} {Evolution} of {Permissive} {Action} {Links}'. {CSIA} {Occasional} {Paper} {Series}. {Lanham}, {Md}. \& {London}: 1987, 127 pp. {USD} 18.50, hc. {USD} 7},
	volume = {25},
	issn = {0022-3433},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LTxsxEB6VcOHSAoWW8tCcoBLJso8k9vZShRBUKl5SQIhT5NhrcUlYkaSI_9I_1H_FjHcdEUAVJ07RRpbt9Y5nxuNvvgFI4iCsPdMJwsYmEeR7k74UqaxraZK-DiPVsMrofjob24Hcp8aUCzoKGGVFE3S6mzc7B6f3yjtHTumOk3rCvCZk0fmy6OdkPOgV4W9fZYP_4fvqyYCvujUDJB9qPt1tDubZ1vG26O4fTVU5HR3DKd04DeCzbl4dc8ayPYGFOUt1-An--pdyABUui_AUqb_n2BEdJYZngnzPBViEj6UHjK1CZJfgQzZchi8zkUmcQvSWYe5Y3X-Gf12uyllFByfG7fKX_FfqHjmiEeAOSZrLucR2Ab_HW4unTNes7vAqUwwFDpC2BXb-lPuNW5wzGmjEIH5suRwP5OP5aCfAdveohWckewVxCZ6rnAbjcGJGHR2r4Y0aVPHEBDSfoirKDzeVKkaxwDwP8LJ7gJEMGmEVb3TxKFbg4rBz0f5VK6tQ1DRpO-Yelmm9qcnNbZKvpqVNZd_2dSoaRhpDCj-jlQ9tIqwiu6EinUpLhzqhFdl9co9XoTK8HWZfATMrtE21STWfy-KYumoaa-mjCRPFWqzBrhegXl5wjfQiT8f-4guvwXeWiZ6XkP80_fb2puuwQCslC5TdBlTGd5Nsk96ApHQL5n93Ts-ut9weeQRqyCG6},
	doi = {10.1177/002234338802500122},
	language = {English},
	number = {1},
	journal = {Journal of peace research},
	year = {1988},
	note = {Place: Thousand Oaks, CA
Publisher: SAGE Publications},
	pages = {106--108},
}

@article{borning_computer_1987,
	title = {Computer system reliability and nuclear war},
	volume = {30},
	issn = {0001-0782},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Nb9QwELWgXOBSWkD0A8gBuFRpY8dO7AOHpWrFocBlK3GzHNtBeyCLNrvq3-9M7GQTCqKIi5WPSZz4Wc8TZ-aZkJydZukvnFCAWy5yQ00hCyuVyJWraidR7hIFp-h0bidof7Z_Cmo_-2-k4RhgjZmz_4D2cFM4ANuAOZSAOpT3wr1fpiFqNGOyyiJocQelpQYFjM3q5Masxo7pJFGk7SMHZufDxMzHZTeFEpJiYpdyIX0OCCQbIi96BqQpugVjBox_RhajD9FAZzSGOIeRkQa-vku6HPUpwFNi5SmWcju29P_Tv3zVl9dXV3p-8W3-HkXNf7iFXX_wTbppH5JHrFQZLj8Bb7UdRkURlp-IDxyTK6Gys1FVE3fi94Nq5ynMn5LdXrI7mQVw9sgD3-yT3R6YJNLpPnkyEoOEvc-Dgm77jJwM5gHHZIRjAjgmEccEcHxOri8v5uef0riwRWpzJdepN6Uvma0kV2VWicxydJstFcbzwksBTnfupKW5UZWTpc9qUUvjOGdwnQGf7wXZaZaNf0kSY8tOBE65nHPhaoNzDrR2hlbCSacOyNu-ffTPoF-iQy660F0zdqU8IO-w7TTiul4Za2JyBlSC-mB6VjCmeM7gdhO770Eb_a7Z4cQMKMuOTr7pAdJ4AqP8Gr_ctJpJfPeCHv7V4og83vbuY7KzXm38K2gUYIjXXTe6BRvzZBY},
	doi = {10.1145/12527.12528},
	abstract = {Given the devastating consequences of nuclear war, it is appropriate to look at current and planned uses of computers in nuclear weapons command and control systems, and to examine whether these systems can fulfill their intended roles.},
	language = {English},
	number = {2},
	journal = {Communications of the ACM},
	author = {Borning, Alan},
	year = {1987},
	note = {Publisher: Association for Computing Machinery, Inc},
	pages = {112--131},
}

@article{rauchhaus_evaluating_2009,
	title = {Evaluating the {Nuclear} {Peace} {Hypothesis}: {A} {Quantitative} {Approach}},
	volume = {53},
	issn = {0022-0027},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwhV07T8MwED7RTiw8CoVQHp4QHQqJnSYOExVq1QEhVYK5OtcOQkKhaloh_j1nJ-lLqhgTe_DjfPfZ9_kzgOD3fmfLJ0S6m-pU-pNUR6hVhFGCIQV_MojEdJ06w9rZTsGpyUuWpaMJuqQ-4SX1ZWi_Hkmb3qtBjfY3habryvvy2K8Uwu3HKjVpb35zVy5pEy8siW4tFBVsxA2cuUbtctFmcAijqmGOZGKfNlhn2z84hUMna1GpOf7biSM4KKEn6xW2cgx7JmvA2caRIFty4xpQe8GfBnjF_V1W-oCc3ZVC1e0TeOqXUuHZByMcyV6tNjLOmHWzhg1_p_Z2V_6ZP7IeGy0wc_fZyLuyXilkfgrvg_7b87BTvsjQmYg4nncCNZFaCcENcq65iENFCFNJq2JEQESHFHGRI6JKQ6S9kpHcxDhJfCQcgoEvmlDPvjNzDsxPjVYy4WkSYahCITUFRvrl0kIqSD1oV5MznhbCG-Og0ibfmkgPmm58lxWrwfWgVU3nuFyb-ZhAS5dwXhJ4cLMspUVlMyWYme8FVSFgFUY82V2jm0gpCB16wHbUIOQZCPuyswe31pBWDdjVjYtd3WjBfpXE8oNLqM9nC3NFI0lmd-2s_w9EcQG7},
	doi = {10.1177/0022002708330387},
	abstract = {Do nuclear weapons reduce the probability of war? This article quantitatively evaluates the nuclear peace hypothesis. The results indicate that the impact of nuclear weapons is more complicated than is conventionally appreciated. Both proliferation optimists and pessimists find confirmation of some of their key claims. When a nuclear asymmetry exists between two states, there is a greater chance of militarized disputes and war. In contrast, when there is symmetry and both states possess nuclear weapons, then the odds of war precipitously drop. When combined, these findings provide support for the existence of the stability-instability paradox. Evidence suggests that while nuclear weapons promote strategic stability, they simultaneously allow for more risk-taking in lower intensity disputes. Reprinted by permission of Sage Publications, Inc.;Do nuclear weapons reduce the probability of war? This article quantitatively evaluates the nuclear peace hypothesis. The results indicate that the impact of nuclear weapons is more complicated than is conventionally appreciated. Both proliferation optimists and pessimists find confirmation of some of their key claims. When a nuclear asymmetry exists between two states, there is a greater chance of militarized disputes and war. In contrast, when there is symmetry and both states possess nuclear weapons, then the odds of war precipitously drop. When combined, these findings provide support for the existence of the stability—instability paradox. Evidence suggests that while nuclear weapons promote strategic stability, they simultaneously allow for more risk-taking in lower intensity disputes.;Do nuclear weapons reduce the probability of war? This article quantitatively evaluates the nuclear peace hypothesis. The results indicate that the impact of nuclear weapons is more complicated than is conventionally appreciated. Both proliferation optimists and pessimists find confirmation of some of their key claims. When a nuclear asymmetry exists between two states, there is a greater chance of militarized disputes and war. In contrast, when there is symmetry and both states possess nuclear weapons, then the odds of war precipitously drop. When combined, these findings provide support for the existence of the stability-instability paradox. Evidence suggests that while nuclear weapons promote strategic stability, they simultaneously allow for more risk-taking in lower intensity disputes. [PUBLICATION ABSTRACT];Do nuclear weapons reduce the probability of war? This article quantitatively evaluates the nuclear peace hypothesis. The results indicate that the impact of nuclear weapons is more complicated than is conventionally appreciated. Both proliferation optimists and pessimists find confirmation of some of their key claims. When a nuclear asymmetry exists between two states, there is a greater chance of militarized disputes and war. In contrast, when there is symmetry and both states possess nuclear weapons, then the odds of war precipitously drop. When combined, these findings provide support for the existence of the stability -- instability paradox. Evidence suggests that while nuclear weapons promote strategic stability, they simultaneously allow for more risk-taking in lower intensity disputes. [Reprinted by permission of Sage Publications Inc., copyright 2009.];},
	language = {English},
	number = {2},
	journal = {The Journal of conflict resolution},
	author = {Rauchhaus, Robert},
	year = {2009},
	note = {Place: Los Angeles, CA
Publisher: Sage Publications},
	keywords = {Arms control \& disarmament, Asymmetry, Cold wars, Conflict resolution, Death, Democracy, Deterrence, Dyadic relations, Hypotheses, Impact analysis, International disputes, Nuclear Proliferation, Nuclear Weapons, Nuclear deterrence, Peace, Peacetime, Political conditions, Probability, Research design, Risk, Security, Stability, Strategic behaviour, Studies, War, Warfare},
	pages = {258--277},
}

@article{avenhaus_probability_1989,
	title = {The {Probability} of {Nuclear} {War}},
	volume = {26},
	issn = {0022-3433},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV07T8MwED7RsrDwKK9SCFmRKKSx8_CEAIEAoQKiCDFFTuxsbaG0QvwY_it3Thy1oA4sLBkSy3Z89vkenz8DMP_Ia__QCZ4MUoVbdZinQkuPiTxXEi0NJmLOA0M7OxXbgTd7NKYc0PcjQllhB43upsVOwenjMudIR7p9xtHZEsSQhR6GJ04m435SxL_tNRv0hhLWkz7lujNCSH627Xm3GizSZkfr4vHsutLl6Dt6Fd84tlDyFs1pdGZvK-CNM4brFFbMbF-XK_Bl_9SgVuiuhGn4_rGhTDQ8GZYe8l9HZRWWS7vYPS0m8hos6EEDtmbilW4F3GtA7VZ-rIODk9y9H6FKMhDfT3eYu10iaJYj91mONuDp8qJ3ftUuL3xoZ0yEY3zKWEl0oCTPYlQlUkZxKFmYK8KqhjpKRZBFaCFFWiimfR0HnvRUxJXuaJELtgn1wXCgt8HNuNYipoKa81QwGSolgijz4oileRg04dCKKnkteD2SjqU-_z1wTVg34qzKcp-OIDdh10o3sUJJ0IKiXDa6-U1o_f7sd9BkQzMZ69yvvuKapkSNHOjh5D0JiZePUasHJOGpquf3cOcPZVuwVEDlCJWzC_XxaKL3cOhw1jlQi3oPjuFJdmDx5qJ79-KYNfEN9G0dZg},
	doi = {10.1177/0022343389026001009},
	abstract = {A theoretical analysis of the probability of nuclear war is presented. The analysis assumes a starting probability and an annual reduction factor.;A theoretical analysis of the probability of nuclear war is developed that assumes a starting probability and an annual reduction factor. Whatever the starting probability is, a constant reduction factor leads to an eventual probability that is less than 1, whereas the eventual probability goes to 1 if there is no reduction or if the reduction proportion decreases at a constant rate. Numerical calculations and graphical results illustrate trade-offs between the starting probabilities and the reduction factors, demonstrating especially the significance of the latter. In addition, upper and lower limits for, and approximations of, the eventual probabilities - along with measures of the rate of convergence - are derived. The applicability of the analysis to lowering the probability of nuclear war is discussed, with particular attention paid to real-life factors that seem to affect this probability.;},
	language = {English},
	number = {1},
	journal = {Journal of peace research},
	author = {Avenhaus, Rudolf and Brams, Steven J. and Fichtner, John and Kilgour, D. Marc},
	year = {1989},
	note = {Place: 28 Banner St, London EC1Y 8QE, UK
Publisher: Sage Publications},
	keywords = {Future, Nuclear War, Nuclear weapons, Probability, War},
	pages = {91--99},
}

@incollection{institute_of_medicine_sources_2000,
	title = {Sources of {Human} {Instability} in the {Handling} of {Nuclear} {Weapons}},
	isbn = {0309036925;9780309036924;},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwbVzJTsMwEB2hckFwoCyibPIPpPGWuDlXVD0hgRAcIzd2BRc3aumBv2fGrhHbJVKiWBNHluf5zbwHoOSYF7_2BCG56SbCVrikPK9d5amkppRweF2K7ie3A1WWxgTbjzMrZlPDOJ4fqcCPkMqVjeZl92p7_ISSxNT7EtEzHcEeH57zqkJAUdXfTOfExJBJnf5iYriMJiixlEusRd3IamfNk-81Zp6QO6Rj5pkdwyGpEdg0hR_Cng8ncJTINpY0RKeIuCMFv2GrJYusPKMegOTA_cHeAkOUx-bkp4CJil66Jxdju2Yv3lKH7BmMZndP03mB0ds--U-0OOtWCXUOg7AK_gJYIxfOY7bTCEe01N4aaxa-UUo5Y5TVIxj-HX_538MrOEhac1Fwcw2D9_XW32CcbrO9jX_1E-Npf8U},
	abstract = {Written by world-renowned scientists, this volume portrays the possible direct and indirect devastation of human health from a nuclear attack. The most comprehensive work yet produced on this subject, The Medical Implications of Nuclear War includes an overview of the potential environmental and physical effects of nuclear bombardment, describes the problems of choosing who among the injured would get the scarce medical care available, addresses the nuclear arms race from a psychosocial perspective, and reviews the medical needs-in contrast to the medical resources likely to be available-after a nuclear attack. "It should serve as the definitive statement on the consequences of nuclear war." - Arms Control Today},
	language = {English},
	booktitle = {The {Medical} {Implications} of {Nuclear} {War}},
	publisher = {National Academies Press},
	author = {{Institute of Medicine} and {Steering Committee for the Symposium on the Medical Implications of Nuclear War}},
	year = {2000},
	pages = {490--528},
}

@article{noauthor_scott_1995,
	title = {Scott {D}. {Sagan}: {The} {Limits} of {Safety}. {Organizations}, {Acciden}},
	volume = {16},
	issn = {0170-8406},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1BS8MwFH7oDuJFdCpuUwkehjJb26XtWtGDug2FoYdV8FaWNhUPdmC3w_69r0natYpD8VJKEtLQL3l5Cd_7HgDt6ob2xSZQyw5xM7KYx8yI9yLbYo4X2iaN3Th2GKve7chUoulPpPaLfyONZYh1Fjn7B7SLTrEA3xFzfCLq-PwV7iJDfaevd8aT10mSkypEHJNgbYwnMZ8t9GoQprAQYZglGC17q-U2Qog2ZxxGKm7OLnhQ6pqwxACSFLsla0jcK_YMDc96SpVa2kJ0NjRqSHnGwlg6pUlhlyyfJ7MIVxWtH5-C4fNoFPiDF79aKw8g3czjcHrtTOb8PXoLZ9c80ebpOqxTM0uEML59KLZVaoo8tsVIv22ewiPwt2FLufLkRmKwA2s8qcNGHklQh4YMfSbKfKbkVGl8n9WhWQQKkTZR7aRiy2IXrgSGpK8TgeElQQSJRJBMY6IQJBUEz4nCbw9OhgP_7l7Lhx2oaZMGmZPmZMpjdB9qyTThB0DQkWUGdui61EWngbohrh9uM255UZdT3oDWio6aK2tbsLmcI4dQm33M-RF-GRfYsfjrn__iLi8},
	language = {English},
	number = {5},
	journal = {Organization studies},
	year = {1995},
	note = {Place: Berlin
Publisher: Sage Publications Ltd},
	pages = {904},
}

@inproceedings{hafemeister_primer_2014,
	address = {Melville},
	title = {Primer on nuclear exchange models},
	volume = {1596},
	isbn = {0094-243X},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1JS8NAFB60RfDmUnGpJV68SNpkJskkBw8iLRaK7SEFb2EyM4EemkCTgj_fN5ksrRVBvISSlGzf5L3v7QgRPLTMbzJBSOoL5nEbWw6oIApagQgKdANTl5MywLvr2-nVpTE_JrWP_o007AOsVeXsH9BuTgo74DdgDltAHbaHuP-ofl6mC5VMXjeQbf-T766Pherrv1GxglS1NGabJ_mpq4D1dJy8lU2JXMtVPcGjTYKvfAW2U2bmtRKpCQLtJSKUqaZ81zUIJp-JnXJOL-iISjC6tkk9XRfZSE5XT6PdWyNai-qWLQfyGQiRchUMwUwCKuS2SqgOvL_Po8lyNovC8Uf4qLqfr8WKF88yNbf5MepiAvSmTNBsEnkwMFitb6u7rvtHeWTUXAgUbgaPfKBwSxYRnqFeW19pLBpYztGRTC_QSfWGLtGDxsbIUqPCxqixMTQ2PbScjMPXN7MaZWFmNvUKMPdV1xtgexQsxJjBlwOGq-eLxOdYOpz4nhUzXwDZ8-NYspjGdsAtht0kUWH6gFyhTpql8hoZggcsANFpuUnsUO4zYFyBxNyRjDhEiBvUV48aAYNSbYC5ypfiRaQ8fWrcAByuX0FULds8Um3-PVf19bn9_fAdOm3XVR91is1W3sOtwZc5KFEZoO48nIfTL9K3ONc},
	doi = {10.1063/1.4876435},
	abstract = {Basic physics is applied to nuclear force exchange models between two nations. Ultimately, this scenario approach can be used to try and answer the age old question of 'how much is enough?' This work is based on Chapter 2 of Physics of Societal Issues: Calculations on National Security, Environment and Energy (Springer, 2007 and 2014)},
	language = {English},
	booktitle = {{AIP} conference proceedings},
	publisher = {American Institute of Physics},
	author = {Hafemeister, David},
	year = {2014},
	note = {Issue: 1
Conference Proceedings},
	keywords = {Exchanging, MATHEMATICAL MODELS, NATIONAL SECURITY, NON-PROLIFERATION POLICY, NUCLEAR DETERRENCE, NUCLEAR DISARMAMENT, SAFEGUARDS AND PHYSICAL PROTECTION, NUCLEAR WEAPONS, PROLIFERATION},
	pages = {38--38},
}

@article{pate-cornell_black_2012,
	title = {On "{Black} {Swans}" and "{Perfect} {Storms}": {Risk} {Analysis} and {Management} {When} {Statistics} {Are} {Not} {Enough}},
	volume = {32},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV3NbtQwELagXOBQKL-BtjIXblvs2I5jboV2uwhRoFtEOVlOYktQKVvtbqHHPgi8XJ-EGWeT7lbVCiEu0Saxo_V4xv5mPP5MiEi3WO_KmJDx0hXSZLwA-J2LwGSomApMqcKnJlJ5zsV2mnQo3BrT0EV08Tc0lDh8o727YrJo80qYXgb-xIyYk4MubiG85EJjst_rr5frC7gHM0ZfdNwzdCXH59oPLUxct7APzq5DpYsgN85S_bvkR9ugmJyCRyLMZ-m_jMyIkQ6jZYH8P42_R1ZnuJZuN4q4Rm74-j65M8d2CHfvO4rYyQPy_UNNL85_xQAiHf6EGfPi_Dd1dYVPP_oxppnQ4RQgNb54RQ--TY5pS6ESy11m7lCYUmqKuLmhnYa_4en-aEp3azyE6CH53N89fDPozQ5-6JUqg0EPfCiVSuUNT4MQ4MMJUUhV6eBFVYUcKeKl485wbwLSOQqfpZ45U_qKFRWgkEdkpR7V_gmhWrhS4mE8LAuS-9yUQrsqGBmUKmUmE8LbXrUnDb-HnfOLQKoWpWpRqjZK1Z4l5EXs_q6CGx9jfpxW9sv-ns0H_XfsaNi3g4Sst_phZ0PDxCL_ERMIpBPyvHsNRo0rNa72o1Mso43CiAFbUgbXxQCNZXpZGQXw3gBSWVJGcJWDUylNQh43Otw1DLBjDhAZauuofn8tInvwdriNP5_-c81n5DY8T5t9n-tkZTo-9RvQr2Azm-SmPvy0GU0arjtHgz94Sk4z},
	doi = {10.1111/j.1539-6924.2011.01787.x},
	abstract = {Two images, "black swans" and "perfect storms," have struck the public's imagination and are used-at times indiscriminately-to describe the unthinkable or the extremely unlikely. These metaphors have been used as excuses to wait for an accident to happen before taking risk management measures, both in industry and government. These two images represent two distinct types of uncertainties (epistemic and aleatory). Existing statistics are often insufficient to support risk management because the sample may be too small and the system may have changed. Rationality as defined by the von Neumann axioms leads to a combination of both types of uncertainties into a single probability measure-Bayesian probability-and accounts only for risk aversion. Yet, the decisionmaker may also want to be ambiguity averse. This article presents an engineering risk analysis perspective on the problem, using all available information in support of proactive risk management decisions and considering both types of uncertainty. These measures involve monitoring of signals, precursors, and near-misses, as well as reinforcement of the system and a thoughtful response strategy. It also involves careful examination of organizational factors such as the incentive system, which shape human performance and affect the risk of errors. In all cases, including rare events, risk quantification does not allow "prediction" of accidents and catastrophes. Instead, it is meant to support effective risk management rather than simply reacting to the latest events and headlines. Adapted from the source document.;Two images, "black swans" and "perfect storms," have struck the public's imagination and are used--at times indiscriminately--to describe the unthinkable or the extremely unlikely. These metaphors have been used as excuses to wait for an accident to happen before taking risk management measures, both in industry and government. These two images represent two distinct types of uncertainties (epistemic and aleatory). Existing statistics are often insufficient to support risk management because the sample may be too small and the system may have changed. Rationality as defined by the von Neumann axioms leads to a combination of both types of uncertainties into a single probability measure--Bayesian probability--and accounts only for risk aversion. Yet, the decisionmaker may also want to be ambiguity averse. This article presents an engineering risk analysis perspective on the problem, using all available information in support of proactive risk management decisions and considering both types of uncertainty. These measures involve monitoring of signals, precursors, and near-misses, as well as reinforcement of the system and a thoughtful response strategy. It also involves careful examination of organizational factors such as the incentive system, which shape human performance and affect the risk of errors. In all cases, including rare events, risk quantification does not allow "prediction" of accidents and catastrophes. Instead, it is meant to support effective risk management rather than simply reacting to the latest events and headlines.;Two images, 'black swans' and 'perfect storms,\&\#8221 ; have struck the public's imagination and are used - at times indiscriminately - to describe the unthinkable or the extremely unlikely. These metaphors have been used as excuses to wait for an accident to happen before taking risk management measures, both in industry and government. These two images represent two distinct types of uncertainties (epistemic and aleatory). Existing statistics are often insufficient to support risk management because the sample may be too small and the system may have changed. Rationality as defined by the von Neumann axioms leads to a combination of both types of uncertainties into a single probability measure - Bayesian probability - and accounts only for risk aversion. Yet, the decisionmaker may also want to be ambiguity averse. This article presents an engineering risk analysis perspective on the problem, using all available information in support of proactive risk management decisions and considering both types of uncertainty. These measures involve monitoring of signals, precursors, and near-misses, as well as reinforcement of the system and a thoughtful response strategy. It also involves careful examination of organizational factors such as the incentive system, which shape human performance and affect the risk of errors. In all cases, including rare events, risk quantification does not allow 'prediction' of accidents and catastrophes. Instead, it is meant to support effective risk management rather than simply reacting to the latest events and headlines. Reprinted by permission of Blackwell Publishers;Two images, "black swans" and "perfect storms," have struck the public's imagination and are used--at times indiscriminately--to describe the unthinkable or the extremely unlikely. These metaphors have been used as excuses to wait for an accident to happen before taking risk management measures, both in industry and government. These two images represent two distinct types of uncertainties (epistemic and aleatory). Existing statistics are often insufficient to support risk management because the sample may be too small and the system may have changed. Rationality as defined by the von Neumann axioms leads to a combination of both types of uncertainties into a single probability measure--Bayesian probability--and accounts only for risk aversion. Yet, the decisionmaker may also want to be ambiguity averse. This article presents an engineering risk analysis perspective on the problem, using all available information in support of proactive risk management decisions and considering both types of uncertainty. These measures involve monitoring of signals, precursors, and near-misses, as well as reinforcement of the system and a thoughtful response strategy. It also involves careful examination of organizational factors such as the incentive system, which shape human performance and affect the risk of errors. In all cases, including rare events, risk quantification does not allow "prediction" of accidents and catastrophes. Instead, it is meant to support effective risk management rather than simply reacting to the latest events and headlines. [PUBLICATION ABSTRACT];},
	language = {English},
	number = {11},
	journal = {Risk analysis},
	author = {Paté-Cornell, Elisabeth},
	year = {2012},
	note = {Place: Malden, USA
Publisher: Blackwell Publishing Inc},
	keywords = {Accidents, Aleatory, Ambiguity, Analysis, Decision making, Deepwater Horizon, Disasters, Emergency preparedness, Engineering, Errors, Fukushima, Industry, Nuclear power plants, Offshore oil exploration \& development, Rationality, Risk, Risk Assessment, Risk analysis, Risk management, Risk theory, Statistics, Storms, Studies, Uncertainty, epistemic, perfect storms, probability black swans, uncertainties},
	pages = {1823--1833},
}

@article{caswell_probabilistic_2011,
	title = {Probabilistic {Analysis} of a {Country}'s {Program} to {Acquire} {Nuclear} {Weapons}},
	volume = {16},
	issn = {1082-5983},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV07T8MwELagLCyIp3jLC2WoEoJT183AgKoihERh4CGmKrUdwUBbJeF38Je58yNNeUgglqhKq9rxXe4-3313JiRmYRR8sgmAK_A4FNVRMVdZe2QSXgmAER5Lpdv6U2zn3ZfGfEtqP_m3pOEeyBorZ_8g7epP4QZ8BpnDFaQO11_J_TaHNxQZr9iAea7nSGoK0EvMm4sCKwSQmIXY81wiHVi3BtjbOM1bjzqd-iieP-zJNPPGdPxU54495_oEPSNIdXUyuaXePqRhLcLQSwtPvTYM-tZVOEtclTZTH_QmuSfcXIdINis82awKSpjSvHpQoprUzWxSnkno6ag1owswJOCJPdAm1OYeA5wYMGHbuleWuvNFI63Z5TX_bWrrvngGLoxnwKFwJMS5Mw9Y8RKxTBhcB2ti3_VX9SLLMz0O3opFssQEIKcGWbrqD26eqigelvImsU2pu4ew1RU43kl9tDncU6e-GiBzt0pW3A6EnlvVWSMLerxOtv1a0iYdpKCP1Bn9DXI5p1HUaxSdZDSlTqOOC-r0iZYT6vSJOn2iTp82yf1F_653GbjzNwIJhrwMEjnqwrsa87ZOpGJRrGRHgcUWEWDEjGHtLZMcEL3QEQdTILiOFJ7kEnXFSJ3KeIs0xpOx3iaUcylw65wCYGxrlnVj8G6n2YgrkUihujvkyK_OcGrbrAxhe4qrOKyv4g7ZMktX_chLbPenL_bI8kxB90mjzN_0AcwLbMmhk-YHeHFwUg},
	doi = {10.5711/108259831615},
	abstract = {This paper describes a risk analysis approach for assessing the progress of another country's nuclear weapons program over time. To handle the dynamics inherent to nuclear weapons development, we embed a semi-Markov decision process into a Bayesian network. The Bayesian network accounts for distributions on the time to transition between possible states of the nuclear weapons program. Our approach enables analysis of the country's nuclear weapons program decisions by identifying how each decision maker would direct the program given the domestic, international, and security influences affecting the country. We demonstrate the model with a case study of Pakistan's nuclear weapons program.},
	language = {English},
	number = {1},
	journal = {Military operations research (Alexandria, Va.)},
	author = {Caswell, David J. and Paté-Cornell, M. Elisabeth},
	year = {2011},
	note = {Publisher: Military Operations Research Society},
	keywords = {Bayesian networks, Countries, Military operations, Nuclear research, Nuclear weapons, Nuclear weapons testing, Operations research, Optimal policy, Probability distributions, Weapons},
	pages = {5--20},
}

@article{pate-cornell_probabilistic_1995,
	title = {Probabilistic interpretation of command and control signals: {Bayesian} updating of the probability of nuclear attack},
	volume = {47},
	issn = {0951-8320},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1LT9wwEB61y6UVgj5ALI_WR3pIExPHwdxoVURVqdsDPVsTO0YrRDbazR7498zkAbutKiR6yMWKbWU8nhk733wDkJ58TqI_bAKidzmSPyj0qfahzAopke_8U50H1bIZr9ztPKbGMMqydwWdiW-Nd98S98KN6-k05lCBtJPp4JhTZfISNshZmWwEG-fff1z-fEyWNB39J9eX5w5DPp3U8UPbsVGf2mGiyb_81WaNC5Ji6Mpf_GXJW_d0sQ3V8CUtKoVrIazC8-OWErHlwRjoH__vq9_AVh_IivPutbfwoqzewesVesP3sPg1J2vB6FsmgxbTNXyjmAVB891i5QU_PWZeMKCEtsSZ-IJ3JWd4imXNKRjVNfegcFXUw6jNHTdVzMiMc4FNg-5mB35ffLv6ehn1RR4ip2TSRJk33mNwKR1VXe5OUAbm3zF8EPSBgonU6DJobYIPRRG0kXSO1njKsVRIM0x3YVTNqnIPhAy-IAULEjOnNA2FuU6US5QqsiJx-RiiYSlt3XF52AHkxoK0LElrlG1laSdjyIf1tmvLYcndPNHzaE09HqYjdZcqS8bwcVAXS9uZ_9FgVc6WCyt1nmgKGfefPfcBvOrS7vma6BBGzXxZHpGMSOU-9HvhHpOyFf4},
	doi = {10.1016/0951-8320(94)00037-O},
	abstract = {A warning system such as the Command, Control, Communication, and Intelligence system (C super(3)I) for the United States nuclear forces operates on the basis of various sources of information among which are signals from sensors. A fundamental problem in the use of such signals is that these sensors provide only imperfect information. Bayesian probability, defined as a degree of belief in the possibility of each event, is therefore a key concept in the logical treatment of the signals. However, the base of evidence for estimation of these probabilities may be small and, therefore, the results of the updating (posterior probabilities of attack) may also be uncertain. In this paper, we examine the case where uncertainties hinge upon the existence of several possible underlying hypotheses (or models), and where the decision-maker attributes a different probability of attack to each of these fundamental hypotheses. We present a two-stage Bayesian updating process, first of the probabilities of the fundamental hypotheses, then of the probabilities of attack conditional on each hypothesis, given a positive signal from the C super(3)I. We illustrate the method in the discrete case where there are only two possible fundamental hypotheses, and in the case of a continuous set of hypotheses. We discuss briefly the implications of the results for decision-making.;A warning system such as the Command, Control, Communication, and Intelligence system (C

3I) for the United States nuclear forces operates on the basis of various sources of information among which are signals from sensors. A fundamental problem in the use of such signals is that these sensors provide only imperfect information. Bayesian probability, defined as a degree of belief in the possibility of each event, is therefore a key concept in the logical treatment of the signals. However, the base of evidence for estimation of these probabilities may be small and, therefore, the results of the updating (posterior probabilities of attack) may also be uncertain. In this paper, we examine the case where uncertainties hinge upon the existence of several possible underlying hypotheses (or models), and where the decision-maker attributes a different probability of attack to each of these fundamental hypotheses. We present a two-stage Bayesian updating process, first of the probabilities of the fundamental hypotheses, then of the probabilities of attack conditional on each hypothesis, given a positive signal from the C

3I. We illustrate the method in the discrete case where there are only two possible fundamental hypotheses, and in the case of a continuous set of hypotheses. We discuss briefly the implications of the results for decision-making. The method can be generalized to other warning systems with imperfect signals, when the prior probability of the event of interest is uncertain.;},
	language = {English},
	number = {1},
	journal = {Reliability engineering \& system safety},
	author = {Paté-Cornell, M. Elisabeth and Fischbeck, Paul S.},
	year = {1995},
	note = {Place: Oxford
Publisher: Elsevier Ltd},
	keywords = {Applied sciences, Energy, Energy. Thermal use of fuels, Exact sciences and technology, Fission nuclear power plants, Installations for energy generation and conversion: thermal and electrical energy},
	pages = {27--36},
}

@article{pate-cornell_improving_2014,
	title = {Improving {Risk} {Management}: {From} {Lame} {Excuses} to {Principled} {Practice}},
	volume = {34},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwnV1Lb9NAEF5BucCB9yNQokVIHJBSbO8bcWlL0yAKKqEIOK3W67WoqiZV3Ej9-cysH0kQsgQXK1HGsXZmZz0z-823hLBsJxn9sSYwobKccV6kLGjhmZEe8ujEKBGClnnYrO2Qd21rTE0X0dXf0FHi8o3-7vJqzeeRknYnbhPBepwyhfC-vZ-rHQXsuoz1FhW7hLKGqhRRPatbN15ON1DPVwiWdBXoq6wPuvhbJLoZ2MY30_gO-dUOIgJS8BiEdWT-m8iGGCkwWubH_x3wXXK7iV7pbj3d7pFrYXaf3FrjNIRvnzoi2OoB2e-KFnR6Wp3RFdrmLR0v5uf0yJ0HenDll1Wo6OWcHrfF_4IeNw1cD8m38cHJ_mTUnNsw8kKodFQo6bQ2RaZ96mHNkKX2sgyJy3XwUhbe50KptIRMsRDGZVqnTrHSOF_wMgkFe0S2ZvNZeEKoS_PEMeUyiDIg9eQuERrmXI6H68DVDMjL1mD2oqbnsG1agwqyUUED8irashNxizMEtClhv38-tHJqPh6OJ0d2b0CGG8buboC8UkMoDM_bbq1vG2evLGZ9WkBcKgfkRfczuCnuvbhZmC9RRuCmp-K8V0ZgZzsOq0dGZiaFvKhHRmIUC6GX7pFRCUJxOYf_eVzP4tVgudFGGVDb6zgBezRrpx--7sZPT_9F-Bm5CYEnr2HP22TrcrEMz8Ho4BtDcl2dfBlG54Xr-x-T3x6CSkE},
	doi = {10.1111/risa.12241},
	abstract = {The three classic pillars of risk analysis are risk assessment (how big is the risk and how sure can we be?), risk management (what shall we do about it?), and risk communication (what shall we say about it, to whom, when, and how?). We propose two complements as important parts of these three bases: risk attribution (who or what addressable conditions actually caused an accident or loss?) and learning from experience about risk reduction (what works, and how well?). Failures in complex systems usually evoke blame, often with insufficient attention to root causes of failure, including some aspects of the situation, design decisions, or social norms and culture. Focusing on blame, however, can inhibit effective learning, instead eliciting excuses to deflect attention and perceived culpability. Productive understanding of what went wrong, and how to do better, thus requires moving past recrimination and excuses. This article identifies common blame-shifting "lame excuses" for poor risk management. These generally contribute little to effective improvements and may leave real risks and preventable causes unaddressed. We propose principles from risk and decision sciences and organizational design to improve results. These start with organizational leadership. More specifically, they include: deliberate testing and learning--especially from near-misses and accident precursors; careful causal analysis of accidents; risk quantification; candid expression of uncertainties about costs and benefits of risk-reduction options; optimization of tradeoffs between gathering additional information and immediate action; promotion of safety culture; and mindful allocation of people, responsibilities, and resources to reduce risks. We propose that these principles provide sound foundations for improving successful risk management. [PUBLICATION ABSTRACT];The three classic pillars of risk analysis are risk assessment (how big is the risk and how sure can we be?), risk management (what shall we do about it?), and risk communication (what shall we say about it, to whom, when, and how?). We propose two complements as important parts of these three bases: risk attribution (who or what addressable conditions actually caused an accident or loss?) and learning from experience about risk reduction (what works, and how well?). Failures in complex systems usually evoke blame, often with insufficient attention to root causes of failure, including some aspects of the situation, design decisions, or social norms and culture. Focusing on blame, however, can inhibit effective learning, instead eliciting excuses to deflect attention and perceived culpability. Productive understanding of what went wrong, and how to do better, thus requires moving past recrimination and excuses. This article identifies common blame‐shifting “lame excuses” for poor risk management. These generally contribute little to effective improvements and may leave real risks and preventable causes unaddressed. We propose principles from risk and decision sciences and organizational design to improve results. These start with organizational leadership. More specifically, they include: deliberate testing and learning—especially from near‐misses and accident precursors; careful causal analysis of accidents; risk quantification; candid expression of uncertainties about costs and benefits of risk‐reduction options; optimization of tradeoffs between gathering additional information and immediate action; promotion of safety culture; and mindful allocation of people, responsibilities, and resources to reduce risks. We propose that these principles provide sound foundations for improving successful risk management.;The three classic pillars of risk analysis are risk assessment (how big is the risk and how sure can we be?), risk management (what shall we do about it?), and risk communication (what shall we say about it, to whom, when, and how?). We propose two complements as important parts of these three bases: risk attribution (who or what addressable conditions actually caused an accident or loss?) and learning from experience about risk reduction (what works, and how well?). Failures in complex systems usually evoke blame, often with insufficient attention to root causes of failure, including some aspects of the situation, design decisions, or social norms and culture. Focusing on blame, however, can inhibit effective learning, instead eliciting excuses to deflect attention and perceived culpability. Productive understanding of what went wrong, and how to do better, thus requires moving past recrimination and excuses. This article identifies common blame-shifting 'lame excuses' for poor risk management. These generally contribute little to effective improvements and may leave real risks and preventable causes unaddressed. We propose principles from risk and decision sciences and organizational design to improve results. These start with organizational leadership. More specifically, they include: deliberate testing and learning-especially from near-misses and accident precursors; careful causal analysis of accidents; risk quantification; candid expression of uncertainties about costs and benefits of risk-reduction options; optimization of tradeoffs between gathering additional information and immediate action; promotion of safety culture; and mindful allocation of people, responsibilities, and resources to reduce risks. We propose that these principles provide sound foundations for improving successful risk management. Reprinted by permission of Blackwell Publishers;The three classic pillars of risk analysis are

risk assessment

(how big is the risk and how sure can we be?),

risk management

(what shall we do about it?), and

risk communication

(what shall we say about it, to whom, when, and how?). We propose two complements as important parts of these three bases:

risk attribution

(who or what addressable conditions actually caused an accident or loss?) and

learning from experience

about risk reduction (what works, and how well?). Failures in complex systems usually evoke blame, often with insufficient attention to root causes of failure, including some aspects of the situation, design decisions, or social norms and culture. Focusing on blame, however, can inhibit effective learning, instead eliciting excuses to deflect attention and perceived culpability. Productive understanding of what went wrong, and how to do better, thus requires moving past recrimination and excuses. This article identifies common blame‐shifting “lame excuses” for poor risk management. These generally contribute little to effective improvements and may leave real risks and preventable causes unaddressed. We propose principles from risk and decision sciences and organizational design to improve results. These start with organizational leadership. More specifically, they include: deliberate testing and learning—especially from near‐misses and accident precursors; careful causal analysis of accidents; risk quantification; candid expression of uncertainties about costs and benefits of risk‐reduction options; optimization of tradeoffs between gathering additional information and immediate action; promotion of safety culture; and mindful allocation of people, responsibilities, and resources to reduce risks. We propose that these principles provide sound foundations for improving successful risk management.;The three classic pillars of risk analysis are risk assessment (how big is the risk and how sure can we be?), risk management (what shall we do about it?), and risk communication (what shall we say about it, to whom, when, and how?). We propose two complements as important parts of these three bases: risk attribution (who or what addressable conditions actually caused an accident or loss?) and learning from experience about risk reduction (what works, and how well?). Failures in complex systems usually evoke blame, often with insufficient attention to root causes of failure, including some aspects of the situation, design decisions, or social norms and culture. Focusing on blame, however, can inhibit effective learning, instead eliciting excuses to deflect attention and perceived culpability. Productive understanding of what went wrong, and how to do better, thus requires moving past recrimination and excuses. This article identifies common blame-shifting 'lame excuses' for poor risk management. These generally contribute little to effective improvements and may leave real risks and preventable causes unaddressed. We propose principles from risk and decision sciences and organizational design to improve results. These start with organizational leadership. More specifically, they include: deliberate testing and learning-especially from near-misses and accident precursors; careful causal analysis of accidents; risk quantification; candid expression of uncertainties about costs and benefits of risk-reduction options; optimization of tradeoffs between gathering additional information and immediate action; promotion of safety culture; and mindful allocation of people, responsibilities, and resources to reduce risks. We propose that these principles provide sound foundations for improving successful risk management. Adapted from the source document.;},
	language = {English},
	number = {7},
	journal = {Risk analysis},
	author = {Paté-Cornell, Elisabeth and Cox Jr, Louis Anthony},
	year = {2014},
	note = {Place: Hoboken, NJ
Publisher: Blackwell Publishing Ltd},
	keywords = {Accident causation analysis, Accidents, Analysis, Benefits, Biological and medical sciences, Causal analysis, Causation, Complex systems, Cost, Culture, Decision making, Decisions, Economic behaviour, Failure, Leadership, Learning, Medical sciences, Organization theory, Public health. Hygiene-occupational medicine, Risk, Risk analysis, Risk assessment, Risk communication, Risk management, Risk theory, Studies, Uncertainty, excuses, high-reliability organizations, organizational design, risk attribution},
	pages = {1228--1239},
}

@article{pate-cornell_games_2012,
	title = {Games, {Risks}, and {Analytics}: {Several} {Illustrative} {Cases} {Involving} {National} {Security} and {Management} {Situations}},
	volume = {9},
	issn = {1545-8490},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwjV1LT-MwELYQEojLLq_VshTkC7sXAo7jxDE3QDx6pfRsObGL0JaA1i2_f2ccF0iLVC7pZWol4_HMN5PJN4Rk_IQlcz7B8pHIWSVMIVQGZpMZmaZFmYpKWYiBVbe281b-mHuhD-j-1DrI9AEksBOILpj2ZIVUIUsfviVamYo8qSJPSqFYJGtc_HsnGEWXvNYylvoF5xwizvV3cj_7bic0muB4g48d96eB5TBQW3xgdFz6IJvkW0Sg9Lw1mS2y4pptsj5rgN8hTzfYOHtM7x79X_gxjaWBuQT5nM_owL1iFYv2x-NpS7n76uglhEJP-w24OqxP0Ei2PaaDOB0vrPLeaUMHj5OWYtzvkuH11f3lbRKHMiQ1YLNJMmLclqWtmGM5Y7XJHZxoVyOwK0bCVqqWRgIsklbZtDBl5vKyKAtjWTpymBz9IKvNc-N-EipTLivHKydNJnIrlS0Fr9NMAGThtsr3yJ_Z7uiXlntDY84C2tOoPY3a06i9PXKEm6fj4E64eCxt-Acz9V6fcyUkQLucwYpBDrcYVFSb-A0C3A_SYHUkf3ckH1oS8M8Eex1BOJ11d51oT0sfoTczNx3diNc4Aw4JDmXx68u62CcbAOp4287WI6uTf1N3ADoH-zyEbOFieBgOy38JxxDd},
	doi = {10.1287/deca.1120.0241},
	abstract = {This paper presents and compares four models of games and risk analyses designed to support strategic and policy decisions, three focusing on national security issues and one on project management. They share a common core of probability, linked decisions among the parties involved, and risks to a principal decision maker. Their structure is based on systems and decision analysis. Their level of complexity depends on the strategies, the environment, and assumptions of variation over time of probabilities, preferences, and options. They are part of the field of analytics and some of its real-life applications. The first model is based on a one-move game, in which the United States faces risks of terrorist attacks by several possible groups using various types of weapons. The result is a probabilistic ranking, at a given time, of the threat posed by these weapons. The second model is a dynamic simulation of counterterrorism scenarios in an alternate game between a government and a terrorist group. The objective is to compare the stabilizing effects of different short- and long-term government strategies. The third model is a dynamic evaluation of nuclear counterproliferation strategies involving an analysis of the weapon development program of a particular country with evolving intent and capabilities and of the effectiveness of different U.S. strategies to prevent or delay its success. The fourth model is a principal–agent representation of the development of an engineered system, in which an agent in charge of part of the project may consider meeting a deadline by cutting corners if he falls behind schedule, generally increasing the system failure probability. The goal is to support the decisions of the manager in setting constraints and incentives. This paper shows how a set of similar game and risk analysis models at different levels of complexity can provide valuable insights to decision makers, both in national security and management situations, and help them avoid mistakes such as excessive focus on the short term and underestimation of dependencies. It compares their capabilities, including the number of moves, dynamics of the underlying situation, possible changes of context, actors' preferences and strategic options, and risk characterization.;This paper presents and compares four models of games and risk analyses designed to support strategic and policy decisions, three focusing on national security issues and one on project management. They share a common core of probability, linked decisions among the parties involved, and risks to a principal decision maker. Their structure is based on systems and decision analysis. Their level of complexity depends on the strategies, the environment, and assumptions of variation over time of probabilities, preferences, and options. They are part of the field of analytics and some of its real-life applications. This paper shows how a set of similar game and risk analysis models at different levels of complexity can provide valuable insights to decision makers, both in national security and management situations, and help them avoid mistakes such as excessive focus on the short term and underestimation of dependencies. It compares their capabilities, including the number of moves, dynamics of the underlying situation, possible changes of context, actors' preferences and strategic options, and risk characterization.;},
	language = {English},
	number = {2},
	journal = {Decision analysis},
	author = {Pate-Cornell, Elisabeth M.},
	year = {2012},
	note = {Place: Linthicum
Publisher: INFORMS},
	keywords = {Behavior, Comparative analysis, Counterterrorism, Decision analysis, Decision-making, Dynamic programming, Game theory, Military aspects, National security, Nuclear weapons, Probability, Project management, Rationality, Risk assessment, Shadow prices, Studies, Terrorism, analytics, failure probability, game analysis, nuclear proliferation, practice, principal-agent model, risk analysis},
	pages = {186--203},
}

@techreport{gale_seismic_1989,
	title = {Seismic analysis of the {EBR}-{II} ({Experimental} {Breeder} {Reactor}-{II}) containment structure},
	url = {https://www.osti.gov/biblio/5711018},
	abstract = {The Experimental Breeder Reactor-II (EBR-II) is a liquid metal reactor located at the Argonne National Laboratory near Idaho Falls, Idaho. At the time the EBR-II was designed and constructed, there were no engineering society or federal guidelines specifically directed toward the seismic design of reactor containment structures; hence static analysis techniques were used in the design. With the increased focus on safety of reactor and fuel reprocessing facilities. Argonne has initiated a program of analyzing its existing facilities for seismic integrity using current Department of Energy Guidelines and industry concensus standards. A seismic analysis of the EBR-II containment building has been performed using finite element analysis techniques. The containment building is essentially a vertical right cylindrical steel shell with heads on both ends. The structure is unique in that the interior of the shell is lined with reinforced concrete. The actual containment function of the building is served by the steel shell; whereas the function of the concrete liner is to serve as a missile shield and a thermal insulating shield to protect the steel containment shell from internally generated missiles and fires. Model development and structural evaluation of the EBR-II containment building are discussed in this paper. 6 refs., 8 figs.},
	language = {English},
	number = {CONF-890741-2},
	urldate = {2025-02-15},
	institution = {Argonne National Lab., Idaho Falls, ID (USA)},
	author = {Gale, J. G. and Lehto, W. K.},
	month = jan,
	year = {1989},
}

@article{noauthor_origin_nodate,
	title = {Origin of fission-product releases in {EBR}-{II}, {November} 23, 1967--{May} 6, 1968},
	url = {https://inis.iaea.org/records/b0v52-xwe03},
	abstract = {no abstract available},
	language = {en},
	urldate = {2025-02-15},
}

@techreport{noauthor_report_1968,
	title = {{REPORT} {ON} {THE} {FUEL} {MELTING} {INCIDENT} {IN} {THE} {ENRICO} {FERMI} {ATOMIC} {POWER} {PLANT} {ON} {OCTOBER} 5, 1966.},
	url = {https://www.osti.gov/biblio/4766757},
	abstract = {{\textbar} OSTI.GOV},
	language = {English},
	number = {APDA-233},
	urldate = {2025-02-15},
	institution = {Atomic Power Development Associates, Inc., Detroit, Mich. (US)},
	month = jan,
	year = {1968},
	doi = {10.2172/4766757},
}

@article{noauthor_regulatory_2018,
	title = {Regulatory {Guide} 1.232, {Guidance} for {Developing} {Principal} {Design} {Criteria} for {Non}-{Light}-{Water} {Reactors}.},
	volume = {2},
	language = {en},
	year = {2018},
}

@misc{noauthor_1971_1971,
	title = {1971 {Accidents} {Agreement}},
	year = {1971},
}

@article{frankel_aborting_1990,
	title = {Aborting unauthorized launches of nuclear‐armed ballistic missiles through postlaunch destruction},
	volume = {2},
	issn = {0892-9882, 1547-7800},
	url = {http://www.tandfonline.com/doi/abs/10.1080/08929889008426344},
	doi = {10.1080/08929889008426344},
	language = {en},
	number = {1},
	urldate = {2025-02-13},
	journal = {Science \& Global Security},
	author = {Frankel, Sherman},
	month = nov,
	year = {1990},
	pages = {1--20},
}

@misc{noauthor_p68jpg_nodate,
	title = {P68.jpg (1990×2870)},
	url = {https://www.icrp.org/coverimages/P68.jpg},
	urldate = {2025-02-13},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC}: {Package} {ML23268A454} -{X} {Energy}, {LLC} ({X}-energy) {Submittal} of {Xe}-100 {Licensing} {Topical} {Report}: {Atmospheric} {Dispersion} and {Dose} {Calculation} {Methodology}, {Revision} 2},
	url = {https://www.nrc.gov/docs/ML2326/ML23268A454.html},
	urldate = {2025-02-13},
}

@misc{noauthor_nrc_nodate-1,
	title = {{NRC}: {ML24088A065} - {TerraPower}, {LLC}, {Preliminary} {Safety} {Analysis} {Report}},
	url = {https://www.nrc.gov/docs/ML2408/ML24088A065.html},
	urldate = {2025-02-13},
}

@techreport{parry_ecar-5139_2020,
	type = {{INL}/{EXT}-21-61251-{Revision}-0},
	title = {{ECAR}-5139 {MARVEL} {Radiological} {Source} {Term}},
	url = {https://inldigitallibrary.inl.gov/sites/sti/sti/Sort_89456.pdf},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Parry, James P},
	month = aug,
	year = {2020},
}

@inproceedings{alpay_one_2023,
	address = {Cambridge United Kingdom},
	title = {One {Pass} to {Bind} {Them}: {The} {First} {Single}-{Pass} {SYCL} {Compiler} with {Unified} {Code} {Representation} {Across} {Backends}},
	isbn = {9798400707452},
	shorttitle = {One {Pass} to {Bind} {Them}},
	url = {https://dl.acm.org/doi/10.1145/3585341.3585351},
	doi = {10.1145/3585341.3585351},
	language = {en},
	urldate = {2025-02-12},
	booktitle = {International {Workshop} on {OpenCL}},
	publisher = {ACM},
	author = {Alpay, Aksel and Heuveline, Vincent},
	month = apr,
	year = {2023},
	pages = {1--12},
}

@article{rauzy_exact_1997,
	title = {Exact and truncated computations of prime implicants of coherent and non-coherent fault trees within {Aralia}},
	volume = {58},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832097000343},
	doi = {10.1016/S0951-8320(97)00034-3},
	language = {en},
	number = {2},
	urldate = {2025-02-12},
	journal = {Reliability Engineering \& System Safety},
	author = {Rauzy, Antoine and Dutuit, Yves},
	month = nov,
	year = {1997},
	pages = {127--144},
}

@misc{noauthor_lpmpbdd_2024,
	title = {{LPMP}/{BDD}},
	copyright = {GPL-3.0},
	url = {https://github.com/LPMP/BDD},
	abstract = {An integer linear program solver using a Lagrange decomposition into binary decision diagrams. Lagrange multipliers are updated through dual block coordinate ascent.},
	urldate = {2025-02-12},
	publisher = {LPMP},
	month = nov,
	year = {2024},
	note = {original-date: 2020-10-07T06:55:11Z},
	keywords = {gpu, ilp-solver, optimization},
}

@misc{noauthor_github_nodate,
	title = {{GitHub} - {Tractables}/{Dice}.jl at hybit},
	url = {https://github.com/Tractables/Dice.jl},
	abstract = {Contribute to Tractables/Dice.jl development by creating an account on GitHub.},
	language = {en},
	urldate = {2025-02-12},
	journal = {GitHub},
}

@misc{noauthor_fptalks_nodate,
	title = {{FPTalks} 2024 - {YouTube}},
	url = {https://www.youtube.com/watch},
	urldate = {2025-02-12},
}

@misc{silva_quantum_2024,
	title = {Quantum {Fault} {Trees} and {Minimal} {Cut} {Sets} {Identification}},
	url = {http://arxiv.org/abs/2404.05853},
	doi = {10.48550/arXiv.2404.05853},
	abstract = {Fault Trees represent an essential tool in the reliability and risk assessment of engineering systems. By decomposing the structure of the system into Boolean function, Fault Trees allow the quantitative and qualitative analysis of the system. One of the main important tasks in Fault Tree analysis is the identification of Minimal Cut Sets, defined as groups of components that present the least path of resistance toward a system's failure. Identifying them allows reliability engineers to enhance the reliability and safety of the system, making system failures less likely to occur. However, the minimal cut set identification problem is challenging to solve, due to the exponential growth experienced in the number of feasible configurations as the system's size grows linearly. Over the last few years, quantum computation has been heralded as a promising tool to tackle computational challenges of increased complexity. The reason for this is the promising prospects that the use of quantum effects has for challenging computational tasks. However, its application into Probabilistic Risk Assessment and reliability engineering, and in particular to challenges related to the Fault Tree model, is still uncharted territory. To fill this gap, the objective of the paper is to integrate quantum computation into the Fault Tree Model and present an assessment of their capabilities for the minimal cut set identification problem. To this end, this paper proposes a novel algorithm to encode a fault tree into a quantum computer and to perform the identification of minimal cut sets with increased efficiency via the application of the Quantum Amplitude Amplification protocol. For validation purposes, a series of theoretical and numerical results, the latter obtained using a quantum simulator, are presented in which the proposed algorithm is compared against traditional approaches, such as Monte Carlo sampling.},
	urldate = {2025-02-12},
	publisher = {arXiv},
	author = {Silva, Gabriel San Martín and Droguett, Enrique López},
	month = apr,
	year = {2024},
	note = {arXiv:2404.05853 [stat]},
	keywords = {Statistics - Computation},
}

@inproceedings{volk_safest_2024,
	address = {Albuquerque, NM, USA},
	title = {{SAFEST}: {Fault} {Tree} {Analysis} {Via} {Probabilistic} {Model} {Checking}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350307696},
	shorttitle = {{SAFEST}},
	url = {https://ieeexplore.ieee.org/document/10457719/},
	doi = {10.1109/RAMS51492.2024.10457719},
	urldate = {2025-02-12},
	booktitle = {2024 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	publisher = {IEEE},
	author = {Volk, Matthias and Sher, Falak and Katoen, Joost-Pieter and Stoelinga, Mariëlle},
	month = jan,
	year = {2024},
	pages = {1--7},
}

@inproceedings{zhao_solving_2024,
	address = {Albuquerque, NM, USA},
	title = {Solving {Large} {Fault} {Trees} with {Importance} {Sampling} and {Tree} {Search}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350307696},
	url = {https://ieeexplore.ieee.org/document/10457836/},
	doi = {10.1109/RAMS51492.2024.10457836},
	urldate = {2025-02-12},
	booktitle = {2024 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	publisher = {IEEE},
	author = {Zhao, Yunfei and O'Leary, Joseph},
	month = jan,
	year = {2024},
	pages = {1--6},
}

@incollection{ceccarelli_coyan_2024,
	address = {Cham},
	title = {Coyan: {Fault} {Tree} {Analysis} – {Exact} and {Scalable}},
	volume = {14988},
	isbn = {978-3-031-68605-4 978-3-031-68606-1},
	shorttitle = {Coyan},
	url = {https://link.springer.com/10.1007/978-3-031-68606-1_15},
	language = {en},
	urldate = {2025-02-12},
	booktitle = {Computer {Safety}, {Reliability}, and {Security}},
	publisher = {Springer Nature Switzerland},
	author = {Garagiola, Nazareno and Hermanns, Holger and D’Argenio, Pedro R.},
	editor = {Ceccarelli, Andrea and Trapp, Mario and Bondavalli, Andrea and Bitsch, Friedemann},
	year = {2024},
	doi = {10.1007/978-3-031-68606-1_15},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {235--250},
}

@misc{garagiola_nazagaracoyan_2024,
	title = {{NazaGara}/{Coyan}},
	copyright = {MIT},
	url = {https://github.com/NazaGara/Coyan},
	abstract = {Coyan is a tool that processes Static Fault Trees to compute the Top Event Probabilty.},
	urldate = {2025-02-12},
	author = {Garagiola, Nazareno},
	month = dec,
	year = {2024},
	note = {original-date: 2024-05-13T09:05:58Z},
	keywords = {fault-trees, unreliability},
}

@article{buddemeier_reducing_2010,
	title = {Reducing the {Consequences} of a {Nuclear} {Detonation}; {Recent} {Research} and {Guidance}},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfVxNS8NAEB20vXiRFhW1tQzeY9tstrH0JNWqFwOSe9nMTkAQI_n4_50xEaqHHva07Ofs7ryZfTwAE97Ngn9vgueIlsRZbPOZJYHYJrTOSolVL8Rnf3M7rWpO1bEsCznrPxRLTVPKYqrpd1N-TuehipOZY-hLELCQO9lP0iR9ladVG-w5ic0ATjt0hw-tOYZwxF9nkLyrPKq4CBSwhes9-jIWOTp8U0lhV-Ij10Wbm1uhoDnxBvjLi0OJ9_G5-fBqo3O43Tyl65dAZ7AVF6Y6rKSEFaq33XzNBfQksOdLQAFfLNGpCzO2EfvY8YLuDXuBCDlZiq5gdKCj64O1Izhp_7mjYG7G0KvLhm9kZKqaSbdTO_fAeyg},
	language = {English},
	number = {Journal Article},
	journal = {Reducing the Consequences of a Nuclear Detonation; Recent Research and Guidance, na, no. 2, June 21, 2010, pp. 28-38},
	author = {Buddemeier, B. R. and Lawrence Livermore National Lab. (LLNL), CA (United States), Livermore},
	year = {2010},
	note = {Place: United States},
	keywords = {AND NATIONAL DEFENSE, MILITARY TECHNOLOGY, WEAPONRY},
}

@article{carley_deterring_2018,
	title = {Deterring the development and use of nuclear weapons: a multi-level modeling approach},
	volume = {15},
	issn = {1548-5129},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3dS-QwEA-6vvgifpzonUqeBJGe2yZrWsEH8evg1Cc97m1JmwkIWqXuIv5B_p9Okum2VgVFWMpuSNtt5teZyXwyJpLf_ajDE1AqFpm2wrpKgf3EFIgrKwDljYJEKtOx7TzXqTHvBrXvfJvSOIa0dpmzX6D25KI4gN-R5nhEquPxU3Q_cvEtVZ0EZZqYIO8mGAfTfemqGOtq-xG0i5ANGc8-tjC6cWeEBjk-f5Fqjn-gxBqwuA-G1nxnh7--paZgjYejItt4Hb3RWGHPfWMpss_7tLJWR2VdUh43hfeTF4vMFHE6CXhr-8fetUS6TVPk9I4gkmhsgLwv7f9_xagHLUDKFteVoRcOCXAZWi6-lQ3eO-3u5m6Gv1BQh5Y-nYrbNHn4Zqqrxn5rrovRPpTR-GGazSQK9akemzk4_Xv2r9YAcMvta7VOHqxxj-90r_lKHWrFEnr15nKezRFJ-UEA1AKbgnKRrZz7Gu7VE9_kFxpRykkULLGrCc444oy3cMYRAhxxxu8sJ5xxwtke17yFMl6jhtco-8GuTo4vD_9E1KIjKhIhR1Gc59akYAuhZJbu5kbh6525qop5gpJLCKmUhcSAjgXYpIhzmxq7qyGVuG8wViyzXnlXwgrjFlVtq0FkUmv85LnSuBW3OWQK-oM0XmVb9UoN70MllmFMxeq7q7rKNt1SDum9fPhw4s_PTvzFZhtUr7HeqBrDOv53ZEkbRP4XH8CGLg},
	doi = {10.1177/1548512917706768},
	abstract = {We describe a multi-country, multi-stakeholder model for the accrual and use of nuclear weapons and illustrate the model’s value for addressing nuclear weapon proliferation issues using a historic Pacific Rim scenario. We instantiate the agent-based dynamic network model for information and belief diffusion using data from subject matter experts and data mined from open source news documents. We present the techniques that supported model instantiation. A key feature of this model and these techniques is enabling rapid model re-use through the ability to instantiate at two levels: generically and for specific cases. We demonstrate these generic and specific cases using a scenario regarding North Korea’s interest in nuclear weapons and the resulting impact on the Pacific Rim circa 2014, that is, prior to the fourth and fifth nuclear weapons tests by the Democratic People’s Republic of Korea. A key feature of this model is that it uses two levels of network interaction, the country level and the stakeholder level, thus supporting the inclusion of non-state actors and the assessment of complex scenarios. Using this model, we conducted virtual experiments in which we assessed the impact of alternative courses of action on the overall force posture and desire to develop and use nuclear weapons.},
	language = {English},
	number = {4},
	journal = {Journal of defense modeling and simulation},
	author = {Carley, Kathleen M. and Morgan, Geoffrey P. and Lanham, Michael J.},
	year = {2018},
	note = {Place: London, England
Publisher: SAGE Publications},
	pages = {483--493},
}

@article{banks_adversarial_2022,
	title = {Adversarial risk analysis: {An} overview},
	volume = {14},
	issn = {1939-5108},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1fT9swELegvMDDBAy0boCiPUyTppTUdhwXiYcK6OBhLxuDx8hJHFQhUkTo-Ex8S-78J6EtSEy8RJVrOfLd5e58vvsdIYz2onBOJ2jGBVNSgfHIaMZL0BBSiFwnJRZCRvlcbOfRl8a8mNS-_25OwxjwGitn_4PbzaIwAL-B5_AErsPzTXw3HZZrZZpxmLxx5WBHXAgQUzab6wDnlVrVgMgRdzNVug6qtPfD9n7wcUMsQrL4zm0ctLqu51Lkp4c_sU_LlYnFXpgL-ePcYhvb8LP6p8e2yub3ZNxc_NiJkxrTGKZqdk0XnaB0LjrxQvrPQo4nuJCDEFSDVcO6HcPylRlFzRcE0prsxqAt2AOLL_sABOmBao9ao-cv-ptJ8avTjLG_PDv6Y_5CRPabYpzfH-oqnNbLZIUm4FN1yMpwNMJIkfUCEAdP2IwGuzmPahXR_eY9s75Qe8B5fkwyfs75OvngDijB0ErWBlnS1SZZ-9Wg-9YfybdnMhagjAVexg6CYRV4Cdsif0cn50enoeu3EeYMC-lVVHItWBFnXEialZQlTCUDLVmZUCZ0LMtSc8QvygodDwpwRosy5uAD50rKvM-2SaeaVPoTCWhf6ayQgutY8QRc-JzqWGRqgHD-qp90yVe_8_TWwqqkFkCbpkieFMnTJTueJqn7wuqUCgqHfCoj2SXfDZ1eXyD1XPv89qlfyGorxzukc3831buwL9A9e47Hewgme_kEE3mCCA},
	doi = {10.1002/wics.1530},
	abstract = {Adversarial risk analysis (ARA) is a relatively new area of research that informs decision‐making when facing intelligent opponents and uncertain outcomes. It is a decision‐theoretic alternative to game theory. ARA enables an analyst to express her Bayesian beliefs about an opponent's utilities, capabilities, probabilities, and the type of strategic calculations that the opponent is using to make his decision. Within that framework, the analyst then solves the problem from the perspective of the opponent. This calculation produces a distribution over the actions of the opponent that permits the analyst to maximize her expected utility. This review covers conceptual, modeling, computational, and applied issues in ARA as well as interesting open research issues.This article is categorized under:Statistical and Graphical Methods of Data Analysis {\textgreater} Bayesian Methods and TheoryApplications of Computational Statistics {\textgreater} Defense and National Security;Adversarial risk analysis (ARA) is a relatively new area of research that informs decision‐making when facing intelligent opponents and uncertain outcomes. It is a decision‐theoretic alternative to game theory. ARA enables an analyst to express her Bayesian beliefs about an opponent's utilities, capabilities, probabilities, and the type of strategic calculations that the opponent is using to make his decision. Within that framework, the analyst then solves the problem from the perspective of the opponent. This calculation produces a distribution over the actions of the opponent that permits the analyst to maximize her expected utility. This review covers conceptual, modeling, computational, and applied issues in ARA as well as interesting open research issues.

This article is categorized under:

Statistical and Graphical Methods of Data Analysis {\textgreater} Bayesian Methods and Theory

Applications of Computational Statistics {\textgreater} Defense and National Security

A multi‐agent influence diagram for a simple adversarial game;Adversarial risk analysis (ARA) is a relatively new area of research that informs decision‐making when facing intelligent opponents and uncertain outcomes. It is a decision‐theoretic alternative to game theory. ARA enables an analyst to express her Bayesian beliefs about an opponent's utilities, capabilities, probabilities, and the type of strategic calculations that the opponent is using to make his decision. Within that framework, the analyst then solves the problem from the perspective of the opponent. This calculation produces a distribution over the actions of the opponent that permits the analyst to maximize her expected utility. This review covers conceptual, modeling, computational, and applied issues in ARA as well as interesting open research issues.

This article is categorized under:

Statistical and Graphical Methods of Data Analysis {\textgreater} Bayesian Methods and Theory

Applications of Computational Statistics {\textgreater} Defense and National Security;},
	language = {English},
	number = {1},
	journal = {Wiley interdisciplinary reviews. Computational statistics},
	author = {Banks, David and Gallego, Víctor and Naveiro, Roi and Ríos Insua, David},
	year = {2022},
	note = {Place: Hoboken, USA
Publisher: John Wiley \& Sons, Inc},
	keywords = {Bayes Nash equilibrium, Bayesian analysis, Computer applications, Data analysis, Decision analysis, Decision making, Decision theory, Defense programs, Expected utility, Game theory, Graphical methods, Probability theory, Risk analysis, Risk assessment, Security, Statistical analysis, Statistical methods, auctions, level‐k thinking},
	pages = {e1530--n/a},
}

@article{rios_insua_adversarial_2009,
	title = {Adversarial {Risk} {Analysis}},
	volume = {104},
	issn = {0162-1459},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwnV3PS8MwFA4yL7v4e1intTdPdUuaNM1RZENEFGQePJU0TUCFTuwG_vm-pOlmHV52bZvQ5L28973k5XsIJeR6HP-xCYBDjSaG8URiZpgRRaJ0pjNJJBWe-3m9t9MkWdY-y9KG1KbhjXCm2651WfiCJCIbvctaeuJJcI5gjSFGsMlds-nD2iZzV4ES8A2JMWXC0zduNu-4pw55aZuwaLMnZQ0TaJrKFxtG3Hmm6X6TQVI7QsP5t72z1MnMHzk2REeB0TI_bjfgA7TnsWt00yjbIdrR1RHqW7jasD0fo8DVd66l1ero-a3-iFrSkxP0Mp3Mbu9iX3whVjQli5inZiyxklKmHAuqSaI4MaXUXChWisJweECpUUalOFUQ6soM0CTmheSaYZMMUK-aV_oURapUSWIZcBmFvpUpBFWFwrQ02jKRjgN01c55_tlwbOQuNhFZbsdqS2WK3I41QOS3SPKF29XwgsiT_xoNnOBWfQNGFfYKcIDCjiRXH1gYxMBzB2jYijb3S7vOIYzPAGMzaH65egtr0h60yErPl_AjEIQyiMPOtvndIeo3J1Z2p-cc9RZfS30Bcwl6Ezr-5xDt3k8en15Dp-I_q_IBvQ},
	doi = {10.1198/jasa.2009.0155},
	abstract = {Applications in counterterrorism and corporate competition have led to the development of new methods for the analysis of decision making when there are intelligent opponents and uncertain outcomes. This field represents a combination of statistical risk analysis and game theory, and is sometimes called adversarial risk analysis. In this article, we describe several formulations of adversarial risk problems, and provide a framework that extends traditional risk analysis tools, such as influence diagrams and probabilistic reasoning, to adversarial problems. We also discuss the research challenges that arise when dealing with these models, illustrate the ideas with examples from business, and point out relevance to national defense.;Applications in counterterrorism and corporate competition have led to the development of new methods for the analysis of decision making when there are intelligent opponents and uncertain outcomes. This field represents a combination of statistical risk analysis and game theory, and is sometimes called adversarial risk analysis. In this article, we describe several formulations of adversarial risk problems, and provide a framework that extends traditional risk analysis tools, such as influence diagrams and probabilistic reasoning, to adversarial problems. We also discuss the research challenges that arise when dealing with these models, illustrate the ideas with examples from business, and point out relevance to national defense. [PUBLICATION ABSTRACT];},
	language = {English},
	number = {486},
	journal = {Journal of the American Statistical Association},
	author = {Rios Insua, David and Rios, Jesus and Banks, David},
	year = {2009},
	note = {Place: Alexandria, VA
Publisher: Taylor \& Francis},
	keywords = {Applications, Auctions, Bidding, Competition, Corporate governance, Decision making, Decision theory, Decision trees, Exact sciences and technology, Expected utility, Game theory, General topics, Influence diagrams, Mathematics, Nash equilibrium, Probability and statistics, Review, Risk analysis, Risk assessment, Risk management, Sciences and techniques of general use, Statistical methods, Statistics, Terrorism, Utilities costs, Utility functions},
	pages = {841--854},
}

@article{lundgren_what_2013,
	title = {{WHAT} {ARE} {THE} {ODDS}? {ASSESSING} {THE} {PROBABILITY} {OF} {A} {NUCLEAR} {WAR}},
	volume = {20},
	issn = {1073-6700},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3db9MwELfoeEFIaIyPsQEyD_BSZXPstE4fEEq7lk2KWlRSDZ6qOD4jJEinbtX-fe7itKTbHoZ4saKTdbH8O5_v7LszY0oeieCGTjDaqJBueAqZxxG42FkVQ6iF7VnrVHHjbOfxOjXmzqD24_9GGmmINWXO_gPaG6ZIwG_EHFtEHdt74X5-mmTtZDqsYnkmJydf36sRFW-kKRp_rqhfppN-0j9Lz7LvFPSTtMezQTpMpu3zZNo0VkmExovygh72cVCLynLrMiFdlfbH0quuQb781TxEoAcd9PoQwes9XOkBZew0FaMUDQGQDS2nfP30esNU_pmdW7rYBy8SZ2JMUXTqSKN3VyeDb5W-Hk_mo1mazrPht-wDFT3_bX8WVx-hDFaXLdbSmpSXnvU3vjRy7fhwUj_udVZkLI7v-uOtnbYyH7Jd9qS2-3niAXvKHkC5x15uncfyTWDiHmul-fUzVoHJEUyOsHEC8xPfQFnRGlDyyYgnvIaSI5TP2Ww0zAanQf3eRVBIEV0FxoEWYAopbY_s1CKUEFHFQACHHdAX77gw7NnIGWtyEDF0QxvpjlVIDrtGvmA75aKEfcZF3oXcGaF6Bl1ArWK05JBHDFV5_8K9Yu_W8zFHfUKXRHkJi9XlHE1q6QMSDu7R55A9-itOr9lDh6sI3uAwcKm-rRD7A89NMC4},
	doi = {10.1080/10736700.2013.799828},
	abstract = {Nuclear optimists and pessimists disagree on whether the odds of nuclear war are low or high. This viewpoint assesses the odds of nuclear war over the past sixty-six years, exploring three pathways to nuclear war: an international crisis leading directly to nuclear war, an accident or misperception leading to nuclear escalation or nuclear retaliation against an imaginary attack, and a general conventional war leading to nuclear war. The assessment is based on the application of Bayes's theorem and other statistical reasoning and finds that the expected probability of nuclear war during this historical period was greater than 50 percent. This level of risk is unacceptably high. It is therefore urgent that effective measures be taken to substantially reduce the risk of nuclear war. Adapted from the source document.},
	language = {English},
	number = {2},
	journal = {The Nonproliferation review},
	author = {Lundgren, Carl},
	year = {2013},
	keywords = {Escalation, Generals, Nuclear War, Probability, Risk},
	pages = {361--374},
}

@article{talmadge_would_2017,
	title = {Would {China} {Go} {Nuclear}?: {Assessing} the {Risk} of {Chinese} {Nuclear} {Escalation} in a {Conventional} {War} with the {United} {States}},
	volume = {41},
	issn = {0162-2889},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwlV1Rb9MwED7R8cILjMGgbFRGiMesjuPECS8IVR0gIRB00x4tO3a0gGinpQxpv37nS9MlIIR4SR5ysZzc2ffd5csdQCKOePTbnmBS3BOEcYVyoeeRd-iWTZlWlqN79twMczvwsvs1JuQhjr6dt-Hi5l1Os1QVcT6CuyKs90DXO11sd98sp5ZuiGTCb8d50ZHdMzH9sJjPtNEUiQ3cUMtERO_yo14PcyB_7NDkdo4fwOduhsQ2CT0O-rT7KZU6pPoWXVnHfzzNLtzfIFD2tr3wEO745R48GWQG2ZYitwejj-bXI7g6C62wGXXbZu9W7FMog2wu37xm7VdjnBpDKMm-1s13tqpI0De-k2PzBm2BhmT1khk265Hd2RkKhHwwjdCCYNaC4Mdwejw_mb2PNi0bolIKvo6MQQDoSmstV95RNBdLlRTcxXluU8WV5S4VNvalU7kRgdtqRJarxElTySrZh53laumfAvOxJTQVF9ZJtBjrkgSxZmqVKCvEGWN41WlQX7SVOTRFNJnQfU2PYZ_UuxUSmVIKcfIYXqC-9WbNNn-5uRjI1I0vr2RcS42TkVzq0H1eh7PU1_UFXb-9N-pZ0u0YrcL1An0NxqJcYkxIH4DHcNjZWm9SiNdCiTpePPvP4Q7gnggQhFhGh7Czvvzpn-PbRROdwEidfMEjLvUJlUSe0CK6Aa-6Fkk},
	doi = {10.1162/ISEC_a_00274},
	abstract = {Could a conventional war with the United States inadvertently prompt Chinese nuclear escalation? The military-technical threat that such a war would pose to China’s retaliatory capability—combined with wartime perceptual dynamics that might cause China to view this threat in an especially pessimistic light—could lead to reasonable Chinese fears that the United States might be attempting conventional counterforce, or considering or preparing for nuclear counterforce. China might see several forms of limited nuclear escalation as its least-bad response to this sort of threat to its nuclear deterrent, notwithstanding the country’s no-first-use policy. This finding, derived from a more general framework about the military-technical and perceptual drivers of potential nuclear escalation in response to conventional counterforce, has broader ramifications for U.S. policy and military strategy, and it illustrates recurring dilemmas that the United States may face in conventional wars with other nuclear-armed adversaries.},
	language = {English},
	number = {4},
	journal = {International security},
	author = {Talmadge, Caitlin},
	year = {2017},
	note = {Place: One Rogers Street, Cambridge, MA 02142-1209, USA
Publisher: MIT Press},
	keywords = {Escalation, Military policy, Military strategy, Nuclear weapons, Risk assessment, Risk factors, War},
	pages = {50--92},
}

@article{scouras_nuclear_2019,
	title = {Nuclear {War} as a {Global} {Catastrophic} {Risk}},
	volume = {10},
	issn = {2194-5888},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV07T8MwED7xkBALb8RbGVgYAnGcRz0gVCpKkcpDpYjHEjl-CITUlrYs_HrunAQoAxNDzkOsKDn7zr7L-fsAeHgY-L98QioUj43SOS5_AZc65YqQoxKDcZAJQj2Z24Gr6mgMVVlWLtL5bd1XlDI_ItQWwq6qiZPBm08kUvSztWLUkCXTgj5mYRrG0zBLwGVoALP1buPm9isJExCalSNORsON_BjDwfIMH8FK54qAiZg4JDL0n6vWpNN2K1FzET6ql3YFKER78LMS_8ihHzrIiwrp8f8-cAkWyv2rVy8m3DJMmd4KzFXl86twcEUAyXLo3eMlR570ClYBryHHcjQe9gfPL8rrvIxe1-CuedZttPySjsFXaPhjnxklNcvzJMhlTUSx5bVESJ1YDNFSq41hxGYWWKtxExEZbhKphJaKSWWEyC1fh5lev2c2wEtjG4k8MbllMrIYNDHNUduhNJqHIrGbsF-pOxsUqBtZUY6WZtgvo1HJWLIJO5XustL0Rtm34rb-vr0N8_ScIp-yAzPj4bvZxVfEAduD6fT-keTD6R5Omlbn_ILa9m3btTSJsG01LppP2Osy6JIM205eO9n5BJu83D4},
	doi = {10.1017/bca.2019.16},
	abstract = {Nuclear war is clearly a global catastrophic risk, but it is not an existential risk as is sometimes carelessly claimed. Unfortunately, the consequence and likelihood components of the risk of nuclear war are both highly uncertain. In particular, for nuclear wars that include targeting of multiple cities, nuclear winter may result in more fatalities across the globe than the better-understood effects of blast, prompt radiation, and fallout. Electromagnetic pulse effects, which could range from minor electrical disturbances to the complete collapse of the electric grid, are similarly highly uncertain. Nuclear war likelihood assessments are largely based on intuition, and they span the spectrum from zero to certainty. Notwithstanding these profound uncertainties, we must manage the risk of nuclear war with the knowledge we have. Benefit-cost analysis and other structured analytic methods applied to evaluate risk mitigation measures must acknowledge that we often do not even know whether many proposed approaches (e.g., reducing nuclear arsenals) will have a net positive or negative effect. Multidisciplinary studies are needed to better understand the consequences and likelihood of nuclear war and the complex relationship between these two components of risk, and to predict both the direction and magnitude of risk mitigation approaches.},
	language = {English},
	number = {2},
	journal = {Journal of benefit-cost analysis},
	author = {Scouras, James},
	year = {2019},
	note = {Place: Berlin
Publisher: Cambridge University Press},
	keywords = {Bombings, Catastrophes, Collapse, Cost analysis, Cost benefit analysis, Earth, Electromagnetic radiation, Extinction, Fallout, Multidisciplinary research, National security, Nitrogen, Nuclear war, Nuclear weapons, Nuclear winter, Radiation, Risk management, Risk reduction, War},
	pages = {274--295},
}

@inproceedings{mohmand_sodium_2021,
	title = {Sodium {Filter} {Performance} in the {NaSCoRD} {Database}.},
	url = {https://www.osti.gov/servlets/purl/1899530/},
	doi = {10.2172/1899530},
	abstract = {Sodium-cooled Fast Reactors (SFRs) have an extensive operational history that can be leveraged to accelerate the licensing process for advanced reactor designs. Sandia National Laboratories has reconstituted the United States SFR data from the Centralized Reliability Data Organization (CREDO) into a new database called the Sodium System Component Reliability Database (NaSCoRD). The NaSCoRD database and others like it will help reduce parametric uncertainties encountered in probabilistic risk analysis (PRA) models for advanced non-light water reactor technologies. This paper is an extension of previous work done at Sandia National Laboratories which analyzed pump data. This paper investigates the failure rates of filters/strainers. NaSCoRD contains unique records of 147 filters/strainers that have operated in Experimental Breeder Reactor II, Fast Flux Test Facility, and test loops including those operated by both Westinghouse and the Energy Technology Engineering Center. This paper presents filter failure rates for various conditions allowable from the CREDO data that has been recovered under NaSCoRD. The current filter reliability estimates are presented in comparison to estimates provided in historical studies. The impacts of the suggested corrections from the Idaho National Laboratory report, Generic Component Failure Data Base for Light Water and Liquid Sodium Reactor PRAs, and various prior distributions on these reliability estimates are also presented. The paper also briefly describes the potential improvement of the NaSCoRD database.},
	language = {en},
	urldate = {2025-02-11},
	booktitle = {Proposed for presentation at the {PSA} 2021 held {November} 7-12, 2021 in {Columbus}, {Ohio} {United} {States}},
	publisher = {US DOE},
	author = {Mohmand, Jamal and Clark, Andrew},
	month = nov,
	year = {2021},
}

@techreport{eide_generic_1990,
	title = {Generic component failure data base for light water and liquid sodium reactor {PRAs} (probabilistic risk assessments)},
	url = {https://www.osti.gov/biblio/6958536},
	abstract = {A comprehensive generic component failure data base has been developed for light water and liquid sodium reactor probabilistic risk assessments (PRAs). The Nuclear Computerized Library for Assessing Reactor Reliability (NUCLARR) and the Centralized Reliability Data Organization (CREDO) data bases were used to generate component failure rates. Using this approach, most of the failure rates are based on actual plant data rather than existing estimates. 21 refs., 9 tabs.},
	language = {English},
	number = {EGG-SSRE-8875},
	urldate = {2025-02-11},
	institution = {EG and G Idaho, Inc., Idaho Falls, ID (United States)},
	author = {Eide, S. A. and Chmielewski, S. V. and Swantz, T. D.},
	month = feb,
	year = {1990},
	doi = {10.2172/6958536},
}

@misc{noauthor_industry-average_nodate,
	title = {Industry-{Average} {Performance} for {Components} and {Initiating} {Events} at {U}.{S}. {Commercial} {Nuclear} {Power} {P}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6928/index.html},
	abstract = {Industry-Average Performance for Components and Initiating Events at U.S. Commercial Nuclear Power P},
	language = {en-US},
	urldate = {2025-02-10},
	journal = {NRC Web},
}

@misc{noauthor_probabilistic_2021,
	address = {New York, N.Y},
	title = {Probabilistic {Risk} {Assessment} {Standard} for {Advanced} {Non}-{LWR} {Nuclear} {Power} {Plants}},
	publisher = {ASME},
	month = feb,
	year = {2021},
}

@techreport{mcdonald_helium_1986,
	title = {Helium {Circulator} {Design} {Considerations} for {Modular} {High} {Temperature} {Gas} {Cooled} {Reactor} {Plant}},
	url = {https://www.osti.gov/servlets/purl/6305323},
	language = {English},
	institution = {GA Technologies},
	author = {McDonald, C.F. and Nichols, M.K.},
	month = dec,
	year = {1986},
}

@book{miczo_digital_2003,
	address = {Hoboken, NJ},
	edition = {2nd ed},
	title = {Digital logic testing and simulation},
	isbn = {978-0-471-43995-0},
	language = {en},
	publisher = {Wiley-Interscience},
	author = {Miczo, Alexander},
	year = {2003},
	keywords = {Digital electronics, Testing},
}

@misc{noauthor_regulatory_2023,
	title = {{REGULATORY} {GUIDE} 1.183, {REVISION} 1, {ALTERNATIVE} {RADIOLOGICAL} {SOURCE} {TERMS} {FOR} {EVALUATING} {DESIGN} {BASIS} {ACCIDENTS} {AT} {NUCLEAR} {POWER} {REACTORS}},
	publisher = {US Nuclear Regulatory Commission},
	month = oct,
	year = {2023},
}

@techreport{noauthor_alternative_nodate,
	title = {{ALTERNATIVE} {RADIOLOGICAL} {SOURCE} {TERMS} {FOR} {EVALUATING} {DESIGN} {BASIS} {ACCIDENTS} {AT} {NUCLEAR} {POWER} {REACTORS}},
}

@misc{noauthor_alternative_nodate-1,
	title = {{ALTERNATIVE} {RADIOLOGICAL} {SOURCE} {TERMS} {FOR} {EVALUATING} {DESIGN} {BASIS} {ACCIDENTS} {AT} {NUCLEAR} {POWER} {REACTORS}},
}

@techreport{dinunno_calculation_1962,
	title = {{CALCULATION} {OF} {DISTANCE} {FACTORS} {FOR} {POWER} {AND} {TEST} {REACTOR} {SITES}},
	url = {http://www.osti.gov/servlets/purl/4827930-j5MEIa/},
	language = {en},
	number = {TID-14844, 4827930},
	urldate = {2025-02-04},
	author = {DiNunno, J.J. and Anderson, F.D. and Baker, R.E. and Waterfield, R.L.},
	month = jan,
	year = {1962},
	doi = {10.2172/4827930},
	pages = {TID--14844, 4827930},
}

@misc{noauthor_accident_nodate,
	title = {Accident {Source} {Terms} for {Light}-{Water} {Nuclear} {Power} {Plants} ({NUREG}-1465)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1465/index.html},
	abstract = {Accident Source Terms for Light-Water Nuclear Power Plants (NUREG-1465)},
	language = {en-US},
	urldate = {2025-02-04},
	journal = {NRC Web},
}

@techreport{dinunno_calculation_1962-1,
	title = {{CALCULATION} {OF} {DISTANCE} {FACTORS} {FOR} {POWER} {AND} {TEST} {REACTOR} {SITES}},
	url = {http://www.osti.gov/servlets/purl/4827930-j5MEIa/},
	language = {en},
	number = {TID-14844, 4827930},
	urldate = {2025-02-04},
	author = {DiNunno, J.J. and Anderson, F.D. and Baker, R.E. and Waterfield, R.L.},
	month = jan,
	year = {1962},
	doi = {10.2172/4827930},
	pages = {TID--14844, 4827930},
}

@techreport{dinunno_calculation_1962-2,
	title = {{CALCULATION} {OF} {DISTANCE} {FACTORS} {FOR} {POWER} {AND} {TEST} {REACTOR} {SITES}},
	url = {http://www.osti.gov/servlets/purl/4827930-j5MEIa/},
	language = {en},
	number = {TID-14844, 4827930},
	urldate = {2025-02-04},
	author = {DiNunno, J.J. and Anderson, F.D. and Baker, R.E. and Waterfield, R.L.},
	month = jan,
	year = {1962},
	doi = {10.2172/4827930},
	pages = {TID--14844, 4827930},
}

@techreport{grabaskas_regulatory_2016,
	title = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}: {Mechanistic} {Source} {Term} – {Trial} {Calculation}},
	shorttitle = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}},
	url = {http://www.osti.gov/servlets/purl/1334189/},
	language = {en},
	number = {ANL-ART--49-Vol1-Vol2, 1334189},
	urldate = {2025-02-04},
	author = {Grabaskas, David and Bucknor, Matthew and Jerden, James and Brunett, Acacia J. and Denman, Matthew and Clark, Andrew and Denning, Richard S. and {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)}},
	month = oct,
	year = {2016},
	doi = {10.2172/1334189},
	pages = {ANL--ART--49--Vol1--Vol2, 1334189},
}

@techreport{grabaskas_regulatory_2016-1,
	title = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}: {Mechanistic} {Source} {Term} – {Trial} {Calculation}},
	shorttitle = {Regulatory {Technology} {Development} {Plan} - {Sodium} {Fast} {Reactor}},
	url = {http://www.osti.gov/servlets/purl/1334189/},
	language = {en},
	number = {ANL-ART--49-Vol1-Vol2, 1334189},
	urldate = {2025-02-04},
	author = {Grabaskas, David and Bucknor, Matthew and Jerden, James and Brunett, Acacia J. and Denman, Matthew and Clark, Andrew and Denning, Richard S. and {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)}},
	month = oct,
	year = {2016},
	doi = {10.2172/1334189},
	pages = {ANL--ART--49--Vol1--Vol2, 1334189},
}

@misc{noauthor_towards_nodate,
	title = {Towards {Risk}-{Informed} {Performance}-{Based} {Emergency} {Planning}},
	url = {https://www.anl.gov/argonne-scientific-publications/pub/188366},
	language = {en},
	urldate = {2025-02-04},
	journal = {Argonne National Laboratory},
}

@techreport{humphreys_radtrad_1998,
	title = {{RADTRAD}: {A} simplified model for {RADionuclide} {Transport} and {Removal} {And} {Dose} estimation},
	shorttitle = {{RADTRAD}},
	url = {https://www.osti.gov/biblio/604405},
	abstract = {This report documents the RADTRAD computer code developed for the U.S. Nuclear Regulatory Commission (NRC) Office of Nuclear Reactor Regulation (NRR) to estimate transport and removal of radionuclides and dose at selected receptors. The document includes a users` guide to the code, a description of the technical basis for the code, the quality assurance and code acceptance testing documentation, and a programmers` guide. The RADTRAD code can be used to estimate the containment release using either the NRC TID-14844 or NUREG-1465 source terms and assumptions, or a user-specified table. In addition, the code can account for a reduction in the quantity of radioactive material due to containment sprays, natural deposition, filters, and other natural and engineered safety features. The RADTRAD code uses a combination of tables and/or numerical models of source term reduction phenomena to determine the time-dependent dose at user-specified locations for a given accident scenario. The code system also provides the inventory, decay chain, and dose conversion factor tables needed for the dose calculation. The RADTRAD code can be used to assess occupational radiation exposures, typically in the control room; to estimate site boundary doses; and to estimate dose attenuation due to modification of a facility or accident sequence.},
	language = {English},
	number = {NUREG/CR-6604; SAND-98-0272},
	urldate = {2025-02-04},
	institution = {ITSC, Albuqerque, NM (United States); Nuclear Regulatory Commission, Washington, DC (United States). Office of Nuclear Reactor Regulation; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Humphreys, S. L. and Miller, L. A. and Monroe, D. K. and Heames, T. J.},
	month = apr,
	year = {1998},
	doi = {10.2172/604405},
}

@inproceedings{strubelj_goal_2018,
	address = {Zadar, Croatia},
	title = {The {Goal} of the {New} {Approach} to {Reactor} {Safety} {Improvements} ({NARSIS}) {Project}},
	language = {en},
	author = {Strubelj, L and Foerster, E and Rastiello, G and Daniell, J and Bazargan-Sabet, Behrooz and Gehl, Pierre and Vardon, P J and Mohan, V K Duvvuru},
	year = {2018},
}

@article{noauthor_ebr-2_nodate,
	title = {{EBR}-2 [{Experimental} {Breeder} {Reactor}-2] containment seismic analysis},
	url = {https://inis.iaea.org/records/598h0-5s075},
	abstract = {The Experimental Breeder Reactor-2 (EBR-2) is a liquid metal reactor located at the Argonne National Laboratory near Idaho Falls, Idaho. At the time the EBR-2 was designed and constructed, there were no engineering society or federal guide lines specifically directed toward the seismic design of reactor containment structures; hence, static analysis techniques were used in the design. With the increased focus on safety of reactor and fuel reprocessing facilities, Argonne has initiated a program to analyze its existing facilities for seismic integrity using current Department of Energy guidelines and industry consensus standards. A seismic analysis of the EBR-2 containment building has been performed using finite-element analysis techniques. The containment building is essentially a vertical right cylindrical steel shell with heads on both ends. The structure is unique in that the interior of the steel shell is lined with reinforced concrete. The actual containment function of the building is served by the steel shell; whereas the function of the concrete liner is to serve as a missile shield and a thermal insulating shield to protect the steel containment shell from internally generated missiles and fires. Model development and structural evaluation of the EBR-2 containment building are discussed in this paper. 7 refs., 8 figs},
	language = {en},
	urldate = {2025-02-02},
}

@article{noauthor_ebr-2_nodate-1,
	title = {{EBR}-2 [{Experimental} {Breeder} {Reactor}-2] containment seismic analysis},
	url = {https://inis.iaea.org/records/598h0-5s075},
	abstract = {The Experimental Breeder Reactor-2 (EBR-2) is a liquid metal reactor located at the Argonne National Laboratory near Idaho Falls, Idaho. At the time the EBR-2 was designed and constructed, there were no engineering society or federal guide lines specifically directed toward the seismic design of reactor containment structures; hence, static analysis techniques were used in the design. With the increased focus on safety of reactor and fuel reprocessing facilities, Argonne has initiated a program to analyze its existing facilities for seismic integrity using current Department of Energy guidelines and industry consensus standards. A seismic analysis of the EBR-2 containment building has been performed using finite-element analysis techniques. The containment building is essentially a vertical right cylindrical steel shell with heads on both ends. The structure is unique in that the interior of the steel shell is lined with reinforced concrete. The actual containment function of the building is served by the steel shell; whereas the function of the concrete liner is to serve as a missile shield and a thermal insulating shield to protect the steel containment shell from internally generated missiles and fires. Model development and structural evaluation of the EBR-2 containment building are discussed in this paper. 7 refs., 8 figs},
	language = {en},
	urldate = {2025-02-02},
}

@article{intriligator_accidental_1988,
	title = {{ACCIDENTAL} {NUCLEAR} {WAR}: {A} {SIGNIFICANT} {ISSUE} {FOR} {ARMS} {CONTROL}},
	volume = {11},
	issn = {0356-7893},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Rb9MwELZoeeEFscFgMJCfeIlS6tqJHTQeoizbiqoMtakQT5XjuKMThKnr4O9zjp2kKyCBeIkiS0kcf-fz-Xz3HUJ0NBj6OzqhELDuGuqrkBEdRqWhDQs4AfNCjKTSase3EzSpMb8Nan_z30hDG2BtMmf_Ae32pdAA94A5XAF1uP4V7nGSjE_SLI8nXjZPJmk89T7GU5uAPhufZeNTU-Qx98az2Tz1YA_oxVPYzCcXWd4Uobm6S0jq-IA-m3OFa9Cg9sDhu8tXamWr2qxXXwxhh3UAuHh872TQ7fhXdc0mkLTLOp7bmww6pwOJhNhxOuQSbPq19j7UH21iBLv4hi0lRoPQ58JWQWw1LtmWrDYnxapQm1PqFmObi7zDiG043cCuHL027Ohfy5XavNOVf3vTQz1KWB_df59mF59aT5thwOGW8rXpTBN8-ssCXFsV-SP00G0HcGxx3EP3dLWPnt5x0-I2XnEf9Sbyx2N03GGMHcYYMH6LY7yFMK4RxoAwNghjh_ATND9N8-Tcd1Uw_CtCg41PhBZlqCM-jApRavgFIiPNKNUSTMOCylIzrpdggUgWRkwFajkMVBGYKaaZLOkB6lffKv0M4WIpaKgoL6kkrNBRocB6U4WWlNNgyNghOqiHZXFtmU4WzUgfoqNmnBZO1m8WYClybhgRyfM_PfcCPeik5wj1N-tb_RK6AxP5lYPpJ_50Qho},
	language = {English},
	number = {1/2},
	journal = {Current research on peace and violence},
	author = {Intriligator, Michael D. and Brito, Dagobert L.},
	year = {1988},
	note = {Place: Tampere, Finland
Publisher: Tampere Peace Research Institute},
	keywords = {Accidents, An Arms Control Perspective, Arms control, Missiles, Multilateralism, Nuclear warfare, Nuclear weapons, Radiation accidents, Randomness, Warning systems, Weapons},
	pages = {14--23},
}

@article{blair_accidental_1990,
	title = {Accidental {Nuclear} {War}},
	volume = {263},
	issn = {0036-8733},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwhV1LT8MwDLZgSAguY4OJ8ZjKDQ5laR5NepzQJsRhCAmEOFVpm55Qh_b4_zhJO8YA8QNcNbaT2PHnzwCM3pJw60woYyMTqXlBSKkVhqnUcJarTFAlqKBbbzseU7OoUZYOJuiK-hgvZe9miBlDIl1f1a4i1MP4vk5fGpM10a5kbB-ufGu58o0yDoGj62qIfYQJBft2J3lY4o-j2d03kzY8Nb_mYCZ2uMEm3n7oOA4dsUXD5_jvMo6g3ZBJByPvLh3YMVUXDjc4CbvQqXf7IriuKalvjqE3ynM7fRQj9WBqGZD1PHjV8xN4mYyf7-7DeqJCmFMulrglDLf87zQyGMdEBnMdmeuCxEmWMcxdIsaNLG1jR2JsLBUJpTHNxLSjzIuYcdaDVjWrzCkEJX4Bky1NigLNyvMMjYk2pVlpCoKK7wNtdJp-eOKM1BW8mUp_N0QqUKjn1LSWaHTUh6AxR4r-b4saujKz1SLF8MYWhyU5-0v2HA4ivHM9BuUCWsv5ylziOtBkA9h7GE8f3wbOhz4BncbG0Q},
	doi = {10.1038/scientificamerican1290-53},
	abstract = {Although tensions have eased between the US and the USSR, an accidental nuclear exchange remains a frightening possibility. To prevent this, both nations should place additional safeguards on nuclear arsenals.},
	language = {English},
	number = {6},
	journal = {Scientific American},
	author = {Blair, Bruce G. and Kendall, Henry W.},
	year = {1990},
	note = {Place: New York
Publisher: Scientific American, Incorporated},
	keywords = {Arms control and disarmament, Delegation of authority, Intercontinental ballistic missiles, International relations-US, Military bases, Missiles, Nuclear accidents \& safety, Nuclear tests, Nuclear war, Nuclear warfare, Nuclear weapons, Spacecraft launching, Superpowers, Warheads, Weapons},
	pages = {53--59},
}

@article{wallace_accidental_1986,
	title = {Accidental {Nuclear} {War}: {A} {Risk} {Assessment}},
	volume = {23},
	issn = {0022-3433},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV3JTsQwDLVYLlzYl7IMPYJQhzZp05YLGhAjQAgkFiFOVZukEkKzaBYh_oWPxW4n1QybOHHopU2b1I4d23GeATiru84nnaB1wDMZK85jn6mAKU-wSEmW-xFeSk3GdqBrjsaMCNqvU5YVDrDQ3STsFJw-HO050pFuxn10tgRZ1ISSdjwctJIy_G2qbNAd2q8etmirW1KC5JtjjrtNwyytdSQWdycXlSpH19Gt4MaxA3Pq5ts-J1a2MrlxwmwdyxQrFq_mAryb_yxyVqhSwnjy_mEBmFigZBhwyP-kySLMj4xiu1HO4iWY0u1lWJ8IVtpV1t4yTF-lryuw35CSKqKi92BfEypz2rMf096R3bBvn_svdqPCHF2Fh-bZ_em5Myr84Eg0jwaOkqGngyBHfSO4ELF2ZYqeXagCn_k6FJmQQebFOtUqokBuxPOQSyaZzlSouORrMNPutPUG2LHOdZBLNw0Vvoq2oB-ixxxplaPjF6SZBQeGaUm3xPdIPAOB_oWEFqwUfK2aojHqx74F24bNieFOgoYUVQITLrdgt3qMwks7Mmlbd4b9pET_j35pIVAFo8qNLdgjdo99_sdBbv696RbMeXEkypy6bZgZ9IZ6B2mHE7BWQCXXYPby7PrmqVbIxQcshCCJ},
	doi = {10.1177/002234338602300102},
	abstract = {Recent developments in strategic weaponry have led to increasing fears that the danger of war by acci dent or inadvertence is growing. In particular, the deployments of 'fast-attack' systems with short flight times, combined with the growing complexity and automation of strategic warning and command and control systems, has given rise to the belief that during a major international crisis there would be insuf ficient time to distinguish false alarms from an actual warning of an enemy attack. An examination of a mathematical model of the warning and launch sequence that would follow from a strategic alarm sug gests strongly that there would be almost no time to make such a decision unless a 'launch-on-warning' strategic posture were adopted. There is evidence to suggest that in fact both superpowers believe they would be forced to adopt such a policy in the event of a serious crisis. Given a 'launch-on-warning' pos ture, an examination of available data on false alarms provided by NORAD leads to the conclusion that a false alarm sufficiently severe to trigger a strategic attack would occur about 50\% of the time during a lengthy crisis. This finding highlights the urgent need for the superpowers to undertake co-operative measures to reduce the risk of war by accident, including the dismantling of short flight time systems and undertaking major improvements in their ability to communicate and to co-ordinate their actions in time of crisis.;Recent developments in strategic weaponry have led to increasing fears that the danger of war by accident or inadvertence is growing. In particular, the deployments of 'fast-attack' systems with short flight times, combined with the growing complexity and automation of strategic warning and command and control systems, has given rise to the belief that during a major international crisis there would be insufficient time to distinguish false alarms from an actual warning of an enemy attack. An examination of a mathematical model of the warning and launch sequence that would follow from a strategic alarm suggests strongly that there would be almost no time to make such a decision unless a 'launch-on-warning' strategic posture were adopted. There is evidence to suggest that in fact both superpowers believe they would be forced to adopt such a policy in the event of a serious crisis. Given a 'launch-on-warning' posture, an examination of available data on false alarms provided by NORAD leads to the conclusion that a false alarm sufficiently severe to trigger a strategic attack would occur about 50\% of the time during a lengthy crisis. This finding highlights the urgent need for the superpowers to undertake co-operative measures to reduce the risk of war by accident, including the dismantling of short flight time systems and undertaking major improvements in their ability to communicate and to co-ordinate their actions in time of crisis.;},
	language = {English},
	number = {1},
	journal = {Journal of peace research},
	author = {Wallace, Michael D. and Crissey, Brian L. and Sennott, Linn I.},
	year = {1986},
	note = {Place: Thousand Oaks, CA
Publisher: Norwegian University Press},
	keywords = {Accidents, False alarms, Flight time, Intercontinental ballistic missiles, Missiles, Nuclear war, Nuclear warfare, Risk, Spacecraft launching, Superpowers, War, Warnings},
	pages = {9--27},
}

@inproceedings{eisenhawer_initiating-event_1996,
	address = {United States},
	title = {Initiating-event frequencies for nuclear weapons dismantlement hazard analysis},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfZxNT8MwDIYt2C7cQAzB-JD5AWXpurbJGTGxC-PQ--SmnkCCgdpVSPx67KaCCQnOiZI4X46tJy9AMr0x0a87IVWNk9KZhGJrSueYfcompjU7zsvuw9xObidoRzc9Zfkme71DLDVNKcY0k_e2fplMc5PZdB-GEgNkciSHy2JZLORm1fo7PmJ-CKOf33P4-O0XjmCPN8fwsFBKhxQyjjrRJFzXgWKWUBXl5YgbVRamGj-YlFrF6rl5FbMD3o1P9ClridRriIzgen5X3N5HOoyVuDHVYvUKrfjtKow5OYGBxPZ8Cpg7ryEKxdXMzrhypc2sKuDksaucYTqD8d_tjP8rPIeDABgrq3YBg23d8qX065v2qp-rL13IfaE},
	abstract = {A quantitative data base for initiating events encountered during nuclear weapons handling is described. This data base was assembled from incident reports at the plant where the weapons are handled. The strengths and pitfalls of constructing such a data base are elaborated using examples encountered in the data. Insights gained into accident sequences, human error probabilities, and other areas of concern are discussed.},
	language = {English},
	author = {Eisenhawer, S. W. and Bott, T. F. and Los Alamos National Lab., NM (United States)},
	year = {1996},
	note = {Conference Proceedings},
	keywords = {ACCIDENTS, CHEMICAL EXPLOSIVES, HUMAN FACTORS, INFORMATION SYSTEMS, MATERIALS HANDLING, MILITARY TECHNOLOGY, WEAPONRY, AND NATIONAL DEFENSE, NUCLEAR WEAPONS, NUCLEAR WEAPONS DISMANTLEMENT, PROBABILISTIC ESTIMATION, RISK ASSESSMENT, SAFETY ANALYSIS},
}

@article{downes_nuclear_2017,
	title = {Nuclear terrorism and virtual risk: {Implications} for prediction and the utility of models},
	volume = {2},
	issn = {2057-5637},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwnV07T8MwELZou7DwfhRKZQkxpk3sJG5YUEGUVioMQCWYIsdxpDIkJS38fu7yKAlCDCyREltW7Dvfy-fvCOGsZxo_ZIJrSejtcunYWjgiAL0bBiGITVu5jnR1PbaTx9-WRZZlKSIzuR0mCkPmffC9PdDNpvCuFu8GFpHCw9aiokaDtJjFBbB9azh9mk6-gy5gHdtZ4WIGdorhuFyUkKWW6Os54ndboudUgRbqCqsurzMlNNomb-X_ZrknWPGgmoTfz4APM7SLEuTx_3PbIVuFqUqHOW_tkg0d75GjWgiRrnPp9snrA0Ijy5RCe5ogNCGVcUg_5yleUaGYw35JJ5UEdgr2Ml2keFKE71lvMEcpbAX0DWgS0axOz_KAzEa3zzdjoyjcYCjO2Qos9gj8rlDDqkqsaC3QLdG2EmANBHj53oNl9iKmWRBwU2L5H497OnK5GrgDsOAOSTNOYn1MqK1syewIHBvp2krLgMvIspRiUeAo05FtcrGmlF9sv6Wfp64JHyjqI0V9p03OSyr6ixzH49denZIilcHW5Dj5u_mUbOIweTJvhzRX6Yc-g5kAG3RJQ8yu8fkCz9Zw_Hg36RbcCV_v2fQLp_ryoQ},
	doi = {10.1017/eis.2017.5},
	abstract = {Assessing the risk of nuclear terrorism is a challenging task due to the diversity of actors involved, variety of pathways to success, range of defensive measures employed, and the lack of detailed historical record upon which to base analysis. Numerical models developed to date vary wildly in both approach and ultimate assessment: estimates of the likelihood a nuclear terrorist attack differ by up to nine orders of magnitude. This article critiques existing efforts from the standpoint of probability theory, and proposes an alternative perspective on the utility of risk assessment in this area. Nuclear terrorism is argued to be a ‘virtual risk’ for which it is not possible to meaningfully ascribe a quantitative measure, making numerical estimates of the likelihood of nuclear terrorism misleading. Instead, we argue that focus should be placed on utilising models to identify areas of disagreement as targets for further research, with greater emphasis on understanding terrorist decision-making and adaption in response to nuclear security measures.},
	language = {English},
	number = {2},
	journal = {European journal of international security},
	author = {Downes, Robert J. and Hobbs, Christopher},
	year = {2017},
	note = {Place: Cambridge, UK
Publisher: Cambridge University Press},
	keywords = {Black markets, Counterterrorism, Decision making, Mathematical models, National security, Nuclear weapons, Risk assessment, Terrorism},
	pages = {203--222},
}

@article{toon_nuclear_2007,
	title = {Nuclear war. {Consequences} of regional-scale nuclear conflicts},
	volume = {315},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3Na9swFBdbR2GXsWbrxz51GhvBrS1FlnPYIRsNO4T04sJuRraeT61d4oay_vV9L5ITpXS0YxhMbGIn0e-Xp5_1vhiT4jiO7tmE2FiSJiPaqtQmRquk1mBVLOo0FvfXdm771JgHg9pP_htpPIdYU-bsP6C9vimewNeIOe4Rddw_Cfc5FSg2i-GNWRyv2nH2sdIkC6kNA0nvqENoYNj491Y-N6QLpWr_r0cJunbrBGCu4xMnLoqgDyrwlwUrDHnrPPtnN9AMAw9P6U3x5GLD0Hy5qNog4X-TfvYDjwDCEIGtBQu9ithyFheckY2pP6SIZWiFpcvq9HRTWRKaVXL_BVM0HqqHzX_QsBKoXQ2KW72Z6Xrv_vysmJ7PZkV--jv_QiXWLy2O8XdoomX3nL0QGkWSiw7dqt_sK0MFOVf9R_z98WQlU_LX7JV_vuATR4w99gyaAdt1HUf_DNieh6fjX33B8W9vWM8ZTpzhIWd4W_NtznDPGb7mzFt2Pj3Nf_6KfFuN6Arl_nVEBZNEDGOAMU5XdSoqZcuEYnJHksrvGVVVZaZH1RiyUgD-QqmsAZuZWmc1Sp59ttO0DRwyDqAyLaRNdYq6WqhSppAJbZVJaauO2Od-XAo0W-SLMg20y67QpB3VSB6xAzdcxZWrrlIkWkohx-m7R699z15u-PWB7VwvlvARvxuaiU8r9O4AKYVqSg},
	doi = {10.1126/science.1137747},
	language = {English},
	number = {5816},
	journal = {Science (American Association for the Advancement of Science)},
	author = {Toon, Owen B. and Robock, Alan and Turco, Richard P. and Bardeen, Charles and Oman, Luke and Stenchikov, Georgiy L.},
	year = {2007},
	note = {Place: United States},
	keywords = {Agriculture, Atmosphere, Climate, Humans, International Cooperation, Mortality, Nuclear Warfare - prevention \& control, Nuclear Warfare - statistics \& numerical data, Smoke},
	pages = {1224--1225},
}

@article{baum_confronting_2015,
	title = {Confronting the threat of nuclear winter},
	volume = {72},
	issn = {0016-3287},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpZ3PS8MwFMcfsh1UxB9Tsf4YPXjw0jX9kbQ9juGYCJ70HNKmge2wja3iv29emrpOFEUPPbQ0kOYled80730CEIUD4n2aE7STkrTEA2rigiQKN2diwQIlU0akVPn2vx0YNakxGGVpXUE9xZvJ2z7xbeP6y-kUU361tED9j4j_GAGgXe2tMt3ru8OHx8nTZm-BkpohHjAPC2zyevzZoCZ5IMc7oDX9NP7OY7UU6Rc-y_in8REsmk8xYSl4GEI7Pt83TEQDwmj4j__87GM4tFLWHdbvncBOOe_BbpPpvO7Bfgt2eAp3mFyIuAR952rZqS8UrO5CuXOEKouV-4bwitUZvIzvn0cTz57T4BV6OVh5SZGwMssFLVgmlRAFnoclCctzodWY7iR5zlic5gkNIlGoVApdZVJGMgsDFsZJdA4HAuP555XJ-5MX4KaRSqJUMpIWFPk4aZKpOFOSEBEKLdIcGDRG4cuay8GbgLUZt1bkaEVOIq5bxoG0MR3falqufcdPRa8bU3M7wtdcCz_8BUcz6sBt2_wf1TGsHz2FUrOFkjkQ_Oa1kUWzI5Kguvx7pa9gD-_qcLhr6FSr1_IGOtjx-nZE9M0Som-WEO_uuBqU},
	doi = {10.1016/j.futures.2015.03.004},
	abstract = {Large-scale nuclear war sends large quantities of smoke into the stratosphere, causing severe global environmental effects including surface temperature declines and increased ultraviolet radiation. The temperature decline and the full set of environmental effects are known as nuclear winter. This paper surveys the range of actions that can confront the threat of nuclear winter, both now and in the future. Nuclear winter can be confronted by reducing the probability of nuclear war, reducing the environmental severity of nuclear winter, increasing humanity's resilience to nuclear winter, and through indirect interventions that enhance these other interventions. While some people may be able to help more than others, many people -- perhaps everyone across the world -- can make a difference. Likewise, the different opportunities available to different people suggests personalized evaluations of nuclear winter, and of catastrophic threats more generally, instead of a one-size-fits-all approach.;Large-scale nuclear war sends large quantities of smoke into the stratosphere, causing severe global environmental effects including surface temperature declines and increased ultraviolet radiation. The temperature decline and the full set of environmental effects are known as nuclear winter. This paper surveys the range of actions that can confront the threat of nuclear winter, both now and in the future. Nuclear winter can be confronted by reducing the probability of nuclear war, reducing the environmental severity of nuclear winter, increasing humanity's resilience to nuclear winter, and through indirect interventions that enhance these other interventions. While some people may be able to help more than others, many people perhaps everyone across the world can make a difference. Likewise, the different opportunities available to different people suggests personalized evaluations of nuclear winter, and of catastrophic threats more generally, instead of a one-size-fits-all approach. (C) 2015 Elsevier Ltd. All rights reserved.;•Nuclear winter refers to environmental consequences of nuclear war.•This article surveys the options for confronting nuclear winter.•Many options are available for many actors around the world.

Large-scale nuclear war sends large quantities of smoke into the stratosphere, causing severe global environmental effects including surface temperature declines and increased ultraviolet radiation. The temperature decline and the full set of environmental effects are known as nuclear winter. This paper surveys the range of actions that can confront the threat of nuclear winter, both now and in the future. Nuclear winter can be confronted by reducing the probability of nuclear war, reducing the environmental severity of nuclear winter, increasing humanity's resilience to nuclear winter, and through indirect interventions that enhance these other interventions. While some people may be able to help more than others, many people—perhaps everyone across the world—can make a difference. Likewise, the different opportunities available to different people suggests personalized evaluations of nuclear winter, and of catastrophic threats more generally, instead of a one-size-fits-all approach.;},
	language = {English},
	number = {Journal Article},
	journal = {Futures : the journal of policy, planning and futures studies},
	author = {Baum, Seth D.},
	year = {2015},
	note = {Place: OXFORD
Publisher: Elsevier Ltd},
	keywords = {Business \& Economics, Catastrophic threats, Economics, Environmental impact, Global catastrophic risk, Nuclear war, Nuclear winter, Public Administration, Regional \& Urban Planning, Risk reduction, Social Sciences, Studies, Ultraviolet radiation, War},
	pages = {69--79},
}

@article{winter_survival_2020,
	title = {Survival of the best fit: modelling nuclear proliferation},
	volume = {ahead-of-print},
	issn = {0305-0629},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3da9swED_68VIYo2u7NWsX9LC34sy25Mge7GGUjj30rRnbm5FlGTKYMzKng_31u5PkrzSwjr6YICe2cne6u9_p7gTA41kYbOkENPKyRGPNDY_TKuKRLozRkhvNOQKSeCu2s2hLY3Ymtb97MqdxDHlNlbP_we3uoTiAn5HneEWu4_VRfL_b4OK_dy4mOZUFqv2ramkjgPbYG1t_XlMbY-pyTYf2VGbd8-d7n9reRwqpqcTalUB0PvhXO7idXXhr6qULkt7Uf1bDmAICSNoh6RHoOBnJV1dRkt_cRyeMV5ZCBlK4_o2tNlVoQ8pgVQUUl2wGErTjhtOZ0cD4uoLSB2rd50HiHGgKM5ryDDUJgkXZ27Euu7C9Q83Tf5RL3XwwdbD5tQ-HscxCi5HvvvVbTYkz1-0fbMu8qAH7rheOHJhRe9udvov1UxbH8NwDDPbRScYL2DP1CbwasZN1GZAnsH-rfp9C1koNW1UMpYaR1DCUmveskxnmZYaNZOYMvny6WVx_DvyhGoFGT74JktCURhVhpisTchWWJpEqTHUsVFHImM8LgXpdavQEZaI0OnQaAVgkpOQyK3TGX8IzRcUXdWOLNMtzYAiyFT4kKdW8FLzQqUg1Ui7NhMa1LqoJzFqS5T9dE5U8anvTehrnROPc03gC2ZCweWOjV5U7aibn__jt2yEXuhcSOqGzYCNhd7QmED3ma9e-Uz51iGheP2FaF3DUr7RLOGjWG_MGDkinTS2Um1ooN7XC-RcvF513},
	doi = {10.1080/03050629.2020.1792897},
	abstract = {The study of nuclear proliferation has recently undergone a renaissance, one element of which is the widespread application of a particular statistical technique known as survival modeling. But survival models are often misapplied and this misapplication has consequences for our understanding of nuclear proliferation. Scholars of nuclear proliferation consistently fail to account for two methodological challenges present in survival modeling: selecting an appropriate distribution and meeting the proportional hazards assumption. We show by example how accounting for these challenges alters key results and has a bearing on current debates in the field. We endorse the continued, judicious application of methodologically sound survival models and conclude by highlighting three possible theoretical and methodological paths forward.},
	language = {English},
	number = {ahead-of-print},
	journal = {International interactions},
	author = {Winter, Paul and Lenine, Enzo},
	year = {2020},
	note = {Place: ABINGDON
Publisher: Routledge},
	keywords = {Duration analysis/duration model, International Relations, Social Sciences, data, nuclear proliferation, statistical methodology, time series},
	pages = {1--14},
}

@article{grover_climatic_1984,
	title = {The {Climatic} and {Biological} {Consequences} of {Nuclear} {War}},
	volume = {26},
	issn = {0013-9157},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3dS9xAEB_EIm0ptk0rXm3jPpS-3ZncfuTyKIdiwY8Hr_i4bHazVNC7cokF__vObBLNiVLBl8CFzcfu_XZ2ZvOb3wDw8SgZPrAJAqMMmZfWo_cqbSoL4RDZzihy0E1Zru7tNOTCqmVZUkjtG92IYLpprpui6ghye8GLSWU2wvhZjHC9TbKcgnh09ElM_5gSMTvTnIVim6GkAV3SpfQ8dZeVxWpFyhQt-ALn4Ipf-sjKFVapw_dw3XUokFOoJEKfpb8XlBGDHEanAvmizn-AzdadZfsN_j7CWjmP4G1P5DCCrYP7XDps2hqTKoLXbQH237cRbJ8EtfDlLfvBTs3f-3YRbASSqq0-QYaYZtOry6Ayy_CVWVNJk3DGpj1aOFt4dkpCzWbJLszyM_w6PJhNj4Zt4Yeh5UrVw7GZlLIUBl1XNzHcJta63I4LYRA96GT4pJCCO-_xJM9dxh2eUIkoMmNN4Qq-Be8MJQjM65BI6LaJwiWk4dIr73JBCcPWWWFSNGfKZkU2HsCo-6v1n0boQ6d3-qnNIGsaZN0O8gDyPiB0HXZYfFMORfP_XLtD6NGIFZLqtcRpsrWWkguV8AHsdqDSONnpC46Zl4ubCuO0dKJkOhnA9z7W7l54nx5yfi6UIrDjjdLnNJu2avCkglB_eUG3duAN_Wz4oF9hvV7elN9gnWAeh02TOAQtcQha6HhyFIcJGsOrs9nZ7Oc_yjA5DQ},
	doi = {10.1080/00139157.1984.9930790},
	abstract = {Recent studies disclose that 50-70\% of the human population in both Northern and Southern hemispheres might survive the direct effects of a large-scale nuclear war. The prospects for their survival depend on the climatic and biological consequences of such warfare. Current theories on the nuclear winter phenomenon are addressed; this effect refers to sunlight obscuration and correpsonding reductions in atmospheric temperatures. Scenarios analyzing radioactive fallout, weather alterations, and impacts to aquatic, marine, and terrestrial ecosystems are outlined. Implications for international nuclear weapons policy are surveyed. ( 1 graph, 5 photos, 29 references, 1 table, );Projecting comprehensively the climatic and biological consequences of nuclear war brings into question the perceived security ascribed to policies of deterrence, as well as the efficacy of civil preparedness measures, particularly relocation plans. It is presumed the probability that nuclear war will occur is low, but the potential consequences are so great that the issue must be given full attention. Nuclear war is the greatest environmental threat we face. Yet the problem should be solvable. It is especially important that environmentally concerned citizens and scientists apply their knowledge and understanding to the problem because many of the changes in environmental quality that concerns us today, such as air and water pollution by a host of organic and inorganic agents, represent the principle mechanism whereby life could be threatened in the aftermath of nuclear war. 29 references.;},
	language = {English},
	number = {4},
	journal = {Environment : science and policy for sustainable development},
	author = {Grover, Herbert D. and Univ. of New Mexico, Albuquerque},
	year = {1984},
	note = {Place: WASHINGTON
Publisher: Taylor \& Francis Group},
	keywords = {450200 - Military Technology, Weaponry, \& National Defense- Nuclear Explosions \& Explosives, AMBIENT TEMPERATURE, ANIMALS, BIOLOGICAL EFFECTS, CLIMATES, DUSTS, EARTH ATMOSPHERE, ELECTROMAGNETIC RADIATION, ENVIRONMENTAL EFFECTS, EXPLOSIONS, Environmental Sciences, Environmental Sciences \& Ecology, Environmental Studies, INJURIES, LAYERS, LOSSES, Life Sciences \& Biomedicine, MAMMALS, MAN, MILITARY TECHNOLOGY, WEAPONRY, AND NATIONAL DEFENSE, NUCLEAR EXPLOSIONS, NUCLEAR WINTER, OZONE, OZONE LAYER, PRIMATES, RADIATIONS, SOOT, STRATOSPHERE, Science \& Technology, THERMAL RADIATION, TROPOSPHERE, VERTEBRATES},
	pages = {6--38},
}

@article{baum_riskrisk_2019,
	title = {Risk–{Risk} {Tradeoff} {Analysis} of {Nuclear} {Explosives} for {Asteroid} {Deflection}},
	volume = {39},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Lb9QwELagvYAQ4t1AiYzgRJWtH3n5wGEpoEWIHtoicYvc2BEraBY12Tv_gX_IL8HjR7K7QNWKS3YTjxzFM5nM8zNCnE1IsqETmNJC15TlMi0KSM2UitRCKt5oxTPFNmI7Q2vMX4va9_-b0-aa4TV0zl6B28Ok5oL5b3hujobr5ngpvh_Nu6-hgoHDCeCXK71omjUAkkPAMZbne7YGr7PYs1BwOAXchMUcqpObb7ZKq101X-180k8zBkHdXsnHuv-y92ayGkegwjfUjeqGFbZ_yulGHdShSHLhupyDvnTgQ0Eu6Kr2S12fv_-SGsuBXaClAUR4YlxkP98aFPZAlf2bzn6Ej94fT90YQKWfqXndv9Jtsuyuo21WCGK97M-zIbEEzbc27OYf1iPWQnHXeJ91G-UPx2PDRll3a6xdcnIH3fYOBZ46SbiLrun2Hrq5AjNpzj4O2LzdffQBmPjrx0_4wUE2cJANvGiwlw08ygY2soGDbOBRNh6gT-_enhzMEr-lRlLzrBCJkqmoiRJENHVJaVMKmeaZVFQ2TLBaGmstz4nWVCmbsE5VfpqXwqh1RXTDav4Q3ZLQetH2tkVT7SBMdFFQZTyLsjbuNjmVVJuFJUSmkvOi5hF6Hlaz-u4gVKrgesKaV3bNI7QbFrryr1NXGeeDAZRslkXo2TBsFCBktWSrF0tHkwGqp6F55Bg03IbDvkqckwi9WOXYMO7gkSCeblP6EaKXITvw6PmAGtFH6KXl_gWPVg1C-vgqxE_QjfE93UVb_flSP0VboAVjtP16NjucxjYUFVtXMLaCHluH8DeiZq-0},
	doi = {10.1111/risa.13339},
	abstract = {To prevent catastrophic asteroid-Earth collisions, it has been proposed to use nuclear explosives to deflect away earthbound asteroids. However, this policy of nuclear deflection could inadvertently increase the risk of nuclear war and other violent conflict. This article conducts risk-risk tradeoff analysis to assess whether nuclear deflection results in a net increase or decrease in risk. Assuming nonnuclear deflection options are also used, nuclear deflection may only be needed for the largest and most imminent asteroid collisions. These are low-frequency, high-severity events. The effect of nuclear deflection on violent conflict risk is more ambiguous due to the complex and dynamic social factors at play. Indeed, it is not clear whether nuclear deflection would cause a net increase or decrease in violent conflict risk. Similarly, this article cannot reach a precise conclusion on the overall risk-risk tradeoff. The value of this article comes less from specific quantitative conclusions and more from providing an analytical framework and a better overall understanding of the policy decision. The article demonstrates the importance of integrated analysis of global risks and the policies to address them, as well as the challenge of quantitative evaluation of complex social processes such as violent conflict.},
	language = {English},
	number = {11},
	journal = {Risk analysis},
	author = {Baum, Seth D.},
	year = {2019},
	note = {Place: HOBOKEN
Publisher: Wiley},
	keywords = {Ambiguity, Asteroid collisions, Asteroid deflection, Asteroids, Conflict, Decision analysis, Deflection, Explosives, Life Sciences \& Biomedicine, Mathematical Methods In Social Sciences, Mathematics, Mathematics, Interdisciplinary Applications, Nuclear war, Physical Sciences, Public, Environmental \& Occupational Health, Quantitative analysis, Risk analysis, Risk assessment, Science \& Technology, Social Sciences, Social Sciences, Mathematical Methods, Social factors, Social processes, Tradeoff analysis, Tradeoffs, nuclear weapons, risk–risk tradeoff},
	pages = {2427--2442},
}

@article{baum_riskrisk_2019-1,
	title = {Risk–{Risk} {Tradeoff} {Analysis} of {Nuclear} {Explosives} for {Asteroid} {Deflection}},
	volume = {39},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Lb9QwELagvYAQ4t1AiYzgRJWtH3n5wGEpoEWIHtoicYvc2BEraBY12Tv_gX_IL8HjR7K7QNWKS3YTjxzFM5nM8zNCnE1IsqETmNJC15TlMi0KSM2UitRCKt5oxTPFNmI7Q2vMX4va9_-b0-aa4TV0zl6B28Ok5oL5b3hujobr5ngpvh_Nu6-hgoHDCeCXK71omjUAkkPAMZbne7YGr7PYs1BwOAXchMUcqpObb7ZKq101X-180k8zBkHdXsnHuv-y92ayGkegwjfUjeqGFbZ_yulGHdShSHLhupyDvnTgQ0Eu6Kr2S12fv_-SGsuBXaClAUR4YlxkP98aFPZAlf2bzn6Ej94fT90YQKWfqXndv9Jtsuyuo21WCGK97M-zIbEEzbc27OYf1iPWQnHXeJ91G-UPx2PDRll3a6xdcnIH3fYOBZ46SbiLrun2Hrq5AjNpzj4O2LzdffQBmPjrx0_4wUE2cJANvGiwlw08ygY2soGDbOBRNh6gT-_enhzMEr-lRlLzrBCJkqmoiRJENHVJaVMKmeaZVFQ2TLBaGmstz4nWVCmbsE5VfpqXwqh1RXTDav4Q3ZLQetH2tkVT7SBMdFFQZTyLsjbuNjmVVJuFJUSmkvOi5hF6Hlaz-u4gVKrgesKaV3bNI7QbFrryr1NXGeeDAZRslkXo2TBsFCBktWSrF0tHkwGqp6F55Bg03IbDvkqckwi9WOXYMO7gkSCeblP6EaKXITvw6PmAGtFH6KXl_gWPVg1C-vgqxE_QjfE93UVb_flSP0VboAVjtP16NjucxjYUFVtXMLaCHluH8DeiZq-0},
	doi = {10.1111/risa.13339},
	abstract = {To prevent catastrophic asteroid-Earth collisions, it has been proposed to use nuclear explosives to deflect away earthbound asteroids. However, this policy of nuclear deflection could inadvertently increase the risk of nuclear war and other violent conflict. This article conducts risk-risk tradeoff analysis to assess whether nuclear deflection results in a net increase or decrease in risk. Assuming nonnuclear deflection options are also used, nuclear deflection may only be needed for the largest and most imminent asteroid collisions. These are low-frequency, high-severity events. The effect of nuclear deflection on violent conflict risk is more ambiguous due to the complex and dynamic social factors at play. Indeed, it is not clear whether nuclear deflection would cause a net increase or decrease in violent conflict risk. Similarly, this article cannot reach a precise conclusion on the overall risk-risk tradeoff. The value of this article comes less from specific quantitative conclusions and more from providing an analytical framework and a better overall understanding of the policy decision. The article demonstrates the importance of integrated analysis of global risks and the policies to address them, as well as the challenge of quantitative evaluation of complex social processes such as violent conflict.},
	language = {English},
	number = {11},
	journal = {Risk analysis},
	author = {Baum, Seth D.},
	year = {2019},
	note = {Place: HOBOKEN
Publisher: Wiley},
	keywords = {Ambiguity, Asteroid collisions, Asteroid deflection, Asteroids, Conflict, Decision analysis, Deflection, Explosives, Life Sciences \& Biomedicine, Mathematical Methods In Social Sciences, Mathematics, Mathematics, Interdisciplinary Applications, Nuclear war, Physical Sciences, Public, Environmental \& Occupational Health, Quantitative analysis, Risk analysis, Risk assessment, Science \& Technology, Social Sciences, Social Sciences, Mathematical Methods, Social factors, Social processes, Tradeoff analysis, Tradeoffs, nuclear weapons, risk–risk tradeoff},
	pages = {2427--2442},
}

@article{baum_riskrisk_2019-2,
	title = {Risk–{Risk} {Tradeoff} {Analysis} of {Nuclear} {Explosives} for {Asteroid} {Deflection}},
	volume = {39},
	issn = {0272-4332},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Lb9QwELagvYAQ4t1AiYzgRJWtH3n5wGEpoEWIHtoicYvc2BEraBY12Tv_gX_IL8HjR7K7QNWKS3YTjxzFM5nM8zNCnE1IsqETmNJC15TlMi0KSM2UitRCKt5oxTPFNmI7Q2vMX4va9_-b0-aa4TV0zl6B28Ok5oL5b3hujobr5ngpvh_Nu6-hgoHDCeCXK71omjUAkkPAMZbne7YGr7PYs1BwOAXchMUcqpObb7ZKq101X-180k8zBkHdXsnHuv-y92ayGkegwjfUjeqGFbZ_yulGHdShSHLhupyDvnTgQ0Eu6Kr2S12fv_-SGsuBXaClAUR4YlxkP98aFPZAlf2bzn6Ej94fT90YQKWfqXndv9Jtsuyuo21WCGK97M-zIbEEzbc27OYf1iPWQnHXeJ91G-UPx2PDRll3a6xdcnIH3fYOBZ46SbiLrun2Hrq5AjNpzj4O2LzdffQBmPjrx0_4wUE2cJANvGiwlw08ygY2soGDbOBRNh6gT-_enhzMEr-lRlLzrBCJkqmoiRJENHVJaVMKmeaZVFQ2TLBaGmstz4nWVCmbsE5VfpqXwqh1RXTDav4Q3ZLQetH2tkVT7SBMdFFQZTyLsjbuNjmVVJuFJUSmkvOi5hF6Hlaz-u4gVKrgesKaV3bNI7QbFrryr1NXGeeDAZRslkXo2TBsFCBktWSrF0tHkwGqp6F55Bg03IbDvkqckwi9WOXYMO7gkSCeblP6EaKXITvw6PmAGtFH6KXl_gWPVg1C-vgqxE_QjfE93UVb_flSP0VboAVjtP16NjucxjYUFVtXMLaCHluH8DeiZq-0},
	doi = {10.1111/risa.13339},
	abstract = {To prevent catastrophic asteroid-Earth collisions, it has been proposed to use nuclear explosives to deflect away earthbound asteroids. However, this policy of nuclear deflection could inadvertently increase the risk of nuclear war and other violent conflict. This article conducts risk-risk tradeoff analysis to assess whether nuclear deflection results in a net increase or decrease in risk. Assuming nonnuclear deflection options are also used, nuclear deflection may only be needed for the largest and most imminent asteroid collisions. These are low-frequency, high-severity events. The effect of nuclear deflection on violent conflict risk is more ambiguous due to the complex and dynamic social factors at play. Indeed, it is not clear whether nuclear deflection would cause a net increase or decrease in violent conflict risk. Similarly, this article cannot reach a precise conclusion on the overall risk-risk tradeoff. The value of this article comes less from specific quantitative conclusions and more from providing an analytical framework and a better overall understanding of the policy decision. The article demonstrates the importance of integrated analysis of global risks and the policies to address them, as well as the challenge of quantitative evaluation of complex social processes such as violent conflict.},
	language = {English},
	number = {11},
	journal = {Risk analysis},
	author = {Baum, Seth D.},
	year = {2019},
	note = {Place: HOBOKEN
Publisher: Wiley},
	keywords = {Ambiguity, Asteroid collisions, Asteroid deflection, Asteroids, Conflict, Decision analysis, Deflection, Explosives, Life Sciences \& Biomedicine, Mathematical Methods In Social Sciences, Mathematics, Mathematics, Interdisciplinary Applications, Nuclear war, Physical Sciences, Public, Environmental \& Occupational Health, Quantitative analysis, Risk analysis, Risk assessment, Science \& Technology, Social Sciences, Social Sciences, Mathematical Methods, Social factors, Social processes, Tradeoff analysis, Tradeoffs, nuclear weapons, risk–risk tradeoff},
	pages = {2427--2442},
}

@article{barrett_analyzing_2013,
	title = {Analyzing and {Reducing} the {Risks} of {Inadvertent} {Nuclear} {War} {Between} the {United} {States} and {Russia}},
	volume = {21},
	issn = {0892-9882},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwnV3JTsMwEB0BvSAh9qUslQ-IW8BLkiYnBBUIDiCxiWPxEkuAVAotB_h6ZpwEWoQQIlIO2ZzEmcw8289vAJTc5dE3n2Cy3Bc8kTrlscg4uk7jnUliZTVG0JBJYaRvp-x_G1Qsy9pFBr_tnix1me8JhZdhLE_lfv85oiRSNNhaZdSYhAaNp5GRt68vPttf6KUDozHLZZQjsqxn0pHUNu6jXcT1UrttSqoYj2HOH6JSiEDHc_BQP2wgnlC6g1EG_l5QPQxSF7XC4_9fbB5mK5zKDkrDWoCJorcIq2P9h-yTSLcIa2dB7fvlje2wc43WyyqnsQR3QffkHZ-Y6Z7Di9yrpQ1EnuzyfvA4YE-enfZ0yAyNIZCdk8SyfmG3uB6WNLJwcgmPWQmPy7Je8Y_Wy3BzfHTdOYmqvA6RVWk2jITXKbZ_Lbb24lw469qec48fALGbKrR2iBraphBSK5spRLTO6sIKn6axMzyXcgVmNPH_e8MwT9CtARPOxFIUhUgdtvgTrn0Sm0RhMd5YKUwTNuvq7lZ_6aD7VddN2B79wN1-KfVBQ_OEIXm5qCaIv5zWqeTVSVZguP77nTdgWoYMG8Sh3ISGx8PFFkyR_bSC_bagcXRx2Ln6APgc_7Q},
	doi = {10.1080/08929882.2013.798984},
	abstract = {This article develops a mathematical modeling framework using fault trees and Poisson processes for analyzing the risks of inadvertent nuclear war from U.S. or Russian misinterpretation of false alarms in early warning systems, and for assessing the potential value of options to reduce the risks of inadvertent nuclear war. The model also uses publicly available information on early warning systems, near-miss incidents, and other factors to estimate probabilities of a U.S.-Russia crisis, the rates of false alarms, and the probabilities that leaders will launch missiles in response to a false alarm. The article discusses results, uncertainties, limitations, and policy implications. [PUBLICATION ABSTRACT];This article develops a mathematical modeling framework using fault trees and Poisson processes for analyzing the risks of inadvertent nuclear war from U.S. or Russian misinterpretation of false alarms in early warning systems, and for assessing the potential value of options to reduce the risks of inadvertent nuclear war. The model also uses publicly available information on early warning systems, near-miss incidents, and other factors to estimate probabilities of a U.S.-Russia crisis, the rates of false alarms, and the probabilities that leaders will launch missiles in response to a false alarm. The article discusses results, uncertainties, limitations, and policy implications.

Supplemental materials are available for this article. Go to the publisher's online edition of Science \& Global Security to view the free online appendix with additional tables and figures.;},
	language = {English},
	number = {2},
	journal = {Science \& global security},
	author = {Barrett, Anthony M. and Baum, Seth D. and Hostetler, Kelly},
	year = {2013},
	note = {Place: ABINGDON
Publisher: Taylor \& Francis},
	keywords = {False alarms, International Relations, Nuclear weapons, Poisson distribution, Risk assessment, Social Sciences},
	pages = {106--133},
}

@article{johnson_artificial_2020,
	title = {Artificial {Intelligence} in {Nuclear} {Warfare}: {A} {Perfect} {Storm} of {Instability}?},
	volume = {43},
	issn = {0163-660X},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV3fa9RAEF60vggitlZ72h77IL6UnJvdXLIRpRxFKYgiWNG3sNkkcA-NkqYP9987szv51R600pdw5O6yezezs98s33zDmJILEVyLCVYZlUeiSkMrRWILYaLYCptUIq1ye-Ns50NXGrOV1P7u3paGe2BrrJz9D2v3D4Ub8BpsDlewOlzvZPdV49g_XkNjJLe5ro-_oXaxaY5_maYyDRWlfy8bp1_8A5LvC19YAoDRUWY311h_jnzTNV-qsR5zygelbls9-XZ8oiCFI6IM-eeUikTHjrEK4lj89rtGFyoFhEpqwkKx1Esukc_IUWAMPQuX9ljpA-yN8E18RxgNB1vg5BYwAqRZetivehZh9w6KpF8Ua9t-LOvg6vIheyQTyPkRG389GxSYI01C7_6ndOVcKLS-bcAJUJnI2E6SkS1wxUGT82fsKeUUfOWdYZc9KOs9tu8FYDb8LUd1YeM6OG_22MvJGTDvyZDP2ZfBdfjYdfi65uQ6nFznPV9xchzuHIf_qfjIcU722c_Pn85PzwLqtQFLUy_bYCmFwey1sqoM42VRLAG1qDIOrbEo61dEhcF02lQy15EtAHXHgPSwuwIAzkSqF-yJwZqMunW1m8UB41KlAp-TKwW4NbGpiXScV7oMDQQAlczYovuHs79eWyULO8laMkmGJsnIJDOWju2Qte5Qq_IdaDJ1y3cPO6NltFwvM4CvWofYhG3G3owN2c_H5TQaIJzCbEjMWHiXj52Svj7qSrSv7jHr1-zxsEIP2U7bXJVHbAcj4dwlgHOXAM6dq_8DKi2sqw},
	doi = {10.1080/0163660X.2020.1770968},
	abstract = {Johnson demystifies the hype surrounding artificial intelligence (AI) in the context of nuclear weapons and, more broadly, future warfare. Specifically, it highlights the potential, multifaceted intersections of this disruptive technology with nuclear stability. The inherently destabilizing effects of military AI may exacerbate tension between nuclear-armed great powers, especially China and the US, but not for the reasons you may think. He will begin this assessment by first examining the destabilizing characteristics of AI, such as machine-speed, bias, vulnerability, and non-human decision-making.},
	language = {English},
	number = {2},
	journal = {The Washington quarterly},
	author = {Johnson, James},
	year = {2020},
	note = {Place: ABINGDON
Publisher: Routledge},
	keywords = {Artificial intelligence, Bias, Decision making, Government \& Law, International Relations, Law, Nuclear war, Nuclear weapons, Social Sciences, Stability, Technology, Technology adoption, Vulnerability, War},
	pages = {197--211},
}

@article{acton_escalation_2018,
	title = {Escalation through {Entanglement}: {How} the {Vulnerability} of {Command}-and-{Control} {Systems} {Raises} the {Risks} of an {Inadvertent} {Nuclear} {War}},
	volume = {43},
	issn = {0162-2889},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwlV1Lb9QwEB7RckFCUAqFQFkZAcd0Y8dJHG7Vaqsi8ZBaCsfItZ3t8shWm1QV9_7wzjjJkkUg6GEvycTrxGPPjP3NNwCx2IvC39YEza3M3anEeSldEmt0YiXqknXoP3Cl9freDrzsU2NoH2Lv61kbLnbfcpxFxMK2AbcxeOEE43t_crxafVPlS7qhJ0Npxyrvwe6pGM9rZwpNbJhU3XtghlokIlqXH_NmfQ-ky6v_o1XyFujgPnzsO-uBJ1TuYIjAH3vWQ0910TM8_uPFtuBe54yy_fbGA7jlqm14vLZJyFZouW3YeKcvH8LVtMZx9ddYV-WHTSv0MWctEv0NO1xc4h3HPl98J05rD7_9yRYlo2wUXdmQfpMWI886ynR2RGdYtX_uaF5_q0leV-xtpX3JaGyYfSDuZb1kX_TyEZwcTD9NDsOulkNo0ONswkRn3EVZpqQRjieZTE-djLSJrXaWGy1LqZLcpokxUVQqa8oyFyKyQprECafiHbirCfNfNT430D4BptH7tGUaZy5PpcmFQsEszo2KlRW8VAG87se4OG-5Owof86SiGOpCADteAVZCIs2op2kAL3Dwi25W1395OBzoyy_ZdiyLY7QoGHFGEj0pn7cewJQ0qtCzeX3e-KyquiA0cNEy5eKtxXJWoEGjv4tjnvaigrjVOB0_xhjkBrA_bKddF2_cxquhWq_e3x_zc9qwIHdGBMD_R2zSkcoTmULz9Iaf5Rncob610Mpd2GyWF-45bNIsGvlIZ-QjnZEncB75KX8NJChUrA},
	doi = {10.1162/isec_a_00320},
	abstract = {The 2018 U.S. Nuclear Posture Review contains a highly consequential threat that has been largely

overlooked in the wave of commentary surrounding the document's release: the United States warns potential adversaries that it would consider using nuclear weapons in the event of "significant nonnuclear strategic attacks . . . on U.S. or allied nuclear forces, their command and control, or warning and attack assessment capabilities". In issuing this threat, the Nuclear Posture Review illustrates that nonnuclear attacks on nuclear forces and C3I capabilities could be highly escalatory, even to the point of directly sparking a nuclear war. This article's thesis is that the risks of inadvertent escalation are even more serious than these warnings suggest and are likely to increase significantly in the future. Driving these risks is the possibility that Chinese, Russian, or U.S. C3I assets located outside -potentially far outside - theaters of operation could be attacked over the course of a conventional conflict.;Nonnuclear weapons are increasingly able to threaten dual-use command, control, communication, and intelligence assets that are spaced based or distant from probable theaters of conflict. This form of “entanglement” between nuclear and nonnuclear capabilities creates the potential for Chinese or Russian nonnuclear strikes against the United States or U.S. strikes against either China or Russia to spark inadvertent nuclear escalation. Escalation pressures could be generated through crisis instability or through one of two newly identified mechanisms: “misinterpreted warning” or the “damage-limitation window.” The vulnerability of dual-use U.S. early-warning assets provides a concrete demonstration of the risks. These risks would be serious for two reasons. First, in a conventional conflict against the United States, China or Russia would have strong incentives to launch kinetic strikes on U.S. early-warning assets. Second, even limited strikes could undermine the United States' ability to monitor nuclear attacks by the adversary. Moreover, cyber interference with dual-use early-warning assets would create the additional danger of the target's misinterpreting cyber espionage as a destructive attack. Today, the only feasible starting point for efforts to reduce the escalation risks created by entanglement would be unilateral measures—in particular, organizational reform to ensure that those risks received adequate consideration in war planning, acquisition decisions, and crisis decisionmaking. Over the longer term, unilateral measures might pave the way for more challenging cooperative measures, such as agreed restrictions on threatening behavior.;Nonnuclear weapons are increasingly able to threaten dual-use command, control, communication, and intelligence assets that are space based or distant from probable theaters of conflict. This form of “entanglement” between nuclear and nonnuclear capabilities creates the potential for Chinese or Russian nonnuclear strikes against the United States or U.S. strikes against either China or Russia to spark inadvertent nuclear escalation. Escalation pressures could be generated through crisis instability or through one of two newly identified mechanisms: “misinterpreted warning” or the “damage-limitation window.” The vulnerability of dual-use U.S. early-warning assets provides a concrete demonstration of the risks. These risks would be serious for two reasons. First, in a conventional conflict against the United States, China or Russia would have strong incentives to launch kinetic strikes on U.S. early-warning assets. Second, even limited strikes could undermine the United States’ ability to monitor nuclear attacks by the adversary. Moreover, cyber interference with dual-use early-warning assets would create the additional danger of the target’s misinterpreting cyber espionage as a destructive attack. Today, the only feasible starting point for efforts to reduce the escalation risks created by entanglement would be unilateral measures—in particular, organizational reform to ensure that those risks received adequate consideration in war planning, acquisition decisions, and crisis decisionmaking. Over the longer term, unilateral measures might pave the way for more challenging cooperative measures, such as agreed restrictions on threatening behavior.;},
	language = {English},
	number = {1},
	journal = {International security},
	author = {Acton, James M.},
	year = {2018},
	note = {Place: One Rogers Street, Cambridge, MA 02142-1209, USA
Publisher: MIT Press},
	keywords = {FOREIGN POLICY, GOVERNMENT POLICY, INTERNATIONAL RELATIONS, Military policy, NUCLEAR WEAPONS, Nuclear warfare, Social Sciences, WAR},
	pages = {56--99},
}

@inproceedings{alpay_sycl_2020,
	address = {Munich Germany},
	title = {{SYCL} beyond {OpenCL}: {The} architecture, current state and future direction of {hipSYCL}},
	isbn = {978-1-4503-7531-3},
	shorttitle = {{SYCL} beyond {OpenCL}},
	url = {https://dl.acm.org/doi/10.1145/3388333.3388658},
	doi = {10.1145/3388333.3388658},
	language = {en},
	urldate = {2025-01-16},
	booktitle = {Proceedings of the {International} {Workshop} on {OpenCL}},
	publisher = {ACM},
	author = {Alpay, Aksel and Heuveline, Vincent},
	month = apr,
	year = {2020},
	pages = {1--1},
}

@inproceedings{alpay_exploring_2022,
	address = {Bristol, United Kingdom United Kingdom},
	title = {Exploring the possibility of a {hipSYCL}-based implementation of {oneAPI}},
	isbn = {978-1-4503-9658-5},
	url = {https://dl.acm.org/doi/10.1145/3529538.3530005},
	doi = {10.1145/3529538.3530005},
	language = {en},
	urldate = {2025-01-16},
	booktitle = {International {Workshop} on {OpenCL}},
	publisher = {ACM},
	author = {Alpay, Aksel and Soproni, Bálint and Wünsche, Holger and Heuveline, Vincent},
	month = may,
	year = {2022},
	pages = {1--12},
}

@article{kugler_fast_2022,
	title = {Fast {Bayesian} inversion for high dimensional inverse problems},
	volume = {32},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-021-10019-5},
	doi = {10.1007/s11222-021-10019-5},
	abstract = {We investigate the use of learning approaches to handle Bayesian inverse problems in a computationally efficient way when the signals to be inverted present a moderately high number of dimensions and are in large number. We propose a tractable inverse regression approach which has the advantage to produce full probability distributions as approximations of the target posterior distributions. In addition to provide confidence indices on the predictions, these distributions allow a better exploration of inverse problems when multiple equivalent solutions exist. We then show how these distributions can be used for further refined predictions using importance sampling, while also providing a way to carry out uncertainty level estimation if necessary. The relevance of the proposed approach is illustrated both on simulated and real data in the context of a physical model inversion in planetary remote sensing. The approach shows interesting capabilities both in terms of computational efficiency and multimodal inference.},
	language = {en},
	number = {2},
	urldate = {2025-01-16},
	journal = {Statistics and Computing},
	author = {Kugler, Benoit and Forbes, Florence and Douté, Sylvain},
	month = mar,
	year = {2022},
	keywords = {Artificial Intelligence, Bayesian analysis, Importance sampling, Inverse problems, Mixtures of Gaussians, Planetary science, Remote sensing},
	pages = {31},
}

@article{glasserman_multilevel_1999,
	title = {Multilevel {Splitting} for {Estimating} {Rare} {Event} {Probabilities}},
	volume = {47},
	issn = {0030-364X, 1526-5463},
	url = {https://pubsonline.informs.org/doi/10.1287/opre.47.4.585},
	doi = {10.1287/opre.47.4.585},
	abstract = {We analyze the performance of a splittingtechnique for the estimation of rare event probabilities by simulation. A straightforward estimator of the probability of an event evaluates the proportion of simulated paths on which the event occurs. If the event is rare, even a large number of paths may produce little information about its probability using this approach. The method we study reinforces promising paths at intermediate thresholds by splitting them into subpaths which then evolve independently. If implemented appropriately, this has the effect of dedicating a greater fraction of the computational effort to informative runs. We analyze the method for a class of models in which, roughly speaking, the number of states through which each threshold can be crossed is bounded. Under additional assumptions, we identify the optimal degree of splitting at each threshold as the rarity of the event increases: It should be set so that the expected number of subpaths reaching each threshold remains roughly constant. Thus implemented, the method is provably effective in a sense appropriate to rare event simulations. These results follow from a branching-process analysis of the method. We illustrate our theoretical results with some numerical examples for queueing models.},
	language = {en},
	number = {4},
	urldate = {2025-01-16},
	journal = {Operations Research},
	author = {Glasserman, Paul and Heidelberger, Philip and Shahabuddin, Perwez and Zajic, Tim},
	month = aug,
	year = {1999},
	pages = {585--600},
}

@article{botev_efficient_2012,
	title = {Efficient {Monte} {Carlo} simulation via the generalized splitting method},
	volume = {22},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-010-9201-4},
	doi = {10.1007/s11222-010-9201-4},
	abstract = {We describe a new Monte Carlo algorithm for the consistent and unbiased estimation of multidimensional integrals and the efficient sampling from multidimensional densities. The algorithm is inspired by the classical splitting method and can be applied to general static simulation models. We provide examples from rare-event probability estimation, counting, and sampling, demonstrating that the proposed method can outperform existing Markov chain sampling methods in terms of convergence speed and accuracy.},
	language = {en},
	number = {1},
	urldate = {2025-01-16},
	journal = {Statistics and Computing},
	author = {Botev, Zdravko I. and Kroese, Dirk P.},
	month = jan,
	year = {2012},
	keywords = {Artificial Intelligence, Boolean Satisfiability problem, Combinatorial counting, Convergence diagnostic, Fixed effort, Fixed splitting, Importance sampling, Level-crossing, MCMC, RESTART, Rare-event probability estimation, Sequential Monte Carlo, Splitting method},
	pages = {1--16},
}

@article{bakiri_survey_2018,
	title = {Survey on hardware implementation of random number generators on {FPGA}: {Theory} and experimental analyses},
	volume = {27},
	issn = {15740137},
	shorttitle = {Survey on hardware implementation of random number generators on {FPGA}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013716302271},
	doi = {10.1016/j.cosrev.2018.01.002},
	language = {en},
	urldate = {2025-01-16},
	journal = {Computer Science Review},
	author = {Bakiri, Mohammed and Guyeux, Christophe and Couchot, Jean-François and Oudjida, Abdelkrim Kamel},
	month = feb,
	year = {2018},
	pages = {135--153},
}

@inproceedings{salmon_parallel_2011,
	address = {Seattle Washington},
	title = {Parallel random numbers: as easy as 1, 2, 3},
	isbn = {978-1-4503-0771-0},
	shorttitle = {Parallel random numbers},
	url = {https://dl.acm.org/doi/10.1145/2063384.2063405},
	doi = {10.1145/2063384.2063405},
	language = {en},
	urldate = {2025-01-16},
	booktitle = {Proceedings of 2011 {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {ACM},
	author = {Salmon, John K. and Moraes, Mark A. and Dror, Ron O. and Shaw, David E.},
	month = nov,
	year = {2011},
	pages = {1--12},
}

@inproceedings{al_bahou_xnorbin_2018,
	address = {Yokohama},
	title = {{XNORBIN}: {A} 95 {TOp}/s/{W} hardware accelerator for binary convolutional neural networks},
	isbn = {978-1-5386-6103-1},
	shorttitle = {{XNORBIN}},
	url = {https://ieeexplore.ieee.org/document/8373076/},
	doi = {10.1109/CoolChips.2018.8373076},
	urldate = {2025-01-16},
	booktitle = {2018 {IEEE} {Symposium} in {Low}-{Power} and {High}-{Speed} {Chips} ({COOL} {CHIPS})},
	publisher = {IEEE},
	author = {Al Bahou, Andrawes and Karunaratne, Geethan and Andri, Renzo and Cavigelli, Lukas and Benini, Luca},
	month = apr,
	year = {2018},
	pages = {1--3},
}

@article{mula_faster_2018,
	title = {Faster {Population} {Counts} {Using} {AVX2} {Instructions}},
	volume = {61},
	issn = {0010-4620, 1460-2067},
	url = {http://academic.oup.com/comjnl/article/61/1/111/3852071},
	doi = {10.1093/comjnl/bxx046},
	language = {en},
	number = {1},
	urldate = {2025-01-16},
	journal = {The Computer Journal},
	author = {Muła, Wojciech and Kurz, Nathan and Lemire, Daniel},
	month = jan,
	year = {2018},
	pages = {111--120},
}

@inproceedings{khaldi_extending_2021,
	address = {St. Louis, MO, USA},
	title = {Extending {LLVM} {IR} for {DPC}++ {Matrix} {Support}: {A} {Case} {Study} with {Intel}$^{\textrm{®}}$ {Advanced} {Matrix} {Extensions} ({Intel}$^{\textrm{®}}$ {AMX})},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-66541-134-9},
	shorttitle = {Extending {LLVM} {IR} for {DPC}++ {Matrix} {Support}},
	url = {https://ieeexplore.ieee.org/document/9651301/},
	doi = {10.1109/LLVMHPC54804.2021.00008},
	urldate = {2025-01-16},
	booktitle = {2021 {IEEE}/{ACM} 7th {Workshop} on the {LLVM} {Compiler} {Infrastructure} in {HPC} ({LLVM}-{HPC})},
	publisher = {IEEE},
	author = {Khaldi, Dounia and Luo, Yuanke and Yu, Bing and Sotkin, Alexey and Morais, Bruno and Girkar, Milind},
	month = nov,
	year = {2021},
	pages = {20--26},
}

@misc{sule_implicant_2016,
	title = {Implicant based parallel all solution solver for {Boolean} satisfiability},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1611.09590},
	doi = {10.48550/ARXIV.1611.09590},
	abstract = {This paper develops a parallel computational solver for computing all satifying assignments of a Boolean system of equations defined by Boolean functions of several variables. While there are we known solvers for satisfiability of Boolean formulas in CNF form, these are designed primarily for deciding satisfiability of the formula and do not address the problem of finding all satisfying solutions. Moreover development of parallel solvers for satisfiability problems is still an unfinished problem of Computer Science. The solver proposed in this paper is aimed at representing all solutions of Boolean formulas even without the CNF form with a parallel algorithm. Algorithm proposed is applied to Boolean functions in algebraic normal form (ANF). The algorithm is based on the idea to represent the satisfying assignments in terms of a complete set of implicants of the Boolean functions appearing as factors of a Boolean formula. The algorithm is effective mainly in the case when the factors of the formula are sparse (i.e. have a small fraction of the total number of variables). This allows small computation of a complete set of implicants of individual factors one at a time and reduce the formula at each step. An algorithm is also proposed for finding a complete set of orthogonal implicants of functions in ANF. An advantages of this algorithm is that all solutions can be represented compactly in terms of implicants. Finally due to small and distributed computation at every step as well as computation in terms of independent threads, the solver proposed in this paper is expected to be useful for developing heuristics for a well scalable parallel solver for large size problems of Boolean satisfiability over large number of processors.},
	urldate = {2025-01-16},
	publisher = {arXiv},
	author = {Sule, Virendra},
	year = {2016},
	note = {Version Number: 3},
	keywords = {03G05, 06E30, 94C10, Data Structures and Algorithms (cs.DS), FOS: Computer and information sciences, I.1.2; F.2.2; G.2, Logic in Computer Science (cs.LO)},
}

@inproceedings{coudert_implicit_1992,
	address = {Anaheim, CA, USA},
	title = {Implicit and incremental computation of primes and essential primes of {Boolean} functions},
	isbn = {978-0-8186-2822-1},
	url = {http://ieeexplore.ieee.org/document/227866/},
	doi = {10.1109/DAC.1992.227866},
	urldate = {2025-01-16},
	booktitle = {[1992] {Proceedings} 29th {ACM}/{IEEE} {Design} {Automation} {Conference}},
	publisher = {IEEE Comput. Soc. Press},
	author = {Coudert, O. and Madre, J.C.},
	year = {1992},
	pages = {36--39},
}

@misc{teixeira_zettasticksbdd-fpga_2023,
	title = {zettasticks/{Bdd}-{Fpga}},
	url = {https://github.com/zettasticks/Bdd-Fpga},
	urldate = {2025-01-14},
	author = {Teixeira, Rúben},
	month = nov,
	year = {2023},
	note = {original-date: 2020-12-31T16:02:46Z},
}

@inproceedings{salem_farag_evaluating_2024,
	address = {Las Vegas, NV},
	title = {Evaluating {PRA} {Tools} for {Accurate} and {Efficient} {Quantifications}: {A} {Follow}-{Up} {Benchmarking} {Study} {Including} {FTREX}},
	shorttitle = {Evaluating {PRA} {Tools} for {Accurate} and {Efficient} {Quantifications}},
	doi = {doi.org/10.13182/T130-43377},
	abstract = {In the rapidly evolving technological landscape, probabilistic risk assessment (PRA) is increasingly essential in supporting decision-making and engineering processes across multiple industries, particularly in the nuclear sector. Central to the development and safety assurance of nuclear power plants (NPPs), PRA is crucial in navigating the challenges of complex system designs. This study addresses the limitations and current capabilities of traditional PRA tools and emphasizes the necessity for advancements to align with the evolving needs of the industry. We focus on event tree and fault tree analyses methods, widely used in PRA, utilizing tools like SAPHIRE (with SAPHSOLVE engine), Phoenix Architect (CAFTA with PRAQuant and FTREX engines), XFTA engine, and the recent OpenPRA's SCRAM-cpp (previously called SCRAM) open-source engine. Our study extends previous benchmarking to include the industry most utilized FTREX engine. We conduct a detailed evaluation of SAPHSOLVE, FTREX, XFTA, and SCRAM-cpp, using synthetic fault trees of varying specifications and complexities. The analysis aims to assess the accuracy and efficiency of these tools in terms of time and memory use for calculating top event failure probabilities and minimal cut sets. The results will inform enhancements of current PRA tools and contribute to the development of the OpenPRA software platform moving towards improved PRA methodologies in the nuclear industry.},
	publisher = {American Nuclear Society},
	author = {Salem Farag, Asmaa and Wood, S and Earthperson, Arjun and Aras, Egemen and Boyce, Jordan and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{wood_advancing_2024,
	address = {Las Vegas, NV},
	title = {Advancing {SAPHIRE}: {Transitioning} from {Legacy} to {State}-of-{Art} {Excellence}},
	shorttitle = {Advancing {SAPHIRE}},
	doi = {doi.org/10.13182/T130-43357},
	abstract = {Over its 35-year evolution, Systems Analysis Programs for Hands-on Integrated Reliability Evaluations (SAPHIRE) has embraced technological advancements, yet opportunities for improvement persist. Specifically, challenges in quantifying large models, model tracking, and facilitating model exchange have spurred our unique research roadmap. Our research begins with the extraction and enhancement of key solvers within SAPHIRE, including the fault tree solver, event tree/sequence solver, cut set updater, cut set post-processor, event tree linker, cut set partition processor, change set processor, uncertainty sampler, and end state gather. These enhancements target existing bottlenecks to elevate the SAPHIRE experience. Notably, the process introduces a cloud-based solving option, offering users the flexibility to employ SAPHIRE on their desktop or in a cloud environment. This solution streamlines model exchange and efficient model tracking and enhances computational resources, reducing model-solving time. This paper provides an overview of the processing engines within SAPHIRE, outlining their goals and the roadmap for achieving state-of-the-art excellence. The initiative successfully extracts processing engines, paving the way for a cloud-based solve option. Emphasizing security, comprehensive measures are in place to fortify the security of SAPHIRE's cloud solution.},
	publisher = {American Nuclear Society},
	author = {Wood, Stephen and Boyce, Jordan and Aras, Egemen and Salem Farag, Asmaa and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{aras_enhancing_2024,
	address = {Las Vegas, NV},
	title = {Enhancing the {SAPHIRE} {Solve} {Engine}: {Initial} {Progress} and {Efforts}},
	shorttitle = {Enhancing the {SAPHIRE} {Solve} {Engine}},
	doi = {doi.org/10.13182/T130-43361},
	abstract = {Improving methods and tools used for reactor safety, whether deterministic or probabilistic, is crucial. This research aims to address the current status of a tool vital for probabilistic safety approaches, showcasing initial progress alongside a roadmap for future development. This investigation focuses on the SAPHIRE Solve Engine (SAPHSOLVE), which plays a pivotal role in transitioning from legacy systems to state-of-the-art excellence. Key objectives include efficiently handling large models, enabling seamless model exchange with other tools, and ensuring robust model tracking capabilities. The ongoing efforts involve extracting and enhancing processing engines within the SAPHIRE API, with a specific emphasis on secure cloud solving in addition to existing desktop capabilities. The current initiative concentrates on enhancing SAPHSOLVE, requiring a detailed analysis. This involves a benchmarking approach comprising performance assessments and source code analysis to identify bottlenecks and optimize quantification performance. Synthetically generated models facilitate the model generation process, a crucial step in these endeavors. The benchmarking results underscore SAPHSOLVE's proficiency, with the Windows version demonstrating superior performance compared to the Linux version. Notably, the truncation size of cut sets significantly affects quantification time. Addressing bottlenecks in the source code has led to an average 29\% increase in speed. Ongoing efforts are focused on further enhancements and exploring parallel processing capabilities. The pursuit of enhanced performance extends to two distinct approaches: shared data parallelization for low-level implementations and distributed data parallelization for high-level implementations within SAPHSOLVE.},
	publisher = {American Nuclear Society},
	author = {Aras, Egemen and Wood, Stephen and Boyce, Jordan and Salem Farag, Asmaa and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{lee_data_2024,
	address = {Las Vegas, NV},
	title = {Data {Updating} {Model} {Development} with {Bayesian} {Inference} for {Data} {Analysis} for {Probabilistic} {Risk} {Assessment} {Application}},
	doi = {doi.org/10.13182/T130-43386},
	abstract = {This study enhances Probabilistic Risk Assessment (PRA) for advanced non-Light Water Reactor (non-LWR) nuclear power plants by focusing on data analysis that extends beyond numerical data to include uncertainty-related information. In this methodology, risk quantification is achieved through the establishment of parameters and their boundaries, utilizing both generic industry benchmarks and specific plant data. A crucial aspect of this approach is the ability to trace data analysis, addressing a notable deficiency in data sources for advanced non-LWR PRA. To overcome this challenge, the NUREG/CR-6928 dataset, representing the Industry-Average Performance for Components and Initiating Events at U.S. Commercial Nuclear Power Plants, is employed. Given its periodic updates, there is a need for consistent data management within the PRA model. To address this, the research introduces an automatic data updating model. This model supports PRA development by providing updated component reliability data with associated uncertainties and facilitates updates to common cause failure parameters through automated grouping. The data updating model ensures efficient transition and conversion of raw datasets for application within the PRA framework. It allows for the manipulation of PRA model data to align with user-specific requirements, using reference values from the NUREG/CR-6928 dataset. Moreover, the model aids in tracking data sources, changes, and related information, maintaining detailed traces, including metadata. This ensures the data characteristics are constantly updated based on new evidence and expert judgment, which will be processed through Bayesian inference in future tasks. Ultimately, this approach significantly enhances the efficiency of PRA teams in integrating and updating data. By enabling more precise and current risk quantification, it ensures a more accurate representation of risk in advanced non-LWR nuclear power plants. This methodology not only enhances the reliability of risk assessments but also contributes to the overall safety and efficiency of nuclear power plant operations.},
	publisher = {American Nuclear Society},
	author = {Lee, Joomyung and Mustafa, Rawan and Hamza, Mostafa and Retourne, Olivier and Liao, Huafei and Lawson, Glen and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{alzahrani_quantification_2024,
	address = {Las Vegas, NV},
	title = {Quantification of {In}-{Containment} {Mechanistic} {Source} {Term} for {Advanced} {Light} {Water} {Reactor}},
	doi = {doi.org/10.13182/T130-43338},
	abstract = {This paper addresses the need for a dynamic approach in evaluating severe accident source terms for Nuclear Power Plants (NPPs), particularly in the early design phase where specific source term evaluations are often lacking. Traditional source term evaluation methods, such as the mechanism and parametric approaches, face implementation challenges and may not align with cost-benefit assessments. In response, this paper will present a simplified approach tailored for the assessment of hypothetical severe accident source terms for an advanced light water reactor. The approach involves the establishment of a simplified containment event tree, encompassing various representative cases, weighted coefficient evaluation, computation of source term cases, and weighted computation. It categorizes potential containment releases into five distinct categories: containment bypass, containment isolation failure, containment early failure, containment late failure, and intact containment. The primary objective of this research is to develop a comprehensive modeling and simulation framework for quantifying and analyzing the behavior of in-containment fission products (FPs) during typical accident scenarios to support full scope probabilistic risk assessment model development using dynamic probabilistic risk assessment. To achieve this, a kinetic model has been implemented to assess the quantification and behavior of in-containment source terms following a loss of feedwater and in containment passive safety systems scenario. The study takes a more realistic approach by considering the continuous release of fission products from a damaged core while accounting for coolant retention. It also investigates the quantification of in-containment fission products, considering the influence of the containment atmosphere and the response of the containment system. The implementations are open sourced in the Mechanistic Source Term for Light Water Reactor (MSTLWR) code part of the web based OpenPRA software stack.},
	publisher = {American Nuclear Society},
	author = {Alzahrani, Yahya and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{aras_introducing_2024,
	address = {Las Vegas, NV},
	title = {Introducing {OpenPRA}'s {Quantification} {Engine}: {Exploring} {Capabilities}, {Recognizing} {Limitations}, and {Charting} the {Path} to {Enhancement}},
	shorttitle = {Introducing {OpenPRA}'s {Quantification} {Engine}},
	doi = {doi.org/10.13182/T130-43362},
	abstract = {Probabilistic Risk Assessment (PRA) is a pivotal process, serving as the cornerstone of risk-informed decision-making for critical infrastructure sectors such as aerospace, chemical, and nuclear industries. It provides a dynamic engineering and scientific framework that underpins these vital systems, from their initial design phases to eventual decommissioning. PRA thrives on adaptability, accommodating the ramifications of deterministic analyses, design alterations, operational shifts, environmental changes, and evolving regulations to update and refine its risk assessments continually. While PRA tools have existed for over three and a half decades, they have made substantial contributions to these industries. Nevertheless, the contemporary landscape demands the acknowledgment of challenges faced by current PRA tools and, more importantly, the formulation of innovative solutions to address them. These challenges encompass the need for more efficient model construction, seamless model exchange between diverse tools, streamlined model quantification, and the incorporation of multi-hazard risk assessments. In response to these imperatives, we introduce scram-cpp and its node.js wrapper, scram-node, an emerging probabilistic risk assessment quantification engine developed under the open-source web-based OpenPRA software stack. Building upon the foundational work of the legacy SCRAM project, this open-source endeavor aspires to confront the current challenges plaguing PRA tools and pave the way for transformative solutions across all legacy PRA tools.},
	publisher = {American Nuclear Society},
	author = {Aras, Egemen and Earthperson, Arjun and Rasheeq, Hasibul and Salem Farag, Asmaa and Wood, Stephen and Boyce, Jordan and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{hamza_state_2024,
	address = {Las Vegas, NV},
	title = {The {State} of {Art} of the {Human} {Failure} {Events} {Dependency} {Analysis} {Methods}},
	doi = {doi.org/10.13182/T130-43380},
	abstract = {Probabilistic risk assessment (PRA) made its inaugural appearance in the realm of safety studies, heralding a transformative approach to the comprehensive and realistic estimation of risks associated with various accidents, as opposed to the traditionally conservative estimates. The crux of human reliability analysis (HRA), an essential technical element in the PRA model, revolves around the identification and quantification of operator actions and associated human failure events (HFE). Numerous HRA methodologies are in existence, each offering distinctive approaches to quantifying human error probability (HEP) linked to diverse HFEs. A pivotal facet of constructing an HRA model involves the assessment of dependencies between different HFEs. Many existing HRA methodologies rely on the dependency model introduced by the Technique for Human Error Prediction (THERP), while other methods encompass various approaches, spanning from in-depth qualitative assessments to the application of Bayesian belief networks (BBN). This paper delves into the diverse approaches employed by various HRA methodologies for conducting dependency analysis. It furnishes an overview of the dependency analysis model embraced by each major HRA method. To facilitate clarity, we introduce high-level categories for classifying these distinct dependency analysis approaches, elucidating the associated limitations for each category. Ultimately, we propose a framework to address these limitations and enhance the versatility of these categories, marking an initial stride toward their mitigation.},
	publisher = {American Nuclear Society},
	author = {Hamza, Mostafa and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{oconnell_primary_2024,
	address = {Las Vegas, NV},
	title = {Primary {Site} {Selection} for {Air} {Freight} {Transport} of {Department} of {Defense} {Microreactors}},
	doi = {doi.org/10.13182/T130-43395},
	abstract = {In recent years, there has been a growing interest in microreactors as readily available, cost-competitive, and environmentally friendly energy sources. This heightened focus has led to an increased need for the safe and efficient transportation of nuclear materials, irradiated waste products, and operational Micro-Nuclear reactors. Transporting cargo by air is highly effective compared to other modes of transportation for several reasons. It provides rapid transit times, reduces delays for time-sensitive shipments, and involves minimal intermediate handling, lowering the risk of damage and simplifying logistics. Air transport is renowned for its reliability due to strict schedules and fewer weather-related disruptions, and it offers enhanced security measures at airports, reducing exposure to theft or damage. These combined advantages make air shipping a highly effective and secure choice for transporting sensitive shipments such as Micro-Nuclear reactors. PRA is a useful tool to evaluate and quantify the risk of shipping of microreactors from different airfields, as well as comparing the risk posed by the site itself to the risk of the ground transport to the site. In this paper, we will present a framework to select suitable airports in the United States land for transportable Micro-Nuclear reactors for the Department of Defense. Based on the available information and data, events trees model will be developed to provide the context necessary to inform decision makers on the best courses of action for selecting sites to transport microreactor packages from. The goal of this paper is to quantify the probabilistic risk of different selected sites, ultimately providing recommendations with supporting evidence to reduce the risk to the public while maintaining the efficiency benefits of utilizing air shipping.},
	publisher = {American Nuclear Society},
	author = {O'Connell, Thomas and Alzahrani, Yahya and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{earthperson_quantifying_2024,
	address = {Las Vegas, NV},
	title = {Quantifying {Safety} {System} {Unavailability} {Margins} via {Inverse} {Estimation} of {Event} {Sequence} {Frequencies}},
	abstract = {Ensuring the reliability and effectiveness of nuclear safety systems is paramount for preventing severe accidents and ensuring operational safety. This study introduces a method for quantifying the unavailability margins of safety systems, employing inverse estimation techniques to deduce event sequence frequencies. The proposed method is demonstrated on a case study involving a liquid metal fire scenario from the Experimental Breeder Reactor-II (EBR-II) Level 1 probabilistic risk assessment (PRA). Uncertainties are modeled by assuming log-normal distributions for all events. For a demonstrative event tree with known end-state frequencies, our method accurately deduced the probabilities of functional events within a small error margin. The results show errors of approximately (1.08 ± 0.96)\% for the means, (4.39 ± 7.09)\% for the 5 th , and (3.82 ± 5.91)\% for the 95 th percentiles, respectively. The analysis highlights the method's strengths, such as its ability to estimate distributions for rare events, but also notes limitations, including dependence on specific distribution assumptions and challenges in optimization techniques. Despite these, the case study's results offer the potential for drawing insights for improving safety system design and operational strategies. Additionally, we have made this method available as an open-source Python tool named inverse-canopy, part of the OpenPRA toolkit [1]. The study concludes by discussing the potential of this methodology for broader application in PRAs and suggests future work to expand it into a Bayesian inverse uncertainty quantification framework.},
	publisher = {American Nuclear Society},
	author = {Earthperson, Arjun and Pandit, Priyanka and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{salem_farag_aalo_2024,
	address = {Las Vegas, NV},
	title = {Aalo {Atomics}' {High} {Level} {Licensing} {Strategy}},
	abstract = {Aalo Atomics, a mission-oriented startup is dedicated to deploying commercially viable microreactors rapidly into the market to support timely transition to clean energy generation. A critical part of our rapid deployment strategy is our Adopt, Adapt, and Advance approach (the 3-A approach) which entails 1) leveraging (adopting), to the maximum extent possible, the best available products (e.g., technologies, processes, tools, etc.) 2) making incremental improvements to (adapting) other available products to add value from the safety and commercial viability points of view , and 3) making transformational changes to (advancing) very specific targeted areas to make a step-wise improvement to the commercial viability attribute. For example, we are leveraging the U.S. Department of Energy (DOE)'s MARVEL a highly promising NaK-cooled thermal spectrum microreactor, which its development was led by Idaho National Laboratory (INL), as the foundation for our technology for the energy generation. We plan to adapt certain design features of MARVEL, to enable higher energy production capability, and we plan to advance the key deployment and operations attributes (e.g., construction speed, outage duration, and operational flexibility, etc.) to make a step change in commercial viability. We also plan to use the same 3-A approach to establish a licensing basis for our plants that support full realization of the promise of this game changing plant by maximizing design and operational flexibility and predictability while ensuring the performance objectives of the regulations, are met with minimal to no unnecessary regulatory burden. This paper describes some of the foundational elements of this strategy. It should be noted that we expect practical considerations, such as available time and resources, may result in a progressive deployment of some of the elements but the licensing basis of our nth of a kind (NOAK) plant will fully include the following elements: • A risk-informed and performance-based (RIPB) safety case for addressing risk to the public that is built by adopting Regulatory Guide-1.233 and its complementary guidance, such as the guidance being developed for establishing Emergency Planning Zone (EPZ). We will adapt this guidance for addressing worker safety and environmental impact. • We will use Technology Inclusive Content of Application (TICAP) and Advanced Reactors Content of Application (ARCAP) guidance to prepare our Combined License Application (COLA). • We plan to establish fully RIPB-based operational programs by adopting those that are under development, such as RIPB change evaluation (TIRICE), and adapting the available * madiacon@ncsu.edu},
	publisher = {American Nuclear Society},
	author = {Salem Farag, Asmaa and Afzali, Amir and Arafat, Yasir and Loszak, Matt and Earthperson, Arjun and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{pandit_leveraging_2024,
	address = {Las Vegas, NV},
	title = {Leveraging {Inverse} {Uncertainty} {Quantification} to {Enhance} the {Resilience} of {Nuclear} {Power} {Plant} {Construction} {Duration} {Estimation}},
	doi = {doi.org/10.13182/T130-43602},
	publisher = {American Nuclear Society},
	author = {Pandit, Priyanka and Earthperson, Arjun and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{mustafa_addressing_2024,
	address = {Las Vegas, NV},
	title = {Addressing {Uncertainties} {Across} {All} {Design} {Stages} of {Advanced} {Reactors} {Development}},
	abstract = {The development of advanced reactors represents a crucial milestone in the pursuit of sustainable and efficient energy sources. However, this journey is riddled with inherent uncertainties, at various stages of the design process. This paper offers a comprehensive approach to manage and mitigate uncertainties throughout the entire development of advanced reactors, spanning from the initial conceptualization to the final implementation. Specific emphasis is placed on the application of probabilistic risk assessment (PRA) as a fundamental tool for addressing and estimating these uncertainties during the design phase which can help in improving the design by iterations process to get to optimal design. Each design stage introduces unique complex sets of uncertainties. To exemplify the need to quantify and analyze these uncertainties, a case study on the advanced high temperature gas cooled reactor is presented to illustrate at what point do these uncertainties have a significant impact, the role and the impact of expert judgment in managing related uncertainties via Bayesian inference techniques is evaluated. Uncertainties in advanced reactor development can be broadly categorized into epistemic and aleatory uncertainties. Epistemic uncertainties arise from a lack of knowledge and can often be reduced through research and data acquisition. Aleatory uncertainties, on the other hand, are inherent and irreducible variations that require innovative risk management strategies. This paper delves into the differentiation of these uncertainty types and explores how addressing each type across all design stages is critical for the holistic management of advanced reactor uncertainties.},
	publisher = {American Nuclear Society},
	author = {Mustafa, Rawan and Hamza, Mostafa and Alzahrani, Yahya and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{hamza_applicability_2024,
	address = {Las Vegas, NV},
	title = {On the {Applicability} of the {General} {Transient} {Initiating} {Event} {Group} for {Advanced} {Reactors}},
	doi = {doi.org/10.13182/T130-43383},
	abstract = {Probabilistic risk assessment (PRA) was first introduced in the first safety study, which was the first approach to comprehensively and realistically, rather than conservatively, estimate the risk associated with different accidents. Identifying, grouping, and quantifying a complete list of initiating events is one of the first steps in building a PRA model. An extensive operational history for light-water reactors (LWR) comprised an initial list of initiating events that can be readily used by conventional nuclear power plants. Of those initiating events, general transient groups different plant perturbation that results in a reactor trip while not degrading the response of safety systems. This initiating event group includes 23 different wide-range subcategories that result in either manual or automatic reactor trip. However, the non-light-water-reactor PRA standard sets criteria for grouping initiating events. According to the standard, initiating events may be grouped only if they "can be considered similar in terms of plant response, success criteria, timing, and the effect on performance of operators and the operability of relevant mitigating systems" or "can be bounded by the worst-case impacts within the group." For advanced reactors, the plant response to different transient is not generalized. Depending on the set points exceeded, the reactor protection system's (RPS) response would be different. In other words, the plant response, available mitigating systems, and success criteria would differ greatly depending on the transient. Hence, the definition of the general transient initiating event group does not meet the non-LWR PRA standard's criteria for grouping initiating events. In this paper, the general transient initiating event group is decomposed to assess the expected set point associated with each transient subcategory. Following this decomposition, the applicability of the grouping of these transient subcategories, along with the grouping of general transient itself, is assessed against the criteria set by the non-LWR PRA standard. Finally, a more applicable delineation approach is presented and discussed to meet the standard requirements and ensure the completeness and validity of the initiating event group list.},
	publisher = {American Nuclear Society},
	author = {Hamza, Mostafa and Liao, Huafei and Cursey, Mark and Fleming, Karl and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{earthperson_towards_2024,
	address = {Las Vegas, NV},
	title = {Towards a {Deep}-{Learning} based {Heuristic} for {Optimal} {Variable} {Ordering} in {Binary} {Decision} {Diagrams} to {Support} {Fault} {Tree} {Analysis}},
	abstract = {This pilot study addresses the challenge of optimizing variable ordering in binary decision diagrams (BDDs) for fault tree analysis within probabilistic risk assessment, with a specific focus on addressing the unique challenges posed by advanced nuclear reactors. Advanced reactors, including small modular reactors, present novel operational and safety complexities that demand enhanced computational tools for their safety analysis. The efficiency of BDDs, pivotal in evaluating the reliability of the intricate safety systems of these reactors, is significantly influenced by the sequence in which variables are ordered-a problem recognized as NP-hard. We propose a deep-learning-based heuris-tic, leveraging transformer-backed sequence-to-sequence models, to approximate near-optimal variable ordering for BDDs generated from system fault trees. Our approach involves the development of a representative dataset of boolean functions and their corresponding BDDs, detailing the process of tokenization, numericalization, and normalization of data to train the model effectively. The architecture incorporates an embedding layer, multiple transformer blocks, and a dense layer for sequence predictions, trained using a custom loss function that emphasizes the reduction of larger BDDs for computational efficiency. The model's performance, evaluated through metrics such as multi-class sequence accuracy, reveals a notable challenge in achieving high sequence accuracy, indicating a difficulty in capturing the complex dependencies necessary for optimal variable ordering. Despite a marginal improvement in individual predictions within sequences, the model struggles with the complete and correct prediction of variable orderings, as evidenced by low sequence accuracy metrics observed during training and validation phases. To address these limitations, we propose potential improvements, including the exploration of alternative loss metrics such as connectionist-temporal classification loss, which may better suit the sequence prediction nature of the problem. Additionally, we suggest architectural enhancements and a re-evaluation of the training strategy to improve the model's ability to learn sequential dependencies. This research lays a foundational step towards harnessing deep learning models for solving combinatorial optimization problems in reliability analysis of complex advanced reactor safety systems.},
	publisher = {American Nuclear Society},
	author = {Earthperson, Arjun and Aras, Egemen and Salem Farag, Asmaa and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{pandit_laying_2024,
	address = {Las Vegas, NV},
	title = {Laying the {Foundations} for the {Development} of a {Probabilistic} {Model} {Checking} {Method} to {Quantify} {Common} {Cause} {Failure} {Parameters} in {Digital} {Instrumentation} and {Control}},
	doi = {doi.org/10.13182/T130-43603},
	abstract = {This paper delves into the critical need for a simulation-based framework to aid the evaluation of the reliability of digital Instrumentation and Control (I\&C) systems in advanced nuclear power plants, as the industry transitions from analog to digital systems. With limited operational history for digital I\&C systems, simulation-based methods are essential to comprehend their failure modes including Common Cause Failures (CCFs). When two or more components/systems fail due to a single shared cause and coupling mechanism within the specified mission time, we call the failures CCFs. They are quantified using models such as the alpha factor model whose parameters are developed from extensive operational data from nuclear power plants. In this paper, the focus is on laying the groundwork for utilizing Probabilistic Model Checking (PMC) to quantify Common Cause Failure parameters in digital I\&C systems. We selected the causal alpha factor model for the analysis, as it lends itself very well to the development of parameters from operational or simulation data. Along with the causal alpha factor model, we have also selected a digital I\&C component, the Field Programmable Gate Array (FPGA), inspired by its use in commercial nuclear I\&C systems intended for advanced reactors, analyzed its failure causes and classified them according to the system recommended for the causal alpha factor method. By exploring the development of CCF parameters and the application of probabilistic model checking for formal verification of CCFs, this research aims to develop the foundation for modeling the shared causes and the coupling mechanisms of digital I\&Cs in support of developing a simulation-driven database of CCF parameters for digital I\&C systems.},
	publisher = {American Nuclear Society},
	author = {Pandit, Priyanka and Earthperson, Arjun and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{earthperson_implementing_2024,
	address = {Las Vegas, NV},
	title = {Implementing {Multiple} {Control} {Paths} in the {Dual} {Error} {Propagation} {Graph} for {Stochastic} {Failure} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems}},
	url = {https://epubs.ans.org/?a=56419},
	doi = {doi.org/10.13182/T130-43400},
	abstract = {Advanced nuclear reactors are ushering in a transformative era in the nuclear energy sector, characterized by generational advancements in safety, efficiency, and sustainability. Central to realizing the advanced reactor philosophy is the integration of digital instrumentation and control (I\&C) systems, which are critical for enhancing the operational integrity, economic viability, and safety of advanced reactor designs. Designed to be vastly more complex than their analog counterparts, digital I\&Cs offer comparatively superior control, diagnostic capabilities, and adaptability. However, added complexity makes failures of such systems inherently hard to describe, let alone predict, due, in part, to their potential for propagating internal errors in manners that are often unintuitive and opaque. Consequently, the use of digital I\&Cs poses new challenges to qualifying reactor safety. Addressing these challenges requires a fundamental rethinking of probabilistic failure modeling. The dual error propagation method (DEPM) is a stochastic technique that allows us to induce and track failure behavior by explicitly representing a system in terms of its control and data flows-two attributes that are sufficient to adequately describe combinatorial logic. However, the physical processes underlying digital systems, like all natural processes, are inherently co-incident. So far, the nature of abstraction requires DEPM models to be sequential and time-agnostic, leading to fundamental inconsistencies that are accepted nonetheless by relaxing modeling assumptions. This paper is an extension to our previous work introducing the concept of multiple control paths within DEPM, aimed to address its sequential limitations. Through a case study on basic digital logic building blocks, we showcase the improved expressivity afforded by multi-control DEPM, emphasizing its potential and limitations in supporting the reliability analysis of larger, more complex digital I\&Cs. Our analysis demonstrates that while multi-control DEPM is feasible, it is fundamentally limited by its inability to explicitly model time. Consequently, accurately modeling race conditions, concurrency, and synchronization without compromising modeling assumptions remains unachievable. Furthermore, multi-control DEPM is computationally expensive due to an exponential increase in the number of modeled states with each added control flow. The issue of this so-called state-space explosion stays largely unresolved within DEPM as a whole. Given these limitations, we conclude by proposing future research directions, including the exploration of alternative time-explicit modeling techniques and strategies for managing model complexity, with a deeper case study to follow.},
	publisher = {American Nuclear Society},
	author = {Earthperson, Arjun and Pandit, Priyanka and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@inproceedings{capogrosso_hermesbdd_2023,
	title = {{HermesBDD}: {A} {Multi}-{Core} and {Multi}-{Platform} {Binary} {Decision} {Diagram} {Package}},
	doi = {10.1109/ddecs57882.2023.10139480},
	booktitle = {26th {International} {Symposium} on {Design} and {Diagnostics} of {Electronic} {Circuits} and {Systems} ({DDECS})},
	author = {Capogrosso, Luigi and Geretti, Luca and Cristani, Marco and Fummi, Franco and Villa, Tiziano},
	year = {2023},
}

@article{mrena_teddy_2024,
	title = {{TeDDy}: {Templated} decision diagram library},
	volume = {26},
	issn = {23527110},
	shorttitle = {{TeDDy}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352711024000864},
	doi = {10.1016/j.softx.2024.101715},
	language = {en},
	urldate = {2025-01-13},
	journal = {SoftwareX},
	author = {Mrena, Michal and Kvassay, Miroslav and Zaitseva, Elena},
	month = may,
	year = {2024},
	pages = {101715},
}

@article{somenzi_cudd_2009,
	title = {{CUDD}: {CU} decision diagram package-release 2.4. 0},
	volume = {21},
	journal = {University of Colorado at Boulder},
	author = {Somenzi, Fabio},
	year = {2009},
}

@article{steinbach_compact_2018,
	title = {Compact {XOR}-bi-decomposition for lattices of {Boolean} functions},
	volume = {31},
	copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {0353-3670, 2217-5997},
	url = {https://doiserbia.nb.rs/Article.aspx?ID=0353-36701802223S},
	doi = {10.2298/FUEE1802223S},
	abstract = {Bi-Decomposition is a powerful approach for the synthesis of multi-level
   combinational circuits because it utilizes the properties of the given
   functions to find small circuits, with low power consumption and low delay.
   Compact bi-decompositions restrict the variables in the support of the
   decomposition functions as much as possible. Methods to find compact AND-,
   OR-, or XOR-bi-decompositions for a given completely specified function are
   well known. Lattices of Boolean Functions significantly increase the
   possibilities to synthesize a minimal circuit. However, so far only methods
   to find compact AND- or OR-bi-decompositions for lattices of Boolean functions
   are known. This gap, i.e., a method to find a compact XOR-bi-decomposition
   for a lattice of Boolean functions, has been closed by the approach
   suggested in this paper.
          , 
            nema},
	language = {en},
	number = {2},
	urldate = {2025-01-13},
	journal = {Facta universitatis - series: Electronics and Energetics},
	author = {Steinbach, Bernd and Posthoff, Christian},
	year = {2018},
	pages = {223--240},
}

@incollection{steinbach_alternative_2015,
	address = {Cham},
	title = {Alternative {Approaches} for {Fast} {Boolean} {Calculations} {Using} the {GPU}},
	isbn = {978-3-319-15720-7},
	url = {https://doi.org/10.1007/978-3-319-15720-7_2},
	abstract = {The growing number of Boolean variables requires very efficient approaches to solve the given tasks. We explore the utilization of the GPU for fast parallel Boolean calculations in this chapter. Hundreds of processor cores of the GPU offer a significant potential for improvements. Constraints in their application may restrict the achievable speedup. This chapter gives a taxonomy about possible approaches to solve a problem using a computer. We select one problem from the Boolean domain and summarize alternative approaches for utilizing the GPU. It will be shown that the calculation time could be reduced by several orders of magnitudes for the selected Unate Covering Problem.},
	language = {en},
	urldate = {2025-01-13},
	booktitle = {Computational {Intelligence} and {Efficiency} in {Engineering} {Systems}},
	publisher = {Springer International Publishing},
	author = {Steinbach, Bernd and Werner, Matthias},
	editor = {Borowik, Grzegorz and Chaczko, Zenon and Jacak, Witold and Łuba, Tadeusz},
	year = {2015},
	doi = {10.1007/978-3-319-15720-7_2},
	pages = {17--31},
}

@incollection{steinbach_concepts_2022,
	address = {Cham},
	title = {The {Concepts} of {XBOOLE}},
	isbn = {978-3-030-88945-6},
	url = {https://doi.org/10.1007/978-3-030-88945-6_1},
	abstract = {A logic function that depends on n variables specifies 2n function values. The maximal number of solutions of a logic equation of n variables is also equal to 2n. This exponential increasing number of elements limits the number of logic variables in tasks that can be successfully solved by human beings; hence, computers must be used to solve tasks beyond a certain limit of logic variables. Programming languages of computers can store and manipulate single logic variables or bounded vectors of logic values. The creation of programs that solve challenging logic problems requires comprehensive skills in programming and is time consuming due to the low level of available elements of the programming language. To close this gap, we developed the XBOOLE-system that can efficiently store and manipulate logic functions and solution-sets of logic equations. In this chapter, we explain the concepts of XBOOLE in a compact manner. This background knowledge about XBOOLE supports the readers of this textbook to solve the exercises provided in the following chapters.},
	language = {en},
	urldate = {2025-01-13},
	booktitle = {Logic {Functions} and {Equations}: {Fundamentals} and {Applications} using the {XBOOLE}-{Monitor}},
	publisher = {Springer International Publishing},
	author = {Steinbach, Bernd and Posthoff, Christian},
	editor = {Steinbach, Bernd and Posthoff, Christian},
	year = {2022},
	doi = {10.1007/978-3-030-88945-6_1},
	pages = {3--12},
}

@incollection{steinbach_extremely_2022,
	address = {Cham},
	title = {Extremely {Complex} {Problems}},
	isbn = {978-3-030-88945-6},
	url = {https://doi.org/10.1007/978-3-030-88945-6_10},
	abstract = {The problem of rectangle-free assignments of four colors to a grid will be explored in this chapter. This problem can also be considered as a problem of Ramsey numbers. Nether theoretical approaches of mathematicians nor programs running on the largest computers were able to solve this task for the grids 17 × 17, 17 × 18, 18 × 17, 18 × 18, 12 × 21, and 21 × 12 before we solved these problems. The reason for that is the extreme complexity of 5.23 ∗ 10151 for the grid 12 × 21 and even 1.17 ∗ 10195 for the grid 18 × 18. We will show that it is not sufficient to use logic equations; many other mathematical concepts also have to be used in order to solve the problem using a usual PC. We started this research because we wanted to know how far the power of logic equations and of ternary vectors will reach to solve a problem of this extreme complexity. The successful solution of such a complex problem can be taken as the borderline for the solution of similar problems. The detailed steps of the solution for the grids 18 × 18 and 12 × 21 are completely different; however, the general approach of a very deep analysis and utilization of all properties of the problem guided us to the successful solutions.},
	language = {en},
	urldate = {2025-01-13},
	booktitle = {Logic {Functions} and {Equations}: {Fundamentals} and {Applications} using the {XBOOLE}-{Monitor}},
	publisher = {Springer International Publishing},
	author = {Steinbach, Bernd and Posthoff, Christian},
	editor = {Steinbach, Bernd and Posthoff, Christian},
	year = {2022},
	doi = {10.1007/978-3-030-88945-6_10},
	pages = {543--578},
}

@incollection{steinbach_thirty-six_2023,
	address = {Cham},
	title = {Thirty-{Six} {Officers} of {Euler}-{New} {Insights} {Computed} {Using} {XBOOLE}},
	isbn = {978-3-031-28916-3},
	url = {https://doi.org/10.1007/978-3-031-28916-3_10},
	abstract = {This chapter deals with a problem specified by the outstanding Mathematician Leonhard Euler more than 200 years ago. He asked whether it is possible to place 36 officers, which differ in both six regiments and six ranks, on a square so that each row and column contain one officer of each rank and of each regiment? A straightforward SAT model of this problem using the one-hot encoding would require 1296 Boolean variables and more than 100,000 clauses. Hence, we have to solve a very complex problem. Euler found no solution for this problem and conjectured that no solution exist. We modified the question into “what is the maximal number of officers that satisfy all conditions of Euler and how many such maximal solutions exist?” Utilizing equivalence classes and a CDC-SAT model, we found the solutions of these questions as result of the intersections of 30 DC-clauses by means of the XBOOLE-monitor XBM 2.},
	language = {en},
	urldate = {2025-01-13},
	booktitle = {Advanced {Boolean} {Techniques}: {Selected} {Papers} from the 15th {International} {Workshop} on {Boolean} {Problems}},
	publisher = {Springer International Publishing},
	author = {Steinbach, Bernd and Posthoff, Christian},
	editor = {Drechsler, Rolf and Huhn, Sebastian},
	year = {2023},
	doi = {10.1007/978-3-031-28916-3_10},
	pages = {135--154},
}

@inproceedings{de_alfaro_symbolic_2000,
	address = {Berlin, Heidelberg},
	title = {Symbolic {Model} {Checking} of {Probabilistic} {Processes} {Using} {MTBDDs} and the {Kronecker} {Representation}},
	isbn = {978-3-540-46419-8},
	doi = {10.1007/3-540-46419-0_27},
	abstract = {This paper reports on experimental results with symbolic model checking of probabilistic processes based on Multi-Terminal Binary Decision Diagrams (MTBDDs). We consider concurrent probabilistic systems as models; these allow nondeterministic choice between probability distributions and are particularly well suited to modelling distributed systems with probabilistic behaviour, e.g. randomized consensus algorithms and probabilistic failures. As a specification formalism we use the probabilistic branching-time temporal logic PBTL which allows one to express properties such as “under any scheduling of nondeterministic choices, the probability of φ holding until ψ is true is at least 0.78/at most 0.04”. We adapt the Kronecker representation of (Plateau 1985), which yields a very compact MTBDD encoding of the system. We implement an experimental model checker using the CUDD package and demonstrate that model construction and reachability-based model checking is possible in a matter of seconds for certain classes of systems consisting of up to 1030 states.},
	language = {en},
	booktitle = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
	publisher = {Springer},
	author = {de Alfaro, Luca and Kwiatkowska, Marta and Norman, Gethin and Parker, David and Segala, Roberto},
	editor = {Graf, Susanne and Schwartzbach, Michael},
	year = {2000},
	keywords = {Boolean Variable, Continuous Time Markov Chain, Markov Decision Process, Model Check, Probabilistic Process},
	pages = {395--410},
}

@inproceedings{milvang-jensen_bddnow_1998,
	address = {Berlin, Heidelberg},
	title = {{BDDNOW}: {A} {Parallel} {BDD} {Package}},
	isbn = {978-3-540-49519-2},
	shorttitle = {{BDDNOW}},
	doi = {10.1007/3-540-49519-3_32},
	abstract = {BDDs (binary decision diagrams) are ubiquitous in formal verification tools, and the time and memory used by the BDD package is frequently the constraint that prevents application of formal verification. Accordingly, several researchers have investigated using parallel processing for BDDs. In this paper, we present a parallel BDD package with several novel features. The parallelization scheme strives for minimal communication overhead, so we are able to demonstrate speed-up even running on networked commodity PC workstations. Average memory utilization per node is comparable to that of efficient sequential packages. In addition, the package supports dynamic variable reordering, and simultaneous computation of multiple BDD operations. Finally, the package is designed for portability - providing a subset of the CUDD API for the application programmer, and running on the widely available PVM package.},
	language = {en},
	booktitle = {Formal {Methods} in {Computer}-{Aided} {Design}},
	publisher = {Springer},
	author = {Milvang-Jensen, Kim and Hu, Alan J.},
	editor = {Gopalakrishnan, Ganesh and Windley, Phillip},
	year = {1998},
	pages = {501--507},
}

@phdthesis{van_dijk_sylvan_2016,
	address = {Netherlands},
	type = {{PhD} {Thesis} - {Research} {UT}, graduation {UT}},
	title = {Sylvan: multi-core decision diagrams},
	abstract = {This thesis studies the parallelization of decision diagrams, a fundamental data-structure with applications in many fields, in particular symbolic model checking. Research into parallel processing is essential, as multi-core and many-core computers are ubiquitous. Graph algorithms such as decision diagram operations are known to be difficult to parallelize, as well as difficult to reason about. This is one of the reasons why parallelizing symbolic model checking is difficult. The main result of this research is the multi-core decision diagram package Sylvan. We investigate scalable hash tables, load balancing via work stealing, using Sylvan for symbolic state space exploration and for symbolic bisimulation minimization. The experimental results show high parallel speedup of up to 38x for benchmarks on a 48-core computer. Experiments that compare Sylvan to non-parallel decision diagram packages show that Sylvan is competitive when run with a single core, and faster when run with multiple cores.},
	language = {English},
	school = {University of Twente},
	author = {van Dijk, Tom},
	month = jul,
	year = {2016},
	doi = {10.3990/1.9789036541602},
	note = {ISBN: 978-90-365-4160-2
Issue: 16-398
Series: CTIT Ph.D. thesis series},
}

@article{nakamura_radiological_2017,
	title = {Radiological consequences of a bounding event sequence of {Advanced} {Fusion} {Neutron} {Source} ({A}-{FNS})},
	volume = {118},
	issn = {0920-3796},
	url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV09T8MwED1Bu8DAN6JQkEcYQp06sRO2qCIqQupAQWIz_ohRGdoKtf8f24mrtkJiYEx8iRKf8-58fnkGIP17HG1hgk3jtU6FJES5pJYYQg02VKV9TS1K55u1HRiEX2Mcy7IJBTXEe_BuzvSazu3NJ5PeGOd9TFhuIzJx84j3XWjb6BSnLWgXT8_D0WptgWG_D6-zj9wFG6wv4wofn7pySt4x8_qnXr3y15i1hd4-JJWHMAtP75kobv-DdUp-z8sgeu2LIPn4zzc9goMme0VFbXcMO9X0BPbXNA1P4eNF6ElAVKTWyNpoZpBA0u3jZC2Rl45CodU1Fg0fAZVLV8NDo2rpCvVo7BcY0G0RlaPx3Rm8lY-vg2HUbOMQKTt5W0Ssn-rUZYqMKUkUFYYSQ02qTUIJY1KQJNPWEkusFGFYKpNgJZWFB5FmmSTn0JrOptUFoFzEKiOaaYvhSSorQROt7JRMxBrr2CQdwMFRfF6rdfBAY_viK99y51uOCbe-7cBDcCjf6H9uY8rfF3fDEODNt-_aE5sD2UycXv7n3lew545qcmUXWovvZXVte8IOo5tmSP8Ak7sGlw},
	doi = {10.1016/j.fusengdes.2017.03.060},
	abstract = {Advanced Fusion Neutron Source (A-FNS) [11] is an accelerator-based neutron source utilizing Li(d,xn) nuclear stripping reactions to simulate D-T fusion neutrons for testing and qualifying structural and functional materials of fusion reactor components, which is to be constructed at the Rokkasho site of National Institutes for Quantum and Radiological Science and Technology, Japan, in the near future. The purpose of the study reported here is to demonstrate the ultimate safety margins of A-FNS in the worst case of release of radioactive materials outside the A-FNS confinement system. For this purpose, we analyzed a ‘bounding event’ postulated in A-FNS. The postulated event sequence consists of fire of the purification system of the liquid Li loop during the maintenance, of mobilization of the tritium and 7Be, which are the impurities of the loop, and of the entire loss of confinement of the radioactive materials. We have calculated the early doses to the public due to the release of the tritium and 7Be source terms to the environment. The UFOTRI/COSYMA simulations have been performed considering the site boundary of 500 m away from the facility. The obtained results indicate that the early dose is below the level that requires the emergent public evacuation. Such results demonstrate that the A-FNS complies with the defined safety objective against its radiation hazard. The simulation results suggest that the inherent, ultimate safety characteristic found by this study may assist a licensing process for installation of A-FNS.;Advanced Fusion Neutron Source (A-FNS) [11] is an accelerator-based neutron source utilizing Li(d,xn) nuclear stripping reactions to simulate D-T fusion neutrons for testing and qualifying structural and functional materials of fusion reactor components, which is to be constructed at the Rokkasho site of National Institutes for Quantum and Radiological Science and Technology, Japan, in the near future. The purpose of the study reported here is to demonstrate the ultimate safety margins of A-FNS in the worst case of release of radioactive materials outside the A-FNS confinement system. For this purpose, we analyzed a ‘bounding event’ postulated in A-FNS. The postulated event sequence consists of fire of the purification system of the liquid Li loop during the maintenance, of mobilization of the tritium and 7Be, which are the impurities of the loop, and of the entire loss of confinement of the radioactive materials. We have calculated the early doses to the public due to the release of the tritium and 7Be source terms to the environment. The UFOTRI/COSYMA simulations have been performed considering the site boundary of 500m away from the facility. The obtained results indicate that the early dose is below the level that requires the emergent public evacuation. Such results demonstrate that the A-FNS complies with the defined safety objective against its radiation hazard. The simulation results suggest that the inherent, ultimate safety characteristic found by this study may assist a licensing process for installation of A-FNS.;},
	language = {English},
	number = {Journal Article},
	journal = {Fusion engineering and design},
	author = {Nakamura, Makoto -M and Ochiai, Kentaro},
	year = {2017},
	note = {Place: Amsterdam
Publisher: Elsevier B.V},
	keywords = {Bounding event, Confinement, Dose calculation, Fusion, Fusion neutron source, Licensing (technology), Neutrons, Nuclear engineering, Nuclear reactions, Nuclear safety, Radioactive materials, Radiological consequence, Reactors, Safety, Safety margins, Simulation, Tritium},
	pages = {104--110},
}

@article{berkowitz_proliferation_1985,
	title = {Proliferation, {Deterrence}, and the {Likelihood} of {Nuclear} {War}},
	volume = {29},
	number = {1},
	journal = {The Journal of Conflict Resolution},
	author = {Berkowitz, Bruce},
	month = mar,
	year = {1985},
}

@article{intriligator_nuclear_1981,
	title = {Nuclear {Proliferation} and the {Probability} of {Nuclear} {War}},
	volume = {37},
	number = {2},
	journal = {Public Choice},
	author = {Intriligator, Michael and Brito, Dagobert},
	year = {1981},
}

@book{shaahain_nuclear_2019,
	address = {London ; New York},
	series = {Routledge global security studies},
	title = {Nuclear command and control norms: a comparative study},
	isbn = {978-1-138-34929-2},
	shorttitle = {Nuclear command and control norms},
	publisher = {Routledge},
	author = {Shaahain, Salmaa},
	year = {2019},
	keywords = {Nuclear arms control, Nuclear crisis control, Nuclear weapons},
}

@book{schlosser_command_2013,
	address = {New York},
	title = {Command and control: nuclear weapons, the {Damascus} {Accident}, and the illusion of safety},
	isbn = {978-1-59420-227-8},
	shorttitle = {Command and control},
	publisher = {The Penguin Press},
	author = {Schlosser, Eric},
	year = {2013},
	keywords = {Accidents History, Air Force. Strategic Air Command. Strategic Missile Wing, 308th, Arkansas, Government policy, History, Nuclear weapons, Safety measures, Titan (Missile), United States},
}

@book{perry_my_2015,
	address = {Palo Alto},
	series = {Stanford {Security} {Studies}},
	title = {My {Journey} at the {Nuclear} {Brink}},
	isbn = {978-0-8047-9714-6},
	abstract = {Intro -- Contents -- Foreword by George P. Shultz -- Preface -- Acknowledgments -- Abbreviations -- 1. The Cuban Missile Crisis: A Nuclear Nightmare -- 2. A Fire in the Sky -- 3. The Rise of the Soviet Missile Threat and the Race for Data to Understand It -- 4. An Original Silicon Valley Entrepreneur and the Advance of Spy Technology -- 5. A Call to Serve -- 6. Implementing the Offset Strategy and the Emergence of Stealth Technology -- 7. Buildup of the US Nuclear Force -- 8. Nuclear Alerts, Arms Control, and Missed Opportunities in Nonproliferation -- 9. The Undersecretary as a Diplomat -- 10. Back in Civilian Life: The Cold War Ends, but the Nuclear Journey Continues -- 11. A Return to Washington: The New Challenge of "Loose Nukes" and the Lurching Reform of Defense Acquisition -- 12. I Become Secretary of Defense -- 13. Dismantling Nuclear Weapons and Building the Legacy of Nunn-Lugar -- 14. The Crisis with North Korea: Containing an Emerging Nuclear State -- 15. Ratifying Start II and Battling over the Test Ban Treaty -- 16. NATO, Peacekeeping in Bosnia, and the Rise of Security Ties with Russia -- 17. The "Immaculate Invasion" of Haiti and Forging Ties for Western Hemispheric Security -- 18. The "Iron Logic" between Military Capability and Quality of Life -- 19. A Farewell to Arms -- 20. The Fall of Security Ties with Russia -- 21. Seeking Common Ground with China, India, Pakistan, and Iran -- 22. The North Korean Policy Review: Triumph and Tragedy -- 23. Fiasco in Iraq: Then and Now -- 24. The Nuclear Security Project: Former "Cold Warriors" Offer a New Vision -- 25. A Way Forward: Hope for a World without Nuclear Weapons -- Notes -- Index},
	language = {eng},
	publisher = {Stanford University Press},
	author = {Perry, William},
	year = {2015},
}

@book{ellsberg_doomsday_2017,
	address = {New York},
	title = {The doomsday machine: confessions of a nuclear war planner},
	isbn = {978-1-60819-670-8},
	shorttitle = {The doomsday machine},
	abstract = {"Here, for the first time, former high level defense analyst Daniel Ellsberg reveals his shocking first-hand account of America's nuclear program in the 1960s. From the remotest air bases in the Pacific Command, where he discovered that the authority to initiate use of nuclear weapons was widely delegated, to the secret plans for general nuclear war under Eisenhower, which, if executed, would cause the near-extinction of humanity, Ellsberg shows that the legacy of this most dangerous arms buildup in the history of civilization--and its proposed renewal under the Trump administration--threatens our very survival. No other insider with high level access has written so candidly of the nuclear strategy of the late Eisenhower and early Kennedy years, and nothing has fundamentally changed since that era. Framed as a memoir--a chronicle of madness in which Ellsberg acknowledges participating--this gripping expose reads like a thriller and offers feasible steps we can take to dismantle the existing "doomsday machine" and avoid nuclear catastrophe, returning Ellsberg to his role as whistleblower. The Doomsday Machine is thus a real-life Dr. Strangelove story and an ultimately hopeful--and powerfully important--book about not just our country, but the future of the world."--Provided by publisher},
	publisher = {Bloomsbury},
	author = {Ellsberg, Daniel},
	year = {2017},
	keywords = {20th century, Biography, Cold War, Department of Defense, Ellsberg, Daniel, Government policy History, History, Military planning, Military policy History, Nuclear warfare, Nuclear weapons, Officials and employees, Prevention, Rand Corporation, United States},
}

@book{griffiths_dangers_1979,
	address = {Toronto ; Buffalo},
	title = {The {Dangers} of nuclear war: a {Pugwash} symposium},
	isbn = {978-0-8020-2356-8 978-0-8020-6389-2},
	shorttitle = {The {Dangers} of nuclear war},
	publisher = {University of Toronto Press},
	editor = {Griffiths, Franklyn and Polanyi, J. C.},
	year = {1979},
	keywords = {Congresses, Nuclear disarmament, Nuclear warfare},
}

@book{lebow_nuclear_1987,
	address = {Ithaca (N.Y.) London},
	series = {Cornell studies in security affairs},
	title = {Nuclear crisis management: a dangerous illusion},
	isbn = {978-0-8014-1989-8},
	shorttitle = {Nuclear crisis management},
	language = {eng},
	publisher = {Cornell university press},
	author = {Lebow, Richard Ned},
	year = {1987},
}

@book{ury_beyond_1985,
	address = {Boston, Mass},
	title = {Beyond the hotline: how crisis control can prevent nuclear war},
	isbn = {978-0-395-36671-4},
	shorttitle = {Beyond the hotline},
	publisher = {Houghton Mifflin},
	author = {Ury, William},
	year = {1985},
}

@book{jacobsen_nuclear_2024,
	address = {New York},
	title = {Nuclear war: a scenario},
	isbn = {978-0-593-47609-3 978-0-593-85067-1},
	shorttitle = {Nuclear war},
	abstract = {There is only one scenario other than an asteroid strike that could end the world as we know it in a matter of hours: nuclear war. And one of the triggers for that war would be a nuclear missile inbound toward the United States. Every generation, a journalist has looked deep into the heart of the nuclear military establishment: the technologies, the safeguards, the plans, and the risks. These investigations are vital to how we understand the world we really live in - where one nuclear missile will beget one in return, and where the choreography of the world's end requires massive decisions made on seconds' notice with information that is only as good as the intelligence we have Pulitzer Prize finalist Annie Jacobsen's Nuclear War: A Scenario explores this ticking-clock scenario, based on dozens of exclusive new interviews with military and civilian experts who have built the weapons, have been privy to the response plans, and have been responsible for those decisions should they have needed to be made. Nuclear War: A Scenario examines the handful of minutes after a nuclear missile launch. It is essential reading, and unlike any other book in its depth and urgency},
	language = {eng},
	publisher = {Dutton},
	author = {Jacobsen, Annie},
	year = {2024},
}

@techreport{noauthor_cafta_1989,
	address = {Palo Alto, CA},
	title = {{CAFTA} ({Computer}-{Assisted} {Fault} {Tree} {Analysis}) user's manual: {Version} 2. 0: {Final} report},
	shorttitle = {{CAFTA} ({Computer}-{Assisted} {Fault} {Tree} {Analysis}) user's manual},
	abstract = {CAFTA is a comprehensive PC-based fault tree workstation. It includes a full-screen fault tree editor, a multi-level reliability database, a powerful cut set generation routine, and a cut set results editor. CAFTA's fault tree editor is a full-feature, full-screen, logic model editor. It has numerous editing capabilities, with syntax and logic checking, to support the building and maintaining of large fault tree models. All data of the fault tree models is stored in a multi-level database. This lets you store data for individual events and groups of events separately, minimizing the updating effort. This database contains descriptions, reliability and uncertainty data, source and user-defined fields for each event in the fault tree model. Event names are automatically added to the database as they are added to the fault trees. CAFTA's cut set generator performs the logical reduction of any gate in the fault tree model to find the minimal cut sets. Its efficient algorithm uses all available memory and can truncate on either cut set size or probability. The cut set results can then be loaded into CAFTA's cut set results editor. This editor is designed to help extract information from the analysis. It lets you perform sensitivity and importance studies. For example, to perform ''what if'' studies, you can change event probabilities, or set events to TRUE or FALSE to set the effect on the top event without having to regenerate the cut sets.},
	language = {English},
	number = {EPRI-NP-6296},
	institution = {Electric Power Research Institute (EPRI)},
	month = apr,
	year = {1989},
}

@techreport{noauthor_systems_2011,
	address = {Idaho Falls, ID},
	title = {Systems {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8, {Volume} 1: {Overview} and {Summary}.},
	language = {en},
	number = {NUREG/CR-7039},
	institution = {Idaho National Lab. (INL)},
	year = {2011},
	doi = {10.2172/130641},
	keywords = {SAPHIRE},
}

@misc{noauthor_systems_nodate,
	title = {Systems {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8: {User} {Guide}},
	shorttitle = {Systems {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr7039/v3/index.html},
	language = {en-US},
	urldate = {2023-02-13},
	journal = {NRC Web},
}

@techreport{gertman_spar-h_2005,
	address = {Washington, D.C},
	title = {The {SPAR}-{H} {Human}  {Reliability} {Analysis} {Method}},
	number = {NUREG/CR-6883},
	institution = {US NRC},
	author = {Gertman, D and Blackman, H and Marble, J and Byers, J and Smith, C},
	year = {2005},
}

@techreport{smith_saphire_2016,
	address = {Idaho Falls, ID},
	title = {{SAPHIRE} 8 {Basics}},
	institution = {Idaho National Lab. (INL)},
	author = {Smith, Curtis and Knudsen, James and Vedros, Kurt and Calley, Michael and Kvarfordt, Kellie and Wood, Ted},
	year = {2016},
}

@techreport{noauthor_preliminary_1986,
	title = {Preliminary {Safety} {Information} {Document} for the {Standard} {MHTGR}.},
	number = {DOE-HTGR-86-024},
	institution = {Stone and Webster Engineering Corporation},
	year = {1986},
}

@techreport{noauthor_modular_2011,
	title = {Modular {HTGR} {Safety} {Basis} and {Approach}},
	abstract = {The Next Generation Nuclear Plant (NGNP) will be a licensed commercial high temperature gas-cooled reactor (HTGR) capable of producing electricity and/or high temperature process heat for industrial markets supporting a range of end-user applications. Nuclear Regulatory Commission (NRC) licensing of the NGNP plant will demonstrate the efficacy of licensing future HTGRs for commercial industrial applications. This information paper supports other white papers submitted to address key generic issues of the priority licensing topics as part of the process for establishing HTGR regulatory requirements. This information paper provides a summary level introduction to HTGR history, public safety objectives, inherent and passive safety features, radionuclide release barriers, functional safety approach, and risk-informed safety approach. The information in this paper is intended to further the NRC staff and public stakeholders understanding of the modular HTGR safety approach. The NGNP project is not requesting any NRC action or specific feedback on this information paper because other white papers are addressing key generic issues associated with priority licensing topics in greater detail.},
	language = {English},
	month = aug,
	year = {2011},
}

@techreport{ball_advanced_2012,
	title = {Advanced {Control} and {Protection} system {Design} {Methods} for {Modular} {HTGRs}},
	url = {http://www.osti.gov/servlets/purl/1047629/},
	language = {en},
	number = {ORNL/TM-2012/170, 1047629},
	urldate = {2024-12-15},
	author = {Ball, Sydney J and Wilson Jr, Thomas L and Wood, Richard Thomas},
	month = jun,
	year = {2012},
	doi = {10.2172/1047629},
	pages = {ORNL/TM--2012/170, 1047629},
}

@techreport{noauthor_wp4_nodate,
	title = {{WP4}: {Applying} and comparing various safety assessment approaches on a virtual reactor},
}

@misc{noauthor_nrc_2023,
	title = {{NRC} {Instrumentation} and {Controls} ({I}\&{C}) {Regulatory} {Infrastructure} for {Reactors}},
	url = {https://www.nrc.gov/docs/ML2332/ML23326A045.pdf},
	month = dec,
	year = {2023},
}

@techreport{noauthor_wp3_nodate,
	title = {{WP3}: {Integration} and safety analysis},
}

@techreport{noauthor_wp2_nodate,
	title = {{WP2}: {Fragility} assessment of main {NPPs} critical elements},
}

@techreport{noauthor_wp1_nodate,
	title = {{WP1}: {Characterization} of potential physical threats due to different external hazards and scenarios},
}

@article{earthperson_integrating_2023,
	title = {Integrating {Commercial}-{Off}-{The}-{Shelf} {Components} into {Radiation}-{Hardened} {Drone} {Designs} for {Nuclear}-{Contaminated} {Search} and {Rescue} {Missions}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2504-446X},
	url = {https://www.mdpi.com/2504-446X/7/8/528},
	doi = {10.3390/drones7080528},
	abstract = {This paper conducts a focused probabilistic risk assessment (PRA) on the reliability of commercial off-the-shelf (COTS) drones deployed for surveillance in areas with diverse radiation levels following a nuclear accident. The study employs the event tree/fault tree digraph approach, integrated with the dual-graph error propagation method (DEPM), to model sequences that could lead to loss of mission (LOM) scenarios due to combined hardware–software failures in the drone’s navigation system. The impact of radiation is simulated by a comparison of the total ionizing dose (TID) with the acceptable limit for each component. Errors are then propagated within the electronic hardware and software blocks to determine the navigation system’s reliability in different radiation zones. If the system is deemed unreliable, a strategy is suggested to identify the minimum radiation-hardening requirement for its subcomponents by reverse-engineering from the desired mission success criteria. The findings of this study can aid in the integration of COTS components into radiation-hardened (RAD-HARD) designs, optimizing the balance between cost, performance, and reliability in drone systems for nuclear-contaminated search and rescue missions.},
	language = {en},
	number = {8},
	urldate = {2024-12-03},
	journal = {Drones},
	author = {Earthperson, Arjun and Diaconeasa, Mihai A.},
	month = aug,
	year = {2023},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {COTS, OpenEPL, OpenPRA, discrete dynamic event tree, dual-graph error propagation model, dynamic probabilistic risk assessment, error propagation},
	pages = {528},
}

@article{ryan_coupling_2020,
	title = {Coupling of the {Smoothed} {Particle} {Hydrodynamic} {Code} {Neutrino} and the {Risk} {Analysis} {Virtual} {Environment} for {Particle} {Spacing} {Optimization}},
	volume = {206},
	issn = {0029-5450},
	url = {http://www.scopus.com/inward/record.url?scp=85092620818&partnerID=8YFLogxK},
	doi = {10.1080/00295450.2019.1704576},
	abstract = {Flooding is a hazard for nuclear power plants (NPPs) and has caused extensive damage and economic impact. Improved NPP flooding risk characterization starts with improving scenario realism by using physics-based flooding simulations. Smoothed particle hydrodynamics (SPH) is one method for modeling fluid flow and is being investigated for NPP flooding simulation. While still in its infancy as a fluid simulation tool, SPH offers enticing features especially in three-dimensional modeling. However, when conducting SPH simulations, users must establish, inter alia, the appropriate particle spacing, which can be a tedious and time-consuming process. This paper describes the coupling of the SPH code Neutrino and the Idaho National Laboratory developed Risk Analysis Virtual Environment (RAVEN). By coupling Neutrino and RAVEN, the RAVEN optimization capabilities can now be applied to the particle spacing selection problem. A brief description of SPH, the overall capabilities of RAVEN, and the protocol used to couple the codes are provided. Additionally, the paper details a hypothetical problem and demonstrates the ability of automating the particle spacing selection and performing an example particle spacing optimization using RAVEN. With the Neutrino/RAVEN coupling established, a wide range of capabilities can now be utilized including optimization, reduced order model training and analysis, uncertainty quantification, sensitivity analysis, etc. Previously, these capabilities would require extensive work and time from the Neutrino user. Now, these capabilities are readily available and require only the creation of a RAVEN input file.},
	number = {10},
	urldate = {2024-12-02},
	journal = {Nuclear Technology},
	author = {Ryan, Emerald D. and Pope, Chad L.},
	month = oct,
	year = {2020},
	keywords = {Smoothed particle hydrodynamics, code coupling, risk analysis virtual environment, simulation optimization},
	pages = {1506--1516},
}

@techreport{nrc_pra_1983,
	title = {{PRA} {Procedures} {Guide}: {A} {Guide} {To} {The} {Performance} {Of} {Probabilistic} {Risk} {Assessments} {For} {Nuclear} {Power} {Plants} ({NUREG}/{CR}-2300)},
	author = {{NRC}},
	year = {1983},
}

@techreport{noauthor_nureg-1855_2017,
	title = {{NUREG}-1855, {Revision} 1, "{Guidance} on the {Treatment} of {Uncertainties} {Associated} with {PRAs} in {Risk}-{Informed} {Decision} {Making}."},
	urldate = {2020-08-24},
	year = {2017},
}

@misc{noauthor_common-cause_nodate,
	title = {Common-{Cause} {Failure} {Event} {Insights} ({NUREG}/{CR}-6819, {INEEL}/{EXT}-99-00613)},
	language = {en-US},
	journal = {NRC Web},
}

@article{gougar_brief_nodate,
	title = {A {Brief} {History} and {Overview} of {High} {Temperature} {Reactor} {Technology} {Development} and {Deployment}},
	language = {en},
	author = {Gougar, Hans},
}

@article{fleming_markov_2004,
	title = {Markov models for evaluating risk-informed in-service inspection strategies for nuclear power plant piping systems},
	volume = {83},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832003001935},
	doi = {10.1016/j.ress.2003.08.009},
	language = {en},
	number = {1},
	urldate = {2024-11-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Fleming, Karl N.},
	month = jan,
	year = {2004},
	pages = {27--45},
}

@inproceedings{fleming_reliability_2008,
	address = {Washington, DC, USA},
	title = {Reliability and {Integrity} {Management} {Program} for {PBMR} {Helium} {Pressure} {Boundary} {Components}},
	isbn = {978-0-7918-4855-5},
	url = {https://asmedigitalcollection.asme.org/HTR/proceedings/HTR2008/48555/127/335300},
	doi = {10.1115/HTR2008-58036},
	abstract = {The purpose of this paper is to present the results of a study to establish strategies for the reliability and integrity management (RIM) of passive metallic components for the PBMR. The RIM strategies investigated include design elements, leak detection and testing approaches, and non-destructive examinations. Specific combinations of strategies are determined to be necessary and sufficient to achieve target reliability goals for passive components. This study recommends a basis for the RIM program for the PBMR Demonstration Power Plant (DPP) and provides guidance for the development by the American Society of Mechanical Engineers (ASME) of RIM requirements for Modular High Temperature Gas-Cooled Reactors (MHRs).},
	urldate = {2024-11-13},
	booktitle = {Fourth {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology}, {Volume} 2},
	publisher = {ASMEDC},
	author = {Fleming, Karl N. and Fletcher, John and Broom, Neil and Gamble, Ron and Gosselin, Steve},
	month = jan,
	year = {2008},
	pages = {127--133},
}

@inproceedings{batikh_openmha_2024,
	address = {Las Vegas, NV},
	title = {{OpenMHA}: {Open}-{Source} {Code} for {Creating} {Multi}-{Hazards} {Logic} and {Area} {PRA} {Models} {Considering} {Aging} of {SSCs}},
	shorttitle = {{OpenMHA}},
	url = {https://epubs.ans.org/?a=56466},
	doi = {doi.org/10.13182/T130-43381},
	abstract = {The traditional nuclear power plant safety assessment has historically analyzed internal and external hazards independently. However, the integration of multi-hazard risk analyses has become increasingly important since the Great Tohoku earthquake and the Fukushima disaster. This evolving safety paradigm is especially relevant for advanced reactors, which introduce novel safety features and technologies that necessitate a reevaluation of conventional risk methodologies. As the US nuclear fleet includes reactors operating beyond their original design life and explores license extensions, comprehensive assessments incorporating multi-hazard effects and aging deterioration are essential. This urgency applies with equal weight to the advanced reactor designs that emphasize passive safety features and resilience against Natural Phenomena Hazards (NPH). Our paper contributes to this body of knowledge by presenting an innovative construction platform for multi-hazard PRA logic models. The platform is driven by MongoDB, a flexible NoSQL database, integrated with OpenMHA, a fault tree logic builder code. MongoDB is used for structured data storage of spatial layouts, component details, and template fault tree logic, crucial for representing the complex safety systems of nuclear reactors and the dynamics of external and internal hazards. OpenMHA classes, such as SeismicEvent and SeismicFloodingFaultTree, are employed to generate seismic-induced hazard logic trees that intertwine SSC data with aging factors and cumulative damage. The paper highlights OpenMHA's capacity to build spatial-dependent fault tree logic that incorporates aging effects. By translating complex risk models into the SAPHIRE PRA software, the methodology promotes a scalable and collaborative research platform, extending PRA frontiers.},
	publisher = {American Nuclear Society},
	author = {Batikh, Akram and Diaconeasa, Mihai},
	month = jun,
	year = {2024},
}

@misc{yunfei_zhao_quantitative_nodate,
	title = {Quantitative {Analysis} of {Complex} {Fault} {Trees} {Using} {Importance} {Sampling} with {Monte} {Carlo} {Tree} {Search}},
	author = {{Yunfei Zhao} and {Mohamed Y. Nassar}},
}

@misc{noauthor_dissertation_nodate,
	title = {Dissertation},
	url = {https://www.overleaf.com/project/672418523fb7b10a6ba4b305},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2024-11-04},
}

@article{kubo_application_2023,
	title = {Application of quasi-{Monte} {Carlo} and importance sampling to {Monte} {Carlo}-based fault tree quantification for seismic probabilistic risk assessment of nuclear power plants},
	volume = {10},
	issn = {2187-9745},
	url = {https://www.jstage.jst.go.jp/article/mej/10/4/10_23-00051/_article},
	doi = {10.1299/mej.23-00051},
	language = {en},
	number = {4},
	urldate = {2024-10-30},
	journal = {Mechanical Engineering Journal},
	author = {Kubo, Kotaro and Tanaka, Yoichi and Hakuta, Yuto and Arake, Daisuke and Uchiyama, Tomoaki and Muramatsu, Ken},
	year = {2023},
	pages = {23--00051--23--00051},
}

@book{steinbach_boolean_2017,
	address = {San Rafael, California},
	series = {Synthesis lectures on digital circuits and systems},
	title = {Boolean differential calculus},
	isbn = {978-1-62705-617-5 978-3-031-79892-4},
	language = {eng},
	number = {\# 52},
	publisher = {Morgan \& Claypool},
	author = {Steinbach, Bernd and Posthoff, Christian},
	year = {2017},
	doi = {10.1007/978-3-031-79892-4},
}

@incollection{matos_evaluation_2024,
	address = {Cham},
	title = {Evaluation of {Fault} {Tree} {Analysis} {Algorithms} for {Probabilistic} {Risk} {Assessment}: {A} {Systematic} {Comparative} {Study}},
	volume = {494},
	isbn = {978-3-031-60270-2 978-3-031-60271-9},
	shorttitle = {Evaluation of {Fault} {Tree} {Analysis} {Algorithms} for {Probabilistic} {Risk} {Assessment}},
	url = {https://link.springer.com/10.1007/978-3-031-60271-9_11},
	language = {en},
	urldate = {2024-10-18},
	booktitle = {20th {International} {Probabilistic} {Workshop}},
	publisher = {Springer Nature Switzerland},
	author = {Afshan, Nailah and Bodda, Saran Srikanth and Gupta, Abhinav and Han, Kevin},
	editor = {Matos, José C. and Lourenço, Paulo B. and Oliveira, Daniel V. and Branco, Jorge and Proske, Dirk and Silva, Rui A. and Sousa, Hélder S.},
	year = {2024},
	doi = {10.1007/978-3-031-60271-9_11},
	note = {Series Title: Lecture Notes in Civil Engineering},
	pages = {137--146},
}

@book{devore_probability_2016,
	address = {Boston, MA},
	title = {Probability and statistics for engineering and the sciences},
	isbn = {978-1-305-25180-9},
	url = {https://catalog.lib.ncsu.edu/catalog/NCSU3510029},
	language = {English},
	publisher = {Cengage Learning},
	author = {Devore, Jay L.},
	year = {2016},
	keywords = {Mathematical statistics, Probabilities},
}

@phdthesis{farag_benchmarking_2023,
	address = {Raleigh, North Carolina},
	title = {Benchmarking {Study} of {Probabilistic} {Risk} {Assessment} {Tools} {Using} {Synthetically} {Generated} {Fault} {Tree} {Models}: {SAPHSOLVE}, {XFTA}, and {SCRAM}},
	school = {North Carolina State University},
	author = {Farag, Asmaa Salem},
	year = {2023},
}

@misc{noauthor_what_nodate,
	title = {What {Is} {OpenAPI}?},
	url = {https://swagger.io/docs/specification/v3_0/about/},
	language = {en},
	urldate = {2024-09-26},
	journal = {Swagger Docs},
}

@misc{noauthor_compodoc_nodate,
	title = {Compodoc - {The} missing documentation tool for your {Angular} application},
	url = {https://compodoc.app/guides/getting-started.html},
	urldate = {2024-09-26},
}

@misc{noauthor_overview_nodate,
	title = {Overview},
	url = {https://typedoc.org/guides/overview/},
	urldate = {2024-09-26},
	journal = {TypeDoc Documentation Generator},
}

@misc{noauthor_doxygen_nodate,
	title = {Doxygen: {Overview}},
	url = {https://www.doxygen.nl/manual/index.html},
	urldate = {2024-09-26},
}

@misc{noauthor_what_nodate-1,
	title = {What is {TSDoc}? {\textbar} {TSDoc}},
	shorttitle = {What is {TSDoc}?},
	url = {https://tsdoc.org/},
	abstract = {TSDoc is a proposal to standardize the doc comments used in TypeScript code, so that different tools can extract content without getting confused by each other's markup. The TSDoc notation looks pretty familiar:},
	language = {en},
	urldate = {2024-09-26},
}

@misc{noauthor_use_nodate,
	title = {Use {JSDoc}: {Getting} {Started} with {JSDoc} 3},
	url = {https://jsdoc.app/about-getting-started},
	urldate = {2024-09-26},
}

@misc{noauthor_starting_nodate,
	title = {The starting point for learning {TypeScript}},
	url = {https://www.typescriptlang.org/docs/},
	abstract = {Find TypeScript starter projects: from Angular to React or Node.js and CLIs.},
	language = {en},
	urldate = {2024-09-26},
}

@misc{noauthor_quick_nodate,
	title = {Quick {Start} – {React}},
	url = {https://react.dev/learn},
	abstract = {The library for web and native user interfaces},
	language = {en},
	urldate = {2024-09-26},
}

@misc{noauthor_project_nodate,
	title = {Project description and objectives {\textbar} {NARSIS}},
	url = {http://www.narsis.eu/page/project-description-and-objectives},
	urldate = {2024-09-25},
}

@misc{noauthor_supertest_2024,
	title = {supertest},
	url = {https://www.npmjs.com/package/supertest},
	abstract = {SuperAgent driven library for testing HTTP servers. Latest version: 7.0.0, last published: 5 months ago. Start using supertest in your project by running `npm i supertest`. There are 2374 other projects in the npm registry using supertest.},
	language = {en},
	urldate = {2024-09-25},
	journal = {npm},
	month = apr,
	year = {2024},
}

@misc{noauthor_microsoftplaywright_2024,
	title = {microsoft/playwright},
	copyright = {Apache-2.0},
	url = {https://github.com/microsoft/playwright},
	abstract = {Playwright is a framework for Web Testing and Automation. It allows testing Chromium, Firefox and WebKit with a single API.},
	urldate = {2024-09-25},
	publisher = {Microsoft},
	month = sep,
	year = {2024},
	note = {original-date: 2019-11-15T18:32:42Z},
	keywords = {automation, chrome, chromium, e2e-testing, electron, end-to-end-testing, firefox, javascript, playwright, test, test-automation, testing, testing-tools, web, webkit},
}

@misc{noauthor_boost_nodate,
	title = {Boost {C}++ {Libraries}},
	url = {https://www.boost.org/},
	urldate = {2024-09-25},
}

@misc{noauthor_getting_2024,
	title = {Getting {Started} · {Jest}},
	url = {https://jestjs.io/docs/getting-started},
	abstract = {Install Jest using your favorite package manager:},
	language = {en},
	urldate = {2024-09-25},
	month = jan,
	year = {2024},
}

@misc{noauthor_nestia_2024,
	title = {Nestia {Guide} {Documents} - {Index}},
	url = {https://nestia.io},
	abstract = {NestJS Helper Libraries},
	urldate = {2024-09-25},
	journal = {Nestia Guide Documents},
	month = sep,
	year = {2024},
}

@misc{noauthor_quick_nodate-1,
	title = {Quick {Start} – {React}},
	url = {https://react.dev/learn},
	abstract = {The library for web and native user interfaces},
	language = {en},
	urldate = {2024-09-25},
}

@misc{noauthor_mongoose_nodate,
	title = {Mongoose v8.6.2: {Schemas}},
	url = {https://mongoosejs.com/docs/guide.html},
	urldate = {2024-09-25},
}

@misc{noauthor_typia_2024,
	title = {Typia {Guide} {Documents} - {Index}},
	url = {https://typia.io},
	abstract = {Superfast Runtime Validator with only one line},
	urldate = {2024-09-25},
	journal = {Typia Guide Documents},
	month = sep,
	year = {2024},
}

@misc{auth0com_jwtio_nodate,
	title = {{JWT}.{IO} - {JSON} {Web} {Tokens} {Introduction}},
	url = {http://jwt.io/},
	abstract = {Learn about JSON Web Tokens, what are they, how they work, when and why you should use them.},
	language = {en},
	urldate = {2024-09-25},
	author = {auth0.com},
}

@misc{noauthor_getting_nodate,
	title = {Getting {Started} {\textbar} {Axios} {Docs}},
	url = {https://axios-http.com/docs/intro},
	urldate = {2024-09-25},
}

@misc{noauthor_introduction_2024,
	title = {Introduction to {GraphQL} {\textbar} {GraphQL}},
	url = {https://graphql.org/learn/},
	language = {en},
	urldate = {2024-09-25},
	month = aug,
	year = {2024},
}

@misc{noauthor_rabbitmq_nodate,
	title = {{RabbitMQ} {Documentation} {\textbar} {RabbitMQ}},
	url = {https://www.rabbitmq.com/docs},
	abstract = {{\textless}!--},
	language = {en},
	urldate = {2024-09-25},
}

@misc{noauthor_graphql_nodate,
	title = {{GraphQL} {\textbar} {A} query language for your {API}},
	url = {https://graphql.org/},
	language = {en},
	urldate = {2024-09-25},
}

@misc{noauthor_documentation_nodate,
	title = {Documentation {\textbar} {NestJS} - {A} progressive {Node}.js framework},
	url = {https://docs.nestjs.com},
	abstract = {Nest is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript, is built with TypeScript and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming).},
	language = {en},
	urldate = {2024-09-25},
	journal = {Documentation {\textbar} NestJS - A progressive Node.js framework},
}

@misc{noauthor_documentation_nodate-1,
	title = {Documentation {\textbar} {NestJS} - {A} progressive {Node}.js framework},
	url = {https://docs.nestjs.com},
	abstract = {Nest is a framework for building efficient, scalable Node.js server-side applications. It uses progressive JavaScript, is built with TypeScript and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming).},
	language = {en},
	urldate = {2024-09-25},
	journal = {Documentation {\textbar} NestJS - A progressive Node.js framework},
}

@misc{noauthor_risk-informed_nodate,
	title = {Risk-{Informed} {Evaluation} of {Protective} {Action} {Strategies} for {Nuclear} {Plant} {Off}-{Site} {Emergency} {Planning}},
	url = {https://www.epri.com/research/products/1015105},
	urldate = {2024-09-23},
}

@article{fleming_risk-informed_2024,
	title = {A risk-informed and performance-based approach to defining prevention and mitigation},
	volume = {428},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549324006587},
	doi = {10.1016/j.nucengdes.2024.113558},
	abstract = {The terms “prevention” and “mitigation” are often used to define safety functions in nuclear power plants and other complex engineered systems. For existing light water reactor (LWR) nuclear plants, these terms are typically used in the context of preventing core damage and mitigating the consequences of a severe accident. Balancing the reliance on prevention and mitigation is often stated as an important principle of defense-in-depth. To apply these terms to formulate design requirements for advanced reactors, it is necessary to define specifically what is to be prevented and mitigated because the concept of core damage is not generally applicable to advanced non-LWR concepts and designs. Advanced non-LWR reactor concepts use different fuels, moderators, coolants and different strategies for achieving the functional containment of radionuclides. The adoption of the small modular reactor concept also leads to plants with many small reactors. This paper discusses a risk-informed and performance-based definition of prevention and mitigation that can be applied to any reactor concept or design. It was developed as part of the Licensing Modernization Project (LMP) which has introduced a new approach to developing a safety case to support design and licensing. A new way of thinking about prevention and mitigation was needed to formulate advanced reactor design and special treatment requirements for structures, systems and components (SSCs) that could be applied to a wide diversity of designs. The LMP approach discussed in this paper includes criteria to identify safety significant SSC prevention and mitigation functions and uses SSC reliability and capability targets to inform the selection of design and special treatment requirements and to support the evaluation of defense-in-depth adequacy. These prevention and mitigation functions are defined in the context of event sequences that comprise the licensing basis events that anchor the safety case for the reactor operating license.},
	urldate = {2024-08-29},
	journal = {Nuclear Engineering and Design},
	author = {Fleming, Karl N. and Wallace, Edward G. and Afzali, Amir},
	month = nov,
	year = {2024},
	keywords = {Defense-in-depth, Performance-based, Probabilistic risk assessment, Risk-informed, Special treatment},
	pages = {113558},
}

@article{zio_digital_2024,
	title = {Digital twins in safety analysis, risk assessment and emergency management},
	volume = {246},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832024001157},
	doi = {10.1016/j.ress.2024.110040},
	language = {en},
	urldate = {2024-05-24},
	journal = {Reliability Engineering \& System Safety},
	author = {Zio, Enrico and Miqueles, Leonardo},
	month = jun,
	year = {2024},
	pages = {110040},
}

@article{verfondern_safety_2017,
	title = {Safety concept of nuclear cogeneration of hydrogen and electricity},
	volume = {42},
	issn = {03603199},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S036031991630550X},
	doi = {10.1016/j.ijhydene.2016.04.239},
	abstract = {There is a significant potential for nuclear combined heat and power (CHP) in quite a number of industries. The reactor concepts of the next generation would be capable to open up, in particular, the high temperature heat market where nuclear energy is applicable to the production processes of hydrogen (or liquid fuels) by steam reforming or water splitting. Due to the need to locate a nuclear facility near the hydrogen plant, an overall safety concept has to deal with the question of safety of the combined nuclear/industrial system by taking into account a qualitatively new class of events characterized by interacting influences. Specific requirements will be determined by such factors as the reactor type, the nature of the industrial process, the separation distances of the industrial facility and population centers from the nuclear plant, and prevailing public attitudes. Based on the Japanese concept of the GTHTR300C nuclear reactor for electricity and hydrogen cogeneration, theoretical studies were conducted on the release, dispersive transport, and explosion of a hydrogen cloud in the atmosphere for the sake of assessing the required minimum separation distance to avoid any risk to the nuclear plant’s safety systems. In the case of sulfur-iodine water splitting, the accidental release of process intermediates including large amounts of sulfur dioxide, sulfur trioxide, and sulfuric acid need to be investigated as well to estimate the potential risk to nuclear installations like the operators’ room and estimate appropriate separation distances against toxic gas propagation. Results of respective simulation studies will be presented.},
	language = {en},
	number = {11},
	urldate = {2024-08-14},
	journal = {International Journal of Hydrogen Energy},
	author = {Verfondern, K. and Yan, X. and Nishihara, T. and Allelein, H.-J.},
	month = mar,
	year = {2017},
	pages = {7551--7559},
}

@techreport{jw_hickman_pra_1983,
	title = {{PRA} {Procedures} {Guide}: {Chapters} 1–8 ({NUREG}/{CR}-2300, {Volume} 1)},
	shorttitle = {{PRA} {Procedures} {Guide}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2300/vol1/index.html},
	number = {NUREG/CR-2300},
	urldate = {2021-04-05},
	institution = {Nuclear Regulatory Commission, Washington, D.C. (USA)},
	author = {{J.W. Hickman}},
	month = jan,
	year = {1983},
}

@article{wahlstrom_differences_nodate,
	title = {{DIFFERENCES} {BETWEEN} {ANALOG} {AND} {DIGITAL} {I}\&{C}},
	abstract = {Fifty years ago instrumentation and control (I\&C) systems at nuclear power plants (NPP) were analog and relied on a mixture of mechanical, pneumatic and electric components. Today analog technology has been replaced with digital technology. Digital I\&C has over the years experienced difficulties in the licensing process, which has delayed and escalated costs of both NPP and I\&C projects. In the paper it is argued that some of the difficulties are connected to misunderstandings regarding differences between analog and digital I\&C. These misunderstandings have led to unrealistic expectations regarding proofs that selected I\&C systems can be considered acceptable. To ensure a successful licensing process it would be necessary to agree on evidence for safety that can be considered sufficient. Such evidence should be collected both from the I\&C design process and from testing intermediate and final I\&C solutions. By a combination of evidence from different sources it should be possible to build a safety case that can be agreed to give sufficient proofs for acceptability. The first component in building the safety case is to make use of safety principles to provide structural evidence that certain classes of design errors have been avoided. The second component is to use simulators and targeted testing to demonstrate functionality of the I\&C in different plant situations.},
	language = {en},
	author = {Wahlström, Björn},
}

@inproceedings{andrew_hahn_simulation_2024,
	address = {Las Vegas, Nevada},
	title = {Simulation {Based} {Analytical} {Approaches} to {Cyber} {Risk} {Mitigation} in {Advanced} {Nuclear} {Reactors}},
	doi = {doi.org/10.13182/T130-44646},
	abstract = {Advanced Reactor (AR) technologies are increasingly relying upon digital automation control systems which increases the demand for cybersecurity. Evaluating the cyber security of advanced reactors in a rigorous, systematic, and repeatable manner presents a major challenge for designers, licensees, and regulators. SNL has developed the Advanced Reactor Cyber Analysis and Development Environment (ARCADE) to reduce these challenges and the costs, time, and effort required by designers to evaluate the cybersecurity of their designs. ARCADE has been designed to be plug-and-play for popular industry simulation tools (Flownex, Simulink) via generic APIs for AR designers’ models. ARCADE, its tools, and an educational platform based on ARCADE are opensource. This paper will describe the development of ARCADE tools and an analysis of an AR control system design using ARCADE.},
	author = {{Andrew Hahn} and {Lee Maccarone} and {Mike Rowland}},
	month = jul,
	year = {2024},
}

@misc{noauthor_handbook_nodate,
	title = {Handbook of {Safety} {Principles} {\textbar} {Wiley} {Online} {Books}},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119443070},
	urldate = {2024-07-05},
}

@article{seong_analysis_2018,
	title = {Analysis of the technical status of multiunit risk assessment in nuclear power plants},
	volume = {50},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573317301870},
	doi = {10.1016/j.net.2017.12.015},
	abstract = {Since the Fukushima Daiichi nuclear disaster, concern and worry about multiunit accidents have been increasing. Korea has a higher urgency to evaluate its site risk because its number of nuclear power plants (NPPs) and population density are higher than those in other countries. Since the 1980s, technical documents have been published on multiunit probabilistic safety assessment (PSA), but the Fukushima accident accelerated research on multiunit PSA. It is therefore necessary to summarize the present situation and draw implications for further research. This article reviews journal and conference papers on multiunit or site risk evaluation published between 2011 and 2016. The contents of the reviewed literature are classified as research status, initiators, and methodologies representing dependencies, and the insights and conclusions are consolidated. As of 2017, the regulatory authority and nuclear power utility have launched a full-scale project to assess multiunit risk in Korea. This article provides comprehensive reference materials on the necessary enabling technology for subsequent studies of multiunit or site risk assessment.},
	number = {3},
	urldate = {2024-07-02},
	journal = {Nuclear Engineering and Technology},
	author = {Seong, Changkyung and Heo, Gyunyoung and Baek, Sejin and Yoon, Ji Woong and Kim, Man Cheol},
	month = apr,
	year = {2018},
	keywords = {Multiunit, Nuclear Power Plant, Probabilistic Safety Assessment, Site Risk Assessment},
	pages = {319--326},
}

@article{kim_pragmatic_2020,
	title = {A pragmatic approach to modeling common cause failures in multi-unit {PSA} for nuclear power plant sites with a large number of units},
	volume = {195},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832019305368},
	doi = {10.1016/j.ress.2019.106739},
	abstract = {One of the major issues in multi-unit probabilistic safety assessment (MUPSA) is how to deal with inter-unit common cause failures (CCFs). Most existing studies on MUPSA have focused on two-unit nuclear power plant (NPP) sites, where it is often not difficult to extend currently available CCF modeling approaches, such as the Alpha Factor and Beta Factor models, to address inter-unit CCFs. However, when considering an NPP site with three or more units, these approaches can be inapplicable or yield overly conservative results. This paper proposes a pragmatic approach to modeling CCFs for application to MUPSA involving a large number of NPP units. Provided here are the criteria for selecting CCF groups for which inter-unit CCFs are considered, as well as the methods for modeling CCF combinations and estimating their probabilities. The effectiveness of the proposed approach is then demonstrated by application to cases with different numbers of identical units as well as to cases where non-identical units are included in MUPSA. Results are also compared with those obtained from existing approaches.},
	urldate = {2024-07-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Kim, Dong-San and Park, Jin Hee and Lim, Ho-Gon},
	month = mar,
	year = {2020},
	keywords = {Common cause failure, Inter-unit common cause failure, Inter-unit dependency, Multi-unit PRA, Multi-unit PSA},
	pages = {106739},
}

@article{kim_pragmatic_2020-1,
	title = {A pragmatic approach to modeling common cause failures in multi-unit {PSA} for nuclear power plant sites with a large number of units},
	volume = {195},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832019305368},
	doi = {10.1016/j.ress.2019.106739},
	abstract = {One of the major issues in multi-unit probabilistic safety assessment (MUPSA) is how to deal with inter-unit common cause failures (CCFs). Most existing studies on MUPSA have focused on two-unit nuclear power plant (NPP) sites, where it is often not difficult to extend currently available CCF modeling approaches, such as the Alpha Factor and Beta Factor models, to address inter-unit CCFs. However, when considering an NPP site with three or more units, these approaches can be inapplicable or yield overly conservative results. This paper proposes a pragmatic approach to modeling CCFs for application to MUPSA involving a large number of NPP units. Provided here are the criteria for selecting CCF groups for which inter-unit CCFs are considered, as well as the methods for modeling CCF combinations and estimating their probabilities. The effectiveness of the proposed approach is then demonstrated by application to cases with different numbers of identical units as well as to cases where non-identical units are included in MUPSA. Results are also compared with those obtained from existing approaches.},
	urldate = {2024-07-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Kim, Dong-San and Park, Jin Hee and Lim, Ho-Gon},
	month = mar,
	year = {2020},
	keywords = {Common cause failure, Inter-unit common cause failure, Inter-unit dependency, Multi-unit PRA, Multi-unit PSA},
	pages = {106739},
}

@article{kim_pragmatic_2020-2,
	title = {A pragmatic approach to modeling common cause failures in multi-unit {PSA} for nuclear power plant sites with a large number of units},
	volume = {195},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832019305368},
	doi = {10.1016/j.ress.2019.106739},
	abstract = {One of the major issues in multi-unit probabilistic safety assessment (MUPSA) is how to deal with inter-unit common cause failures (CCFs). Most existing studies on MUPSA have focused on two-unit nuclear power plant (NPP) sites, where it is often not difficult to extend currently available CCF modeling approaches, such as the Alpha Factor and Beta Factor models, to address inter-unit CCFs. However, when considering an NPP site with three or more units, these approaches can be inapplicable or yield overly conservative results. This paper proposes a pragmatic approach to modeling CCFs for application to MUPSA involving a large number of NPP units. Provided here are the criteria for selecting CCF groups for which inter-unit CCFs are considered, as well as the methods for modeling CCF combinations and estimating their probabilities. The effectiveness of the proposed approach is then demonstrated by application to cases with different numbers of identical units as well as to cases where non-identical units are included in MUPSA. Results are also compared with those obtained from existing approaches.},
	urldate = {2024-07-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Kim, Dong-San and Park, Jin Hee and Lim, Ho-Gon},
	month = mar,
	year = {2020},
	keywords = {Common cause failure, Inter-unit common cause failure, Inter-unit dependency, Multi-unit PRA, Multi-unit PSA},
	pages = {106739},
}

@article{modarres_advances_2017,
	title = {Advances in multi-unit nuclear power plant probabilistic risk assessment},
	volume = {157},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832016303611},
	doi = {10.1016/j.ress.2016.08.005},
	abstract = {The Fukushima Dai-ichi accident highlighted the importance of risks from multiple nuclear reactor unit accidents at a site. As a result, there has been considerable interest in Multi-Unit Probabilistic Risk Assessment (MUPRA) in the past few years. For considerations in nuclear safety, the MUPRA estimates measures of risk and identifies contributors to risk representing the entire site rather than the individual units in the site. In doing so, possible unit-to-unit interactions and dependencies should be modeled and accounted for in the MUPRA. In order to effectively account for these risks, six main commonality classifications—initiating events, shared connections, identical components, proximity dependencies, human dependencies, and organizational dependencies—may be used. This paper examines advances in MUPRA, offers formal definitions of multi-unit site risk measures and proposes quantitative approaches and data to account for unit-to-unit dependencies. Finally, a parametric approach for the multi-unit dependencies has been discussed and a simple example illustrates application of the proposed methodology.},
	urldate = {2024-07-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Modarres, Mohammad and Zhou, Taotao and Massoud, Mahmoud},
	month = jan,
	year = {2017},
	keywords = {Dependent Failures, Multi-Module PRA, Multi-Unit Incident Data, Multi-Unit PRA, PRA},
	pages = {87--100},
}

@article{yang_multi-unit_2018,
	title = {Multi-unit risk assessment of nuclear power plants: {Current} status and issues},
	volume = {50},
	issn = {1738-5733},
	shorttitle = {Multi-unit risk assessment of nuclear power plants},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573318304947},
	doi = {10.1016/j.net.2018.09.010},
	abstract = {After the Fukushima-Daiichi accident in 2011, the multi-unit risk, i.e., the risk due to several nuclear power plants (NPPs) in a site has become an important issue in several countries such as Korea, Canada, and China. However, the multi-unit risk has been discussed for a long time in the nuclear community before the Fukushima-Daiichi nuclear accident occurred. The regulatory authorities around the world and the international organizations had proposed requirements or guidelines to reduce the multi-unit risk. The concerns regarding the multi-unit risk can be summarized in the following three questions: How much the accident of an NPP in a site affects the safety of other NPPs in the same site? What is the total risk of a site with many NPPs? Will the risk of the simultaneous accidents at several NPPs in a site such as the Fukushima Daiichi accident be low enough? The multi-unit risk assessment (MURA) in an integrated framework is a practical approach to obtain the answers for the above questions. Even though there were few studies to assess the multi-unit risk before the Fukushima-Daiichi nuclear accident, there are still several issues to be resolved to perform the complete MURA. This article aims to provide an overview of the multi-unit risk issues and its assessment. We discuss the several critical issues in the current MURA to get useful insights regarding the multi-unit risk with the current state art of probabilistic safety assessment (PSA) technologies. Also, the qualitative answers for the above questions are addressed.},
	number = {8},
	urldate = {2024-07-02},
	journal = {Nuclear Engineering and Technology},
	author = {Yang, Joon-Eon},
	month = dec,
	year = {2018},
	keywords = {Fukushima accident, Multi-unit risk assessment, Site risk management},
	pages = {1199--1209},
}

@article{ingersoll_nuscale_2014,
	title = {{NuScale} small modular reactor for {Co}-generation of electricity and water},
	volume = {340},
	issn = {0011-9164},
	url = {https://www.sciencedirect.com/science/article/pii/S0011916414000885},
	doi = {10.1016/j.desal.2014.02.023},
	abstract = {The worldwide demand for potable water has been steadily growing and is projected to accelerate while natural reserves of fresh water are generally flat or diminishing. Desalination of seawater or brackish groundwater is expected to make up the difference; however, the desalination of water is energy intensive, requiring large amounts of electricity and/or thermal energy. Nuclear energy is an attractive option for large scale desalination application since the thermal energy produced in a nuclear plant can provide both electricity and heat for clean water production without the emission of greenhouse gases or the variability of renewable sources. A particularly attractive option for nuclear desalination is to couple a desalination plant with a new generation of designs — small modular reactors. The NuScale small modular reactor design is especially well suited for the cogeneration of electricity and clean water because of the enhanced safety, improved affordability, and deployment flexibilities of the plant design, which provides a cost-effective approach to expanding global desalination capacity. Parametric studies were performed to evaluate the technical and economic considerations of coupling a NuScale plant to a variety of different desalination technologies. The study concludes that although a NuScale plant coupled to a reverse osmosis desalination plant provides the most favorable economics, NuScale design features offer several flexibilities for coupling to thermal distillation plants and hybrid plant configurations.},
	urldate = {2024-07-02},
	journal = {Desalination},
	author = {Ingersoll, D. T. and Houghton, Z. J. and Bromm, R. and Desportes, C.},
	month = may,
	year = {2014},
	keywords = {NuScale Power, Nuclear desalination, Small modular reactors},
	pages = {84--93},
}

@article{scarlat_preliminary_2012,
	series = {5th {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology} ({HTR} 2010)},
	title = {Preliminary safety analysis of a {PBMR} supplying process heat to a co-located ethylene production plant},
	volume = {251},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549311010582},
	doi = {10.1016/j.nucengdes.2011.10.069},
	abstract = {This paper considers the safety analysis and licensing approach for co-locating a pebble bed modular reactor (PBMR) to provide process heat to an ethylene production unit. The PBMR is an advanced nuclear reactor design that provides 400MW of thermal energy. Ethylene production is an energy intensive process that utilizes large gas furnaces to provide the heat for the process. Coupling a PBMR with an ethylene production plant would open a new market for nuclear power, and would provide the chemical industry with a cleaner power source, helping to achieve the Clean Air Act standards, and eliminating the 0.5ton of CO2 emissions per ton of produced ethylene. Our analysis uses the Chevron Phillips chemical plant in Sweeney, TX as a prototypical site. The plant has four ethylene production trains, with a total power consumption of 2.4GW, for an ethylene output of 3.7milliontons per year, 4\% of the global ethylene production capacity. This paper proposes replacement of the gas furnaces by low-emission PBMR modules, and presents the safety concerns and risk mitigation and management options for this coupled system. Two coupling design options are proposed, and the necessary changes to the design basis events and severe accidents for the PBMR licensing application are discussed. A joint effort between the chemical and the nuclear entities to optimize the coupling design, establish preventive maintenance procedures, and develop emergency response plans for both of the units is recommended.},
	urldate = {2024-07-02},
	journal = {Nuclear Engineering and Design},
	author = {Scarlat, Raluca O. and Cisneros, Anselmo T. and Koutchesfahani, Tawni and Hong, Rada and Peterson, Per F.},
	month = oct,
	year = {2012},
	pages = {53--59},
}

@techreport{schey_feasibility_2009,
	title = {Feasibility {Study} of {Hydrogen} {Production} at {Existing} {Nuclear} {Power} {Plants}},
	url = {https://www.osti.gov/biblio/968345},
	abstract = {Cooperative Agreement DE-FC07-06ID14788 was executed between the U.S. Department of Energy, Electric Transportation Applications, and Idaho National Laboratory to investigate the economics of producing hydrogen by electrolysis using electricity generated by nuclear power. The work under this agreement is divided into the following four tasks: Task 1 – Produce Data and Analyses Task 2 – Economic Analysis of Large-Scale Alkaline Electrolysis Task 3 – Commercial-Scale Hydrogen Production Task 4 – Disseminate Data and Analyses. Reports exist on the prospect that utility companies may benefit from having the option to produce electricity or produce hydrogen, depending on market conditions for both. This study advances that discussion in the affirmative by providing data and suggesting further areas of study. While some reports have identified issues related to licensing hydrogen plants with nuclear plants, this study provides more specifics and could be a resource guide for further study and clarifications. At the same time, this report identifies other area of risks and uncertainties associated with hydrogen production on this scale. Suggestions for further study in some of these topics, including water availability, are included in the report. The goals and objectives of the original project description have been met. Lack of industry design for proton exchange membrane electrolysis hydrogen production facilities of this magnitude was a roadblock for a significant period. However, recent design breakthroughs have made costing this facility much more accurate. In fact, the new design information on proton exchange membrane electrolyzers scaled to the 1 kg of hydrogen per second electrolyzer reduced the model costs from \$500 to \$100 million. Task 1 was delayed when the original electrolyzer failed at the end of its economic life. However, additional valuable information was obtained when the new electrolyzer was installed. Products developed during this study include a process model and a N2H2 economic assessment model (both developed by the Idaho National Laboratory). Both models are described in this report. The N2H2 model closely tracked and provided similar results as the H2A model and was instrumental in assessing the effects of plant availability on price when operated in the shoulder mode for electrical pricing. Differences between the H2A and N2H2 model are included in this report.},
	language = {English},
	number = {INL/EXT-09-16326},
	urldate = {2024-07-02},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Schey, Stephen},
	month = jul,
	year = {2009},
	doi = {10.2172/968345},
}

@techreport{muhlheim_initiating_2014,
	title = {Initiating {Events} for {Multi}-{Reactor} {Plant} {Sites}},
	url = {https://www.osti.gov/biblio/1237615},
	abstract = {Inherent in the design of modular reactors is the increased likelihood of events that initiate at a single reactor affecting another reactor. Because of the increased level of interactions between reactors, it is apparent that the Probabilistic Risk Assessments (PRAs) for modular reactor designs need to specifically address the increased interactions and dependencies.},
	language = {English},
	number = {ORNL/TM-2014/533},
	urldate = {2024-07-02},
	institution = {Oak Ridge National Lab. (ORNL), Oak Ridge, TN (United States)},
	author = {Muhlheim, Michael David and Flanagan, George F. and Poore, I. I. I.},
	month = sep,
	year = {2014},
	doi = {10.2172/1237615},
}

@techreport{vedros_probabilistic_2022,
	title = {Probabilistic {Risk} {Assessment} of a {Light}-{Water} {Reactor} {Coupled} with a {High}-{Temperature} {Electrolysis} {Hydrogen} {Production} {Plant}},
	url = {https://www.osti.gov/biblio/1903606},
	abstract = {This report details an expansion of the original two generic probabilistic risk assessments (PRAs) for the addition of a heat extraction system (HES) to a light-water reactor, one for a pressurized-water reactor and one for a boiling-water reactor. The new material in this revision includes a new HES design, direct electrical coupling of the nuclear power plant to the High-Temperature Electrolysis Facility (HTEF), and a smaller 100-MWt HTEF analysis. The results investigate the applicability of the potential licensing approaches, which do not require a full United States Nuclear Regulatory Commission licensing review. The PRAs are generic and include some assumptions. We eliminated many conservative assumptions from the preliminary pressurized-water reactor PRA report using design data for both the HES and HTEF. The PRA results indicate that the 10 CFR 50.59 licensing approach is justified due to the minimal increase in initiating event frequencies for all design basis accidents, with none exceeding 5.6\%. The PRA results for core damage frequency and large early release frequency support the use of RG 1.174 as further risk information that supports a change without a full licensing amendment review. Further insights provided through hazard analyses and sensitivity studies confirm with high confidence that the safety case for licensing an HES addition and an HTEF sited 1.0 km from the nuclear power plant is strong and that the placement of a HTEF at 0.5 km is also a viable case. Site-specific information can alter these conclusions.},
	language = {English},
	number = {INL/EXT-20-60104-Rev.001},
	urldate = {2024-07-02},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Vedros, Kurt G. and Christian, Robby and Otani, Courtney Mariko Yang Hui},
	month = nov,
	year = {2022},
	doi = {10.2172/1903606},
}

@techreport{worsham_site_2024,
	title = {Site {Integration} and {Regulatory} {Considerations} for a {Nuclear} {Power} {Plant} {Colocated} with {Industrial} {Facilities}: {Colocation} {Studies} for a {Petroleum} {Refinery}, {Methanol} {Plant}, and {Wood} {Pulp} {Plant}},
	shorttitle = {Site {Integration} and {Regulatory} {Considerations} for a {Nuclear} {Power} {Plant} {Colocated} with {Industrial} {Facilities}},
	url = {https://www.osti.gov/biblio/2370305},
	abstract = {This research explores the colocation of nuclear power plants (NPPs) with industrial applications. Three existing industrial sites were considered to demonstrate the siting process and illuminate technological gaps for future work. The three applications demonstrated for colocation here are a petroleum refinery, a methanol production plant, and a pulp and paper plant. This study uses a modified version of the EPRI siting criteria to explore the geological and demographic characteristics of the location of the current industrial site, as well as exploring external hazards from the industrial plant and its surrounding land use. Data was collected from public databases to estimate site characteristics. We then discuss how the site characteristics may impact the ability to colocate an NPP with an industrial application. The application site and 5 additional sites were explored for each application to give a general indication of the siting implications for an NPP in each area. The hazards for each industrial application was also explored to determine how colocation may impact reactor safety. The following gaps have been identified and should be explored in future research on colocation of NPPs with petroleum refineries, methanol plants, and pulp and paper plants: - There is a variety of industrial use, hazards, and pipelines in the surrounding area. A more thorough review of these hazards should be considered for colocation. - In general, the whole region around some applications seems to have softer soil, with implications for large site preparation costs. Further site investigations should prioritize looking into the geotechnical conditions. - Applications along coastlines are susceptible to flooding and hurricanes. The benefits of colocation should be weighed against the potential design implications. - The benefits of natural gas pipeline infrastructure in place should be explored further. If heat supply from the NPP is not required or not feasible due to the distance between the NPP and the application, there may be an opportunity to supply hydrogen to the plant through an existing pipeline. - Because there are several collocated industrial plants in the regions for the refinery and methanol plant, the benefits of sharing resources from the NPP should be explored further. This may open up additional sites for colocation. The following knowledge gaps were identified for the colocation of NPPs with these three industries, and industrial applications in general. These gaps are: - While the STAND tool contains many important characteristics for the reactor siting process, it is not calibrated for the colocation of NPPs with industrial facilities. - There are aspects of both the NPP and industrial application that need to be quantified for a siting analysis. Particularly, we need to understand the water intake requirements for NPPs and each application. - Further work may focus on adapting the STAND site comparison methodology to comparison of sites for co-location. This will involve using the data documented in this report as a starting point and performing a comprehensive and quantitative comparison. - Without spending significant resources, it would be impossible to gather data for each site to evaluate all aspects of siting. One approach to finding data and understanding its implications to siting is looking at FSARs for existing plants. For example, most sites considered in this study have small Vs30 values, indicating soft soil. However, there are NPPs located in the vicinity of most of the sites (e.g., Waterford Steam Electric Station near New Orleans) and reviewing available site characteristics and geotechnical data for these NPPs, might provide further information for siting. - The siting analysis in this study indicates that colocation of the NPP with the industrial site could be difficult based on external hazards, cooling requirements, weather, or population. We need to determine the impact of distance between the two facilities on cost and quality of energy transport. - This study did not touch on socioeconomic impacts for NPP colocation with industrial facilities. The input-output analysis methodology could be applied to the communities referenced in this study to determine the socioeconomic impact of these projects. - Similarly, the impacts of colocation on emergency planning was not explored in this study. The impacts on emergency planning infrastructure are somewhat related to the socioeconomic impacts, and could be explored using a similar methodology. - This study also did not address physical and cybersecurity, which will be important aspects of co-location [ref] . Cybersecurity will be important, regardless of the distance, but physical security will be important if the facilities are located very closely. Physical security might also be important for the steam lines between the plants, unless they are determined to be non-safety significant. - In many site l},
	language = {English},
	number = {INL/RPT-24-77936-Rev000},
	urldate = {2024-07-02},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Worsham, Elizabeth Kirkpatrick and Bolisetti, Chandrakanth and Cheng, Wen-Chi and Yang Hui Otani, Courtney Mariko and Griffith, George W. and Saeed, Rami M. and Bryan, Haydn C. and Vedros, Kurt G.},
	month = apr,
	year = {2024},
}

@techreport{worsham_site_2024-1,
	title = {Site {Integration} and {Regulatory} {Considerations} for a {Nuclear} {Power} {Plant} {Colocated} with {Industrial} {Facilities}: {Colocation} {Studies} for a {Petroleum} {Refinery}, {Methanol} {Plant}, and {Wood} {Pulp} {Plant}},
	shorttitle = {Site {Integration} and {Regulatory} {Considerations} for a {Nuclear} {Power} {Plant} {Colocated} with {Industrial} {Facilities}},
	url = {https://www.osti.gov/biblio/2370305},
	abstract = {This research explores the colocation of nuclear power plants (NPPs) with industrial applications. Three existing industrial sites were considered to demonstrate the siting process and illuminate technological gaps for future work. The three applications demonstrated for colocation here are a petroleum refinery, a methanol production plant, and a pulp and paper plant. This study uses a modified version of the EPRI siting criteria to explore the geological and demographic characteristics of the location of the current industrial site, as well as exploring external hazards from the industrial plant and its surrounding land use. Data was collected from public databases to estimate site characteristics. We then discuss how the site characteristics may impact the ability to colocate an NPP with an industrial application. The application site and 5 additional sites were explored for each application to give a general indication of the siting implications for an NPP in each area. The hazards for each industrial application was also explored to determine how colocation may impact reactor safety. The following gaps have been identified and should be explored in future research on colocation of NPPs with petroleum refineries, methanol plants, and pulp and paper plants: - There is a variety of industrial use, hazards, and pipelines in the surrounding area. A more thorough review of these hazards should be considered for colocation. - In general, the whole region around some applications seems to have softer soil, with implications for large site preparation costs. Further site investigations should prioritize looking into the geotechnical conditions. - Applications along coastlines are susceptible to flooding and hurricanes. The benefits of colocation should be weighed against the potential design implications. - The benefits of natural gas pipeline infrastructure in place should be explored further. If heat supply from the NPP is not required or not feasible due to the distance between the NPP and the application, there may be an opportunity to supply hydrogen to the plant through an existing pipeline. - Because there are several collocated industrial plants in the regions for the refinery and methanol plant, the benefits of sharing resources from the NPP should be explored further. This may open up additional sites for colocation. The following knowledge gaps were identified for the colocation of NPPs with these three industries, and industrial applications in general. These gaps are: - While the STAND tool contains many important characteristics for the reactor siting process, it is not calibrated for the colocation of NPPs with industrial facilities. - There are aspects of both the NPP and industrial application that need to be quantified for a siting analysis. Particularly, we need to understand the water intake requirements for NPPs and each application. - Further work may focus on adapting the STAND site comparison methodology to comparison of sites for co-location. This will involve using the data documented in this report as a starting point and performing a comprehensive and quantitative comparison. - Without spending significant resources, it would be impossible to gather data for each site to evaluate all aspects of siting. One approach to finding data and understanding its implications to siting is looking at FSARs for existing plants. For example, most sites considered in this study have small Vs30 values, indicating soft soil. However, there are NPPs located in the vicinity of most of the sites (e.g., Waterford Steam Electric Station near New Orleans) and reviewing available site characteristics and geotechnical data for these NPPs, might provide further information for siting. - The siting analysis in this study indicates that colocation of the NPP with the industrial site could be difficult based on external hazards, cooling requirements, weather, or population. We need to determine the impact of distance between the two facilities on cost and quality of energy transport. - This study did not touch on socioeconomic impacts for NPP colocation with industrial facilities. The input-output analysis methodology could be applied to the communities referenced in this study to determine the socioeconomic impact of these projects. - Similarly, the impacts of colocation on emergency planning was not explored in this study. The impacts on emergency planning infrastructure are somewhat related to the socioeconomic impacts, and could be explored using a similar methodology. - This study also did not address physical and cybersecurity, which will be important aspects of co-location [ref] . Cybersecurity will be important, regardless of the distance, but physical security will be important if the facilities are located very closely. Physical security might also be important for the steam lines between the plants, unless they are determined to be non-safety significant. - In many site l},
	language = {English},
	number = {INL/RPT-24-77936-Rev000},
	urldate = {2024-07-02},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Worsham, Elizabeth Kirkpatrick and Bolisetti, Chandrakanth and Cheng, Wen-Chi and Yang Hui Otani, Courtney Mariko and Griffith, George W. and Saeed, Rami M. and Bryan, Haydn C. and Vedros, Kurt G.},
	month = apr,
	year = {2024},
}

@techreport{christensen_determining_2020,
	title = {Determining the {Appropriate} {Emergency} {Planning} {Attributes} for {Microreactors}},
	url = {https://www.osti.gov/biblio/1668830},
	abstract = {Micro-reactor designs incorporate design features that provide very low reactor decay heat power at 24 hours after shutdown that is manageable in comparison with larger reactors. This attribute translates into a low probability of core damage negligible offsite dose. This paper provides the conceptual framework for appropriately structuring emergency planning requirements for micro-reactors while ensuring the U.S. Nuclear Regulatory Commission’s (NRC) commitment to safety is met. Due to the diversity in reactor designs comprising the micro-reactor community, this paper identifies the necessary concepts that should be considered to ensure emergency plans for micro-reactors are appropriate for the risk. This paper does not mandate specific design features for micro-reactors but provides reactor designers a conceptual framework for a scalable, graded approach to Emergency Planning Standards that should be considered in their individual designs in order to support simplified emergency plans. Given that accident source terms associated with micro-reactors are essentially negligible when compared with those for large light water reactors, revisions to emergency planning standards are justified. A graded approach to implementing emergency planning guidance can be used to appropriately structure micro-reactor emergency plans and reduce the size of the emergency planning zone and plume exposure pathway. Appropriately structuring emergency planning requirements will better optimize licensee and offsite agencies emergency planning resources and reduce the resources associated with emergency planning.},
	language = {English},
	number = {INL/EXT-20-58467-Rev000},
	urldate = {2024-07-02},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Christensen, Jason Albert and Moe, Wayne L. and Jordan, Peter},
	month = may,
	year = {2020},
	doi = {10.2172/1668830},
}

@techreport{vedros_expansion_2023,
	title = {Expansion of {Hazards} and {Probabilistic} {Risk} {Assessments} of a {Light}-{Water} {Reactor} {Coupled} with {Electrolysis} {Hydrogen} {Production} {Plants}},
	url = {https://www.osti.gov/servlets/purl/1998560/},
	language = {en},
	number = {INL/RPT--23-74319-Rev000, 1998560},
	urldate = {2024-07-02},
	author = {Vedros, Kurt and Christian, Robby and Yang Hui Otani, Courtney},
	month = aug,
	year = {2023},
	doi = {10.2172/1998560},
	pages = {INL/RPT--23--74319--Rev000, 1998560},
}

@techreport{vedros_expansion_2023-1,
	title = {Expansion of {Hazards} and {Probabilistic} {Risk} {Assessments} of a {Light}-{Water} {Reactor} {Coupled} with {Electrolysis} {Hydrogen} {Production} {Plants}},
	url = {https://www.osti.gov/biblio/1998560},
	abstract = {This report builds upon the body of work sponsored by the Department of Energy (DOE) Light-Water Reactor Sustainability (LWRS) Flexible Power Operation and Generation (FPOG) program that presented generic probabilistic risk assessments (PRAs) for the addition of a heat extraction system (HES) to light-water reactors to support the co-location of a high temperature hydrogen electrolysis facility (HTEF). Probabilistic and deterministic hazards assessments and risk analyses are leveraged throughout this report. Several improvements and new analyses are included in this report. First, higher amounts of detail in the specifications of the generic HTEFs are used to produce scaled results for a 100, 500, and 1000 MW nominal hydrogen production facility. An additional hazard assessment of 1000 kg of hydrogen storage is performed. The facility hazards and footprint are assessed to determine the safe distance required for placement near the nuclear power plant (NPP). Second, specific designs for corresponding HESs for the different levels of support required by the HTEFs are analyzed in the PRA model. Third, a hazards analysis of the specified HTEFs leads not only to effects of the quantified risk assessment for the NPP, but also qualitative hazards assessment for the community. Finally, a seismic analysis and a high winds analysis have each been added to the PRA. The results investigate the applicability of the potential licensing approaches which do not require a full United States (U.S.) Nuclear Regulatory Commission (NRC) licensing review. The PRAs are generic and include listed assumptions. The HTEF design built for this project has further eliminated many conservative assumptions from the prior PRAs in this series. The PRA results indicate that the 10 CFR 50.59 licensing approach is justified due to the minimal increase in initiating event frequencies for all design basis accidents, with none exceeding 7.7\%. The PRA results for core damage frequency and large early release frequency support the use of NRC Regulation Guide 1.174 as further risk information that supports a change without a full licensing amendment review. The hazard analyses and PRA confirm the need for engineered blast barriers of storage tanks and the common production header leaving the HTEF. The hazards analyses and PRA also confirm with high confidence that using the assumptions of design in this report that the safety case for licensing an HES addition and an HTEF sited with its unprotected high-pressure stage components 187 meters from the NPP’s transmission towers (the most fragile structure, system, and component) is strong.},
	language = {English},
	number = {INL/RPT-23-74319-Rev000},
	urldate = {2024-07-02},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Vedros, Kurt G. and Christian, Robby and Yang Hui Otani, Courtney Mariko},
	month = aug,
	year = {2023},
	doi = {10.2172/1998560},
}

@article{locatelli_emergency_nodate,
	title = {{EMERGENCY} {PLANNING} {ZONE}: {CONSTRAINTS} {AND} {OPPORUNITIES} {FOR} {THE} {DEVELOPMENT} {OF} {NUCLEAR} {ENERGY} {AND} {EXPLOTATION} {OF} {ITS} {PROCESS} {HEAT}},
	abstract = {Light Water Reactors (LWR), which represent the most common reactor in operation and under construction, have an average thermal efficiency of about 33\%-35\%, therefore two third of the thermal energy produced by the nuclear reaction is typically wasted. The literature presents many possible applications of this thermal energy, however most of them are not feasible because of economic and legislative constraints: among the others the Emergency Planning Zone (EPZ) is one of the most critic. The EPZ is the area surrounding the Nuclear Power Plants (NPP) subject to specific rules constraining the development of the area. These constraints avoid the complete exploitation of the energy produced by the power plants.},
	language = {en},
	author = {Locatelli, Giorgio and Mancini, Mauro},
}

@inproceedings{jung_study_2020,
	address = {GangWon Republic of Korea},
	title = {A {Study} on the {Application} of {Technical} {Assessment} {Methodology} ({TAM}) for {CyberSecurity} in {Nuclear} {Power} {Plant}},
	isbn = {978-1-4503-8304-2},
	url = {https://dl.acm.org/doi/10.1145/3440943.3444741},
	doi = {10.1145/3440943.3444741},
	abstract = {Recently 1 , cyber attacks targeting Industrial Control Systems (ICS) have been increasing rapidly; accordingly, cyber security applications and security evaluations of ICS are becoming very important. Technical Assessment Methodology (TAM) is a method developed by the Electric Power Research Institute (EPRI) in the United States for assessing and applying security control methods for power plants. By applying TAM, limitations of cyber security application and security evaluation of existing nuclear facilities are able to address. In this study, a virtual test bed was composed for one of the safety systems of APR1400, and the TAM was applied and analyzed to derive two advantages and five features of TAM. Based on this, the rationale for using TAM for the application and assessment of security control methods in nuclear facilities was explained, including five considerations for the better application of TAM. Finally, we propose future work for applying TAM.},
	language = {en},
	urldate = {2024-06-28},
	booktitle = {Proceedings of the 2020 {ACM} {International} {Conference} on {Intelligent} {Computing} and its {Emerging} {Applications}},
	publisher = {ACM},
	author = {Jung, Daun and Shin, Jiho and Lee, Chaechang and Kwon, Kookheui and Seo, Jung Taek},
	month = dec,
	year = {2020},
	pages = {1--7},
}

@inproceedings{lee_t__maccaronne_design_nodate,
	address = {Las Vegas, Nevada},
	title = {Design of {Defensive} {Cyber} {Security} {Architectures} {Using} {Event} {Trees}},
	doi = {doi.org/10.13182/T130-44645},
	language = {English},
	publisher = {ANS},
	author = {{Lee T.  Maccaronne}},
}

@article{noauthor_muap-07004-np_nodate,
	title = {{MUAP}-07004-{NP}, "{Safety} {I}\&{C} {System} {Description} and {Design} {Process}."},
	language = {en},
}

@techreport{kolaczkowski_demonstrating_2007,
	title = {Demonstrating the {Feasibility} and {Reliability} of {Operator} {Manual} {Actions} in {Response} to {Fire}},
	language = {en},
	number = {NUREG-1852},
	institution = {Sandia National Laboratories},
	author = {Kolaczkowski, A. and Forester, J. and Gallucci, R. and Bongarra, J.},
	month = oct,
	year = {2007},
}

@techreport{lindeman_eprinrc-res_2020,
	title = {{EPRI}/{NRC}-{RES} {Fire} {Human} {Reliability} {Analysis} {Guidelines}—{Qualitative} {Analysis} for {Main} {Control} {Room} {Abandonment} {Scenarios}},
	language = {en},
	number = {NUREG-1921},
	institution = {Electric Power Research Institute (EPRI)},
	author = {Lindeman, A.},
	month = jan,
	year = {2020},
}

@article{noauthor_summary_nodate,
	title = {Summary of {September} 1-2, 2015 {Nuclear} {Regulatory} {Commission} and {Department} of {Energy} {Co}-{Hosted} {Workshop} on {Advanced} {Non}-{Light} {Water} {Reactors}.},
	language = {en},
}

@article{thompson_results_nodate,
	title = {{RESULTS} {OF} {EVALUATION} {OF} {EMERGENCY} {PLANNING} {FOR} {EVOLUTIONARY} {AND} {ADVANCED} {REACTORS}},
	abstract = {In response to a Commission request, the staff performed an evaluation to develop technical criteria and methods for EP for evolutionary and advanced reactor designs. The evaluation focused on the evolutionary and passive advanced light water reactor (LWR) designs because of the availability of design and risk assessment data and because applicants were pursuing certification of these designs. The staff determined that the rationale upon which EP for current reactor designs is based, that is, potential consequences from a spectrum of accidents, is appropriate for use as the basis for EP for evolutionary and passive advanced LWR designs and is consistent with the Commission's defense-in-depth safety philosophy. Rigid application of the technical criteria derived from this rationale against the evolutionary and passive advanced LWR designs indicates that no changes to EP requirements are warranted because the potential consequences of severe accidents associated with evolutionary and passive advanced LWRs are similar to those for current reactors. The staff recognizes the industry's significant effort to make evolutionary and passive advanced LWRs safer than current designs. The staff also recognizes that changes to EP requirements may be warranted if the technical criteria for the EP requirements were modified to account for the lower probability of severe accidents or the longer time period between accident initiation and release of radioactive material for most severe accidents associated with evolutionary and passive advanced LWRs. In order to justify these types of changes to the EP basis, the staff believes that several issues, which would require significant expenditure of staff resources, need to be addressed: (1) the probability level, if any, below which accidents will not be considered for EP, (2) the use of increased safety in one level of the defense-in-depth framework to justify reducing requirements in another level, and (3) the acceptance of such changes by Federal, State, and local emergency response agencies. Because industry has not petitioned for changes to EP requirements for evolutionary and passive advanced LWRs, the staff did not dedicate the resources to fully evaluate these issues. The staff remains receptive to industry petitions for changes to EP requirements for evolutionary and passive advanced LWRs but it does not intend to dedicate further staff resources until such a petition is received.},
	language = {en},
	author = {Thompson, Hugh L},
}

@article{doane_proposed_nodate,
	title = {{PROPOSED} {RULE}: {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES} ({RIN} 3150-{AJ68}; {NRC}-2015-0225)},
	abstract = {The U.S. Nuclear Regulatory Commission (NRG) staff is proposing to.amend regulations that would specify new alternative EP requirements for SMRs and ONTs. The new EP requirements and implementing guidance would acknowledge technological advancements and other differences from large light-water reactors (LWRs) inherent in SMRs and ONTs, such as non-LWRs arid certain non-power production or utilization facilities (NPUFs). Concurrently, the NRG also proposes to issue for public comment draft regulatory guide (DG) DG-1350, "Emergency Preparedness for Small Modular Reactors and Other New Technologies." The NRG staff plans to hold a public meeting to promote full understanding of the proposed rule and guidance and to facilitate public comments.},
	language = {en},
	author = {Doane, Margaret M},
}

@article{johnson_development_nodate,
	title = {{DEVELOPMENT} {OF} {AN} {EMERGENCY} {PLANNING} {AND} {PREPAREDNESS} {FRAMEWORK} {FOR} {SMALL} {MODULAR} {REACTORS}},
	language = {en},
	author = {Johnson, Michael R},
}

@article{borchardt_potential_nodate,
	title = {{POTENTIAL} {POLICY}, {LICENSING}, {AND} {KEY} {TECHNICAL} {ISSUES} {FOR} {SMALL} {MODULAR} {NUCLEAR} {REACTOR} {DESIGNS}},
	abstract = {The U.S. Nuclear Regulatory Commission (NRC) staff has been meeting with the Department of Energy (DOE) and, as resources allowed, with individual SMR designers to discuss potential policy, licensing, and key technical issues for SMR designs. As a result of these pre-application activities and earlier work by the NRC staff and Commission, the NRC staff has identified a number of potential policy and licensing issues. The enclosure to this paper provides a summary description of these potential policy issues for Commission information. The discussions are consistent with information provided in previous Commission papers and other related agency documents. The references provided in Attachment 2 to the enclosure include these key Commission documents.},
	language = {en},
	author = {Borchardt, R W},
}

@techreport{nuclear_regulatory_commission_washington_dc_usa_office_of_nuclear_regulatory_research_standard_1990,
	title = {Standard format and content for emergency plans for fuel cycle and materials facilities},
	url = {http://www.osti.gov/servlets/purl/6533759-59VUBj/},
	language = {en},
	number = {REG/G-91001955, 6533759},
	urldate = {2024-05-29},
	author = {{Nuclear Regulatory Commission, Washington, DC (USA). Office of Nuclear Regulatory Research}},
	month = sep,
	year = {1990},
	doi = {10.2172/6533759},
	pages = {REG/G--91001955, 6533759},
}

@article{lynch_regulatory_nodate,
	title = {{REGULATORY} {GUIDE} 2.6},
	language = {en},
	author = {Lynch, S and Wertz, G},
}

@article{noauthor_required_nodate,
	title = {Required {Analyses} for {Informing} {Emergency} {Planning} {Zone} {Size} {Determinations}.},
	language = {en},
}

@article{smith_nuregcr-7285_nodate,
	title = {{NUREG}/{CR}-7285, "{Nonradiological} {Health} {Consequences} from {Evacuation} and {Relocation}"},
	language = {en},
	author = {Smith, Todd},
}

@techreport{collins_planning_1978,
	title = {Planning basis for the development of state and local government {Radiological} {Emergency} {Response} {Plans} in support of light water nuclear power plants},
	url = {http://www.osti.gov/servlets/purl/5765828-1RlU8D/},
	language = {en},
	number = {NUREG-0396, EPA-520/1-78-016, 5765828},
	urldate = {2024-05-29},
	author = {Collins, H.E. and Grimes, B.K. and Galpin, F.},
	month = dec,
	year = {1978},
	doi = {10.2172/5765828},
	pages = {NUREG--0396, EPA--520/1--78--016, 5765828},
}

@article{univ_nuregcr-7269_nodate,
	title = {{NUREG}/{CR}-7269, "{Enhancing} {Guidance} for {Evacuation} {Time} {Estimate} {Studies}"},
	language = {en},
	author = {Univ, Embry-Riddle Aeronautical and Univ, Louisiana State},
}

@article{denneny_nuregcr-7248_nodate,
	title = {{NUREG}/{CR}-7248 "{Capabilities} and {Practices} of {Offsite} {Response} {Organizations} for {Protective} {Actions} in the {Intermediate} {Phase} of a {Radiological} {Emergency} {Response}."},
	language = {en},
	author = {Denneny, Matt},
}

@article{noauthor_nureg-2161_nodate,
	title = {{NUREG}-2161, "{Consequence} {Study} of a {Beyond}-{Design}-{Basis} {Earthquake} {Affecting} the {Spent} {Fuel} {Pool} for a {U}.{S}. {Mark} {I} {Boiling} {Water} {Reactor}."},
	language = {en},
}

@article{noauthor_nsirdpr-isg-01_2011,
	title = {{NSIR}/{DPR}-{ISG}-01, "{Interim} {Staff} {Guidance} - {Emergency} {Planning} {For} {Nuclear} {Power} {Plants}."},
	language = {en},
	journal = {EMERGENCY PLANNING FOR NUCLEAR POWER PLANTS},
	year = {2011},
}

@article{clark_secy-20-0045_nodate,
	title = {{SECY}-20-0045: {Population} {Related} {Siting} {Considerations} for {Advanced} {Reactors} {Disapproved} {X} {Abstain}},
	language = {en},
	author = {Clark, Brooke P and Baran, Commissioner},
}

@article{mccree_proposed_nodate,
	title = {{PROPOSED} {RULE}: {REGULATORY} {IMPROVEMENTS} {FOR} {PRODUCTION} {AND} {UTILIZATION} {FACILITIES} {TRANSITIONING} {TO} {DECOMMISSIONING} ({RIN} 3150-{AJ59})},
	language = {en},
	author = {McCree, Victor M},
}

@article{mccree_rulemaking_nodate,
	title = {{RULEMAKING} {PLAN} {ON} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {McCree, Victor M},
}

@article{vietti-cook_staff_nodate,
	title = {{STAFF} {REQUIREMENTS} – {SECY}-16-0069 – {RULEMAKING} {PLAN} {ON} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {Vietti-Cook, Annette L},
}

@article{satorius_options_nodate,
	title = {{OPTIONS} {FOR} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {Satorius, Mark A},
}

@article{vietti-cook_staff_nodate-1,
	title = {{STAFF} {REQUIREMENTS} – {SECY}-15-0077 – {OPTIONS} {FOR} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {Vietti-Cook, Annette L},
}

@article{satorius_performance-based_nodate,
	title = {{PERFORMANCE}-{BASED} {FRAMEWORK} {FOR} {NUCLEAR} {POWER} {PLANT} {EMERGENCY} {PREPAREDNESS} {OVERSIGHT}},
	language = {en},
	author = {Satorius, Mark A},
}

@article{vietti-cook_staff_nodate-2,
	title = {{STAFF} {REQUIREMENTS} - {SECY}-06-0200 - {RESULTS} {OF} {THE} {REVIEW} {OF} {EMERGENCY} {PREPAREDNESS} {REGULATIONS} {AND} {GUIDANCE}},
	language = {en},
	author = {Vietti-Cook, Annette L},
}

@article{klein_aprvd_nodate,
	title = {{APRVD} {DISAPRVD} {ABSTAIN} {PARTICIP} {COMMENTS} {DATE}},
	language = {en},
	author = {Klein, Chrm},
}

@article{podolak_criteria_nodate,
	title = {Criteria for {Preparation} and {Evaluation} of {Radiological} {Emergency} {Response} {Plans} and {Preparedness} in {Support} of {Nuclear} {Power} {Plants}},
	language = {en},
	author = {Podolak, E M and Sanders, M E and Wingert, V L and Donovan, R W},
}

@article{noauthor_nureg-0654fema-rep-1_nodate,
	title = {{NUREG}-0654/{FEMA}-{REP}-1, {Rev}. 2 "{Criteria} for {Preparation} and {Evaluation} of {Radiological} {Emergency} {Response} {Plans} and {Preparedness} in {Support} of {Nuclear} {Power} {Plants}", {Final} {Report}},
	abstract = {NUREG-0654/FEMA-REP-1, “Criteria for Preparation and Evaluation of Radiological Emergency Response Plans and Preparedness in Support of Nuclear Power Plants,” is a joint United States Nuclear Regulatory Commission (NRC) NUREG-series publication and Federal Emergency Management Agency (FEMA) guidance document. Both agencies use the document to evaluate the adequacy of the emergency plans and preparedness of state, local, and tribal governments within the emergency planning zones (EPZs) surrounding commercial nuclear power plants (NPPs), as well as those of the commercial NPP applicants and licensees.},
	language = {en},
}

@article{satorius_request_nodate,
	title = {{REQUEST} {BY} {DOMINION} {ENERGY} {KEWAUNEE}, {INC}. {FOR} {EXEMPTIONS} {FROM} {CERTAIN} {EMERGENCY} {PLANNING} {REQUIREMENTS}},
	abstract = {The EP requirements of 10 CFR 50.47, “Emergency Plans,” and Appendix E, “Emergency Planning and Preparedness for Production and Utilization Facilities,” to 10 CFR Part 50 continue to apply to a nuclear power reactor after permanent cessation of operations and removal of fuel from the reactor vessel. There are no explicit regulatory provisions distinguishing EP requirements for a power reactor that has been shut down from those for an operating power reactor.},
	language = {en},
	author = {Satorius, Mark A},
}

@article{satorius_request_nodate-1,
	title = {{REQUEST} {BY} {DUKE} {ENERGY} {FLORIDA}, {INC}., {FOR} {EXEMPTIONS} {FROM} {CERTAIN} {EMERGENCY} {PLANNING} {REQUIREMENTS}},
	abstract = {The EP requirements of 10 CFR 50.47, “Emergency Plans,” and Appendix E, “Emergency Planning and Preparedness for Production and Utilization Facilities,” to 10 CFR Part 50 continue to apply to a nuclear power reactor after permanent cessation of operations and removal of fuel from the reactor vessel. There are no explicit regulatory provisions distinguishing EP requirements for a power reactor that has been shut down from those for an operating power reactor.},
	language = {en},
	author = {Satorius, Mark A},
}

@article{diaz_voting_nodate,
	title = {{VOTING} {SUMMARY} - {SECY}-04-0236 {RECORDED} {VOTES}},
	language = {en},
	author = {Diaz, Chrm},
}

@article{olmstead_robert_nodate,
	title = {{ROBERT} {BEALL}, {NMSS} {KATHRYN} {BROCK}, {NMSS} {ARLON} {COSTA}, {NRR} {MICHELLE} {HART}, {NRR} {CHRIS} {HOWELLS}, {NMSS} {BOB} {KAHLER}, {NSIR} {ERIC} {SCHRADER}, {NSIR} {JOHN} {SEGALA}, {NRR}},
	language = {en},
	author = {Olmstead, Joan and Beall, Robert and Brock, Kathryn and Costa, Arlon and Hart, Michelle and Howells, Chris and Kahler, Bob and Schrader, Eric and Segala, John},
}

@article{vietti-cook_staff_nodate-3,
	title = {{STAFF} {REQUIREMENTS} – {SECY}-15-0077 – {OPTIONS} {FOR} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {Vietti-Cook, Annette L},
}

@article{satorius_options_nodate-1,
	title = {{OPTIONS} {FOR} {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES}},
	language = {en},
	author = {Satorius, Mark A},
}

@article{doane_proposed_nodate-1,
	title = {{PROPOSED} {RULE}: {EMERGENCY} {PREPAREDNESS} {FOR} {SMALL} {MODULAR} {REACTORS} {AND} {OTHER} {NEW} {TECHNOLOGIES} ({RIN} 3150-{AJ68}; {NRC}-2015-0225)},
	abstract = {The U.S. Nuclear Regulatory Commission (NRG) staff is proposing to.amend regulations that would specify new alternative EP requirements for SMRs and ONTs. The new EP requirements and implementing guidance would acknowledge technological advancements and other differences from large light-water reactors (LWRs) inherent in SMRs and ONTs, such as non-LWRs arid certain non-power production or utilization facilities (NPUFs). Concurrently, the NRG also proposes to issue for public comment draft regulatory guide (DG) DG-1350, "Emergency Preparedness for Small Modular Reactors and Other New Technologies." The NRG staff plans to hold a public meeting to promote full understanding of the proposed rule and guidance and to facilitate public comments.},
	language = {en},
	author = {Doane, Margaret M},
}

@article{vietti-cook_secy-22-0001_nodate,
	title = {{SECY}-22-0001: {Rulemaking}: {Final} {Rule}: {Emergency} {Preparedness} for {Small} {Modular} {Reactors} and {Other} {New} {Technologies}},
	language = {en},
	author = {Vietti-Cook, Annette and Wright, Commissioner},
}

@article{clark_secy-22-0001_nodate,
	title = {{SECY}-22-0001: {Rulemaking}: {Final} {Rule}: {Emergency} {Preparedness} for {Small} {Modular} {Reactors} and {Other} {New} {Technologies}},
	language = {en},
	author = {Clark, Brooke P and Baran, Commissioner},
}

@techreport{noauthor_traditional_nodate,
	title = {Traditional {Probabilistic} {Risk} {Assessment} methods for digital systems},
	url = {https://www.nrc.gov/docs/ml0831/ml083110448.pdf},
	urldate = {2024-06-11},
}

@unpublished{eide_industry-average_nodate,
	title = {Industry-{Average} {Performance} for {Components} and {Initiating} {Events} at {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}},
	url = {https://nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6928/index.html},
	urldate = {2021-01-22},
	author = {Eide, S. A. and Wierman, T. E. and Gentillon, C. D. and Rasmuson, D. M. and Atwood, C. L.},
}

@techreport{sund_htgr_1976,
	title = {{HTGR} {Accident} {Initiation} and {Progression} {Analysis} {Status} {Report}. {Volume} {VII}. {Occupational} {Radiation} {Exposures} from {Gas}-{Borne} and {Plateout} {Activities}},
	url = {https://www.osti.gov/biblio/7283894},
	number = {GA-A-13617},
	institution = {General Atomics, San Diego, CA (United States)},
	author = {Sund, R. E.},
	month = jan,
	year = {1976},
}

@techreport{raabe_htgr_1976,
	title = {{HTGR} {Accident} {Initiation} and {Progression} {Analysis} {Status} {Report}. {Volume} 1. {Introduction} and {Summary}},
	url = {https://www.osti.gov/biblio/7364654},
	number = {GA-A-13617},
	institution = {General Atomics, San Diego, CA (United States)},
	author = {Raabe, P. H. and Houghton, W. J. and Joksimovic, V.},
	month = jan,
	year = {1976},
}

@techreport{alberstein_htgr_1976,
	title = {{HTGR} {Accident} {Initiation} and {Progression} {Analysis} {Status} {Report}. {Volume} {V}. {AIPA} {Fission} {Product} {Source} {Terms}},
	url = {https://www.osti.gov/biblio/7283899},
	number = {GA-A-13617},
	institution = {General Atomics., San Diego, CA (USA)},
	author = {Alberstein, D. and Apperson, C. E. and Hanson, D. L. and Myers, B. F. and Pfeiffer, W. W.},
	month = feb,
	year = {1976},
}

@article{morton_btp_2021,
	title = {{BTP} 7-19, {Revision} 8, {January} 2021},
	language = {en},
	author = {Morton, Wendell},
	year = {2021},
}

@techreport{flemming_htgr_1978,
	title = {{HTGR} accident initiation and progression analysis status report. {Phase} {II} risk assessment},
	url = {https://www.osti.gov/servlets/purl/6649461/},
	language = {en},
	number = {GA-A-15000, 6649461},
	urldate = {2024-04-14},
	author = {Flemming, K. N.},
	month = apr,
	year = {1978},
	doi = {10.2172/6649461},
	pages = {GA--A--15000, 6649461},
}

@article{langseth_inference_2009,
	title = {Inference in hybrid {Bayesian} networks},
	volume = {94},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832009000581},
	doi = {10.1016/j.ress.2009.02.027},
	abstract = {Since the 1980s, Bayesian networks (BNs) have become increasingly popular for building statistical models of complex systems. This is particularly true for boolean systems, where BNs often prove to be a more efficient modelling framework than traditional reliability techniques (like fault trees and reliability block diagrams). However, limitations in the BNs’ calculation engine have prevented BNs from becoming equally popular for domains containing mixtures of both discrete and continuous variables (the so-called hybrid domains). In this paper we focus on these difficulties, and summarize some of the last decade's research on inference in hybrid Bayesian networks. The discussions are linked to an example model for estimating human reliability.},
	number = {10},
	urldate = {2024-06-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Langseth, Helge and Nielsen, Thomas D. and Rumí, Rafael and Salmerón, Antonio},
	month = oct,
	year = {2009},
	keywords = {Bayesian networks, Hybrid models, Inference, Reliability},
	pages = {1499--1509},
}

@article{bensi_efficient_2013,
	title = {Efficient {Bayesian} network modeling of systems},
	volume = {112},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832012002475},
	doi = {10.1016/j.ress.2012.11.017},
	abstract = {The Bayesian network (BN) is a convenient tool for probabilistic modeling of system performance, particularly when it is of interest to update the reliability of the system or its components in light of observed information. In this paper, BN structures for modeling the performance of systems that are defined in terms of their minimum link or cut sets are investigated. Standard BN structures that define the system node as a child of its constituent components or its minimum link/cut sets lead to converging structures, which are computationally disadvantageous and could severely hamper application of the BN to real systems. A systematic approach to defining an alternative formulation is developed that creates chain-like BN structures that are orders of magnitude more efficient, particularly in terms of computational memory demand. The formulation uses an integer optimization algorithm to identify the most efficient BN structure. Example applications demonstrate the proposed methodology and quantify the gained computational advantage.},
	urldate = {2024-06-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Bensi, Michelle and Kiureghian, Armen Der and Straub, Daniel},
	month = apr,
	year = {2013},
	keywords = {Bayesian network, Integer optimization, Max-flow min-cut theorem, Minimum cut sets, Minimum link sets, Parallel systems, Series systems, Systems},
	pages = {200--213},
}

@techreport{muhlheim_technical_2016,
	title = {Technical {Basis} for {Evaluating} {Software}-{Related} {Common}-{Cause} {Failures}},
	url = {http://www.osti.gov/servlets/purl/1279406/},
	language = {en},
	number = {ORNL/SR--2016/130, 1279406},
	urldate = {2024-06-06},
	author = {Muhlheim, Michael David and Wood, Richard},
	month = apr,
	year = {2016},
	doi = {10.2172/1279406},
	pages = {ORNL/SR--2016/130, 1279406},
}

@article{noauthor_protecting_nodate,
	title = {Protecting {Against} {Digital} {Common}-{Cause} {Failure}},
	language = {en},
}

@article{noauthor_protecting_nodate-1,
	title = {Protecting {Against} {Digital} {Common}-{Cause} {Failure}},
	language = {en},
}

@book{hashemian_maintenance_2006,
	series = {Power {Systems}},
	title = {Maintenance of {Process} {Instrumentation} in {Nuclear} {Power} {Plants}},
	isbn = {978-3-540-33703-4},
	url = {http://link.springer.com/10.1007/978-3-540-33704-1},
	language = {en},
	urldate = {2024-01-06},
	publisher = {Springer Berlin Heidelberg},
	author = {Hashemian, H.M.},
	year = {2006},
	doi = {10.1007/978-3-540-33704-1},
}

@inproceedings{hite_symple_2021,
	address = {ANS Virtual Meeting},
	title = {{SymPLe}: {A} {Complexity}-{Aware} {Approach} for {Realizing} {Verifiable} {FPGA}-{Based} {Digital} {I}\&{C} for {Safety} {Critical} {Applications}},
	isbn = {978-0-89448-779-8},
	shorttitle = {{SymPLe}},
	url = {https://www.ans.org/pubs/proceedings/article-49775/},
	doi = {10.13182/T124-34547},
	language = {en},
	urldate = {2024-06-03},
	booktitle = {12th {Nuclear} {Plant} {Instrumentation}, {Control} and {Human}-{Machine} {Interface} {Technologies} ({NPIC}\&{HMIT} 2021)},
	publisher = {American Nuclear Society},
	author = {Hite, Richard and Deloglos, Christopher and Jayakumar, Athira and Gautham, Smitha and Collins, Aidan and Rajagopala, Abhi and Elks, Carl and Gibson, Matt},
	year = {2021},
	pages = {496--508},
}

@techreport{gibson_achieving_2019,
	title = {Achieving {Verifiable} and {High} {Integrity} {Instrumentation} and {Control} {Systems} through {Complexity} {Awareness} and {Constrained} {Design}. {Final} {Report}},
	url = {http://www.osti.gov/servlets/purl/1547345/},
	language = {en},
	number = {DOE/NEUP--15-8044, 1547345},
	urldate = {2024-06-03},
	author = {Gibson, Matt and Elks, Carl and Tantawy, Ashraf and Hite, Richard and Gautham, Smitha and Jayakumar, Athira and Deloglos, Christopher},
	month = jul,
	year = {2019},
	doi = {10.2172/1547345},
	pages = {DOE/NEUP--15--8044, 1547345},
}

@techreport{noauthor_combinatorial_nodate,
	title = {Combinatorial {Testing} for {Digital} {Instrumentation} and {Control} {Systems}},
	url = {https://restservice.epri.com/publicdownload/000000000001023010/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_protecting_nodate-2,
	title = {Protecting {Against} {Digital} {Common}-{Cause} {Failure}: {Combining} {Defensive} {Measures} and {Diversity} {Attributes}},
	url = {https://restservice.epri.com/publicdownload/000000000001019182/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_hazard_nodate,
	title = {Hazard {Analysis} {Methods} for {Digital} {Instrumentation} and {Control} {Systems}},
	url = {https://restservice.epri.com/publicdownload/000000003002000509/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_methods_nodate,
	title = {Methods and {Tools} for {Evaluating} {Digital} {Control} {System} {Architectures}},
	url = {https://restservice.epri.com/publicdownload/000000003002000537/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_systems_nodate,
	title = {Systems {Engineering} {Process}: {Methods} and {Tools} for {Digital} {Instrumentation} and {Control} {Projects}},
	url = {https://restservice.epri.com/publicdownload/000000003002008018/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_digital_nodate,
	title = {Digital {Control} {Systems}: {Survey} of {Current} {Preventive} {Maintenance} {Practices} and {Experience}},
	url = {https://restservice.epri.com/publicdownload/000000000001022713/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_guideline_nodate,
	title = {Guideline for {Performing} {Defense}-in-{Depth} and {Diversity} {Assessments} for {Digital} {Upgrades}: {Applying} {Risk}-{Informed} and {Deterministic} {Methods}},
	url = {https://restservice.epri.com/publicdownload/000000000001002835/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_operating_nodate,
	title = {Operating {Experience} {Insights} on {Common}-{Cause} {Failures} in {Digital} {Instrumentation} and {Control} {Systems}},
	url = {https://restservice.epri.com/publicdownload/000000000001016731/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_practical_nodate,
	title = {Practical {Maintenance} of {Digital} {Systems}: {Guidance} to {Maximize} the {Benefits} of {Digital} {Technology} for the {Maintenance} of {Digital} {Systems} and {Plant} {Equipment}},
	url = {https://restservice.epri.com/publicdownload/000000000001008124/0/Product},
	urldate = {2024-06-03},
}

@techreport{noauthor_preventive_2023,
	type = {Technical {Report}},
	title = {Preventive {Maintenance} {Practices} for {Digital} {Instrumentation} and {Control} {Systems}},
	url = {https://restservice.epri.com/publicdownload/000000003002000502/0/Product},
	number = {3002000502},
	urldate = {2024-06-03},
	institution = {EPRI},
	month = aug,
	year = {2023},
}

@techreport{noauthor_effects_2009,
	type = {Technical {Report}},
	title = {Effects of {Digital} {Instrumentation} and {Control} {Defense}-in-{Depth} and {Diversity} on {Risk} in {Nuclear} {Power} {Plants}},
	url = {https://restservice.epri.com/publicdownload/000000000001019183/0/Product},
	number = {1019183},
	urldate = {2024-06-03},
	institution = {EPRI},
	month = dec,
	year = {2009},
	pages = {138},
}

@article{kerlin_htgr_1976,
	title = {{HTGR} {Steam} {Generator} {Modeling}},
	language = {en},
	author = {Kerlin, T VV},
	month = jul,
	year = {1976},
	pages = {86},
}

@techreport{williams_nureg-1338_1989,
	title = {{NUREG}-1338, "{Draft} {Preapplication} {Safety} {Evaluation} {Report} for the {Modular} {High}-{Temperature} {Gas}-{Cooled} {Reactor}."},
	abstract = {This draft safety evaluation report (SER) presents the preliminary results of a preapplication design review for the standard modular high-temperature gascooled reactor (MHTGR) (Project 672). The MHTGR conceptual design was submitted by the U.S. Department of Energy (DOE) in accordance with the U.S. Nuclear Regulatory Commission (NRC) "Statement of Policy for the Regulation of Advanced Nuclear Power Plants" (51 FR 24643), which provides for early Commission review and interaction. The standard MHTGR consists of four identical reactor modules, each with a thermal output of 350 MWt, coupled with two steam turbine-generator sets to produce a total plant electrical output of 540 MWe. The reactors are helium cooled and graphite moderated and utilize ceramically coated particletype nuclear fuel. The design includes passive reactor-shutdown and decay-heatremoval features. The staff and its contractors at the Oak Ridge National Laboratory and the Brookhaven National Laboratory have reviewed this design with emphasis on those unique provisions in the design that accomplish the key safety functions of reactor shutdown, decay-heat removal, and containment of radioactive material. This report presents the NRC staff's technical evaluation of those features in the MHTGR design important to safety, including their proposed research and testing needs. In addition, this report presents the criteria proposed by the NRC staff to judge the acceptability of the MHTGR design and, where possible, includes statements on the potential of the MHTGR to meet these criteria. However, it should be recognized that final conclusions in all matters discussed in this report require approval by the Commission. Final determination on the acceptability of the MHTGR standard design is contingent on receipt and evaluation of additional information requested from DOE pertaining to the adequacy of the containment design and on the following: (1) satisfactory resolution of open safety issues identified in this report and possible additional safety issues that may become identified at later stages of review (2) satisfactory completion of final design and licensing reviews by NRC (3) conformance with applicable NRC rules, regulations, and other guidelines current at the time of any future licensing action (4) successful completion of required research and development activities, including design, construction, testing, and operation of a prototype reactor before design certification.},
	language = {en},
	author = {Williams, , P. M and King, T. L. and Wilson, J. N.},
	month = mar,
	year = {1989},
	pages = {315},
}

@article{noauthor_protecting_nodate-3,
	title = {Protecting {Against} {Digital} {Common}-{Cause} {Failure}},
	language = {en},
}

@unpublished{wall_kaplan_2011,
	address = {Defense Resources Management Institute, Naval Postgraduate School},
	title = {The {Kaplan} and {Garrick} {Definition} of {Risk} and its {Application} to {Managerial} {Decision} {Problems}},
	url = {https://www.semanticscholar.org/paper/The-Kaplan-and-Garrick-Definition-of-Risk-and-its-Wall/d49316a21ccba882f3cff24524a987ebb3f6c683},
	abstract = {This paper discusses the application of the Kaplan and Garrick (K\&G) definition of risk in the context of the managerial decision problem. These problems have a formulation that provides a different information structure than that originally considered by K\&G. A fourth question must to be asked. The decision maker’s preferences must be ascertained. Without knowledge of decision maker preference there is no risk. The answer to the fourth question gives the decision maker’s payoff function, v(Y ). A new triple \{Y, PY , v(Y )\} replaces the original triple of K\&G, \{F, PF , Y (F )\} and permits an explicit quantification of risk.},
	urldate = {2024-05-31},
	author = {Wall, K.},
	year = {2011},
}

@article{aven_three_2020,
	title = {Three influential risk foundation papers from the 80s and 90s: {Are} they still state-of-the-art?},
	volume = {193},
	issn = {0951-8320},
	shorttitle = {Three influential risk foundation papers from the 80s and 90s},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832019302649},
	doi = {10.1016/j.ress.2019.106680},
	abstract = {Three of the most influential scientific works in the risk field, at least in the engineering environment, are Stan Kaplan and John Garrick's paper from 1981 on risk quantification, George Apostolakis’ paper on probability from 1990, and Elisabeth Paté-Cornell's paper on uncertainty levels in risk assessments from 1996. The present article reviews and discusses these works, the aim being to acknowledge their important contributions to risk science and provide insights on how these works have influenced and relate to the state-of-the-art of the risk science of today. It is questioned to what extent these papers still represent state-of-the-art. Recent documents by the Society for Risk Analysis are used as a reference for comparison, in addition to related publications in scientific journals.},
	urldate = {2024-05-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Aven, Terje},
	month = jan,
	year = {2020},
	keywords = {Models, Risk characterization, Risk science, Uncertainties},
	pages = {106680},
}

@article{locatelli_smallmedium_2010,
	title = {Small–medium sized nuclear coal and gas power plant: {A} probabilistic analysis of their financial performances and influence of {CO2} cost},
	volume = {38},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {03014215},
	shorttitle = {Small–medium sized nuclear coal and gas power plant},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421510004908},
	doi = {10.1016/j.enpol.2010.06.027},
	abstract = {Nations or regions with limited electrical grid and restricted ﬁnancial resources are a suitable market for small medium power plants with a size of 300–400 MWe. The literature presents several comparisons about the economics of large power plants (of about 1000 MWe); however there are not probabilistic analysis regarding the economics of small medium power plants. This paper ﬁlls this gap comparing, with a Monte Carlo evaluation, the economical and ﬁnancial performances of a nuclear reactor, a coal ﬁred power plant and a combined cycle gas turbine (CCGT) of 335 MWe. The paper aims also to investigate the effect of the carbon tax and electrical energy price on the economics of these plants. The analysis show as, without any carbon tax, the coal plant has the lowest levelised unit electricity cost (LUEC) and the highest net present value (NPV). Introducing the carbon tax the rank changes: depending on its amount the ﬁrst and the nuclear after becomes the plant with lower LUEC and highest NPV. Therefore, the uncertainty in the carbon tax cost increases the risk of investing in a coal plant above the level of the new small medium reactor.},
	language = {en},
	number = {10},
	urldate = {2024-05-31},
	journal = {Energy Policy},
	author = {Locatelli, Giorgio and Mancini, Mauro},
	month = oct,
	year = {2010},
	pages = {6360--6374},
}

@article{kolaczkowski_core_nodate,
	title = {Core {Damage} {Frequency}: {Peach} {Bottom}, {Unit} 2 {Internal} {Events} {Appendices}},
	language = {en},
	author = {Kolaczkowski, Prepared A M and Cramond, W R and Sype, T T and Maloney, K J and Daniel, S L},
}

@article{johnson_initiating_nodate,
	title = {Initiating {Event} {Rates} at {U}.{S}. {Nuclear} {Power} {Plants}: 2022 {Update}},
	language = {en},
	author = {Johnson, Nancy and Ma, Zhegang},
}

@misc{noauthor_pra_nodate,
	title = {{PRA} {Procedures} {Guide}: {A} {Guide} to the {Performance} of {Probabilistic} {Risk} {Assessments} for {Nuclear} {Powe}},
	shorttitle = {{PRA} {Procedures} {Guide}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2300/index.html},
	abstract = {PRA  Procedures Guide: A Guide to the Performance of Probabilistic Risk Assessments for Nuclear Powe},
	language = {en-US},
	urldate = {2024-05-22},
	journal = {NRC Web},
}

@misc{earthperson_openpra-orginverse-canopy_2024,
	title = {openpra-org/inverse-canopy: v0.0.21-doi},
	shorttitle = {openpra-org/inverse-canopy},
	url = {https://zenodo.org/records/10888233},
	abstract = {An inverse estimation technique for back-fitting conditional/functional event probability distributions in an event tree to match target end-state frequencies.},
	urldate = {2024-05-21},
	publisher = {Zenodo},
	author = {Earthperson, Arjun},
	month = mar,
	year = {2024},
	doi = {10.5281/zenodo.10888233},
}

@techreport{noauthor_review_nodate,
	title = {Review and {Evaluation} of the {Zion} {Probabilistic} {Safety} {Study}},
}

@article{noauthor_analysis_nodate,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY}: {ZION}, {UNIT} 1, {INTERNAL} {EVENTS}.},
	abstract = {This document contains the accident sequence analyses: of internally = initiated events for the Zion Unit 1 nuclear power plant.- This is one o fthe-five plant analyses conducted as part of the NUREG ll50 effort for-the Nuclear Regulatory Commission. The work performed and described here is an- extensive reanalysis of- the work published in. October 1986- as: -NUREG/CR-4550 Volume 7. It addresses comments from numerous reviewers and provides significantly more detailed modeling of most aspects of the Zion plant.},
	language = {en},
}

@techreport{noauthor_evaluation_nodate,
	title = {Evaluation of {Severe} {Accident} {Risks}: {Zion}, {Unit} 1},
}

@article{bertucio_analysis_nodate,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY}: {SURRY},{UNIT} 1,{INTERNAL} {EVENTS} {APPENDICES}.},
	abstract = {This document contains the appendices for the accident sequence analyses of internally initiated events for the Surry Nuclear Station, Unit 1. This is one of the five plant analyses conducted as part of the NUREG1150 effort by the Nuclear Regulatory Commission. NUREG-1150 documents the risk of a selected group of nuclear power plants. The work performed and described here is an extensive reanalysis of that published in November 1986 as NUREG/CR-4550, Volume 3. It addresses comments from numerous reviewers and significant changes to the plant systems and procedures made since the first report. The uncertainty analysis and presentation of results are also much improved. The context and detail of this report are directed toward PRA practitioners who need to know how the work was performed and the details for use in further studies.},
	language = {en},
	author = {Bertucio, Prepared R C and Julius, J A},
}

@misc{noauthor_analysis_nodate-1,
	title = {Analysis of {Core} {Damage} {Frequency}: {Sequoyah}, {Unit} 1 {Internal} {Events} {Appendices}},
}

@article{noauthor_analysis_nodate-2,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY}: {SURRY} {POWER} {STATION},{UNIT} 1 {EXTERNAL} {EVENTS}.},
	language = {en},
}

@article{noauthor_analysis_nodate-3,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY} {FROM} {INTERNAL} {EVENTS}: {SEQUOYAH},{UNIT} 1.},
	language = {en},
}

@techreport{lambright_analysis_1990,
	title = {Analysis of core damage frequency: {Peach} {Bottom}, {Unit} 2 external events},
	shorttitle = {Analysis of core damage frequency},
	url = {https://www.osti.gov/servlets/purl/6340600/},
	language = {en},
	number = {NUREG/CR-4550-Vol.4-Rev.1-Pt.3, SAND--86-2084-Vol.4-Rev.1-Pt.3, 6340600},
	urldate = {2024-05-21},
	author = {Lambright, J and Bohn, M and Daniel, S and Johnson, J and Ravindra, M and Hashimoto, P and Mraz, M and Tong, W and Brosseau, D},
	month = dec,
	year = {1990},
	doi = {10.2172/6340600},
	pages = {NUREG/CR--4550--Vol.4--Rev.1--Pt.3, SAND--86--2084--Vol.4--Rev.1--Pt.3, 6340600},
}

@techreport{kolaczkowski_analysis_1986,
	title = {Analysis of core damage frequency from internal events: {Peach} {Bottom}, {Unit} 2},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {http://www.osti.gov/servlets/purl/6993388-EIpa9m/},
	language = {en},
	number = {NUREG/CR-4550-Vol.4, SAND-86-2084, 6993388},
	urldate = {2024-04-29},
	author = {Kolaczkowski, A.M. and Lambright, J.A. and Ferrell, W.L. and Cathey, N.G. and Najafi, B. and Harper, F.T.},
	month = oct,
	year = {1986},
	doi = {10.2172/6993388},
	pages = {NUREG/CR--4550--Vol.4, SAND--86--2084, 6993388},
}

@article{noauthor_analysis_nodate-4,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY} {FROM} {INTERNAL} {EVENTS}:{GRAND} {GULF},{UNIT} 1.{Main} {Report}.},
	language = {en},
}

@article{noauthor_analysis_nodate-5,
	title = {{ANALYSIS} {OF} {CORE} {DAMAGE} {FREQUENCY}: {GRAND} {GULF}, {UNIT} 1 {INTERNAL} {EVENTS} {APPENDICES}.{Continuation} {Of} {Appendix} {D}.},
	language = {en},
}

@article{wheeler_expert_nodate,
	title = {Expert {Judgment} {Elicitation}},
	language = {en},
	author = {Wheeler, Prepared T A and Hora, S C and Cramond, W R and Unwin, S D},
}

@article{evans_uranium-zirconium_2024,
	title = {Uranium-zirconium hydride nuclear fuel performance in the {NaK}-cooled {MARVEL} microreactor},
	volume = {598},
	issn = {00223115},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022311524002472},
	doi = {10.1016/j.jnucmat.2024.155145},
	language = {en},
	urldate = {2024-05-14},
	journal = {Journal of Nuclear Materials},
	author = {Evans, Jordan A. and Sweet, Ryan T. and Medvedev, Pavel G. and Wagner, Adrian R. and Parisi, Carlo and Lange, Travis L. and Perez, Emmanuel and Rice, Francine and Jue, Jan-Fong and Woolstenhulme, Eric and Keiser, Dennis D. and Arafat, Yasir},
	month = sep,
	year = {2024},
	pages = {155145},
}

@article{wang_trustworthiness_2024,
	title = {Trustworthiness modeling and evaluation for a nearly autonomous management and control system},
	volume = {245},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832024000838},
	doi = {10.1016/j.ress.2024.110008},
	abstract = {The Nearly Autonomous Management and Control (NAMAC) system supports the advanced reactor operation by recommending control actions to operators based on real-time measurements and digital twins (DTs) learning from the knowledge base. To enable the safe and reliable use of autonomous technologies, NAMAC and its recommendations should be trustworthy to operators and regulators at both the design and operation stages. This study proposes a NAMAC trustworthiness modeling and evaluation framework supported by trustworthiness ontologies and evidence-based approaches. The development-time and run-time ontologies are separately constructed and then converted to Bayesian networks to quantitatively evaluate the NAMAC trustworthiness. This evaluation is demonstrated by collecting and characterizing evidence from NAMAC practices, such as the development and assessment of the NAMAC system, data coverage assessment, and the training and optimizations of neural-network-based DTs. Our proposed approach can aggregate various trustworthiness attributes of complex artificial-intelligence-supported systems for safety-critical applications. It also considers the interaction between different DTs and extends beyond the trustworthiness evaluation of a single DT. The evidence-based method enhances the transparency of the trustworthiness modeling and evaluation processes and helps identify uncertainties and subjectivity involved in the processes.},
	language = {en},
	urldate = {2024-05-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Wang, Longcong and Lin, Linyu and Dinh, Nam},
	month = may,
	year = {2024},
	pages = {110008},
}

@misc{noauthor_aalo_nodate,
	title = {Aalo - {Welcome} to the dawn of a {Second} {Atomic} {Age}},
	url = {https://www.aalo.com/},
	abstract = {Creating abundant and dependable clean energy to power humanity for generations.},
	language = {en},
	urldate = {2024-05-09},
}

@misc{noauthor_modeling_nodate,
	title = {Modeling of {Digital} {Instrumentation} and {Control} in {Nuclear} {Power} {Plant} {Probabilistic} {Risk} {Assessments}},
	url = {https://www.epri.com/research/products/1025278},
	urldate = {2024-04-29},
}

@techreport{lambright_analysis_1990-1,
	title = {Analysis of core damage frequency: {Peach} {Bottom}, {Unit} 2 external events},
	shorttitle = {Analysis of core damage frequency},
	url = {https://www.osti.gov/servlets/purl/6340600/},
	language = {en},
	number = {NUREG/CR-4550-Vol.4-Rev.1-Pt.3, SAND--86-2084-Vol.4-Rev.1-Pt.3, 6340600},
	urldate = {2024-04-26},
	author = {Lambright, J and Bohn, M and Daniel, S and Johnson, J and Ravindra, M and Hashimoto, P and Mraz, M and Tong, W and Brosseau, D},
	month = dec,
	year = {1990},
	doi = {10.2172/6340600},
	pages = {NUREG/CR--4550--Vol.4--Rev.1--Pt.3, SAND--86--2084--Vol.4--Rev.1--Pt.3, 6340600},
}

@incollection{cappelli_instrumentation_2023,
	title = {Instrumentation and {Control} {Systems} for nuclear power plants},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-08-102836-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B978008102836001002X},
	language = {en},
	urldate = {2024-04-25},
	booktitle = {Instrumentation and {Control} {Systems} for {Nuclear} {Power} {Plants}},
	publisher = {Elsevier},
	author = {Cappelli, Mauro},
	year = {2023},
	doi = {10.1016/B978-0-08-102836-0.01002-X},
	pages = {xiii--xiv},
}

@article{coyne_predictive_nodate,
	title = {A {PREDICTIVE} {MODEL} {OF} {NUCLEAR} {POWER} {PLANT} {CREW} {DECISION}-{MAKING} {AND} {PERFORMANCE} {IN} {A} {DYNAMIC} {SIMULATION} {ENVIRONMENT}},
	language = {en},
	author = {Coyne, Kevin A},
}

@article{diaconeasa_dissertation_nodate,
	title = {A dissertation submitted in partial satisfaction of the requirements for the degree {Doctor} of {Philosophy} in {Mechanical} {Engineering}},
	language = {en},
	author = {Diaconeasa, Mihai Aurelian},
}

@article{mercurio_discrete_nodate,
	title = {Discrete {Dynamic} {Event} {Tree} {Modeling} and {Analysis} {Of} {Nuclear} {Power} {Plant} {Crews} {For} {Safety} {Assessment}},
	language = {en},
	author = {Mercurio, Davide},
	pages = {266},
}

@article{mandelli_scenario_2013,
	title = {Scenario clustering and dynamic probabilistic risk assessment},
	volume = {115},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832013000483},
	doi = {10.1016/j.ress.2013.02.013},
	language = {en},
	urldate = {2024-03-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Mandelli, Diego and Yilmaz, Alper and Aldemir, Tunc and Metzroth, Kyle and Denning, Richard},
	month = jul,
	year = {2013},
	pages = {146--160},
}

@phdthesis{osborn_seamless_nodate,
	title = {Seamless {Level} 2/{Level} 3 {Probabilistic} {Risk} {Assessment} {Using} {Dynamic} {Event} {Tree} {Analysis}},
	language = {en},
	author = {Osborn, Douglas Matthew},
}

@article{nejad_automatic_nodate,
	title = {Automatic {Generation} of {Generalized} {Event} {Sequence} {Diagrams} for {Guiding} {Simulation} {Based} {Dynamic} {Probabilistic} {Risk} {Assessment} of {Complex} {Systems}},
	language = {en},
	author = {Nejad, Hamed},
}

@article{ding_automatic_2016,
	series = {7th {IFAC} {Symposium} on {Mechatronic} {Systems} {MECHATRONICS} 2016},
	title = {Automatic {Transformation} of {UML} {System} {Models} for {Model}-based {Error} {Propagation} {Analysis} of {Mechatronic} {Systems}},
	volume = {49},
	issn = {2405-8963},
	url = {http://www.sciencedirect.com/science/article/pii/S2405896316322558},
	doi = {10.1016/j.ifacol.2016.10.643},
	abstract = {Mechatronic systems consist of heterogeneous components: mechanical parts, hardware, and software. Appropriate models, which describe the mutual physical interaction on common Abstract levels, are required. UML is a widely accepted candidate for design and model-based analysis of the mechatronic systems. For the error propagation analysis on system level we have introduced a stochastic dual-graph error propagation model. This model captures control and data flow aspects of the system and allows the computation of various reliability metrics using discrete time Markov chain models. In our recent case-studies, UML Activity Diagrams have been used as baseline models. However, the transformation process was not fully automatic. This process is not so straightforward, despite the obvious structural similarities of the activity diagrams and our error propagation models. This article presents a new fully automatic method for the transformation of annotated activity diagrams. The transformation algorithm is described in detail with formal set-based mathematical notations. The article addresses both theoretical and technical sides of the problem. The method is demonstrated as a part of a complete analytical workflow in the frame of a mechatronic case study.},
	number = {21},
	urldate = {2019-01-21},
	journal = {IFAC-PapersOnLine},
	author = {Ding, Kai and Mutzke, Thomas and Morozov, Andrey and Janschek, Klaus},
	month = jan,
	year = {2016},
	keywords = {Activity Diagrams, Control Flow, Data Flow, Dual-graph Error Propagation Model, Error Propagation Analysis, Medical Patient Table, UML},
	pages = {439--446},
}

@article{mandelli_automatic_2023,
	title = {Automatic {Generation} of {Event} {Trees} and {Fault} {Trees}: {A} {Model}-{Based} {Approach}},
	volume = {209},
	issn = {0029-5450, 1943-7471},
	shorttitle = {Automatic {Generation} of {Event} {Trees} and {Fault} {Trees}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2022.2105780},
	doi = {10.1080/00295450.2022.2105780},
	language = {en},
	number = {11},
	urldate = {2024-04-22},
	journal = {Nuclear Technology},
	author = {Mandelli, Diego and Alfonsi, Andrea and Aldemir, Tunc},
	month = nov,
	year = {2023},
	pages = {1653--1665},
}

@misc{noauthor_remote_nodate,
	title = {Remote {Access} - {Chrome} {Remote} {Desktop}},
	url = {https://remotedesktop.google.com/access},
	urldate = {2024-04-18},
}

@techreport{smith_generic_2021,
	title = {Generic {Pressurized} {Water} {Reactor} {Model} for {SAPHIRE}},
	url = {https://www.osti.gov/servlets/purl/1804754/},
	language = {en},
	number = {INL/EXT-21-62553-Rev000, 1804754},
	urldate = {2024-04-15},
	author = {Smith, Curtis},
	month = apr,
	year = {2021},
	doi = {10.2172/1804754},
	pages = {INL/EXT--21--62553--Rev000, 1804754},
}

@techreport{smith_generic_2021-1,
	title = {Generic {Pressurized} {Water} {Reactor} {Model} for {SAPHIRE}},
	url = {https://www.osti.gov/servlets/purl/1804754/},
	language = {en},
	number = {INL/EXT-21-62553-Rev000, 1804754},
	urldate = {2024-04-15},
	author = {Smith, Curtis},
	month = apr,
	year = {2021},
	doi = {10.2172/1804754},
	pages = {INL/EXT--21--62553--Rev000, 1804754},
}

@article{noauthor_protecting_nodate,
	title = {Protecting {Against} {Digital} {Common}-{Cause} {Failure}},
	language = {en},
}

@article{noauthor_estimating_nodate,
	title = {Estimating {Failure} {Rates} in {Highly} {Reliable} {Digital} {Systems}},
	language = {en},
}

@book{pedroni_finite_2013,
	address = {Cambridge, Massachusetts},
	title = {Finite state machines in hardware: theory and design (with {VHDL} and {SystemVerilog})},
	isbn = {978-0-262-01966-8},
	shorttitle = {Finite state machines in hardware},
	language = {en},
	publisher = {The MIT Press},
	author = {Pedroni, Volnei A.},
	year = {2013},
	keywords = {Computer systems, Data processing, Mathematical models, Sequential machine theory, SystemVerilog (Computer hardware description language), VHDL (Computer hardware description language)},
}

@article{kent_words_1993,
	title = {Words of {Estimative} {Probability}},
	volume = {8},
	url = {https://www.cia.gov/resources/csi/studies-in-intelligence/archives/vol-8-no-4/words-of-estimative-probability/},
	number = {4},
	urldate = {2024-04-10},
	journal = {Center for the Study of Intelligence},
	author = {Kent, Sherman},
	month = sep,
	year = {1993},
	pages = {21},
}

@article{redondo-valero_safety_2023,
	title = {Safety margins improvement by means of the passive second stage hydroaccumulators in a {VVER}-1000/{V320} reactor},
	volume = {414},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549323004934},
	doi = {10.1016/j.nucengdes.2023.112644},
	abstract = {Since the Fukushima accident, there has been a new surge in interest in passive safety systems that ensure the core integrity in accidental sequences involving a total loss of AC power. In this sense, the majority of the GEN-III reactors incorporate advanced passive safety systems. One such system is the Second Stage Hydroaccumulators (HA-2) system, which is a passive safety injection system included in some advanced VVER reactors. The goal of this paper is to analyse the impact of the HA-2 on the events of a LOCA sequence, with and without SBO. For this purpose, a VVER-1000/V320 thermal hydraulic model for TRACEV5P5 code has been modified to include the HA-2 system. By analysing the results, it is found that the single performance of this passive safety system along with the accumulators, without considering any other management action, is enough to avoid the core damage in medium/large LOCA along with SBO during 24 h, moreover this system allows also to relax the success criteria of the active High and Low Pressure Safety Injection Systems in medium/large LOCA sequences without SBO conditions.},
	urldate = {2024-04-03},
	journal = {Nuclear Engineering and Design},
	author = {Redondo-Valero, Elena and Queral, César and Fernandez-Cosials, Kevin and Sanchez-Espinoza, Víctor},
	month = dec,
	year = {2023},
	keywords = {LOCA, Passive safety systems, SBO, Second Stage Hydroaccumulators (HA-2), VVER-1000},
	pages = {112644},
}

@article{sakurahara_modeling_2017,
	title = {{MODELING} {THE} {INTERFACE} {OF} {MANUAL} {FIRE} {PROTECTION} {ACTIONS} {WITH} {FIRE} {PROGRESSION} {IN} {FIRE} {PROBABILISTIC} {RISK} {ASSESSMENT} {OF} {NUCLEAR} {POWER} {PLANTS}},
	language = {en},
	author = {Sakurahara, Tatsuya and Mohaghegh, Zahra and Reihani, Seyed and Kee, Ernie},
	year = {2017},
}

@misc{earthperson_openpra-orgopenpra-monorepo_2024,
	title = {openpra-org/openpra-monorepo: v0.1.1},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {openpra-org/openpra-monorepo},
	url = {https://zenodo.org/doi/10.5281/zenodo.10891407},
	abstract = {No description provided.},
	urldate = {2024-03-28},
	publisher = {The OpenPRA Initiative},
	author = {Earthperson, Arjun and rasheeqqua and nick\_trachtman and wilson556 and Ritwik Vaidya and Mochuan Liu and Rishikesh Pravin Yelne},
	month = mar,
	year = {2024},
	doi = {10.5281/ZENODO.10891407},
}

@misc{mcnelles_failure_2016,
	address = {Lyon, France},
	title = {Failure {Modes} {Taxonomy}: {Assessing} the {Reliability} of {FPGA}-{Based} {I}\&{C} {Systems}},
	url = {https://sunport.ch/wp-content/uploads/2017/06/D2-3-CNSC.pdf},
	urldate = {2024-03-25},
	author = {McNelles, P. and Zeng, Z.C. and Renganathan, G. and Chirila, M. and Lu, L.},
	month = oct,
	year = {2016},
}

@misc{noauthor_storm_nodate,
	title = {Storm -- {A} {Modern} {Probabilistic} {Model} {Checker} -- {Home}},
	url = {https://www.stormchecker.org/},
	urldate = {2024-03-25},
}

@misc{noauthor_hips_nodate,
	title = {The {HIPS} {Platform}: {Forged} on the {Leading} {Edge} of {Advanced} {Reactor} {Ingenuity}},
	shorttitle = {The {HIPS} {Platform}},
	url = {https://paragones.com/hips/},
	abstract = {Nuclear power plant operators want safety-related systems that work for multiple decades without major upgrades. Previous generation digital I\&C systems fell short of this expectation, proving difficult to manage under current cybersecurity and regulatory constraints. The SER-approved HIPS FPGA platform was designed to address these challenges and make safety-related digital I\&C systems easier to install […]},
	language = {en-US},
	urldate = {2024-03-25},
	journal = {Paragon Energy Solutions},
}

@mastersthesis{gaskin_exploring_2001,
	title = {Exploring the {Performance} {Impacts} of {Harmful} {FPGA} {Configurations}},
	abstract = {In this work a new technique for accelerating the aging of FPGA devices is proposed and demonstrated. The proposed technique uses harmful conﬁgurations (short circuits) to accelerate the aging process on targeted portions of an FPGA chip. A testbed is developed for the purpose of measuring FPGA degradation. Using this testbed it is shown that implementing thousands of short circuits in FPGA fabric generates enough heat to cause signiﬁcant damage to the chip, reducing switching speeds by up to 8\%. It is also demonstrated that different parts of the FPGA fabric can be aged at different rates, with some parts of the chip only slowing down 2\% while other parts slow down as much as 8\%.},
	language = {en},
	school = {Brigham Young University},
	author = {Gaskin, Tanner},
	year = {2001},
}

@techreport{noauthor_application_2016,
	address = {Vienna, Austria},
	type = {{IAEA} {Nuclear} {Energy} {Series}},
	title = {Application of {Field} {Programmable} {Gate} {Arrays} in {Instrumentation} and {Control} {Systems} of {Nuclear} {Power} {Plants}},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/Pub1701_web.pdf},
	number = {NP-T-3.17},
	urldate = {2024-03-21},
	institution = {IAEA},
	year = {2016},
}

@article{britton_field_nodate,
	title = {Field {Programmable} {Gate} {Array} {Failure} {Rate} {Estimation} {Guidelines} for {Launch} {Vehicle} {Fault} {Tree} {Models}},
	url = {https://ntrs.nasa.gov/api/citations/20170012420/downloads/20170012420.pdf},
	abstract = {Today’s launch vehicles complex electronic and avionics systems heavily utilize Field Programmable Gate Array (FPGA) integrated circuits (IC) for their superb speed and reconfiguration capabilities. Consequently, FPGAs are prevalent ICs in communication protocols such as MILSTD-1553B and in control signal commands such as in solenoid valve actuations.},
	language = {en},
	author = {Britton, Paul and Hatfield, Glen Spencer and Novack, Steven D},
}

@techreport{ma_causal_2023,
	title = {Causal {CCF} {Parameter} {Estimations} 2020},
	language = {en},
	number = {INL/RPT-23-72728},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Ma, Zhegang and Kvarfordt, Kellie J},
	month = may,
	year = {2023},
}

@article{earthperson_integrating_2023,
	title = {Integrating {Dual} {Error} {Propagation} into {Dynamic} {Event} {Trees} to {Support} {Fission} {Battery} {Probabilistic} {Risk} {Assessments}.},
	url = {https://www.lib.ncsu.edu/resolver/1840.20/41505},
	language = {en},
	urldate = {2024-03-23},
	author = {Earthperson, Arjun},
	month = aug,
	year = {2023},
}

@article{bricas_fpga_2022,
	title = {{FPGA} {Benchmarking} {Structures} {Dedicated} to {TID} {Parametric} {Degradation} {Evaluation}},
	volume = {69},
	issn = {1558-1578},
	url = {https://ieeexplore.ieee.org/document/9787511},
	doi = {10.1109/TNS.2022.3180107},
	abstract = {This article presents a cost-effective and efficient methodology to evaluate and compare parametric degradation of FPGA performance induced by total ionizing dose (TID). At the component level, TID causes increased power consumption and an altered propagation delay of the logic elements. These parametric deviations must be evaluated to be properly considered in the design margins. Dedicated benchmarking structures have been developed to evaluate the propagation delay evolution of logical resources and routing elements of the FPGA. An embedded system based on the reprogrammable feature of embedded PLLs has been implemented to continuously measure in situ the propagation delay evolution during radiation experiments with limited instrumentation. Particular attention was paid to the decoupling of thermal effects and direct TID effects. The effectiveness and benefits of this methodology are demonstrated through X-ray radiation tests. Test results on three FPGA families: Xilinx Spartan7, Artix7, and Intel Cyclone10LP are presented, compared, and discussed.},
	number = {7},
	urldate = {2024-03-23},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Bricas, Gaëtan and Tsiligiannis, Georgios and Touboul, Antoine and Boch, Jérôme and Maraine, Tadec and Saigné, Frédéric},
	month = jul,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Nuclear Science},
	keywords = {Benchmark, Clocks, Degradation, Delays, Field programmable gate arrays, Phase locked loops, Propagation delay, Table lookup, field programmable gate arrays, propagation delay, radiation effects, total ionizing dose (TID)},
	pages = {1453--1460},
}

@techreport{noauthor_understanding_2002,
	title = {Understanding {Soft} and {Firm} {Errors} in {Semiconductor} {Devices}},
	url = {https://www.microsemi.com/document-portal/doc_view/130765-understanding-soft-and-firm-errors-in-semiconductor-devices-questions-and-answers},
	language = {en},
	institution = {Actel},
	month = dec,
	year = {2002},
}

@misc{noauthor_what_nodate,
	title = {What {Are} {Field} {Programmable} {Gate} {Arrays}?},
	shorttitle = {What is an {FPGA}?},
	url = {https://www.xilinx.com/products/silicon-devices/fpga/what-is-an-fpga.html},
	abstract = {What is an FPGA - Field Programmable Gate Arrays are semiconductor devices that are based around a matrix of configurable logic blocks (CLBs) connected via programmable interconnects. FPGAs can be reprogrammed to desired application or functionality requirements after manufacturing.},
	language = {en},
	urldate = {2024-03-23},
	journal = {AMD},
}

@techreport{noauthor_nuscale_2020,
	type = {{NuScale} {FSAR}},
	title = {{NuScale} {Standard} {Plant} {Design} {Certification} {Application}: {Chapter} 7 {Instrumention} and {Controls}},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A495.pdf},
	urldate = {2024-02-02},
	month = jul,
	year = {2020},
}

@techreport{ma_feasibility_2021,
	title = {Feasibility {Study} of {Developing} {Alternative} {Common}-{Cause} {Failure} {Model} for {Event} {Assessment}},
	url = {https://www.osti.gov/servlets/purl/1836026/},
	language = {en},
	number = {INL/EXT-21-33376-Rev001, 1836026},
	urldate = {2024-03-22},
	author = {Ma, Zhegang and Knudsen, James and Schroeder, John and Smith, Curtis},
	month = sep,
	year = {2021},
	doi = {10.2172/1836026},
	pages = {INL/EXT--21--33376--Rev001, 1836026},
}

@techreport{ma_developing_2021,
	title = {Developing {Generic} {Prior} {Distributions} for {Common} {Cause} {Failure} {Alpha} {Factors} and {Causal} {Alpha} {Factors}},
	url = {https://www.osti.gov/servlets/purl/1835896/},
	language = {en},
	number = {INL/EXT-21-43723-Rev001, 1835896},
	urldate = {2024-03-22},
	author = {Ma, Zhegang and Atwood, Corwin and Schroeder, John},
	month = aug,
	year = {2021},
	doi = {10.2172/1835896},
	pages = {INL/EXT--21--43723--Rev001, 1835896},
}

@article{zheng_-decomposition_2013,
	title = {α-{Decomposition} for estimating parameters in common cause failure modeling based on causal inference},
	volume = {116},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832013000604},
	doi = {10.1016/j.ress.2013.02.025},
	abstract = {The traditional α-factor model has focused on the occurrence frequencies of common cause failure (CCF) events. Global α-factors in the α-factor model are defined as fractions of failure probability for particular groups of components. However, there are unknown uncertainties in the CCF parameters estimation for the scarcity of available failure data. Joint distributions of CCF parameters are actually determined by a set of possible causes, which are characterized by CCF-triggering abilities and occurrence frequencies. In the present paper, the process of α-decomposition (Kelly-CCF method) is developed to learn about sources of uncertainty in CCF parameter estimation. Moreover, it aims to evaluate CCF risk significances of different causes, which are named as decomposed α-factors. Firstly, a Hybrid Bayesian Network is adopted to reveal the relationship between potential causes and failures. Secondly, because all potential causes have different occurrence frequencies and abilities to trigger dependent failures or independent failures, a regression model is provided and proved by conditional probability. Global α-factors are expressed by explanatory variables (causes’ occurrence frequencies) and parameters (decomposed α-factors). At last, an example is provided to illustrate the process of hierarchical Bayesian inference for the α-decomposition process. This study shows that the α-decomposition method can integrate failure information from cause, component and system level. It can parameterize the CCF risk significance of possible causes and can update probability distributions of global α-factors. Besides, it can provide a reliable way to evaluate uncertainty sources and reduce the uncertainty in probabilistic risk assessment. It is recommended to build databases including CCF parameters and corresponding causes’ occurrence frequency of each targeted system.},
	urldate = {2024-03-22},
	journal = {Reliability Engineering \& System Safety},
	author = {Zheng, Xiaoyu and Yamaguchi, Akira and Takata, Takashi},
	month = aug,
	year = {2013},
	keywords = {-decomposition, -factor model, Bayesian theory, Causal inference, Common cause failure, Probabilistic risk assessment},
	pages = {20--27},
}

@misc{noauthor_handbook_nodate,
	title = {Handbook of {Parameter} {Estimation} for {Probabilistic} {Risk} {Assessment} ({NUREG}/{CR}-6823, {SAND2003}-{3348P})},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6823/index.html},
	abstract = {Handbook of Parameter Estimation for Probabilistic Risk Assessment (NUREG/CR-6823,  SAND2003-3348P)},
	language = {en-US},
	urldate = {2024-03-22},
	journal = {NRC Web},
}

@article{noauthor_nureg-2225_nodate,
	title = {{NUREG}-2225, "{Basis} for the {Treatment} of {Potential} {Common}-{Cause} {Failure} in the {Significance} {Determination} {Process}."},
	language = {en},
}

@article{lyttle_ornltm-201032_nodate,
	title = {{ORNL}/{TM}-2010/32, {An} {Investigation} of {Digital} {Instrumentation} and {Control} {System} {Failure} {Modes}.},
	language = {en},
	author = {Lyttle, Sandi},
}

@misc{hensel_moves-rwthstorm_2023,
	title = {moves-rwth/storm: v1.8.1},
	copyright = {Open Access},
	shorttitle = {moves-rwth/storm},
	url = {https://zenodo.org/record/1181896},
	abstract = {Workaround for issue with Boost \&gt;= 1.81},
	urldate = {2024-03-18},
	publisher = {[object Object]},
	author = {Hensel, Christian and Quatmann, Tim and Junges, Sebastian and Volk, Matthias and {J. Berger} and {Jipspel} and Kremer, Gereon and Bork, Alex and Basgöze, Daniel and David and Hannah and Gros, Timo P. and Klein, Joachim and {Sp} and Janson, Tom and Lehmann, Johannes and Karuc, Jan and {Looomis} and Kurowski, Sascha Vincent and {SvStein} and Delgrange, Florent and {Marckvdv} and Jeppson, Josh and {Spacefrogg} and Partow, Arash and {Steffi4321} and Linus and Ruijters, Enno and {Legoeggolas} and {Matdeg}},
	month = jun,
	year = {2023},
	doi = {10.5281/ZENODO.1181896},
}

@article{norman_evaluating_2005,
	title = {Evaluating the reliability of {NAND} multiplexing with {PRISM}},
	volume = {24},
	issn = {0278-0070},
	url = {http://ieeexplore.ieee.org/document/1512379/},
	doi = {10.1109/TCAD.2005.852033},
	abstract = {Probabilistic model checking is a formal veriﬁcation technique for analysing the reliability and performance of systems exhibiting stochastic behaviour. In this paper, we demonstrate the applicability of this approach and, in particular, the probabilistic model checking tool PRISM to the evaluation of reliability and redundancy of defect-tolerant systems in the ﬁeld of computeraided design. We illustrate the technique with an example due to von Neumann, namely NAND multiplexing. We show how, having constructed a model of a defect-tolerant system incorporating probabilistic assumptions about its defects, it is straightforward to compute a range of reliability measures and investigate how they are affected by slight variations in the behaviour of the system. This allows a designer to evaluate, for example, the trade-off between redundancy and reliability in the design. We also highlight errors in analytically computed reliability bounds, recently published for the same case study.},
	language = {en},
	number = {10},
	urldate = {2024-03-18},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Norman, G. and Parker, D. and Kwiatkowska, M. and Shukla, S.},
	month = oct,
	year = {2005},
	pages = {1629--1637},
}

@article{hamscher_modeling_1991,
	title = {Modeling digital circuits for troubleshooting},
	volume = {51},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/000437029190112W},
	doi = {10.1016/0004-3702(91)90112-W},
	abstract = {Existing methods for model-based troubleshooting have not previously scaled up to deal with complex digital circuits, in part because traditional circuit models do not represent aspects of the device that troubleshooters consider important. An instruction level simulation of a microprocessor explicitly represents the logic levels present on its external bus at every clock edge, but not the fact that during normal operation those bus signals should be very active. A schematic may represent the connectivity of field replaceable components, but does not show how their combined behavior implements the intentions of the designer. The specifications of a component rarely say how it is likely to fail. This suggests basing troubleshooting on a specialized circuit model that emphasizes such aspects. Although it is beyond current technology to derive such models from circuit schematics automatically, this work shows that these models can make the trouble-shooting of complex circuits feasible. This paper describes an implemented program for troubleshooting complex digital circuits, using a representation that makes explicit their behavior at a high level of temporal abstraction, their physical and functional organization, and the common ways that their components fail.},
	number = {1},
	urldate = {2024-03-17},
	journal = {Artificial Intelligence},
	author = {Hamscher, Walter C.},
	month = oct,
	year = {1991},
	pages = {223--271},
}

@misc{noauthor_operating_nodate,
	title = {Operating {Experience} {Results} and {Databases}},
	url = {https://nrcoe.inl.gov/RADS/},
	language = {en},
	urldate = {2024-03-16},
	journal = {NRC Web},
}

@article{andrews_calculation_2024,
	title = {Calculation of the {System} {Unavailability} {Measures} of {Component} {Importance} {Using} the {D2T2} {Methodology} of {Fault} {Tree} {Analysis}},
	volume = {12},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/12/2/292},
	doi = {10.3390/math12020292},
	abstract = {A recent development in Fault Tree Analysis (FTA), known as Dynamic and Dependent Tree Theory (D2T2), accounts for dependencies between the basic events, making FTA more powerful. The method uses an integrated combination of Binary Decision Diagrams (BDDs), Stochastic Petri Nets (SPN) and Markov models. Current algorithms enable the prediction of the system failure probability and failure frequency. This paper proposes methods which extend the current capability of the D2T2 framework to calculate component importance measures. Birnbaum’s measure of importance, the Criticality measure of importance, the Risk Achievement Worth (RAW) measure of importance and the Risk Reduction Worth (RRW) measure of importance are considered. This adds a vital ability to the framework, enabling the influence that components have on system failure to be determined and the most effective means of improving system performance to be identified. The algorithms for calculating each measure of importance are described and demonstrated using a pressure vessel cooling system.},
	language = {en},
	number = {2},
	urldate = {2024-03-03},
	journal = {Mathematics},
	author = {Andrews, John and Lunt, Sally},
	month = jan,
	year = {2024},
	pages = {292},
}

@article{vaishanav_computationally_2024,
	title = {Computationally efficient approach for risk-informed decision making},
	volume = {167},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197023004183},
	doi = {10.1016/j.pnucene.2023.104983},
	abstract = {Probabilistic risk assessment (PRA) is used as an essential tool for risk-informed decision-making in the nuclear industry. The fault and event trees play a crucial role in PRA to estimate the probability of system failure based on the failure probabilities of components. The fault trees or event trees for an actual power plant unit can be fairly large in size with several different types of logic gates, interconnected events, dependent events, etc. A large fault tree can include hundreds of gates, basic events (BEs), multiple occurring events (MOEs), and dependent events. Complex connectivities can give rise to excessive computational demand and storage requirements for the analysis. Fault and event trees can be solved using the minimal cut-set approaches, or advanced quantification techniques such as Binary decision diagrams or Bayesian networks. However, these techniques can be computationally inefficient for larger fault trees and can run out of memory/storage space. This study focuses on developing and proposing a new approach for accurate estimation of the system-level risk while improving the computational efficiency significantly. More specifically, an attempt is made to reduce the complexity of the analysis of MOEs and dependent events in fault trees. The proposed algorithms in this study present a significant improvement over traditional approaches which makes it highly promising for additional development. The computational efficiency of the proposed approach over the traditional approach is illustrated for fault trees with a varying number of events and different types of logic gate connections.},
	language = {en},
	urldate = {2024-02-22},
	journal = {Progress in Nuclear Energy},
	author = {Vaishanav, Pragya and Bodda, Saran Srikanth and Gupta, Abhinav},
	month = feb,
	year = {2024},
	pages = {104983},
}

@article{pat-cornell_uncertainties_1996,
	title = {Uncertainties in risk analysis: {Six} levels of treatment},
	volume = {54},
	doi = {10.1016/S0951-8320(96)00067-1},
	language = {en},
	number = {2-3},
	journal = {Reliability Engineering \& System Safety},
	author = {Pat-Cornell, M Elisabeth},
	month = dec,
	year = {1996},
	pages = {95--111},
}

@article{kaplan_expert_1992,
	title = {‘{Expert} information’ versus ‘expert opinions’. {Another} approach to the problem of eliciting/ combining/using expert knowledge in {PRA}},
	volume = {35},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/095183209290023E},
	doi = {10.1016/0951-8320(92)90023-E},
	abstract = {In the traditional approach to eliciting expert knowledge for use in risk assessment and decision analysis, the expert is asked for his opinion about, say, the numerical value of some unknown parameter λ. This opinion is then expressed as a point estimate, λi, or a probabilistic estimate, Pi(λ). Much attention and debate is then given, in the traditional approach, to methods of weighing and combining the opinions from the individual experts. The present paper advocates another approach in which we ask each expert, instead, for his body of evidence, Ei, relevant to the value of λ. In this way, the approach first arrives at a consensual body of evidence, E − \{Ei\}, and second, at a consensual curve p(λ{\textbar}E) that expresses our knowledge about λ based on that body of evidence. The essential difference between this ‘expert information’ approach and the traditional ‘expert opinion’ approaches may be captured in the slogan: lsWeigh evidence, not experts!’},
	number = {1},
	urldate = {2024-02-22},
	journal = {Reliability Engineering \& System Safety},
	author = {Kaplan, Stan},
	month = jan,
	year = {1992},
	pages = {61--72},
}

@article{moretti_et_al_collision_nodate,
	title = {Collision risk assessment between aircraft and obstacles in the areas surrounding airports},
	author = {Moretti et al},
}

@book{korsah_investigation_2010,
	title = {{AN} {INVESTIGATION} {OF} {DIGITAL} {INSTRUMENTATION} {AND} {CONTROL} {SYSTEM} {FAILURE} {MODES}},
	abstract = {A study sponsored by the Nuclear Regulatory Commission study was conducted to investigate digital instrumentation and control (DI\&C) systems-and module-level failure modes-using a number of databases both in the nuclear and non-nuclear industries. The objectives of the study were to obtain relevant operational experience data to identify generic DI\&C system failure modes and failure mechanisms, and to obtain generic insights, with the intent of using results to establish a unified framework for categorizing failure modes and mechanisms. Of the seven databases studied, the Equipment Performance Information Exchange database was found to contain the most useful data relevant to the study. Even so, the general lack of "quality" relative to the objectives of the study did not allow the development of a unified framework for failure modes and mechanisms of nuclear I\&C systems. However, an attempt was made to characterize all the failure modes observed (i.e., without regard to the type of I\&C equipment under consideration) into common categories. It was found that all the failure modes identified could be characterized as (a) detectable/preventable before failures, (b) age-related failures, (c) random failures, (d) random/sudden failures, or (e) intermittent failures. The percentage of failure modes characterized as (a) was significant, implying that a significant reduction in system failures could be achieved through improved online monitoring, exhaustive testing prior to installation, adequate configuration control or verification and validation, etc.},
	author = {Korsah, Kofi and Cetiner, Sacit and Muhlheim, Michael and Poore, Willis and Rd, Bethel},
	month = nov,
	year = {2010},
}

@article{smith_integration_nodate,
	title = {Integration of {NIS} ({Nuclear} {Instrumentation} {Systems}) with {FPGA} based {RPS} controls as a {Seamless} {Safety} {Control} {System} and {Hardware} {Platform}},
	abstract = {This paper will overview and discuss the integration of the NIS system (Nuclear Instrumentation System) with the RPS (Reactor Protection System), providing Advanced Reactor \& Small Modular Reactor designs a seamless, integrated Safety Controls System on one standardized hardware platform. The paper will discuss the associated benefits obtained from the implementation.},
	language = {en},
	author = {Smith, Tighe},
}

@misc{nuclear_regulatory_commission_nuscale_2021,
	title = {{NuScale} {Small} {Modular} {Reactor} {Design} {Certification}},
	url = {https://www.federalregister.gov/documents/2021/07/01/2021-13940/nuscale-small-modular-reactor-design-certification},
	author = {{Nuclear Regulatory Commission}},
	month = jul,
	year = {2021},
	note = {Issue: FR 34999
Pages: 34999–35023
Volume: 86
Published: Federal Register},
}

@misc{noauthor_nuscale_2021,
	title = {{NuScale} {Small} {Modular} {Reactor} {Design} {Certification}},
	url = {https://www.federalregister.gov/documents/2021/07/01/2021-13940/nuscale-small-modular-reactor-design-certification},
	abstract = {The U.S. Nuclear Regulatory Commission (NRC) is proposing to amend its regulations to certify the NuScale standard design for a small modular reactor. Applicants or licensees intending to construct and operate a NuScale standard design may do so by referencing this design certification rule. The...},
	language = {en},
	urldate = {2024-02-17},
	journal = {Federal Register},
	month = jul,
	year = {2021},
}

@article{luxhoj_modeling_2006,
	title = {Modeling {Low} {Probability}/{High} {Consequence} {Events}: {An} {Aviation} {Safety} {Risk} {Model}},
	doi = {https://doi.org/10.1109/RAMS.2006.1677377},
	journal = {RAMS 2006 IEEE},
	author = {Luxhøj and Coit},
	year = {2006},
}

@book{fritzson_principles_2015,
	address = {New York, New York},
	edition = {Second edition},
	title = {Principles of object oriented modeling and simulation with {Modelica} 3.3: a cyber-physical approach},
	isbn = {978-1-118-85912-4},
	shorttitle = {Principles of object oriented modeling and simulation with {Modelica} 3.3},
	language = {en},
	publisher = {Wiley},
	author = {Fritzson, Peter},
	year = {2015},
}

@article{reinert_including_2006,
	title = {Including model uncertainty in risk-informed decision making},
	volume = {33},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454905002781},
	doi = {10.1016/j.anucene.2005.11.010},
	language = {en},
	number = {4},
	urldate = {2024-02-15},
	journal = {Annals of Nuclear Energy},
	author = {Reinert, Joshua M. and Apostolakis, George E.},
	month = mar,
	year = {2006},
	pages = {354--369},
}

@article{benjamin_developing_2016,
	title = {Developing probabilistic safety performance margins for unknown and underappreciated risks},
	volume = {145},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015002264},
	doi = {10.1016/j.ress.2015.07.021},
	language = {en},
	urldate = {2024-02-15},
	journal = {Reliability Engineering \& System Safety},
	author = {Benjamin, Allan and Dezfuli, Homayoon and Everett, Chris},
	month = jan,
	year = {2016},
	pages = {329--340},
}

@article{ma_ccf_nodate,
	title = {{CCF} {Parameter} {Estimations}, 2020 {Update}},
	language = {en},
	author = {Ma, Zhegang and Kvarfordt, Kellie J},
}

@book{clarke_handbook_2018,
	address = {Cham},
	title = {Handbook of {Model} {Checking}},
	isbn = {978-3-319-10574-1 978-3-319-10575-8},
	url = {http://link.springer.com/10.1007/978-3-319-10575-8},
	language = {en},
	urldate = {2024-02-12},
	publisher = {Springer International Publishing},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8},
}

@incollection{aldemir_chapter_2024,
	title = {Chapter 4 - {Dynamic} probabilistic risk assessment ({PRA}): {Theory}, tools, and applications for uncertainty quantification},
	isbn = {978-0-323-91152-8},
	shorttitle = {Chapter 4 - {Dynamic} probabilistic risk assessment ({PRA})},
	url = {https://www.sciencedirect.com/science/article/pii/B978032391152800017X},
	abstract = {The conventional approach to probabilistic risk assessment (PRA) using event and fault trees can at best account for the order of occurrence of events in system evolution. Dynamic PRA (DPRA) methodologies are defined as those that explicitly account for the time element in probabilistic system evolution and allow assessment of the impact of epistemic and aleatory uncertainties on system safety and reliability in a phenomenologically and stochastically consistent manner. DPRA methodologies are usually needed when the system has more than one failure mode, control loops, and/or hardware/process/software/human interaction. A review of major DPRA methodologies proposed to date is presented with current challenges in data generation and analysis and some measures to meet these challenges.},
	urldate = {2024-02-10},
	booktitle = {Risk-{Informed} {Methods} and {Applications} in {Nuclear} and {Energy} {Engineering}},
	publisher = {Academic Press},
	author = {Aldemir, Tunc},
	editor = {Smith, Curtis Lee and Le Blanc, Katya and Mandelli, Diego},
	month = jan,
	year = {2024},
	doi = {10.1016/B978-0-323-91152-8.00017-X},
	keywords = {Dynamic PRA, Human interaction, Implementation software, Probabilistic risk assessment (PRA), System evolution, Theoretical basis},
	pages = {43--54},
}

@article{parker_department_2011,
	title = {Department of {Computer} {Science} {University} of {Oxford}},
	language = {en},
	author = {Parker, Dr Dave},
	year = {2011},
}

@article{terrell_variable_1992,
	title = {Variable {Kernel} {Density} {Estimation}},
	volume = {20},
	issn = {00905364},
	url = {http://www.jstor.org/stable/2242011},
	abstract = {We investigate some of the possibilities for improvement of univariate and multivariate kernel density estimates by varying the window over the domain of estimation, pointwise and globally. Two general approaches are to vary the window width by the point of estimation and by point of the sample observation. The first possibility is shown to be of little efficacy in one variable. In particular, nearest-neighbor estimators in all versions perform poorly in one and two dimensions, but begin to be useful in three or more variables. The second possibility is more promising. We give some general properties and then focus on the popular Abramson estimator. We show that in many practical situations, such as normal data, a nonlocality phenomenon limits the commonly applied version of the Abramson estimator to bias of O([ h / log h]2) instead of the hoped for O(h4).},
	number = {3},
	urldate = {2024-02-09},
	journal = {The Annals of Statistics},
	author = {Terrell, George R. and Scott, David W.},
	year = {1992},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1236--1265},
}

@article{kaplan_quantitative_1981,
	title = {On {The} {Quantitative} {Definition} of {Risk}},
	volume = {1},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1981.tb01350.x},
	doi = {10.1111/j.1539-6924.1981.tb01350.x},
	language = {en},
	number = {1},
	urldate = {2022-10-16},
	journal = {Risk Analysis},
	author = {Kaplan, Stanley and Garrick, B. John},
	month = mar,
	year = {1981},
	keywords = {Baye's theorem, decision, probability, risk, uncertainty},
	pages = {11--27},
}

@article{budnitz_external_1984,
	title = {External {Initiators} in {Probabilistic} {Reactor} {Accident} {Analysis}—{Earthquakes}, {Fires}, {Floods}, {Winds}},
	volume = {4},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1984.tb00951.x},
	doi = {10.1111/j.1539-6924.1984.tb00951.x},
	abstract = {This article discusses the methodologies presently available for analyzing the contribution of “external initiators” to overall risks in the context of PRA (probabilistic risk assessment) of large commercial nuclear power reactors. “External initiators” include earthquakes, fires and floods inside the plant, external floods, high winds, aircraft, barge, and ship collisions, noxious or explosive gases offsite, and so on. These are in contrast to “internal initiators” such as active or passive plant equipment failures, human errors, and loss of electrical power. The ability to consider external initiators within PRA has undergone major advances in recent years. In general, uncertainties associated with the calculated risks from external initiators are much larger than those associated with internal initiators. The principal uncertainties lie with development of hazard curves (such as the frequency of occurrence of an event exceeding a given size: for example, the likelihood of a hurricane with winds exceeding 125 knots). For assessment of earthquakes, internal fires and floods, and high winds, the methodology is reasonably mature for qualitative assessment but not for quantitative application. The risks from other external initiators are generally considered to be low, either because of the very long recurrence time associated with the events or because the plants are judged to be well designed to withstand them.},
	language = {en},
	number = {4},
	urldate = {2024-02-08},
	journal = {Risk Analysis},
	author = {Budnitz, Robert J.},
	month = dec,
	year = {1984},
	pages = {323--335},
}

@article{elks_veriable_nodate,
	title = {Veriﬁable {Digital} {I}\&{C} and {Embedded} {Digital} {Devices} for {Nuclear} {Power}},
	language = {en},
	author = {Elks, Dr Carl},
}

@article{lin_main_2010,
	title = {Main control system verification and validation of {NPP} digital {I}\&{C} system based on engineering simulator},
	volume = {240},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549310001585},
	doi = {10.1016/j.nucengdes.2010.03.011},
	abstract = {Full-scope digital instrumentation and controls system (I\&C) technique is being introduced in Chinese new constructed Nuclear Power Plant (NPP), which mainly includes three parts: control system, reactor protection system and engineered safety feature actuation system. For example, SIEMENS TELEPERM XP and XS distributed control system (DCS) have been used in Ling Ao Phase II NPP, which is located in Guangdong province, China. This is the first NPP project in China that Chinese engineers are fully responsible for all the configuration of actual analog and logic diagram, although experience in NPP full-scope digital I\&C is very limited. For the safety, it has to be made sure that configuration is right and control functions can be accomplished before the phase of real plant testing on reactor. Therefore, primary verification and validation (V\&V) of I\&C needs to be carried out. Except the common and basic way, i.e. checking the diagram configuration one by one according to original design, NPP engineering simulator is applied as another effective approach of V\&V. For this purpose, a virtual NPP thermal-hydraulic model is established as a basis according to Ling Ao Phase II NPP design, and the NPP simulation tools can provide plant operation parameters to DCS, accept control signal from I\&C and give response. During the test, one set of data acquisition equipments are used to build a connection between the engineering simulator (software) and SIEMENS DCS I/O cabinet (hardware). In this emulation, original diagram configuration in DCS and field hardware structures are kept unchanged. In this way, firstly judging whether there are some problems by observing the input and output of DCS without knowing the internal configuration. Then secondly, problems can be found and corrected by understanding and checking the exact and complex configuration in detail. At last, the correctness and functionality of the control system are verified. This method is also very convenient for expansion to other type digital I\&C V\&V. This paper is mainly focused on V\&V of closed-loop control systems in full-scope DCS and several detailed reactor control (RRC) systems, including pressurizer pressure and water level control, steam generator water level control. The V\&V works were carried out by applying engineering simulator. This paper describes the structure and function of the simulator, V\&V procedure, results analysis and problems identified. Through the actual on-line virtual closed-loop testing on Ling Ao Phase II NPP project, many problems of DCS configuration were found and solved. And it proved that V\&V based on engineering simulator enables significant time saving, improves economics and safety in the phase of engineering debugging.},
	number = {7},
	urldate = {2024-02-05},
	journal = {Nuclear Engineering and Design},
	author = {Lin, Meng and Hou, Dong and Liu, Pengfei and Yang, Zongwei and Yang, Yanhua},
	month = jul,
	year = {2010},
	pages = {1887--1896},
}

@article{anton_icone19-43169_2011,
	title = {{ICONE19}-43169 {VERIFICATION} {OF} {FPGA}-{BASED} {NPP} {I}\&{C} {SYSTEMS} : {GENERAL} {APPROACH} {AND} {TECHNIQUES}},
	volume = {2011.19},
	shorttitle = {{ICONE19}-43169 {VERIFICATION} {OF} {FPGA}-{BASED} {NPP} {I}\&{C} {SYSTEMS}},
	doi = {10.1299/jsmeicone.2011.19._ICONE1943_61},
	abstract = {This paper presents a general approach and techniques for design and verification of Field Programmable Gates Arrays (FPGA)-based Instrumentation and Control (I\&C) systems for Nuclear Power Plants (NPP). Appropriate regulatory documents used for I\&C systems design, development, verification and validation (V\&V) are discussed considering the latest international standards and guidelines. Typical development and V\&V processes of FPGA electronic design for FPGA-based NPP I\&C systems are presented. Some safety-related features of implementation process are discussed. Corresponding development artifacts, related to design and implementation activities are outlined. An approach to test-based verification of FPGA electronic design algorithms, used in FPGA-based reactor trip systems is proposed. The results of application of test-based techniques for assessment of FPGA electronic design algorithms for reactor trip system (RTS) produced by Research and Production Corporation (RPC) "Radiy" are presented. Some principles of invariant-oriented verification for FPGA-based safety-critical systems are outlined.},
	journal = {The Proceedings of the International Conference on Nuclear Engineering (ICONE)},
	author = {Anton, Andrashov and Kharchenko, Vyacheslav and Sklyar, Vladimir and Siora, Alexander and Reva, Lubov},
	month = aug,
	year = {2011},
	pages = {\_ICONE1943--\_ICONE1943},
}

@inproceedings{noauthor_toward_2016,
	title = {Toward a {Mechanistic} {Source} {Term} in {Advanced} {Reactors}: {A} {Review} of {Past} {U}.{S}. {SFR} {Incidents}, {Experiments}, and {Analyses}},
	language = {en},
	urldate = {2024-01-19},
	booktitle = {2016 {International} {Congress} on {Advances} in {Nuclear} {Power} {Plants}},
	year = {2016},
}

@article{antonello_insights_2023,
	title = {Insights in the safety analysis of an early microreactor design},
	volume = {404},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549323000523},
	doi = {10.1016/j.nucengdes.2023.112203},
	abstract = {A safety analysis of a transportable, plug-and-play, heat-pipe-cooled microreactor – or Nuclear Battery (NB)–designed at MIT is presented. The considered design is a semi-autonomous 5 MW (thermal) high-temperature heat-pipe-cooled, yttrium-hydride moderated NB envisioned to be a transportable, flexible, affordable, and distributed low-carbon energy source.},
	language = {en},
	urldate = {2023-02-07},
	journal = {Nuclear Engineering and Design},
	author = {Antonello, Federico and Buongiorno, Jacopo and Zio, Enrico},
	month = apr,
	year = {2023},
	pages = {112203},
}

@inproceedings{das_advancing_2018,
	address = {Calgary, AB},
	title = {Advancing {Connectionist} {Temporal} {Classification} with {Attention} {Modeling}},
	isbn = {978-1-5386-4658-8},
	url = {https://ieeexplore.ieee.org/document/8461558/},
	doi = {10.1109/ICASSP.2018.8461558},
	urldate = {2024-02-01},
	booktitle = {2018 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Das, Amit and Li, Jinyu and Zhao, Rui and Gong, Yifan},
	month = apr,
	year = {2018},
	pages = {4769--4773},
}

@misc{noauthor_13662_nodate,
	title = {1.3.6.6.2. {Uniform} {Distribution}},
	url = {https://www.itl.nist.gov/div898/handbook/eda/section3/eda3662.htm},
	urldate = {2024-01-31},
}

@article{kucherenko_exploring_2015,
	title = {Exploring multi-dimensional spaces: a {Comparison} of {Latin} {Hypercube} and {Quasi} {Monte} {Carlo} {Sampling} {Techniques}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Exploring multi-dimensional spaces},
	url = {https://arxiv.org/abs/1505.02350},
	doi = {10.48550/ARXIV.1505.02350},
	abstract = {Three sampling methods are compared for efficiency on a number of test problems of various complexity for which analytic quadratures are available. The methods compared are Monte Carlo with pseudo-random numbers, Latin Hypercube Sampling, and Quasi Monte Carlo with sampling based on Sobol sequences. Generally results show superior performance of the Quasi Monte Carlo approach based on Sobol sequences in line with theoretical predictions. Latin Hypercube Sampling can be more efficient than both Monte Carlo method and Quasi Monte Carlo method but the latter inequality holds for a reduced set of function typology and at small number of sampled points. In conclusion Quasi Monte Carlo method would appear the safest bet when integrating functions of unknown typology.},
	urldate = {2024-01-31},
	author = {Kucherenko, Sergei and Albrecht, Daniel and Saltelli, Andrea},
	year = {2015},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {65C05, Applications (stat.AP), Computation (stat.CO), FOS: Computer and information sciences, G.3},
}

@misc{noauthor_tensorflow_nodate,
	title = {{TensorFlow} {Probability}},
	url = {https://www.tensorflow.org/probability},
	abstract = {A library to combine probabilistic models and deep learning on modern hardware (TPU, GPU) for data scientists, statisticians, ML researchers, and practitioners.},
	language = {en},
	urldate = {2024-01-31},
	journal = {TensorFlow},
}

@article{abadi_tensorflow_2016,
	title = {{TensorFlow}: {Large}-{Scale} {Machine} {Learning} on {Heterogeneous} {Distributed} {Systems}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{TensorFlow}},
	url = {https://arxiv.org/abs/1603.04467},
	doi = {10.48550/ARXIV.1603.04467},
	abstract = {TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
	urldate = {2024-01-31},
	author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year = {2016},
	note = {Publisher: arXiv
Version Number: 2},
	keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@book{kruschke_doing_2015,
	address = {Boston},
	edition = {Edition 2},
	title = {Doing {Bayesian} data analysis: a tutorial with {R}, {JAGS}, and {Stan}},
	isbn = {978-0-12-405888-0},
	shorttitle = {Doing {Bayesian} data analysis},
	abstract = {Provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data},
	language = {eng},
	publisher = {Academic Press},
	author = {Kruschke, John K.},
	year = {2015},
}

@misc{noauthor_minimizemethodnelder-mead_nodate,
	title = {minimize(method=’{Nelder}-{Mead}’) — {SciPy} v1.12.0 {Manual}},
	url = {https://docs.scipy.org/doc/scipy/reference/optimize.minimize-neldermead.html},
	urldate = {2024-01-31},
}

@article{helton_uncertainty_1993,
	title = {Uncertainty and sensitivity analysis techniques for use in performance assessment for radioactive waste disposal},
	volume = {42},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209390097I},
	doi = {10.1016/0951-8320(93)90097-I},
	language = {en},
	number = {2-3},
	urldate = {2024-01-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Helton, Jon C},
	month = jan,
	year = {1993},
	pages = {327--367},
}

@techreport{jw_hickman_pra_1983,
	title = {{PRA} {Procedures} {Guide}: {Chapters} 1–8 ({NUREG}/{CR}-2300, {Volume} 1)},
	shorttitle = {{PRA} {Procedures} {Guide}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2300/vol1/index.html},
	number = {NUREG/CR-2300},
	urldate = {2021-04-05},
	institution = {Nuclear Regulatory Commission, Washington, D.C. (USA)},
	author = {{J.W. Hickman}},
	month = jan,
	year = {1983},
}

@article{helton_survey_2006,
	title = {Survey of sampling-based methods for uncertainty and sensitivity analysis},
	volume = {91},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832005002292},
	doi = {10.1016/j.ress.2005.11.017},
	language = {en},
	number = {10-11},
	urldate = {2024-01-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Helton, J.C. and Johnson, J.D. and Sallaberry, C.J. and Storlie, C.B.},
	month = oct,
	year = {2006},
	pages = {1175--1209},
}

@patent{sr_digital_2002,
	title = {Digital plant protection system with engineered safety features component control system},
	url = {https://patents.google.com/patent/US6484126B1/en},
	nationality = {US},
	assignee = {Westinghouse Electric Co LLC},
	number = {US6484126B1},
	urldate = {2024-01-29},
	author = {Sr, Edgar Mel Brown and Jr, Frank Martin Kessler and Jr, Richard Michael Manazir and Senechal, Raymond Robert},
	month = nov,
	year = {2002},
	keywords = {bistable, component control, control system, processor, processors},
}

@article{korsah_nuregcr-6992_nodate,
	title = {{NUREG}/{CR}-6992, {Instrumentation} and {Controls} in {Nuclear} {Power} {Plants}:  {An} {Emerging} {Technologies} {Update}.},
	language = {en},
	author = {Korsah, Kofi},
}

@incollection{beyer_software_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Software {Model} {Checking}: 20 {Years} and {Beyond}},
	isbn = {978-3-031-22337-2},
	shorttitle = {Software {Model} {Checking}},
	url = {https://doi.org/10.1007/978-3-031-22337-2_27},
	abstract = {We give an overview of the development of software model checking, a general approach to algorithmic program verification that integrates static analysis, model checking, and deduction. We start with a look backwards and briefly cover some of the important steps in the past decades. The general approach has become a research topic on its own, with a wide range of tools that are based on the approach. Therefore, we discuss the maturity of the research area of software model checking in terms of looking at competitions, at citations, and most importantly, at the tools that were build in this area: we count 76 verification systems for software written in C or Java. We conclude that software model checking has quickly grown to a significant field of research with a high impact on current research directions and tools in software verification.},
	language = {en},
	urldate = {2024-01-29},
	booktitle = {Principles of {Systems} {Design}: {Essays} {Dedicated} to {Thomas} {A}. {Henzinger} on the {Occasion} of {His} 60th {Birthday}},
	publisher = {Springer Nature Switzerland},
	author = {Beyer, Dirk and Podelski, Andreas},
	editor = {Raskin, Jean-François and Chatterjee, Krishnendu and Doyen, Laurent and Majumdar, Rupak},
	year = {2022},
	doi = {10.1007/978-3-031-22337-2_27},
	keywords = {Automatic Verification, Formal Methods, History, Program Correctness, Programming, Provers, Software Verification, Verification Tools},
	pages = {554--582},
}

@article{kang_software_2009,
	title = {Software {Failure} {Probability} {Quantification} for {System} {Risk} {Assessment}},
	volume = {2009},
	doi = {10.3814/2009/163456},
	abstract = {Risk caused by safety-critical I\&C systems considerably affects overall plant risk. Software failures in digitalized I\&C system must be considered as the cause of risk. As digitalization of safety-critical systems progresses, the need of software failure probability quantification increases. For the software of safety-critical systems, very high reliability is required. This article aims at providing an overview of promising software failure probability quantification models and developing an effective way of real application of these methods. The combined use of the SRGM and the VVQM is proposed.},
	journal = {Scholarly Research Exchange},
	author = {Kang, Hyun and Eom, heung-seop and Seong, Han},
	month = jan,
	year = {2009},
}

@article{kim_evaluation_2019,
	title = {Evaluation of effectiveness of fault-tolerant techniques in a digital instrumentation and control system with a fault injection experiment},
	volume = {51},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573318307150},
	doi = {10.1016/j.net.2018.11.012},
	abstract = {Recently, instrumentation and control (I\&C) systems in nuclear power plants have undergone digitalization. Owing to the unique characteristics of digital I\&C systems, the reliability analysis of digital systems has become an important element of probabilistic safety assessment (PSA). In a reliability analysis of digital systems, fault-tolerant techniques and their effectiveness must be considered. A fault injection experiment was performed on a safety-critical digital I\&C system developed for nuclear power plants to evaluate the effectiveness of fault-tolerant techniques implemented in the target system. A software-implemented fault injection in which faults were injected into the memory area was used based on the assumption that all faults in the target system will be reflected in the faults in the memory. To reduce the number of required fault injection experiments, the memory assigned to the target software was analyzed. In addition, to observe the effect of the fault detection coverage of fault-tolerant techniques, a PSA model was developed. The analysis of the experimental result also can be used to identify weak points of fault-tolerant techniques for capability improvement of fault-tolerant techniques.},
	number = {3},
	urldate = {2024-01-29},
	journal = {Nuclear Engineering and Technology},
	author = {Kim, Man Cheol and Seo, Jeongil and Jung, Wondea and Choi, Jong Gyun and Kang, Hyun Gook and Lee, Seung Jun},
	month = jun,
	year = {2019},
	keywords = {Digital I\&C system, Fault detection coverage, Fault injection, Fault-tolerant technique, Probabilistic safety assessment},
	pages = {692--701},
}

@article{ogheneovo_software_2014,
	title = {Software {Dysfunction}: {Why} {Do} {Software} {Fail}?},
	volume = {02},
	issn = {2327-5219, 2327-5227},
	shorttitle = {Software {Dysfunction}},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jcc.2014.26004},
	doi = {10.4236/jcc.2014.26004},
	abstract = {Software is pervasive in modern society, but we are often unaware of its presence until problems arise. Software is one of the most important and yet one of the most economically challenging techniques of this era. As a purely intellectual product, it is among the most labor-intensive, complex, and error-prone technologies in human history. Until the 1970s, programmers were very meticulous in planning their code, rigorously checking code, providing detailed documentation, and exhaustive testing before the software is released to users. However, as computer became widespread, attitudes changed. Instead of meticulously planning code, the attitude of the average programmer today is possibly hacking sessions or writing any sloppy piece of code and the compiler will run diagonally, a situation called, “code and fix”, where the programmer tried to fix errors one by one until the software compiled properly. As programs grew in size and complexity, the limits of this “code and fix” approach became evident. In this paper, we studied the various reasons why software fails. Our studies reveal that the major reasons why software fails are poor or no design at all, inadequate testing of codes, and attitudinal changes among programmers and other factors.},
	language = {en},
	number = {06},
	urldate = {2024-01-29},
	journal = {Journal of Computer and Communications},
	author = {Ogheneovo, Edward E.},
	year = {2014},
	pages = {25--35},
}

@article{noauthor_operating_nodate,
	title = {Operating {Experience} {Insights} on {Common}-{Cause} {Failures} in {Digital} {Instrumentation} and {Control} {Systems}},
	language = {en},
}

@book{ozmen_simulation-based_2017,
	title = {Simulation-{Based} {Testing} for {Instrumentation} and {Control} {Systems}},
	author = {Özmen, Özgür and Nutaro, James and Cetiner, Sacit and Muhlheim, Michael},
	month = nov,
	year = {2017},
}

@article{korsah_investigation_2010,
	title = {An {Investigation} of {Digital} {Instrumentation} and {Control} {System} {Failure} {Modes}},
	abstract = {A study sponsored by the Nuclear Regulatory Commission study was conducted to investigate digital instrumentation and control (DI and C) systems and module-level failure modes using a number of databases both in the nuclear and non-nuclear industries. The objectives of the study were to obtain relevant operational experience data to identify generic DI and C system failure modes and failure mechanisms, and to obtain generic insights, with the intent of using results to establish a unified framework for categorizing failure modes and mechanisms. Of the seven databases studied, the Equipment Performance Information Exchange database was found to contain the most useful data relevant to the study. Even so, the general lack of quality relative to the objectives of the study did not allow the development of a unified framework for failure modes and mechanisms of nuclear I and C systems. However, an attempt was made to characterize all the failure modes observed (i.e., without regard to the type of I and C equipment under consideration) into common categories. It was found that all the failure modes identified could be characterized as (a) detectable/preventable before failures, (b) age-related failures, (c) random failures, (d) random/sudden failures, or (e) intermittent failures. The percentage of failure modes characterized as (a) was significant, implying that a significant reduction in system failures could be achieved through improved online monitoring, exhaustive testing prior to installation, adequate configuration control or verification and validation, etc.},
	author = {Korsah, Kofi and Cetiner, Sacit and Muhlheim, Michael and Poore, Willis},
	month = jan,
	year = {2010},
}

@article{borst_guidance_2020,
	title = {Guidance for {Addressing} {Software} {Common} cause {Failure} {In} {High} {Safety}-{Significant} {Safety} {Related} {Digital} {I}\&{C} {Systems}},
	language = {en},
	author = {Borst, Allison},
	year = {2020},
}

@article{noauthor_background_nodate,
	title = {Background {Paper}: {Delays} in {Nuclear} {Reactor} {Licensing} and {Construction}: {The} {Possibilities} for {Reform}},
	language = {en},
}

@techreport{leveson_stpa_nodate,
	title = {{STPA} {Handbook}},
	url = {https://psas.scripts.mit.edu/home/get_file.php?name=STPA_handbook.pdf},
	language = {en},
	author = {Leveson, Nancy},
}

@book{internationale_atomenergie-organisation_project_2012,
	address = {Vienna},
	series = {{IAEA} nuclear energy series},
	title = {Project management in nuclear power plant construction: guidelines and experience},
	isbn = {978-92-0-122210-7},
	shorttitle = {Project management in nuclear power plant construction},
	language = {en},
	number = {NP-T-2.7},
	publisher = {IAEA},
	author = {Internationale Atomenergie-Organisation},
	year = {2012},
}

@article{chisholm_development_2019,
	title = {Development of a {Methodology} for {Early} {Integration} of {Safety} {Analysis} {Into} {Advanced} {Reactor} {Design}},
	language = {en},
	author = {Chisholm, Brandon and Krahn, Steve and Sowder, Andrew and Afzali, Amir},
	year = {2019},
	pages = {10},
}

@misc{ma_ccf_2022,
	title = {{CCF} {Parameter} {Estimations} 2020},
	language = {en},
	publisher = {Idaho National Lab},
	author = {Ma, Zhegang and Kvarfordt, Kellie J},
	year = {2022},
}

@article{thurner_how_2014,
	title = {How long does it take to build a nuclear power plant? {A} non-parametric event history approach with {P}-splines},
	volume = {70},
	issn = {03014215},
	shorttitle = {How long does it take to build a nuclear power plant?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421514001621},
	doi = {10.1016/j.enpol.2014.03.015},
	abstract = {Governments deciding to use nuclear energy as part of their country's energy mix are faced with longterm planning efforts and huge investments. As nuclear power plants constitute one of the socially and politically most contested technologies, the question arises, which time horizons companies as well as politicians have to consider for the accomplishment and grid-connection of individual and whole ﬂeets of reactors. Unfortunately, there are no large-N studies investigating the time for completion of such large-scale projects. For the ﬁrst time, we statistically explain the duration of the construction of all initiated nuclear plant projects so far. Based on the International Atomic Energy's comprehensive Power Reactor Information System (PRIS) we assess the impact of demographic, economic, and political preconditions of a country, at the same time accounting for different types of reactor technologies. To account for non-linear relationships, we apply non-parametric survival models with P-splines. A main result of our analysis is that time of connection to grid increases over the years indicating increased societal sensibilities, respect for higher security standards, and increased project complexities. The Harrisburg and the Chernobyl disaster did not induce a separate additional delaying effect.},
	language = {en},
	urldate = {2024-01-26},
	journal = {Energy Policy},
	author = {Thurner, Paul W. and Mittermeier, Laura and Küchenhoff, Helmut},
	month = jul,
	year = {2014},
	pages = {163--171},
}

@article{thurner_how_2014-1,
	title = {How long does it take to build a nuclear power plant? {A} non-parametric event history approach with {P}-splines},
	volume = {70},
	issn = {0301-4215},
	shorttitle = {How long does it take to build a nuclear power plant?},
	url = {https://www.sciencedirect.com/science/article/pii/S0301421514001621},
	doi = {10.1016/j.enpol.2014.03.015},
	abstract = {Governments deciding to use nuclear energy as part of their country׳s energy mix are faced with long-term planning efforts and huge investments. As nuclear power plants constitute one of the socially and politically most contested technologies, the question arises, which time horizons companies as well as politicians have to consider for the accomplishment and grid-connection of individual and whole fleets of reactors. Unfortunately, there are no large-N studies investigating the time for completion of such large-scale projects. For the first time, we statistically explain the duration of the construction of all initiated nuclear plant projects so far. Based on the International Atomic Energy׳s comprehensive Power Reactor Information System (PRIS) we assess the impact of demographic, economic, and political preconditions of a country, at the same time accounting for different types of reactor technologies. To account for non-linear relationships, we apply non-parametric survival models with P-splines. A main result of our analysis is that time of connection to grid increases over the years indicating increased societal sensibilities, respect for higher security standards, and increased project complexities. The Harrisburg and the Chernobyl disaster did not induce a separate additional delaying effect.},
	urldate = {2024-01-26},
	journal = {Energy Policy},
	author = {Thurner, Paul W. and Mittermeier, Laura and Küchenhoff, Helmut},
	month = jul,
	year = {2014},
	keywords = {Construction duration, Event history analysis, Nuclear energy},
	pages = {163--171},
}

@article{shykinov_importance_2016,
	title = {Importance of {Advanced} {Planning} of {Manufacturing} for {Nuclear} {Industry}},
	volume = {7},
	doi = {10.1515/mper-2016-0016},
	abstract = {In the context of energy demands by growing economies, climate changes, fossil fuel pricing volatility, and improved safety and performance of nuclear power plants, many countries express interest in expanding or acquiring nuclear power capacity. In the light of the increased interest in expanding nuclear power the supply chain for nuclear power projects has received more attention in recent years. The importance of the advanced planning of procurement and manufacturing of components of nuclear facilities is critical for these projects. Many of these components are often referred to as long-lead items. They may be equipment, products and systems that are identified to have a delivery time long enough to affect directly the overall timing of a project. In order to avoid negatively affecting the project schedule, these items may need to be sourced out or manufactured years before the beginning of the project. For nuclear facilities, long-lead items include physical components such as large pressure vessels, instrumentation and controls. They may also mean programs and management systems important to the safety of the facility. Authorized nuclear operator training, site evaluation programs, and procurement are some of the examples. The nuclear power industry must often meet very demanding construction and commissioning timelines, and proper advanced planning of the long-lead items helps manage risks to project completion time. For nuclear components there are regulatory and licensing considerations that need to be considered. A national nuclear regulator must be involved early to ensure the components will meet the national legal regulatory requirements. This paper will discuss timing considerations to address the regulatory compliance of nuclear long-lead items.},
	journal = {Management and Production Engineering Review},
	author = {Shykinov, Nick and Rulko, Robert and Mroz, Dariusz},
	month = jun,
	year = {2016},
}

@techreport{noauthor_analysis_nodate,
	title = {An analysis of nuclear power plant construction costs},
	url = {https://www.osti.gov/servlets/purl/6071600},
	urldate = {2024-01-04},
}

@book{sullivan_intoduction_nodate,
	title = {Intoduction to {Uncertainty} {Quantification}},
	author = {Sullivan, T.J.},
}

@book{chen_supply_2022,
	address = {Cham},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Supply {Chain} {Scheduling}},
	volume = {323},
	isbn = {978-3-030-90372-5 978-3-030-90374-9},
	url = {https://link.springer.com/10.1007/978-3-030-90374-9},
	language = {en},
	urldate = {2024-01-26},
	publisher = {Springer International Publishing},
	author = {Chen, Zhi-Long and Hall, Nicholas G.},
	year = {2022},
	doi = {10.1007/978-3-030-90374-9},
}

@article{jung_zero-suppressed_2024,
	title = {Zero-suppressed ternary decision diagram algorithm for solving noncoherent fault trees in probabilistic safety assessment of nuclear power plants},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573324000184},
	doi = {10.1016/j.net.2024.01.017},
	abstract = {Probabilistic safety assessment (PSA) plays a critical role in ensuring the safe operation of nuclear power plants. In PSA, event trees are developed to identify accident sequences that could lead to core damage. These event trees are then transformed into a core-damage fault tree, wherein the accident sequences are represented by usual and complemented logic gates representing failed and successful operations of safety systems, respectively. The core damage frequency (CDF) is estimated by calculating the minimal cut sets (MCSs) of the core-damage fault tree.},
	language = {en},
	urldate = {2024-01-20},
	journal = {Nuclear Engineering and Technology},
	author = {Jung, Woo Sik},
	month = jan,
	year = {2024},
	pages = {S1738573324000184},
}

@article{noauthor_risk-informed_nodate,
	title = {Risk-{Informed} {Decision} {Making}: {A} {Survey} of {United} {States} {Experience}},
	language = {en},
}

@misc{noauthor_winehq_nodate,
	title = {{WineHQ} - {Run} {Windows} applications on {Linux}, {BSD}, {Solaris} and {macOS}},
	url = {https://www.winehq.org/},
	abstract = {Open Source Software for running Windows applications on other operating systems.},
	language = {en},
	urldate = {2024-01-22},
	journal = {WineHQ},
}

@inproceedings{cook_complexity_1971,
	address = {New York, NY, USA},
	series = {{STOC} '71},
	title = {The complexity of theorem-proving procedures},
	isbn = {978-1-4503-7464-4},
	url = {https://dl.acm.org/doi/10.1145/800157.805047},
	doi = {10.1145/800157.805047},
	abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” to the problem of determining whether a given propositional formula is a tautology. Here “reduced” means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
	urldate = {2024-01-21},
	booktitle = {Proceedings of the third annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Cook, Stephen A.},
	month = may,
	year = {1971},
	pages = {151--158},
}

@book{biere_handbook_2009,
	title = {Handbook of {Satisfiability}},
	isbn = {978-1-58603-929-5},
	abstract = {A collection of papers on various theoretical and practical aspects of SAT solving. It is suitable for students and researchers.},
	language = {en},
	publisher = {IOS Press},
	author = {Biere, Armin},
	year = {2009},
	note = {Google-Books-ID: YVSM3sxhBhcC},
	keywords = {Computers / Artificial Intelligence / General, Computers / Programming / Algorithms, Education / Decision-Making \& Problem Solving, Mathematics / Logic},
}

@misc{noauthor_handbook_2021,
	title = {Handbook of {Satisfiability}},
	url = {https://www.iospress.com/catalog/books/handbook-of-satisfiability-2},
	language = {en},
	urldate = {2024-01-22},
	journal = {IOS Press},
	month = apr,
	year = {2021},
}

@techreport{keilholtz_fission-product_1968,
	title = {{FISSION}-{PRODUCT} {RELEASE} {AND} {TRANSPORT} {IN} {LIQUID}--{METAL}-{COOLED} {FAST} {BREEDER} {REACTORS}.},
	url = {https://www.osti.gov/biblio/4487809},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	urldate = {2024-01-19},
	institution = {Originating Research Org. not identified},
	author = {Keilholtz, G. W. and Battle, Jr},
	month = jan,
	year = {1968},
}

@article{latkowski_terrapowers_2021,
	title = {{TerraPower}’s {Molten} {Chloride}},
	language = {en},
	author = {Latkowski, Jeff},
	year = {2021},
}

@book{nazri_seismic_2018,
	address = {Singapore},
	series = {{SpringerBriefs} in {Applied} {Sciences} and {Technology}},
	title = {Seismic {Fragility} {Assessment} for {Buildings} due to {Earthquake} {Excitation}},
	isbn = {978-981-10-7124-9 978-981-10-7125-6},
	url = {http://link.springer.com/10.1007/978-981-10-7125-6},
	language = {en},
	urldate = {2024-01-17},
	publisher = {Springer Singapore},
	author = {Nazri, Fadzli Mohamed},
	year = {2018},
	doi = {10.1007/978-981-10-7125-6},
}

@article{luo_satmcs_2021,
	title = {{SATMCS}: {An} {Efficient} {SAT}-{Based} {Algorithm} and {Its} {Improvements} for {Computing} {Minimal} {Cut} {Sets}},
	volume = {70},
	issn = {0018-9529, 1558-1721},
	shorttitle = {{SATMCS}},
	url = {https://ieeexplore.ieee.org/document/9167287/},
	doi = {10.1109/TR.2020.3014012},
	abstract = {Fault tree analysis (FTA) is a prominent reliability analysis method, which is widely used in safety-critical industries. Computing the minimal cut sets (MCSs) of a fault tree, i.e., ﬁnding all the smallest combinations of the basic events that cause system failures, is a fundamental step in FTA. Since coherent fault trees are the most common in industrial systems in practice, they are the focus of this article. Computing MCSs is a computationally hard problem. Classical methods have been proposed based on manipulation of Boolean expressions and binary decision diagrams. However, given the inherent intractability of computing MCSs in practice, there are still limitations on time and memory in these methods. Therefore, developing new methods over different paradigms remains to be an interesting research direction. In this article, motivated by recent progress on modern Boolean satisﬁability problem (SAT) solvers, we present a new method for computing MCSs based on SAT, namely SATMCS. Speciﬁcally, given a fault tree, we iteratively search for a cut set based on the conﬂict-driven clause learning framework. By exploiting local propagation graph, which characterizes the partial failure propagation based on the cut set, we provide efﬁcient algorithms for extracting an MCS. The new MCS is learned as a block clause for SAT solving, and the conﬂict clauses in iterations are incrementally recorded, which helps to prune search space and ensures completeness of the results. Moreover, we adopt a jump-chronological backtracking strategy to prepare the next iteration, which allows for reusing the same search steps in SAT solving. We compare SATMCS with state-of-the-art commercial tools on practical fault trees. Although SATMCS is only a prototype, it shows comparable performance in time consumption with one tool (XFTA), and in various cases, it outperforms the others (FaultTree+ and Commander). Besides, SATMCS exhibits much better performance on memory usage than these tools. Speciﬁcally, SATMCS consumes about one order of magnitude less memory usage in most instances.},
	language = {en},
	number = {2},
	urldate = {2024-01-15},
	journal = {IEEE Transactions on Reliability},
	author = {Luo, Weilin and Wei, Ou and Wan, Hai},
	month = jun,
	year = {2021},
	pages = {575--589},
}

@misc{noauthor_satmcs_nodate,
	title = {{SATMCS}: {An} {Efficient} {SAT}-{Based} {Algorithm} and {Its} {Improvements} for {Computing} {Minimal} {Cut} {Sets} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/document/9167287},
	urldate = {2024-01-15},
}

@article{aven_considerations_2011,
	series = {Special {Issue} on {Safecomp} 2008},
	title = {Some considerations on the treatment of uncertainties in risk assessment for practical decision making},
	volume = {96},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832010001286},
	doi = {10.1016/j.ress.2010.06.001},
	abstract = {This paper discusses the challenges involved in the representation and treatment of uncertainties in risk assessment, taking the point of view of its use in support to decision making. Two main issues are addressed: (1) how to faithfully represent and express the knowledge available to best support the decision making and (2) how to best inform the decision maker. A general risk-uncertainty framework is presented which provides definitions and interpretations of the key concepts introduced. The framework covers probability theory as well as alternative representations of uncertainty, including interval probability, possibility and evidence theory.},
	language = {en},
	number = {1},
	urldate = {2022-10-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Aven, Terje and Zio, Enrico},
	month = jan,
	year = {2011},
	keywords = {Decision-making, Risk assessment, Uncertainty representations},
	pages = {64--74},
}

@article{cojazzi_dylam_1996,
	title = {The {DYLAM} approach for the dynamic reliability analysis of systems},
	volume = {52},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832095001395},
	doi = {10.1016/0951-8320(95)00139-5},
	language = {en},
	number = {3},
	urldate = {2024-01-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Cojazzi, Giacomo},
	month = jun,
	year = {1996},
	pages = {279--296},
}

@article{faes_multivariate_2019,
	title = {A multivariate interval approach for inverse uncertainty quantification with limited experimental data},
	volume = {118},
	issn = {08883270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888327018305946},
	doi = {10.1016/j.ymssp.2018.08.050},
	language = {en},
	urldate = {2024-01-10},
	journal = {Mechanical Systems and Signal Processing},
	author = {Faes, Matthias and Broggi, Matteo and Patelli, Edoardo and Govers, Yves and Mottershead, John and Beer, Michael and Moens, David},
	month = mar,
	year = {2019},
	pages = {534--548},
}

@article{limbourg_modelling_2008,
	title = {Modelling uncertainty in fault tree analyses using evidence theory},
	volume = {222},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR142},
	doi = {10.1243/1748006XJRR142},
	abstract = {The Dempster—Shafer Theory of Evidence (DST) has been considered as an alternative to probabilistic modelling if both a large amount of uncertainty and a conservative treatment of this uncertainty are necessary. Both requirements are normally met in early design stages. Expert estimates replace field data and hardly any accurate test results are available. Therefore, a conservative uncertainty treatment is beneficial to assure a reliable and safe design. The present paper explores the applicability of DST which merges interval-based and probabilistic uncertainty modelling on a fault tree analysis from the automotive area. The system under investigation, an automatic transmission from the ZF AS Tronic series is still in the development stage. Expert estimates and the Monte Carlo propagation of the resulting mass function through the system model are used to obtain the uncertainty on the system failure probability. An exploratory sensitivity based on a non-specifity measure indicates which components contribute to the overall model uncertainty. The results are used to predict if the system complies with a given target failure measure.},
	language = {en},
	number = {3},
	urldate = {2024-01-10},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Limbourg, P and Savić, R and Petersen, J and Kochs, H-D},
	month = sep,
	year = {2008},
	pages = {291--302},
}

@article{wildeyt_overview_nodate,
	title = {Overview of {Forward} and {InveSrAseNDU2n0c1e8r}-{t8a9in4t3yC} {Quantification} {Methods}},
	language = {en},
	author = {Wildeyt, Tim},
}

@book{sullivan_introduction_2015,
	address = {Cham},
	series = {Texts in {Applied} {Mathematics}},
	title = {Introduction to {Uncertainty} {Quantification}},
	volume = {63},
	isbn = {978-3-319-23394-9 978-3-319-23395-6},
	url = {https://link.springer.com/10.1007/978-3-319-23395-6},
	language = {en},
	urldate = {2024-01-08},
	publisher = {Springer International Publishing},
	author = {Sullivan, T.J.},
	year = {2015},
	doi = {10.1007/978-3-319-23395-6},
}

@article{noauthor_nuregcr-6942_nodate,
	title = {{NUREG}/{CR}-6942 "{Dynamic} {Reliability} {Modeling} of {Digital} {Instrumentation} and {Control} {Systems} for {Nuclear} {Reactor} {Probabilistic} {Risk} {Assessments}."},
	language = {en},
}

@book{noauthor_digital_1997,
	address = {Washington, D.C.},
	title = {Digital {Instrumentation} and {Control} {Systems} in {Nuclear} {Power} {Plants}: {Safety} and {Reliability} {Issues}},
	isbn = {978-0-309-05732-5},
	shorttitle = {Digital {Instrumentation} and {Control} {Systems} in {Nuclear} {Power} {Plants}},
	url = {http://www.nap.edu/catalog/5432},
	language = {en},
	urldate = {2024-01-05},
	publisher = {National Academies Press},
	month = apr,
	year = {1997},
	doi = {10.17226/5432},
	note = {Pages: 5432},
}

@article{noauthor_digital_nodate,
	title = {Digital {Instrumentation} and {Control} {Systems} for {New} and {Existing} {Research} {Reactors}},
	language = {en},
}

@article{xu_new_2023,
	title = {A new approach for dynamic reliability analysis of reactor protection system for {HPR1000}},
	volume = {234},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832023000625},
	doi = {10.1016/j.ress.2023.109147},
	abstract = {Traditional static methods are mostly adopted to analyze the reliability of reactor protection system (RPS) for nuclear power plant (NPP). However, they cannot characterize its dynamic interaction, time correlation, and uncertainty. In order to solve this problem, dynamic fault tree (DFT) analysis was firstly utilized to create the DFT for the RPS to characterize its dynamic interaction. Then, dynamic Bayesian network (DBN) was used to create the DBN model based upon the DFT for the RPS to characterize its dynamic interaction, time correlation, and uncertainty. Furthermore, Latin hypercube sampling (LHS) was employed to define a new Bayesian inference algorithm. Finally, the defined algorithm was applied in a RPS for Hualong-1 (HPR1000) in East China to conduct its dynamic prediction and sensitivity analyses through the Bayesian forward and backward inferences, and a new approach for dynamic reliability analysis of the RPS for HPR1000 was proposed. The research results showed that the proposed approach could be used for the dynamic reliability analysis of the RPS.},
	urldate = {2024-01-05},
	journal = {Reliability Engineering \& System Safety},
	author = {Xu, Jintao and Gui, Maolei and Ding, Rui and Dai, Tao and Zheng, Mengyan and Men, Xinhong and Meng, Fanpeng and Yu, Tao and Sui, Yang},
	month = jun,
	year = {2023},
	keywords = {Dynamic bayesian network model, Dynamic fault tree, Dynamic reliability analysis, New bayesian inference algorithm, Reactor protection system},
	pages = {109147},
}

@article{smidts_probabilistic_1994,
	title = {Probabilistic dynamics: {A} comparison between continuous event trees and a discrete event tree model},
	volume = {44},
	issn = {09518320},
	shorttitle = {Probabilistic dynamics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832094900116},
	doi = {10.1016/0951-8320(94)90011-6},
	language = {en},
	number = {2},
	urldate = {2024-01-05},
	journal = {Reliability Engineering \& System Safety},
	author = {Smidts, C.},
	month = jan,
	year = {1994},
	pages = {189--206},
}

@article{xu_path_nodate,
	title = {Path to modeling dynamic performance shaping factors in nuclear power plants operation – {A} review},
	volume = {n/a},
	copyright = {© 2023 Wiley Periodicals LLC.},
	issn = {1520-6858},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sys.21742},
	doi = {10.1002/sys.21742},
	abstract = {The evolution of the mechanism of human behavior formation analysis has significantly influenced the development of human reliability analysis (HRA), which aims to calculate human error probability (HEP) with performance shaping factors (PSFs). This paper reviews the typical HRA methods in different generations, the role of PSFs, and their interrelation-ships in human risk modeling, with the background of nuclear power plants (NPPs). In a retrospective of typical HRA methods, PSF plays a fundamental role in assessing human performance during task operation. However, the subjectivity in defining and evaluating PSFs often leads to a partial representation of human behavior characteristics and human risk evolution, resulting in the neglect of PSF inter-relationships and conservative HEP estimation. Recent studies have emphasized employing simulation platforms to simulate the task process and obtain data relevant to PSFs that can enable the exploration of the mutual effects to support the calculation of HEP more accurately. Compared to certain previous methods involving over-simplification and inappropriate assumptions resulting in inaccurate results, current HRA methods are prone to the construction of HEP models based on objective data acquisition and dynamic calculations with process models. This shift enables a better illustration of the intricate relationships among PSFs. Reflecting on the current trend of HRA methodology, this paper proposes a possible PSF quantification based on physiological measurement providing accessible and objective data. It improves the shortcomings in data scarcity and time-invariance of HEP calculation, thus more accurately and realistically responds to the accumulation and fluctuation of human risks throughout a task.},
	language = {en},
	number = {n/a},
	urldate = {2024-01-04},
	journal = {Systems Engineering},
	author = {Xu, Zhihui and Yang, Gaoguang and Lu, Yi and Xue, Jiaxin and Wu, Guanyin and Ren, Bingxuan and Fu, Shan},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sys.21742},
	keywords = {human reliability analysis, inter-relationships, nuclear power plant operations, objective data, performance shaping factors},
}

@article{lovering_historical_2016,
	title = {Historical construction costs of global nuclear power reactors},
	volume = {91},
	issn = {03014215},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421516300106},
	doi = {10.1016/j.enpol.2016.01.011},
	abstract = {The existing literature on the construction costs of nuclear power reactors has focused almost exclusively on trends in construction costs in only two countries, the United States and France, and during two decades, the 1970s and 1980s. These analyses, Koomey and Hultman (2007); Grubler (2010), and Escobar-Rangel and Lévêque (2015), study only 26\% of reactors built globally between 1960 and 2010, providing an incomplete picture of the economic evolution of nuclear power construction. This study curates historical reactor-speciﬁc overnight construction cost (OCC) data that broaden the scope of study substantially, covering the full cost history for 349 reactors in the US, France, Canada, West Germany, Japan, India, and South Korea, encompassing 58\% of all reactors built globally. We ﬁnd that trends in costs have varied signiﬁcantly in magnitude and in structure by era, country, and experience. In contrast to the rapid cost escalation that characterized nuclear construction in the United States, we ﬁnd evidence of much milder cost escalation in many countries, including absolute cost declines in some countries and speciﬁc eras. Our new ﬁndings suggest that there is no inherent cost escalation trend associated with nuclear technology.},
	language = {en},
	urldate = {2024-01-03},
	journal = {Energy Policy},
	author = {Lovering, Jessica R. and Yip, Arthur and Nordhaus, Ted},
	month = apr,
	year = {2016},
	pages = {371--382},
}

@article{lovering_historical_2016-1,
	title = {Historical construction costs of global nuclear power reactors},
	volume = {91},
	issn = {03014215},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421516300106},
	doi = {10.1016/j.enpol.2016.01.011},
	abstract = {The existing literature on the construction costs of nuclear power reactors has focused almost exclusively on trends in construction costs in only two countries, the United States and France, and during two decades, the 1970s and 1980s. These analyses, Koomey and Hultman (2007); Grubler (2010), and Escobar-Rangel and Lévêque (2015), study only 26\% of reactors built globally between 1960 and 2010, providing an incomplete picture of the economic evolution of nuclear power construction. This study curates historical reactor-speciﬁc overnight construction cost (OCC) data that broaden the scope of study substantially, covering the full cost history for 349 reactors in the US, France, Canada, West Germany, Japan, India, and South Korea, encompassing 58\% of all reactors built globally. We ﬁnd that trends in costs have varied signiﬁcantly in magnitude and in structure by era, country, and experience. In contrast to the rapid cost escalation that characterized nuclear construction in the United States, we ﬁnd evidence of much milder cost escalation in many countries, including absolute cost declines in some countries and speciﬁc eras. Our new ﬁndings suggest that there is no inherent cost escalation trend associated with nuclear technology.},
	language = {en},
	urldate = {2024-01-03},
	journal = {Energy Policy},
	author = {Lovering, Jessica R. and Yip, Arthur and Nordhaus, Ted},
	month = apr,
	year = {2016},
	pages = {371--382},
}

@book{severance_system_2001,
	address = {Chichester ; New York},
	title = {System modeling and simulation: an introduction},
	isbn = {978-0-471-49694-6},
	shorttitle = {System modeling and simulation},
	language = {en},
	publisher = {J. Wiley},
	author = {Severance, Frank L.},
	year = {2001},
	keywords = {System theory},
}

@techreport{bartel_wash-1400_2016,
	title = {{WASH}-1400 - {The} {Reactor} {Safety} {Study} - {The} {Introduction} of {Risk} {Assessment} to the {Regulation} of {Nuclear} {Reactors}},
	language = {en},
	number = {NUREG/KM-0010},
	author = {Bartel, Reynold},
	year = {2016},
	pages = {60},
}

@techreport{ericson_analysis_1990,
	title = {Analysis of core damage frequency: {Internal} events methodology},
	shorttitle = {Analysis of core damage frequency},
	url = {https://www.osti.gov/biblio/5066882},
	abstract = {NUREG-1150 examines the risk to the public from a selected group of nuclear power plants. This report describes the methodology that evolved as the internal event core damage frequencies for four plants were generated in support of NUREG-1150. The objective is to perform an analysis that closely approximates a state-of-the-art Level 1 Probabilistic Risk Assessment (PRA). Therefore, in principle, it is similar to those used in previous PRAs. However, this methodology, based upon previous studies and using analysts experienced in these techniques, allows the analysis to be focused upon selected areas. With this approach only the most important systems and failure modes are emphasized and modeled in detail, and the data and human reliability analyses are simplified. An analysis employing this methodology (exclusive of external reviews) can be completed in nine to twelve months using two or three full-time experienced systems analysts and part-time personnel in other areas, such as data analysis and human reliability analysis. This is significantly faster and less expensive than previous analyses, but even so, most of the insights that are obtained by the more expensive studies are still provided. 78 refs., 30 figs., 73 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.1-Rev.1; SAND-86-2084-Vol.1-Rev.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Ericson, Jr and Wheeler, T. A. and Sype, T. T. and Cramond, W. R. and Camp, A. L. and Maloney, K. J. and Harper, F. T. and Drouin, M. T.},
	month = jan,
	year = {1990},
	doi = {10.2172/5066882},
}

@techreport{wheeler_analysis_1989,
	title = {Analysis of core damage frequency from internal events: {Expert} judgment elicitation: {Part} 1, {Expert} panel results, {Part} 2, {Project} staff results},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6305841},
	abstract = {Quantitative modeling techniques have limitations as to the resolution of important issues in probabilistic risk assessment (PRA). Not all issues can be resolved via the existing set of methods such as fault trees, event trees, statistical analyses, data collection, and computer simulation. Therefore, an expert judgment process was developed to address issues perceived as important to risk in the NUREG-1150 analysis but which could not be resolved with existing techniques. This process was applied to several issues that could significantly affect the internal event core damage frequencies of the PRAs performed on six light water reactors. Detailed descriptions of these issues and the results of the expert judgment elicitation are reported here, as well as an explanation of the methodology used and the procedure followed in performing the overall elicitation task. The process is time-consuming and expensive. However, the results are very useful, and represent an improvement over the draft NUREG-1150 analysis in the areas of expert selection, elicitation training, issue selection and presentation, elicitation of judgment and aggregation of results. The results are presented in two parts. Part 1 documents the expert panel elicitations, where the most important issues were presented to a panel of experts convened from throughout the nuclear power risk assessment community. Part 2 documents the process by which the project staff performed expert judgment on other important issues, using the project staff as panel members. 7 refs., 3 figs., 6 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.2; SAND-86-2084-Vol.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Labs., Albuquerque, NM (USA)},
	author = {Wheeler, T. A. and Hora, S. C. and Cramond, W. R. and Unwin, S. D.},
	month = apr,
	year = {1989},
}

@techreport{chu_evaluation_1994,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit}-1: {Analysis} of core damage frequency from internal events during mid-loop operations. {Appendices} {F}-{H}, {Volume} 2, {Part} 4},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit}-1},
	url = {https://www.osti.gov/biblio/10171925},
	abstract = {Traditionally, probabilistic risk assessments (PRA) of severe accidents in nuclear power plants have considered initiating events potentially occurring only during full power operation. Some previous screening analyses that were performed for other modes of operation suggested that risks during those modes were small relative to full power operation. However, more recent studies and operational experience have implied that accidents during low power and shutdown could be significant contributors to risk. Two plants, Surry (pressurized water reactor) and Grand Gulf (boiling water reactor), were selected as the plants to be studied. The objectives of the program are to assess the risks of severe accidents initiated during plant operational states other than full power operation and to compare the estimated core damage frequencies, important accident sequences and other qualitative and quantitative results with those accidents initiated during full power operation as assessed in NUREG-1150. The scope of the program includes that of a level-3 PRA. In phase 2, mid-loop operation was selected as the plant configuration to be analyzed based on the results of the phase 1 study. The objective of the phase 2 study is to perform a detailed analysis of the potential accident scenarios that may occur during mid-loop operation, and compare the results with those of NUREG-1150. The scope of the level-1 study includes plant damage state analysis, and uncertainty analysis. Volume 1 summarizes the results of the study. Internal events analysis is documented in Volume 2. It also contains an appendix that documents the part of the phase 1 study that has to do with POSs other than mid-loop operation. Internal fire and internal flood analyses are documented in Volumes 3 and 4. A separate study on seismic analysis, documented in Volume 5, was performed for the NRC by Future Resources Associates, Inc. Volume 6 documents the accident progression, source terms, and consequence analysis.},
	language = {English},
	number = {NUREG/CR-6144-Vol.2-Pt.4; BNL-NUREG-52399-Vol.2-Pt.4},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Office of Nuclear Regulatory Research; Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Chu, T. L. and Musicki, Z. and Kohut, P. and Yang, J. and Bozoki, G. and Hsu, C. J. and Diamond, D. J. and Bley, D. and Johnson, D. and Holmes, B.},
	month = jun,
	year = {1994},
	doi = {10.2172/10171925},
}

@techreport{drouin_analysis_1987,
	title = {Analysis of core damage frequency from internal events: {Methodology} guidelines: {Volume} 1},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/5828278},
	abstract = {NUREG-1150 examines the risk to the public from a selected group of nuclear power plants. This report describes the methodology used to estimate the internal event core damage frequencies of four plants in support of NUREG-1150. In principle, this methodology is similar to methods used in past probabilistic risk assessments; however, based on past studies and using analysts that are experienced in these techniques, the analyses can be focused in certain areas. In this approach, only the most important systems and failure modes are modeled in detail. Further, the data and human reliability analyses are simplified, with emphasis on the most important components and human actions. Using these methods, an analysis can be completed in six to nine months using two to three full-time systems analysts and part-time personnel in other areas, such as data analysis and human reliability analysis. This is significantly faster and less costly than previous analyses and provides most of the insights that are obtained by the more costly studies. 82 refs., 35 figs., 27 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.1; SAND-86-2084-Vol.1},
	urldate = {2023-12-02},
	institution = {Sandia National Labs., Albuquerque, NM (USA)},
	author = {Drouin, M. T. and Harper, F. T. and Camp, A. L.},
	month = sep,
	year = {1987},
}

@techreport{chu_evaluation_1994-1,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit} 1: {Analysis} of core damage frequency from internal events during mid-loop operations. {Appendix} {E} ({Sections} {E}.9-{E}.16), {Volume} 2, {Part} {3B}},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit} 1},
	url = {https://www.osti.gov/biblio/10171928},
	abstract = {Traditionally, probabilistic risk assessments (PRA) of severe accidents in nuclear power plants have considered initiating events potentially occurring only during full power operation. Some previous screening analyses that were performed for other modes of operation suggested that risks during those modes were small relative to full power operation. However, more recent studies and operational experience have implied that accidents during low power and shutdown could be significant contributors to risk. Two plants, Surry (pressurized water reactor) and Grand Gulf (boiling water reactor), were selected as the plants to be studied. The objectives of the program are to assess the risks of severe accidents initiated during plant operational states other than full power operation and to compare the estimated core damage frequencies, important accident sequences and other qualitative and quantitative results with those accidents initiated during full power operation as assessed in NUREG-1150. The scope of the program includes that of a level-3 PRA. In phase 2, mid-loop operation was selected as the plant configuration to be analyzed based on the results of the phase 1 study. The objective of the phase 2 study is to perform a detailed analysis of the potential accident scenarios that may occur during mid-loop operation, and compare the results with those of NUREG-1150. The scope of the level-1 study includes plant damage state analysis, and uncertainty analysis. Volume 1 summarizes the results of the study. Internal events analysis is documented in Volume 2. It also contains an appendix that documents the part of the phase 1 study that has to do with POSs other than mid-loop operation. Internal fire and internal flood analyses are documented in Volumes 3 and 4. A separate study on seismic analysis, documented in Volume 5, was performed for the NRC by Future Resources Associates, Inc. Volume 6 documents the accident progression, source terms, and consequence analysis.},
	language = {English},
	number = {NUREG/CR-6144-Vol.2-Pt.3B; BNL-NUREG-52399-Vol.2-Pt.3B},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Chu, T. L. and Musicki, Z. and Kohut, P. and Yang, J. and Bozoki, G. and Hsu, C. J. and Diamond, D. J. and Wong, S. M. and Bley, D. and Johnson, D.},
	month = jun,
	year = {1994},
	doi = {10.2172/10171928},
}

@techreport{wheeler_analysis_1986,
	title = {Analysis of core damage frequency from internal events: {Zion} {Unit} 1},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6911421},
	abstract = {The Review and Evaluation of the Zion Probabilistic Safety Study (NUREG/CR-3300) represents an analysis of the risk profile at Zion based on the plant status as of 1982. This report reevaluates the dominant accident sequences of NUREG/CR-3300 within the context of changes in plant configurations, operational procedures, and general safety issues. This analysis is restricted to the set of accident sequences in NUREG/CR-3300, and does not investigate potentially new dominant sequences.},
	language = {English},
	number = {NUREG/CR-4550-Vol.7; SAND-86-2084-Vol.7},
	urldate = {2023-12-02},
	institution = {Sandia National Labs., Albuquerque, NM (USA)},
	author = {Wheeler, T. A.},
	month = oct,
	year = {1986},
}

@techreport{chu_evaluation_1994-2,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit}-1: {Analysis} of core damage frequency from internal events during mid-loop operations. {Appendix} {I}, {Volume} 2, {Part} 5},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit}-1},
	url = {https://www.osti.gov/biblio/10171932},
	abstract = {Traditionally, probabilistic risk assessments (PRA) of severe accidents in nuclear power plants have considered initiating events potentially occurring only during full power operation. Some previous screening analyses that were performed for other modes of operation suggested that risks during those modes were small relative to full power operation. However, more recent studies and operational experience have implied that accidents during low power and shutdown could be significant contributors to risk. During 1989, the Nuclear Regulatory Commission (NRC) initiated an extensive program to carefully examine the potential risks during low power and shutdown operations. The program includes two parallel projects being performed by Brookhaven National Lab. (BNL) and Sandia National Labs. (SNL). Two plants, Surry (pressurized water reactor) and Grand Gulf (boiling water reactor), were selected as the plants to be studied. The objectives of the program are to assess the risks of severe accidents initiated during plant operational states other than full power operation and to compare the estimated core damage frequencies, important accident sequences and other qualitative and quantitative results with those accidents initiated during full power operation as assessed in NUREG-1150. The objective of this volume of the report is to document the approach utilized in the level-1 internal events PRA for the Surry plant, and discuss the results obtained. A phased approach was used in the level-1 program. In phase 1, which was completed in Fall 1991, a coarse screening analysis examining accidents initiated by internal events (including internal fire and flood) was performed for all plant operational states (POSs). The objective of the phase 1 study was to identify potential vulnerable plant configurations, to characterize (on a high, medium, or low basis) the potential core damage accident scenarios, and to provide a foundation for a detailed phase 2 analysis.},
	language = {English},
	number = {NUREG/CR-6144-Vol.2-Pt.5; BNL-NUREG-52399-Vol.2-Pt.5},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Office of Nuclear Regulatory Research; Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Chu, T. L. and Musicki, Z. and Kohut, P. and Yang, J. and Bozoki, G. and Hsu, C. J. and Diamond, D. J. and Bley, D. and Johnson, D. and Holmes, B.},
	month = jun,
	year = {1994},
	doi = {10.2172/10171932},
}

@techreport{yakle_evaluation_1994,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Grand} {Gulf}, {Unit} 1: {Analysis} of core damage frequency from internal events for {Plant} {Operational} {State} 5 during a refueling outage. {Volume} 2, {Part} 3: {Internal} {Events} {Appendices} {I} and {J}},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Grand} {Gulf}, {Unit} 1},
	url = {https://www.osti.gov/biblio/10170668},
	abstract = {This report provides supporting documentation for various tasks associated with the performance of the probablistic risk assessment for Plant Operational State 5 during a refueling outage at Grand Gulf, Unit 1 as documented in Volume 2, Part 1 of NUREG/CR-6143.},
	language = {English},
	number = {NUREG/CR-6143-Vol.2-Pt.3; SAND-93-2440-Vol.2-Pt.3},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Yakle, J. and Darby, J. and Whitehead, D. and Staple, B.},
	month = jun,
	year = {1994},
	doi = {10.2172/10170668},
}

@techreport{whitehead_evaluation_1994,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Grand} {Gulf}, {Unit} 1. {Volume} 2, {Part} {1C}: {Analysis} of core damage frequency from internal events for plant operational {State} 5 during a refueling outage, {Main} report ({Sections} 11--14)},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Grand} {Gulf}, {Unit} 1. {Volume} 2, {Part} {1C}},
	url = {https://www.osti.gov/biblio/10170040},
	abstract = {This document contains the accident sequence analysis of internally initiated events for Grand Gulf, Unit 1 as it operates in the Low Power and Shutdown Plant Operational State 5 during a refueling outage. The report documents the methodology used during the analysis, describes the results from the application of the methodology, and compares the results with the results from two full power analyses performed on Grand Gulf.},
	language = {English},
	number = {NUREG/CR-6143-Vol.2-Pt.1C; SAND-93-2440-Vol.2-Pt.1C},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Whitehead, D. and Darby, J. and Yakle, J.},
	month = jun,
	year = {1994},
	doi = {10.2172/10170040},
}

@techreport{wheeler_analysis_1989-1,
	title = {Analysis of core damage frequency from internal events: {Expert} judgment elicitation: {Part} 1, {Expert} panel results, {Part} 2, {Project} staff results},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6305841},
	abstract = {Quantitative modeling techniques have limitations as to the resolution of important issues in probabilistic risk assessment (PRA). Not all issues can be resolved via the existing set of methods such as fault trees, event trees, statistical analyses, data collection, and computer simulation. Therefore, an expert judgment process was developed to address issues perceived as important to risk in the NUREG-1150 analysis but which could not be resolved with existing techniques. This process was applied to several issues that could significantly affect the internal event core damage frequencies of the PRAs performed on six light water reactors. Detailed descriptions of these issues and the results of the expert judgment elicitation are reported here, as well as an explanation of the methodology used and the procedure followed in performing the overall elicitation task. The process is time-consuming and expensive. However, the results are very useful, and represent an improvement over the draft NUREG-1150 analysis in the areas of expert selection, elicitation training, issue selection and presentation, elicitation of judgment and aggregation of results. The results are presented in two parts. Part 1 documents the expert panel elicitations, where the most important issues were presented to a panel of experts convened from throughout the nuclear power risk assessment community. Part 2 documents the process by which the project staff performed expert judgment on other important issues, using the project staff as panel members. 7 refs., 3 figs., 6 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.2; SAND-86-2084-Vol.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Labs., Albuquerque, NM (USA)},
	author = {Wheeler, T. A. and Hora, S. C. and Cramond, W. R. and Unwin, S. D.},
	month = apr,
	year = {1989},
}

@techreport{bertucio_analysis_1987,
	title = {Analysis of core damage frequency from internal events: {Sequoyah}, {Unit} 1},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6570407},
	abstract = {This document contains the accident sequence analyses for Sequoyah, Unit 1, one of the reference plants being examined as part of the NUREG-1150 effort by the Nuclear Regulatory Commission (NRC). NUREG-1150 will document the risk of a selected group of nuclear power plants. As part of that work, this report contains the overall core damage frequency estimate for Sequoyah, Unit 1, and the accompanying plant damage state frequencies. Sensitivity and uncertainty analyses provided additional insights regarding the dominant contributors to the Sequoyah core damage frequency estimate. The numerical results are influenced by modeling assumptions and data selection for issues such as reactor coolant pump seal LOCA, common cause failure probabilities, and operator response to emergency conditions such as small LOCA and station blackout. The sensitivity studies explored the impact of alternate theories and data on these issues.},
	language = {English},
	number = {NUREG/CR-4550-Vol.5; SAND-86-2084-Vol.5},
	urldate = {2023-12-02},
	institution = {Sandia National Labs., Albuquerque, NM (USA); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety},
	author = {Bertucio, R. C. and Moore, D. L. and Held, J. T. and Leahy, T. J. and Harper, F. T.},
	month = feb,
	year = {1987},
}

@techreport{drouin_analysis_1987-1,
	title = {Analysis of core damage frequency from internal events, {Grand} {Gulf}, {Unit} 1: {Appendices}},
	shorttitle = {Analysis of core damage frequency from internal events, {Grand} {Gulf}, {Unit} 1},
	url = {https://www.osti.gov/biblio/6439167},
	abstract = {This document contains the accident sequence analyses for Grand Gulf Unit 1, one of the reference plants being examined as part of the NUREG-1150 effort by the Nuclear Regulatory Commission. NUREG-1150 will document the risk of a selected group of nuclear power plants. As part of that work, this report contains the overall core damage frequency estimate for Grand Gulf Unit 1 and the accompanying plant damage state frequencies. Sensitivity and uncertainty analyses provide additional insights regarding the dominant contributors to the Grand Gulf core damage frequency estimate. The mean core damage frequency at Grand Gulf was calculated to be 2.9E-5. Station blackout type accidents (loss of all AC power accidents) were found to dominate the overall results. Anticipated transient without scram accidents were also found to be contributors. The numerical results are largely driven by common mode failure probability estimates and, to some extent, human error. Because of significant data uncertainties in these two areas, it is recommended that the results of the uncertainty and sensitivity analyses be considered before any future actions are taken based on this analysis. In particular, the single most dominant scenario may require a more detailed data search and analysis before actions are implemented on the basis of this scenario.},
	language = {English},
	number = {NUREG/CR-4550-Vol.6-Pt.2; SAND-86-2084-Vol.6-Pt.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety; Sandia National Labs., Albuquerque, NM (USA)},
	author = {Drouin, M. T. and LaChance, J. L. and Shapiro, B. J. and Harper, F. T. and Wheeler, T. A.},
	month = apr,
	year = {1987},
}

@techreport{drouin_analysis_1987-2,
	title = {Analysis of core damage frequency from internal events, {Grand} {Gulf}, {Unit} 1: {Main} report},
	shorttitle = {Analysis of core damage frequency from internal events, {Grand} {Gulf}, {Unit} 1},
	url = {https://www.osti.gov/biblio/6433678},
	abstract = {This document contains the accident sequence analyses for Grand Gulf Unit 1, one of the reference plants being examined as part of the NUREG-1150 effort by the Nuclear Regulatory Commission. NUREG-1150 will document the risk of a selected group of nuclear power plants. As part of that work, this report contains the overall core damage frequency estimate for Grand Gulf Unit 1 and the accompanying plant damage state frequencies. Sensitivity and uncertainty analyses provide additional insights regarding the dominant contributors to the Grand Gulf core damage frequency estimate. The mean core damage frequency at Grand Gulf was calculated to be 2.9E-5. Station blackout type accidents (i.e., loss of all ac power accidents) were found to dominate the overall results. Anticipated transient without scram accidents were also found to be contributors. The numerical results are largely driven by common mode failure probability estimates and, to some extent, human error. Because of significant data uncertainties in these two areas, it is recommended that the results of the uncertainty and sensitivity analyses be considered before any future actions are taken based on this analysis. In particular, the single most dominant scenario may require a more detailed data search and analysis before actions are implemented on the basis of the scenario.},
	language = {English},
	number = {NUREG/CR-4550-Vol.6-Pt.1; SAND-86-2084-Vol.6-Pt.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety; Sandia National Labs., Albuquerque, NM (USA)},
	author = {Drouin, M. T. and LaChance, J. L. and Shapiro, B. J. and Harper, F. T. and Wheeler, T. A.},
	month = apr,
	year = {1987},
}

@techreport{harper_analysis_1986,
	title = {Analysis of core damage frequency from internal events: {Surry}, {Unit} 1},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6660464},
	abstract = {This document contains the accident sequence analyses for Surry, Unit 1; one of the reference plants being examined as part of the NUREG-1150 effort by the Nuclear Regulatory Commission (NRC). NUREG-1150 will document the risk of a selected group of nuclear power plants. As part of that work, this report contains the overall core damage frequency estimate for Surry, Unit 1, and the accompanying plant damage state frequencies. Sensitivity and uncertainty analyses provide additional insights regarding the dominant contributors to the Surry core damage frequency estimate. The numerical results are driven to some degree by modeling assumptions and data selection for issues such as reactor coolant pump seal LOCAs, common cause failure probabilities, and plant response to station blackout and loss of electrical bust initiators. The sensitivity studies explore the impact of alternate theories and data on these issues.},
	language = {English},
	number = {NUREG/CR-4550-Vol.3; SAND-86-2084-Vol.3},
	urldate = {2023-12-02},
	institution = {Sandia National Labs., Albuquerque, NM (USA); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety},
	author = {Harper, F. T.},
	month = nov,
	year = {1986},
}

@techreport{noauthor_individual_1997,
	title = {Individual plant examination program: {Perspectives} on reactor safety and plant performance. {Part} 1: {Final} summary report; {Volume} 1},
	shorttitle = {Individual plant examination program},
	url = {https://www.osti.gov/biblio/569125},
	abstract = {This report provides perspectives gained by reviewing 75 Individual Plant Examination (IPE) submittals pertaining to 108 nuclear power plant units. IPEs are probabilistic analyses that estimate the core damage frequency (CDF) and containment performance for accidents initiated by internal events. The US Nuclear Regulatory Commission (NRC) reviewed the IPE submittals with the objective of gaining perspectives in three major areas: (1) improvements made to individual plants as a result of their IPEs and the collective results of the IPE program, (2) plant-specific design and operational features and modeling assumptions that significantly affect the estimates of CDF and containment performance, and (3) strengths and weaknesses of the models and methods used in the IPEs. These perspectives are gained by assessing the core damage and containment performance results, including overall CDF, accident sequences, dominant contributions to component failure and human error, and containment failure modes. Methods, data, boundary conditions, and assumptions used in the IPEs are considered in understanding the differences and similarities observed among the various types of plants. This report is divided into three volumes containing six parts. Part 1 is a summary report of the key perspectives gained in each of the areas identified above, with a discussion of the NRC`s overall conclusions and observations. Part 2 discusses key perspectives regarding the impact of the IPE Program on reactor safety. Part 3 discusses perspectives gained from the IPE results regarding CDF, containment performance, and human actions. Part 4 discusses perspectives regarding the IPE models and methods. Part 5 discusses additional IPE perspectives. Part 6 contains Appendices A, B and C which provide the references of the information from the IPEs, updated PRA results, and public comments on draft NUREG-1560 respectively.},
	language = {English},
	number = {NUREG-1560-Vol.1},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Div. of Systems Technology},
	month = dec,
	year = {1997},
	doi = {10.2172/569125},
}

@techreport{noauthor_individual_1997-1,
	title = {Individual plant examination program: {Perspectives} on reactor safety and plant performance. {Parts} 2--5: {Final} report; {Volume} 2},
	shorttitle = {Individual plant examination program},
	url = {https://www.osti.gov/biblio/569126},
	abstract = {This report provides perspectives gained by reviewing 75 Individual Plant Examination (IPE) submittals pertaining to 108 nuclear power plant units. IPEs are probabilistic analyses that estimate the core damage frequency (CDF) and containment performance for accidents initiated by internal events. The US Nuclear Regulatory Commission (NRC) reviewed the IPE submittals with the objective of gaining perspectives in three major areas: (1) improvements made to individual plants as a result of their IPEs and the collective results of the IPE program, (2) plant-specific design and operational features and modeling assumptions that significantly affect the estimates of CDF and containment performance, and (3) strengths and weaknesses of the models and methods used in the IPEs. These perspectives are gained by assessing the core damage and containment performance results, including overall CDF, accident sequences, dominant contributions to component failure and human error, and containment failure modes. Methods, data, boundary conditions, and assumptions used in the IPEs are considered in understanding the differences and similarities observed among the various types of plants. This report is divided into three volumes containing six parts. Part 1 is a summary report of the key perspectives gained in each of the areas identified above, with a discussion of the NRC`s overall conclusions and observations. Part 2 discusses key perspectives regarding the impact of the IPE Program on reactor safety. Part 3 discusses perspectives gained from the IPE results regarding CDF, containment performance, and human actions. Part 4 discusses perspectives regarding the IPE models and methods. Part 5 discusses additional IPE perspectives. Part 6 contains Appendices A, B and C which provide the references of the information from the IPEs, updated PRA results, and public comments on draft NUREG-1560 respectively.},
	language = {English},
	number = {NUREG-1560-Vol.2},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Div. of Systems Technology},
	month = dec,
	year = {1997},
	doi = {10.2172/569126},
}

@techreport{gregory_evaluation_1990,
	title = {Evaluation of severe accident risks, {Sequoyah}, {Unit} 1: {Main} report},
	shorttitle = {Evaluation of severe accident risks, {Sequoyah}, {Unit} 1},
	url = {https://www.osti.gov/biblio/6297440},
	abstract = {In support of the US Nuclear Regulatory Commission's assessment of the risk from severe accidents at commercial nuclear power plants in the US reported in NUREG-1150, the Severe Accident Risk Reduction Program has completed a revised calculation of the risk to the general public from severe accidents at the Sequoyah Power Station, Unit 1. This power plant, located in southeastern Tennessee, is operated by the Tennessee Valley Authority. The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risks from initiating events internal to the power station were assessed. 45 refs., 42 figs., 49 tabs.},
	language = {English},
	number = {NUREG/CR-4551-Vol.5-Rev.1-Pt.1; SAND-86-1309-Vol.5-Rev.1-Pt.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Gregory, J. J. and Higgins, S. J. and Breeding, R. J. and Shiver, A. W. and Murfin, W. B. and Helton, J. C.},
	month = dec,
	year = {1990},
	doi = {10.2172/6297440},
}

@techreport{kolaczkowski_analysis_1986,
	title = {Analysis of core damage frequency from internal events: {Peach} {Bottom}, {Unit} 2},
	shorttitle = {Analysis of core damage frequency from internal events},
	url = {https://www.osti.gov/biblio/6993388},
	abstract = {This document contains the internal event initiated accident sequence analyses for Peach Bottom, Unit 2; one of the reference plants being examined as part of the NUREG-1150 effort by the Nuclear Regulatory Commission. NUREG-1150 will document the risk of a selected group of nuclear power plants. As part of that work, this report contains the overall core damage frequency estimate for Peach Bottom, Unit 2, and the accompanying plant damage state frequencies. Sensitivity and uncertainty analyses provided additional insights regarding the dominant contributors to the Peach Bottom core damage frequency estimate. The mean core damage frequency at Peach Bottom was calculated to be 8.2E-6. Station blackout type accidents (loss of all ac power) were found to dominate the overall results. Anticipated Transient Without Scram accidents were also found to be non-negligible contributors. The numerical results are largely driven by common mode failure probability estimates and to some extent, human error. Because of significant data and analysis uncertainties in these two areas (important, for instance, to the most dominant scenario in this study), it is recommended that the results of the uncertainty and sensitivity analyses be considered before any actions are taken based on this analysis.},
	language = {English},
	number = {NUREG/CR-4550-Vol.4; SAND-86-2084},
	urldate = {2023-12-02},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety},
	author = {Kolaczkowski, A. M. and Lambright, J. A. and Ferrell, W. L. and Cathey, N. G. and Najafi, B. and Harper, F. T.},
	month = oct,
	year = {1986},
	doi = {10.2172/6993388},
}

@techreport{harper_probabilistic_1995,
	title = {Probabilistic accident consequence uncertainty analysis: {Dispersion} and deposition uncertainty assessment, main report},
	shorttitle = {Probabilistic accident consequence uncertainty analysis},
	url = {https://www.osti.gov/biblio/10125585},
	abstract = {The development of two new probabilistic accident consequence codes, MACCS and COSYMA, was completed in 1990. These codes estimate the risks presented by nuclear installations based on postulated frequencies and magnitudes of potential accidents. In 1991, the US Nuclear Regulatory Commission (NRC) and the Commission of the European Communities (CEC) began a joint uncertainty analysis of the two codes. The ultimate objective of the joint effort was to develop credible and traceable uncertainty distributions for the input variables of the codes. Expert elicitation was identified as the best technology available for developing a library of uncertainty distributions for the selected consequence parameters. The study was formulated jointly and was limited to the current code models and to physical quantities that could be measured in experiments. Experts developed their distributions independently. To validate the distributions generated for the wet deposition input variables, samples were taken from these distributions and propagated through the wet deposition code model. Resulting distributions closely replicated the aggregated elicited wet deposition distributions. To validate the distributions generated for the dispersion code input variables, samples from the distributions and propagated through the Gaussian plume model (GPM) implemented in the MACCS and COSYMA codes. Project teams from the NRC and CEC cooperated successfully to develop and implement a unified process for the elaboration of uncertainty distributions on consequence code input parameters. Formal expert judgment elicitation proved valuable for synthesizing the best available information. Distributions on measurable atmospheric dispersion and deposition parameters were successfully elicited from experts involved in the many phenomenological areas of consequence analysis. This volume is the first of a three-volume document describing the project.},
	language = {English},
	number = {NUREG/CR-6244-Vol.1; EUR-1585EN-Vol.1; SAND-94-1453-Vol.1},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Div. of Systems Technology; Commission of the European Communities, Brussels (Belgium); Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Harper, F. T. and Young, M. L. and Miller, L. A. and Hora, S. C. and Lui, C. H. and Goossens, L. H. J. and Cooke, R. M. and Paesler-Sauer, J. and Helton, J. C.},
	month = jan,
	year = {1995},
	doi = {10.2172/10125585},
}

@techreport{gorham_evaluation_1993,
	title = {Evaluation of severe accident risks: {Methodology} for the containment, source term, consequence, and risk integration analyses; {Volume} 1, {Revision} 1},
	shorttitle = {Evaluation of severe accident risks},
	url = {https://www.osti.gov/biblio/140430},
	abstract = {NUREG-1150 examines the risk to the public from five nuclear power plants. The NUREG-1150 plant studies are Level III probabilistic risk assessments (PRAs) and, as such, they consist of four analysis components: accident frequency analysis, accident progression analysis, source term analysis, and consequence analysis. This volume summarizes the methods utilized in performing the last three components and the assembly of these analyses into an overall risk assessment. The NUREG-1150 analysis approach is based on the following ideas: (1) general and relatively fast-running models for the individual analysis components, (2) well-defined interfaces between the individual analysis components, (3) use of Monte Carlo techniques together with an efficient sampling procedure to propagate uncertainties, (4) use of expert panels to develop distributions for important phenomenological issues, and (5) automation of the overall analysis. Many features of the new analysis procedures were adopted to facilitate a comprehensive treatment of uncertainty in the complete risk analysis. Uncertainties in the accident frequency, accident progression and source term analyses were included in the overall uncertainty assessment. The uncertainties in the consequence analysis were not included in this assessment. A large effort was devoted to the development of procedures for obtaining expert opinion and the execution of these procedures to quantify parameters and phenomena for which there is large uncertainty and divergent opinions in the reactor safety community.},
	language = {English},
	number = {NUREG/CR-4551-Vol.1-Rev.1; SAND-86-1309-Vol.1-Rev.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Gorham, E. D. and Breeding, R. J. and Brown, T. D. and Harper, F. T. and Helton, J. C. and Murfin, W. B. and Hora, S. C.},
	month = dec,
	year = {1993},
	doi = {10.2172/140430},
}

@techreport{unwin_zion_1988,
	title = {The {Zion} integrated safety analysis for {NUREG}-1150},
	url = {https://www.osti.gov/biblio/6370758},
	abstract = {The utility-funded Zion Probabilistic Safety Study provided not only a detailed and thorough assessment of the risk profile of Zion Unit 1, but also presented substantial advancement in the technology of probabilistic risk assessment (PRA). Since performance of that study, modifications of plant hardware, the introduction of new emergency procedures, operational experience gained, information generated by severe accident research programs and further evolution of PRA and uncertainty analysis methods have provided a basis for reevaluation of the Zion risk profile. This reevaluation is discussed in this report. 5 refs.},
	language = {English},
	number = {BNL-NUREG-41418; CONF-890405-5},
	urldate = {2023-12-02},
	institution = {Brookhaven National Lab., Upton, NY (USA)},
	author = {Unwin, S. D. and Park, C. K.},
	month = jan,
	year = {1988},
}

@techreport{roesener_age-dependent_1989,
	title = {Age-dependent risk quantification using standard maintenance records},
	url = {https://www.osti.gov/biblio/6990548},
	abstract = {The risk associated with the operation of many individual nuclear power plants has been calculated using Probabilistic Risk Assessment (PRA) techniques. To date, PRA calculations have used time-averaged unreliabilities and unavailabilities as inputs such that the calculated risks are a time-average and say nothing of the risk trends. The calculation of an age-dependent risk is a fairly simple matter given the age-dependent inputs. The development of valid age-dependents inputs is not such a simple matter. It involves the reduction of large masses of information, which were not recorded for the purposes of PRA, into failure time-histories, and the representation of these time-histories by a model. The results must then be tested to check certain assumptions that are made when the model is applied to the data. The specific methodology developed for the reduction of the information and the application and testing of the model is outlined in a stepwise fashion in this paper. Results of the application of the methodology to the Maintenance Records from the Auxiliary Feedwater (AFW) System of an older Pressurized Water Reactor (PWR) are used throughout the paper to demonstrate the methodology. In addition, a very brief discussion of the AFW system is presented to allow better understanding of the application. 6 refs., 7 figs., 4 tabs.},
	language = {English},
	number = {EGG-M-89191; CONF-8910363-1},
	urldate = {2023-12-02},
	institution = {EG and G Idaho, Inc., Idaho Falls, ID (United States)},
	author = {Roesener, W. S. and Wolford, A. J. and Atwood, C. L.},
	month = jan,
	year = {1989},
	doi = {10.1007/978-1-4899-2370-7_17},
}

@techreport{bohn_analysis_1990,
	title = {Analysis of core damage frequency: {Surry} {Power} {Station}, {Unit} 1 external events},
	shorttitle = {Analysis of core damage frequency},
	url = {https://www.osti.gov/biblio/6340434},
	abstract = {This report presents the analysis of external events (earthquakes, fires, floods, etc.) performed for the Surry Power Station as part of the USNRC-sponsored NUREG-1150 program. Both the internal and external events analyses make full use of recent insights and developments in risk assessment methods. In addition, the external event analyses make use of newly-developed simplified methods. As a first step, a screening analysis was performed which showed that all external events were negligible except for fires and seismic events. Subsequent detailed analysis of fires resulted in a total (mean) core damage frequency of 1.13E-5 per year. The seismic analysis resulted in a total (mean) core damage frequency of 1.16E-4 per year using hazard curves developed by Lawrence Livermore National Laboratory and 2.50E-5 per year using hazard curves developed by the Electric Power Research Institute. Uncertainty analyses were performed, and dominant components and sources of uncertainty were identified. 71 refs., 61 figs., 59 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.3-Rev.1-Pt.3; SAND-86-2084-Vol.3-Rev.1-Pt.3},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); EQE, Inc., San Francisco, CA (USA)},
	author = {Bohn, M. P. and Lambright, J. A. and Daniel, S. L. and Johnson, J. J. and Ravindra, M. K. and Hashimoto, P. O. and Mraz, M. J. and Tong, W. H.},
	month = dec,
	year = {1990},
	doi = {10.2172/6340434},
}

@techreport{payne_evaluation_1990,
	title = {Evaluation of severe accident risks, {Peach} {Bottom}, {Unit} 2: {Main} report},
	shorttitle = {Evaluation of severe accident risks, {Peach} {Bottom}, {Unit} 2},
	url = {https://www.osti.gov/biblio/6188992},
	abstract = {In support of the Nuclear Regulatory Commission's (NRC's) assessment of the risk from severe accidents at commercial nuclear power plants in the US reported NUREG-1150, the Severe Accident Risk Reduction Program (SARRP) has completed a revised calculation of the risk to the general public from severe accidents at the Peach Bottom Atomic Power Station, Unit 2. This power plant, located in southeastern Pennsylvania, is operated by the Philadelphia Electric Company. The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiated by events both internal and external to the power station were assessed. 39 refs., 174 figs., 133 tabs.},
	language = {English},
	number = {NUREG/CR-4551-Vol.4-Rev.1-Pt.1; SAND-86-1309-Vol.4-Rev.1-Pt.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Payne, A. C. and Breeding, R. J. and Jow, H. N. and Shiver, A. W. and Helton, J. C. and Smith, L. N.},
	month = dec,
	year = {1990},
	doi = {10.2172/6188992},
}

@techreport{brown_evaluation_1990,
	title = {Evaluation of severe accident risks, {Grand} {Gulf}, {Unit} 1: {Appendices}},
	shorttitle = {Evaluation of severe accident risks, {Grand} {Gulf}, {Unit} 1},
	url = {https://www.osti.gov/biblio/6189033},
	abstract = {In support of the Nuclear Regulatory Commission's (NRC's) assessment of the risk from severe accidents at commercial nuclear power plants in the US report in NUREG-1150, the Severe Accident Risk Reduction Program (SARRP) has completed a revised calculation of the risk to the general public from severe accidents at the Grand Gulf Nuclear Station, Unit 1. This power plant, located in Port Gibson, Mississippi, is operated by the System Energy Resources, Inc. (SERI). The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiated by events internal to the power plant was assessed. This document provides Appendices A through E for this report. Topics included are, respectively: supporting information for the accident progression analysis; supporting information for the source term analysis; supporting information for the consequence analysis; risk results; and sampling information.},
	language = {English},
	number = {NUREG/CR-4551-Vol.6-Rev.1-Pt.2; SAND-86-1309-Vol.6-Rev.1-Pt.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Brown, T. D. and Breeding, R. J. and Jow, H. N. and Higgins, S. J. and Shiver, A. W. and Helton, J. C. and Amos, C. N.},
	month = dec,
	year = {1990},
	doi = {10.2172/6189033},
}

@techreport{brown_evaluation_1990-1,
	title = {Evaluation of severe accident risks, {Grand} {Gulf}, {Unit} 1: {Main} report},
	shorttitle = {Evaluation of severe accident risks, {Grand} {Gulf}, {Unit} 1},
	url = {https://www.osti.gov/biblio/6120530},
	abstract = {In support of the Nuclear Regulatory Commission's (NRC's) assessment of the risk from severe accidents at commercial nuclear power plants in the US report in NUREG-1150, the Severe Accident Risk Reduction Program (SARRP) has completed a revised calculation of the risk to the general public from severe accidents at the Grand Gulf Nuclear Station, Unit 1. This power plant, located in Port Gibson, Mississippi, is operated by the System Energy Resources, Inc. (SERI). The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiated by events internal to the power plant was assessed. 42 refs., 51 figs., 52 tabs.},
	language = {English},
	number = {NUREG/CR-4551-Vol.6-Rev.1-Pt.1; SAND-86-1309-Vol.6-Rev.1-Pt.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Brown, T. D. and Breeding, R. J. and Jow, H. N. and Higgins, S. J. and Shiver, A. W. and Helton, J. C. and Amos, C. N.},
	month = dec,
	year = {1990},
	doi = {10.2172/6120530},
}

@techreport{kolaczkowski_analysis_1989,
	title = {Analysis of core damage frequency: {Peach} {Bottom}, {Unit} 2 internal events appendices},
	shorttitle = {Analysis of core damage frequency},
	url = {https://www.osti.gov/biblio/5740811},
	abstract = {This document contains the appendices for the accident sequence analysis of internally initiated events for the Peach Bottom, Unit 2 Nuclear Power Plant. This is one of the five plant analyses conducted as part of the NUREG-1150 effort for the Nuclear Regulatory Commission. The work performed and described here is an extensive reanalysis of that published in October 1986 as NUREG/CR-4550, Volume 4. It addresses comments from numerous reviewers and significant changes to the plant systems and procedures made since the first report. The uncertainty analysis and presentation of results are also much improved, and considerable effort was expended on an improved analysis of loss of offsite power. The content and detail of this report is directed toward PRA practitioners who need to know how the work was done and the details for use in further studies. The mean core damage frequency is 4.5E-6 with 5\% and 95\% uncertainty bounds of 3.5E-7 and 1.3E-5, respectively. Station blackout type accidents (loss of all ac power) contributed about 46\% of the core damage frequency with Anticipated Transient Without Scram (ATWS) accidents contributing another 42\%. The numerical results are driven by loss of offsite power, transients with the power conversion system initially available operator errors, and mechanical failure to scram. 13 refs., 345 figs., 171 tabs.},
	language = {English},
	number = {NUREG/CR-4550-Vol.4-Rev.1-Pt.2; SAND-86-2084-Vol.4-Rev.1-Pt.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Kolaczkowski, A. M. and Cramond, W. R. and Sype, T. T. and Maloney, K. J. and Wheeler, T. A. and Daniel, S. L.},
	month = aug,
	year = {1989},
	doi = {10.2172/5740811},
}

@techreport{breeding_evaluation_1992,
	title = {Evaluation of severe accident risks: {Quantification} of major input parameters},
	shorttitle = {Evaluation of severe accident risks},
	url = {https://www.osti.gov/biblio/5759468},
	abstract = {In support of the Nuclear Regulatory Commission's (NRC's) assessment of the risk from severe accidents at commercial nuclear power plants in the US reported in NUREG-1150, the Severe Accident Risk Reduction Program (SAARP) has completed a revised calculation of the risk to the general public from severe accidents at five nuclear power plants: Surry, Sequoyah, Zion, Peach Bottom, and Grand Gulf. The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiation by events, both internal to the power station and external to the power station were assessed. Much of the important input to the logic models was generated by expert panels. This document presents the distributions and the rationale supporting the distributions for the questions posed to the Structural Response Panel.},
	language = {English},
	number = {NUREG/CR-4551-Vol.2-Rev.1-Pt.3; SAND-86-1309-Vol.2-Rev.1-Pt.3},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Sandia National Labs., Albuquerque, NM (United States)},
	author = {Breeding, R. J. and Harper, F. T. and Brown, T. D. and Gregory, J. J. and Payne, A. C. and Gorham, E. D. and Murfin, W. and Amos, C. N.},
	month = mar,
	year = {1992},
}

@techreport{benjamin_evaluation_1987,
	title = {Evaluation of severe accident risks and the potential for risk reduction: {Surry} {Power} {Station}, {Unit} 1: {Draft} report for comment},
	shorttitle = {Evaluation of severe accident risks and the potential for risk reduction},
	url = {https://www.osti.gov/biblio/6658846},
	abstract = {The Severe Accident Risk Reduction Program (SARRP) has completed a rebaselining of the risks to the public from a particular pressurized water reactor with a subatmospheric containment (Surry, Unit 1). Emphasis was placed on determining the magnitude and character of the uncertainties, rather than focusing on a point estimate. The risk-reduction potential of a set of proposed safety option backfits was also studied, and their costs and benefits were also evaluated. It was found that the risks from internal events are generally lower than previously evaluated in the Reactor Safety Study (RSS). However, certain unresolved issues (such as direct containment heating) caused the top of the uncertainty band to appear at a level that is comparable with the RSS point estimate. None of the postulated safety options appears to be cost effective for the Surry power plant. This work supports the Nuclear Regulatory Commission's assessment of severe accidents in NUREG-1150.},
	language = {English},
	number = {NUREG/CR-4551-Vol.1; SAND-86-1309-Vol.1},
	urldate = {2023-12-02},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor Systems Safety},
	author = {Benjamin, A. S. and Boyd, G. J. and Kunsman, D. M. and Murfin, W. B. and Williams, D. C.},
	month = feb,
	year = {1987},
	doi = {10.2172/6658846},
}

@techreport{sprung_evaluation_1990,
	title = {Evaluation of severe accident risks: {Quantification} of major input parameters: {MAACS} ({MELCOR} {Accident} {Consequence} {Code} {System}) input},
	shorttitle = {Evaluation of severe accident risks},
	url = {https://www.osti.gov/biblio/6360728},
	abstract = {Estimation of offsite accident consequences is the customary final step in a probabilistic assessment of the risks of severe nuclear reactor accidents. Recently, the Nuclear Regulatory Commission reassessed the risks of severe accidents at five US power reactors (NUREG-1150). Offsite accident consequences for NUREG-1150 source terms were estimated using the MELCOR Accident Consequence Code System (MACCS). Before these calculations were performed, most MACCS input parameters were reviewed, and for each parameter reviewed, a best-estimate value was recommended. This report presents the results of these reviews. Specifically, recommended values and the basis for their selection are presented for MACCS atmospheric and biospheric transport, emergency response, food pathway, and economic input parameters. Dose conversion factors and health effect parameters are not reviewed in this report. 134 refs., 15 figs., 110 tabs.},
	language = {English},
	number = {NUREG/CR-4551-Vol.2-Rev.1-Pt.7; SAND-86-1309-Vol.2-Rev.1-Pt.7},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Sprung, J. L. and Jow, H.-N. and Rollstin, J. A. and Helton, J. C.},
	month = dec,
	year = {1990},
	doi = {10.2172/6360728},
}

@techreport{payne_evaluation_1990-1,
	title = {Evaluation of severe accident risks, {Peach} {Bottom}, {Unit} 2: {Appendices}},
	shorttitle = {Evaluation of severe accident risks, {Peach} {Bottom}, {Unit} 2},
	url = {https://www.osti.gov/biblio/6120351},
	abstract = {In support of the Nuclear Regulatory Commission's (NRC's) assessment of the risk from severe accidents at commercial nuclear power plants in the US reported in NUREG-1150, the Severe Accident Risk Reduction Program (SARRP) has completed a revised calculation of the risk to the general public from severe accidents at the Peach Bottom Atomic Power Station, Unit 2. This power plant, located in southeastern Pennsylvania, is operated by the Philadelphia Electric Company. The emphasis in this risk analysis was not on determining a so-called'' point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiated by events both internal and external to the power station were assessed. This document provides Appendices A through E which include the following topics respectively: accident progression event tree; supporting information for the source term analysis; supporting information for the consequence analysis; risk results; and sampling information. 6 figs., 6 tabs.},
	language = {English},
	number = {NUREG/CR-4551-Vol.4-Rev.1-Pt.2; SAND-86-1309-Vol.4-Rev.1-Pt.2},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Payne, A. C. and Breeding, R. J. and Jow, H. N. and Shiver, A. W. and Helton, J. C. and Smith, L. N.},
	month = dec,
	year = {1990},
	doi = {10.2172/6120351},
}

@techreport{siu_loss_1996,
	title = {Loss of spent fuel pool cooling {PRA}: {Model} and results},
	shorttitle = {Loss of spent fuel pool cooling {PRA}},
	url = {https://www.osti.gov/biblio/578718},
	abstract = {This letter report documents models for quantifying the likelihood of loss of spent fuel pool cooling; models for identifying post-boiling scenarios that lead to core damage; qualitative and quantitative results generated for a selected plant that account for plant design and operational practices; a comparison of these results and those generated from earlier studies; and a review of available data on spent fuel pool accidents. The results of this study show that for a representative two-unit boiling water reactor, the annual probability of spent fuel pool boiling is 5 \{times\} 10\{sup \{minus\}5\} and the annual probability of flooding associated with loss of spent fuel pool cooling scenarios is 1 \{times\} 10\{sup \{minus\}3\}. Qualitative arguments are provided to show that the likelihood of core damage due to spent fuel pool boiling accidents is low for most US commercial nuclear power plants. It is also shown that, depending on the design characteristics of a given plant, the likelihood of either: (a) core damage due to spent fuel pool-associated flooding, or (b) spent fuel damage due to pool dryout, may not be negligible.},
	language = {English},
	number = {INEL-96/0334},
	urldate = {2023-12-02},
	institution = {Lockheed Idaho Technologies Co., Idaho Falls, ID (United States)},
	author = {Siu, N. and Khericha, S. and Conroy, S. and Beck, S. and Blackman, H.},
	month = sep,
	year = {1996},
	doi = {10.2172/578718},
}

@techreport{bley_nrc_1998,
	title = {{NRC} support for the {Kalinin} ({VVER}) probabilistic risk assessment},
	url = {https://www.osti.gov/biblio/353178},
	abstract = {The US Nuclear Regulatory Commission (NRC) and the Federal Nuclear and Radiation Safety Authority of the Russian Federation have been working together since 1994 to carry out a probabilistic risk assessment (PRA) of a VVER-1000 in the Russian Federation. This was a recognition by both parties that this technology has had a profound effect on the discipline of nuclear reactor safety in the West and that the technology should be transferred to others so that it can be applied to Soviet-designed plants. The NRC provided funds from the Agency for International Development and technical support primarily through Brookhaven National Laboratory and its subcontractors. The latter support was carried out through workshops, by documenting the methodology to be used in a set of guides, and through periodic review of the technical activity. The result of this effort to date includes a set of procedure guides, a draft final report on the Level 1 PRA for internal events (excluding internal fires and floods), and progress reports on the fire, flood, and seismic analysis. It is the authors belief that the type of assistance provided by the NRC has been instrumental in assuring a quality product and transferring important technology for use by regulators and operators of Soviet-designed reactors. After a thorough review, the report will be finalized, lessons learned will be applied in the regulatory and operational regimes in the Russian Federation, and consideration will be given to supporting a containment analysis in order to complete a simplified Level 2 PRA.},
	language = {English},
	number = {BNL-NUREG-66229; CONF-9810144-},
	urldate = {2023-12-02},
	institution = {Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Bley, D. and Diamond, D. J. and Chu, T. L. and Azarm, A. and Pratt, W. T. and Johnson, D. and Szukiewicz, A. and Drouin, M. and El-Bassioni, A. and Su, T. M.},
	month = dec,
	year = {1998},
}

@techreport{haskin_perspectives_1997,
	title = {Perspectives on reactor safety. {Revision} 1},
	url = {https://www.osti.gov/biblio/569128},
	abstract = {The US Nuclear Regulatory Commission (NRC) maintains a technical training center at Chattanooga, Tennessee to provide appropriate training to both new and experienced NRC employees. This document describes a one-week course in reactor safety concepts. The course consists of five modules: (1) the development of safety concepts; (2) severe accident perspectives; (3) accident progression in the reactor vessel; (4) containment characteristics and design bases; and (5) source terms and offsite consequences. The course text is accompanied by slides and videos during the actual presentation of the course.},
	language = {English},
	number = {NUREG/CR-6042-Rev.1; SAND-93-0971-Rev.1},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Technical Training Div.; New Mexico Univ., Albuquerque, NM (United States). Dept. of Chemical and Nuclear Engineering; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Oak Ridge National Lab. (ORNL), Oak Ridge, TN (United States)},
	author = {Haskin, F. E. and Camp, A. L. and Hodge, S. A.},
	month = nov,
	year = {1997},
	doi = {10.2172/569128},
}

@techreport{lui_accident_1997,
	title = {Accident sequence precursor analysis level 2/3 model development},
	url = {https://www.osti.gov/biblio/467929},
	abstract = {The US Nuclear Regulatory Commission`s Accident Sequence Precursor (ASP) program currently uses simple Level 1 models to assess the conditional core damage probability for operational events occurring in commercial nuclear power plants (NPP). Since not all accident sequences leading to core damage will result in the same radiological consequences, it is necessary to develop simple Level 2/3 models that can be used to analyze the response of the NPP containment structure in the context of a core damage accident, estimate the magnitude of the resulting radioactive releases to the environment, and calculate the consequences associated with these releases. The simple Level 2/3 model development work was initiated in 1995, and several prototype models have been completed. Once developed, these simple Level 2/3 models are linked to the simple Level 1 models to provide risk perspectives for operational events. This paper describes the methods implemented for the development of these simple Level 2/3 ASP models, and the linkage process to the existing Level 1 models.},
	language = {English},
	number = {NUREG/CP-0157-Vol.3; CONF-9610202-Vol.3},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Office of Nuclear Regulatory Research; Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Lui, C. H. and Galyean, W. J. and Brownson, D. A.},
	month = feb,
	year = {1997},
}

@techreport{barriere_multidisciplinary_1995,
	title = {Multidisciplinary framework for human reliability analysis with an application to errors of commission and dependencies},
	url = {https://www.osti.gov/biblio/106594},
	abstract = {Since the early 1970s, human reliability analysis (HRA) has been considered to be an integral part of probabilistic risk assessments (PRAs). Nuclear power plant (NPP) events, from Three Mile Island through the mid-1980s, showed the importance of human performance to NPP risk. Recent events demonstrate that human performance continues to be a dominant source of risk. In light of these observations, the current limitations of existing HRA approaches become apparent when the role of humans is examined explicitly in the context of real NPP events. The development of new or improved HRA methodologies to more realistically represent human performance is recognized by the Nuclear Regulatory Commission (NRC) as a necessary means to increase the utility of PRAS. To accomplish this objective, an Improved HRA Project, sponsored by the NRC`s Office of Nuclear Regulatory Research (RES), was initiated in late February, 1992, at Brookhaven National Laboratory (BNL) to develop an improved method for HRA that more realistically assesses the human contribution to plant risk and can be fully integrated with PRA. This report describes the research efforts including the development of a multidisciplinary HRA framework, the characterization and representation of errors of commission, and an approach for addressing human dependencies. The implications of the research and necessary requirements for further development also are discussed.},
	language = {English},
	number = {NUREG/CR-6265; BNL-NUREG-52431},
	urldate = {2023-12-02},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Div. of Systems Technology; Brookhaven National Lab. (BNL), Upton, NY (United States); Wreathall (John) and Co., Dublin, OH (United States); Science Applications International Corp., Reston, VA (United States); PLG, Inc., Newport Beach, CA (United States)},
	author = {Barriere, M. T. and Luckas, W. J. and Wreathall, J. and Cooper, S. E. and Bley, D. C. and Ramey-Smith, A.},
	month = aug,
	year = {1995},
	doi = {10.2172/106594},
}

@techreport{iman_pramis_1990,
	title = {{PRAMIS}: {Probabilistic} {Risk} {Assessment} {Model} {Integration} {System}},
	shorttitle = {{PRAMIS}},
	url = {https://www.osti.gov/biblio/6927792},
	abstract = {This document has been designed for users of the Probabilistic Risk Assessment Model Integration System (PRAMIS) computer developed by the authors at Sandia National Laboratories for easy assembly of the individual parts of the NUREG-1150 plant analyses into overall risk results. PRAMIS assembles the following files associated with the NUREG-1150 analyses in matrix format to obtain risk: the Latin hypercube sample, the results of the systems analysis, the results of the accident progression analysis, the results of the source term/partitioning analysis, and the results of the consequence analysis. In addition, various intermediate and conditional quantities are calculated when requested by user-specified input; the fractional contribution to risk of individual plant damage states, accident progression bins and source term groups are determined, and a file containing the original Latin hypercube sample and user-specified dependent variables is generated for use as input to the SAS statistical package. This report provides a tutorial that details how to use the PRAMIS program. The PRAMIS program is written in ANSI standard FORTRAN 77 to make the code as machine-independent as possible.},
	language = {English},
	number = {NUREG/CR-5262; SAND-88-3093},
	urldate = {2023-12-02},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Iman, R. L. and Johnson, J. D. and Helton, J. C.},
	month = may,
	year = {1990},
	doi = {10.2172/6927792},
}

@inproceedings{wei-ping_using_2011,
	title = {Using {MongoDB} to implement textbook management system instead of {MySQL}},
	url = {https://ieeexplore.ieee.org/abstract/document/6013720},
	doi = {10.1109/ICCSN.2011.6013720},
	abstract = {With the development of Internet Web2.0 technology, the traditional relational database is widely used in information management system. However, it is not effective, when we need to query a wide range of massive data, especially with multi-table join queries. Now, a kind of new technology emerged - NoSQL, which is non-relational database management system with format loose data storage, not support the join operation, the effective query capability etc advantages. This paper attempts to use NoSQL database to replace the relational database, applied to traditional information management systems, compare the two database technologies, give the key code of NoSQL implementation, and finally list the performance comparison of two schemes.},
	urldate = {2023-12-07},
	booktitle = {2011 {IEEE} 3rd {International} {Conference} on {Communication} {Software} and {Networks}},
	author = {Wei-ping, Zhu and Ming-xin, Li and Huan, Chen},
	month = may,
	year = {2011},
	pages = {303--305},
}

@techreport{chang_experimental_2018,
	title = {Experimental {Breeder} {Reactor} {II} ({EBR}-{II}) {Level} 1 {Probabilistic} {Risk} {Assessment}},
	url = {https://www.osti.gov/biblio/1483951-experimental-breeder-reactor-ii-ebr-ii-level-probabilistic-risk-assessment},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {ANL-NSE-2},
	urldate = {2021-09-09},
	institution = {Argonne National Lab. (ANL), Argonne, IL (United States)},
	author = {Chang, Yoon},
	month = oct,
	year = {2018},
	doi = {10.2172/1483951},
}

@book{committee_to_assess_safety_and_technical_issues_at_doe_reactors_safety_1988,
	address = {Washington, D.C.},
	title = {Safety {Issues} at the {DOE} {Test} and {Research} {Reactors}: {A} {Report} to the {U}.{S}. {Department} of {Energy}},
	isbn = {978-0-309-31901-0},
	shorttitle = {Safety {Issues} at the {DOE} {Test} and {Research} {Reactors}},
	url = {https://www.nap.edu/catalog/19106},
	language = {en},
	urldate = {2021-09-09},
	publisher = {National Academies Press},
	author = {{Committee to Assess Safety and Technical Issues at DOE Reactors} and {Commission on Physical Sciences, Mathematics, and Resources} and {Commission on Engineering and Technical Systems} and {National Research Council}},
	month = jan,
	year = {1988},
	doi = {10.17226/19106},
	note = {Pages: 19106},
}

@techreport{eide_advanced_1992,
	title = {Advanced {Test} {Reactor} probabilistic risk assessment methodology and results summary},
	url = {https://www.osti.gov/biblio/10138400-advanced-test-reactor-probabilistic-risk-assessment-methodology-results-summary},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {EGG-PRP-10024},
	urldate = {2021-09-09},
	institution = {EG and G Idaho, Inc., Idaho Falls, ID (United States)},
	author = {Eide, S. A. and Atkinson, S. A. and Thatcher, T. A.},
	month = jan,
	year = {1992},
	doi = {10.2172/10138400},
}

@techreport{roglans_applications_1993,
	title = {Applications of the {EBR}-{II} {Probabilistic} {Risk} {Assessment}},
	url = {https://www.osti.gov/biblio/10116824-applications-ebr-ii-probabilistic-risk-assessment},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {ANL/CP-75952},
	urldate = {2021-09-09},
	institution = {Argonne National Lab., IL (United States)},
	author = {Roglans, J. : Ragland and Hill, D. J.},
	month = dec,
	year = {1993},
	doi = {10.2172/10116824},
}

@techreport{roglans_experimental_1994,
	title = {The {Experimental} {Breeder} {Reactor} {II} seismic probabilistic risk assessment},
	url = {https://www.osti.gov/biblio/10124502-experimental-breeder-reactor-ii-seismic-probabilistic-risk-assessment},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {ANL/RA/CP-79972; CONF-940312-53},
	urldate = {2021-09-09},
	institution = {Argonne National Lab., IL (United States)},
	author = {Roglans, J. and Hill, D. J.},
	month = feb,
	year = {1994},
}

@techreport{armstrong_use_1988,
	title = {The use of {Probabilistic} {Risk} {Assessment} in the safety assessment of {Hanford} nuclear facilities},
	url = {https://www.osti.gov/biblio/6160735-use-probabilistic-risk-assessment-safety-assessment-hanford-nuclear-facilities},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WHC-SA-0481; CONF-890405-23},
	urldate = {2021-09-09},
	institution = {Westinghouse Hanford Co., Richland, WA (USA)},
	author = {Armstrong, G. R.},
	month = dec,
	year = {1988},
}

@techreport{heaberlin_united_1993,
	title = {United {States} experience in probabilistic risk assessment for a graphite moderated, channel reactor},
	url = {https://www.osti.gov/biblio/10176803-united-states-experience-probabilistic-risk-assessment-graphite-moderated-channel-reactor},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {PNL-SA-21788; CONF-9306189-3},
	urldate = {2021-09-09},
	institution = {Pacific Northwest Lab., Richland, WA (United States)},
	author = {Heaberlin, S. W. and Zentner, M. D.},
	month = jun,
	year = {1993},
}

@techreport{zentner_n_1990,
	title = {N reactor level 1 probabilistic risk assessment},
	url = {https://www.osti.gov/biblio/6954643-reactor-level-probabilistic-risk-assessment},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WHC-EP-0322},
	urldate = {2021-09-09},
	institution = {Westinghouse Hanford Co., Richland, WA (United States)},
	author = {Zentner, M. D. and Atkinson, J. K. and Carlson, P. A. and Coles, G. A. and Leitz, E. E. and Lindberg, S. E. and Powers, T. B. and Kelley, J. E.},
	month = may,
	year = {1990},
	doi = {10.2172/6954643},
}

@techreport{wang_doe_1990,
	title = {{DOE} safety goals comparison using {NUREG}-1150 {PRA} (probabilistic risk assessment) methodology},
	url = {https://www.osti.gov/biblio/6851795-doe-safety-goals-comparison-using-nureg-pra-probabilistic-risk-assessment-methodology},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WHC-SA-0822; CONF-900917-9},
	urldate = {2021-09-09},
	institution = {Westinghouse Hanford Co., Richland, WA (USA)},
	author = {Wang, O. S. and Zentner, M. D. and Rainey, T. E.},
	month = jun,
	year = {1990},
}

@techreport{bozoki_level_1994,
	title = {Level 1 {Tornado} {PRA} for the {High} {Flux} {Beam} {Reactor}},
	url = {https://www.osti.gov/biblio/48761-ZkXR6M/webviewable/},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {BNL-52456},
	urldate = {2021-09-09},
	institution = {Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Bozoki, G. E. and Conrad, C. S.},
	month = may,
	year = {1994},
	doi = {10.2172/48761},
}

@article{flanagan_probabilistic_1990,
	title = {Probabilistic risk assessment of the {High}-{Flux} {Isotope} {Reactor}},
	issn = {0003-018X},
	abstract = {The High-Flux Isotope Reactor (HFIR) is a high-performance isotope production and
research reactor, which has been in operation at Oak Ridge National Laboratory (ORNL)
since 1965 In late 1986, the reactor was shut down as a result of the discovery of
unexpected neutron embrittlement of the reactor vessel In January 1988, a level 1
Probabilistic Risk Assessment (PRA) (excluding external events) was published as part
of the response to the many reviews that followed the shutdown and for use by ORNL
to prioritize action items intended to upgrade the safety of the reactor This was
followed by a draft external initiated events PRA in May 1989 The HFIR PRA represented
the first PRA of a major research reactor in the United States The core damage frequencies
from external events (fire, 1834 x 10-5/yr; wind, 301 x 10-5/yr; seismic, 155 x 10-4/yr;
other, 181 x 10-6/yr) were combined with the total internal events' contribution,
resulting in an overall HFIR mean core damage frequency of 5 x 10-4/yr Several design,
administrative, and operational procedure changes are currently being pursued in order
to reduce the core damage frequency},
	journal = {Transactions of the American Nuclear Society},
	author = {Flanagan, G.F. and Johnson, D.H.},
	year = {1990},
	note = {Place: United States
INIS Reference Number: 22035067},
	pages = {231--233},
}

@article{azarm_high-flux_1991,
	title = {High-flux beam reactor {PRA}: {Level} 1, internal events},
	volume = {63},
	issn = {0003-018X},
	shorttitle = {High-flux beam reactor {PRA}},
	url = {https://www.osti.gov/biblio/7168339-high-flux-beam-reactor-pra-level-internal-events},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	urldate = {2021-09-09},
	journal = {Transactions of the American Nuclear Society; (United States)},
	author = {Azarm, M. A. and Bari, R. A. and Chu, T. L. and Oliveira, L.},
	month = jan,
	year = {1991},
	note = {Number: CONF-911107-},
}

@techreport{miller_n_1990,
	title = {N {Reactor} {Probabilistic} {Risk} {Assessment} supporting calculations},
	url = {https://www.osti.gov/biblio/6756475-reactor-probabilistic-risk-assessment-supporting-calculations},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {SAND-89-2101-Vol.1},
	urldate = {2021-09-09},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Miller, L. A. and Wyss, G. D. and Kunsman, D. M. and Dingman, S. E. and Boucheron, E. A. and Carmel, M. K. and Shaffer, C. J.},
	month = jun,
	year = {1990},
	doi = {10.2172/6756475},
}

@techreport{bailey_srs_1992,
	title = {{SRS} {K}-{Reactor} {PRA} {LOCA} analyses using best-estimate methods},
	url = {https://www.osti.gov/biblio/6659523},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WSRC-MS-92-386-Del.Ver.; CONF-930116-26-Del.Ver.},
	urldate = {2021-09-09},
	institution = {Westinghouse Savannah River Co., Aiken, SC (United States)},
	author = {Bailey, R. T. and Kalinich, D. A. and Chou, C. Y.},
	month = jan,
	year = {1992},
}

@article{mosleh_common_1991,
	title = {Common cause failures: {An} analysis methodology and examples},
	volume = {34},
	issn = {09518320},
	shorttitle = {Common cause failures},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209190104F},
	doi = {10.1016/0951-8320(91)90104-F},
	language = {en},
	number = {3},
	urldate = {2023-11-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Mosleh, Ali},
	month = jan,
	year = {1991},
	pages = {249--292},
}

@book{wymore_model-based_2018,
	edition = {1},
	title = {Model-{Based} {Systems} {Engineering}},
	isbn = {978-0-203-74693-6},
	url = {https://www.taylorfrancis.com/books/9781351431095},
	language = {en},
	urldate = {2023-11-28},
	publisher = {CRC Press},
	author = {Wymore, A. Wayne},
	month = may,
	year = {2018},
	doi = {10.1201/9780203746936},
}

@article{van_der_vorst_supply_1998,
	title = {Supply {Chain} {Management} in {Food} {Chains}: {Improving} {Performance} by {Reducing} {Uncertainty}},
	volume = {5},
	issn = {0969-6016, 1475-3995},
	shorttitle = {Supply {Chain} {Management} in {Food} {Chains}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1475-3995.1998.tb00131.x},
	doi = {10.1111/j.1475-3995.1998.tb00131.x},
	abstract = {This paper investigates the impact of Supply Chain Management on logistical performance indicators in food supply chains. From a review of quantitative and more qualitative managerial literature, we believe that Supply Chain Management should be concerned with the reduction or even elimination of uncertainties to improve the performance of the chain. The following clusters of sources of uncertainty are identified: order forecast horizon, input data, administrative and decision processes and inherent uncertainties. For each source of uncertainty, several improvement principles are identified. A case study was conducted in a food chain in which a simulation model helped quantify the effects of alternative configurations and operational management concepts. By comparing this simulation study with a pilot study, the model is validated against real data, and organisational consequences are identified. The results of the case study suggest that reduction of uncertainties can improve service levels significantly, although current supply chain configurations restrict possible benefits. The availability of real‐time information systems is found to be a requirement for obtaining efficient and effective Supply Chain Management concepts.},
	language = {en},
	number = {6},
	urldate = {2023-11-27},
	journal = {International Transactions in Operational Research},
	author = {Van Der Vorst, J.G.A.J. and Beulens, A.J.M. and De Wit, W. and Van Beek, P.},
	month = nov,
	year = {1998},
	pages = {487--499},
}

@article{schwabe_uncertainty_2015,
	title = {Uncertainty quantification metrics for whole product life cycle cost estimates in aerospace innovation},
	volume = {77},
	issn = {03760421},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0376042115000433},
	doi = {10.1016/j.paerosci.2015.06.002},
	abstract = {The lack of defensible methods for quantifying cost estimate uncertainty over the whole product life cycle of aerospace innovations such as propulsion systems or airframes poses a signiﬁcant challenge to the creation of accurate and defensible cost estimates. Based on the axiomatic deﬁnition of uncertainty as the actual prediction error of the cost estimate, this paper provides a comprehensive overview of metrics used for the uncertainty quantiﬁcation of cost estimates based on a literature review, an evaluation of publicly funded projects such as part of the CORDIS or Horizon 2020 programs, and an analysis of established approaches used by organizations such NASA, the U.S. Department of Defence, the ESA, and various commercial companies. The metrics are categorized based on their foundational character (foundations), their use in practice (state-of-practice), their availability for practice (state-of-art) and those suggested for future exploration (state-of-future). Insights gained were that a variety of uncertainty quantiﬁcation metrics exist whose suitability depends on the volatility of available relevant information, as deﬁned by technical and cost readiness level, and the number of whole product life cycle phases the estimate is intended to be valid for. Information volatility and number of whole product life cycle phases can hereby be considered as deﬁning multi-dimensional probability ﬁelds admitting various uncertainty quantiﬁcation metric families with identiﬁable thresholds for transitioning between them. The key research gaps identiﬁed were the lacking guidance grounded in theory for the selection of uncertainty quantiﬁcation metrics and lacking practical alternatives to metrics based on the Central Limit Theorem. An innovative uncertainty quantiﬁcation framework consisting of; a set-theory based typology, a data library, a classiﬁcation system, and a corresponding input-output model are put forward to address this research gap as the basis for future work in this ﬁeld.},
	language = {en},
	urldate = {2023-11-27},
	journal = {Progress in Aerospace Sciences},
	author = {Schwabe, O. and Shehab, E. and Erkoyuncu, J.},
	month = aug,
	year = {2015},
	pages = {1--24},
}

@article{liagkouras_sources_2023,
	title = {Sources of {Uncertainty} and {Risk} {Quantification} {Methods} in {Supply} {Chain} {Management}: {A} {Literature} {Study}},
	volume = {4},
	issn = {2662-2556},
	shorttitle = {Sources of {Uncertainty} and {Risk} {Quantification} {Methods} in {Supply} {Chain} {Management}},
	url = {https://link.springer.com/10.1007/s43069-023-00275-8},
	doi = {10.1007/s43069-023-00275-8},
	abstract = {Modern supply chain networks operate in an increasingly unstable business and geopolitical environment alike. Nowadays, supply chains are not only threatened by traditional sources of uncertainty that are related to the geographically dispersed nature of their operations but also by new sources of uncertainty that arise from the geopolitical unrest caused by Russia’s invasion of Ukraine, climate change, and an unstable economic environment that is further deteriorated by the increase in oil prices and food commodity prices. Furthermore, pandemics such as coronavirus cause panic buying and pose a serious threat not only to global health but also to supply chain networks around the world, forcing businesses to reassess their business model. At the same time, we witness an escalated trade war in the form of tariffs and import quotas between USA and China. But, while numerous studies have explored some of the aforementioned challenges, what is missing from the current literature is a systematic and holistic approach to understand and mitigate the uncertainties that are caused by an unstable business and geopolitical environment. This study covers this gap by providing a literature study that intends to examine the various challenges that are facing the modern supply chain networks in an integrated way.},
	language = {en},
	number = {4},
	urldate = {2023-11-27},
	journal = {Operations Research Forum},
	author = {Liagkouras, Konstantinos and Metaxiotis, Konstantinos},
	month = nov,
	year = {2023},
	pages = {90},
}

@article{nguyen_operational_2021,
	title = {An {Operational} {Risk} {Analysis} {Model} for {Container} {Shipping} {Systems} considering {Uncertainty} {Quantification}},
	volume = {209},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832020308516},
	doi = {10.1016/j.ress.2020.107362},
	abstract = {Different uncertain factors obstruct the analysis of operational risks in container shipping, especially those rooted in the subjectivity of multiple risk assessments and their aggregation. This paper proposes a risk analysis model featuring a quantification of the uncertainty. Bayesian probability theory is employed to quantify the risk magnitude, while a dedicated module to handle uncertainty is enabled by Evidential Reasoning and a set of three uncertainty indicators, including expert ignorance, disagreement among experts, and polarization of their assessments. The situation of risk is diagnosed by risk ranking and visualized by risk mapping, using both Risk Magnitude Index and Uncertainty Index. The functionality of the proposed model in identifying critical and uncertain risks was demonstrated in an organizational-scale case study, followed by an examination of validity criteria and a sensitivity test. The case study reveals the physical flow as the dominant origin of high-ranking risks with po­ tential significant consequences such as piracy, dangerous cargoes, and maritime accidents; while information and financial operational risks are more uncertain, especially cargo misdeclaration and unexpected rises of fuel costs.},
	language = {en},
	urldate = {2023-11-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Nguyen, Son and Chen, Peggy Shu-Ling and Du, Yuquan and Thai, Vinh V.},
	month = may,
	year = {2021},
	pages = {107362},
}

@inproceedings{nannapaneni_uncertainty_2014,
	address = {Washington, DC, USA},
	title = {Uncertainty quantification in performance evaluation of manufacturing processes},
	isbn = {978-1-4799-5666-1},
	url = {http://ieeexplore.ieee.org/document/7004333/},
	doi = {10.1109/BigData.2014.7004333},
	abstract = {This paper proposes a systematic framework using Bayesian networks to integrate all the available information for uncertainty quantification (UQ) in the performance evaluation of a manufacturing process. Energy consumption, one of the key metrics of sustainability, is used to illustrate the proposed methodology. The evaluation of energy consumption is not straight-forward due to the presence of uncertainties in different variables in the process and occurring at different stages in the process. Both aleatory and epistemic sources of uncertainty are considered in the UQ methodology. A dimension reduction approach through variance-based global sensitivity analysis is proposed to reduce the number of variables in the system and facilitate scalability to highdimensional problems. The proposed methodologies for uncertainty quantification and dimension reduction are demonstrated using two examples – an injection molding process and a welding process.},
	language = {en},
	urldate = {2023-11-27},
	booktitle = {2014 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	publisher = {IEEE},
	author = {Nannapaneni, Saideep and Mahadevan, Sankaran},
	month = oct,
	year = {2014},
	pages = {996--1005},
}

@techreport{gerstner_marvel_2023,
	title = {{MARVEL} 90\% {Final} {Design} {Report}},
	url = {https://www.osti.gov/servlets/purl/2208844/},
	number = {INL/RPT-23-74280, 2208844},
	urldate = {2023-11-22},
	author = {Gerstner, Doug and Arafat, Yasir},
	month = sep,
	year = {2023},
	doi = {10.2172/2208844},
	pages = {INL/RPT--23--74280, 2208844},
}

@techreport{patterson_marvel_2023,
	title = {{MARVEL} {Hazard} {Evaluation} {ECAR}-6440},
	url = {https://www.osti.gov/servlets/purl/2205226/},
	number = {INL/MIS-23-75407-Rev000, 2205226},
	urldate = {2023-11-22},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Patterson, Mw},
	month = sep,
	year = {2023},
	doi = {10.2172/2205226},
	pages = {INL/MIS--23--75407--Rev000, 2205226},
}

@techreport{patterson_safety_2021,
	title = {Safety {Design} {Strategy} for the {Microreactor} {Applications} {Research} {Validation} and {Evaluation} ({MARVEL}) {Project} {SDS}-119},
	url = {https://www.osti.gov/biblio/2205230},
	number = {INL/MIS-23-75411-Rev000, 2205230},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Patterson, MW},
	month = dec,
	year = {2021},
}

@techreport{evans_marvel_2023,
	type = {S\&{T} {Accomplishment} {Report}},
	title = {{MARVEL} {Reactor} {Fuel} {Performance} {Report}},
	url = {https://www.osti.gov/biblio/2000862},
	number = {INL/RPT-22-68555-Rev001, 2000862},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Evans, Jordan Andrew and Keiser Jr, Dennis D},
	month = sep,
	year = {2023},
}

@article{kennedy_bayesian_2001,
	title = {Bayesian {Calibration} of {Computer} {Models}},
	volume = {63},
	issn = {1369-7412, 1467-9868},
	url = {https://academic.oup.com/jrsssb/article/63/3/425/7083367},
	doi = {10.1111/1467-9868.00294},
	abstract = {We consider prediction and uncertainty analysis for systems which are approximated using complex mathematical models. Such models, implemented as computer codes, are often generic in the sense that by a suitable choice of some of the model's input parameters the code can be used to predict the behaviour of the system in a variety of speci®c applications. However, in any speci®c application the values of necessary parameters may be unknown. In this case, physical observations of the system in the speci®c context are used to learn about the unknown parameters. The process of ®tting the model to the observed data by adjusting the parameters is known as calibration. Calibration is typically effected by ad hoc ®tting, and after calibration the model is used, with the ®tted input values, to predict the future behaviour of the system. We present a Bayesian calibration technique which improves on this traditional approach in two respects. First, the predictions allow for all sources of uncertainty, including the remaining uncertainty over the ®tted parameters. Second, they attempt to correct for any inadequacy of the model which is revealed by a discrepancy between the observed data and the model predictions from even the best-®tting parameter values. The method is illustrated by using data from a nuclear radiation release at Tomsk, and from a more complex simulated nuclear accident exercise.},
	language = {en},
	number = {3},
	urldate = {2023-11-20},
	journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
	author = {Kennedy, Marc C. and O'Hagan, Anthony},
	month = sep,
	year = {2001},
	pages = {425--464},
}

@article{shrestha_inverse_2016,
	title = {Inverse uncertainty quantification of input model parameters for thermal-hydraulics simulations using expectation–maximization under {Bayesian} framework},
	volume = {43},
	issn = {0266-4763, 1360-0532},
	url = {http://www.tandfonline.com/doi/full/10.1080/02664763.2015.1089220},
	doi = {10.1080/02664763.2015.1089220},
	language = {en},
	number = {6},
	urldate = {2023-11-20},
	journal = {Journal of Applied Statistics},
	author = {Shrestha, Rijan and Kozlowski, Tomasz},
	month = apr,
	year = {2016},
	pages = {1011--1026},
}

@article{kang_development_2018,
	title = {Development of a {Bayesian} belief network model for software reliability quantification of digital protection systems in nuclear power plants},
	volume = {120},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454918302299},
	doi = {10.1016/j.anucene.2018.04.045},
	abstract = {As the instrumentation and control (I\&C) systems in nuclear power plants (NPPs) have been replaced with digital-based systems, the need has emerged to not only establish a basis for incorporating software behavior into digital I\&C system reliability models, but also to quantify the software reliability used in NPP digital protection systems. Therefore, a Bayesian belief network (BBN) model which estimates the number of faults in a software considering its software development life cycle (SDLC) is developed in this study. The model structure and parameters are established based on the information applicable to safetyrelated systems and expert elicitation. The evidence used in the model was collected from three stages of expert elicitation. To assess the feasibility of using BBN in NPP digital protection software reliability quantiﬁcation, the BBN model was applied to the Integrated Digital Protection System–Reactor Protection System and estimated the number of defects at each SDLC phase and further assessed the software failure probability. The developed BBN model can be employed to estimate the reliability of deployed safety-related NPP software and such results can be used to evaluate the quality of the digital I\&C systems in addition to estimating the potential reactor risk due to software failure.},
	language = {en},
	urldate = {2023-11-15},
	journal = {Annals of Nuclear Energy},
	author = {Kang, Hyun Gook and Lee, Sang Hun and Lee, Seung Jun and Chu, Tsong-Lun and Varuttamaseni, Athi and Yue, Meng and Yang, Steve and Eom, Heung Seop and Cho, Jaehyun and Li, Ming},
	month = oct,
	year = {2018},
	pages = {62--73},
}

@article{kang_development_2018-1,
	title = {Development of a {Bayesian} belief network model for software reliability quantification of digital protection systems in nuclear power plants},
	volume = {120},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454918302299},
	doi = {10.1016/j.anucene.2018.04.045},
	abstract = {As the instrumentation and control (I\&C) systems in nuclear power plants (NPPs) have been replaced with digital-based systems, the need has emerged to not only establish a basis for incorporating software behavior into digital I\&C system reliability models, but also to quantify the software reliability used in NPP digital protection systems. Therefore, a Bayesian belief network (BBN) model which estimates the number of faults in a software considering its software development life cycle (SDLC) is developed in this study. The model structure and parameters are established based on the information applicable to safetyrelated systems and expert elicitation. The evidence used in the model was collected from three stages of expert elicitation. To assess the feasibility of using BBN in NPP digital protection software reliability quantiﬁcation, the BBN model was applied to the Integrated Digital Protection System–Reactor Protection System and estimated the number of defects at each SDLC phase and further assessed the software failure probability. The developed BBN model can be employed to estimate the reliability of deployed safety-related NPP software and such results can be used to evaluate the quality of the digital I\&C systems in addition to estimating the potential reactor risk due to software failure.},
	language = {en},
	urldate = {2023-11-15},
	journal = {Annals of Nuclear Energy},
	author = {Kang, Hyun Gook and Lee, Sang Hun and Lee, Seung Jun and Chu, Tsong-Lun and Varuttamaseni, Athi and Yue, Meng and Yang, Steve and Eom, Heung Seop and Cho, Jaehyun and Li, Ming},
	month = oct,
	year = {2018},
	pages = {62--73},
}

@article{wu_comprehensive_2021,
	title = {A comprehensive survey of inverse uncertainty quantification of physical model parameters in nuclear system thermal–hydraulics codes},
	volume = {384},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002954932100412X},
	doi = {10.1016/j.nucengdes.2021.111460},
	abstract = {Uncertainty Quantification (UQ) is an essential step in computational model validation because assessment of the model accuracy requires a concrete, quantifiable measure of uncertainty in the model predictions. The concept of UQ in the nuclear community generally means forward UQ, in which the information flow is from the inputs to the outputs. Inverse UQ, in which the information flow is from the model outputs and experimental data to the inputs, is an equally important component of UQ but has been significantly underrated until recently. Forward UQ requires knowledge in the input uncertainties which has been specified by expert opinion or user selfevaluation. Inverse UQ is defined as the process to inversely quantify the input uncertainties based on experi­ mental data.},
	language = {en},
	urldate = {2023-11-13},
	journal = {Nuclear Engineering and Design},
	author = {Wu, Xu and Xie, Ziyu and Alsafadi, Farah and Kozlowski, Tomasz},
	month = dec,
	year = {2021},
	pages = {111460},
}

@misc{noauthor_risk-informed_nodate,
	title = {Risk-{Informed} {Assessment} of {Degraded} {Containment} {Vessels} ({NUREG}/{CR}-6920)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6920/index.html},
	language = {en-US},
	urldate = {2023-11-10},
	journal = {NRC Web},
}

@article{chae_optimization_2021,
	title = {Optimization of binary decision diagram: {Heuristics} from reinforcement learning},
	author = {Chae, Young Ho and Seong, Poong Hyun},
	year = {2021},
}

@article{cappart_improving_2019,
	title = {Improving {Optimization} {Bounds} {Using} {Machine} {Learning}: {Decision} {Diagrams} {Meet} {Deep} {Reinforcement} {Learning}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Improving {Optimization} {Bounds} {Using} {Machine} {Learning}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/3956},
	doi = {10.1609/aaai.v33i01.33011443},
	abstract = {Finding tight bounds on the optimal solution is a critical element of practical solution methods for discrete optimization problems. In the last decade, decision diagrams (DDs) have brought a new perspective on obtaining upper and lower bounds that can be significantly better than classical bounding mechanisms, such as linear relaxations. It is well known that the quality of the bounds achieved through this flexible bounding method is highly reliant on the ordering of variables chosen for building the diagram, and finding an ordering that optimizes standard metrics is an NP-hard problem. In this paper, we propose an innovative and generic approach based on deep reinforcement learning for obtaining an ordering for tightening the bounds obtained with relaxed and restricted DDs. We apply the approach to both the Maximum Independent Set Problem and the Maximum Cut Problem. Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known. To the best knowledge of the authors, this is the first paper to apply machine learning to directly improve relaxation bounds obtained by general-purpose bounding mechanisms for combinatorial optimization problems.},
	number = {01},
	urldate = {2023-11-06},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Cappart, Quentin and Goutierre, Emmanuel and Bergman, David and Rousseau, Louis-Martin},
	month = jul,
	year = {2019},
	pages = {1443--1451},
}

@article{patel_leo_2023,
	title = {{LEO}: {Learning} {Efficient} {Orderings} for {Multiobjective} {Binary} {Decision} {Diagrams}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {{LEO}},
	url = {https://arxiv.org/abs/2307.03171},
	doi = {10.48550/ARXIV.2307.03171},
	abstract = {Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time. However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering. To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time. Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is {\textasciitilde}30-300\% and {\textasciitilde}10-200\% faster at PF enumeration than common ordering strategies and algorithm configuration. Our code and instances are available at https://github.com/khalil-research/leo.},
	urldate = {2023-11-06},
	author = {Patel, Rahul and Khalil, Elias B.},
	year = {2023},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
}

@incollection{stuckey_improving_2021,
	address = {Cham},
	title = {Improving {Branch}-and-{Bound} {Using} {Decision} {Diagrams} and {Reinforcement} {Learning}},
	volume = {12735},
	isbn = {978-3-030-78229-0 978-3-030-78230-6},
	url = {https://link.springer.com/10.1007/978-3-030-78230-6_28},
	language = {en},
	urldate = {2023-11-06},
	booktitle = {Integration of {Constraint} {Programming}, {Artificial} {Intelligence}, and {Operations} {Research}},
	publisher = {Springer International Publishing},
	author = {Parjadis, Augustin and Cappart, Quentin and Rousseau, Louis-Martin and Bergman, David},
	editor = {Stuckey, Peter J.},
	year = {2021},
	doi = {10.1007/978-3-030-78230-6_28},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {446--455},
}

@article{cappart_improving_2022,
	title = {Improving {Variable} {Orderings} of {Approximate} {Decision} {Diagrams} {Using} {Reinforcement} {Learning}},
	volume = {34},
	issn = {1091-9856, 1526-5528},
	url = {https://pubsonline.informs.org/doi/10.1287/ijoc.2022.1194},
	doi = {10.1287/ijoc.2022.1194},
	abstract = {Prescriptive analytics provides organizations with scalable solutions for large-scale, automated decision making. At the core of prescriptive analytics methodology is optimization, a field devoted to the study of algorithms that solve complex decision-making problems. Optimization algorithms rely heavily on generic methods for identifying tight bounds, which provide both solutions to problems and optimality guarantees. In the last decade, decision diagrams (DDs) have demonstrated significant advantages in obtaining bounds compared with the standard linear relaxation commonly used by commercial solvers. However, the quality of the bounds computed by DDs depends heavily on the variable ordering chosen for the construction. Besides, the problem of finding an ordering that optimizes a given metric is generally NP-hard. This paper studies how machine learning, specifically deep reinforcement learning (DRL), can be used to improve bounds provided by DDs, in particular through learning a good variable ordering. The introduced DRL models improve primal and dual bounds, even over standard linear programming relaxations, and are integrated in a full-fledged branch-and-bound algorithm. This paper, therefore, provides a novel mechanism for utilizing machine learning to tighten bounds, adding to recent research on using machine learning to obtain high-quality heuristic solutions and, for the first time, using machine learning to improve relaxation bounds through a generic bounding method. We apply the methods on a classic optimization problem, the maximum independent set, and demonstrate through computational testing that optimization bounds can be significantly improved through DRL. We provide the code to replicate the results obtained on the maximum independent set.
            Summary of Contribution: This paper studies the use of reinforcement learning to compute a variable ordering of decision diagram-based approximations for discrete optimization problems. This is among the first works to propose the use of machine learning to improve upon generic bounding methods for discrete optimization problems, thereby establishing a critical bridge between optimization and learning.},
	language = {en},
	number = {5},
	urldate = {2023-11-06},
	journal = {INFORMS Journal on Computing},
	author = {Cappart, Quentin and Bergman, David and Rousseau, Louis-Martin and Prémont-Schwarz, Isabeau and Parjadis, Augustin},
	month = sep,
	year = {2022},
	pages = {2552--2570},
}

@misc{noauthor_doosan_nodate,
	title = {Doosan starts forging components for {NuScale} {SMR} : {New} {Nuclear} - {World} {Nuclear} {News}},
	url = {https://world-nuclear-news.org/Articles/Doosan-starts-forging-components-for-NuScale-SMR},
	urldate = {2023-11-02},
}

@misc{noauthor_what_nodate,
	title = {What are microreactors?},
	url = {https://inl.gov/trending-topic/microreactors/},
	abstract = {INL is working with developers, private industry, regulators, universities and others to develop, demonstrate, test and validate this new generation of microreactors.},
	language = {en-US},
	urldate = {2023-03-16},
	journal = {INL},
}

@misc{noauthor_microreactors_nodate,
	title = {Microreactors},
	url = {https://inl.gov/trending-topics/microreactors/},
	abstract = {Idaho National Laboratory {\textbar} Microreactors},
	language = {en-US},
	urldate = {2023-10-30},
	journal = {Idaho National Laboratory},
}

@misc{noauthor_nuscale_2023,
	title = {{NuScale}: {Investor} {Presentation}},
	url = {https://www.nuscalepower.com/-/media/nuscale/pdf/investors/2023/investor-presentation.pdf},
	language = {English},
	urldate = {2023-10-30},
	month = aug,
	year = {2023},
}

@misc{noauthor_vogtle_nodate,
	title = {Vogtle {Construction} {Photos}},
	url = {https://www.georgiapower.com/company/plant-vogtle/vogtle-photos.html},
	abstract = {View the latest progress on the project and download high resolution images.},
	language = {en},
	urldate = {2023-10-30},
}

@techreport{aras_refining_2023,
	title = {Refining {Processing} {Engines} from {SAPHIRE}: {Initialization} of {Fault} {Tree}/{Event} {Tree} {Solver}},
	shorttitle = {Refining {Processing} {Engines} from {SAPHIRE}},
	url = {https://www.osti.gov/biblio/2203095},
	abstract = {SAPHIRE has been extensively employed for over 35 years to model risk-important systems and quantify risk models. As a well-established and thoroughly documented Probabilistic Risk Assessment (PRA) tool, SAPHIRE has continuously tracked computational trends and received regular updates. Despite its ongoing evolution, there remains a need for further enhancements, particularly in dealing with the quantification of exceptionally large models. These improvements could take the form of algorithmic advancements, harnessing the power of parallel computing, and exploring the potential benefits of cloud computing solutions. Considering these aspirations, the notion of a remote solve option was introduced and subsequently evolved into a dedicated project within the SAPHIRE development team. A significant outcome of this initiative is SAPHSOLVE, an engine extracted from the SageRisk API designed specifically for remote solving capabilities. The ongoing project is nearing its culmination, marked by a series of discoveries that have brought undocumented aspects to light. Among these revelations is the intricacy of the input and output format for the SAPHSOLVE engine. This document serves the crucial purpose of meticulously delineating the precise formats for both input and output, as they form an indispensable foundation. The importance of documenting these formats cannot be overstated, as it is a pivotal step in facilitating rigorous testing and comparison. Whether it involves scrutinizing SAPHSOLVE results against those of the internal integrated solver or other external solvers, the ability to construct models or transform existing ones into a compatible SAPHSOLVE format is imperative. Chapter 1 offers a succinct introduction to both SAPHIRE and SAPHSOLVE, followed by Chapter 2 which outlines the roadmap for enhancing SAPHSOLVE. The core of this report is Chapter 3, which intricately elucidates the intricacies of the input and output file formats. To provide a tangible illustration of these formats, a rudimentary example has been compiled and is available in Appendix. SAPHSOLVE represents a novel external solving mechanism developed by the SAPHIRE team, although it has not yet reached the full spectrum of capabilities possessed by SAPHIRE's internal solver. However, the SAPHIRE team has set a comprehensive course for incorporating the functionalities of SAPHSOLVE. A comprehensive outlook on the future of SAPHSOLVE is expounded upon in Chapter 4.},
	language = {English},
	number = {INL/RPT-23-75066-Rev000},
	urldate = {2023-10-29},
	institution = {Idaho National Laboratory (INL), Idaho Falls, ID (United States)},
	author = {Aras, Egemen Mutlu and Amin Aly Farag, Asmaa Salem and Wood, Stephen Ted and Boyce, Jordan Thomas},
	month = oct,
	year = {2023},
	doi = {10.2172/2203095},
}

@misc{noauthor_eprinrc-res_nodate,
	title = {{EPRI}/{NRC}-{RES} {Fire} {PRA} {Methodology} for {Nuclear} {Power} {Facilities}: {Detailed} {Methodology}, {Final} {Report},},
	shorttitle = {{EPRI}/{NRC}-{RES} {Fire} {PRA} {Methodology} for {Nuclear} {Power} {Facilities}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6850/v2/index.html},
	language = {en-US},
	urldate = {2023-10-20},
	journal = {NRC Web},
}

@misc{noauthor_fire_nodate,
	title = {Fire {Dynamics} {Tools} ({FDTs}) {Quantitative} {Fire} {Hazard} {Analysis} {Methods} for the {U}.{S}. {Nuclear} {Regulatory}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1805/s1/index.html},
	language = {en-US},
	urldate = {2023-10-20},
	journal = {NRC Web},
}

@misc{noauthor_pandas_nodate,
	type = {Information},
	title = {Pandas {Dataframe} {Documentation}},
	url = {https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html},
	urldate = {2022-04-20},
	journal = {Pandas},
}

@book{noauthor_waste_1996,
	address = {Washington, D.C. (USA)},
	title = {The {Waste} {Isolation} {Pilot} {Plant}: {A} {Potential} {Solution} for the {Disposal} of {Transuranic} {Waste}},
	url = {https://www.nap.edu/read/5269/chapter/13},
	language = {English},
	urldate = {2021-10-05},
	publisher = {National Academy Press},
	year = {1996},
	doi = {10.17226/5269},
}

@techreport{lipson_reliability_nodate,
	address = {New York},
	title = {Reliability {Prediction} - {Mechanical} {Stress}/ {Strength} {Interference}},
	url = {https://apps.dtic.mil/sti/pdfs/AD0813574.pdf},
	language = {English},
	number = {RADC-TR- 66-710},
	institution = {Rome Air Development Center},
	author = {Lipson, Charles and J. Sheth, Narendra and L. Disney, Ralph},
	pages = {463},
}

@misc{pearl_bayesian_2011,
	title = {Bayesian networks},
	url = {https://escholarship.org/uc/item/53n4f34m},
	language = {English},
	urldate = {2021-09-17},
	publisher = {UCLA, Department of Statistics Papers},
	author = {Pearl, Judea},
	month = oct,
	year = {2011},
}

@book{russell_artificial_nodate,
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}, 4th {US} ed.},
	url = {https://aima.cs.berkeley.edu/},
	urldate = {2023-10-05},
	author = {Russell, Stuart and Norvig, Peter},
}

@misc{mccarthy_what_2007,
	title = {What is {Artificial} {Intelligence}?},
	abstract = {This article for the layman answers basic questions about artiﬁcial intelligence. The opinions expressed here are not all consensus opinion among researchers in AI.},
	language = {English},
	publisher = {Computer Science Department, Stanford University},
	author = {McCarthy, John},
	month = nov,
	year = {2007},
}

@misc{noauthor_companies_2022,
	title = {Companies use {MIT} research to identify and respond to supply chain risks},
	url = {https://news.mit.edu/2022/companies-use-mit-research-identify-respond-supply-chain-risks-0615},
	abstract = {Two years after MIT professor David Simchi-Levi predicted global supply chain woes caused by Covid-19, companies are using his research to identify their supply chain risks and implement cost-saving solutions.},
	language = {English},
	urldate = {2023-10-05},
	journal = {MIT News {\textbar} Massachusetts Institute of Technology},
	month = jun,
	year = {2022},
}

@misc{noauthor_new_2020,
	type = {{NGO}},
	title = {New {Toolkit} for {Nuclear} {Supply} {Chain} {Management}},
	url = {https://www.iaea.org/newscenter/news/new-toolkit-for-nuclear-supply-chain-management},
	abstract = {The IAEA has launched a Nuclear Supply Chain Toolkit to support countries in coordinating among regulators, technical support organizations, owner/operators of nuclear facilities and their suppliers.},
	language = {English},
	urldate = {2023-09-19},
	journal = {IAEA},
	month = nov,
	year = {2020},
}

@techreport{barry_advanced_2013,
	type = {Technical},
	title = {Advanced {Nuclear} {Technology}: {Supplier} {Quality} {Management} for {New} {Nuclear} {Plant} {Construction} {Projects}},
	language = {English},
	institution = {EPRI},
	author = {Barry, K},
	year = {2013},
}

@misc{noauthor_supply_nodate,
	type = {Company},
	title = {Supply {Chain} {Management}},
	url = {https://www.rolls-royce.com/~/media/Files/R/Rolls-Royce/documents/customers/nuclear/supply-chain-management.pdf},
	language = {English},
	urldate = {2023-10-02},
	journal = {Rolls-Royce},
}

@misc{noauthor_supply_nodate-1,
	type = {Company},
	title = {Supply {Chain} {Solutions} for the {Power} {Generation} and {Industrial} {Markets}},
	url = {https://www.cwnuclear.com/brands/nova/services/supply-chain-management/default.aspx},
	language = {English},
	urldate = {2023-10-02},
	journal = {Curtiss-Wright Nuclear},
}

@techreport{noauthor_nuclear_2004,
	address = {Vienna, Austria},
	type = {{TECDOC}},
	title = {The nuclear power industry’s ageing workforce: {Transfer} of knowledge to the next generation},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/te_1399_web.pdf},
	number = {1399},
	urldate = {2023-10-02},
	institution = {IAEA},
	month = jun,
	year = {2004},
}

@misc{noauthor_opportunities_2015,
	type = {News},
	title = {Opportunities to avoid nuclear skills shortage},
	url = {https://world-nuclear-news.org/Articles/Opportunities-to-avoid-nuclear-skills-shortage},
	urldate = {2023-10-02},
	journal = {World Nuclear News},
	month = sep,
	year = {2015},
}

@misc{noauthor_commercial-grade_nodate,
	title = {Commercial-{Grade} {Dedication}},
	url = {https://www.nrc.gov/reactors/new-reactors/how-we-regulate/oversight/quality-assurance/vendor-insp/comm-grade-dedication.html},
	language = {English},
	urldate = {2023-10-02},
	journal = {USNRC},
}

@article{tannenbaum_nuclear_2019,
	title = {Nuclear supply chain challenges and opportunities},
	shorttitle = {Supply {Chain} {Special} {Section}},
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjUx8CuufSBAxVElGoFHdIwDMYQFnoECCkQAQ&url=https%3A%2F%2Fwww.ans.org%2Fpubs%2Fmagazines%2Fdownload%2Farticle-1157%2F&usg=AOvVaw10rh2lshtDozMulV4YPsOX&opi=89978449},
	abstract = {Maintaining the spare and replacement items needed to support a nuclear power plant is a significant undertaking. Nuclear licensees and their suppliers are working diligently to meet the challenges of sustaining the flow of replacement items.},
	language = {en},
	journal = {ANS Nuclear News},
	author = {Tannenbaum, Marc},
	month = apr,
	year = {2019},
}

@techreport{noauthor_management_nodate,
	address = {Vienna, Austria},
	title = {Management of {Ageing} and {Obsolescence} of {Instrumentation} and {Control} {Systems} and {Equipment} in {Nuclear} {Power} {Plants} and {Related} {Facilities} {Through} {Modernization}},
	url = {https://www.world-nuclear-news.org/rs-indictments_for_south_korea_forgery_scandal-1010137.html},
	language = {English},
	number = {NR‑T‑3.34},
	urldate = {2023-10-02},
	institution = {IAEA},
}

@techreport{noauthor_countering_2019,
	address = {England and Wales},
	type = {Supply {Chain} {Working} {Group}},
	title = {Countering {Counterfeit}, {Fraudulent} and {Suspect} {Items} in the {Nuclear} {Supply} {Chain}},
	url = {https://www.world-nuclear.org/getattachment/e310428b-84ea-4592-a4a8-9f07efb53c01/REPORT-countering-counterfeit.pdf.aspx},
	number = {2019/005},
	urldate = {2023-10-02},
	institution = {World Nuclear Association},
	month = aug,
	year = {2019},
}

@techreport{noauthor_managing_2019,
	type = {{IAEA} {Nuclear} {Energy} {Series}},
	title = {Managing {Counterfeit} and {Fraudulent} {Items} in the {Nuclear} {Industry}},
	url = {https://www.iaea.org/publications/11182/managing-counterfeit-and-fraudulent-items-in-the-nuclear-industry},
	language = {English},
	number = {No. NP-T-3.26},
	urldate = {2023-10-02},
	institution = {International Atomic Energy Agency},
	year = {2019},
	note = {ISBN: 9789201023186
Publication Title: Managing Counterfeit and Fraudulent Items in the Nuclear Industry},
	pages = {1--94},
}

@techreport{noauthor_supply_2022,
	type = {Workshop {Summary}},
	title = {Supply {Chain} {Challenges} and {Opportunities} for {Structural} {Components} in {Advanced} {Energy} {Systems}},
	url = {https://www.epri.com/research/products/000000003002025254},
	abstract = {Unprecedented energy transformation is reshaping the energy system and placing new strain on an already pressed global supply chain.},
	language = {English},
	institution = {EPRI},
	year = {2022},
}

@misc{noauthor_nuclear_nodate,
	type = {{NGO}},
	title = {Nuclear power and the environment},
	url = {https://www.eia.gov/energyexplained/nuclear/nuclear-power-and-the-environment.php},
	urldate = {2023-09-06},
	journal = {U.S. Energy Information Administration (EIA)},
}

@misc{noauthor_new_2009,
	type = {News},
	title = {New nuclear build},
	url = {https://www.neimagazine.com/opinion/opinionnew-nuclear-build-sufficient-supply-capability/},
	language = {English},
	urldate = {2023-10-02},
	journal = {Nuclear Engineering International},
	month = mar,
	year = {2009},
}

@misc{noauthor_getting_2010,
	type = {News},
	title = {Getting heavy},
	url = {https://www.neimagazine.com/features/featuregetting-heavy/},
	language = {English},
	urldate = {2023-10-02},
	journal = {Nuclear Engineering International},
	month = jul,
	year = {2010},
}

@misc{noauthor_heavy_2021,
	type = {{NGO}},
	title = {Heavy {Manufacturing} of {Power} {Plants}},
	url = {https://world-nuclear.org/information-library/nuclear-fuel-cycle/nuclear-power-reactors/heavy-manufacturing-of-power-plants.aspx},
	language = {English},
	urldate = {2023-10-02},
	journal = {World Nuclear Association},
	month = mar,
	year = {2021},
}

@techreport{noauthor_advanced_2023,
	title = {Advanced {Reactor} {Roadmap} {Phase} 1: {North} {America}},
	language = {English},
	institution = {EPRI, NEI},
	year = {2023},
}

@misc{noauthor_nuclear_nodate-1,
	type = {Company},
	title = {Nuclear {Component} {Certification}},
	url = {https://www.asme.org/certification-accreditation/Nuclear-Component-Certification},
	abstract = {ASME BPVC section III certification of components installed for a nuclear facility, small modular reactor (SMR), microreactor, and advanced reactor.},
	language = {English},
	urldate = {2023-10-02},
	journal = {ASME},
}

@misc{noauthor_viewpoint_2023,
	type = {News},
	title = {Viewpoint: {The} critical production of cobalt-60 in nuclear reactors: {Perspectives}},
	url = {https://www.world-nuclear-news.org/Articles/The-critical-production-of-cobalt-60-in-nuclear-re},
	language = {English},
	urldate = {2023-09-25},
	journal = {World Nuclear News},
	month = mar,
	year = {2023},
}

@misc{noauthor_supply_2019,
	type = {{NGO}},
	title = {The {Supply} of {Medical} {Radioisotopes}},
	url = {https://www.oecd-nea.org/jcms/pl_14680/the-supply-of-medical-radioisotopes?details=true},
	abstract = {The reliable supply of molybdenum-99 (99Mo) and its decay product, technetium-99m (99mTc), is a vital component of modern medical diagnostic practices. Disruptions in the supply chain of these radioisotopes can delay or prevent important medical testing services. Unfortunately, supply reliability ha...},
	language = {English},
	urldate = {2023-09-25},
	journal = {Nuclear Energy Agency (NEA)},
	month = dec,
	year = {2019},
}

@techreport{noauthor_nuclear_2022,
	title = {Nuclear {Energy} {Supply} {Chain} {Deep} {Dive} {Assessment}},
	url = {https://www.energy.gov/sites/default/files/2022-02/Nuclear%20Energy%20Supply%20Chain%20Report%20-%20Final.pdf},
	language = {English},
	urldate = {2022-09-09},
	institution = {USDOE},
	month = feb,
	year = {2022},
}

@techreport{noauthor_role_nodate,
	type = {World {Energy} {Outlook} {Special} {Report}},
	title = {The {Role} of {Critical} {Minerals} in {Clean} {Energy} {Transitions}},
	language = {English},
	institution = {IEA},
}

@techreport{noauthor_advanced_2021,
	address = {UK},
	title = {Advanced {Modular} {Reactors} {Technical} {Assessment}},
	language = {en},
	institution = {Nuclear Innovation and Research Office},
	month = jul,
	year = {2021},
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {Reactor} {Types}},
	url = {https://www.energy.gov/sites/default/files/2020/05/f74/Advanced-Reactor-Types_Fact-Sheet_Draft_Hi-Res_R1.pdf},
	language = {English},
	urldate = {2023-09-25},
	journal = {Department of Energy Office of Nuclear Energy},
}

@misc{noauthor_building_2022,
	type = {News},
	title = {Building the {Gen} {IV} fuel supply chain -},
	url = {https://www.neimagazine.com/features/featurebuilding-the-gen-iv-fuel-supply-chain-9809794/},
	language = {English},
	urldate = {2023-09-25},
	journal = {Nuclear Engineering International},
	month = jun,
	year = {2022},
}

@misc{noauthor_making_2023,
	type = {News},
	title = {Making a move on molten salt reactors},
	url = {https://www.neimagazine.com/opinion/opinionmaking-a-move-on-molten-salt-reactors-11020126/},
	language = {English},
	urldate = {2023-09-25},
	journal = {Nuclear Engineering International},
	month = jul,
	year = {2023},
}

@misc{noauthor_centrus_2023,
	title = {Centrus {Completes} {Construction} and {Initial} {Testing} of {HALEU} {Demonstration} {Cascade}, {Expects} to {Begin} {Production} by {End} of 2023},
	url = {https://www.centrusenergy.com/news/centrus-completes-construction-and-initial-testing-of-haleu-demonstration-cascade-expects-to-begin-production-by-end-of-2023/},
	abstract = {Centrus Energy Corp. (NYSE American: LEU) announced today that it has completed construction of a cascade of advanced uranium enrichment centrifuges as well as most of the associated support systems.  This milestone puts Centrus on track to begin demonstrating first-of-a-kind production of High-Assay, Low-Enriched Uranium (HALEU) in Piketon, Ohio, by the end of 2023, after completing remaining support systems and obtaining final approval from the Nuclear Regulatory Commission.},
	language = {English},
	urldate = {2023-09-25},
	journal = {Centrus Energy Corp},
	month = feb,
	year = {2023},
}

@misc{ashton_fueling_2023,
	type = {Text},
	title = {Fueling the future},
	url = {https://www.iaea.org/bulletin/fuelling-the-future},
	language = {English},
	urldate = {2023-09-25},
	journal = {IAEA},
	author = {Ashton, Lucy},
	month = sep,
	year = {2023},
	note = {Publisher: IAEA},
}

@misc{bader_back-end_2021,
	title = {Back-{End} of the {Nuclear} {Fuel} {Cycle}: {Used} {Fuel} {Management} for {Advanced} {Reactors}},
	url = {https://www.nap.edu/catalog/26500},
	language = {en},
	urldate = {2023-09-25},
	author = {Bader, Sven},
	month = sep,
	year = {2021},
	doi = {10.17226/26500},
	note = {Pages: 26500},
}

@misc{noauthor_guide_2023,
	type = {News},
	title = {A guide: {Uranium} in {Niger}},
	url = {https://www.world-nuclear-news.org/Articles/A-guide-Uranium-in-Niger},
	language = {English},
	urldate = {2023-09-25},
	journal = {World Nuclear News},
	month = jul,
	year = {2023},
}

@misc{noauthor_high-assay_2023,
	type = {Government},
	title = {High-{Assay} {Low}-{Enriched} {Uranium} ({HALEU})},
	url = {https://www.nrc.gov/materials/new-fuels/haleu.html},
	language = {English},
	urldate = {2023-09-25},
	journal = {USNRC},
	month = jul,
	year = {2023},
}

@misc{noauthor_terrapower_2022,
	type = {News},
	title = {{TerraPower} announces delay due to lack of fuel availability},
	url = {https://www.ans.org/news/article-4589/terrapower-announces-delay-due-to-lack-of-fuel-availability/},
	language = {English},
	urldate = {2023-09-25},
	journal = {Nuclear Newswire},
	month = dec,
	year = {2022},
}

@misc{noauthor_uranium_2022,
	type = {{NGO}},
	title = {Uranium {Enrichment}},
	url = {https://world-nuclear.org/information-library/nuclear-fuel-cycle/conversion-enrichment-and-fabrication/uranium-enrichment.aspx},
	language = {English},
	urldate = {2023-09-25},
	journal = {World Nuclear Association},
	month = oct,
	year = {2022},
}

@misc{noauthor_world_2023,
	type = {{NGO}},
	title = {World {Uranium} {Mining} {Production}},
	url = {https://world-nuclear.org/information-library/nuclear-fuel-cycle/mining-of-uranium/world-uranium-mining-production.aspx},
	language = {English},
	urldate = {2023-09-25},
	journal = {World Nuclear Association},
	month = aug,
	year = {2023},
}

@misc{noauthor_uranium_2021,
	type = {News},
	title = {Uranium producers feel impact of supply chain issues: {Uranium} \& {Fuel} - {World} {Nuclear} {News}},
	url = {https://www.world-nuclear-news.org/Articles/Uranium-producers-feel-impact-of-supply-chain-issu},
	language = {English},
	urldate = {2023-09-25},
	journal = {World Nuclear News},
	month = nov,
	year = {2021},
}

@techreport{noauthor_world_2016,
	address = {England, and Wales},
	title = {The world nuclear supply chain outlook 2035},
	language = {English},
	number = {2016/006},
	institution = {World Nuclear Association},
	month = sep,
	year = {2016},
}

@techreport{noauthor_world_2016-1,
	title = {The world nuclear supply chain: outlook 2035.},
	shorttitle = {The world nuclear supply chain},
	url = {https://world-nuclear.org/our-association/publications/global-trends-reports/world-nuclear-supply-chain-outlook-2040.aspx},
	language = {en},
	number = {2016/006},
	year = {2016},
	note = {OCLC: 1039351631},
}

@misc{noauthor_are_nodate,
	type = {{NGO}},
	title = {Are there different types of nuclear reactors?},
	url = {https://www.world-nuclear.org/nuclear-essentials/are-there-different-types-of-reactor.aspx},
	abstract = {Nuclear reactors come in many different shapes and sizes. Most are large enough to power major cities, and small reactors are being developed to complement them. Most use water to cool their cores, whilst others use gas or metals.},
	language = {English},
	urldate = {2023-09-16},
	journal = {World Nuclear Association},
}

@book{noauthor_nuclear_2022,
	title = {Nuclear {Power}, and {Secure} {Energy} {Transitions}: {From} today’s challenges to tomorrow’s clean energy systems},
	isbn = {978-92-64-55926-4},
	shorttitle = {Nuclear {Power} and {Secure} {Energy} {Transitions}},
	url = {https://www.oecd-ilibrary.org/energy/nuclear-power-and-secure-energy-transitions_aca1d7ee-en},
	abstract = {Nuclear Power and Secure Energy Transitions: From Today’s Challenges to Tomorrow’s Clean Energy Systems is a new report by the International Energy Agency that looks at how nuclear energy could help address two major crises energy and climate – facing the world today. Russia’s invasion of Ukraine and the disruptions in global energy supplies that it has fuelled have made governments rethink their energy security strategies, putting a stronger focus on developing more diverse and domestically based supplies. For multiple governments, nuclear energy is among the options for achieving this. At the same time, many governments have in recent years stepped up their ambitions and commitments to reach net zero emissions. Nuclear Power and Secure Energy Transitions expands upon the IEA’s landmark 2021 report, Net Zero by 2050: A Roadmap for the Global Energy Sector. It does so by exploring in depth nuclear power’s potential role as a source of low emissions electricity that is available on demand to complement the leading role of renewables such as wind and solar in the transition to electricity systems with net zero emissions. In this context, the report examines the difficulties facing nuclear investment, particularly in advanced economies, in the areas of cost, performance, safety and waste management. It considers the additional challenge of meeting net zero targets with less nuclear power than envisioned in the IEA Net Zero Roadmap, as well as what kind of cost targets could enable nuclear power to play a larger role in energy transitions. For countries where nuclear power is considered an acceptable part of the future energy mix, the new report identifies the potential policy, regulatory and market changes that could be implemented in order to create new investment opportunities. It also looks at the role of new technologies, particularly small modular reactors, and their potential development and deployment.},
	language = {English},
	urldate = {2023-09-11},
	publisher = {IEA},
	month = aug,
	year = {2022},
	doi = {10.1787/aca1d7ee-en},
}

@misc{noauthor_summary_nodate,
	title = {Summary for {Policymakers}},
	url = {https://www.ipcc.ch/sr15/chapter/spm/},
	language = {English},
	journal = {Special Report: Global Warming of 1.5 ºC},
}

@misc{noauthor_commercializing_2023,
	type = {{DOE}},
	title = {Commercializing {Advanced} {Nuclear} {Reactors} {Explained} in {Five} {Charts}},
	url = {https://www.energy.gov/ne/articles/commercializing-advanced-nuclear-reactors-explained-five-charts},
	abstract = {New DOE pathways report estimates advanced nuclear could provide about 200 GW of additional capacity by 2050.},
	language = {English},
	journal = {Office of Nuclear Energy},
	month = mar,
	year = {2023},
}

@misc{noauthor_european_2023,
	type = {News},
	title = {European {Pressurized} {Reactors}: {Nuclear} {Power}’s {Latest} {Costly} and {Delayed} {Disappointments}},
	shorttitle = {European {Pressurized} {Reactors}},
	url = {https://ieefa.org/articles/european-pressurized-reactors-nuclear-powers-latest-costly-and-delayed-disappointments},
	abstract = {Touted as a safer alternative to earlier nuclear plant designs, European Pressurized Reactors (EPRs) have so far done little to disprove conventional wisdom: Nuclear plants always cost more than estimated and take longer to build than promised.},
	language = {English},
	urldate = {2023-09-11},
	journal = {Institute for Energy Economics and Financial Analysis},
	month = feb,
	year = {2023},
}

@misc{overstraeten_edf_2022,
	type = {News},
	title = {{EDF} announces new delay and higher costs for {Flamanville} 3 reactor},
	url = {https://www.reuters.com/business/energy/edf-announces-new-delay-higher-costs-flamanville-3-reactor-2022-01-12/},
	abstract = {France's Flamanville 3 reactor will cost 300 million euros more than forecast and fuel loading is being pushed back by up to six months, EDF said on Wednesday, in the latest setback for a project already running more than a decade late.},
	language = {English},
	urldate = {2023-09-11},
	journal = {Reuters},
	author = {Overstraeten, Benoit Van and Mallet, Benjamin},
	month = jan,
	year = {2022},
}

@misc{amy_georgia_2023,
	title = {Georgia nuclear rebirth arrives 7 years late, \${17B} {Over} {Cost}},
	url = {https://apnews.com/article/georgia-nuclear-power-plant-vogtle-rates-costs-75c7a413cda3935dd551be9115e88a64},
	abstract = {The first new U.S. nuclear reactor built from scratch in decades has begun generating electricity. The Georgia reactor is supposed to reach full power output in coming days, with a second reactor scheduled for completion in 2024.},
	language = {en},
	urldate = {2023-09-11},
	journal = {AP News},
	author = {Amy, Jeff},
	month = may,
	year = {2023},
}

@misc{rogers_finlands_2022,
	type = {News},
	title = {Finland’s {Olkiluoto} 3 goes online after 12-year construction delay},
	url = {https://www.globalconstructionreview.com/finlands-olkiluoto-3-goes-online-after-12-year-construction-delay/},
	abstract = {The Olkiluoto 3 nuclear reactor went online in Finland on Saturday, 12 years after its deadline, and around €8bn over its original €3bn budget. Finnish nuclear operator Teollisuuden Voima (TVO)…},
	language = {English},
	urldate = {2023-09-11},
	journal = {Global Construction Review},
	author = {Rogers, David},
	month = mar,
	year = {2022},
}

@book{noauthor_unlocking_2020,
	series = {Nuclear {Technology} {Development} and {Economics}},
	title = {Unlocking {Reductions} in the {Construction} {Costs} of {Nuclear}: {A} {Practical} {Guide} for {Stakeholders}},
	isbn = {978-92-64-75135-4},
	shorttitle = {Unlocking {Reductions} in the {Construction} {Costs} of {Nuclear}},
	url = {https://www.oecd-ilibrary.org/nuclear-energy/unlocking-reductions-in-the-construction-costs-of-nuclear_33ba86e1-en},
	language = {English},
	urldate = {2023-09-11},
	publisher = {OECD and NEA},
	month = aug,
	year = {2020},
	doi = {10.1787/33ba86e1-en},
}

@misc{noauthor_how_nodate,
	title = {How can nuclear combat climate change?},
	url = {https://world-nuclear.org/nuclear-essentials/how-can-nuclear-combat-climate-change.aspx},
	abstract = {To limit the impacts of climate change, the world must rapidly reduce its dependency on fossil fuels to reduce greenhouse gas emissions. Nuclear energy is low-carbon and can be deployed on a large scale at the timescale required, supplying the world with clean, reliable, and affordable electricity.},
	urldate = {2023-09-06},
	journal = {World Nuclear Association},
}

@book{noauthor_read_nodate,
	title = {Read "{The} {Waste} {Isolation} {Pilot} {Plant}: {A} {Potential} {Solution} for the {Disposal} of {Transuranic} {Waste}" at {NAP}.edu},
	shorttitle = {Read "{The} {Waste} {Isolation} {Pilot} {Plant}},
	url = {https://www.nap.edu/read/5269/chapter/13},
	abstract = {Read chapter B.  THE COMPLEMENTARY CUMULATIVE DISTRIBUTION FUNCTION: THE RISK CURVE: This volume discusses the readiness of the U.S. Department of Energy'...},
	language = {en},
	urldate = {2023-10-08},
	doi = {10.17226/5269},
}

@book{russell_artificial_2010,
	address = {Upper Saddle River},
	edition = {3rd ed},
	series = {Prentice {Hall} series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial intelligence},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
	year = {2010},
	keywords = {Artificial intelligence},
}

@misc{gao_disruption_2016,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Disruption {Risk} {Mitigation} in {Supply} {Chains} - {The} {Risk} {Exposure} {Index} {Revisited}},
	url = {https://papers.ssrn.com/abstract=2875596},
	doi = {10.2139/ssrn.2875596},
	abstract = {Simchi-Levi et al. (2014, 2015a) proposed a novel approach using the Time-To-Recover (TTR) parameters to analyze the Risk Exposure Index (REI) of supply chains under disruption.  This approach is able to capture the cascading effects of disruptions in the supply chains, albeit in simplified environments -- TTRs are deterministic, and at most one node in the supply chain can be disrupted. In this paper, we proposed a new method to integrate probabilistic assessment of disruption risks into the REI approach and measure supply chain resiliency by analyzing the Worst-case CVaR (WCVaR) of total lost sales under disruptions.},
	language = {en},
	urldate = {2023-10-05},
	author = {Gao, Sarah Yini and Simchi-Levi, David and Teo, Chung-Piaw and Yan, Zhenzhen},
	month = nov,
	year = {2016},
	keywords = {completely positive programming., disruption management, sensitivity analysis, supply chain risk management, time-to-survive},
}

@article{seck_simulation-based_2015,
	series = {Complex {Adaptive} {Systems} {San} {Jose}, {CA} {November} 2-4, 2015},
	title = {A {Simulation}-based {Approach} to {Risk} {Assessment} and {Mitigation} in {Supply} {Chain} {Networks}},
	volume = {61},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915029919},
	doi = {10.1016/j.procs.2015.09.161},
	abstract = {We present in this paper a simulation-based approach to evaluate the risk associated with supply chain disruptions caused by failures in some supply chains nodes and measure the impact of such disruptions on supply chain key performance measures (KPIs) of interest. The proposed framework enables analysts and managers to repeatedly assess the risk to their supply chains based on various simulated scenarios and identify the most critical nodes whose disruption will have the highest impact on the KPIs of interest. As a result, companies can focus on the most critical supply chain assets and develop targeted mitigation plans that minimize their risk.},
	urldate = {2023-10-05},
	journal = {Procedia Computer Science},
	author = {Seck, Mamadou and Rabadi, Ghaith and Koestler, Christian},
	month = jan,
	year = {2015},
	keywords = {DEMO Methodology, agents simulation, enterprise modeling, ontological modeli},
	pages = {98--104},
}

@misc{noauthor_how_2021,
	title = {How to plot a normal distribution with {Matplotlib} in {Python} ?},
	url = {https://www.geeksforgeeks.org/how-to-plot-a-normal-distribution-with-matplotlib-in-python/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	language = {en-us},
	urldate = {2023-10-03},
	journal = {GeeksforGeeks},
	month = jan,
	year = {2021},
	note = {Section: Python},
}

@misc{noauthor_fluor_nodate,
	title = {Fluor \& {Jovix} {Created} a {Digital} {Supply} {Chain} via {Material} {Readiness}},
	url = {https://aliresources.hexagon.com/all-resources/fluor-jovix-created-a-digital-supply-chain-via-material-readiness},
	abstract = {Fluor has used Jovix to onboard hundreds of suppliers into their digital supply chain program, giving construction teams visibility into material flow throughout their supply chains.},
	urldate = {2023-10-02},
}

@misc{noauthor_duke_nodate,
	title = {Duke {Energy} {Supplier} {Management} {Program}},
	url = {https://pages.avetta.com/DUKE-ENERGY},
	urldate = {2023-10-02},
}

@article{reay_fault_2002,
	title = {A fault tree analysis strategy using binary decision diagrams},
	volume = {78},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832002001072},
	doi = {10.1016/S0951-8320(02)00107-2},
	language = {en},
	number = {1},
	urldate = {2023-10-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Reay, Karen A. and Andrews, John D.},
	month = oct,
	year = {2002},
	pages = {45--56},
}

@article{rosenberg_algorithm_1996,
	title = {Algorithm for finding minimal cut sets in a fault tree},
	volume = {53},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832096000348},
	doi = {10.1016/0951-8320(96)00034-8},
	language = {en},
	number = {1},
	urldate = {2023-10-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Rosenberg, Ladislav},
	month = jul,
	year = {1996},
	pages = {67--71},
}

@article{serradilla_deep_2022,
	title = {Deep learning models for predictive maintenance: a survey, comparison, challenges and prospects},
	volume = {52},
	issn = {0924-669X, 1573-7497},
	shorttitle = {Deep learning models for predictive maintenance},
	url = {https://link.springer.com/10.1007/s10489-021-03004-y},
	doi = {10.1007/s10489-021-03004-y},
	language = {en},
	number = {10},
	urldate = {2023-10-02},
	journal = {Applied Intelligence},
	author = {Serradilla, Oscar and Zugasti, Ekhi and Rodriguez, Jon and Zurutuza, Urko},
	month = aug,
	year = {2022},
	pages = {10934--10964},
}

@article{cheng_improved_1998,
	title = {An improved neural network realization for reliability analysis},
	volume = {38},
	issn = {00262714},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0026271497001674},
	doi = {10.1016/S0026-2714(97)00167-4},
	language = {en},
	number = {3},
	urldate = {2023-10-02},
	journal = {Microelectronics Reliability},
	author = {Cheng, C.-S. and Hsu, Y.-T. and Wu, C.-C.},
	month = mar,
	year = {1998},
	pages = {345--352},
}

@article{li_deep_2020,
	title = {Deep learning for high-dimensional reliability analysis},
	volume = {139},
	issn = {08883270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S088832701930620X},
	doi = {10.1016/j.ymssp.2019.106399},
	language = {en},
	urldate = {2023-10-02},
	journal = {Mechanical Systems and Signal Processing},
	author = {Li, Mingyang and Wang, Zequn},
	month = may,
	year = {2020},
	pages = {106399},
}

@incollection{mciver_lift_2018,
	address = {Cham},
	title = {{LIFT}: {Learning} {Fault} {Trees} from {Observational} {Data}},
	volume = {11024},
	isbn = {978-3-319-99153-5 978-3-319-99154-2},
	shorttitle = {{LIFT}},
	url = {http://link.springer.com/10.1007/978-3-319-99154-2_19},
	urldate = {2023-10-02},
	booktitle = {Quantitative {Evaluation} of {Systems}},
	publisher = {Springer International Publishing},
	author = {Nauta, Meike and Bucur, Doina and Stoelinga, Mariëlle},
	editor = {McIver, Annabelle and Horvath, Andras},
	year = {2018},
	doi = {10.1007/978-3-319-99154-2_19},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {306--322},
}

@article{verkuil_automated_2022,
	title = {Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters},
	copyright = {Creative Commons Attribution Share Alike 4.0 International},
	shorttitle = {Automated fault tree learning from continuous-valued sensor data},
	url = {https://arxiv.org/abs/2203.07374},
	doi = {10.48550/ARXIV.2203.07374},
	abstract = {Many industrial sectors have been collecting big sensor data. With recent technologies for processing big data, companies can exploit this for automatic failure detection and prevention. We propose the first completely automated method for failure analysis, machine-learning fault trees from raw observational data with continuous variables. Our method scales well and is tested on a real-world, five-year dataset of domestic heater operations in The Netherlands, with 31 million unique heater-day readings, each containing 27 sensor and 11 failure variables. Our method builds on two previous procedures: the C4.5 decision-tree learning algorithm, and the LIFT fault tree learning algorithm from Boolean data. C4.5 pre-processes each continuous variable: it learns an optimal numerical threshold which distinguishes between faulty and normal operation of the top-level system. These thresholds discretise the variables, thus allowing LIFT to learn fault trees which model the root failure mechanisms of the system and are explainable. We obtain fault trees for the 11 failure variables, and evaluate them in two ways: quantitatively, with a significance score, and qualitatively, with domain specialists. Some of the fault trees learnt have almost maximum significance (above 0.95), while others have medium-to-low significance (around 0.30), reflecting the difficulty of learning from big, noisy, real-world sensor data. The domain specialists confirm that the fault trees model meaningful relationships among the variables.},
	urldate = {2023-10-02},
	author = {Verkuil, Bart and Budde, Carlos E. and Bucur, Doina},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 3},
	keywords = {Artificial Intelligence (cs.AI), Computational Engineering, Finance, and Science (cs.CE), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@article{niloofar_data-driven_2023,
	title = {Data-driven extraction and analysis of repairable fault trees from time series data},
	volume = {215},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422023636},
	doi = {10.1016/j.eswa.2022.119345},
	language = {en},
	urldate = {2023-10-02},
	journal = {Expert Systems with Applications},
	author = {Niloofar, Parisa and Lazarova-Molnar, Sanja},
	month = apr,
	year = {2023},
	pages = {119345},
}

@techreport{noauthor_analysis_2020,
	title = {Analysis of {Nuclear} {Fuel} {Availability} at the {EU} {Level} from a {Security} of {Supply} {Perspective}.pdf},
	number = {MJ0320183ENN},
	institution = {Euratom Supply Agency},
	month = mar,
	year = {2020},
}

@book{tsoulfanidis_nuclear_2013,
	address = {New York, NY},
	title = {Nuclear {Energy}: {Selected} {Entries} from the {Encyclopedia} of {Sustainability} {Science} and {Technology}},
	isbn = {978-1-4614-5715-2 978-1-4614-5716-9},
	shorttitle = {Nuclear {Energy}},
	url = {https://link.springer.com/10.1007/978-1-4614-5716-9},
	language = {en},
	urldate = {2023-09-25},
	publisher = {Springer New York},
	editor = {Tsoulfanidis, Nicholas},
	year = {2013},
	doi = {10.1007/978-1-4614-5716-9},
}

@book{lee_risk_2012,
	title = {Risk and {Safety} {Analysis} of {Nuclear} {Systems}},
	isbn = {978-1-118-04345-5},
	abstract = {The book has been developed in conjunction with NERS 462, a course offered every year to seniors and graduate students in the University of Michigan NERS program. The first half of the book covers the principles of risk analysis, the techniques used to develop and update a reliability data base, the reliability of multi-component systems, Markov methods used to analyze the unavailability of systems with repairs, fault trees and event trees used in probabilistic risk assessments (PRAs), and failure modes of systems. All of this material is general enough that it could be used in non-nuclear applications, although there is an emphasis placed on the analysis of nuclear systems. The second half of the book covers the safety analysis of nuclear energy systems, an analysis of major accidents and incidents that occurred in commercial nuclear plants, applications of PRA techniques to the safety analysis of nuclear power plants (focusing on a major PRA study for five nuclear power plants), practical PRA examples, and emerging techniques in the structure of dynamic event trees and fault trees that can provide a more realistic representation of complex sequences of events. The book concludes with a discussion on passive safety features of advanced nuclear energy systems under development and approaches taken for risk-informed regulations for nuclear plants.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Lee, John C. and McCormick, Norman J.},
	month = jan,
	year = {2012},
	note = {Google-Books-ID: mB5rLNJH534C},
	keywords = {Arjun's Library - Physical Copy, Science / Chemistry / General, Technology \& Engineering / Chemical \& Biochemical},
}

@misc{hiranuma_overview_2017,
	address = {Vienna, Austria},
	title = {Overview of {Guidelines} on {Technical} {Safety} {Review} {Services} for {Accident} {Management}},
	author = {Hiranuma, Naoki},
	year = {2017},
}

@misc{harter_organizational_2017,
	address = {Vienna, Austria},
	title = {Organizational {Aspects} of {SAMG} {Implementation}},
	author = {Harter, Roy},
	year = {2017},
}

@techreport{brown_artificial_2022,
	title = {Artificial {Intelligence} for {Accelerating} {Nuclear} {Applications}, {Science}, and {Technology}},
	url = {https://www.osti.gov/servlets/purl/1913826/},
	language = {en},
	number = {BNL-223196-2022-INRE, 1913826},
	urldate = {2023-09-21},
	author = {Brown, David},
	month = jul,
	year = {2022},
	doi = {10.2172/1913826},
	pages = {BNL--223196--2022--INRE, 1913826},
}

@article{huang_review_2023,
	title = {A review of the application of artificial intelligence to nuclear reactors: {Where} we are and what's next},
	volume = {9},
	issn = {24058440},
	shorttitle = {A review of the application of artificial intelligence to nuclear reactors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844023010903},
	doi = {10.1016/j.heliyon.2023.e13883},
	abstract = {As a form of clean energy, nuclear energy has unique advantages compared to other energy sources in the present era, where low-carbon policies are being widely advocated. The expo­ nential growth of artificial intelligence (AI) technology in recent decades has resulted in new opportunities and challenges in terms of improving the safety and economics of nuclear reactors. This study briefly introduces modern AI algorithms such as machine learning, deep learning, and evolutionary computing. Furthermore, several studies on the use of AI techniques for nuclear reactor design optimization as well as operation and maintenance (O\&M) are reviewed and discussed. The existing obstacles that prevent the further fusion of AI and nuclear reactor tech­ nologies so that they can be scaled to real-world problems are classified into two categories: (1) data issues: insufficient experimental data increases the possibility of data distribution drift and data imbalance; (2) black-box dilemma: methods such as deep learning have poor interpretability. Finally, this study proposes two directions for the future fusion of AI and nuclear reactor tech­ nologies: (1) better integration of domain knowledge with data-driven approaches to reduce the high demand for data and improve the model performance and robustness; (2) promoting the use of explainable artificial intelligence (XAI) technologies to enhance the transparency and reli­ ability of the model. In addition, causal learning warrants further attention owing to its inherent ability to solve out-of-distribution generalization (OODG) problems.},
	language = {en},
	number = {3},
	urldate = {2023-09-21},
	journal = {Heliyon},
	author = {Huang, Qingyu and Peng, Shinian and Deng, Jian and Zeng, Hui and Zhang, Zhuo and Liu, Yu and Yuan, Peng},
	month = mar,
	year = {2023},
	pages = {e13883},
}

@misc{noauthor_my_nodate,
	title = {My {Devices}},
	url = {https://veepn.com/account/device/},
	urldate = {2023-09-20},
}

@article{research_our_2022,
	title = {From {Our} {Perspective}: {FDA}’s {Role} in {Helping} a {Critical} {Medical} {Isotope} {Meet} {Sufficient} {Supply} in the {US} for {First} {Time}},
	shorttitle = {From {Our} {Perspective}},
	url = {https://www.fda.gov/drugs/news-events-human-drugs/our-perspective-fdas-role-helping-critical-medical-isotope-meet-sufficient-supply-us-first-time},
	abstract = {Recently FDA’s Center for Drug Evaluation and Research (CDER) and the U.S. Department of Energy’s (DOE) National Nuclear Security Administration (NNSA) recognized that the U.S. has reached a sufficient supply of Molybdenum 99 (Mo-99).},
	language = {en},
	urldate = {2023-09-19},
	journal = {FDA},
	author = {Research, Center for Drug Evaluation and},
	month = may,
	year = {2022},
	note = {Publisher: FDA},
}

@misc{noauthor_triso_nodate,
	title = {{TRISO} {Particles}: {The} {Most} {Robust} {Nuclear} {Fuel} on {Earth}},
	shorttitle = {{TRISO} {Particles}},
	url = {https://www.energy.gov/ne/articles/triso-particles-most-robust-nuclear-fuel-earth},
	abstract = {TRISO particles cannot melt in a reactor and can withstand extreme temperatures that are well beyond the threshold of current nuclear fuels.},
	language = {en},
	urldate = {2023-09-19},
	journal = {Energy.gov},
}

@techreport{dauer_deterministic_2005,
	title = {Deterministic {Safety} {Analysis} for {Nuclear} {Power} {Plants}},
	shorttitle = {Preparedness and {Response} for a {Nuclear} or {Radiological} {Emergency}},
	url = {http://journals.lww.com/00004032-200502000-00010},
	language = {en},
	urldate = {2023-08-04},
	author = {Dauer, Lawrence T.},
	month = feb,
	year = {2005},
	pages = {175--176},
}

@article{mohaghegh_incorporating_2009,
	title = {Incorporating organizational factors into probabilistic risk assessment of complex socio-technical systems: {Principles} and theoretical foundations},
	volume = {47},
	issn = {09257535},
	shorttitle = {Incorporating organizational factors into probabilistic risk assessment of complex socio-technical systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753508002245},
	doi = {10.1016/j.ssci.2008.12.008},
	abstract = {The current generation of Probabilistic Risk Analysis (PRA), particularly those for technical systems, does not include an explicit representation of the possible impacts of organization and management on the safety performance of equipment and personnel. There are a number of technical challenges in developing a predictive model of organizational safety performance. There is a need for a widely accepted and theoretically sound set of principles on which models of organizational inﬂuences could be developed and validated. As a result of a multidisciplinary effort, this paper explores the feasibility of developing such principles and proposes a set of principles for organizational safety risk analysis. Then, as a realization of the proposed modeling principles, a safety risk framework, named Socio-Technical Risk Analysis (SoTeRiA), is developed. SoTeRiA formally integrates the technical system risk models with the social (safety culture and safety climate) and structural (safety practices) aspects of safety prediction models, and provides a theoretical basis for the integration. A systematic view of safety culture and safety climate leaves an important gap in modeling complex system safety risk, and SoTeRiA, describing the relationship between these two concepts, bridges this gap. The framework explicitly recognizes the relationship among constructs at multiple levels of analysis, and extends the PRA framework to include the effects of organizational factors in a more comprehensive and defensible way.},
	language = {en},
	number = {8},
	urldate = {2023-01-11},
	journal = {Safety Science},
	author = {Mohaghegh, Zahra and Mosleh, Ali},
	month = oct,
	year = {2009},
	pages = {1139--1158},
}

@article{fernandez-moguel_updated_2019,
	title = {Updated analysis of {Fukushima} unit 3 with {MELCOR} 2.1. {Part} 1: {Thermal}-hydraulic analysis},
	volume = {123},
	issn = {03064549},
	shorttitle = {Updated analysis of {Fukushima} unit 3 with {MELCOR} 2.1. {Part} 1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645491830481X},
	doi = {10.1016/j.anucene.2018.09.008},
	abstract = {The accident sequence of Fukushima Unit 3 was analysed with MELCOR 2.1. Hundreds of calculations have been performed and three plausible scenarios which predicted remarkably well the main signatures (i.e. pressure in RPV and containment and containment water level) have been selected and studied in the present analysis.},
	language = {en},
	urldate = {2023-08-08},
	journal = {Annals of Nuclear Energy},
	author = {Fernandez-Moguel, L. and Rydl, A. and Lind, T.},
	month = jan,
	year = {2019},
	pages = {59--77},
}

@article{fernandez-moguel_updated_2019-1,
	title = {Updated analysis of {Fukushima} {Unit} 3 with {MELCOR} 2.1. {Part} 2: {Fission} product release and transport analysis},
	volume = {130},
	issn = {03064549},
	shorttitle = {Updated analysis of {Fukushima} {Unit} 3 with {MELCOR} 2.1. {Part} 2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454919300878},
	doi = {10.1016/j.anucene.2019.02.017},
	abstract = {The ﬁssion product release and transport during the accident of Fukushima Daiichi Unit 3 was analysed in the present paper as a complement to the thermal-hydraulic analysis presented in the ﬁrst part of the present study, where three sequences obtained with MELCOR 2.1. were evaluated.},
	language = {en},
	urldate = {2023-08-08},
	journal = {Annals of Nuclear Energy},
	author = {Fernandez-Moguel, L. and Rydl, A. and Lind, T.},
	month = aug,
	year = {2019},
	pages = {93--106},
}

@article{sow_experimental_2019,
	title = {Experimental study of aerosol release following liquid leaks of fission products concentrates simulants},
	volume = {341},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318304072},
	doi = {10.1016/j.nucengdes.2018.09.034},
	abstract = {This article presents an experimental study that encompasses a need for nuclear safety on the consequences of a leakage of fission products (FP) concentrates in a failed vessel during spent fuel reprocessing operations. Particulate airborne release fractions (ARFs), as the result of liquid FP simulants impacting a rigid surface, were assessed for two circular leakage geometries of 1 and 2 mm diameter. The detailed analysis of these ARFs which are between 2.7 × 10−5 and 5.2 × 10−5 for the different experimental configurations revealed their dependence on the surface tension and the viscosity of the solutions, as well as on the impacting jet diameter. The study also makes it possible to develop an empirical correlation that links the ARFs with the dimensionless Ohnesorge and Weber numbers in the considered surface tension and viscosity range.},
	language = {en},
	urldate = {2023-08-08},
	journal = {Nuclear Engineering and Design},
	author = {Sow, Mamadou and Leblois, Yohan and Gensdarmes, François},
	month = jan,
	year = {2019},
	pages = {46--55},
}

@misc{noauthor_duke_nodate-1,
	title = {Duke {Energy} {Supplier} {Management} {Program}},
	url = {https://pages.avetta.com/DUKE-ENERGY},
	urldate = {2023-09-18},
}

@techreport{european_commission_joint_research_centre_current_2020,
	address = {LU},
	title = {Current challenges of the {European} nuclear supply chain.},
	url = {https://data.europa.eu/doi/10.2760/23903},
	language = {en},
	urldate = {2023-09-18},
	institution = {Publications Office},
	author = {{European Commission. Joint Research Centre.}},
	year = {2020},
}

@article{noauthor_procurement_nodate,
	title = {Procurement {Engineering} and {Supply} {Chain} {Guidelines} in {Support} of {Operation} and {Maintenance} of {Nuclear} {Facilities}},
	language = {en},
}

@misc{noauthor_microreactors_nodate,
	title = {Microreactors},
	url = {https://inl.gov/trending-topics/microreactors/},
	abstract = {Idaho National Laboratory {\textbar} Microreactors},
	language = {en-US},
	urldate = {2023-09-15},
	journal = {Idaho National Laboratory},
}

@incollection{schneider_world_2021,
	title = {The {World} {Nuclear} {Industry} {Status} {Report} 2019},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789811213953_0021},
	language = {en},
	urldate = {2023-09-06},
	author = {Schneider, Mycle and Froggatt, Antony},
	month = may,
	year = {2021},
	doi = {10.1142/9789811213953_0021},
	pages = {203--209},
}

@misc{noauthor_nuclear_nodate,
	title = {Nuclear energy and climate change - {World} {Nuclear} {Association}},
	url = {https://world-nuclear.org/nuclear-essentials/how-can-nuclear-combat-climate-change.aspx},
	urldate = {2023-09-06},
}

@book{european_commission_joint_research_centre_current_2020-1,
	address = {LU},
	title = {Current challenges of the {European} nuclear supply chain.},
	url = {https://data.europa.eu/doi/10.2760/23903},
	language = {en},
	urldate = {2023-09-06},
	publisher = {Publications Office},
	author = {{European Commission. Joint Research Centre.}},
	year = {2020},
}

@techreport{lohse_advanced_2023,
	title = {Advanced {Reactor} {Supply} {Chain} {Assessment} ({GAIN} {Report})},
	url = {https://www.osti.gov/servlets/purl/1973747/},
	language = {en},
	number = {INL/RPT-23-70928-Rev000, 1973747},
	urldate = {2023-09-06},
	author = {Lohse, Christopher and Abou Jaoude, Abdalla and Jenson, William and Prado, Ian},
	month = apr,
	year = {2023},
	doi = {10.2172/1973747},
	pages = {INL/RPT--23--70928--Rev000, 1973747},
}

@misc{noauthor_nuclear_2021,
	type = {Text},
	title = {Nuclear {Power} {Supply} {Chain} {Eyes} {New} {Avenues} of {Success} as {Global} {Markets} {Shift}},
	url = {https://www.iaea.org/newscenter/news/nuclear-power-supply-chain-eyes-new-avenues-of-success-as-global-markets-shift},
	language = {en},
	urldate = {2023-09-06},
	month = sep,
	year = {2021},
	note = {Publisher: IAEA},
}

@article{wakefield_unified_nodate,
	title = {A {Unified} {Approach} to {PSA} {Accident} {Sequence} {Model} {Quantification}},
	abstract = {Existing, fault tree linking models and large, event tree linking models for nuclear power plants are so large that they challenge computer memory limits and/or require excessive run times to fully quantify at the frequency cut-offs required for convergence. In some software quantification tools, the amount of frequency cut-off is not known, and for others, the sheer size of the models becomes unwieldy. The conceptual approach described here is to make use of Monte Carlo simulation. The simulation is one which treats a series of initiating event challenges to the logic model as constants and each challenge assesses whether the logic model end states are true or not. The logic model may be a single fault tree, a single event tree with branch probabilities, or a combination of fault trees and event trees. The outcomes of each challenge are tallied at the end of the simulation to obtain conditional end state probabilities and then combined with the initiating event frequencies to obtain accident sequence frequencies. Quantification cut-offs are not used for this approach and there are no restrictions on the use of NOT gates. Convergence of the Monte Carlo simulation would be the main issue.},
	language = {en},
	author = {Wakefield, Donald J and Lin, James C},
}

@article{siu_dynamic_nodate,
	title = {Dynamic {PRA}: {The} vision and a peek under the hood},
	abstract = {The term “Dynamic PRA” sparks many reactions within the PRA community. This seminar provides a high-level view of dynamic PRA (what is it? why is it of interest? what are the general characteristics of current approaches and activities?) and a more detailed look at key issues likely to be of interest to NRC reviewers.},
	language = {en},
	author = {Siu, N and Coyne, K},
}

@article{wiltbank_dynamic_2021,
	title = {Dynamic {PRA} {Prospects} for the {Nuclear} {Industry}},
	volume = {9},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/articles/10.3389/fenrg.2021.750453},
	abstract = {This review paper highlights approaches and tools available to the nuclear industry for dynamic probabilistic risk assessment (DPRA) using dynamic event trees. DPRA is an emerging methodology that has advantages as compared to traditional, static PRA predominantly owing to the addition of time dependent modeling. Traditional PRAs predefine events and outcomes into Event Trees (ET) and Fault Trees (FT), that are coupled with various combinations of Initiating Events (IE), Top Events (TE), branches, end states and sequences. A more complete depiction of the system and accident progression behavior can be quantified using DPRA to account for dynamic events such as those involving human actions. This paper discusses the strengths and needs of existing DPRA tools to align with the risk informed methodology currently used in the nuclear industry. DPRA is evolving during an exciting time in the nuclear industry with emerging advanced reactor designs also coming on the scene. Advanced nuclear (Gen IV) designs often incorporate passively safe systems that have less readily available data for traditional PRA due to their limited operating history. DPRA is a promising methodology that can address this challenge and demonstrate to the regulatory bodies and public that advanced designs operate within safety margins. In this light, the paper considers the historical role of PRA in the nuclear industry and motivation for considering dynamic PRA models. An introduction to the differences inherent in DPRA and how it complements and enhances existing PRA approaches is discussed. Additionally, a review of research from U.S national laboratories and universities features recent DPRA tool advancements that could be applied in the nuclear industry. These DPRA approaches and tools are summarized and examined to thoughtfully provide a path forward to best leverage existing research and integrate DPRA into advanced reactor design and analysis.},
	urldate = {2023-08-31},
	journal = {Frontiers in Energy Research},
	author = {Wiltbank, Nathan E. and Palmer, Camille J.},
	year = {2021},
}

@misc{noauthor_emrald_nodate,
	title = {{EMRALD} - {Overview}},
	url = {https://emrald.inl.gov:443/SitePages/Overview.aspx},
	language = {en-US},
	urldate = {2023-08-31},
}

@article{liu_brief_2012,
	title = {A brief introduction to grey systems theory},
	volume = {2},
	issn = {2043-9377},
	url = {https://doi.org/10.1108/20439371211260081},
	doi = {10.1108/20439371211260081},
	abstract = {Purpose– The purpose of this paper is to introduce the elementary concepts and fundamental principles of grey systems and the main components of grey systems theory. Also to discuss the astonishing progress that grey systems theory has made in the world of learning and its wide‐ranging applications in the entire spectrum of science.Design/methodology/approach– The characteristics of unascertained systems including incomplete information and inaccuracies in data are analysed and four uncertain theories: probability statistics, fuzzy mathematics, grey system and rough set theory are compared. The scientific principle of simplicity and how precise models suffer from inaccuracies are also shown.Findings– The four uncertain theories, probability statistics, fuzzy mathematics, grey system and rough set theory are examined with different research objects, different basic sets, different methods and procedures, different data requirements, different emphasis, different objectives and different characteristics.Practical implications– The scientific principle of simplicity and how precise models suffer from inaccuracies are shown. So, precise models are not necessarily an effective means to deal with complex matters, especially in the case that the available information is incomplete and the collected data inaccurate.Originality/value– The elementary concepts and fundamental principles of grey systems and the main components of grey systems theory are introduced briefly. The reader is given a general picture of grey systems theory as a new method for studying problems where partial information is known, partial information is unknown; especially for uncertain systems with few data points and poor information.},
	number = {2},
	urldate = {2023-08-28},
	journal = {Grey Systems: Theory and Application},
	author = {Liu, Sifeng and Forrest, Jeffrey and Yang, Yingjie},
	month = jan,
	year = {2012},
	note = {Publisher: Emerald Group Publishing Limited},
	pages = {89--104},
}

@book{zsidisin_supply_2009,
	address = {Boston, MA},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {Supply {Chain} {Risk}: {A} {Handbook} of {Assessment}, {Management}, and {Performance}},
	volume = {124},
	isbn = {978-0-387-79933-9 978-0-387-79934-6},
	shorttitle = {Supply {Chain} {Risk}},
	url = {http://link.springer.com/10.1007/978-0-387-79934-6},
	language = {en},
	urldate = {2023-08-28},
	publisher = {Springer US},
	editor = {Zsidisin, George A. and Ritchie, Bob and Hillier, Frederick S.},
	year = {2009},
	doi = {10.1007/978-0-387-79934-6},
}

@article{majumdar_analysing_2021,
	title = {Analysing the vulnerability of green clothing supply chains in {South} and {Southeast} {Asia} using fuzzy analytic hierarchy process},
	volume = {59},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2019.1708988},
	doi = {10.1080/00207543.2019.1708988},
	abstract = {Various risks related to green clothing supply chains of South and Southeast Asian countries have been quantified based on their impact and probability of occurrence. Risks were classified into five categories, namely supply risks, demand risks, process or operation risks, business environment risks and financial risks. These risks were further divided into 18 specific risks. The fuzzy analytic hierarchy process (FAHP) was used to incorporate the vagueness of perception of experts regarding the impact of various supply chain risks. The probability of various risks was quantified by capturing the experts’ opinion using fuzzy numbers. Financial and business environment-related risks were found to have high impact whereas supply, demand and process-related risks have a high probability of occurrence in green clothing supply chain. Finally, a vulnerability matrix was developed where each specific risk was mapped based on their respective impact and probability. The outcome of this research would be very helpful for developing strategies for resilient green clothing supply chains in South and Southeast Asia. This would further drive the implementation of green clothing supply chain management practices in this geographic region.},
	number = {3},
	urldate = {2023-08-26},
	journal = {International Journal of Production Research},
	author = {Majumdar, Abhijit and Sinha, Sanjib Kumar and Shaw, Mahesh and Mathiyazhagan, K.},
	month = feb,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2019.1708988},
	keywords = {clothing supply chain, fuzzy analytic hierarchy process, green supply chain management, supply chain risks, vulnerability},
	pages = {752--771},
}

@article{earthperson_integrating_2023,
	title = {Integrating {Commercial}-{Off}-{The}-{Shelf} {Components} into {Radiation}-{Hardened} {Drone} {Designs} for {Nuclear}-{Contaminated} {Search} and {Rescue} {Missions}},
	volume = {7},
	issn = {2504-446X},
	url = {https://www.mdpi.com/2504-446X/7/8/528},
	doi = {10.3390/drones7080528},
	abstract = {This paper conducts a focused probabilistic risk assessment (PRA) on the reliability of commercial off-the-shelf (COTS) drones deployed for surveillance in areas with diverse radiation levels following a nuclear accident. The study employs the event tree/fault tree digraph approach, integrated with the dual-graph error propagation method (DEPM), to model sequences that could lead to loss of mission (LOM) scenarios due to combined hardware–software failures in the drone’s navigation system. The impact of radiation is simulated by a comparison of the total ionizing dose (TID) with the acceptable limit for each component. Errors are then propagated within the electronic hardware and software blocks to determine the navigation system’s reliability in different radiation zones. If the system is deemed unreliable, a strategy is suggested to identify the minimum radiation-hardening requirement for its subcomponents by reverse-engineering from the desired mission success criteria. The findings of this study can aid in the integration of COTS components into radiation-hardened (RAD-HARD) designs, optimizing the balance between cost, performance, and reliability in drone systems for nuclear-contaminated search and rescue missions.},
	language = {en},
	number = {8},
	urldate = {2023-08-18},
	journal = {Drones},
	author = {Earthperson, Arjun and Diaconeasa, Mihai A.},
	month = aug,
	year = {2023},
	pages = {528},
}

@book{thakkar_multi-criteria_2021,
	address = {Singapore},
	series = {Studies in {Systems}, {Decision} and {Control}},
	title = {Multi-{Criteria} {Decision} {Making}},
	volume = {336},
	isbn = {978-981-334-744-1 978-981-334-745-8},
	url = {https://link.springer.com/10.1007/978-981-33-4745-8},
	language = {en},
	urldate = {2023-08-17},
	publisher = {Springer Singapore},
	author = {Thakkar, Jitesh J.},
	year = {2021},
	doi = {10.1007/978-981-33-4745-8},
}

@article{lei_assessing_2019,
	title = {Assessing risk in different types of supply chains with a dynamic fault tree},
	volume = {137},
	issn = {0360-8352},
	url = {https://www.sciencedirect.com/science/article/pii/S0360835219305200},
	doi = {10.1016/j.cie.2019.106061},
	abstract = {Supply chain risk analysis is an important field in operations management and logistics. Identifying those risks, assessing the probability of those risks, and understanding how those risks change if mitigation strategies are implemented contribute to better supply chain risk management. Reliability analysis has a long tradition of assessing the probability of failure, and fault trees are typically used to understand how the failure of individual components can lead to system failure within an engineered system. More recently, fault trees have been proposed to assess the probability of a supply chain failure. Dynamic fault trees, which are relatively new in reliability analysis, model the dependency among possible component failure and how these probabilities change over time. This paper applies dynamic fault trees to model supply chain risk for different types of supply chains. The dynamic fault tree allows a firm to model complex interactions among suppliers and understand how those interactions impact its risk. The model incorporates an information system that relays information about the status of suppliers to the firm, and this information system could also fail. A Markov chain model and Monte Carlo simulation are used to numerically assess supply chain risk as modeled by these dynamic fault trees.},
	urldate = {2023-08-14},
	journal = {Computers \& Industrial Engineering},
	author = {Lei, Xue and MacKenzie, Cameron A.},
	month = nov,
	year = {2019},
	keywords = {Dynamic fault tree, Markov chain, Monte Carlo simulation, Risk analysis, Supply chain risk},
	pages = {106061},
}

@article{sherwin_proactive_2016,
	title = {Proactive cost-effective identification and mitigation of supply delay risks in a low volume high value supply chain using fault-tree analysis},
	volume = {175},
	issn = {0925-5273},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527316000372},
	doi = {10.1016/j.ijpe.2016.02.001},
	abstract = {In this paper we use a well-accepted methodology, fault-tree analysis, to identify delay risks and proactively propose a cost-effective mitigation strategy within a low volume high value supply chain. The basis for the assessment is the bill of materials of the product being studied. The top-level event of interest represents the delay in delivering a product to a customer and lower-level events represent the probabilities associated with delays caused by quality and capability deficiencies within the supply chain of the product being studied. Supply chain risk mitigation strategies have been well documented in academic literature. However, much of what has been documented addresses such topics as facility location, inventory buffers, and is generally focused on response strategies once the risk has been realized. This paper presents a robust method to reduce the likelihood of delays in material flow by representing the system of suppliers within a supply chain as a fault-tree and proactively determining the optimum mitigation strategy for the portfolio. The approach is illustrated via real-world numerical scenarios based on hypothetical data sets and the results are presented.},
	urldate = {2023-08-14},
	journal = {International Journal of Production Economics},
	author = {Sherwin, Michael D. and Medal, Hugh and Lapp, Steven A.},
	month = may,
	year = {2016},
	keywords = {Fault-tree analysis, Risk mitigation, Supplier selection, Supply chain},
	pages = {153--163},
}

@inproceedings{bhardwaj_application_2020,
	title = {Application of {Fault} {Tree} {Analysis} and {Petri} {Net} {Modeling} in {Perishable} {Product} {Supply} {Chain}},
	doi = {10.1109/IEEM45057.2020.9309958},
	abstract = {In this paper, fault tree analysis (FTA) has been conducted to identify uncertainties in perishable product supply chain (PPSC). Supply chain of these products are complex in nature due to short-life cycle and uncertain behavior. Fault tree is a top-down approach and based on structural analysis we identified the basic events for uncertainty occurrence that leads to failure in PPSC. There are anomalies in FTA such as data explosion and non-diagnosis of dynamic nature. Petri Net (PN) modelling addresses these issues. Relational matrix analysis is applied to evaluate minimal cut sets (MCS) in fault tree which identifies the uncertainty in PPSC. PN establish state equation and initial token to identify faults mathematically and to improve efficiency of PPSC. Finally, using PPSC as an example, the proposed method proved to be effective.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Industrial} {Engineering} and {Engineering} {Management} ({IEEM})},
	author = {Bhardwaj, Manisha and Agrawal, Rajat},
	month = dec,
	year = {2020},
	keywords = {Explosions, Fault Tree Analysis, Fault trees, Logic gates, Mathematical model, Minimal Cut Set, Perishable Product Supply Chain, Petri Net, Petri nets, Relational Matrix, Supply chains, Uncertainty},
	pages = {1189--1193},
}

@article{kumar_before_2013,
	title = {Before and after disaster strikes: {A} relief supply chain decision support framework},
	volume = {145},
	issn = {0925-5273},
	shorttitle = {Before and after disaster strikes},
	url = {https://www.sciencedirect.com/science/article/pii/S0925527313002430},
	doi = {10.1016/j.ijpe.2013.05.016},
	abstract = {The potential and scope of damages resulting from large scale natural disasters is undisputed. Additionally, the risks that societies are facing continue to grow along with the global population. A decision support risk assessment and mitigation framework for disaster relief supply chain is proposed. This framework was applied to the example of the March 2011 disaster in Japan which was the result of a Tsunami, after a strong earthquake, followed by flooding and meltdown of multiple nuclear reactors. The evidence of relief supply chain effectiveness is examined and diagnosed in specific instances when the supply chain has failed to perform. Key stages are identified within the relief supply chain, and these stages are connected through communication and collaboration. By identifying and quantifying different risks under different stages in the supply chain using fault tree analysis and then imputing them into the model, the results are helpful in the decision making process. The failure mode effects and critical analysis method was used to assess the reliability of a relief supply chain system and its critical components. The research suggests the support for a network authority for utilizing diverse expertise for organizing the efficient relief supply chain. This structure makes use of the community relationships and trust that NGOs have built in areas throughout the world to aid in crises. The development of a robust communications plan and system will help coordination of all groups, prior to, during, and after a disaster, and will provide a more effective response.},
	number = {2},
	urldate = {2023-08-14},
	journal = {International Journal of Production Economics},
	author = {Kumar, Sameer and Havey, Thomas},
	month = oct,
	year = {2013},
	keywords = {Authority structure, Communication, Disaster preparedness, Failure mode effects and critical analysis (FMECA), Relief supply chain, Social media},
	pages = {613--629},
}

@inproceedings{xu_combining_2004,
	title = {Combining dynamic fault trees and event trees for probabilistic risk assessment},
	doi = {10.1109/RAMS.2004.1285450},
	abstract = {As system analysis methodologies, both event tree analysis (ETA) and fault tree analysis (FTA) are used in probabilistic risk assessment (PRA), especially in identifying system interrelationships due to shared events. Although there are differences between them, ETA and FTA, are so closely linked that fault trees (FT) are often used to quantify system events that are part of event tree (ET) sequences (J.D. Andrew et al., 2000). The logical processes employed to evaluate ET sequences and quantify the consequences are the same as those used in FTA. Although much work has been done to combine FT and ET, traditional methods only concentrate on combining static fault trees (SFT) and ET. Our main concern is considering how to combine dynamic fault trees (DFT) and ET. We proposed a reasonable approach in this paper, which is illustrated through a hypothetical example. Because of the complexity of dynamic systems, including the huge size and complicated dependencies, there may exist contradictions among different dynamic subsystems. The key benefit of our approach is that we avoid the generation of such contradictions in our model. Another benefit is that efficiency may be improved through modularization.},
	booktitle = {Annual {Symposium} {Reliability} and {Maintainability}, 2004 - {RAMS}},
	author = {Xu, Hong and Dugan, J.B.},
	month = jan,
	year = {2004},
	keywords = {Event detection, Fault trees, Hydrogen, Logic, Risk analysis, Risk management, Time of arrival estimation, Tree graphs, US Department of Transportation, Valves},
	pages = {214--219},
}

@article{sherwin_identifying_2020,
	title = {Identifying and mitigating supply chain risks using fault tree optimization},
	volume = {52},
	issn = {2472-5854},
	url = {https://doi.org/10.1080/24725854.2019.1630865},
	doi = {10.1080/24725854.2019.1630865},
	abstract = {Although supply chain risk management and supply chain reliability are topics that have been studied extensively, a gap exists for solutions that take a systems approach to quantitative risk mitigation decision making and especially in industries that present unique risks. In practice, supply chain risk mitigation decisions are made in silos and are reactionary. In this article, we address these gaps by representing a supply chain as a system using a fault tree based on the bill of materials of the product being sourced. Viewing the supply chain as a system provides the basis to develop an approach that considers all suppliers within the supply chain as a portfolio of potential risks to be managed. Next, we propose a set of mathematical models to proactively and quantitatively identify and mitigate at-risk suppliers using enterprise available data with consideration for a firm’s budgetary constraints. Two approaches are investigated and demonstrated on actual problems experienced in industry. The examples presented focus on Low-Volume High-Value (LVHV) supply chains that are characterized by long lead times and a limited number of capable suppliers, which make them especially susceptible to disruption events that may cause delays in delivered products and subsequently increase the financial risk exposure of the firm. Although LVHV supply chains are used to demonstrate the methodology, the approach is applicable to other types of supply chains as well. Results are presented as a Pareto frontier and demonstrate the practical application of the methodology.},
	number = {2},
	urldate = {2023-08-14},
	journal = {IISE Transactions},
	author = {Sherwin, Michael D. and Medal, Hugh R. and MacKenzie, Cameron A. and Brown, Kennedy J.},
	month = feb,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24725854.2019.1630865},
	keywords = {Supply chain management, fault tree, optimization, risk},
	pages = {236--254},
}

@misc{noauthor_identifying_nodate,
	title = {Identifying and mitigating supply chain risks using fault tree optimization},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/24725854.2019.1630865?needAccess=true&role=button},
	language = {en},
	urldate = {2023-08-14},
	note = {ISSN: 2472-5854},
}

@inproceedings{liu_research_2018,
	address = {Singapore},
	series = {Uncertainty and {Operations} {Research}},
	title = {Research on {Supply} {Chain} {Risk} {Assessment} {Based} on {FMEA}},
	isbn = {978-981-10-7817-0},
	doi = {10.1007/978-981-10-7817-0_9},
	abstract = {In the information, under the background of globalization, great changes have taken place in the internal and external environment, in order to make the supply chain more lean, the enterprises in the pursuit of efficiency and reduce the cost at the same time, it also increased its supply chain vulnerability and risk, when any one of the links in the supply chain are uncertain the resulting problems are extremely easy to cause the collapse of supply chain operations or obstacles. In order to control and reduce the impact of supply chain uncertainties, reduce supply chain risk and loss caused by out of control, based on the risk assessment concepts and ideas as a guide, try to be a potential failure mode and effects analysis (FMEA) is introduced into the supply chain risk analysis, in order to evaluate the quality of the supply chain, reduce the supply of analysis method a quantitative risk brought by uncertainty.},
	language = {en},
	booktitle = {Proceedings of the {Fifth} {International} {Forum} on {Decision} {Sciences}},
	publisher = {Springer},
	author = {Liu, Shi-Ming and Chen, Hui-hong},
	editor = {Li, Xiang and Xu, Xiaofeng},
	year = {2018},
	keywords = {Detection degree, FMEA, Risk assessment, Supply chain},
	pages = {79--88},
}

@book{li_proceedings_2018,
	address = {Singapore},
	series = {Uncertainty and {Operations} {Research}},
	title = {Proceedings of the {Fifth} {International} {Forum} on {Decision} {Sciences}},
	isbn = {978-981-10-7816-3 978-981-10-7817-0},
	url = {http://link.springer.com/10.1007/978-981-10-7817-0},
	language = {en},
	urldate = {2023-08-14},
	publisher = {Springer Singapore},
	editor = {Li, Xiang and Xu, Xiaofeng},
	year = {2018},
	doi = {10.1007/978-981-10-7817-0},
}

@article{pandey_fmea-based_2017,
	title = {{FMEA}-based interpretive structural modelling approach to model automotive supply chain risk},
	volume = {27},
	issn = {1742-7967},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJLSM.2017.085221},
	doi = {10.1504/IJLSM.2017.085221},
	abstract = {The purpose of this study is to analyse and model various risks which may disrupt the automotive supply chain. For illustration, an automotive supply chain of tractor manufacturing company has been undertaken, 17 potential modes of failures or risk sources are identified through close scrutiny of literature and weighted risk priority numbers (WRPN) have been calculated. Out of these 17 failure modes, 11 are selected as key learning's (by performing SAP-LAP analysis) based upon higher WRPN numbers. Further to model the structural relationship among these key risks interpretive structural modelling (ISM) approach is used. In order to find out the driving power and dependency of risks MICMAC analysis has been performed. The results of the study demonstrate that the variables, i.e., poor planning and scheduling and hazards are the key risk variables (highest driving power) and can be considered as the root cause of the problem. Quality risk, inventory risk and outsourcing risk have strong dependence power and hence can be considered as the most important risks and management shall focus on these for the managing the disruptions in an automotive supply chain.},
	number = {4},
	urldate = {2023-08-14},
	journal = {International Journal of Logistics Systems and Management},
	author = {Pandey, Ajay Kumar and Sharma, Rajiv Kumar},
	month = jan,
	year = {2017},
	note = {Publisher: Inderscience Publishers},
	keywords = {FMEA, ISM, automotive supply chain, case study, failure modes and effect analysis, interpretive structural modelling},
	pages = {395--419},
}

@article{sandito_supply_2022,
	title = {Supply {Chain} {Risk} {Management} in {Newspaper} {Printing} {Using} {FMEA} and {FTA} {Methods}: {A} {Case} {Study}},
	abstract = {In the newspaper supply chain, the printing process, the procurement of paper, ink, and printing plates to the distribution of newspapers to consumers are the main business processes. The risk involved in the supply chain of the newspaper industry is particularly large. Supply chain risk management is used to identify and mitigate the negative impacts of supply chain performance. This study aims to identify operational risks in the newspaper supply chain using the Failure Mode and Effect Analysis (FMEA) and Fault Tree Analysis (FTA) methods and create alternative mitigation strategies. Risk measurement in FMEA is done by using a risk matrix, namely the Risk Priority Number (RPN). As a result, 27 operational risks have the potential to disrupt the newspaper printing process, with critical risks occurring in the newspaper delivery process. Then identify the factors causing the critical risk from the top event to the root cause of the risk (basic event). The results received are the causes of risk in the form of error splicing, unstable roller, inaccurate plate, unpredictable weather, lack of worker skills, pests and diseases, purchase forecast error, old transport, and traffic jam.},
	language = {en},
	author = {Sandito, Aqshal Raffa and Rahma, Dina Nurfitri and Tyastuti, Niken Utami and Putri, Arinda Soraya and Sutopo, Wahyudi},
	year = {2022},
}

@article{ghadge_supply_2017,
	title = {Supply chain risk assessment approach for process quality risks},
	volume = {34},
	issn = {0265-671X},
	url = {https://doi.org/10.1108/IJQRM-01-2015-0010},
	doi = {10.1108/IJQRM-01-2015-0010},
	abstract = {Purpose The purpose of this paper is to proactively analyse and mitigate the root causes of the product and security risks. The case study approach examines the effectiveness of the fuzzy logic approach for assessing the product and process-related failure modes within global supply chain context. Design/methodology/approach The case study of a Printed Circuit Board Company in China is used as a platform for conducting the research. Using data triangulation, the data are collected and analyzed through interviews, questionnaires, expert opinions and quantitative modelling for some interesting insights. Findings Fuzzy logic approach for failure mode and effect analysis (FMEA) provides a structured approach for understanding complex behaviour of failure modes and their associated risks for products and processes. Today’s managers should conduct robust risk assessment during the design stage to avoid product safety and security risks such as recalls. Research limitations/implications The research is based on the single case study and multiple cases from different industry sectors may provide some additional insights. Originality/value The study attempts to mitigate the root causes of product and processes using fuzzy approach to FMEA in supply chain network.},
	number = {7},
	urldate = {2023-08-14},
	journal = {International Journal of Quality \& Reliability Management},
	author = {Ghadge, Abhijeet and Fang, Xie and Dani, Samir and Antony, Jiju},
	month = jan,
	year = {2017},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Case study, FMEA, Fuzzy logic, Risk mitigation, Supply chain risk},
	pages = {940--954},
}

@inproceedings{guo_preliminary_2012,
	address = {Berlin, Heidelberg},
	series = {Advances in {Intelligent} and {Soft} {Computing}},
	title = {Preliminary {Study} on {Reliability} {Analysis} of {Safety} {I}\&{C} {System} in {NPP}},
	isbn = {978-3-642-28314-7},
	doi = {10.1007/978-3-642-28314-7_41},
	abstract = {Digital instrumentation and control (I\&C) systems, such as digital Reactor Protection System (RPS), are being employed gradually at newly-built and upgraded Nuclear Power Plants (NPPs). The reliability analysis of digital I\&C system turns to be a research focus. This paper proposes a preliminary study on reliability analysis for the digital RPS of High Temperature Gas-Cooled Reactor-Pebble bed Module (HTR-PM). We first introduce the function and structure of RPS in HTR-PM; then the processes of failure mode and effect analysis (FMEA) at system level are given; finally we present the FMEA of a computer device as an example and introduce the future work. This study analyses all possible safety-relevant implications arising from failures in RPS and promotes the reliability analysis of the digital RPS in HTR-PM.},
	language = {en},
	booktitle = {Proceedings of the 2011 2nd {International} {Congress} on {Computer} {Applications} and {Computational} {Science}},
	publisher = {Springer},
	author = {Guo, Chao and Li, Duo and Xiong, Huasheng},
	editor = {Gaol, Ford Lumban and Nguyen, Quang Vinh},
	year = {2012},
	keywords = {digital reactor protection system, failure mode and effect analysis, nuclear power plant, reliability},
	pages = {303--310},
}

@article{noauthor_nuregia-0254_nodate,
	title = {{NUREG}/{IA}-0254, "{International} {Agreement} {Report}, {Suitability} of {Fault} {Modes} and {Effects} {Analysis} for {Regulatory} {Assurance} of {Complex} {Logic} in {Digital} {Instrumentation} and {Control} {Systems}."},
	language = {en},
}

@misc{maioli_westinghouse_2019,
	title = {Westinghouse {eVinci} {Micro}-{Reactor} {Licensing} {Modernization} {Project} {Demonstration}},
	url = {https://www.nrc.gov/docs/ML1922/ML19227A322.pdf},
	publisher = {Southern Company},
	author = {Maioli, Andrea and Detar, Heather and Haessler, Richard},
	month = aug,
	year = {2019},
}

@techreport{wakefield_example_2004,
	address = {Operational Risk and Performance Consulting Division, 300 Commerce Drive 200, Irvine, CA, 92602},
	title = {Example {Application} of {RISKMAN}®},
	url = {https://flightsafety.org/wp-content/uploads/2016/09/RISKMAN_application.pdf},
	language = {en},
	institution = {ABS Consulting, Inc.},
	author = {Wakefield, Donald},
	month = sep,
	year = {2004},
	pages = {10},
}

@article{erkut_modeling_1998,
	title = {Modeling of {Transport} {Risk} for {Hazardous} {Materials}},
	volume = {46},
	issn = {0030-364X, 1526-5463},
	url = {https://pubsonline.informs.org/doi/10.1287/opre.46.5.625},
	doi = {10.1287/opre.46.5.625},
	abstract = {The transport of hazardous materials is an important strategic and tactical decision problem. Risks associated with this activity make transport planning difficult. Although most existing analytical approaches for hazardous materials transport account for risk, there is no agreement among researchers on how to model the associated risks. This paper provides an overview of the prevailing models, and addresses the question “Does it matter how we quantify transport risk?” Our empirical analysis on the U.S. road network suggests that different risk models usually select different “optimal” paths for a hazmat shipment between a given origin-destination pair. Furthermore, the optimal path for one model could perform very poorly under another model. This suggests that researchers and practitioners must pay considerable attention to the modeling of risks in hazardous materials transport.},
	language = {en},
	number = {5},
	urldate = {2023-08-04},
	journal = {Operations Research},
	author = {Erkut, Erhan and Verter, Vedat},
	month = oct,
	year = {1998},
	pages = {625--642},
}

@inproceedings{st_germain_nrc_2014,
	address = {Honolulu, O'ahu, Hawaii, USA},
	title = {{NRC} {Reactor} {Operating} {Experience} {Data}},
	author = {St. Germain, Shawn},
	month = jul,
	year = {2014},
}

@misc{noauthor_operating_nodate,
	title = {Operating {Experience} {Results} and {Databases}},
	url = {https://nrcoe.inl.gov/AvgPerf/},
	language = {en},
	urldate = {2023-08-01},
	journal = {NRC Web},
}

@article{vesely_uncertainties_1984,
	title = {Uncertainties in {Nuclear} {Probabilistic} {Risk} {Analyses}},
	volume = {4},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1984.tb00950.x},
	doi = {10.1111/j.1539-6924.1984.tb00950.x},
	language = {en},
	number = {4},
	urldate = {2023-08-01},
	journal = {Risk Analysis},
	author = {Vesely, W. E. and Rasmuson, D. M.},
	month = dec,
	year = {1984},
	pages = {313--322},
}

@book{kuo_optimal_2003,
	address = {Hoboken, N.J},
	title = {Optimal reliability modeling: principles and applications},
	isbn = {978-0-471-39761-8},
	shorttitle = {Optimal reliability modeling},
	publisher = {John Wiley \& Sons},
	author = {Kuo, Way and Zuo, Ming J.},
	year = {2003},
	keywords = {Mathematical models, Reliability (Engineering)},
}

@book{modarres_risk_2006,
	address = {Boca Raton},
	title = {Risk analysis in engineering: techniques, tools, and trends},
	isbn = {978-1-57444-794-1},
	shorttitle = {Risk analysis in engineering},
	publisher = {Taylor \& Francis},
	author = {Modarres, M.},
	year = {2006},
	note = {OCLC: ocm62533849},
	keywords = {Reliability (Engineering), Risk assessment, Technology},
}

@article{aven_risk_2016,
	title = {Risk assessment and risk management: {Review} of recent advances on their foundation},
	volume = {253},
	issn = {03772217},
	shorttitle = {Risk assessment and risk management},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221715011479},
	doi = {10.1016/j.ejor.2015.12.023},
	language = {en},
	number = {1},
	urldate = {2023-08-01},
	journal = {European Journal of Operational Research},
	author = {Aven, Terje},
	month = aug,
	year = {2016},
	pages = {1--13},
}

@book{haimes_risk_2009,
	address = {Hoboken, NJ},
	edition = {3rd ed},
	series = {Wiley series in systems engineering and management},
	title = {Risk modeling, assessment, and management},
	isbn = {978-0-470-28237-3},
	publisher = {John Wiley \& Sons},
	author = {Haimes, Yacov Y.},
	year = {2009},
	note = {OCLC: 232605676},
	keywords = {Case studies, Risk assessment, Risk management, Technology},
}

@misc{noauthor_ftrex_nodate,
	title = {{FTREX} 2.0 {User} {Manual}},
	url = {https://www.epri.com/research/programs/061177/results/3002018234},
	urldate = {2023-07-31},
}

@article{groth_hybrid_2010,
	title = {Hybrid causal methodology and software platform for probabilistic risk assessment and safety monitoring of socio-technical systems},
	volume = {95},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010001390},
	doi = {10.1016/j.ress.2010.06.005},
	language = {en},
	number = {12},
	urldate = {2023-07-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina and Wang, Chengdong and Mosleh, Ali},
	month = dec,
	year = {2010},
	pages = {1276--1285},
}

@article{wang_quantitative_2011,
	title = {Quantitative risk assessment through hybrid causal logic approach},
	volume = {225},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X10397370},
	doi = {10.1177/1748006X10397370},
	abstract = {In this paper, a hybrid causal logic (HCL) model is improved by mapping a fuzzy fault tree (FFT) into a Bayesian network (BN). The first step is to substitute an FFT for the traditional FT. The FFT is based on the Takagi–Sugeno model and the translation rules needed to convert the FFT into a BN are derived. The proposed model is demonstrated in a study of a fire hazard on an offshore oil production facility. It is clearly shown that the FFT can be directly converted into a BN and that the parameters of the FFT can be estimated more accurately using the basic inference techniques of a BN. The improved HCL approach is able to both accurately determine how failures cause an undesired problem using FFT and also model non-deterministic cause–effect relationships among system elements using the BN.},
	language = {en},
	number = {3},
	urldate = {2023-07-31},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Wang, Y-F and Xie, M and Habibullah, M S and Ng, K-M},
	month = sep,
	year = {2011},
	pages = {323--332},
}

@misc{noauthor_openepl_2023,
	title = {{OpenEPL} / {OpenEPL} {Engine} · {GitLab}},
	url = {https://gitlab.openpra.org/openepl/openepl-engine},
	abstract = {C++ implementation of the DEPM algorithm},
	language = {en},
	urldate = {2023-07-31},
	journal = {GitLab},
	month = may,
	year = {2023},
}

@article{groth_hybrid_2010-1,
	title = {Hybrid causal methodology and software platform for probabilistic risk assessment and safety monitoring of socio-technical systems},
	volume = {95},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010001390},
	doi = {10.1016/j.ress.2010.06.005},
	language = {en},
	number = {12},
	urldate = {2023-07-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina and Wang, Chengdong and Mosleh, Ali},
	month = dec,
	year = {2010},
	pages = {1276--1285},
}

@misc{vesely_prep_1997,
	title = {{PREP} {KITT}, {System} {Reliability} by {Fault} {Tree} {Analysis}. {PREP}, {Min} {Path} {Set} and {Min} {Cut} {Set} for {Fault} {Tree} {Analysis}, {Monte}-{Carlo} {Method}. {KITT}, {Component} and {System} {Reliability} {Information} from {Kinetic} {Fault} {Tree} {Theory}},
	author = {Vesely, W E,  and Narum, R E},
	month = mar,
	year = {1997},
}

@inproceedings{batikh_integrating_2023,
	address = {Knoxville, TN},
	title = {Integrating {Seismic} {Fragility} of {ASR}-{Affected} {Nuclear} {Containment} {Vessel} in a {Level}-{II} {SPRA} in {Support} of {Multi}-{Hazard} {Risk} {Assessment}},
	abstract = {In light of the Fukushima Daiichi accident in 2011, the incorporation of external multi-hazards in probabilistic risk assessments (PRAs) for nuclear power plants (NPPs) has become essential. However, a comprehensive PRA framework that accounts for all potential external multi-hazards has yet to be established. Our current research objective is to develop a time-dependent multi-hazard PRA approach that takes into account the deterioration of structures related to aging. The deterioration of concrete due to alkali silica reaction (ASR) is a well-known issue that affects concrete structures at different rates. Recently, there has been evidence of this deterioration in concrete structures in nuclear power plants, which could affect the seismic capacity of nuclear containment vessels. In this study, we aim at developing a framework for integrating the effects of ASR on the early release frequency of radionuclides from a generic pressurized water rector (PWR). A level-I PRA model was utilized for a generic (PWR) to estimate the frequencies of core damage at different levels of peak ground acceleration (PGA). The output of this analysis is assumed to be the initiating event in a simplified containment event tree (CET) where accident progression in the containment is tracked. The time-dependent ASR impact on the seismic capacity of the containment was captured using fault tree structure. The minimal cut sets for the CET were then quantified in SAPHIRE at each PGA level. The findings revealed a significant increase in Large Early Release Frequency (LERF) mean values at low PGA bins as ASR-induced degradation increases. A small increase in LERF was observed at intermediate PGA levels, while no increase was detected at high PGA level.},
	language = {en},
	author = {Batikh, Akram S and Dhulipala, Somayajulu L N and Spencer, Benjamin W and Dahal, Albert and Diaconeasa, Mihai A.},
	month = jul,
	year = {2023},
}

@inproceedings{farag_preliminary_2023,
	address = {Knoxville, TN},
	title = {Preliminary {Benchmarking} of {SAPHSOLVE}, {XFTA}, and {SCRAM} using {Synthetically} {Generated} {Fault} {Trees} with {Common} {Cause} {Failures}},
	abstract = {Nowadays, probabilistic risk assessment (PRA) has contributed prominently to many technological fields, assisting decision-makers and engineers in assessing and mitigating risks inherent in their systems and designs. In the nuclear industry, PRA has become crucial in all nuclear power plant (NPP) design stages, informing engineers and decision-makers to efficiently ensure the reliability and safety of their NPPs. However, significant computational resources are required to perform PRA with current legacy PRA tools, and their enhancement is indispensable. Event tree and fault tree analyses are the most utilized methods to perform PRA in various technological industries, including the nuclear and aerospace industries. These methods comprise different modeling and analysis techniques implemented by many commercial and research PRA tools, such as SAPHIRE with SAPHSOLVE executable engine, CAFTA with PRAQuant and FTREX engines, XFTA and SCRAM engines, and OpenPRA engine. In this study, we benchmark the accuracy and computational efficiency of SAPHSOLVE, XFTA, and SCRAM engines by developing synthetically generated fault trees with various specifications and levels of complexity to challenge these codes. We compare their accuracy in terms of failure probabilities and the number of minimal cut sets, their computational speed, and memory usage. Additionally, the study's results will be utilized to enhance the quantification approach and algorithm used in the open-source PRA tool (OpenPRA) that is under development by the PRA group at North Carolina State University (NCSU).},
	language = {en},
	author = {Farag, Asmaa S and Aras, Egemen M and Earthperson, Arjun and Wood, S Ted and Boyce, Jordan and Diaconeasa, Mihai A.},
	month = jul,
	year = {2023},
}

@inproceedings{batikh_time-dependent_2023,
	address = {Knoxville, TN},
	title = {Time-{Dependent} {Fragility} {Curves} for {SSCs}: {Incorporating} {Seismic} {Aftershocks} in {Multi}-{Hazard} {PRA}},
	abstract = {The consideration of external multi-hazards in probabilistic risk assessments (PRAs) for nuclear power plants (NPPs) has become a necessity after the Fukushima Daiichi accident in 2011. However, a comprehensive PRA framework that incorporates all possible external multi-hazards is yet to be developed. In our current research path, we aim at developing a multi-hazard time-dependent PRA approach that considers the aging-related deterioration of structures. A generic pressurized water reactor (PWR) reactor subjected to seismic mainshock-aftershock (MS-AF) sequences was considered as a case study to demonstrate the multi-hazard PRA approach. We propose a methodology for integrating aftershock sequences in conventional seismic PRAs to support multihazard analysis. The triggering probability for aftershocks was based on the modified Omori Law. A seismic Equipment list (SEL) was developed based on NRC’s guidance and industry practice. We applied the new framework to three levels of plant systems: component-level, system level and plant-level. For component and systems level, we obtained the time-dependent fragility curves with their associated uncertainties, calculated by applying the Latin Hypercube Monte Carlo Method (LHS) while marching along the peak ground acceleration (PGA) axis. The results indicate a rise in the failure probability of SSCs with time, especially in lower PGA bins. For a plant-level analysis, a seismic event tree was quantified to get the time-dependent fragility function. The results show a significant increase in the probability of failure, particularly with the median value, which exhibits a two-order-of-magnitude rise.},
	language = {en},
	author = {Batikh, Akram S and Dhulipala, Somayajulu L N and Spencer, Benjamin W and Dahal, Albert and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{liao_xe-100_2023,
	address = {Knoxville, TN},
	title = {Xe-100 {PRA} {Event} {Sequence} {Modeling} {Framework}},
	abstract = {The Xe-100 is an advanced non-light water, High-Temperature, Gas-Cooled, Pebble Bed reactor (HTGR-PBR). A probabilistic risk assessment (PRA) model is developed at early stages in the design and licensing process to guide the design and evaluate the overall safety characteristic of the design. This is accomplished by systematically enumerating a sufficiently complete set of accident scenarios and assessing the frequencies and consequences of those scenarios individually and in the aggregate to identify challenges to the safety case and quantify the overall risk profile. This paper presents the probabilistic risk assessment (PRA) event sequence modeling framework for Xe-100 to support a specific set of PRA applications for a construction permit application (CPA), including evaluation of design alternatives and incorporation of risk insights into the design, selection of licensing basis events (LBEs), safety classification of systems, structures and components (SSCs), defense-in-depth (DID) evaluation, development of system requirements. The framework consists of four elements: initiating event, plant response, reactor building response and end state. It applies to both internal and external hazards and addresses the radionuclide sources that are contained within the helium pressure boundary (HPB), including the reactor core fuel inventory, radionuclides circulating in the helium coolant during normal operation including those residing on graphite dust particles, and radionuclides and dust plated out and settled on internal HPB components and surfaces.},
	language = {en},
	author = {Liao, Huafei and Fleming, Karl and Hamza, Mostafa and McSweeney, Luke and Cursey, Mark and Deeken, Eric and Retourne, Olivier and Lawson, Glen and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{tezbasaran_high-performance_2023,
	address = {Knoxville, TN},
	title = {High-{Performance} {Computing} {Implementation} for {ADS}-{IDAC}},
	abstract = {Unlike classical Probabilistic Risk Assessment (PRA) methods, Dynamic Probabilistic Risk Assessment (D-PRA) leverages simulations to estimate the timings of pivotal events and evaluate the system/human interactions during transients and corresponding outcomes of the perturbations made to resolve the success and failure of a system such as nuclear power plants. We must address the uncertainties inherent to simulations to determine the success and failure sequences. These uncertainties stem from the nature of a transient. An operator choosing to (or not to) perform a specific action during an accident might be the deciding factor in preventing a reactor from melting. But before simulating both scenarios, it is unknown how the transient will end. Calculating each possible outcome means creating two branches, one with action performed and one not. A full-scope D-PRA study requires hundreds to thousands of sequences simulated through rigorous branching. ADS-IDAC is the D-PRA tool currently partially developed and maintained by the Probabilistic Risk Assessment Group of the NCSU Nuclear Engineering department. It is capable of advanced branching mechanisms and can create branches dynamically when pivotal events happen without the need to pre-define failures of components. It is currently coupled with RELAP5/MOD3.3 as the thermal-hydraulics simulation tool and can also model human reliability. Additionally, ADS-IDAC can model reactor components not in the simulation tool RELAP5 through fault trees.},
	language = {en},
	author = {Tezbasaran, Alp and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{aras_method_2023,
	address = {Knoxville, TN},
	title = {Method of {Developing} a {SCRAM} {Parallel} {Engine} for {Efficient} {Quantification} of {Probabilistic} {Risk} {Assessment} {Models}},
	abstract = {Current probabilistic risk assessment (PRA) quantification engines should be updated since they have served the community for over a decade without significant updates. Today’s personal computers are like the supercomputers of twenty years ago. Also, most of the PRA quantification engines lack the applicability of efficient computation. Some readily available techniques, like parallel computing or distributed memory, may significantly reduce computational time, memory usage, and energy consumption. Improvement of the PRA quantification engines should be made systematically. The progress starts with setting up a benchmark study for the engine to see computational time, memory usage, and energy consumption during the computation. After that, the profiling of the engine to determine hot spots in the source code should be completed. This step will help to address the points that need an update. The last step is updating the engines, considering the findings in the previous actions. This study puts a framework for the parallelization of the SCRAM engine. Depending on the initial results of the performance analysis of PRA quantification engines, this work aims to make the engine faster with less memory and energy consumption. Synthetically generated fault trees are used as input files to be quantified using different algorithms.},
	language = {en},
	author = {Aras, Egemen M and Farag, Asmaa S and Earthperson, Arjun and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{pandit_analyzing_2023,
	address = {Knoxville, TN},
	title = {Analyzing {Hardware} and {Software} {Common} {Cause} {Failures} in {Digital} {Instrumentation} and {Control} {Systems} {Using} {Dual} {Error} {Propagation} {Method}},
	abstract = {This paper develops a methodology for quantifying software common cause failure parameters (CCFs) in nuclear power plants' digital instrumentation and control systems. Probabilistic Risk Assessment (PRA) techniques are used to support the transition of analog instrumentation and control systems to digital in nuclear power plants. The hardware components of the I\&C systems have reliability databases that can be used in probabilistic risk assessment studies. However, the failure data for redundant software components of the systems is sparse. Failure of components constitutes a CCF, wherein two or more components or systems fail due to a single shared cause and coupling mechanism.},
	language = {en},
	author = {Pandit, Priyanka and Earthperson, Arjun and Diaconeasa, Mihai},
	month = jul,
	year = {2023},
}

@inproceedings{pandit_quantifying_2023,
	address = {Knoxville, TN},
	title = {Quantifying the {Likelihood} of {Nuclear} {Supply} {Chain} {Shortage} {Risk}},
	abstract = {Advanced reactor designs, such as Nuscale's NuScale Power Module (NPM) and X-energy's Xe100, maximize the use of off-the-shelf components manufactured and shipped to the site. Small modular reactors will employ factory fabrication compared to the large-scale construction of nuclear power plants [1] [2]. Consequently, stakeholders will have to expand the existing nuclear supply chain capabilities. However, supply chain shortages take a heavy toll on stakeholders. Significant investment from the stakeholders will be needed to make them more resilient to disruptions. A recent study by the United States Department of Energy assessing the USA's nuclear supply chains identifies the supply of uranium, critical minerals, HALEU (High Assay Low Enriched Uranium) fuel, and vendor certifications as vulnerabilities [3].},
	language = {en},
	author = {Pandit, Priyanka and Earthperson, Arjun and Nevius, Daniel and Diaconeasa, Mihai},
	month = jul,
	year = {2023},
}

@inproceedings{earthperson_introducing_2023,
	address = {Knoxville, TN},
	title = {Introducing {Multiple} {Control} {Paths} in the {Dual} {Error} {Propagation} {Graph} for {Stochastic} {Failure} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems}},
	abstract = {Research into digital instrumentation and control (I\&C) upgrades is an important topic for the nuclear industry. Despite their advantages, there has been limited implementation of digital I\&C systems in nuclear power plants (NPPs). Digital I\&Cs can have complex failure modes, including software and hardware related common cause failures (CCFs), which are difficult to detect. In recent years, error propagation methods have been used for the dependability analysis of digital I\&C systems. This paper presents a method for extending the Dual Error Propagation Model (DEPM) to include multiple control flows to better model parallel system behavior. Examples of this method are provided along with modeling techniques and a brief discussion on its use. Ultimately, multiflow DEPM can reduce model complexity while improving readability, expressivity and usefulness, enabling the modeling of complicated parallel system behaviors without compromising performance.},
	language = {en},
	author = {Earthperson, Arjun and Pandit, Priyanka and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{sekiguchi_creating_2023,
	address = {Knoxville, TN},
	title = {Creating {Annotated} {Corpus} and {Named} {Entity} {Recognition} {Model} for {Nuclear} {Power} {Industry}},
	abstract = {This work is to create annotated corpus for named entity recognition (NER) and to create NER model that capable for nuclear domain text data. NER is the first step of information extraction such as extracting event sequence from text-based report. As like as other kind of natural language processing tasks, NER is a domain-specific task and there are only a few research in nuclear domain due to lack of annotated data that can be used for training machine learning model, since creating annotating data manually requires huge works of experts. To address this problem, this work aimed to create annotated corpus for NER automatically. The work succeeds to create 21,186 annotations of system, structure, and component (SSC) of nuclear power plants using descriptions of EIIS codes that showed in Licensee Event Reports (LERs), apply rule based EIIS code estimating process to augment the annotations into 119,082, and create NER model by training spaCy’s NER model using the dataset. The homogeneity and rationality were evaluated by statistical analysis of the NER model, and the accuracy of the model was confirmed through sample check. The work demonstrated the feasibility of creating a Natural Language Processing (NLP) model using human annotated text and defined future tasks to exploit NLP model to free text in nuclear division.},
	language = {en},
	author = {Sekiguchi, Hideki and Lee, Joomyung and Alzahrani, Yahya A and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{dhulipala_preliminary_2023,
	address = {Knoxville, TN},
	title = {Preliminary {Nuclear} {Containment} {Vessel} {Modeling} for {Multi}-{Hazard} {Probabilistic} {Risk} {Assessment} under {Seismic} {Hazards} and {Concrete} {Degradation}},
	abstract = {The current practice for natural phenomena hazards (NPH) risk assessment of nuclear facilities is to compute the risk for each hazard independently and then compound the total risk as a combination of single hazard risks. This state of practice does not consider correlations between hazards and the cascading impacts to structures, systems, and components (SSCs), and could thus underestimate the NPH risk or overestimate the nuclear facility safety. Events such as the Fukushima Daiichi accident have highlighted the importance of multi-hazard risk considerations to nuclear power plants (NPPs) that quantify the cascading damage effects to SSCs in the risk models. Moreover, the current fleet of NPPs in the United States is aging; these NPPs are now expected to operate well beyond their initially planned design life. Aging-related deterioration can potentially decrease the capacity of critical structures such as containment vessels to withstand NPH. Such aging considerations may not be adequately accounted for by the current NPH risk assessment guidelines.},
	language = {en},
	author = {Dhulipala, Somayajulu L N and Dahal, Albert and Spencer, Benjamin W and Jain, Amit and Batikh, Akram S and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{aras_methodology_2023,
	address = {Knoxville, TN},
	title = {Methodology and {Demonstration} for {Performance} {Analysis} of a {Probabilistic} {Risk} {Assessment} {Quantification} {Engine}: {SCRAM}},
	abstract = {Probabilistic risk assessment (PRA) tools are used to model complex systems using event and fault trees. The goal is to evaluate some metrics that assist the decision-makers in improving their design, like the failure probability of the top event and the importance factors. The evaluations should also cover the uncertainty and sensitivity analysis. For the mentioned goal, many tools and engines are available and used by regulatory bodies or industries. All the tools use the same mathematical approaches with different and sometimes unique algorithms. They can be distinguished by modeling approach, quantification algorithms, and input and output file configurations. The legacy PRA tools need to be upgraded since they have been serving for nearly two decades with only minor updates. The number of nuclear power plants (NPPs) is increasing, and advanced NPP designs are ready to build in the next decade. That requires analyzing new aspects of plants. Moreover, larger plant models are developed, which need more computational power. This study focuses on methodology development and demonstration for performance analysis of a PRA quantification engine, SCRAM. A synthetically generated fault tree is used as input files to be quantified using different algorithms. The work finds the hot spots in SCRAM and recommends benefiting from parallel and distributed computing technologies depending on the findings.},
	language = {en},
	author = {Aras, Egemen M and Farag, Asmaa S and Earthperson, Arjun and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{hamza_xe-100_2023,
	address = {Knoxville, TN},
	title = {Xe-100 {PRA} {Initiating} {Events} and {Human} {Reliability} {Analysis} {Modeling} {Frameworks} during the {Early} {Design} {Stages}},
	abstract = {Probabilistic risk assessment (PRA) was first introduced in the first safety study which was the first approach to comprehensively and realistically, rather than conservatively, estimate the risk associated with different accidents. In Light-Water-Reactors (LWR), PRA models for NPPs are divided into three levels. In the level 1 PRA, the model focuses only on sequences that could lead to damage to the reactor core estimating the core damage frequency. Whereas level 2 PRA models start from core damage and estimate the frequency of a release of radioactive material into the environment. Finally, level 3 PRA/PSA models start from release accidents and estimate the public doses and other environmental damage. However, the proposed approach for non-LWR PRA in the Licensing Modernization Project (LMP) is to assess the aggregate plant-level risk. This is done by identifying and assessing the licensing basis events (LBE) and investigating the entire scenario starting from initiating events and ending with end states that include public doses and other environmental damage. In other words, the PRA model of a non-LWR is a full scope PRA model given the frequencies, consequences, and their associated uncertainties of credible scenarios. Moreover, the Regulatory Guide 1.233, which endorsed the approach presented by the LMP, presented “guidance on using a technology-inclusive, risk-informed, and performance-based methodology to inform the licensing basis and content of applications for non-light-water reactors.” Hence, PRA is expected to support the design of advanced reactors through an iterative process that gets updated with each iteration of the design. However, during the early design stages, the limited design information and operational experience present a challenge to implementing PRA. This paper presents some of the challenges faced during the process of initiating event identification, initiating event frequency quantification, and human reliability analysis. Specific methodologies to address each of these challenges are presented and demonstrated using the Xe-100 high-temperature gascooled reactor design. Finally, the paper presents additional remarks regarding the role and limitations of PRA during the early design stages.},
	language = {en},
	author = {Hamza, Mostafa and Liao, Huafei and McSweeney, Luke and Cursey, Mark and Fleming, Karl and Lawson, Glen and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{hamza_model_2023,
	address = {Knoxville, TN},
	title = {Model {Exchange} {Methodology} {Between} {Probabilistic} {Risk} {Assessment} {Tools}: {SAPHIRE} and {CAFTA} {Case} {Study}},
	abstract = {Probabilistic risk assessment (PRA) is integral to large-scale, high-risk industries, such as aerospace, chemical, and nuclear. Fault tree and event tree modeling techniques are essential parts of any PRA model. Fault trees are used to model system failures and their possible failure paths to quantify their reliability. On the other hand, event trees are developed to track the progression of postulated initiating events along with their associated system responses and failure paths. Multiple tools are used to build and quantify fault trees, event trees, and their associated uncertainty; SAPHIRE, CAFTA, and RiskMAN are the most widely used. Due to the lack of a widely used standard, the project files of different PRA tools are binary files, SRA for SAPHIRE and CAF for CAFTA, that can only be imported and modified using the same tool. As the complexity of the systems or event progression increases, their associated fault tree and event tree models become more complex. For models developed, modified, and updated by a single analyst, increasing complexity does not necessarily present a challenge for model development. However, once the need arises to convert the project from one tool to the other, CAFTA to SAPHIRE, and vice versa, no publicly available guidance for such a process exists. The ASME/ANS probabilistic risk assessment standard for advanced non-light-water reactor nuclear power plants requires the PRA model to go through a peer review process to determine if the method and its implementation meet the requirements of this Standard. Moreover, any assessment of the PRA model during the licensing process may result in the need to convert the entire model of parts of it from one tool to the other. Hence, this paper presents guidance on converting PRA models between different PRA tools. This guidance utilizes these PRA tools' existing capabilities and the MAR-D legacy file format. A demonstration of converting models between CAFTA and SAPHIRE is given in which the limitations and bottlenecks are identified, and potential rudimentary solutions to the constraints faced are presented. Better implementation of the proposed approach can be incorporated directly into the PRA tools, such as the OpenPSA model exchange format. However, until implementing such a feature into the PRA tools, the proposed methodology provides a straightforward solution to the issue of crosscompatibility for PRA models.},
	language = {en},
	author = {Hamza, Mostafa and Tezbasaran, Alp and Aras, Egemen and Farag, Asmaa S and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@inproceedings{alzahrani_characterization_2023,
	address = {Knoxville, TN},
	title = {Characterization of {Dynamic} {Behaviors} in {Licensee} {Event} {Report} {Data} to {Support} {PRA}},
	abstract = {The Licensee Event Report (LER) is a data report generated by the United States Nuclear Regulatory Commission (NRC) that documents any event or condition at a nuclear power plant that could potentially affect public health and safety or the environment. The report is submitted by the licensee of the nuclear facility and contains detailed information about the event, including its cause, consequences, and corrective actions taken. The LER is part of the NRC's comprehensive regulatory framework for ensuring the safe operation of nuclear facilities and is used to identify and address potential safety issues. The report is publicly available and can be accessed through the NRC's online database. In addition, data extracted from the LER reports can greatly support the traditional and dynamic probabilistic risk assessment studies. However, extracting accumulative and meaningful data from the LER reports requires a lot of post-processing effort, and automating this process is significant in terms of saving time and money. In this study, we present a historical overview of critical dynamic behaviors of the previous loss of offsite power (LOOP) incidents occurring in the existing NPP fleet. We consider approximately three hundred of LOOP events according to the last update by NRC of past LOOP incidents of LER and we characterize them based on the type of the nuclear power plant, cause of the event, and important dynamic behavior types of the plant response. The trend of LOOP events has decreased from 1980 to 2023 due to improvements in technology, engineering practices, operational procedures, and regulatory requirements. The primary cause of LOOP events is switchyard-centered events, followed by plant-centered, weather-related, and gridrelated events. The occurrence of LOOP events is higher during the warmer seasons, particularly summer and spring. The number of LOOP events in PWRs is higher than in Boiling Water Reactors (BWRs) due to the greater number of PWRs in operation.},
	language = {en},
	author = {Alzahrani, Yahya A and Farag, Asmaa S and Sekiguchi, Hideki and Diaconeasa, Mihai A},
	month = jul,
	year = {2023},
}

@phdthesis{mosleh_use_nodate,
	address = {United States -- California},
	type = {Ph.{D}.},
	title = {On the {Use} of {Quantitative} {Judgment} in {Risk} {Assessment}: {A} {Bayesian} {Approach}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	shorttitle = {On the {Use} of {Quantitative} {Judgment} in {Risk} {Assessment}},
	url = {https://www.proquest.com/docview/303005250/abstract/F0F8DF90B3BE4591PQ/1},
	abstract = {The development of a methodology for the use of expert quantitative judgment with particular emphasis on the problems of interest in risk assessments, is the subject of this work. A general methodology in the context of Bayesian theory of probability is presented and several models for using the opinions of one or more experts are proposed. These models account for both the experts' opinions and the information about the experts themselves. It is shown that existing aggregation techniques are special cases of the proposed methodology. A method is presented for the estimation of distributions for cases where the opinion of experts is expressed in the form of point or interval estimates or some percentiles of a distribution. The methods are then applied to estimate fragility curves for a nuclear reactor component from several experts' estimates for the percentiles. Finally, the methodology is used in the analysis of component failure data. Furthermore, the performance of different aggregation techniques in several examples with real data is studied and some conclusions are drawn.},
	language = {English},
	urldate = {2023-07-27},
	school = {University of California, Los Angeles},
	author = {MOSLEH, ALI},
	note = {ISBN: 9798660121999},
	keywords = {Applied sciences},
}

@book{modarres_reliability_2010,
	address = {Boca Raton},
	edition = {2nd ed},
	title = {Reliability engineering and risk analysis: a practical guide},
	isbn = {978-0-8493-9247-4},
	shorttitle = {Reliability engineering and risk analysis},
	publisher = {CRC Press},
	author = {Modarres, M. and Kaminskiy, Mark and Krivtsov, Vasiliy},
	year = {2010},
	note = {OCLC: ocn144565822},
	keywords = {Reliability (Engineering), Risk assessment},
}

@article{fleetwood_overview_2000,
	title = {An overview of radiation effects on electronics in the space telecommunications environment},
	volume = {40},
	issn = {00262714},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0026271499002255},
	doi = {10.1016/S0026-2714(99)00225-5},
	language = {en},
	number = {1},
	urldate = {2023-07-26},
	journal = {Microelectronics Reliability},
	author = {Fleetwood, Daniel M. and Winokur, Peter S. and Dodd, Paul E.},
	month = jan,
	year = {2000},
	pages = {17--26},
}

@article{ladbury_threats_2021,
	title = {Threats to {Resiliency} of {Redundant} {Systems} {Due} to {Destructive} {SEEs}},
	volume = {68},
	issn = {0018-9499, 1558-1578},
	url = {https://ieeexplore.ieee.org/document/9351754/},
	doi = {10.1109/TNS.2021.3055740},
	number = {5},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Ladbury, R. and Bay, Michael and Zinchuk, Jeff},
	month = may,
	year = {2021},
	pages = {970--979},
}

@article{privat_multiscale_2019,
	title = {Multiscale {Modeling} of {Total} {Ionizing} {Dose} {Effects} in {Commercial}-off-the-{Shelf} {Parts} in {Bipolar} {Technologies}},
	volume = {66},
	issn = {0018-9499, 1558-1578},
	url = {https://ieeexplore.ieee.org/document/8579161/},
	doi = {10.1109/TNS.2018.2887235},
	number = {1},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Privat, A. and Barnaby, H. J. and Adell, P. C. and Tolleson, B. S. and Wang, Y. and Han, X. and Davis, P. and Rax, B. R. and Buchheit, T. E.},
	month = jan,
	year = {2019},
	pages = {190--198},
}

@article{winokur_use_1999,
	title = {Use of {COTS} microelectronics in radiation environments},
	volume = {46},
	issn = {0018-9499, 1558-1578},
	url = {https://ieeexplore.ieee.org/document/819113/},
	doi = {10.1109/23.819113},
	number = {6},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Winokur, P.S. and Lum, G.K. and Shaneyfelt, M.R. and Sexton, F.W. and Hash, G.L. and Scott, L.},
	month = dec,
	year = {1999},
	pages = {1494--1503},
}

@inproceedings{hejase_dynamic_2018,
	address = {Kissimmee, Florida},
	title = {Dynamic {Probabilistic} {Risk} {Assessment} of {Unmanned} {Aircraft} {Adaptive} {Flight} {Control} {Systems}},
	isbn = {978-1-62410-527-2},
	url = {https://arc.aiaa.org/doi/10.2514/6.2018-1982},
	doi = {10.2514/6.2018-1982},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {2018 {AIAA} {Information} {Systems}-{AIAA} {Infotech} @ {Aerospace}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Hejase, Mohammad and Kurt, Arda and Aldemir, Tunc and Ozguner, Umit and Guarro, Sergio and Yau, Michael K. and Knudson, Matt},
	month = jan,
	year = {2018},
}

@article{apostolakis_concept_1990,
	title = {The {Concept} of {Probability} in {Safety} {Assessments} of {Technological} {Systems}},
	volume = {250},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.2255906},
	doi = {10.1126/science.2255906},
	language = {en},
	number = {4986},
	urldate = {2023-07-26},
	journal = {Science},
	author = {Apostolakis, George},
	month = dec,
	year = {1990},
	pages = {1359--1364},
}

@article{dodd_current_2010,
	title = {Current and {Future} {Challenges} in {Radiation} {Effects} on {CMOS} {Electronics}},
	volume = {57},
	issn = {0018-9499},
	url = {http://ieeexplore.ieee.org/document/5550487/},
	doi = {10.1109/TNS.2010.2042613},
	number = {4},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Dodd, P. E. and Shaneyfelt, M. R. and Schwank, J. R. and Felix, J. A.},
	month = aug,
	year = {2010},
	pages = {1747--1763},
}

@article{normand_single_1996,
	title = {Single event upset at ground level},
	volume = {43},
	issn = {0018-9499, 1558-1578},
	url = {https://ieeexplore.ieee.org/document/556861/},
	doi = {10.1109/23.556861},
	number = {6},
	urldate = {2023-07-26},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Normand, E.},
	month = dec,
	year = {1996},
	pages = {2742--2750},
}

@incollection{siciliano_disaster_2016,
	address = {Cham},
	title = {Disaster {Robotics}},
	isbn = {978-3-319-32550-7 978-3-319-32552-1},
	url = {https://link.springer.com/10.1007/978-3-319-32552-1_60},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Springer {Handbook} of {Robotics}},
	publisher = {Springer International Publishing},
	author = {Murphy, Robin R. and Tadokoro, Satoshi and Kleiner, Alexander},
	editor = {Siciliano, Bruno and Khatib, Oussama},
	year = {2016},
	doi = {10.1007/978-3-319-32552-1_60},
	note = {Series Title: Springer Handbooks},
	pages = {1577--1604},
}

@article{miskov-zivanov_modeling_2008,
	title = {Modeling and {Optimization} for {Soft}-{Error} {Reliability} of {Sequential} {Circuits}},
	volume = {27},
	issn = {0278-0070},
	url = {http://ieeexplore.ieee.org/document/4492840/},
	doi = {10.1109/TCAD.2008.917591},
	number = {5},
	urldate = {2023-07-25},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Miskov-Zivanov, Natasa and Marculescu, Diana},
	month = may,
	year = {2008},
	pages = {803--816},
}

@misc{mbsa-tud_mbsa-tudllvmpars_2021,
	title = {mbsa-tud/{LLVMPars}},
	url = {https://github.com/mbsa-tud/LLVMPars},
	abstract = {Transformation of C code to DEPM using LLVM},
	urldate = {2023-07-25},
	author = {{mbsa-tud}},
	month = may,
	year = {2021},
	note = {original-date: 2019-05-24T14:47:01Z},
}

@article{detlefs_memory_1994,
	title = {Memory allocation costs in large {C} and {C}++ programs},
	volume = {24},
	issn = {00380644, 1097024X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/spe.4380240602},
	doi = {10.1002/spe.4380240602},
	language = {en},
	number = {6},
	urldate = {2023-07-24},
	journal = {Software: Practice and Experience},
	author = {Detlefs, David and Dosser, Al and Zorn, Benjamin},
	month = jun,
	year = {1994},
	pages = {527--542},
}

@misc{williams_nuscale_2022,
	title = {{NuScale} {Power}: {Is} 2030 {Soon} {Enough} {For} {The} {First} {SMR} {Reactor}? ({NYSE}:{SMR}) {\textbar} {Seeking} {Alpha}},
	shorttitle = {{NuScale} {Power}},
	url = {https://seekingalpha.com/article/4507992-nuscale-power-is-2030-soon-enough-for-first-smr-reactor, https://seekingalpha.com/article/4507992-nuscale-power-is-2030-soon-enough-for-first-smr-reactor},
	abstract = {NuScale Power has recently gone public via SPAC. Is SMR stock a good buy? Click to read our analysis of NuScale Power, renewable energy, and the future of SMR stock.},
	language = {en},
	urldate = {2023-07-19},
	author = {Williams, Keith},
	month = may,
	year = {2022},
}

@misc{noauthor_this_2021,
	title = {This next generation nuclear power plant is pitched for {Washington}. {Can} it 'change the world'?},
	url = {https://www.seattletimes.com/seattle-news/environment/this-next-generation-nuclear-power-plant-is-pitched-for-washington-state-can-it-change-the-world/},
	abstract = {The newest generation of nuclear power plants is taking shape in Washington state. These smaller reactors could provide flexible power free of direct carbon emissions. But a perilous nuclear history and big questions over safety remain.},
	language = {en-US},
	urldate = {2023-07-19},
	journal = {The Seattle Times},
	month = nov,
	year = {2021},
}

@misc{noauthor_nuscale_2022,
	title = {{NuScale} {Power} {Module}: {The} 200 {Best} {Inventions} of 2022},
	shorttitle = {{NuScale} {Power} {Module}},
	url = {https://time.com/collection/best-inventions-2022/6228841/nuscale-power-module/},
	abstract = {Find out why NuScale Power Module made this year's list},
	language = {en},
	urldate = {2023-07-18},
	journal = {Time},
	month = nov,
	year = {2022},
}

@article{klibi_design_2010,
	title = {The design of robust value-creating supply chain networks: {A} critical review},
	volume = {203},
	issn = {03772217},
	shorttitle = {The design of robust value-creating supply chain networks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221709004792},
	doi = {10.1016/j.ejor.2009.06.011},
	abstract = {This paper discusses Supply Chain Network (SCN) design problem under uncertainty, and presents a critical review of the optimization models proposed in the literature. Some drawbacks and missing aspects in the literature are pointed out, thus motivating the development of a comprehensive SCN design methodology. Through an analysis of supply chains uncertainty sources and risk exposures, the paper reviews key random environmental factors and discusses the nature of major disruptive events threatening SCN. It also discusses relevant strategic SCN design evaluation criteria, and it reviews their use in existing models. We argue for the assessment of SCN robustness as a necessary condition to ensure sustainable value creation. Several deﬁnitions of robustness, responsiveness and resilience are reviewed, and the importance of these concepts for SCN design is discussed. This paper contributes to framing the foundations for a robust SCN design methodology.},
	language = {en},
	number = {2},
	urldate = {2023-07-12},
	journal = {European Journal of Operational Research},
	author = {Klibi, Walid and Martel, Alain and Guitouni, Adel},
	month = jun,
	year = {2010},
	pages = {283--293},
}

@misc{noauthor_scaled_nodate,
	title = {Scaled down {SMR} pilot project remains on course : {New} {Nuclear} - {World} {Nuclear} {News}},
	url = {https://world-nuclear-news.org/Articles/Scaled-down-SMR-pilot-project-remains-on-course},
	urldate = {2023-07-10},
}

@misc{noauthor_scaled_nodate-1,
	title = {Scaled down {SMR} pilot project remains on course : {New} {Nuclear} - {World} {Nuclear} {News}},
	url = {https://world-nuclear-news.org/Articles/Scaled-down-SMR-pilot-project-remains-on-course},
	urldate = {2023-07-10},
}

@misc{noauthor_haleu_nodate,
	title = {{HALEU} fuel availability delays {Natrium} reactor project : {New} {Nuclear} - {World} {Nuclear} {News}},
	url = {https://world-nuclear-news.org/Articles/HALEU-fuel-availability-delays-Natrium-reactor-pro},
	urldate = {2023-07-10},
}

@misc{noauthor_combined_nodate,
	title = {Combined {Licenses} for {Virgil} {C}. {Summer} {Nuclear} {Station}, {Units} 2 and 3},
	url = {https://www.nrc.gov/reactors/new-reactors/large-lwr/col/summer.html},
	language = {en-US},
	urldate = {2023-07-10},
	journal = {NRC Web},
}

@article{robb_stewart_construction_2023,
	title = {Construction schedule and cost risk for large and small light water reactors},
	volume = {407},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549323001541},
	doi = {10.1016/j.nucengdes.2023.112305},
	abstract = {Capital cost and construction schedule estimates for nuclear projects often under-estimate the realized costs upon project completion. Uncertainty quantification of nuclear construction project cost estimates have seldom been used in open-literature and have not shown to effectively bound the realized schedules and costs. Building on recent studies of advanced light water reactor costs and construction schedules, this paper explored the risk of different construction delay drivers and the implication on total installed cost. Using data from previous nuclear projects, as well as other megaprojects and analyses, we modeled the impact of supply chain delays, human error, change orders, and productivity on four different reactor architectures: a large passively safe PWR, a large modular BWR, small modular BWR, and a multi-module PWR. The probability and impact of supply chain delays and change orders were modeled based on the AP1000 construction experience at Vogtle Units 3 \& 4, while the human error and productivity models came from non-nuclear sources. The estimated risk to cost overrun and schedule delays were found to be significant. The multi-module plant was the most susceptible to construction delays, and the small modular BWR was the least susceptible. However, the risk mitigation by a small reactor only offset the lost economy of scale in a few scenarios relative to the large reactors, because there was still significant onsite work despite modularization. Access to large labor markets mitigated the upper bound cost and schedule risks significantly for all reactor types. Finally, design changes and the resulting productivity hits were the largest driver of construction delays, and human error was the second largest driver, but supply chain delays only accounted for a small fraction of the delays for the assessed water-cooled concepts.},
	language = {en},
	urldate = {2023-07-07},
	journal = {Nuclear Engineering and Design},
	author = {Robb Stewart, W. and Shirvan, Koroush},
	month = jun,
	year = {2023},
	pages = {112305},
}

@misc{noauthor_utility-scale_nodate,
	title = {Utility-scale solar projects report delays},
	url = {https://www.eia.gov/todayinenergy/detail.php?id=53400},
	abstract = {Energy Information Administration - EIA - Official Energy Statistics from the U.S. Government},
	language = {en},
	urldate = {2023-07-07},
}

@techreport{lachance_discrete_nodate,
	title = {Discrete {Dynamic} {Probabilistic} {Risk} {Assessment} {Model} {Development} and {Application}.},
	abstract = {As part of an exploratory long-term research project, Sandia National Laboratories and the University of Maryland, under the support and guidance of the US Nuclear Regulatory Commission, developed a tool for conducting dynamic probabilistic risk analysis (PRA) for postulated severe accident scenarios by coupling and extending existing capabilities in hardware/phenomena and operator response simulation. The effort encompasses aspects of both Level 1 and Level 2 PRA. The dynamic PRA tool utilizes MELCOR as the code for simulating severe nuclear reactor accidents in a discrete dynamic event tree (DDET) framework. The Accident Dynamics Simulator (ADS) developed at the University of Maryland is used to generate the DDETs for an accident simulation that reflect variations in important parameters including: phenomenological events, the behavior of active and passive components, and operators’ cognitive activities and actions. Specific focus was placed on inclusion of an operator cognitive model in the dynamic PRA tool that addresses both pre-core damage human actions and post-core damage human actions. To that purpose, the Information, Decision, and Actions in a Crew (IDAC) context cognitive model developed at the University of Maryland was utilized. An existing ADS-IDAC model developed for a pressurized water reactor was expanded to address operator actions directed in both emergency operating procedures and severe accident management guidelines. The developed tool was applied to a demonstration problem; a station blackout (SBO) scenario at the Surry Nuclear Station. Both short-term and long-term SBO sequences were included in the demonstration evaluation. This report describes the developed tool and corresponding models and the results of the SBO demonstration problem. Insights from the demonstration evaluation, including potential further development of the dynamic PRA tool, are provided.},
	language = {en},
	author = {LaChance, J and Cardoni, J and Li, Y and Mosleh, A and Aird, D and Helton, D and Coyne, K},
	pages = {148},
}

@article{swaminathan_event_1999,
	title = {The {Event} {Sequence} {Diagram} framework for dynamic {Probabilistic} {Risk} {Assessment}},
	volume = {63},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832098000271},
	doi = {10.1016/S0951-8320(98)00027-1},
	language = {en},
	number = {1},
	urldate = {2023-06-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Smidts, C.},
	month = jan,
	year = {1999},
	pages = {73--90},
}

@techreport{gu_medvedevs_jprs_1989,
	title = {{JPRS} {Report}, {Soviet} {Union}: {Economic} {Affairs} ("{Chernobyl} {Notebook}")},
	shorttitle = {{JPRS} {Report}, {Soviet} {Union}},
	url = {https://apps.dtic.mil/sti/pdfs/ADA335076.pdf},
	abstract = {Medvedevs Chernobyl Notebook is a competent and dispassionately truthful account of the tragedy that occurred more than 3 years ago and which is continuing to disturb millions of people. This is perhaps the first time we have such a complete first-hand account in which nothing is kept back and there is no departmental diplomacy. The author is a nuclear power specialist who worked for a time at the Chernobyl AES and knows it well, just as he is personally acquainted with all the principal participants in the events. By virtue of his official position, he has attended many of the crucial conferences concerning nuclear power plant construction. Immediately after the accident, Medvedev was sent to Chernobyl and had an opportunity to learn a great deal while the trail was still fresh and to see things with his own eyes. He presents many technical details indispensable to understanding the mechanism whereby the accident occurred, he exposes the secrets of bureaucratic relations, he tells about the oversights of scientists and designers, about the disastrous overbearing pressure in the command system, about the violations of glasnost before the accident and in the emergency situation following it that have caused enormous harm. The chronicle of events at Chernobyl in the tragic days of April and May 1986 takes up the central place in the story. The author portrays the behavior and role of numerous participants in the drama, of real living people with their shortcomings and virtues, their doubts, their weaknesses, their illusions, and their heroism alongside the nuclear monster that had gone out of control. It is not possible to read about this without the deepest emotion. We knew about the exploits of the firemen. The author tells about the heroism of the electricians, the turbine specialists, the operators, and other workers at the station who prevented the a},
	language = {en},
	number = {JPRS-UEA-89-034},
	urldate = {2023-06-19},
	institution = {Soviet Union: Economic Affairs},
	author = {{G.U. Medvedevs}},
	month = oct,
	year = {1989},
	note = {Section: Technical Reports},
	pages = {78},
}

@incollection{ahn_institute_2017,
	address = {Cham},
	title = {The {Institute} of {Resilient} {Communities}},
	isbn = {978-3-319-58767-7 978-3-319-58768-4},
	url = {http://link.springer.com/10.1007/978-3-319-58768-4_16},
	language = {en},
	urldate = {2023-06-19},
	booktitle = {Resilience: {A} {New} {Paradigm} of {Nuclear} {Safety}},
	publisher = {Springer International Publishing},
	author = {Vetter, Kai},
	editor = {Ahn, Joonhong and Guarnieri, Franck and Furuta, Kazuo},
	year = {2017},
	doi = {10.1007/978-3-319-58768-4_16},
	pages = {207--218},
}

@article{vetter_multi-sensor_2016,
	title = {Multi-sensor radiation detection, imaging, and fusion},
	volume = {805},
	issn = {01689002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900215010748},
	doi = {10.1016/j.nima.2015.08.078},
	language = {en},
	urldate = {2023-06-19},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Vetter, Kai},
	month = jan,
	year = {2016},
	pages = {127--134},
}

@techreport{markgraf_total_2004,
	title = {Total {Ionizing} {Dose} {Testing} of the {Orion} and {Phoenix} {GPS} {Receivers}},
	url = {https://www.dlr.de/rb/Portaldata/38/Resources/dokumente/GSOC_dokumente/RB-RFT/TN_0401.pdf},
	language = {en},
	number = {TN 04-01},
	institution = {German Space Operations Center (GSOC)},
	author = {Markgraf, M and Montenbruck, O},
	month = feb,
	year = {2004},
	pages = {40},
}

@misc{noauthor_gsfc_nodate,
	title = {{GSFC} {Radiation} {Data} {Base}},
	url = {https://radhome.gsfc.nasa.gov/radhome/RadDataBase/RadDataBase.html},
	urldate = {2023-06-16},
}

@article{chambers_participatory_1994,
	title = {Participatory rural appraisal ({PRA}): {Analysis} of experience},
	volume = {22},
	issn = {0305-750X},
	shorttitle = {Participatory rural appraisal ({PRA})},
	url = {https://www.sciencedirect.com/science/article/pii/0305750X94900035},
	doi = {10.1016/0305-750X(94)90003-5},
	abstract = {The more significant principles of Participatory Rural Appraisal (PRA) concern the behavior and attitudes of outsider facilitators, including not rushing, “handing over the stick,” and being self-critically aware. The power and popularity of PRA are partly explained by the unexpected analytical abilities of local people when catalyzed by relaxed rapport, and expressed through sequences of participatory and especially visual methods. Evidence to date shows high validity and reliability of information shared by local people through PRA compared with data from more traditional methods. Explanations include reversals and shifts of emphasis: from etic to emic, closed to open, individual to group, verbal to visual, and measuring to comparing; and from extracting information to empowering local analysts.},
	language = {en},
	number = {9},
	urldate = {2023-06-13},
	journal = {World Development},
	author = {Chambers, Robert},
	month = sep,
	year = {1994},
	pages = {1253--1268},
}

@article{pinto_radiological_2021,
	title = {Radiological {Scouting}, {Monitoring} and {Inspection} {Using} {Drones}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/9/3143},
	doi = {10.3390/s21093143},
	abstract = {Human populations and natural ecosystems are bound to be exposed to ionizing radiation from the deposition of artificial radionuclides resulting from nuclear accidents, nuclear devices or radiological dispersive devices (“dirty bombs”). On the other hand, Naturally Occurring Radioactive Material industries such as phosphate production or uranium mining, contribute to the on site storage of residuals with enhanced concentrations of natural radionuclides. Therefore, in the context of the European agreements concerning nuclear energy, namely the European Atomic Energy Community Treaty, monitoring is an essential feature of the environmental radiological surveillance. In this work, we obtain 3D maps from outdoor scenarios, and complete such maps with measured radiation levels and with its radionuclide signature. In such scenarios, we face challenges such as unknown and rough terrain, limited number of sampled locations and the need for different sensors and therefore different tasks. We propose a radiological solution for scouting, monitoring and inspecting an area of interest, using a fleet of drones and a controlling ground station. First, we scout an area with a Light Detection and Ranging sensor onboard a drone to accurately 3D-map the area. Then, we monitor that area with a Geiger–Müller Counter at a low-vertical distance from the ground to produce a radiological (heat)map that is overlaid on the 3D map of the scenario. Next, we identify the hotspots of radiation, and inspect them in detail using a drone by landing on them, to reveal its radionuclide signature using a Cadmium–Zinc–Telluride detector. We present the algorithms used to implement such tasks both at the ground station and on the drones. The three mission phases were validated using actual experiments in three different outdoor scenarios. We conclude that drones can not only perform the mission efficiently, but in general they are faster and as reliable as personnel on the ground.},
	language = {en},
	number = {9},
	urldate = {2023-06-11},
	journal = {Sensors},
	author = {Pinto, Luís Ramos and Vale, Alberto and Brouwer, Yoeri and Borbinha, Jorge and Corisco, José and Ventura, Rodrigo and Silva, Ana Margarida and Mourato, André and Marques, Gonçalo and Romanets, Yuri and Sargento, Susana and Gonçalves, Bruno},
	month = apr,
	year = {2021},
	pages = {3143},
}

@article{alrammah_digitalized_2023,
	title = {A digitalized framework for responding to radiological accidents in a public major event},
	volume = {16},
	issn = {16878507},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1687850723000146},
	doi = {10.1016/j.jrras.2023.100536},
	language = {en},
	number = {2},
	urldate = {2023-06-11},
	journal = {Journal of Radiation Research and Applied Sciences},
	author = {Alrammah, Ibrahim A. and AlShareef, Mohammed R.},
	month = jun,
	year = {2023},
	pages = {100536},
}

@article{ahmad_ionizing_2021,
	title = {Ionizing {Radiation} {Monitoring} {Technology} at the {Verge} of {Internet} of {Things}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/22/7629},
	doi = {10.3390/s21227629},
	abstract = {As nuclear technology evolves, and continues to be used in various fields since its discovery less than a century ago, radiation safety has become a major concern to humans and the environment. Radiation monitoring plays a significant role in preventive radiological nuclear detection in nuclear facilities, hospitals, or in any activities associated with radioactive materials by acting as a tool to measure the risk of being exposed to radiation while reaping its benefit. Apart from in occupational settings, radiation monitoring is required in emergency responses to radiation incidents as well as outdoor radiation zones. Several radiation sensors have been developed, ranging from as simple as a Geiger-Muller counter to bulkier radiation systems such as the High Purity Germanium detector, with different functionality for use in different settings, but the inability to provide real-time data makes radiation monitoring activities less effective. The deployment of manned vehicles equipped with these radiation sensors reduces the scope of radiation monitoring operations significantly, but the safety of radiation monitoring operators is still compromised. Recently, the Internet of Things (IoT) technology has been introduced to the world and offered solutions to these limitations. This review elucidates a systematic understanding of the fundamental usage of the Internet of Drones for radiation monitoring purposes. The extension of essential functional blocks in IoT can be expanded across radiation monitoring industries, presenting several emerging research opportunities and challenges. This article offers a comprehensive review of the evolutionary application of IoT technology in nuclear and radiation monitoring. Finally, the security of the nuclear industry is discussed.},
	language = {en},
	number = {22},
	urldate = {2023-06-11},
	journal = {Sensors},
	author = {Ahmad, Muhammad Ikmal and Ab. Rahim, Mohd Hafizi and Nordin, Rosdiadee and Mohamed, Faizal and Abu-Samah, Asma’ and Abdullah, Nor Fadzilah},
	month = nov,
	year = {2021},
	pages = {7629},
}

@article{baek_development_2023,
	title = {Development of {Dynamic} {Integrated} {Consequence} {Evaluation} ({DICE}) for {Dynamic} {Event} {Tree} {Approaches}: {Numerical} {Validation} for a {Loss} of {Coolant} {Accident}},
	issn = {0951-8320},
	shorttitle = {Development of {Dynamic} {Integrated} {Consequence} {Evaluation} ({DICE}) for {Dynamic} {Event} {Tree} {Approaches}},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832023003393},
	doi = {10.1016/j.ress.2023.109425},
	abstract = {Although conventional probabilistic safety assessment (PSA) makes a sufficient contribution to evaluating the safety of nuclear facilities, it suffers some limitations in performing optimal assessments close to the actual behavior by reflecting time dependencies in accident management. However, integrated deterministic and probabilistic safety assessment (IDPSA) literally combines two methodologies to enable synchronized evaluation based on physical behavior, system availability of facilities, and operator's response. Dynamic integrated consequence evaluation (DICE) is one of the IDPSA tools developed for this purpose, which is the first achievement in South Korea and supported by a regulatory authority. Based on dynamic discrete event tree (DDET) methodology, DICE consists of a scheduler that supports the exchange of information between modules, including a physical module that computes thermal-hydraulic simulations, a diagnosis module that specifies branching points for safety systems, and a reliability module that provides system availability. This paper deals with numerical validation comparing the conventional deterministic and probabilistic results for a sample scenario with those of DICE, and discusses an application of DICE to support and extend the scope of conventional PSA through a case study. It is expected that DICE emphasizes the compliance with conventional PSA methodologies while providing magnified perception in investigating unforeseen scenarios.},
	language = {en},
	urldate = {2023-06-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Baek, Sejin and Heo, Gyunyoung},
	month = jun,
	year = {2023},
	keywords = {Dynamic Discrete Event Tree (DDET), Dynamic Integrated Consequence Evaluation (DICE), Integrated Deterministic-Probabilistic Safety Assessment (IDPSA)},
	pages = {109425},
}

@article{bazzano_radiation_2021,
	title = {Radiation testing of a commercial 6-axis {MEMS} inertial navigation unit at {ENEA} {Frascati} proton linear accelerator},
	volume = {67},
	issn = {02731177},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0273117720308310},
	doi = {10.1016/j.asr.2020.11.031},
	language = {en},
	number = {4},
	urldate = {2023-06-09},
	journal = {Advances in Space Research},
	author = {Bazzano, G. and Ampollini, A. and Cardelli, F. and Fortini, F. and Nenzi, P. and Palmerini, G.B. and Picardi, L. and Piersanti, L. and Ronsivalle, C. and Surrenti, V. and Trinca, E. and Vadrucci, M. and Sabatini, M.},
	month = feb,
	year = {2021},
	pages = {1379--1391},
}

@article{qiu_effects_2015,
	title = {Effects of neutron and gamma radiation on lithium-ion batteries},
	volume = {345},
	issn = {0168583X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168583X1401088X},
	doi = {10.1016/j.nimb.2014.12.058},
	language = {en},
	urldate = {2023-06-09},
	journal = {Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms},
	author = {Qiu, Jie and He, Dandan and Sun, Mingzhai and Li, Shimeng and Wen, Cun and Hattrick-Simpers, Jason and Zheng, Yuan F. and Cao, Lei},
	month = feb,
	year = {2015},
	pages = {27--32},
}

@techreport{ulrich_solutions_2023,
	title = {Solutions for {Enhanced} {Legacy} {Probabilistic} {Risk} {Assessment} {Tools} and {Methodologies}: {Improving} {Efficiency} of {Model} {Development} and {Processing} via {Innovative} {Human} {Reliability} {Dependency} {Analysis}},
	shorttitle = {Solutions for {Enhanced} {Legacy} {Probabilistic} {Risk} {Assessment} {Tools} and {Methodologies}},
	url = {https://www.osti.gov/servlets/purl/1964064/},
	language = {en},
	number = {INL/RPT-23-71788-Rev000, 1964064},
	urldate = {2023-04-11},
	author = {Ulrich, Thomas and Boring PhD, Ronald and Kim, Jisuk and Hall, Anna and Mortenson, Torrey and Zucal, Gregory and Miller, Andrew and Collins, Erin and Lawrence, Svetlana and Lew, Roger},
	month = mar,
	year = {2023},
	doi = {10.2172/1964064},
	pages = {INL/RPT--23--71788--Rev000, 1964064},
}

@article{camp_potential_2019,
	title = {Potential {Improvements} to the {Nuclear} {Safety} and {Launch} {Approval} {Process} for {Nuclear} {Reactors} {Utilized} for {Space} {Power} and {Propulsion} {Applications}},
	language = {en},
	author = {Camp, Allen},
	year = {2019},
}

@article{zhou_improved_2018,
	title = {An improved multi-unit nuclear plant seismic probabilistic risk assessment approach},
	volume = {171},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832017308323},
	doi = {10.1016/j.ress.2017.11.015},
	language = {en},
	urldate = {2023-05-18},
	journal = {Reliability Engineering \& System Safety},
	author = {Zhou, Taotao and Modarres, Mohammad and Droguett, Enrique López},
	month = mar,
	year = {2018},
	pages = {34--47},
}

@article{hakata_seismic_2007,
	title = {Seismic {PSA} method for multiple nuclear power plants in a site},
	volume = {92},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832006001104},
	doi = {10.1016/j.ress.2006.04.022},
	abstract = {The maximum number of nuclear power plants in a site is eight and about 50\% of power plants are built in sites with three or more plants in the world. Such nuclear sites have potential risks of simultaneous multiple plant damages especially at external events. Seismic probabilistic safety assessment method (Level-1 PSA) for multi-unit sites with up to 9 units has been developed. The models include Fault-tree linked Monte Carlo computation, taking into consideration multivariate correlations of components and systems from partial to complete, inside and across units. The models were programmed as a computer program CORAL reef. Sample analysis and sensitivity studies were performed to verify the models and algorithms and to understand some of risk insights and risk metrics, such as site core damage frequency (CDF per site-year) for multiple reactor plants. This study will contribute to realistic state of art seismic PSA, taking consideration of multiple reactor power plants, and to enhancement of seismic safety.},
	language = {en},
	number = {7},
	urldate = {2023-05-18},
	journal = {Reliability Engineering \& System Safety},
	author = {Hakata, Tadakuni},
	month = jul,
	year = {2007},
	pages = {883--894},
}

@article{ma_developing_2018,
	title = {Developing {Generic} {Prior} {Distributions} for {Common} {Cause} {Failure} {Alpha} {Factors}},
	abstract = {Common cause failures (CCFs) have been recognized as significant risk contributors since the early launching of probabilistic risk assessments (PRAs). A series of United States Nuclear Regulatory Commission (U.S. NRC) regulation (NUREG) reports have been published since the 1980s to provide guidelines for CCF modeling in PRA. A CCF database system has been developed and maintained by the NRC and Idaho National Laboratory (INL) for the nuclear industry. However, although the CCF database system has been routinely maintained and the CCF parameter estimations updated on a yearly basis, the process for developing CCF parameter prior distributions has not been published and the prior distributions themselves have not been updated since the early 2000s. In this paper, an overview of the history of the NUREG CCF reports is provided. Existing CCF prior distributions are listed. The process for developing prior distributions for CCF parameter estimations is described. Prior distributions for CCF alpha factor are updated with data from 1997 through 2015. The issues identified from the study as well as the suggested future work are discussed.},
	language = {en},
	journal = {Los Angeles},
	author = {Ma, Zhegang and Schroeder, John and Smith, Curtis},
	year = {2018},
}

@article{schroeder_common_nodate,
	title = {Common {Cause} {Failure} {Data} and {Alpha} {Factor} {Modeling}},
	language = {en},
	author = {Schroeder, John A},
}

@misc{noauthor_probabilistic_nodate,
	title = {Probabilistic {Models} for the {Behavior} of {Compartment} {Fires} ({NUREG}/{CR}-2269)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2269/index.html},
	language = {en-US},
	urldate = {2023-05-17},
	journal = {NRC Web},
}

@article{noauthor_eprinrc-res_nodate,
	title = {{EPRI}/{NRC}-{RES} {Fire} {PRA} {Methodology} for {Nuclear} {Power} {Facilities} - {Volume} 1: {Summary} and {Overview}},
	language = {en},
}

@article{noauthor_eprinrc-res_nodate-1,
	title = {{EPRI}/{NRC}-{RES} {Fire} {PRA} {Methodology} for {Nuclear} {Power} {Facilities} - {Volume} 1: {Summary} and {Overview}},
	language = {en},
}

@article{gallucci_fire-induced_1981,
	title = {Fire-induced loss of nuclear power plant safety functions},
	volume = {64},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/002954938190039X},
	doi = {10.1016/0029-5493(81)90039-X},
	abstract = {A methodology is developed for evaluating the probability for loss of nuclear power plant safety functions due to fire. A framework for the investigation of fire scenarios involving safety-related equipment is established which models fire development as an event tree consisting of a series of ignition, detection, suppression, and propagation steps. The methodology has been applied to a representative BWR. Variations in the methodology are discussed for application to specific plants. Conservative estimates of core-damage probabilities due to fire were obtained; application of the methodology to a particular BWR including specific knowledge of cable locations, fire-retardants, detectors, etc. would result in considerably lower probabilities.},
	language = {en},
	number = {1},
	urldate = {2023-05-17},
	journal = {Nuclear Engineering and Design},
	author = {Gallucci, R. and Hockenbury, R.},
	month = mar,
	year = {1981},
	pages = {135--147},
}

@techreport{noauthor_branch_nodate,
	title = {{BRANCH} {TECHNICAL} {POSITION} {ASS} 9.5-1 {GUIDELINES} {FOR} {FIRE} {PROTECTION} {FOR} {NUCLEAR} {POWER} {PLANTS}},
	institution = {US NRC},
}

@incollection{siu_fire_2016,
	address = {New York, NY},
	title = {Fire {Risk} {Analysis} for {Nuclear} {Power} {Plants}},
	isbn = {978-1-4939-2565-0},
	url = {https://doi.org/10.1007/978-1-4939-2565-0_89},
	abstract = {Fire risk analysis for nuclear power plants, as currently performed in the U.S. and abroad, is focused on assessing the likelihood of a particular industrial accident: the loss of cooling to the reactor core and subsequent core damage.The analyses are performed using a probabilistic approach developed in the late 1970s and implemented in numerous studies.},
	language = {en},
	urldate = {2023-05-17},
	booktitle = {{SFPE} {Handbook} of {Fire} {Protection} {Engineering}},
	publisher = {Springer},
	author = {Siu, Nathan O. and Melly, Nicholas and Nowlen, Steven P. and Kazarians, Mardy},
	editor = {Hurley, Morgan J. and Gottuk, Daniel and Hall, John R. and Harada, Kazunori and Kuligowski, Erica and Puchovsky, Milosh and Torero, José and Watts, John M. and Wieczorek, Christopher},
	year = {2016},
	doi = {10.1007/978-1-4939-2565-0_89},
	keywords = {Fire Protection, Fire Risk, Fire Source, Nuclear Power Plant, Plant Area},
	pages = {3326--3369},
}

@techreport{fleming_risk_1980,
	title = {Risk assessment of major fires in an {HTGR} plant},
	url = {https://www.osti.gov/biblio/5553356},
	abstract = {The HTGR Risk Assessment Study has been extended to include major fires as initiating events. The major aspects of this study have included the development of methodology, the collection and interpretation of fire experience data and the application of these methods and data to an HTGR plant. Qualitative and quantitative methods were derived to screen a nuclear plant layout and identify important fire locations. A fire propagation model was used in conjunction with experience data and detailed fault tree analyses to estimate common cause failure probabilities associated with a spectrum of potential fires. It was determined that fires make a significant contribution to the HTGR risk assessment only at accident frequency levels below 10/sup -7//reactor-year.},
	language = {English},
	number = {GA-A-15622; CONF-800403-38},
	urldate = {2023-05-17},
	institution = {General Atomic Co., San Diego, CA (USA)},
	author = {Fleming, K. N.},
	month = apr,
	year = {1980},
}

@article{von_cube_monetary_2016,
	series = {Factories of the {Future} in the digital environment - {Proceedings} of the 49th {CIRP} {Conference} on {Manufacturing} {Systems}},
	title = {Monetary {Quantification} of {Supply} {Risks} of {Manufacturing} {Enterprises} - {Discrete} {Event} {Simulation} {Based} {Approach}},
	volume = {57},
	issn = {2212-8271},
	url = {https://www.sciencedirect.com/science/article/pii/S2212827116311829},
	doi = {10.1016/j.procir.2016.11.029},
	abstract = {Various approaches exist to quantify risks in supply chains. However, two aspects in risk assessments are not usually considered: monetarized risk quantification and use-case dependent model complexity. Monetarily quantifying risks means quantifying root-cause and severity of each single risk and aggregating these risks into an aggregated risk value. Thereby information uncertainty, complex interrelations and dynamic influences need to be considered. Depending on a use-case's goal information or process models need to be created at different levels of detail. This paper presents a Discrete Event Simulation (DES) approach providing all necessary features to monetarily quantify risks independent of the depth of information and thus allow adjusting the model dependent on the use-case. It provides graphical modeling language equipped with risk assessment probes enabling to capture all risk-relevant aspects. Based on this instrumented model, the framework is then able to compute and report about monetary risk quantification using an efficient DES engine driven by a Monte-Carlo procedure. Within this paper applicability of such an approach shall be assessed in use-case specific processes characterized by determined risks and parameter settings.},
	language = {en},
	urldate = {2023-05-12},
	journal = {Procedia CIRP},
	author = {von Cube, Philipp and Härtel, Lasse and Schmitt, Robert and Ponsard, Christophe and Massonet, Philippe and De Landtsheer, Renaud and Ospina, Gustavo and Printz, Stephan and Jeschke, Sabina},
	month = jan,
	year = {2016},
	keywords = {discrete event simulation, monetary risk quantification, monte carlo simulation, use-cases},
	pages = {164--170},
}

@article{lau_risk_2021,
	title = {Risk quantification in cold chain management: a federated learning-enabled multi-criteria decision-making methodology},
	volume = {121},
	issn = {0263-5577},
	shorttitle = {Risk quantification in cold chain management},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IMDS-04-2020-0199/full/html},
	doi = {10.1108/IMDS-04-2020-0199},
	abstract = {Purpose: In the cold supply chain, effective risk management is regarded as an essential component to address the risky and uncertain supply chain environment in the handling temperature-time-sensitive products. However, existing multi-criteria decision-making (MCDM) approaches greatly rely on expert opinions for pairwise comparisons. Despite the fact that machine learning models can be customised to conduct pairwise comparisons, it is difficult for small and medium enterprises (SMEs) to intelligently measure the ratings between risk criteria without sufficiently large datasets. Therefore, this paper aims at developing an enterprise-wide solution to identify and assess cold chain risks.},
	language = {en},
	number = {7},
	urldate = {2023-05-12},
	journal = {Industrial Management \& Data Systems},
	author = {Lau, Henry and Tsang, Yung Po and Nakandala, Dilupa and Lee, Carman K.M.},
	month = jul,
	year = {2021},
	pages = {1684--1703},
}

@article{kt_integrated_2019,
	title = {An integrated framework for the assessment of inbound supply risk and prioritization of the risk drivers: {A} real-life case on electronics supply chain},
	volume = {27},
	issn = {1463-5771},
	shorttitle = {An integrated framework for the assessment of inbound supply risk and prioritization of the risk drivers},
	url = {https://www.emerald.com/insight/content/doi/10.1108/BIJ-03-2019-0119/full/html},
	doi = {10.1108/BIJ-03-2019-0119},
	abstract = {Purpose – The purpose of this paper is to present a framework for identifying various inbound supply-risk factors and analyzing its indicators considering the contextual relationship between them. This study additionally proposes a framework for developing an overall inbound supply-risk score considering a real-life case of the electronics supply chain (ESC) in the Indian context.},
	language = {en},
	number = {3},
	urldate = {2023-05-12},
	journal = {Benchmarking: An International Journal},
	author = {K.T., Ramesh and Sarmah, Sarada P. and Tarei, Pradeep Kumar},
	month = dec,
	year = {2019},
	pages = {1261--1286},
}

@inproceedings{macqueen_total_1999,
	address = {Norfolk, VA, USA},
	title = {Total ionizing dose effects in a {SRAM}-based {FPGA}},
	isbn = {978-0-7803-5660-3},
	url = {http://ieeexplore.ieee.org/document/816052/},
	doi = {10.1109/REDW.1999.816052},
	urldate = {2023-05-12},
	booktitle = {1999 {IEEE} {Radiation} {Effects} {Data} {Workshop}. {Workshop} {Record}. {Held} in conjunction with {IEEE} {Nuclear} and {Space} {Radiation} {Effects} {Conference} ({Cat}. {No}.{99TH8463})},
	publisher = {IEEE},
	author = {MacQueen, D.M. and Gingrich, D.M. and Buchanan, N.J. and Green, P.W.},
	year = {1999},
	pages = {24--29},
}

@article{yao_impact_2008,
	title = {The {Impact} of {Total} {Ionizing} {Dose} on {Unhardened} {SRAM} {Cell} {Margins}},
	volume = {55},
	issn = {0018-9499},
	url = {http://ieeexplore.ieee.org/document/4723767/},
	doi = {10.1109/TNS.2008.2007122},
	number = {6},
	urldate = {2023-05-12},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Yao, Xiaoyin and Hindman, Nathan and Clark, Lawrence T. and Holbert, Keith E. and Alexander, David R. and Shedd, Walter M.},
	month = dec,
	year = {2008},
	pages = {3280--3287},
}

@inproceedings{rezzak_total_2014,
	address = {Paris, France},
	title = {Total {Ionizing} {Dose} {Characterization} of 65 nm {Flash}-{Based} {FPGA}},
	isbn = {978-1-4799-5884-9 978-1-4799-5883-2 978-1-4799-5882-5},
	url = {http://ieeexplore.ieee.org/document/7004606/},
	doi = {10.1109/REDW.2014.7004606},
	urldate = {2023-05-12},
	booktitle = {2014 {IEEE} {Radiation} {Effects} {Data} {Workshop} ({REDW})},
	publisher = {IEEE},
	author = {Rezzak, Nadia and Wang, Jih-Jong and Huang, Chang-Kai and Nguyen, Victor and Bakker, Gregory},
	month = jul,
	year = {2014},
	pages = {1--5},
}

@article{gyagenda_review_2022,
	title = {A review of {GNSS}-independent {UAV} navigation techniques},
	volume = {152},
	issn = {09218890},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889022000343},
	doi = {10.1016/j.robot.2022.104069},
	language = {en},
	urldate = {2023-05-12},
	journal = {Robotics and Autonomous Systems},
	author = {Gyagenda, Nasser and Hatilima, Jasper V. and Roth, Hubert and Zhmud, Vadim},
	month = jun,
	year = {2022},
	pages = {104069},
}

@inproceedings{balamurugan_survey_2016,
	address = {Paralakhemundi, Odisha, India},
	title = {Survey on {UAV} navigation in {GPS} denied environments},
	isbn = {978-1-5090-4620-1},
	url = {http://ieeexplore.ieee.org/document/7955787/},
	doi = {10.1109/SCOPES.2016.7955787},
	urldate = {2023-05-12},
	booktitle = {2016 {International} {Conference} on {Signal} {Processing}, {Communication}, {Power} and {Embedded} {System} ({SCOPES})},
	publisher = {IEEE},
	author = {Balamurugan, G and Valarmathi, J and Naidu, V P S},
	month = oct,
	year = {2016},
	pages = {198--204},
}

@inproceedings{conte_integrated_2008,
	address = {Big Sky, MT, USA},
	title = {An {Integrated} {UAV} {Navigation} {System} {Based} on {Aerial} {Image} {Matching}},
	isbn = {978-1-4244-1487-1 978-1-4244-1488-8},
	url = {http://ieeexplore.ieee.org/document/4526556/},
	doi = {10.1109/AERO.2008.4526556},
	urldate = {2023-05-12},
	booktitle = {2008 {IEEE} {Aerospace} {Conference}},
	publisher = {IEEE},
	author = {Conte, Gianpaolo and Doherty, Patrick},
	month = mar,
	year = {2008},
	note = {ISSN: 1095-323X},
	pages = {1--10},
}

@article{ayoub_generic_2022,
	title = {Generic and adaptive probabilistic safety assessment models: {Precursor} analysis and multi-purpose utilization},
	volume = {54},
	issn = {17385733},
	shorttitle = {Generic and adaptive probabilistic safety assessment models},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573322001334},
	doi = {10.1016/j.net.2022.03.013},
	abstract = {Motivated by learning from experience and exploiting existing knowledge in civil nuclear operations, we have developed in-house generic Probabilistic Safety Assessment (PSA) models for pressurized and boiling water reactors. The models are computationally light, handy, transparent, user-friendly, and easily adaptable to account for major plant-speciﬁc differences. They cover the common internal initiating events, frontline and support systems reliability and dependencies, human-factors, common-cause failures, and account for new factors typically overlooked in many PSAs. For quantiﬁcation, the models use generic US reliability data, precursor analysis reports, the ETHZ Curated Nuclear Events Database, and experts’ opinions. Moreover, uncertainties in the most inﬂuential basic events are addressed. The generated results show good agreement with assessments available in the literature with detailed PSAs. We envision the models as an unbiased framework to measure nuclear operational risk with the same “ruler”, and hence support inter-plant risk comparisons that are usually not possible due to differences in plant-speciﬁc PSA assumptions and scopes. The models can be used for initial risk screening, order-ofmagnitude precursor analysis, and other research/pedagogic applications especially when no plantspeciﬁc PSAs are available. Finally, we are using the generic models for large-scale precursor analysis that will generate big picture trends, lessons, and insights.},
	language = {en},
	number = {8},
	urldate = {2023-05-09},
	journal = {Nuclear Engineering and Technology},
	author = {Ayoub, Ali and Kröger, Wolfgang and Sornette, Didier},
	month = aug,
	year = {2022},
	pages = {2924--2932},
}

@article{lawrence_leveraging_2020,
	title = {Leveraging a {Bayesian} network approach to model and analyze supplier vulnerability to severe weather risk: {A} case study of the {U}.{S}. pharmaceutical supply chain following {Hurricane} {Maria}},
	volume = {49},
	issn = {2212-4209},
	shorttitle = {Leveraging a {Bayesian} network approach to model and analyze supplier vulnerability to severe weather risk},
	url = {https://www.sciencedirect.com/science/article/pii/S2212420919311847},
	doi = {10.1016/j.ijdrr.2020.101607},
	abstract = {The United States government has identified the health care sector as part of the critical infrastructure for homeland security to protect citizens against health risks arising from terrorism, natural disasters, and epidemics. Citizens also have expectations about the role that health care plays in enjoying a good quality of life, by providing response systems to handle emergencies and other illness situations adequately. Among the systems required to supportdesired performance levels is a robust and resilient pharmaceutical supply chain that is free of disruption. Shortages of drugs place undue pressure on healthcare providers to devise alternative approaches to administer patient care. With climate change expected to result in increasingly severe weather patterns in the future, it is critical that logistics engineers understand the impact that a catastrophic weather event could have on supply chain disruption to facilitate the design of supply systems that are robust and resilient. This study investigates the main causal and intermediate events that led to risk propagation in, and disruption of, the U.S. pharmaceutical supply chain following Hurricane Maria. A causality Bayesian model is developed to depict linkages between risk events and quantify the associated cumulative risk. The quantification is further examined through different advanced techniques such as predictive inference reasoning and sensitivity analysis. The general interpretation of these analyses suggests that port resilience is imperative to pharmaceutical supply chain performance in the case of Puerto Rico.},
	language = {en},
	urldate = {2023-05-08},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Lawrence, Jeanne-Marie and Ibne Hossain, Niamat Ullah and Jaradat, Raed and Hamilton, Michael},
	month = oct,
	year = {2020},
	keywords = {Bayesian network, Hurricane, Pharmaceutical supply chain, Puerto Rico, Resilience, Severe weather risk, Supply chain risk},
	pages = {101607},
}

@article{sharma_supply_2022,
	title = {Supply chain risk factor assessment of {Indian} pharmaceutical industry for performance improvement},
	volume = {ahead-of-print},
	issn = {1741-0401},
	url = {https://doi.org/10.1108/IJPPM-01-2022-0035},
	doi = {10.1108/IJPPM-01-2022-0035},
	abstract = {Purpose The purpose of the present work is to improve the industry performance by identifying and quantifying the risks faced by the Indian pharmaceutical industry (IPI). The risk values for the prominent risks and overall industry are determined based on the four risk parameters, which would help determine the most contributive risks for mitigation. Design/methodology/approach An extensive literature survey was done to identify the risks, which were also validated by industry experts. The finalized risks were then evaluated using the fuzzy synthetic evaluation (FSE) method, which is the most suitable approach for the risk assessment with parameters having a set of different risk levels. Findings The three most contributive sub-risks are counterfeit drugs, demand fluctuations and loss of customers due to partners' poor service performance, while the main risks obtained are demand, financial and logistics. Also, the overall risk value indicates that the industry faces medium to high risk. Practical implications The study identifies the critical risks which need to be mitigated for an efficient industry. The industry is most vulnerable to the demand risk category. Therefore, the managers should minimize this risk by mitigating its sub-risks, like demand fluctuations, bullwhip effect, etc. Another critical sub-risk, the counterfeit risk, should be managed by adopting advanced technologies like blockchain, artificial intelligence, etc. Originality/value There is insufficient literature focusing on risk quantification. Therefore, this work addresses this gap and obtains the industry's most critical risks. It also discusses suitable mitigation strategies for better industry performance.},
	number = {ahead-of-print},
	urldate = {2023-05-08},
	journal = {International Journal of Productivity and Performance Management},
	author = {Sharma, Astha and Kumar, Dinesh and Arora, Navneet},
	month = jan,
	year = {2022},
	keywords = {Fuzzy synthetic evaluation, Healthcare, Pharmaceutical industry, Risk analysis},
}

@article{bogaert_qualitative_2015,
	title = {A {Qualitative} {Approach} to a {Better} {Understanding} of the {Problems} {Underlying} {Drug} {Shortages}, as {Viewed} from {Belgian}, {French} and the {European} {Union}’s {Perspectives}},
	volume = {10},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4420462/},
	doi = {10.1371/journal.pone.0125691},
	abstract = {The problem of drug shortages has been reported worldwide, gaining prominence in multiple domains and several countries in recent years. The aim of the study was to analyze, characterise and assess this problem in Belgium and France, while also adopting a wider perspective from the European Union. A qualitative methodological approach was employed, including semi-structured interviews with the representatives of respective national health authorities, pharmaceutical companies and wholesalers, as well as hospital and community pharmacists. The research was conducted in early 2014. Four themes, which were identified through the interviews, were addressed in the paper, i.e. a) defining drug shortages, b) their dynamics and perception, c) their determinants, d) the role of the European and national institutions in coping with the problem. Three groups of determinants of drug shortages were identified throughout this study: manufacturing problems, distribution and supply problems, and problems related to economic aspects. Currently, the Member States of the European Union are striving to resolve the problem very much on their own, although a far more focused and dedicated collaboration may well prove instrumental in coping with drug shortages throughout Europe more effectively. To the best of the authors’ knowledge, this is the first qualitative study to investigate the characteristics, key determinants, and the problem drivers of drug shortages, focusing on this particular group of countries, while also adopting the European Union’s perspective.},
	number = {5},
	urldate = {2023-05-08},
	journal = {PLoS ONE},
	author = {Bogaert, Petronille and Bochenek, Tomasz and Prokop, Anna and Pilc, Andrzej},
	month = may,
	year = {2015},
	pmid = {25942432},
	pmcid = {PMC4420462},
	pages = {e0125691},
}

@article{ramesh_integrated_2020,
	title = {An integrated framework for the assessment of inbound supply risk and prioritization of the risk drivers: {A} real-life case on electronics supply chain},
	volume = {27},
	copyright = {© Emerald Publishing Limited 2019},
	issn = {14635771},
	shorttitle = {An integrated framework for the assessment of inbound supply risk and prioritization of the risk drivers},
	url = {https://www.proquest.com/docview/2534583609/abstract/C11547F5FBB84EBFPQ/1},
	doi = {10.1108/BIJ-03-2019-0119},
	abstract = {Purpose
The purpose of this paper is to present a framework for identifying various inbound supply-risk factors and analyzing its indicators considering the contextual relationship between them. This study additionally proposes a framework for developing an overall inbound supply-risk score considering a real-life case of the electronics supply chain (ESC) in the Indian context.
In total, 32 risk indicators are identified by a systematic literature review approach and are validated by supply chain practitioners/experts and further categorized into six main risk factors. A hybrid multi-criteria decision-making-based DANP (DEMATEL and ANP) framework is employed to develop the overall inbound-supply-risk score (ISRS) and to prioritize the risk indicators. Indian ESC is chosen as a viable case study to demonstrate the effectiveness of the proposed framework.
The outcomes from the study reveal that the overall ISRS in the ESC is 36 percent and additionally forewarns critical inbound-supply-risk factors such as supplier performance, product, and buyer organization. Further, the study also identifies the most significant risk indicators such as price margin, investment, on-time delivery, order fulfillment and design changes for ESC.
Supply chain practitioners can adopt this framework as a useful inbound supply-risk assessment tool. Moreover, the hybrid framework will address subjectivity and interrelations among various factors through experts’ judgments. The results will assist the managers to have better insights on the critical risk factors and their complicated interrelationships and further strategize action plans to nullify the impact of incoming risks. This study mainly focused on risk identification and assessment of electronics inbound-supply-risk indicators in the Indian context. The framework can be used for other manufacturing and service industries, albeit the results derived are in the context of a developing country.
This paper provides an effective risk assessment framework for the supply chain practitioners/managers to develop a decision-support system for inbound-supply-risk quantification and prioritization of risk factors in the context of the ESC.},
	language = {English},
	number = {3},
	urldate = {2023-05-08},
	journal = {Benchmarking},
	author = {Ramesh, K. T. and Sarmah, Sarada P. and Tarei, Pradeep Kumar},
	year = {2020},
	note = {Num Pages: 26
Place: Bradford, United Kingdom
Publisher: Emerald Group Publishing Limited},
	keywords = {Business And Economics--Management, Competitive advantage, Context, Decision making, Decision support systems, Developing countries--LDCs, Electronics, Electronics industry, Identification, Indicators, Literature reviews, Manufacturing, Multiple criterion, OEM, Product life cycle, Raw materials, Research, Risk analysis, Risk assessment, Risk factors, Service industries, Suppliers, Supply chains},
	pages = {1261--1286},
}

@article{zhang_resilience-cost_2021,
	title = {Resilience-cost tradeoff supply chain planning for the prefabricated construction project},
	volume = {27},
	copyright = {© 2021. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
	issn = {13923730},
	url = {https://www.proquest.com/docview/2488164230/abstract/78FCAEA741424DC3PQ/1},
	doi = {10.3846/jcem.2021.14114},
	abstract = {Delivery of the prefabricated components may be disrupted by low productivity and various of traffic restrictions, thus delaying the prefabricated construction project. However, planning of the prefabricated component supply chain (PCSC) under disruptions has seldom been studied. This paper studies the construction schedule-dependent resilience for the PCSC plan by considering transportation costs and proposes a multi-objective optimization model. First, the PCSC planning problem regarding schedule-dependent resilience and resultant transportation cost is analyzed. Second, a quantification scheme of the schedule-dependent resilience of the PCSC plan is proposed. Third, formulation of the resilience-cost tradeoff optimization model for the PCSC planning is developed. Fourth, the multi-objective particle swarm optimization (MOPSO)-based method for solving the resilience-cost tradeoff model is presented. Finally, a case study is presented to demonstrate and justify the developed method. This study contributes to the knowledge and methodologies for PCSC management by addressing resilience at the planning stage.},
	language = {English},
	number = {1},
	urldate = {2023-05-08},
	journal = {Journal of Civil Engineering and Management},
	author = {Zhang, Hong and Lu, Yu and Link to external site, this link will open in a new window},
	month = jan,
	year = {2021},
	note = {Num Pages: 45-59
Place: Vilnius, Lithuania
Publisher: Vilnius Gediminas Technical University
Section: Articles},
	keywords = {disruption, multiobjective particle swarm optimization (MOPSO), prefabricated component supply chain (PCSC), prefabricated construction, resilience quantification, resiliencecost tradeoff, scheduledependent resilience},
	pages = {45--59},
}

@article{tarei_hybrid_2018,
	title = {A hybrid approach for quantifying supply chain risk and prioritizing the risk drivers: {A} case of {Indian} petroleum supply chain},
	volume = {29},
	issn = {1741-038X},
	shorttitle = {A hybrid approach for quantifying supply chain risk and prioritizing the risk drivers},
	url = {https://doi.org/10.1108/JMTM-10-2017-0218},
	doi = {10.1108/JMTM-10-2017-0218},
	abstract = {Purpose The purpose of this paper is to identify various risk and sub-risk drivers that affect the supply chain (SC) performance and to propose a framework to quantify the overall SC risk index by considering the importance of each risk and sub-risk drivers and their mutual interactions. Design/methodology/approach A hybrid method based on decision-making trial and evaluation laboratory and analytical network process has been proposed to develop the risk quantification framework. A case study of Indian petroleum supply chain (PSC) has been illustrated to explain the proposed method. Findings The results of this study found that transportation/logistics (delivery system), quality of the petroleum products, crude supply, customer’s order and legal/political regulations are the most significant risk drivers of a typical PSC. It is also found that the Indian PSC possesses a risk score of 34 percent. Research limitations/implications The quantification of risk in operational measure provides an unblemished representation of the overall SC risk. Unlike the existing financial measure, it takes complex subjective operational effectiveness like product quality, customer satisfaction, etc., into consideration. Identifying the high-prioritized risks helps the decision and policy makers to merely focus on the most prominent risk drivers, and reduce the impact of overall SC risk. Planning a risk mitigation strategy at a given level of risk is however beyond the scope of this research. Originality/value The paper develops a risk quantification framework in the context of a PSC.},
	number = {3},
	urldate = {2023-05-08},
	journal = {Journal of Manufacturing Technology Management},
	author = {Tarei, Pradeep Kumar and Thakkar, Jitesh J. and Nag, Barnali},
	month = jan,
	year = {2018},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {ANP, DEMATEL, Petroleum supply chain, Supply chain risk assessment},
	pages = {533--569},
}

@article{nishat_faisal_information_2007,
	title = {Information risks management in supply chains: an assessment and mitigation framework},
	volume = {20},
	issn = {1741-0398},
	shorttitle = {Information risks management in supply chains},
	url = {https://doi.org/10.1108/17410390710830727},
	doi = {10.1108/17410390710830727},
	abstract = {Purpose – This paper aims to identify various information risks that could impact a supply chain, and develops a conceptual framework to quantify and mitigate them. Design/methodology/approach – Graph theory has been used to quantify information risks while interpretive structural modelling (ISM) is employed to understand the interrelationships among the enablers of information risks mitigation. Findings – The research presents a classification of the enablers of information risks mitigation according to their driving power and dependence. It also presents a risk index to quantify information risks. The research suggests that management should focus on improving the high driving power enabler variables. Practical implications – The proposed risk index and the hierarchy‐based model would help to develop suitable strategies to manage information risks in supply chains. Originality/value – The major contribution of this paper lies in the development of a framework to quantify information risks and a hierarchy based model for their mitigation in context of supply chains.},
	number = {6},
	urldate = {2023-05-08},
	journal = {Journal of Enterprise Information Management},
	author = {Nishat Faisal, Mohd and Banwet, D.K. and Shankar, Ravi},
	month = jan,
	year = {2007},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Graph theory, Information management, Risk management, Supply chain management},
	pages = {677--699},
}

@article{rathore_quantitative_2017,
	title = {A quantitative risk assessment methodology and evaluation of food supply chain},
	volume = {28},
	issn = {0957-4093},
	url = {https://doi.org/10.1108/IJLM-08-2016-0198},
	doi = {10.1108/IJLM-08-2016-0198},
	abstract = {Purpose The food supply chain is exposed to severe environmental and social issues with serious economic consequences. The identification and assessment of risk involved in the food supply chain can help to overcome these challenges. In response, the purpose of this paper is to develop a risk assessment framework for a typical food supply chain. Design/methodology/approach An integrated methodology of grey analytical hierarchy process and grey technique for order preference by similarity to the ideal solution is proposed for developing a comprehensive risk index. The opinion of the experts is used to illustrate an application of the proposed methodology for the risk assessment of the food supply chain in India. Findings Valuable insights and recommendations are drawn from the results, which are helpful to the practitioners working at strategic and tactical levels in the food supply chain for minimising the supply chain disruptions. Research limitations/implications The risk quantification for the case organisation is primarily based on inputs collected from the experts working for Indian food supply chain, and so the generalisation of the results is limited to the context of developing countries. However, the generalisability of the proposed risk quantification methodology and key insights developed in the food supply chain will assist practitioners in policy making. Practical implications The risk priorities established by this research would enable an implementation of systematic risk mitigation strategies and deployment of necessary resources for leveraging the efficiency of food supply chain. Originality/value Specifically, this research has delivered a risk quantification framework and strengthened the inquiry of risk management for the food supply chain.},
	number = {4},
	urldate = {2023-05-08},
	journal = {The International Journal of Logistics Management},
	author = {Rathore, Rishabh and Thakkar, Jitesh J. and Jha, Jitendra Kumar},
	month = jan,
	year = {2017},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {Analytic hierarchy process (AHP), Food supply chain, Risk management, Technique for order preference and similarity to ideal solution (TOPSIS)},
	pages = {1272--1293},
}

@inproceedings{qazi_novel_2014,
	address = {Dagstuhl, Germany},
	series = {{OpenAccess} {Series} in {Informatics} ({OASIcs})},
	title = {A {Novel} {Framework} for {Quantification} of {Supply} {Chain} {Risks}},
	volume = {37},
	isbn = {978-3-939897-67-5},
	url = {http://drops.dagstuhl.de/opus/volltexte/2014/4665},
	doi = {10.4230/OASIcs.SCOR.2014.1},
	urldate = {2023-05-01},
	booktitle = {4th {Student} {Conference} on {Operational} {Research}},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Qazi, Abroon and Quigley, John and Dickson, Alex},
	editor = {Granado, Pedro Crespo Del and Joyce-Moniz, Martim and Ravizza, Stefan},
	year = {2014},
	note = {ISSN: 2190-6807},
	keywords = {bayesian belief network, cognitive maps, conflicting incentives, game theory, supply chain risk management},
	pages = {1--15},
}

@article{yankai_application_2020,
	title = {Application of the dynamic {FMEA} in the reliability analysis of {DCS}},
	volume = {194},
	issn = {2267-1242},
	url = {https://www.e3s-conferences.org/10.1051/e3sconf/202019401018},
	doi = {10.1051/e3sconf/202019401018},
	abstract = {Digital distributed instrumentation and control system (DCS) is critical to the safety of nuclear power plants (NPPs). Static analysis methods developed from analog control system are not applicable to DCS due to its enhanced dynamic interactions and complex structure of hardware/software/firmware. The enhanced dynamic interactions of DCS include both sequence and timing factors, which are hardly modelled in the traditional Failure Mode and Effect Analysis (FMEA). In this study, dynamic FMEA (DFMEA) method based on simulation technology is put forward for the design and review of DCS in NPP. DFMEA based on real DCS hardware and software is developed to reveal the dynamic failure paths and failure modes. The results of DFMEA can well support the establishment of the dynamic fault tree/event tree in the review of NPP DCS, which reduces the dependency on the analyst’s experience significantly.},
	urldate = {2023-05-01},
	journal = {E3S Web of Conferences},
	author = {Yankai, Li and Xu, Wang and Meng, Lin},
	editor = {Weerasinghe, R. and Wu, J. and Weng, C.-H.},
	year = {2020},
	pages = {01018},
}

@techreport{bao_integrated_2019,
	title = {An {Integrated} {Risk} {Assessment} {Process} for {Digital} {Instrumentation} and {Control} {Upgrades} of {Nuclear} {Power} {Plants}},
	url = {https://www.osti.gov/servlets/purl/1616252/},
	number = {INL/EXT--19-55219-Rev000, 1616252},
	urldate = {2023-05-01},
	author = {Bao, Han and Zhang, Hongbin and Thomas, Kenneth},
	month = aug,
	year = {2019},
	doi = {10.2172/1616252},
	pages = {INL/EXT--19--55219--Rev000, 1616252},
}

@article{shorthill_novel_2021,
	title = {A novel approach for software reliability analysis of digital instrumentation and control systems in nuclear power plants},
	volume = {158},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921001365},
	doi = {10.1016/j.anucene.2021.108260},
	language = {en},
	urldate = {2023-05-01},
	journal = {Annals of Nuclear Energy},
	author = {Shorthill, Tate and Bao, Han and Zhang, Hongbin and Ban, Heng},
	month = aug,
	year = {2021},
	pages = {108260},
}

@article{munoz_quantification_2015,
	title = {On the quantification of operational supply chain resilience},
	volume = {53},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2015.1057296},
	doi = {10.1080/00207543.2015.1057296},
	abstract = {Operational disruptions impact a supply chain’s ability to match supply and demand. To remain competitive, supply chains need to be resilient and thus capable of rapidly and effectively recovering from operational disruptions. Supply chain resilience is inherently multidimensional, as it spans across multiple tiers, and thus is difficult to quantify. Extant research has measured the transient response through a single-dimension or single-organisation as a proxy for operational resilience. Whilst this greatly simplifies the analysis, it is also potentially misleading, as an erroneous selection of metric(s) may lead to an inaccurate evaluation of the transient response. This research extends the understanding of operational resilience via quantitative evaluation of multiple transient response measures across multiple tiers; the objective being to construct a multidimensional, multi-echelon operational supply chain resilience metric. The study utilises disruptions as experimental inputs for a serial supply chain simulation model; results are obtained for individual measurements of the transient response across multiple supply chain tiers. Analysis indicates that individual dimensions of resilience can adequately explain the transient response at the single-firm level, whilst aggregation of multiple resilience dimensions across multiple tiers has greater capacity to holistically capture the performance response to supply chain disruptions.},
	number = {22},
	urldate = {2023-05-01},
	journal = {International Journal of Production Research},
	author = {Munoz, Albert and Dunbar, Michelle},
	month = nov,
	year = {2015},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2015.1057296},
	keywords = {performance measurement, resilience, simulation applications, structural equation modelling},
	pages = {6736--6751},
}

@article{rinaldi_literature_2022,
	title = {A literature review on quantitative models for supply chain risk management: {Can} they be applied to pandemic disruptions?},
	volume = {170},
	issn = {0360-8352},
	shorttitle = {A literature review on quantitative models for supply chain risk management},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9197564/},
	doi = {10.1016/j.cie.2022.108329},
	abstract = {Supply chain risk management is considered a topic of increasing interest worldwide and its focus has evolved over time. The recent coronavirus pandemic (known as COVID-19) has forced business to handle a new global crisis and rapidly adapt to unexpected challenges. In an attempt to help companies counteract the pandemic risk, as well as to fuel the scientific discussion about this topic, this paper proposes a systematic literature review on risk management and disruptions in the supply chain focusing on quantitative models and paying a particular attention to highlighting the potentials of the studies reviewed for being applied to counteract pandemic emergencies. An appropriate query was made on Scopus and returned, after a manual screening, a useful set of 99 papers that proposed models for supply chain risk management. The relevant aspects of pandemics risk management have been first identified and mapped; then, the studies reviewed have been analysed with the aim of evaluating their suitability of being applied to sanitary crises. In carrying out this review of the literature, the study moves from previous, more general, reviews about risk management and updates them, starting from the lines of research that have been covered in recent years and evaluating their consistency with future research directions emerging also as a consequence of the pandemic crisis. Gaps and limitations of the existing models are identified and future research directions for pandemics risk management are suggested.},
	urldate = {2023-05-01},
	journal = {Computers \& Industrial Engineering},
	author = {Rinaldi, Marta and Murino, Teresa and Gebennini, Elisa and Morea, Donato and Bottani, Eleonora},
	month = aug,
	year = {2022},
	pmid = {35722204},
	pmcid = {PMC9197564},
	pages = {108329},
}

@article{shorthill_redundancy-guided_2022,
	title = {A {Redundancy}-{Guided} {Approach} for the {Hazard} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} in {Advanced} {Nuclear} {Power} {Plants}},
	volume = {208},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2021.1957659},
	doi = {10.1080/00295450.2021.1957659},
	language = {en},
	number = {5},
	urldate = {2023-05-01},
	journal = {Nuclear Technology},
	author = {Shorthill, Tate and Bao, Han and Zhang, Hongbin and Ban, Heng},
	month = may,
	year = {2022},
	pages = {892--911},
}

@book{beizer_black-box_1995,
	title = {Black-box testing: techniques for functional testing of software and systems},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Beizer, Boris},
	year = {1995},
}

@article{popovic_testing_1987,
	title = {Testing and installation of a {BWR} digital feedwater control system: {Final} report},
	url = {https://www.osti.gov/biblio/5625789},
	author = {Popovic, J R and Hammer, M F and Sun, B K.H. and Divakaruni, S M},
	month = dec,
	year = {1987},
}

@article{miltersen_derandomizing_2001,
	title = {Derandomizing complexity classes},
	volume = {9},
	number = {2},
	journal = {COMBINATORIAL OPTIMIZATION-DORDRECHT-},
	author = {Miltersen, Peter Bro},
	year = {2001},
	note = {Publisher: Kluwer Academic Publishers},
	pages = {843--941},
}

@article{aldemir_computer-assisted_1987,
	title = {Computer-{Assisted} {Markov} {Failure} {Modeling} of {Process} {Control} {Systems}},
	volume = {R-36},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/5222318/},
	doi = {10.1109/TR.1987.5222318},
	number = {1},
	urldate = {2023-05-01},
	journal = {IEEE Transactions on Reliability},
	author = {Aldemir, Tunc},
	month = apr,
	year = {1987},
	pages = {133--144},
}

@book{hsu_cell--cell_2013,
	title = {Cell-to-cell mapping: a method of global analysis for nonlinear systems},
	volume = {64},
	publisher = {Springer Science \& Business Media},
	author = {Hsu, Chieh Su},
	year = {2013},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {LMP} {Lessons} {Learned}, {Best} {Practices}, and {Frequently} {Asked} {Questions}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1700534},
	abstract = {This report captures lessons learned, best practices, and frequently asked questions with responses gleaned from the experiences of early adopters of the LMP RIPB process. Interviews were conducted in late 2019 with five non-LWR design organizations to gather their feedback on the application of the LMP RIPB process under real production conditions. The overall feedback from the reactor developers is that the LMP RIPB process can be successfully implemented with material benefits to the designer. As with any new processes, numerous challenges and questions were relayed by the designers. These challenges have been translated into lessons learned and best practices. Those two sections address both technical and organizational aspects of implementing the LMP RIPB process. Questions that were asked by multiple designers were turned into “frequently asked questions” and responses were provided by the LMP team.},
	language = {English},
	number = {INL/EXT-20-60392-Rev000},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700534},
}

@techreport{moe_modernization_2020-1,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors} ({Final} {Project} {Report})},
	url = {https://www.osti.gov/biblio/1700667},
	abstract = {Advanced (i.e., non-light-water) reactor technologies offer developers new opportunities to enhance the reliability, efficiency, and safety of nuclear power reactors through changes in fundamental design and operation. A variety of advanced design concepts are being developed that generally trend toward increased reliance on innovative, inherent, and passive safety features. Many of these features are substantially different from components now found in large light water reactors (LWRs) that dominate the commercial operating fleet. Similarly, non-light water reactor (non-LWR) suppliers are also pursuing market niches quite different from the regional baseload power generation sites typically associated with large LWR facilities.},
	language = {English},
	number = {INL/EXT-20-60393; SC-29980-105-Rev.01},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company, Atlanta, GA (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700667},
}

@techreport{moe_modernization_2019,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Safety} {Classification} and {Performance} {Criteria} for {Structures}, {Systems}, and {Components}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1560535},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Safety Classification and Performance Criteria for Structures, Systems and Components,” represents a key element in the development of a framework for the efficient licensing of advanced non-Light Water Reactors (non-LWRs).},
	language = {English},
	number = {INL/EXT-19-55516-Rev000; SC-29980-102.Rev0},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company Services, Birmingham, AL (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = aug,
	year = {2019},
	doi = {10.2172/1560535},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1700670},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Probabilistic Risk Assessment Approach,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs). It is the result of a Licensing Modernization Project (LMP) led by Southern Company and cost-shared by the U.S. Department of Energy (DOE). The LMP has developed detailed proposals for establishing licensing technical requirements to facilitate risk-informed and performance-based design and licensing of advanced non-LWRs. Such a methodology acknowledges enhancements in safety achievable with advanced designs and reflects more recent states of knowledge regarding safety and design innovation, creating an opportunity for reduced regulatory complexity with increased levels of safety. The project builds on best practices, as well as previous activities through DOE and industry-sponsored advanced reactor licensing initiatives.},
	language = {English},
	number = {INL/EXT-20-60395; SC-29980-101-Rev.01},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company, Atlanta, GA (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700670},
}

@techreport{moe_modernization_2020-1,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Selection} and {Evaluation} of {Licensing} {Basis} {Events}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1700668},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Selection and Evaluation of Licensing Basis Events,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs). It is the result of a Licensing Modernization Project (LMP) led by Southern Company and cost-shared by the U.S. Department of Energy (DOE). The LMP will result in detailed proposals for establishing licensing technical requirements to facilitate risk-informed and performance-based design and licensing of advanced non-LWRs. Such a methodology acknowledges enhancements in safety achievable with advanced designs and reflects more recent states of knowledge regarding safety and design innovation, creating an opportunity for reduced regulatory complexity with increased levels of safety. The project builds on best practices as well as previous activities through DOE and industry-sponsored advanced reactor licensing initiatives.},
	language = {English},
	number = {INL/EXT-20-60394; SC-29980-100-Rev.01},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company, Atlanta, GA (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700668},
}

@techreport{moe_modernization_2020-2,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Risk}-{Informed} and {Performance}-{Based} {Evaluation} of {Defense}-in-{Depth} {Adequacy}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1700533},
	abstract = {This document supports the work contained in Nuclear Energy Institute (NEI) 18-04 “Risk-Informed Performance-Based Technology Inclusive Guidance for Advanced Reactor Licensing Basis Development” Revision 0. NEI 18-04 presents a modern, technology-inclusive, risk-informed, and performance-based (TI-RIPB) process for selection of Licensing Basis Events (LBEs); safety classification of structures, systems, and components (SSCs) and associated risk-informed special treatments; and determination of defense-in-depth (DID) adequacy for non-LWRs. The NEI guidance document provides one acceptable means for addressing the aforementioned topics as part of demonstrating a specific design provides reasonable assurance of adequate radiological protection. This report provides the framework and associated methodology guidelines and discussion for establishing, then evaluating, confirming, and documenting the adequacy of defense-in-depth (DID) for advanced non-light-water reactor technologies. It was developed as part of the Licensing Modernization Project led by Southern Company and cost-shared by the United States Department of Energy and has benefited from considerable NRC formal reviews and public workshops. The methodology converts the DID philosophy into a structured process that is implementable, embraces existing United States and international definitions and philosophies of DID that set the foundation for the process. It builds on the DID framework developed in the Department of Energy Next Generation Nuclear Plant Project and earlier works on this subject. The approach to establishing DID adequacy involves the incorporation of DID attributes into the plant capabilities and programmatic elements of DID. The integrated evaluation of DID adequacy includes both quantitative elements to incorporate risk-informed and performance-based (RIPB) considerations and qualitative elements that address uncertainties and limitations in the quantitative models and supporting data. Demonstration of DID adequacy ensures that there are multiple layers of defense for risk-significant challenges to the design and that the plant capabilities and programs that support each layer are provided in a manner that minimizes dependencies among these layers. The focus of this report is assurance of DID adequacy with respect to protection of the public from radiological exposures resulting from accidental releases of radioactive material. While other hazards are not specifically addressed, this methodology is expected to be beneficial for determining DID adequacy for them as well. Risk-informed evaluation of DID considers the integrated performance of all plant SSCs and associated programs to manage daily operational activities, transients, and accidents, including the evaluation of strategies for accident prevention and mitigation. The RIPB LBE scenario methodology used in this evaluation defines the challenges to the plant safety features included in the plant design basis and beyond, and the scope of all deterministic and probabilistic safety evaluations. By examining event sequences across the whole spectrum of LBEs, a systematic assessment of DID can be accomplished.},
	language = {English},
	number = {INL/EXT-20-57941; SC-29980-103-Rev.01},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company, Atlanta, GA (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700533},
}

@techreport{grabaskas_utilization_2022,
	title = {Utilization of the {LMP} {Methodology} in {Support} of the {VTR} {Conceptual} {Safety} {Design} {Report}},
	url = {https://www.osti.gov/biblio/1871306},
	abstract = {The Versatile Test Reactor (VTR) is a fast spectrum test reactor currently being developed in the United States under the direction of the US Department of Energy (DOE), Office of Nuclear Energy. The VTR is utilizing a risk-informed performance-based (RIPB) approach for design support and authorization by the DOE, derived from recent efforts by the US industry led Licensing Modernization Project (LMP). This document contains an overview of the implementation of the LMP approach in support of the VTR Conceptual Safety Design Report (CSDR). The work reported here is the result of studies supporting a VTR conceptual design, cost, and schedule estimate for DOE-NE to make a decision on procurement. As such, it is preliminary. The VTR RIPB authorization approach utilizes information from the probabilistic risk assessment (PRA), coupled with deterministic analyses, to aid in decision-making regarding the identification and categorization of safety basis events (SBEs), the classification of structures, systems, and components (SSCs), and the evaluation of defense-in-depth (DID) adequacy. As part of initial reactor design efforts, a VTR conceptual design PRA was developed to support the RIPB process, which focused on at-power internal events, with scoping analyses for seismic and sodium fire hazards. In addition to supporting numerous design studies, preliminary results from the RIPB approach and the VTR conceptual design PRA were utilized as the basis of the VTR CSDR. The initial identification and categorization of SBEs, SSC classification, and DID evaluation were contained within the CSDR, which was submitted to DOE in 2019 as part of the CD-1 submittal package. Following review, DOE approved the CSDR in April 2020 and the CD-1 package in late 2020. Valuable experience was gained through the implementation of the RIPB approach for design and authorization during the VTR conceptual design phase, which is summarized in this document. To the extent possible, this experience has been shared with the advanced reactor industry, through publications and participation in licensing tabletops, in addition to informing DOE:NE advanced reactor regulatory development efforts. Furthermore, the approval of the CSDR by the DOE as part of CD-1 represents a significant milestone in the use of RIPB approaches for advanced reactor licensing.},
	language = {English},
	number = {INL/RPT-22-65633-Rev000},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Grabaskas, David and Chen, Ben and Bucknor, Matthew and Li, Jonathon and Henneke, Dennis and Warner, Matthew and Seeman, Glen and Andrus, Jason P. and Wells, Alison and Reiss, Troy P. and Gerstner, Doug},
	month = jan,
	year = {2022},
	doi = {10.2172/1871306},
}

@techreport{moe_risk-informed_2019,
	title = {Risk-{Informed} {Performance}-{Based} {Technology}. {Inclusive} {Guidance} for {Advanced} {Reactor} {Licensing} {Basis} {Development} ({NEI} 18-04)},
	url = {https://www.osti.gov/biblio/1557649},
	abstract = {This guideline presents a modern, technology-inclusive, risk-informed, and performance-based (TI-RIPB) process for selection of Licensing Basis Events (LBEs); safety classification of structures, systems, and components (SSCs) and associated risk-informed special treatments; and determination of defense-in-depth (DID) adequacy for non-LWRs. This guidance document provides one acceptable means for addressing the aforementioned topics as part of demonstrating a specific design provides reasonable assurance of adequate radiological protection.},
	language = {English},
	number = {INL/EXT-19-55375-Rev000; NEI-18-04},
	urldate = {2023-04-28},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Nuclear Energy Institute, Washington, DC (United States)},
	author = {Moe, Wayne L.},
	month = apr,
	year = {2019},
	doi = {10.2172/1557649},
}

@article{aldemir_benchmark_nodate,
	title = {A {Benchmark} {Implementation} of {Two} {Dynamic} {Methodologies} for the {Reliability} {Modeling} of {Digital} {Instrumentation} and {Control} {Systems}},
	language = {en},
	author = {Aldemir, T and Guarro, S and Kirschenbaum, J and Mandellil, D and Mangan, L A and Bucci, P and Yau, M and Johnson, B and Elks, C and Ekici, E and Stovsky, M P and Miller, D W and Sun, X and Arndt, S A and Nguyen, Q},
}

@article{yang_algorithm_2016,
	title = {An algorithm for the computationally efficient deductive implementation of the {Markov}/{Cell}-to-{Cell}-{Mapping} {Technique} for risk significant scenario identification},
	volume = {145},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015002550},
	doi = {10.1016/j.ress.2015.08.013},
	language = {en},
	urldate = {2023-04-24},
	journal = {Reliability Engineering \& System Safety},
	author = {Yang, Jun and Aldemir, Tunc},
	month = jan,
	year = {2016},
	pages = {1--8},
}

@article{yang_deductive_2018,
	title = {A {Deductive} {Method} for {Diagnostic} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems}},
	volume = {67},
	issn = {0018-9529, 1558-1721},
	url = {https://ieeexplore.ieee.org/document/8449110/},
	doi = {10.1109/TR.2018.2864630},
	number = {4},
	urldate = {2023-04-24},
	journal = {IEEE Transactions on Reliability},
	author = {Yang, Jun and Aldemir, Tunc and Smidts, Carol},
	month = dec,
	year = {2018},
	pages = {1442--1458},
}

@article{honda_uncertainty_2018,
	title = {Uncertainty {Analysis} for {Source} {Term} {Evaluation} of {High} {Temperature} {Gas}-{Cooled} {Reactor} {Under} {Accident} {Conditions}—{Identification} of {Influencing} {Factors} in {Loss}-of-{Forced} {Circulation} {Accidents}},
	volume = {4},
	issn = {2332-8983},
	url = {https://doi.org/10.1115/1.4039066},
	doi = {10.1115/1.4039066},
	abstract = {One of the key elements in probabilistic risk assessment is the identification and characterization of uncertainties. This paper suggests a procedure to identify influencing factors for uncertainty in source term evaluation, which are important to risk of public dose. We propose the following six steps for the identification in a systematic manner in terms of completeness and transparency of the results using both a logic diagram based on basic equations and expert opinions: (1) identification of uncertainty factors based on engineering knowledge of accident scenario analysis; (2) derivation of factors at the level of physical phenomena and variable parameters by expansion of dynamic equation for the system and scenario to be investigated, (3) extraction of uncertainties in variable parameters; (4) selection of important factors based on sensitivity study results and engineering knowledge; (5) identification of important factors for uncertainty analysis using expert opinions; and (6) integration of selected factors in the aforementioned steps. The proposed approach is tested with a case study for a risk-dominant accident scenario in direct cycle high-temperature gas-cooled reactor (HTGR) plant. We use this approach for evaluating the fuel temperature in terms of reactor dynamics and thermal hydraulic characteristics during a depressurized loss-of-forced circulation (DLOFC) accident with the failure of mitigation systems such as control rod systems (CRS) in a representative HTGR plan. In total, six important factors and 16 influencing factors were successfully identified by the proposed method in the case study. The selected influencing factors can be used as input parameters in uncertainty propagation analysis.},
	number = {3},
	urldate = {2023-04-22},
	journal = {Journal of Nuclear Engineering and Radiation Science},
	author = {Honda, Yuki and Sato, Hiroyuki and Nakagawa, Shigeaki and Ohashi, Hirofumi},
	month = may,
	year = {2018},
}

@article{park_uncertainty_2022,
	title = {Uncertainty analysis of source term and off-site consequence for {WH600} using {MELCOR} and {WinMACCS}},
	volume = {175},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454922002109},
	doi = {10.1016/j.anucene.2022.109175},
	abstract = {In PSA, uncertainty analysis is required to assess the reliability of the safety assessment results. Uncertainties related to severe accidents have been reported in previous studies. But existing uncertainty analysis has been focused on such severe accident phenomena, as changes in pressure and temperature of the containment building and hydrogen production. However, in order to conduct uncertainty analysis of off-site risk, it is necessary to analyse the uncertainty related to the information of radioactive material released, not just the phenomenon. In this study, the source term uncertainty is evaluated using MELCOR and off-site consequence uncertainty analysis using MACCS are performed. And WH600 has been selected as a reference plant. The variables related with these result are selected. The values are adjusted taking into consideration the characteristics and environmental conditions of an actual NPP. The LHS method is used for sampling the random variables. In off-site consequence analysis, early fatality and cancer fatality are uses as measures. As a result of MELCOR uncertainty analysis source term information has significant uncertainty that affects the off-site consequence. Also in case of off-site consequence, risk band is so wide that risk has to be determined.},
	language = {en},
	urldate = {2023-04-22},
	journal = {Annals of Nuclear Energy},
	author = {Park, Hyunae and Jae, Moosung},
	month = sep,
	year = {2022},
	keywords = {MACCS, MELCOR, Probabilistic risk assessment, Severe Accident, Uncertainty Analysis},
	pages = {109175},
}

@techreport{belle_r_upadhyaya_autonomous_2007,
	title = {Autonomous {Control} of {Space} {Reactor} {Systems}},
	url = {http://www.osti.gov/servlets/purl/920996-Sf4Gad/},
	language = {en},
	number = {DOE/ID/14589, 920996},
	urldate = {2023-04-19},
	author = {{Belle R. Upadhyaya} and {K. Zhao} and {S.R.P. Perillo} and {Xiaojia Xu} and {M.G. Na}},
	month = nov,
	year = {2007},
	doi = {10.2172/920996},
	pages = {DOE/ID/14589, 920996},
}

@book{buden_space_2011,
	title = {Space {Nuclear} {Fission} {Electric} {Power} {Systems}},
	isbn = {978-0-9741443-4-4},
	abstract = {The advantages of space nuclear fission power systems can be summarized as: compact size; low to moderate mass; long operating lifetimes; the ability to operate in extremely hostile environments; operation independent of the distance from the Sun or of the orientation to the Sun; and high system reliability and autonomy. In fact, as power requirements approach the tens of kilowatts and megawatts, fission nuclear energy appears to be the only realistic power option. The building blocks for space nuclear fission electric power systems include the reactor as the heat source, power generation equipment to convert the thermal energy to electrical power, waste heat rejection radiators and shielding to protect the spacecraft payload. The power generation equipment can take the form of either static electrical conversion elements that have no moving parts (e.g., thermoelectric or thermionic) or dynamic conversion components (e.g., the Rankine, Brayton or Stirling cycle). The U.S. has only demonstrated in space, or even in full systems in a simulated ground environment, uranium-zirconium-hydride reactor power plants. These power plants were designed for a limited lifetime of one year and the mass of scaled up power plants would probably be unacceptable to meet future mission needs. Extensive development was performed on the liquid-metal cooled SP-100 power systems and components were well on their way to being tested in a relevant environment. A generic flight system design was completed for a seven year operating lifetime power plant, but not built or tested. The former USSR made extensive use of space reactors as a power source for radar ocean reconnaissance satellites. They launched some 31 missions using reactors with thermoelectric power conversion systems and two with thermionic converters. Current activities are centered on Fission Surface Power for lunar applications. Activities are concentrating on demonstrating component readiness. This book will discuss the components that make up a nuclear fission power system, the principal requirements and safety issues, various development programs, status of developments, and development issues.},
	language = {en},
	publisher = {Polaris Books},
	author = {Buden, David},
	year = {2011},
	note = {Google-Books-ID: WB6UygAACAAJ},
}

@misc{noauthor_space_nodate,
	title = {Space {Nuclear} {Fission} {Electric} {Power} {Systems} ({Space} {Nuclear} {Propulsion} and {Power}): {Buden}, {David}: 9780974144344: {Amazon}.com: {Books}},
	url = {https://www.amazon.com/Nuclear-Fission-Electric-Systems-Propulsion/dp/0974144347},
	urldate = {2023-04-18},
}

@book{el-genk_critical_1994,
	title = {A {Critical} {Review} of {Space} {Nuclear} {Power} and {Propulsion} 1984-1993},
	url = {https://ui.adsabs.harvard.edu/abs/1994crsn.book.....E},
	abstract = {Market: Researchers in nuclear power, physicists, chemical and nuclear engineers, students, and policy makers. The papers in this volume summarize key technological advancements that occurred during the ten years from 1984 to 1993 in such areas as heat pipe technology, fuels, space nuclear safety, dynamic power conversion systems, and advanced radiator technologies for spacecraft power systems. In light of new industry initiatives to form a consortia and the possibility of bi-modal space nuclear power and propulsion systems, this informative volume will be an invaluable reference source.},
	urldate = {2023-04-18},
	author = {El-Genk, Mohamed S.},
	month = jan,
	year = {1994},
	note = {Publication Title: A Critical Review of Space Nuclear Power and Propulsion 1984-1993
ADS Bibcode: 1994crsn.book.....E},
	keywords = {Extraterrestrial Physics},
}

@article{metzger_model_1991,
	title = {Model {Reference} {Adaptive} {Control} with {Selective} {State} {Variable} {Weighting} {Applied} to a {Space} {Nuclear} {Power} {System}},
	volume = {109},
	issn = {0029-5639},
	url = {https://doi.org/10.13182/NSE91-A28516},
	doi = {10.13182/NSE91-A28516},
	abstract = {To ensure that a space nuclear power system will operate safely and respond in a predictable and desired manner, the system’s controller design must account for changes in the system parameters over its lifetime. A model reference adaptive controller is applied to enable the actual space nuclear power system to follow a predictable and desired response of a reference model system, despite changes in the actual system’s operating parameters. Model reference adaptive control is well developed for linear systems and has been applied to simple, single-input, single-output (and the output’s derivative) systems. Model reference adaptive control is applied to a single-input, multiple-output nonlinear system but also shows the development for a multiple-input, multiple-output linear system. An algorithm is developed for linear systems to determine the constant gains in the model reference adaptive control algorithm and a method is developed that allows selective weighting of a desired state variable. Examples are presented to show that a model reference adaptive controller can ensure the load-following response of a nonlinear space nuclear power system and that the reference model can be complex enough to embody the physics of the plant. The results of the example cases show that a model reference adaptive controller can cause a selected nonlinear plant state variable to track the transient trajectory of the corresponding state variable of the reference model with local stability.},
	number = {2},
	urldate = {2023-04-18},
	journal = {Nuclear Science and Engineering},
	author = {Metzger, John D. and El-Genk, Mohamed S. and Parlos, Alexander G.},
	month = oct,
	year = {1991},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.13182/NSE91-A28516},
	pages = {171--187},
}

@article{metzger_application_1992,
	title = {Application of a model-reference adaptive controller to a space nuclear power system},
	volume = {8},
	issn = {0748-4658, 1533-3876},
	url = {https://arc.aiaa.org/doi/10.2514/3.23597},
	doi = {10.2514/3.23597},
	language = {en},
	number = {5},
	urldate = {2023-04-18},
	journal = {Journal of Propulsion and Power},
	author = {Metzger, John D. and El-Genk, Mohamed S.},
	month = sep,
	year = {1992},
	pages = {1093--1102},
}

@misc{noauthor_novel_nodate,
	title = {A {Novel} {Proportional}−{Integral}-{Derivative} {Control} {Configuration} with {Application} to the {Control} of {Batch} {Distillation} {\textbar} {Industrial} \& {Engineering} {Chemistry} {Research}},
	url = {https://pubs.acs.org/doi/full/10.1021/ie990287c},
	urldate = {2023-04-18},
}

@incollection{mareels_revisiting_1987,
	address = {Oxford},
	series = {{IFAC} {Workshop} {Series}},
	title = {{REVISITING} {THE} {MIT} {RULE} {FOR} {ADAPTIVE} {CONTROL}},
	isbn = {978-0-08-034085-2},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080340852500316},
	abstract = {The MIT rule is a scalar parameter adjustment law which was proposed in 1961 for the model reference adaptive control of linear systems modeled as the cascade of a known stable plant and a single unknown gain. This adjustment law was derived by approximating a gradient descent procedure for an integral error squared performance criterion. For the early part of the 1960s this rule was the basis of many adaptive control schemes and a considerable wealth of practical experience and engineering folklore was amassed. The MIT rule is in general not globally convergent nor stable but has a performance determined by several factors such as algorithm gain, reference input magnitude and frequency, and the particular transfer function appearing in the cascade. These restrictions on the MIT rule slowly came to be discerned through experimentation and simulation but effectively were without theoretical support until some novel algorithm modifications and stability analysis, so-called Lyapunov redesign, due to Parks. Our aim in this paper is to pursue a theoretical analysis of the original MIT rule to support the existing simulation evidence and to indicate mechanisms for treating questions of robustness of MIT-rule-based adaptive controllers with undermodelling effects. The techniques that we apply to this problem centre on root locus methods, Nyquist methods and the application of the theory of averaging. Stability and instability results are presented and, using pertinent theories for different regimes of the gain-frequency plane, we approximate the experimentally derived stability margins, but for a broader signal class than simply periodic inputs. The mechanisms of instability and stability for these adaptive systems are highlighted and allow us to enunciate guidelines for the MIT rule to work. It is a pleasing by-product of this theoretical analysis that these guidelines coincide to a large degree with those advanced in earlier times on experimental and heuristic grounds.},
	language = {en},
	urldate = {2023-04-18},
	booktitle = {Adaptive {Systems} in {Control} and {Signal} {Processing} 1986},
	publisher = {Pergamon},
	author = {Mareels, Iven M. Y. and Anderson, Brian D. O. and Bitmead, Robert R. and Bodson, Marc and Sastry, Shankar S.},
	editor = {Åström, K. J. and Wittenmark, B.},
	month = jan,
	year = {1987},
	doi = {10.1016/B978-0-08-034085-2.50031-6},
	pages = {161--166},
}

@article{takamatsu_adaptive_1985,
	series = {{IFAC} {Workshop} on {Adaptive} {Control} of {Chemical} {Processes}, {Frankfurt} a.{M} ,{FRG}, 21-22 {October} 1985},
	title = {Adaptive {Internal} {Model} {Control} and its {Application} to a {Batch} {Polymerization} {Reactor}},
	volume = {18},
	issn = {1474-6670},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080334318500233},
	doi = {10.1016/B978-0-08-033431-8.50023-3},
	abstract = {In this paper, the internal model control (IMC) and the adaptive parameter identification technique by the model refernece adaptive system (MRAS) are newly combined, and the combined one is called the adaptive IMC (AIMC). The proposed AIMC inherits the advantageous points from IMC, e.g., easiness to evaluate the robustness of the modelling error and to design a filter of an AIMC taking into account of its robustness. Moreover, parameters of the internal model are adjusted by MRAS in the proposed scheme. Then, the system can be controlled perfectly if the order of the system is appropriately assumed and if the system is a minimum phase one. One more advantageous point which is most significant one in practical application of the AIMC is; if the model is taken as 1st order system, the AIMC can be reduced to an auto-tuning proportional-plus-integral (PI) feedback controller. The proposed AIMC is applied to the control of a batch polymerization reactor. Temperature of the reactor is controlled so as to follow the desired temperature profile by the AIMC. The system equation of the batch reactor is time-dependent, and parameter adaptation will be required for getting a sophisticated controller. For this problem, the proposed AIMC can be utilized successfully and is shown to be superior compared with a traditional PI controller by the computer simulation.},
	language = {en},
	number = {15},
	urldate = {2023-04-18},
	journal = {IFAC Proceedings Volumes},
	author = {Takamatsu, T. and Shioya, S. and Okada, Y.},
	month = oct,
	year = {1985},
	keywords = {Adaptive control, Auto-tuning control, Internal model control, Styrene suspension polymerization, Temperature control},
	pages = {109--114},
}

@inproceedings{dumont_concepts_2002,
	title = {Concepts, methods and techniques in adaptive control},
	volume = {2},
	doi = {10.1109/ACC.2002.1023173},
	abstract = {This tutorial paper looks back at almost 50 years of adaptive control trying to establish how much more we need to be able to offer the industrial community an adaptive controller which will be used and referred to with the same ease as existing PID controllers. Since the first commercial adaptive controller, significant progress in the design and analysis of these controllers has been achieved. Various forms of adaptive controllers are now readily available targeting a significant range of industries from process to aerospace. A general overview of adaptive control will allow the reader to place on the map several industrial architectures for such controllers, all with the aim of bridging the gap between academic and industrial views of the topic. Such a presentation of design and analysis tools currently opens a more philosophical question "Has the critical mass in adaptive control been reached?".},
	booktitle = {Proceedings of the 2002 {American} {Control} {Conference} ({IEEE} {Cat}. {No}.{CH37301})},
	author = {Dumont, G.A. and Huzmezan, M.},
	month = may,
	year = {2002},
	note = {ISSN: 0743-1619},
	keywords = {Adaptive control, Aerospace industry, Automatic control, Control systems, Electrical equipment industry, Industrial control, Nonlinear control systems, Programmable control, Three-term control, Weight control},
	pages = {1137--1150 vol.2},
}

@article{metzger_application_1992-1,
	title = {Application of a model-reference adaptive controller to a space nuclear power system},
	volume = {8},
	issn = {0748-4658, 1533-3876},
	url = {https://arc.aiaa.org/doi/10.2514/3.23597},
	doi = {10.2514/3.23597},
	language = {en},
	number = {5},
	urldate = {2023-04-17},
	journal = {Journal of Propulsion and Power},
	author = {Metzger, John D. and El-Genk, Mohamed S.},
	month = sep,
	year = {1992},
	pages = {1093--1102},
}

@inproceedings{malagari_nuclear_2015,
	title = {{NUCLEAR} {POWER} {AND} {PROPULSION} {SYSTEMS} {FOR} {UNMANNED} {SPACECRAFT}},
	abstract = {Nuclear power and propulsion systems are a smart alternative to traditional rocket systems. Topics discussed include, a brief history of nuclear power and propulsion is provided along with a background on nuclear power in space. The current nuclear technologies of Radioisotope Thermoelectric Generators (RTGs), Nuclear Thermal Propulsion (NTP) and Nuclear Electric Propulsion (NEP) are described to provide the reader with enough knowledge to compare nuclear to chemical. The case for replacing chemical propulsion with nuclear propulsion is made by presenting the pros and cons of nuclear and chemical side by side. Furthermore, the safety and ethicality of nuclear power and propulsion systems are explained and presented against the public opposition to nuclear technology. Future potential and development of nuclear power systems are discussed and conclude the paper.},
	language = {en},
	publisher = {University of Pittsburgh, Swanson School of Engineering},
	author = {Malagari, Nicholas},
	year = {2015},
}

@inproceedings{mason_power_2002,
	title = {Power technology options for nuclear electric propulsion},
	doi = {10.1109/IECEC.2002.1391989},
	abstract = {On-going studies being conducted under the office of space science (Code S) in-space propulsion program have identified high power (100 kWe) NEP as an enabling technology for space science missions. The benefits of NEP include larger payload fractions, faster and more direct trajectories, and increased power at destination as compared to other propulsion technologies. In order to realize these benefits, a critical first-step is the development of a lightweight, long-lived reactor power system. This paper presents a historical review of relevant space reactor power programs, describes the operational characteristics of candidate power conversion technology options, and proposes a reactor power system concept with appealing near term performance and long term growth potential.},
	booktitle = {{IECEC} '02. 2002 37th {Intersociety} {Energy} {Conversion} {Engineering} {Conference}, 2002.},
	author = {Mason, L.S.},
	month = jul,
	year = {2002},
	keywords = {Inductors, NASA, Payloads, Power conversion, Power system measurements, Power systems, Propulsion, Space missions, Space technology, Temperature},
	pages = {114--121},
}

@article{hunter_basis_nodate,
	title = {Basis for the {Treatment} of {Potential} {Common}-{Cause} {Failure} in the {Significance} {Determination} {Process}},
	language = {en},
	author = {Hunter, Christopher},
}

@techreport{wells_seismic_1981,
	title = {Seismic safety margins research program. {Phase} {I}. {Final} report: systems analysis ({Project} {VII})},
	shorttitle = {Seismic safety margins research program. {Phase} {I}. {Final} report},
	url = {https://www.osti.gov/biblio/5344101},
	abstract = {This document reports on the Phase 1 efforts of the Systems Analysis Project to develop the tools and methods for computing the probability of radioactive release from a commercial nuclear power plant in the event of an earthquake. The results of the application of these tools and methods to the Zion Nuclear Power Plant Unit 1 are given.},
	language = {English},
	number = {NUREG/CR-2015-Vol.8; UCRL-53021-Vol.8},
	urldate = {2023-04-14},
	institution = {Lawrence Livermore National Lab., CA (USA)},
	author = {Wells, J. E. and George, L. L. and Cummings, C. E.},
	month = nov,
	year = {1981},
}

@misc{fujimoto_addressing_2018,
	title = {Addressing {Function} {Approximation} {Error} in {Actor}-{Critic} {Methods}},
	url = {http://arxiv.org/abs/1802.09477},
	abstract = {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.},
	urldate = {2023-04-07},
	publisher = {arXiv},
	author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
	month = oct,
	year = {2018},
	note = {arXiv:1802.09477 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kim_time-aware_2023,
	title = {Time-aware deep reinforcement learning with multi-temporal abstraction},
	issn = {0924-669X, 1573-7497},
	url = {https://link.springer.com/10.1007/s10489-022-04392-5},
	doi = {10.1007/s10489-022-04392-5},
	abstract = {Deep reinforcement learning (DRL) is advantageous, but it rarely performs well when tested on real-world decision-making tasks, particularly those involving irregular time series with sparse actions. Although irregular time series with sparse actions can be handled using temporal abstractions for the agent to grasp high-level states, they aggravate temporal irregularities by increasing the range of time intervals essential to represent a state and estimate expected returns. In this work, we propose a general Time-aware DRL framework with Multi-Temporal Abstraction (T-MTA) that incorporates the awareness of time intervals from two aspects: temporal discounting and temporal abstraction. For the former, we propose a Time-aware DRL method, whereas for the latter we propose a Multi-Temporal Abstraction mechanism. T-MTA was tested in three standard RL testbeds and two real-life tasks (control of nuclear reactors and prevention of septic shock), which represent four common contexts of learning environments, online and offline, as well as fully and partially observable. As T-MTA is a general framework, it can be combined with any model-free DRL method. In this work, we examined two in particular: the Deep Q-Network approach and its variants, and Truly Proximal Policy Optimization. Our results show that T-MTA significantly outperforms competing baseline frameworks, including a standalone Time-aware DRL framework, MTAs, and the original DRL methods without considering either type of temporal aspect, especially when partially observable environments are involved and the range of time intervals is large.},
	language = {en},
	urldate = {2023-04-04},
	journal = {Applied Intelligence},
	author = {Kim, Yeo Jin and Chi, Min},
	month = mar,
	year = {2023},
}

@article{phuong_impacts_2019,
	title = {The impacts of medication shortages on patient outcomes: {A} scoping review},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {The impacts of medication shortages on patient outcomes},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6499468/},
	doi = {10.1371/journal.pone.0215837},
	abstract = {Background
In recent years, medication shortages have become a growing worldwide issue. This scoping review aimed to systematically synthesise the literature to report on the economic, clinical, and humanistic impacts of medication shortages on patient outcomes.

Methods
Medline, Embase, Global Health, PsycINFO and International Pharmaceutical Abstracts were searched using the two key concepts of medicine shortage and patient outcomes. Articles were limited to the English language, human studies and there were no limits to the year of publication. Manuscripts included contained information regarding the shortage of a scheduled medication and had gathered data regarding the economic, clinical, and/or humanistic outcomes of drug shortages on human patients.

Findings
We found that drug shortages were predominantly reported to have adverse economic, clinical and humanistic outcomes to patients. Patients were more commonly reported to have increased out of pocket costs, rates of drug errors, adverse events, mortality, and complaints during times of shortage. There were also reports of equivalent and improved patient outcomes in some cases.

Conclusions
The results of this review provide valuable insights into the impact drug shortages have on patient outcomes. The majority of studies reported medication shortages resulted in negative patient clinical, economic and humanistic outcomes.},
	number = {5},
	urldate = {2023-04-03},
	journal = {PLoS ONE},
	author = {Phuong, Jonathan Minh and Penm, Jonathan and Chaar, Betty and Oldfield, Lachlan Daniel and Moles, Rebekah},
	month = may,
	year = {2019},
	pmid = {31050671},
	pmcid = {PMC6499468},
	pages = {e0215837},
}

@article{katsaliaki_supply_2022,
	title = {Supply chain disruptions and resilience: a major review and future research agenda},
	volume = {319},
	issn = {1572-9338},
	shorttitle = {Supply chain disruptions and resilience},
	url = {https://doi.org/10.1007/s10479-020-03912-1},
	doi = {10.1007/s10479-020-03912-1},
	abstract = {Our study examines the literature that has been published in important journals on supply chain disruptions, a topic that has emerged the last 20 years, with an emphasis in the latest developments in the field. Based on a review process important studies have been identified and analyzed. The content analysis of these studies synthesized existing information about the types of disruptions, their impact on supply chains, resilience methods in supply chain design and recovery strategies proposed by the studies supported by cost–benefit analysis. Our review also examines the most popular modeling approaches on the topic with indicative examples and the IT tools that enhance resilience and reduce disruption risks. Finally, a detailed future research agenda is formed about SC disruptions, which identifies the research gaps yet to be addressed. The aim of this study is to amalgamate knowledge on supply chain disruptions which constitutes an important and timely as the frequency and impact of disruptions increase. The study summarizes and builds upon the knowledge of other well-cited reviews and surveys in this research area.},
	language = {en},
	number = {1},
	urldate = {2023-04-03},
	journal = {Annals of Operations Research},
	author = {Katsaliaki, K. and Galetsi, P. and Kumar, S.},
	month = dec,
	year = {2022},
	keywords = {Disruptions, IT tools, Modeling techniques, Resilience, Review, Ripple effect, Supply chain},
	pages = {965--1002},
}

@book{simchi-levi_designing_2003,
	title = {Designing and {Managing} the {Supply} {Chain}: {Concepts}, {Strategies}, and {Case} {Studies}},
	isbn = {978-0-07-249256-9},
	shorttitle = {Designing and {Managing} the {Supply} {Chain}},
	abstract = {Introduction to Supply Chain Management - Logistics Network Configuration - Inventory Management and Risk Pooling - The Value of Information - Supply chain integration - Strategic Alliances - Procurement and outsourcing strategies - International Issues in Supply Chain Management - Coordinated Product and Supply Chain Design - Customer Value and Supply Chain Management - Information technology for supply chain management - Decision-support systems for supply chain management.},
	language = {en},
	publisher = {McGraw Hill Professional},
	author = {Simchi-Levi, David and Kaminsky, Philip and Simchi-Levi, Edith},
	year = {2003},
	note = {Google-Books-ID: SYKYU06odPgC},
}

@article{earthperson_combined_2023,
	title = {A combined strategy for dynamic probabilistic risk assessment of fission battery designs using {EMRALD} and {DEPM}},
	volume = {160},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197023001087},
	doi = {10.1016/j.pnucene.2023.104673},
	abstract = {The notion of nuclear reactors with battery-like capabilities, called fission batteries, puts forth system requirements and design constraints that have so far been unseen in the nuclear power production industry. Such restrictions require fission batteries to be modular, integrated, autonomous, tamper-proof (i.e., resilient, fault-tolerant, all-weather, and safe), and affordable. With design requirements specifying no human intervention for operation, and minimal connectivity to remote monitoring networks, fission batteries are unique among existing nuclear power plants and emerging advanced reactor designs. Given these attributes, traditional probabilistic risk assessment (PRA) of fission batteries is expected to require dynamic methods to model advanced aspects, such as self-diagnosis, self-adjustment, and duration-prediction capabilities, as they are key ingredients for unattended operations. In addition, availability models need to integrate autonomous control, associated error-detection algorithms, and adversarial human actions. Currently, no existing framework demonstrably assesses these advanced attributes. This paper introduces and demonstrates an integrated framework for the dynamic modeling of fission battery designs. The proposed framework comprises a combined modeling strategy that uses the dual-graph error propagation methodology (DEPM) based on the continuous-time Markov chain (CTMC) models implemented in OpenPRA Error Propagation (OpenErrorPro) and the dynamic PRA tool, Event Modeling Risk Assessment using Linked Diagrams (EMRALD), based on discrete dynamic event trees (DDET). This combination overcomes some of the limitations of the tools when used independently. It enables detailed dynamic analysis to produce time explicit results to support the development of fission battery traditional PRA models. To evaluate the utility of this novel approach, a demonstration case is shown that models the hypothesized response of a fission battery design to an external fire event. DEPM CTMCs and alternative failure approaches are coupled with EMRALD to characterize and quantify the likelihood of the event sequences. The results show that the combined framework effectively captures the dynamic aspects of fission battery design in terms of the timing and realism of modeled events. Given the complexity of the failure scenarios, we believe that EMRALD and DEPM are necessary and complementary when the need for high-resolution analysis offsets the challenges of detailed modeling.},
	language = {en},
	urldate = {2023-03-30},
	journal = {Progress in Nuclear Energy},
	author = {Earthperson, Arjun and Otani, Courtney M. and Nevius, Daniel and Prescott, Steven R. and Diaconeasa, Mihai A.},
	month = jun,
	year = {2023},
	keywords = {Continuous-time Markov chain, Discrete dynamic event tree, Dual-graph error propagation model, Dynamic probabilistic risk assessment, EMRALD, Error propagation, OpenEPL, OpenPRA},
	pages = {104673},
}

@phdthesis{hamza_openphi_2022,
	title = {{OpenPHI} – {A} {Human} {Reliability} {Analysis} {Methodology} to {Risk}-{Inform} the {Importance} of {Operator} {Actions} for {Advanced} {Reactors} during {Early} {Design} {Stages}},
	school = {North Carolina State University},
	author = {Hamza, Mostafa},
	year = {2022},
}

@phdthesis{tayfur_probabilistic_2023,
	title = {A {Probabilistic} {Risk} {Assessment} {Study} of a {Pebble}-{Bed} {High} {Temperature} {Gas} {Cooled} {Reactor} {Onsite} {Spent} {Fuel} {Storage} {System}},
	school = {North Carolina State University},
	author = {Tayfur, Havva},
	year = {2023},
}

@article{arafat_evinci_2019,
	title = {{eVinci} {Micro} {Reactor}},
	volume = {37},
	url = {https://www.westinghousenuclear.com/Portals/0/new%20plants/evincitm/eVinci%20Micro%20Reactor%20NPJ%20M-A%202019.pdf},
	journal = {Nuclear Plant Journal},
	author = {Arafat, Yasir and Van Wyk, Jurie},
	month = mar,
	year = {2019},
	pages = {34--36},
}

@inproceedings{klugel_challenges_2004,
	address = {London},
	title = {Challenges to future {Seismic} {PRA}},
	isbn = {978-0-85729-410-4},
	doi = {10.1007/978-0-85729-410-4_199},
	abstract = {NPP Goesgen completed its first PRA (Level 1 and 2, shutdown, external and internal events) in 1994 in close cooperation with PLG (now ABS Consulting). During the review process by the regulatory authority completed in 1999 it was understood, that the methodology and the scope of the seismic PRA should be expanded. In 2001, a completely revised and updated seismic PRA was submitted to the regulatory authority. Experience gained from this update indicated that further improvements in the methodology are necessary. Insights gained and recommendations for further improvements of the methodology are presented in the paper.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer},
	author = {Klügel, J.-U. and Rao, S. and Short, S.},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	keywords = {Masonry Wall, Nuclear Power Plant, Probabilistic Seismic Hazard Analysis, Seismic Hazard, Uncertainty Distribution},
	pages = {1232--1238},
}

@article{smidts_ida_1997,
	title = {The {IDA} cognitive model for the analysis of nuclear power plant operator response under accident conditions. {Part} {I}: problem solving and decision making model},
	volume = {55},
	issn = {0951-8320},
	shorttitle = {The {IDA} cognitive model for the analysis of nuclear power plant operator response under accident conditions. {Part} {I}},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832096001044},
	doi = {10.1016/S0951-8320(96)00104-4},
	abstract = {This paper is the first of a series of papers describing IDA which is a cognitive model for analysing the behaviour of nuclear power plant operators under accident conditions. The domain of applicability of the model is a relatively constrained environment where behaviour is significantly influenced by high levels of training and explicit requirement to follow written procedures. IDA consists of a model for individual operator behaviour and a model for control room operating crew expanded from the individual model. The model and its derivatives such as an error taxonomy and data collection approach has been designed with ultimate objective of becoming a quantitative method for human reliability analysis (HRA) in probabilistic risk assessment (PRA). The present paper gives a description of the main components of IDA such as memory structure, goals, and problem solving and decision making strategies. It also identifies factors that are at the origin of transitions between goals or between strategies. These factors cover the effects of external conditions and psychological state of the operator. The description is generic at first and then made specific to the nuclear power plant environment and more precisely to abnormal conditions.},
	language = {en},
	number = {1},
	urldate = {2023-03-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Smidts, C. and Shen, S. H. and Mosleh, A.},
	month = jan,
	year = {1997},
	pages = {51--71},
}

@techreport{yau_nuclear_2006,
	title = {Nuclear power plant digital system {PRA} pilot study with the dynamic flow-graph methodology},
	url = {https://www.osti.gov/biblio/22030179},
	abstract = {Current Probabilistic Risk Assessment (PRA) methodology is well established in analyzing hardware and some of the key human interactions. However processes for analyzing the software functions of digital systems within a plant PRA framework, and accounting for the digital system contribution to the overall risk are not generally available nor are they well understood and established. A recent study reviewed a number of methodologies that have potential applicability to modeling and analyzing digital systems within a PRA framework. This study identified the Dynamic Flow-graph Methodology (DFM) and the Markov Methodology as the most promising tools. As a result of this study, a task was defined under the framework of a collaborative agreement between the U.S. Nuclear Regulatory Commission (NRC) and the Ohio State Univ. (OSU). The objective of this task is to set up benchmark systems representative of digital systems used in nuclear power plants and to evaluate DFM and the Markov methodology with these benchmark systems. The first benchmark system is a typical Pressurized Water Reactor (PWR) Steam Generator (SG) Feedwater System (FWS) level control system based on an earlier ASCA work with the U.S. NRC 2, upgraded with modern control laws. ASCA, Inc. is currently under contract to OSU to apply DFM to this benchmark system. The goal is to investigate the feasibility of using DFM to analyze and quantify digital system risk, and to integrate the DFM analytical results back into the plant event tree/fault tree PRA model. (authors)},
	language = {English},
	urldate = {2023-03-29},
	institution = {American Nuclear Society - ANS; La Grange Park (United States)},
	author = {Yau, M. and Motamed, M. and Guarro, S.},
	month = jul,
	year = {2006},
}

@article{dube_application_2014,
	title = {Application of risk informed safety margin characterization to extended power uprate analysis},
	volume = {129},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832014000763},
	doi = {10.1016/j.ress.2014.04.008},
	abstract = {In this paper we present some initial results of the application of a risk-informed safety margin characterization (RISMC) approach to the analysis of the impact of an extended power uprate (EPU) on plant safety for selected transient and accident sequences. These initial applications were conducted to demonstrate the feasibility and practicality of using the RISMC approach to analyze the safety impact of EPUs at both a pressurized water reactor (PWR) and a boiling water reactor (BWR). For the PWR application, the analysis focused on the loss of main feedwater (LOMFW) event with failure of auxiliary feedwater (AFW) where feed and bleed (F\&B) cooling is required to prevent core damage. For the BWR case study, station blackout (SBO) sequences leading to core damage were analyzed. A consistent and repeatable process was developed and applied to identify those key parameters that would be analyzed. Distributions were constructed to represent the uncertainties associated with each of the key parameters. These distributions were sampled using a Latin Hypercube Sampling (LHS) technique to generate sets of sample cases that were used in the physics simulation runs using the MAAP4 code. Simulation results were evaluated to determine the changes to safety margins which would occur due to the uprated power conditions; the results obtained were then compared to those for the current nominal full power. The results obtained indicate, as expected, that safety margins may be reduced with increases in plant power level. However, for most power uprate levels, these safety margin reductions were found to be small. A limited study of margin recovery strategies was performed for the PWR case that indicated that minor to moderate changes in plant operation or design could be used to recover the safety margin reduction that would occur from the power uprate.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Dube, Donald A. and Sherry, Richard R. and Gabor, Jeffery R. and Hess, Stephen M.},
	month = sep,
	year = {2014},
	keywords = {Extended power uprate, Probabilistic risk assessment, Risk-informed decision-making, Safety margins},
	pages = {19--28},
}

@article{peterson_overview_2019,
	title = {An overview of methodologies for cybersecurity vulnerability assessments conducted in nuclear power plants},
	volume = {346},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549319300330},
	doi = {10.1016/j.nucengdes.2019.02.025},
	abstract = {Cyber-attacks against critical energy infrastructure have gone from possible to eventual to actual. With electrical generation sources in the United States changing under a wide range of pressures, the current fleet of nuclear power plants in the United States provides a reliable and sustainable source of electrical generation capacity. However, in order to extend the lifetime of the fleet, modernization upgrades to digital instrumentation and control systems are required. While this produces many opportunities for increased efficiency, it introduces a new level of complexity for securing and reliably operating reactors in the presence cyber-threats. The United States Nuclear Regulatory Commission recently began urging stronger cybersecurity efforts at nuclear power plants. As upgrades at nuclear power plants begin, the implementation of digital instrumentation and control systems to monitor and run the power plant introduces new vulnerabilities that must be addressed. This necessitates a more modern discussion of risk. Within this context, we critically review past cyber-vulnerability incidents at nuclear installations and other critical facilities. We then analyze challenges to vulnerabilities within the context of modernization of the current nuclear fleet and propose future research directions needed to resolve these issues.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Nuclear Engineering and Design},
	author = {Peterson, John and Haney, Michael and Borrelli, R. A.},
	month = may,
	year = {2019},
	pages = {75--84},
}

@article{purba_fuzzy-based_2014,
	title = {A fuzzy-based reliability approach to evaluate basic events of fault tree analysis for nuclear power plant probabilistic safety assessment},
	volume = {70},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454914001029},
	doi = {10.1016/j.anucene.2014.02.022},
	abstract = {Fault tree analysis has been widely utilized as a tool for nuclear power plant probabilistic safety assessment. This analysis can be completed only if all basic events of the system fault tree have their quantitative failure rates or failure probabilities. However, it is difficult to obtain those failure data due to insufficient data, environment changing or new components. This study proposes a fuzzy-based reliability approach to evaluate basic events of system fault trees whose failure precise probability distributions of their lifetime to failures are not available. It applies the concept of failure possibilities to qualitatively evaluate basic events and the concept of fuzzy sets to quantitatively represent the corresponding failure possibilities. To demonstrate the feasibility and the effectiveness of the proposed approach, the actual basic event failure probabilities collected from the operational experiences of the David–Besse design of the Babcock and Wilcox reactor protection system fault tree are used to benchmark the failure probabilities generated by the proposed approach. The results confirm that the proposed fuzzy-based reliability approach arises as a suitable alternative for the conventional probabilistic reliability approach when basic events do not have the corresponding quantitative historical failure data for determining their reliability characteristics. Hence, it overcomes the limitation of the conventional fault tree analysis for nuclear power plant probabilistic safety assessment.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Annals of Nuclear Energy},
	author = {Purba, Julwan Hendry},
	month = aug,
	year = {2014},
	keywords = {Failure possibility, Failure probability, Fault tree analysis, Fuzzy sets, Nuclear power plant, Reliability},
	pages = {21--29},
}

@article{lee_design-phase_2019,
	title = {A design-phase probabilistic safety assessment of a research reactor to enhance its safety},
	volume = {131},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454919301859},
	doi = {10.1016/j.anucene.2019.04.007},
	abstract = {This paper describes the effort to improve the design and procedure of a research rector with regard to safety, using a probabilistic safety assessment (PSA) at the conceptual design stage. A PSA was undertaken to assess the level of safety for the design of a research reactor and evaluate whether it is probabilistically safe to operate and reliable to use. The scope of the PSA reported here is a Level 1 PSA, which addresses the risks associated with core damage. The technical objectives of this study were to identify accident sequences leading to core damage and to derive design and procedure improvements from the dominant accident sequences through sensitivity analysis. The preliminary result indicates a point estimate of 6.79E-05/yr for the overall core damage frequency (CDF), attributable to internal initiating events for the research reactor under design. Based on the dominant accident sequences from the PSA, six kinds of sensitivity analysis were performed, and some design and procedure improvements were derived. When four of these six ways to improve safety were applied to the reactor design and procedure, risk was reduced to approximately 1.21E-06/yr. The safety of the research reactor was significantly improved, and the risk was considerably more reduced than that observed before the design and procedure improvements gained from the sensitivity analysis were adapted. The present study indicated that the research reactor has well-balanced safety with regard to each initiating event contributing to the CDF.},
	language = {en},
	urldate = {2023-03-26},
	journal = {Annals of Nuclear Energy},
	author = {Lee, Yoon-Hwan},
	month = sep,
	year = {2019},
	keywords = {Core damage frequency, Initiating event, PSA, Research reactor, Risk-informed design},
	pages = {367--377},
}

@article{liu_event_2023,
	title = {An event sequence modeling method in multi-unit probabilistic risk assessment for high temperature gas-cooled reactor},
	volume = {182},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S030645492200648X},
	doi = {10.1016/j.anucene.2022.109618},
	abstract = {The number of multi-unit nuclear power plants (NPPs) increases, so does the demand for multi-unit probabilistic risk assessment (MUPRA). Considering dependencies among multiple units on one site, conventional probabilistic risk assessment (PRA) for a single unit cannot meet requirements of the overall site risk analysis. Existing MUPRA studies mainly evaluate limited risk characteristics, such as core damage, or focus on a limited number of units, within the range of two to six units. This study proposes a multi-unit event sequence modeling method for MUPRA, and develops a corresponding computer-aided tool, making it possible to deal with considerable number of units. Furthermore, their application to high temperature gas-cooled reactor – pebble bed module (HTR-PM) was carried out, showing that the modeling method and computer-aided tool can be applied to address dependencies of function events (FEs) and provide a reference for the full risk spectrum.},
	language = {en},
	urldate = {2023-03-26},
	journal = {Annals of Nuclear Energy},
	author = {Liu, Ao and Peng, Pengcheng and Zhao, Jun and Ding, Hongchun and Liu, Tao and Tong, Jiejuan},
	month = mar,
	year = {2023},
	keywords = {Event sequence modeling, High temperature gas-cooled reactor, Multi-unit probabilistic risk assessment},
	pages = {109618},
}

@article{mercurio_integrated_2018,
	title = {Integrated {Level} 1–{Level} 2 decommissioning probabilistic risk assessment for boiling water reactors},
	volume = {50},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573317307143},
	doi = {10.1016/j.net.2018.03.001},
	abstract = {This article describes an integrated Level 1–Level 2 probabilistic risk assessment (PRA) methodology to evaluate the radiological risk during postulated accident scenarios initiated during the decommissioning phase of a typical Mark I containment boiling water reactor. The fuel damage scenarios include those initiated while the reactor is permanently shut down, defueled, and the spent fuel is located into the spent fuel storage pool. This article focuses on the integrated Level 1–Level 2 PRA aspects of the analysis, from the beginning of the accident to the radiological release into the environment. The integrated Level 1–Level 2 decommissioning PRA uses event trees and fault trees that assess the accident progression until and after fuel damage. Detailed deterministic severe accident analyses are performed to support the fault tree/event tree development and to provide source term information for the various pieces of the Level 1–Level 2 model. Source terms information is collected from accidents occurring in both the reactor pressure vessel and the spent fuel pool, including simultaneous accidents. The Level 1–Level 2 PRA model evaluates the temporal and physical changes in plant conditions including consideration of major uncertainties. The goal of this article is to provide a methodology framework to perform a decommissioning Probabilistic Risk Assessment (PRA), and an application to a real case study is provided to show the use of the methodology. Results will be derived from the integrated Level 1–Level 2 decommissioning PSA event tree in terms of fuel damage frequency, large release frequency, and large early release frequency, including uncertainties.},
	language = {en},
	number = {5},
	urldate = {2023-03-26},
	journal = {Nuclear Engineering and Technology},
	author = {Mercurio, Davide and Andersen, Vincent M. and Wagner, Kenneth C.},
	month = jun,
	year = {2018},
	keywords = {Decommissioning Probabilistic Risk Assessment, Large Early Release Frequency, Level 1 Probabilistic Risk Assessment, Level 2 Probabilistic Risk Assessment, Severe Accident Progression},
	pages = {627--638},
}

@misc{united_states_department_of_transportation_49_nodate,
	title = {49 {CFR} § 174.86 - {Maximum} allowable operating speed.},
	url = {https://www.law.cornell.edu/cfr/text/49/174.86},
	language = {en},
	urldate = {2022-11-21},
	author = {{United States Department of Transportation}},
}

@techreport{bentrup_agroforestry_2017,
	address = {Washington Office},
	type = {General {Technical} {Report}},
	title = {Agroforestry: {Enhancing} resiliency in {U}.{S}. agricultural landscapes under changing conditions},
	shorttitle = {Great {Plains}},
	language = {en},
	number = {WO-96},
	institution = {U.S Department of Agriculture, Forest Service},
	author = {Bentrup, Gary and Schoneneberger, Michele and {Patel-Weynand, Toral}},
	year = {2017},
	pages = {169 -- 176},
}

@techreport{mills_tractortrailer_2006,
	type = {Sandia {Report}},
	title = {Tractor/{Trailer} {Accident} {Statistics}},
	abstract = {This report describes the analysis that was performed to construct (1) a new truck accident event tree, including the fractional occurrences of route wayside surfaces, (2) new truck accident speed distributions and (3) new estimates of truck accident fire probabilities. The branch point fractions needed to construct the new event tree were calculated using truck accident data for the years 1996 through 2000 and vehicle mileage data for the years 1997 and 2000. Truck accident data was also used to estimate the fraction of bridge accidents that result in the truck falling off of the bridge. A count of bridges on Interstate 95 yielded a conservative estimate of the number of truck accidents that might lead to collisions with very large bridge columns. The occurrence frequencies of route wayside surfaces and surfaces under bridges were developed using Geographic Information System (GIS) databases and methods of analysis.},
	language = {en},
	number = {SAND2006-7723},
	institution = {Sandia National Lab.},
	author = {Mills, G Scott and Sprung, Jeremy L and Osborn, Douglas M},
	month = dec,
	year = {2006},
	pages = {55},
}

@article{li_safety_2021,
	title = {Safety assessment of nuclear fuel reprocessing plant under the free drop impact of spent fuel cask and fuel assembly part {I}: {Large}-scale model test and finite element model validation},
	volume = {53},
	issn = {1738-5733},
	shorttitle = {Safety assessment of nuclear fuel reprocessing plant under the free drop impact of spent fuel cask and fuel assembly part {I}},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573321000942},
	doi = {10.1016/j.net.2021.02.004},
	abstract = {This paper aims to evaluate the structural dynamic responses and damage/failure of the nuclear fuel reprocessing plant under the free drop impact of spent fuel cask (SFC) and fuel assembly (FA) during the on-site transportation. At the present Part I of this paper, the large-scale SFC model free drop test and the corresponding numerical simulations are performed. Firstly, a composite target which is composed of the protective structure, i.e., a thin RC plate (representing the inverted U-shaped slab in the loading shaft) and/or an autoclaved aerated concrete (AAC) blocks sacrificial layer, as well as a thick RC plate (representing the bottom slab in the loading shaft) is designed and fabricated. Then, based on the large dropping tower, the free drop test of large-scale SFC model with the mass of 3 t is carried out from the height of 7 m–11 m. It indicates that the bottom slab in the loading shaft could not resist the free drop impact of SFC. The composite protective structure can effectively reduce the damage and vibrations of the bottom slab, and the inverted U-shaped slab could relieve the damage of the AAC blocks layer dramatically. Furthermore, based on the finite element (FE) program LS-DYNA, the corresponding refined numerical simulations are performed. By comparing the experimental and numerical damage and vibration accelerations of the composite structures, the present adopted numerical algorithms, constitutive models and parameters are validated, which will be applied in the further assessment of drop impact effects of full-scale SFC and FA on prototype nuclear fuel reprocessing plant in the next Part II of this paper.},
	language = {en},
	number = {8},
	urldate = {2023-03-23},
	journal = {Nuclear Engineering and Technology},
	author = {Li, Z. C. and Yang, Y. H. and Dong, Z. F. and Huang, T. and Wu, H.},
	month = aug,
	year = {2021},
	keywords = {Autoclaved aerated concrete, Free drop, Nuclear fuel reprocessing plant, Numerical simulation, Spent fuel cask},
	pages = {2682--2695},
}

@article{kelly_bayesian_2009,
	title = {Bayesian inference in probabilistic risk assessment—{The} current state of the art},
	volume = {94},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832008001919},
	doi = {10.1016/j.ress.2008.07.002},
	abstract = {Markov chain Monte Carlo (MCMC) approaches to sampling directly from the joint posterior distribution of aleatory model parameters have led to tremendous advances in Bayesian inference capability in a wide variety of ﬁelds, including probabilistic risk analysis. The advent of freely available software coupled with inexpensive computing power has catalyzed this advance. This paper examines where the risk assessment community is with respect to implementing modern computational-based Bayesian approaches to inference. Through a series of examples in different topical areas, it introduces salient concepts and illustrates the practical application of Bayesian inference via MCMC sampling to a variety of important problems.},
	language = {en},
	number = {2},
	urldate = {2023-03-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Kelly, Dana L. and Smith, Curtis L.},
	month = feb,
	year = {2009},
	pages = {628--643},
}

@misc{noauthor_probabilistic_nodate,
	title = {Probabilistic risk assessment based model validation method using {Bayesian} network {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832016305907?token=455A4CEB463251BAE1B304AA15728381A84361E2C64B3789DA6212B6E60475C267F5EB6B076B2C8B3E82CCE4BBD5F522&originRegion=us-east-1&originCreation=20230301183031},
	language = {en},
	urldate = {2023-03-01},
	doi = {10.1016/j.ress.2017.09.013},
}

@misc{noauthor_rapid_nodate,
	title = {Rapid source term prediction in nuclear power plant accidents based on dynamic {Bayesian} networks and probabilistic risk assessment {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0306454921000931?token=8978EDC499C024E7DC7766C5E1DF8F5C7A0451209C20AB6F224F4A2D63FAD899CEF2A65A2C4737641D39D28A4FCA6FB7&originRegion=us-east-1&originCreation=20230301182907},
	language = {en},
	urldate = {2023-03-01},
	doi = {10.1016/j.anucene.2021.108217},
}

@misc{weiner_risk_nodate,
	address = {Sandia National Laboratories},
	title = {Risk {Assessment} of {Transportation} of {Radioactive} {Materials} {Using} {RADTRAN}},
	language = {English},
	author = {Weiner, Ruth},
}

@misc{national_river__recreation_area_minnesota_mississippi_2022,
	title = {Mississippi {River} {Facts}},
	url = {https://www.nps.gov/miss/riverfacts.htm},
	abstract = {Mississippi River Facts},
	language = {en},
	urldate = {2023-02-19},
	journal = {Mississippi},
	author = {{National River \& Recreation Area Minnesota}},
	month = feb,
	year = {2022},
}

@misc{nuclear_energy_agency_origen-22_2002,
	title = {{ORIGEN}-2.2, {Isotope} {Generation} and {Depletion} {Code} {Matrix} {Exponential} {Method}},
	url = {https://www.oecd-nea.org/tools/abstract/detail/ccc-0371/},
	language = {English},
	urldate = {2022-12-07},
	journal = {CCC-0371 OREIGEN-2.2},
	author = {{Nuclear Energy Agency}},
	month = oct,
	year = {2002},
}

@techreport{john_r_cook_nureg-2125_2014,
	address = {Washington, D.C},
	type = {Final {Report}},
	title = {{NUREG}-2125, "{Spent} {Fuel} {Transportation} {Risk} {Assessment}."},
	language = {en},
	number = {2125},
	institution = {NRC},
	author = {{John R. Cook}},
	month = jan,
	year = {2014},
	pages = {517},
}

@misc{nebraska_department_of_environmental_quality_nebraska_2016,
	title = {{NEBRASKA} {HAZARDOUS} {WASTE} {REGULATIONS}},
	language = {English},
	author = {{NEBRASKA DEPARTMENT OF ENVIRONMENTAL QUALITY}},
	month = jul,
	year = {2016},
	pages = {527},
}

@article{sabek_risk_nodate,
	title = {{RISK} {ASSESSMENT} {DURING} {TRANSPORT} {OF} {RADIOACTIVE} {MATERIALS} {THROUGH} {THE} {SUEZ} {CANAL}},
	abstract = {In this paper a study for risk assessment of the impact of transporting radioactive materials, during the period 1986-1992, through the Suez Canal of Egypt is given. The code RADTRAN-IV was used for this study. The results of the code, for a normal case, show that the transportation of low activity materials such as uranium (U308) represent the main items that contribute significantlyto the collective dose within the Suez Canal area (Port-Said, Ismailia and Suez). The values of the annual collectivedose due to transportation of all radionuclide materials was found to be at a maximum in Suez town and is equal to 5.04 x 10\_8 Man-Sv for the whole populations. If we only consider the worker at the harbour (estimated to be 50 persons), the value of the annual collectivedose is about 3.33 x 10-4 Man-Sv. These values are less than the exemption value of I Man-Sv recommendedby the IAEA. For the accident case, the following pathways are considered by the code: ground-shine, direct inhalation, inhalation of resuspended material and cloud-shine. The total values of the estimated risks for each radionuclide material are presented in table form and, in addition, health effects (geneticeffects, GE, and latent cancer fatality, LCF) are discussed. The calculated values of the radiological risks are very low for the three towns, showing that no radiation-induced early deaths are to be expected. © 1997 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	author = {Sabek, M G and El-Shinawy, R M K and Gomaa, M},
}

@misc{wyoming_department_of_environmental_quality_wyoming_2022,
	title = {Wyoming {Environmental} {Quality} {Act}},
	language = {English},
	author = {{Wyoming Department of Environmental Quality}},
	month = apr,
	year = {2022},
}

@techreport{sowder_uranium_2020,
	type = {Topical {Report} {EPRI}-{AR}-1 ({NP})-{A}},
	title = {Uranium {Oxycarbide} ({UCO}) {Tristructural} {Isotropic} ({TRISO})-{Coated} {Particle} {Fuel} {Performance}},
	language = {en},
	number = {3002019978},
	author = {Sowder, A and Marciulescu, C},
	month = nov,
	year = {2020},
	pages = {99},
}

@misc{united_states_department_of_defense_record_2022,
	title = {Record of {Decision} for the {Final} {Construction} and {Demonstration} of a {Prototype} {Mobile} {Microreactor} {Environmental} {Impact} {Statement}},
	language = {English},
	author = {{United States Department of Defense}},
	month = apr,
	year = {2022},
}

@techreport{united_states_department_of_defense_defense_science_board_energy_2016,
	title = {Energy {Systems} for {Forward}/{Remote} {Operating} {Bases}},
	language = {English},
	author = {{United States Department of Defense Defense Science Board}},
	month = aug,
	year = {2016},
	pages = {99},
}

@article{united_states_department_of_defense_draft_2021,
	title = {Draft {Construction} and {Demonstration} of a {Prototype} {Mobile} {Microreactor} {Environmental} {Impact} 4 {Statement} ({Draft} {EIS})},
	language = {en},
	author = {{United States Department of Defense}},
	month = sep,
	year = {2021},
	pages = {314},
}

@inproceedings{stott_common_2018,
	title = {Common {Cause} {Failure} {Modeling}: {Aerospace} vs. {Nuclear}},
	url = {https://ntrs.nasa.gov/api/citations/20100025991/downloads/20100025991.pdf},
	abstract = {Aggregate nuclear plant failure data is used to produce generic common-cause factors that are specifically for use in the common-cause failure models of NUREG/CR-5485. Furthermore, the models presented in NUREG/CR-5485 are specifically designed to incorporate two significantly distinct assumptions about the methods of surveillance testing from whence this aggregate failure data came. What are the implications of using these NUREG generic factors to model the common-cause failures of aerospace systems? Herein, the implications of using the NUREG generic factors in the modeling of aerospace systems are investigated in detail and strong recommendations for modeling the common-cause failures of aerospace systems are given.},
	language = {en},
	booktitle = {{PSAM}},
	author = {Stott, James E and Britton, Paul T and Ring, Robert W and Hark, Frank and Spencer, G},
	month = may,
	year = {2018},
	pages = {12},
}

@techreport{chu_review_nodate,
	title = {A {Review} of {Software}-{Induced} {Failure} {Experience}},
	url = {https://www.bnl.gov/isd/documents/32718.pdf},
	abstract = {Wepresent a review of sofiare-induced failures in commercial nuclear powerplants (NPPs) and in several non-nuclear industries. We discuss the approach usedfor coNecting operational events related to thesefailures and the imights gainedfrom this review Inparticular, we elaborate on insights that can be used lo model this kind offailure in a probabilistic risk assessment (PRA) model. Wepresent the conclusions reached in these areas.},
	language = {en},
	institution = {Brookhaven National Lab. (BNL), Upton, NY (United States); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor and Plant Systems},
	author = {Chu, T L and Martinez-Guridi, G and Yue, M and Lehner, J},
	pages = {16},
}

@inproceedings{mohaghegh_physics-based_nodate,
	title = {Physics-{Based} {Common} {Cause} {Failure} {Modeling} in {Probabilistic} {Risk} {Analysis}: {A} {Mechanistic} {Perspective}},
	shorttitle = {Power2011-55324 {Physics}-{Based} {Common} {Cause} {Failure} {Modeling} in {Probabilistic} {Risk} {Analysis}},
	url = {https://www.researchgate.net/publication/267608196_Physics-Based_Common_Cause_Failure_Modeling_in_Probabilistic_Risk_Analysis_A_Mechanistic_Perspective},
	doi = {DOI: 10.1115/POWER2011-55324},
	abstract = {ABSTRACT The modeling of dependent failures, specifically Common Cause Failures (CCFs), is one of the most important topics in Probabilistic Risk Analysis (PRA). Currently, CCFs are treated using parametric methods, which are based on historical failure events. Instead of utilizing these existing data-driven approaches, this paper proposes using physics-based CCF modeling which refers to the incorporation of underlying physical failure mechanisms into risk models so that the root causes of dependencies can be "explicitly" included. This requires building a theoretical foundation for the integration of Probabilistic Physics-Of-Failure (PPOF) models into PRA in a way that the interactions of failure mechanisms and, ultimately, the dependencies between the multiple component failures are depicted. To achieve this goal, this paper highlights the following methodological steps (1) modeling the individual failure mechanisms (e.g. fatigue and wear) of two dependent components, (2) applying a mechanistic approach to deterministically model the interactions of their failure mechanisms, (3) utilizing probabilistic sciences (e.g. uncertainty modeling, Bayesian analysis) in order to make the model of interactions probabilistic, and (4) developing appropriate modeling techniques to link the physics-based CCF models to the system-level PRA. The proposed approach is beneficial for (a) reducing CCF occurrence in currently operating plants and (b) modeling CCFs for plants in the design stage.},
	author = {Mohaghegh, Zahra and Modarres, Mohammad and Christou, Aris},
}

@techreport{noauthor_use_2002,
	title = {The {Use} and {Development} of {Probabilistic} {Safety} {Assessment} in {NEA} {Member} {Countries}},
	url = {https://one.oecd.org/document/NEA/CSNI/R(2019)10/En/pdf},
	abstract = {The mission of the CSNI is to assist Member countries in maintaining and further developing the scientific and technical knowledge base required to assess the safety of nuclear reactors and fuel cycle facilities.},
	language = {en},
	number = {NEA/CSNI/R(2002)18},
	year = {2002},
}

@techreport{mitman_oram-sentineltm_nodate,
	type = {Manual},
	title = {{ORAM}-{SentinelTM} {Version} 3.4 {User}'s {Manual} {All} {Modes} {Maintenance} and {Safety} {Function} {Advisor}},
	url = {https://www.epri.com/research/products/1006363},
	language = {en},
	number = {1006363},
	institution = {EPRI},
	author = {Mitman, J},
}

@techreport{noauthor_applications_2001,
	title = {Applications of probabilistic safety assessment ({PSA}) for nuclear power plants},
	url = {https://www-pub.iaea.org/mtcd/publications/pdf/te_1200_prn.pdf},
	number = {IAEA-TECDOC-1200},
	urldate = {2023-03-19},
	institution = {IAEA},
	month = feb,
	year = {2001},
}

@misc{noauthor_texas_nodate,
	title = {Texas {Instruments} {Failure} {Database}: {MTBF} and {FIT} {Rate} {Estimator}},
	url = {https://www.ti.com/quality/docs/estimator.tsp},
	urldate = {2022-12-07},
}

@misc{noauthor_mtbf_nodate,
	title = {{MTBF} and {FIT} {Rate} {Estimator}},
	url = {https://www.ti.com/quality/docs/estimator.tsp},
	urldate = {2023-03-20},
}

@misc{noauthor_cafta_nodate,
	title = {{CAFTA} {Software} {Technology} {PackageV} 10 - {Phoenix} {Architect}},
	url = {https://polestartechnicalservices.com/cafta-software/},
	abstract = {CAFTA is the industry leader in fault tree analysis for large, complicated, or multi-user collaborative projects. View our CAFTA software package.},
	language = {en-US},
	urldate = {2023-03-20},
	journal = {Polestar Technical Services},
}

@inproceedings{chao_risk_2003,
	address = {Japan},
	title = {Risk management in {Taiwan}'s nuclear power plants by adopting {TIRM}-2},
	abstract = {The TIRM-2 is the second generation risk monitor developed by INER and TPC By providing
risk indexes such as CDF, LERF, ΔCDF, ΔLERF, importance measurements and availability
of safety systems, the TIRM-2 can precisely capture the plant risks and can serve
as a better management resource Examples about how to use TIRM-2 for the risk management
are discussed in this paper For plant at power operation, the TIRM-2 allows the plant
staff to change plant configuration directly from the P and I Diagram For a new plant
configuration, only a few minutes will be spent for TIRM-2 to recalculate all the
risk indexes TIRM-2 can also provide risk profile and the associated risk indexes
based on a given online maintenance schedule The risk profile of CDF and LERF with
ΔCDF and ΔLERF will help the plant staff with preparing associated information for
the applications of risk-informed, performance-based regulation With the proposed
refueling outage schedule, the TIRM-2 can predict status of safety system and risk
profile of CDF hourly All calculations can be done within 40 minutes for a typical
50-days outage schedule The plant staff and managers can rearrange the maintenance
schedule referring to TIRM-2' predicted results and avoiding the plant entering into
a potential high-risk situation With the capability of performing both CDF and LERF
calculations, the TIRM-2's will become a very helpful tool in monitoring the risk
of different plant status and will provide further information directly for risk-informed
applications (author)},
	publisher = {Japan Society of Mechanical Engineers},
	author = {Chao, Chun-Chang and Kao, Tsu-Mu and Huang, Shian-Hung},
	year = {2003},
	note = {INIS Reference Number: 35045106},
	pages = {3610},
}

@techreport{kim_development_2002,
	title = {Development of full power risk monitoring system for {UCN} 3 and 4 nuclear power plants},
	url = {https://www.osti.gov/etdeweb/biblio/20412421},
	abstract = {This report describes full power risk monitoring system (DynaRM) of NPPs which evaluates the current plant risk and monitor the risk change caused by the configuration change due to preventive maintenance or periodic maintenance activities. In order to calculate the core damage frequency, the inoperable equipment's basic event should be submitted to a quantification engine. DynaRM uses a risk monitor model converted from PSA model as the quantification engine, which can respond fast for the various equipment configuration changes. DynaRM is developed to solve these kinds of problems and difficulties. The main two key features of DynaRM are real time risk monitoring and real time maintenance plan decision supporting. With DynaRM, the plant risk can be calculated automatically only with out of service equipment information and equipment maintenance scheduling is easy by modifying the detail schedule plan. We have developed the DynaRM for the Korean standard nuclear power plant and it is currently using at Ulchin 3,4 NPP. The adaptation for the other NPPs is also easy with a little modification since DynaRM was developed by considering it to be used in the other NPPs. Moreover, we also expect DynaRM will be a good advisory tool for the plant risk monitoring and maintenance scheduling.},
	language = {Korean},
	urldate = {2023-03-20},
	author = {Kim, Seung Hwan and Jang, Seung Chul and Kim, Kil Yoo and Han, Sang Hoon and Jung, Won Dae},
	month = mar,
	year = {2002},
}

@misc{backstrom_riskspectrum_nodate,
	title = {{RiskSpectrum}, {Current} {Status} and {Future} {Plans}},
	url = {https://open-psa.github.io/joomla1.5/attachments/010_presentation_backstrom.pdf},
	urldate = {2023-03-20},
	author = {Backstrom, Ola},
}

@misc{noauthor_riskspectrum_nodate,
	title = {{RiskSpectrum}® {\textbar} {Risk} \& {Reliability} {Software}},
	url = {https://www.riskspectrum.com},
	abstract = {Discover a proven suite of software tools that enable you to precisely, rapidly \& confidently calculate, visualise, monitor \& manage risk.},
	language = {en},
	urldate = {2023-03-20},
}

@misc{noauthor_oram-sentinel_nodate,
	title = {{ORAM}-{Sentinel} ({TM}) {Version} 3.4 {User}'s {Manual}: {All} {Modes} {Maintenance} and {Safety} {Function} {Advisor}},
	url = {https://www.epri.com/research/products/1006363},
	urldate = {2023-03-20},
}

@misc{rawson_safety_1997,
	title = {The {Safety} {Monitor} and {RCM} {Workstation} {As} {Complementary} {Tools} {In} {Risk} {Based} {Maintenance} {Optimization}},
	url = {https://inis.iaea.org/collection/NCLCollectionStore/_Public/31/022/31022344.pdf?r=1&r=1},
	abstract = {Reliability Centred Maintenance (RCM) represents a proven technique for rendering
maintenance activities safer, more effective, and less expensive, in terms of systems
unavailability and resource management. However, it is believed that RCM can be enhanced
by the additional consideration of operational plant risk. This paper discusses how two
computer-based tools, i.e., the RCM Workstation and the Safety Monitor, can complement
each other in helping to create a living preventive maintenance strategy.},
	publisher = {IAEA},
	author = {Rawson, P. D.},
	month = sep,
	year = {1997},
}

@misc{noauthor_curtiss-wright_nodate,
	title = {Curtiss-{Wright} {Nuclear} - {Brands} - {Scientech} - {Safety} \& {Risk} - {Safety} {MonitorTM}},
	url = {https://www.cwnuclear.com/brands/scientech/safety-and-risk/safety-monitortm/default.aspx},
	urldate = {2023-03-20},
}

@misc{noauthor_phoenix_nodate,
	title = {Phoenix {Risk} {Monitor} ({RM}) {Version} 2.0a - {Software}},
	url = {https://www.epri.com/research/products/3002008103},
	urldate = {2023-03-19},
}

@misc{noauthor_equipment_nodate,
	title = {Equipment {Out} of {Service} ({EOOS}), {A} {Tool} for {Risk} {Awareness}, {Version} 4.1},
	url = {https://www.epri.com/research/products/000000000001011195},
	urldate = {2023-03-19},
}

@misc{wong_risk_nodate,
	address = {NRC},
	title = {Risk {Monitors} {Applications}: {US} {Experience}},
	url = {https://www.nrc.gov/docs/ML1415/ML14150A469.pdf},
	author = {Wong, Meng},
}

@inproceedings{noauthor_defense--depth_nodate,
	title = {Defense-in-{Depth} {Risk} {Evaluation} {Model} {Development} {Strategy} for {Plant} {Configuration} {Risk} {Management} of {Pressurized} {Heavy} {Water} {Reactor} {Low} {Power}/{Shutdown} {Operation}},
	url = {https://www.kns.org/files/pre_paper/21/466%EC%96%91%ED%9D%AC%EC%B0%BD.pdf},
	urldate = {2023-03-19},
}

@misc{noauthor__nodate,
	title = {§ 50.65 {Requirements} for monitoring the effectiveness of maintenance at nuclear power plants.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/part050-0065.html},
	language = {en-US},
	urldate = {2023-03-19},
	journal = {NRC Web},
}

@incollection{yoshikawa_design_2014,
	title = {Design of {Risk} {Monitor} for {Nuclear} {Reactor} {Plants}},
	isbn = {978-4-431-54609-2},
	abstract = {In this chapter, the method of how to comprise a concept of “plant Defense-in-Depth (DiD) risk monitor” and “reliability monitor” for nuclear power plant is discussed in detail. The discussion starts on the defi nition of risk and risk ranking on the items of (a) design principle of nuclear safety, (b) risk to be monitored, (c) severe accident phenomena, and (d) risk ranking. After analyzing the anatomy of fault event occurrence from the view of common mode failure and considering the semiotic modeling of nuclear power plant as a whole by utilizing multilevel flow model (MFM), the image of distributed human- machine interface system of plant DiD risk monitor and reliability monitor is introduced. Also discussion is made on how to visualize risk state intuitively as “dynamic risk monitor” as the display to human. Then an example practice is presented for containment spray system of PWR by the proposed concept of “reliability monitor” with the application of FMEA and GO-FLOW analysis. The formation of “plant DiD risk monitor” by utilization of revised MFM will be the next step study for configuring the proposed concept for the “plant DiD risk monitor.”},
	author = {Yoshikawa, Hidekazu and Yang, Ming and Hashim, Madihah and Lind, Morten and Zhang, Zhijian},
	month = jan,
	year = {2014},
	doi = {10.1007/978-4-431-54610-8_13},
	pages = {125--135},
}

@article{wang_risk_2016,
	title = {Risk monitor riskangel for risk-informed applications in nuclear power plants},
	volume = {91},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454915300293},
	doi = {10.1016/j.anucene.2015.12.019},
	language = {en},
	urldate = {2023-03-19},
	journal = {Annals of Nuclear Energy},
	author = {Wang, Fang and Wang, Jiaqun and Wang, Jin and Li, Yazhou and Hu, Liqin and Wu, Yican},
	month = may,
	year = {2016},
	pages = {142--147},
}

@inproceedings{riley_applied_2019,
	address = {Orlando, FL, USA},
	title = {Applied {Risk} {Management} in {Electric} {Power} {Plant} {Decision} {Making}},
	isbn = {978-1-5386-6554-1},
	url = {https://ieeexplore.ieee.org/document/8768918/},
	doi = {10.1109/RAMS.2019.8768918},
	abstract = {CONCLUSIONS Large electric power plants incorporate a large number of complex, highly redundant, and very reliable systems in order to produce power in safe and efficient manner. Much effort is expended to assure that the systems are maintained to maximize the availability of all normal and safety-related systems. To assure safe operation while performing maintenance or responding to unexpected equipment outages, power plants must continually evaluate the risk of changes in plant configuration.},
	language = {en},
	urldate = {2023-03-19},
	booktitle = {2019 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	publisher = {IEEE},
	author = {Riley, Jeff and Weglian, John},
	month = jan,
	year = {2019},
	pages = {1--6},
}

@article{moreno_implementation_2019,
	title = {Implementation of {Risk} {Monitor} at a {U}.{S}. {Nuclear} {Power} {Plant}},
	abstract = {This paper will cover an example of the implementation of risk monitor software at a nuclear power plant in the U.S. The site uses the risk monitor and results from the PSA to inform decisions made for work control, online risk management and outage risk, and emergent issues. How the insights translate to indicators used at the site on a daily basis and risk control measures put in place during heightened risk evolutions will be discussed. Specific examples of when the tools and insights are used, how results are communicated, as well as how this information has steered decisions will be included.},
	language = {en},
	author = {Moreno, Aaron and Tirsun, Daniel and Trull, Carroll},
	year = {2019},
}

@article{mosleh_common_1991,
	title = {Common cause failures: {An} analysis methodology and examples},
	volume = {34},
	issn = {09518320},
	shorttitle = {Common cause failures},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209190104F},
	doi = {10.1016/0951-8320(91)90104-F},
	language = {en},
	number = {3},
	urldate = {2023-03-19},
	journal = {Reliability Engineering \& System Safety},
	author = {Mosleh, Ali},
	month = jan,
	year = {1991},
	pages = {249--292},
}

@techreport{noauthor_digital_2014,
	title = {Digital {Common}-{Cause} {Failure} {Susceptibility}},
	url = {https://www.nrc.gov/docs/ML1525/ML15252A038.pdf},
	urldate = {2023-03-19},
	institution = {EPRI},
	year = {2014},
}

@misc{lyubarskiy_l8_nodate,
	title = {L8. {Living} {PSA} and the {Development} of {Risk} {Monitors}},
	language = {en},
	author = {Lyubarskiy, Artur},
}

@article{simic_comparison_nodate,
	title = {Comparison of {On}-{Line} {Maintenance} {Support} {Tools}},
	abstract = {Modeling approach to on-line risk monitoring is today in a rapid developing phase. For that reason number of different solutions are available. This paper will attempt to present existing approaches to address on-line risk modeling problem. Starting with description of on-line risk monitoring issues in general, then following by presentation of existing software tools (EPRI®'s Safety Monitor, Equipment Out of Service Monitor, and ORAM-SENTINEL) the current state of the art in this area will be demonstrated. Finally, conclusions and ideas will be outlined.},
	language = {en},
	author = {Simic, Zdenko and Follen, Steve M and Mikulicic, Vladimir},
}

@article{hoseyni_probabilistic_2017,
	title = {Probabilistic analysis of containment structural performance in severe accidents},
	volume = {8},
	issn = {0975-6809, 0976-4348},
	url = {http://link.springer.com/10.1007/s13198-016-0540-1},
	doi = {10.1007/s13198-016-0540-1},
	abstract = {To study the capacity of reactor containment under pressurization, it is important to know the way that this structure reacts under internal pressure loading. This is usually performed through structural fragility analysis for assuring that the containment structure has high capability of withstanding the loads associated with severe accident phenomena and its consequent pressurization, therefore the potential for significant radioactive release is small. In this paper, the methodology of structural fragility analysis for pressurization is thoroughly reviewed, and its practical application is demonstrated on a real case Pressurized Water Reactor containment. The reactor containment is analyzed using finite element method, and the ultimate pressure is computed. Containment performance is further analyzed using the structural fragility method. The structural fragility serves as the interface between the structural analysis model and the risk model of the systems. Therefore, a probabilistic scheme is used to represent the structural fragility. Final outcome of this study is the overpressure fragility curve which depicts the probability of failure of the containment at a given value of pressure. This curve is a key element in conducting probabilistic safety assessment (level 2 PSA) of nuclear power plants.},
	language = {en},
	number = {3},
	urldate = {2023-03-18},
	journal = {International Journal of System Assurance Engineering and Management},
	author = {Hoseyni, Seyed Mojtaba and Hoseyni, Seyed Mohsen and Yousefpour, Faramarz and Karimi, Kaveh},
	month = sep,
	year = {2017},
	pages = {625--634},
}

@misc{noauthor_18_nodate,
	title = {(18) ({PDF}) {Probabilistic} analysis of containment structural performance in severe accidents},
	url = {https://www.researchgate.net/publication/309380497_Probabilistic_analysis_of_containment_structural_performance_in_severe_accidents},
	urldate = {2023-03-18},
}

@misc{noauthor_defense_nodate,
	title = {Defense in depth},
	url = {https://www.nrc.gov/reading-rm/basic-ref/glossary/defense-in-depth.html},
	language = {en-US},
	urldate = {2023-03-18},
	journal = {NRC Web},
}

@misc{bao_quantitative_2022,
	title = {Quantitative {Evaluation} of {Common} {Cause} {Failures} in {High} {Safety}-significant {Safety}-related {Digital} {Instrumentation} and {Control} {Systems} in {Nuclear} {Power} {Plants}},
	url = {http://arxiv.org/abs/2204.03717},
	doi = {10.48550/arXiv.2204.03717},
	abstract = {Digital instrumentation and control (DIC) systems at nuclear power plants (NPPs) have many advantages over analog systems. They are proven to be more reliable, cheaper, and easier to maintain given obsolescence of analog components. However, they also pose new engineering and technical challenges, such as possibility of common cause failures (CCFs) unique to digital systems. This paper proposes a Platform for Risk Assessment of DIC (PRADIC) that is developed by Idaho National Laboratory (INL). A methodology for evaluation of software CCFs in high safety-significant safety-related DIC systems of NPPs was developed as part of the framework. The framework integrates three stages of a typical risk assessment, qualitative hazard analysis and quantitative reliability and consequence analyses. The quantified risks compared with respective acceptance criteria provide valuable insights for system architecture alternatives allowing design optimization in terms of risk reduction and cost savings. A comprehensive case study performed to demonstrate the framework capabilities is documented in this paper. Results show that the PRADIC is a powerful tool capable to identify potential digital-based CCFs, estimate their probabilities, and evaluate their impacts on system and plant safety.},
	urldate = {2023-03-18},
	publisher = {arXiv},
	author = {Bao, Han and Zhang, Hongbin and Shorthill, Tate and Chen, Edward and Lawrence, Svetlana},
	month = apr,
	year = {2022},
	note = {arXiv:2204.03717 [cs, eess]},
	keywords = {Electrical Engineering and Systems Science - Systems and Control},
}

@misc{noauthor_rapid_nodate,
	title = {A rapid modeling method and accuracy criteria for common-cause failures in {Risk} {Monitor} {PSA} model {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S1738573320300760?token=8B4179AFEAC0214A20ADADA06455662A5F333638A08C5D47F82E21B2521815DCC570032F7625188F032F21933B8F459F&originRegion=us-east-1&originCreation=20230318025727},
	language = {en},
	urldate = {2023-03-18},
	doi = {10.1016/j.net.2020.06.021},
}

@techreport{noauthor_collection_nodate,
	title = {Collection and {Analysis} of {Common}-{Cause} {Failures} due to {Nuclear} {Power} {Plant} {Modifications}},
	url = {https://one.oecd.org/document/NEA/CSNI/R(2019)4/En/pdf},
	number = {NEA/CSNI/R(2019)4},
	urldate = {2023-03-18},
	institution = {Nuclear Energy Agency},
}

@techreport{noauthor_risk_nodate,
	title = {Risk {Monitors}: {The} {State} of the {Art} in their {Development} and {Use} at {Nuclear} {Power} {Plants}},
	url = {https://www.oecd-nea.org/jcms/pl_18136/risk-monitors-the-state-of-the-art-report-soar-in-their-development-and-use-at-nuclear-power-plants-produced-on-behalf-of-the-iaea-and-the-nea-wgrisk?details=true},
	language = {en},
	number = {NEA/CSNI/R(2004)20},
	institution = {NUCLEAR ENERGY AGENCY COMMITTEE ON THE SAFETY OF NUCLEAR INSTALLATIONS},
}

@misc{noauthor_published_2023,
	title = {Published {Tools} and {Methods} / {Introducing} {Multiple} {Control} {Paths} in the {Dual} {Error} {Propagation} {Graph} for {Stochastic} {Failure} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} · {GitLab}},
	url = {https://gitlab.openpra.org/published-tools-and-methods/introducing-multiple-control-paths-in-the-dual-error-propagation-graph-for-stochastic-failure-analysis-of-digital-instrumentation-and-control-systems},
	abstract = {OpenPRA Gitlab},
	language = {en},
	urldate = {2023-03-18},
	journal = {GitLab},
	month = mar,
	year = {2023},
}

@techreport{tunc_aldemir_current_2006,
	title = {Current {State} of {Reliability} {Modeling} {Methodologies} for {Digital} {Systems} and {Their} {Acceptance} {Criteria} for {Nuclear} {Power} {Plant} {Assessments} ({NUREG}/{CR}-6901)},
	shorttitle = {{NUREG}/{CR}-6901},
	url = {https://www.nrc.gov/docs/ML0608/ML060800179.pdf},
	language = {en-US},
	number = {NUREG/CR-6901},
	urldate = {2023-03-18},
	institution = {Nuclear Regulatory Commission},
	author = {{Tunc Aldemir}},
	month = feb,
	year = {2006},
	pages = {108},
}

@book{national_research_council_staff_digital_1997,
	address = {Washington, D.C.},
	title = {Digital instrumentation and control systems in nuclear power plants safety and reliability issues: final report},
	isbn = {978-0-309-52444-5},
	shorttitle = {Digital instrumentation and control systems in nuclear power plants safety and reliability issues},
	language = {eng},
	publisher = {National Academy Press},
	author = {National Research Council Staff},
	year = {1997},
	note = {OCLC: 1108976232},
}

@misc{kansas_department_of_health_and_environment_hazardous_2019,
	title = {Hazardous {Waste}},
	language = {en},
	author = {{Kansas Department of Health and Environment}},
	month = feb,
	year = {2019},
	pages = {69},
}

@misc{state_of_georgia_department_of_transportation_transportation_2023,
	title = {Transportation of {Hazardous} {Materials}},
	url = {https://rules.sos.ga.gov/gac/672-10},
	language = {en},
	urldate = {2023-02-01},
	author = {{State of Georgia Department of Transportation}},
	month = mar,
	year = {2023},
}

@article{nuclear_news_final_2022,
	title = {Final {EIS} for {Project} {Pele} microreactor available},
	volume = {Power \& Operations},
	url = {https://www.ans.org/news/article-3697/final-eis-for-project-pele-microreactor-available/},
	language = {en},
	urldate = {2023-02-01},
	journal = {Nuclear Newswire},
	author = {{Nuclear News}},
	month = feb,
	year = {2022},
}

@misc{us_coast_guard_top_nodate,
	title = {{TOP} 10 {TOWING} {VESSEL} {MATERIAL} {FAILURES}},
	author = {{U.S Coast Guard}},
}

@techreport{us_department_of_energy_section_2014,
	title = {Section {Two}: {Packaging}, {Transportation} and {Storage} of {Radioactive} {Materials}},
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwj9xOrBq-P9AhXKlGoFHX7jBYkQFnoECAkQAQ&url=https%3A%2F%2Fwww.energy.gov%2Fsites%2Fprod%2Ffiles%2F2014%2F04%2Ff14%2Frmem2_0.pdf&usg=AOvVaw0V8TQ-XVT9c7i4IOKU71Qo},
	language = {en},
	author = {{U.S. Department of Energy}},
	month = apr,
	year = {2014},
	pages = {12},
}

@misc{us_bureau_of_transportation_statistics_mississippi_2021,
	title = {Mississippi {River} and {Waterborne} {Freight} {\textbar} {Bureau} of {Transportation} {Statistics}},
	url = {https://www.bts.gov/modes/maritime-and-inland-waterways/mississippi-river-and-waterborne-freight},
	urldate = {2023-02-19},
	journal = {Mississippi River and Waterborne Freight},
	author = {{U.S. Bureau of Transportation Statistics}},
	month = may,
	year = {2021},
}

@misc{us_nuclear_regulatory_commission_10_2021,
	title = {10 {CFR} § 71.73 {Hypothetical} accident conditions.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part071/part071-0073.html},
	language = {en-US},
	urldate = {2023-03-14},
	author = {{U.S. Nuclear Regulatory Commission}},
	month = mar,
	year = {2021},
}

@misc{us_nuclear_regulatory_commission__2021,
	title = {§ 71.47 {External} radiation standards for all packages.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part071/part071-0047.html},
	language = {en-US},
	urldate = {2023-03-09},
	author = {{U.S. Nuclear Regulatory Commission}},
	month = mar,
	year = {2021},
}

@misc{us_nuclear_regulatory_commission_10_2021-1,
	title = {10 {CFR} § 70.12 {Carriers}.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part070/part070-0012.html},
	language = {en-US},
	urldate = {2023-03-14},
	author = {{U.S. Nuclear Regulatory Commission}},
	month = mar,
	year = {2021},
}

@misc{us_nuclear_regulatory_commission_10_2021-2,
	title = {10 {CFR} § 70.13 {Department} of {Defense}.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part070/part070-0013.html},
	language = {en-US},
	urldate = {2023-03-14},
	author = {{U.S. Nuclear Regulatory Commission}},
	month = mar,
	year = {2021},
}

@techreport{noauthor_chapter_2020,
	type = {{NuScale} {FSAR}},
	title = {Chapter {Nine}: {Auxiliary} {Systems}.pdf},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A498.pdf},
	urldate = {2022-10-17},
	month = jun,
	year = {2020},
}

@article{pandit_development_nodate,
	title = {The development of {Supply} chain {Probabilistic} {Risk} {Assessment} {Tool}},
	journal = {(unpublished)},
	author = {Pandit, Priyanka and Earthperson, Arjun and Nevius, Daniel and Diaconeasa, Mihai A},
}

@article{sturzebecher_regulatory_nodate,
	title = {{REGULATORY} {GUIDE} 1.168},
	language = {en},
	author = {Sturzebecher, Karl},
}

@inproceedings{kafka_risk_2004,
	address = {London},
	title = {Risk {Monitoring} {Systems}},
	isbn = {978-0-85729-410-4},
	doi = {10.1007/978-0-85729-410-4_422},
	abstract = {The paper shows the idea, the drivers and some basics within the wide spread field of Risk Monitoring Systems for nuclear power plants. Pros and cons are summarised and the status of last developments is touched. The situation in non-nuc technologies is commented.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer},
	author = {Kafka, Peter},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	keywords = {Component Outage, Deterministic Criterion, Plant Configuration, Risk Impact, Risk Level},
	pages = {2635--2640},
}

@inproceedings{chen_system_2018,
	title = {System {Safety} {Analysis} {Method} {Based} on {Real}-{Time} {Online} {Risk} {Monitoring} {Technology}},
	doi = {10.1115/ICONE26-82563},
	abstract = {In the continuous operation process of Nuclear Power Plant (NPP), its configuration is full of variety over time because of the system’s dynamic characteristics. There is a great need to update the risk/safety analysis models when it becomes necessary to reflect those dynamic characteristics of the system/component. Most of the current methods for risk/safety analysis belong to the scope of safety pre-analyzing, which analyzes the system risk/safety before system being in service. The main purpose of these safety pre-analyzing is to guide system design and optimization, but the real-time operational risk/safety analysis of NPPs is considered little. In order to know well the real-time risk/safety for system, a System Safety Analysis Method based on Real-time Online Risk Monitoring Technology is proposed. The safety risk model is established based on the modular fault tree that is used to represent logic structure of system. The real-time risk/safety is monitored according to the correspondence monitoring signal or data of component/system. Simultaneously the method can account for the change of risks based on the established mapping relationship between the state transition rules and corresponding risk/safety model updating rules. Finally, a case monitoring the safety for the system of two redundant pumps was used to demonstrate the effectiveness of the method.},
	author = {Chen, Sijuan and Zhang, Zhijian and Wang, He and Zhang, Min and Zhang, Huazhi and Xu, Anqi and Ma, Yingfei and Zheng, Gangyang},
	month = jul,
	year = {2018},
	pages = {V002T14A024},
}

@inproceedings{ma_standby_2018,
	title = {Standby {Equipment} {Reliability} {Data} {Analysis} on {Risk} {Monitor} of {Nuclear} {Power} {Plant}},
	doi = {10.1115/ICONE26-82590},
	abstract = {Reliability data works as the basis of risk monitor of nuclear power plant. The failure modes of the equipment in a nuclear power plant can be divided into operation failure, demand failure and standby failure. A standby equipment is affected by the demand stress and the standby stress simultaneously, so the method of reliability data analysis must consider the two types of failure. The reliability data in online risk monitor should reflect the change of equipment reliability with time, including standby equipment. A method to deal with the reliability data of the standby equipment is presented in this paper. This model takes into account the failure of the equipment during the spare time and the failure of the starting time. Considering the characteristics of the reliability data in the nuclear power plant, the method of parameter estimation is studied. Finally, this method is applied to online risk monitor in nuclear power plant and the suggestion of reliability data application is put forward.},
	author = {Ma, Yingfei and Zhang, Zhijian and Wang, He and Chen, Sijuan and Xu, Anqi and Zheng, Gangyang},
	month = jul,
	year = {2018},
	pages = {V002T14A025},
}

@article{zubair_review_2010,
	title = {A {Review}: {Advancement} in {Probabilistic} {Safety} {Assessment} and {Living} {Probabilistic} {Safety} {Assessment}},
	shorttitle = {A {Review}},
	doi = {10.1109/APPEEC.2010.5449216},
	abstract = {Due to increasing demand of Electricity, every country in the world wants to construct more and more nuclear power plants and apply different advance techniques for accident prevention, safety and reliability. Probabilistic Safety Assessment (PSA) and Living Probabilistic Safety Assessment (LPSA) are two of them, which are presented in this review paper. The paper consists of four parts, in first part latest application of PSA in second part definitions and methodology of LPSA, in third part risk monitoring and in fourth part comparison between these three, has been described.},
	journal = {Asia-Pacific Power and Energy Engineering Conference, APPEEC},
	author = {Zubair, Muhammad and Zhang, Zhijian and Aamir, Muhammad},
	month = jan,
	year = {2010},
}

@article{zubair_methodology_2010,
	title = {A methodology for {Living} {Probabilistic} {Safety} {Assessment} ({LPSA})},
	doi = {10.1115/ICONE18-29352},
	abstract = {The objective of this paper is to summarize the latest techniques, applications, methodologies, use of different software, and development of codes, in the field of Living Probabilistic Safety Assessment (LPSA) and Risk Monitoring (RM). The paper consists of three parts, in first part definitions, history, aims, uses of LPSA, and a new detailed model for LPSA have been explain. In second part brief introduction, worldwide use of RM, benefits and draw backs of software in RM, and in final part comparison between LPSA and RM have been discussed. The study also makes recommendations for further use and development of these two techniques in present and future NPPs.},
	journal = {International conference on System Science and Simulation in Engineering - Proceedings},
	author = {Zubair, Muhammad and Zhang, Zhijian},
	month = jan,
	year = {2010},
}

@article{zubair_calculation_2011,
	title = {Calculation and {Updating} of {Reliability} {Parameters} in {Probabilistic} {Safety} {Assessment}},
	volume = {30},
	doi = {10.1007/s10894-010-9325-8},
	abstract = {The internal events of nuclear power plant are complex and include equipment maintenance, equipment damage etc. These events
will affect the probability of the current risk level of the system as well as the reliability of the equipment parameter
values so such kind of events will serve as an important basis for systematic analysis and calculation. This paper presents
a method for reliability parameters calculation and their updating. The method is based on binomial likelihood function and
its conjugate beta distribution. For update parameters Bayes’ theorem has been selected. To implement proposed method a computer
base program is designed which provide help to estimate reliability parameters.

KeywordsReliability parameters–Proposed method–Algorithm for program},
	journal = {Journal of Fusion Energy},
	author = {Zubair, Muhammad and Zhang, Zhijian and Khan, Salah},
	month = feb,
	year = {2011},
	pages = {13--15},
}

@techreport{moe_risk-informed_2019,
	title = {Risk-{Informed} {Performance}-{Based} {Technology}. {Inclusive} {Guidance} for {Advanced} {Reactor} {Licensing} {Basis} {Development} ({NEI} 18-04)},
	url = {https://www.osti.gov/biblio/1557649},
	abstract = {This guideline presents a modern, technology-inclusive, risk-informed, and performance-based (TI-RIPB) process for selection of Licensing Basis Events (LBEs); safety classification of structures, systems, and components (SSCs) and associated risk-informed special treatments; and determination of defense-in-depth (DID) adequacy for non-LWRs. This guidance document provides one acceptable means for addressing the aforementioned topics as part of demonstrating a specific design provides reasonable assurance of adequate radiological protection.},
	language = {English},
	number = {INL/EXT-19-55375-Rev000; NEI-18-04},
	urldate = {2023-03-16},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Nuclear Energy Institute, Washington, DC (United States)},
	author = {Moe, Wayne L.},
	month = apr,
	year = {2019},
	doi = {10.2172/1557649},
}

@article{shannon_mathematical_1948,
	title = {A {Mathematical} {Theory} of {Communication}},
	volume = {27},
	issn = {00058580},
	url = {https://ieeexplore.ieee.org/document/6773024},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	language = {en},
	number = {3},
	urldate = {2023-03-16},
	journal = {Bell System Technical Journal},
	author = {Shannon, C. E.},
	month = jul,
	year = {1948},
	pages = {379--423},
}

@misc{noauthor_plant_nodate,
	title = {Plant {Vogtle}},
	url = {https://www.georgiapower.com/company/plant-vogtle.html},
	language = {en},
	urldate = {2023-03-16},
}

@misc{noauthor_project_nodate,
	title = {Project {PELE} {Mobile} {Nuclear} {Reactor} – {DoD} {Research} \& {Engineering}, {OUSD}({R}\&{E})},
	url = {https://www.cto.mil/pele_eis/},
	urldate = {2023-03-16},
}

@misc{noauthor_nuscale_nodate,
	title = {{NuScale} {Power} {\textbar} {Small} {Modular} {Reactor} ({SMR}) {Nuclear} {Technology}},
	url = {https://nuscale-prod-fragindto-nuscale-power.vercel.app/},
	abstract = {We are the global leaders in SMR nuclear technology, delivering our groundbreaking NuScale Power Module to customers in 4, 6, and 12-module VOYGR power plants.},
	language = {en},
	urldate = {2023-03-16},
}

@misc{noauthor_reactor_2023,
	title = {Reactor: {Xe}-100 — {X}-energy: {HTGR} {\textbar} {Nuclear} {Reactors} ({SMR}) \& {TRISO} {Fuel}},
	shorttitle = {Reactor},
	url = {https://x-energy.com/reactors/xe-100},
	abstract = {We’re focused on Gen-IV High-Temperature Gas-cooled Reactors (HTGR) as the technology of choice, with advantages in sustainability, economics, reliability and safety.},
	language = {en-US},
	urldate = {2023-03-16},
	journal = {X-energy},
	month = mar,
	year = {2023},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC} {Certifies} {First} {U}.{S}. {Small} {Modular} {Reactor} {Design}},
	url = {https://www.energy.gov/ne/articles/nrc-certifies-first-us-small-modular-reactor-design},
	abstract = {NuScale power module becomes the first SMR design certified by the NRC.},
	language = {en},
	urldate = {2023-03-16},
	journal = {Energy.gov},
}

@misc{idaho_waste_management_and_remediation_division_580105_2022,
	title = {58.01.05 – {Rules} and {Standards} for {Hazardous} {Waste}},
	author = {{Idaho Waste Management and Remediation Division}},
	year = {2022},
}

@article{rejc_extension_2014,
	title = {An extension of {Multiple} {Greek} {Letter} method for common cause failures modelling},
	volume = {29},
	issn = {0950-4230},
	url = {https://www.sciencedirect.com/science/article/pii/S0950423014000321},
	doi = {10.1016/j.jlp.2014.02.009},
	abstract = {Common cause failure describes a condition where several components share the same source of failure that causes them to fail or become unavailable simultaneously. The objective of this paper is to present an improved approach to common cause failure modelling within reliability analyses. The currently used methods allow one component to share common characteristics with only one group of components, which may be affected by the same source of failure. Therefore, an improved method was developed, where components can be assigned to several groups of components that are susceptible to faulty operation with respect to their similar characteristics. A mathematical derivation of the method is presented and the theory is applied to smaller theoretical samples and to a simplified real example. The results show that the new method enables a more detailed reliability analysis. The results prove that consideration of common cause failures using the improved method may decrease the system reliability compared to traditional common cause failure consideration. The system reliability decreases more, if the redundant components have more similarities and are therefore assigned to several common cause failure groups.},
	language = {en},
	urldate = {2023-03-13},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {Rejc, Živa Bricman and Čepin, Marko},
	month = may,
	year = {2014},
	keywords = {Common cause failures, Multiple Greek Letter method, Reliability, Safety injection system},
	pages = {144--154},
}

@techreport{johanson_safety_1994,
	title = {Safety {Evaluation} by {Living} {Probabilistic} {Safety} {Assessment}},
	url = {https://inis.iaea.org/collection/NCLCollectionStore/_Public/28/043/28043550.pdf},
	institution = {Swedish Nuclear Power Inspec'orole},
	author = {Johanson, Gunnar and Holmberg, Jan},
	month = jan,
	year = {1994},
}

@book{european_commission_joint_research_centre_institute_for_energy_and_transport_analysis_2011,
	address = {LU},
	title = {Analysis of common cause failures coupling factors and mechanisms from ageing point of view},
	url = {https://data.europa.eu/doi/10.2790/25453},
	language = {en},
	urldate = {2023-03-13},
	publisher = {Publications Office},
	author = {{European Commission. Joint Research Centre. Institute for Energy and Transport}},
	year = {2011},
}

@techreport{knudsen_evaluation_2010,
	title = {Evaluation {Between} {Existing} and {Improved} {CCF} {Modeling} {Using} the {NRC} {SPAR} {Models}},
	url = {https://www.osti.gov/biblio/974768},
	abstract = {Abstract: The NRC SPAR models currently employ the alpha factor common cause failure (CCF) methodology and model CCF for a group of redundant components as a single “rolled-up” basic event. These SPAR models will be updated to employ a more computationally intensive and accurate approach by expanding the CCF basic events for all active components to include all terms that appear in the Basic Parameter Model (BPM). A discussion is provided to detail the differences between the rolled-up common cause group (CCG) and expanded BPM adjustment concepts based on differences in core damage frequency and individual component importance measures. Lastly, a hypothetical condition is evaluated with a SPAR model to show the difference in results between the current adjustment method (rolled-up CCF events) and the newer method employing all of the expanded terms in the BPM. The event evaluation on the SPAR model employing the expanded terms will be solved using the graphical evaluation module (GEM) and the proposed method discussed in Reference 1.},
	language = {English},
	number = {INL/CON-10-18011},
	urldate = {2023-03-13},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Knudsen, James K.},
	month = jun,
	year = {2010},
}

@article{mohammadhasani_multi-state_2021,
	title = {Multi-state {Risk}-{Based} {Maintenance} {Analysis} of {Redundant} {Safety} {Systems} {Using} the {Markov} {Model} and {Fault} {Tree} {Method}},
	volume = {9},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/articles/10.3389/fenrg.2021.685634},
	abstract = {The risk-based maintenance strategy has received special attention in the safe operation of nuclear power plants. Simultaneous quantification of the positive and negative effects of maintenance activities and components degradation effect makes it possible to accurately evaluate the risk criterion for safety systems of nuclear power plants. However, it is difficult to integrate the effects of maintenance and components degradation into the standard reliability approaches. A straightforward approach for considering components degradation and different maintenance policies is to make use of Markov maintenance models. In this article, the effectiveness of maintenance activities (including changes in the surveillance test intervals and alteration in the different maintenance policies) on the components unavailability with considering aging effects is quantified using Markov maintenance models and then by coupling these models and the fault tree method, the risk measure is upgraded from the component level to the system level. The proposed models are applied to evaluate the unavailability of two safety systems of VVER-1000/V446 nuclear power plants as case studies. The results show that the Markov method due to its multi-state nature is effective in the conservative evaluation of risk measures so that the unavailability computed by the coupling process is higher than the original unavailability (calculated by system fault tree using PSA data of nuclear power plants) for all maintenance policies. In addition, this study illustrates that the developed Markov maintenance models could be applied to the large-scale whole plant level and provides a proper transition from the classical PSA methods to new techniques. This approach integrates the effects of maintenance strategies and components degradation. Also, it provides a practical and a more accurate tool to determine the technical specification of a real nuclear power plant from the risk point of view.},
	urldate = {2023-03-13},
	journal = {Frontiers in Energy Research},
	author = {Mohammadhasani, F. and Pirouzmand, A.},
	year = {2021},
}

@article{pandey_statistical_nodate,
	title = {Statistical {Analysis} of {Common} {Cause} {Failure} {Data} to {Support} {Safety} and {Reliability} {Analysis} of {Nuclear} {Plant} {Systems}},
	abstract = {This report describes the findings of a project “Statistical Analysis of Common Cause Failure Data to Support Safety and Reliability Analysis of Nuclear Plant Systems for the CNSC” under the contract No. 87055-12-0221.},
	language = {en},
	author = {Pandey, Professor Mahesh},
}

@article{ric_us_nodate,
	title = {U.{S}. {NRC} {Operating} {Experience} {Data} – {Applications} in {Risk} {Modeling} {Operating} {Experience} {Data} to {Support} {Common} {Cause} {Failure} ({CCF}) {Modeling}},
	language = {en},
	author = {Ric, Nrc},
}

@article{zhang_rapid_2021,
	title = {A rapid modeling method and accuracy criteria for common-cause failures in {Risk} {Monitor} {PSA} model},
	volume = {53},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573320300760},
	doi = {10.1016/j.net.2020.06.021},
	abstract = {In the development of a Risk Monitor probabilistic safety assessment (PSA) model from the basic PSA model of a nuclear power plant, the modeling of common-cause failure (CCF) is very important. At present, some approximate modeling methods are widely used, but there lacks criterion of modeling accuracy and error analysis. In this paper, aiming at ensuring the accuracy of risk assessment and minimizing the Risk Monitor PSA models size, we present three basic issues of CCF model resulted from the changes of a nuclear power plant configuration, put forward corresponding modeling methods, and derive accuracy criteria of CCF modeling based on minimum cut sets and risk indicators according to the requirements of risk monitoring. Finally, a nuclear power plant Risk Monitor PSA model is taken as an example to demonstrate the effectiveness of the proposed modeling method and accuracy criteria, and the application scope of the idea of this paper is also discussed.},
	language = {en},
	number = {1},
	urldate = {2023-03-13},
	journal = {Nuclear Engineering and Technology},
	author = {Zhang, Bing and Chen, Shanqi and Lin, Zhixian and Wang, Shaoxuan and Wang, Zhen and Ge, Daochuan and Guo, Dingqing and Lin, Jian and Wang, Fang and Wang, Jin},
	month = jan,
	year = {2021},
	keywords = {Common-cause failure, Criteria for modeling accuracy, Nuclear power plant, Probabilistic safety assessment, Risk monitor},
	pages = {103--110},
}

@article{hassija_pragmatic_2014,
	title = {A pragmatic approach to estimate alpha factors for common cause failure analysis},
	volume = {63},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645491300409X},
	doi = {10.1016/j.anucene.2013.07.053},
	abstract = {Most of the modern technological systems are deployed with high redundancy but still they fail mainly on account of common cause failures (CCF). Various models such as Beta Factor, Multiple Greek Letter, Binomial Failure Rate and Alpha Factor exists for estimation of risk from common cause failures. Amongst all, alpha factor model is considered most suitable for high redundant systems as it arrives at common cause failure probabilities from a set of ratios of failures and the total component failure probability QT. In the present study, alpha factor model is applied for the assessment of CCF of safety systems deployed at two nuclear power plants. A method to overcome the difﬁculties in estimation of the coefﬁcients viz., alpha factors in the model, importance of deriving plant speciﬁc alpha factors and sensitivity of common cause contribution to the total system failure probability with respect to hazard imposed by various CCF events is highlighted. An approach described in NUREG/CR-5500 is extended in this study to provide more explicit guidance for a statistical approach to derive plant speciﬁc coefﬁcients for CCF analysis especially for high redundant systems. The procedure is expected to aid regulators for independent safety assessment.},
	language = {en},
	urldate = {2023-03-12},
	journal = {Annals of Nuclear Energy},
	author = {Hassija, Varun and Senthil Kumar, C. and Velusamy, K.},
	month = jan,
	year = {2014},
	pages = {317--325},
}

@techreport{agency_handbook_2010,
	type = {Text},
	title = {Handbook of {Parameter} {Values} for the {Prediction} of {Radionuclide} {Transfer} in {Terrestrial} and {Freshwater} {Environments}},
	url = {https://www.iaea.org/publications/8201/handbook-of-parameter-values-for-the-prediction-of-radionuclide-transfer-in-terrestrial-and-freshwater-environments},
	language = {en},
	urldate = {2023-03-10},
	institution = {International Atomic Energy Agency},
	author = {Agency, International Atomic Energy},
	year = {2010},
	note = {ISBN: 9789201130099
Publication Title: Handbook of Parameter Values for the Prediction of Radionuclide Transfer in Terrestrial and Freshwater Environments},
	pages = {1--194},
}

@techreport{agency_performance_2001,
	type = {Text},
	title = {Performance of {Engineered} {Barrier} {Materials} in {Near} {Surface} {Disposal} {Facilities} for {Radioactive} {Waste}},
	url = {https://www.iaea.org/publications/6297/performance-of-engineered-barrier-materials-in-near-surface-disposal-facilities-for-radioactive-waste},
	language = {en},
	urldate = {2023-03-10},
	institution = {International Atomic Energy Agency},
	author = {Agency, International Atomic Energy},
	year = {2001},
	note = {Publication Title: Performance of Engineered Barrier Materials in Near Surface Disposal Facilities for Radioactive Waste},
	pages = {1--56},
}

@techreport{travis_safety_1997,
	title = {A safety and regulatory assessment of generic {BWR} and {PWR} permanently shutdown nuclear power plants},
	url = {https://www.osti.gov/biblio/510336},
	abstract = {The long-term availability of less expensive power and the increasing plant modification and maintenance costs have caused some utilities to re-examine the economics of nuclear power. As a result, several utilities have opted to permanently shutdown their plants. Each licensee of these permanently shutdown (PSD) plants has submitted plant-specific exemption requests for those regulations that they believe are no longer applicable to their facility. This report presents a regulatory assessment for generic BWR and PWR plants that have permanently ceased operation in support of NRC rulemaking activities in this area. After the reactor vessel is defueled, the traditional accident sequences that dominate the operating plant risk are no longer applicable. The remaining source of public risk is associated with the accidents that involve the spent fuel. Previous studies have indicated that complete spent fuel pool drainage is an accident of potential concern. Certain combinations of spent fuel storage configurations and decay times, could cause freshly discharged fuel assemblies to self heat to a temperature where the self sustained oxidation of the zircaloy fuel cladding may cause cladding failure. This study has defined four spent fuel configurations which encompass all of the anticipated spent fuel characteristics and storage modes following permanent shutdown. A representative accident sequence was chosen for each configuration. Consequence analyses were performed using these sequences to estimate onsite and boundary doses, population doses and economic costs. A list of candidate regulations was identified from a screening of 10 CFR Parts 0 to 199. The continued applicability of each regulation was assessed within the context of each spent fuel storage configuration and the results of the consequence analyses.},
	language = {English},
	number = {NUREG/CR-6451; BNL-NUREG-52498},
	urldate = {2023-03-10},
	institution = {US Nuclear Regulatory Commission (NRC), Washington, DC (United States). Div. of Regulatory Applications; Brookhaven National Lab. (BNL), Upton, NY (United States)},
	author = {Travis, R. J. and Davis, R. E. and Grove, E. J. and Azarm, M. A.},
	month = aug,
	year = {1997},
	doi = {10.2172/510336},
}

@misc{noauthor_microreactors_nodate,
	title = {Microreactors},
	url = {https://inl.gov/trending-topic/microreactors/},
	abstract = {INL is working with developers, private industry, regulators, universities and others to develop, demonstrate, test and validate this new generation of microreactors.},
	language = {en-US},
	urldate = {2023-03-09},
	journal = {INL},
}

@article{lovering_historical_2016,
	title = {Historical construction costs of global nuclear power reactors},
	volume = {91},
	issn = {0301-4215},
	url = {https://www.sciencedirect.com/science/article/pii/S0301421516300106},
	doi = {10.1016/j.enpol.2016.01.011},
	abstract = {The existing literature on the construction costs of nuclear power reactors has focused almost exclusively on trends in construction costs in only two countries, the United States and France, and during two decades, the 1970s and 1980s. These analyses, Koomey and Hultman (2007); Grubler (2010), and Escobar-Rangel and Lévêque (2015), study only 26\% of reactors built globally between 1960 and 2010, providing an incomplete picture of the economic evolution of nuclear power construction. This study curates historical reactor-specific overnight construction cost (OCC) data that broaden the scope of study substantially, covering the full cost history for 349 reactors in the US, France, Canada, West Germany, Japan, India, and South Korea, encompassing 58\% of all reactors built globally. We find that trends in costs have varied significantly in magnitude and in structure by era, country, and experience. In contrast to the rapid cost escalation that characterized nuclear construction in the United States, we find evidence of much milder cost escalation in many countries, including absolute cost declines in some countries and specific eras. Our new findings suggest that there is no inherent cost escalation trend associated with nuclear technology.},
	language = {en},
	urldate = {2023-03-09},
	journal = {Energy Policy},
	author = {Lovering, Jessica R. and Yip, Arthur and Nordhaus, Ted},
	month = apr,
	year = {2016},
	keywords = {Experience curves, International comparison, Nuclear construction costs},
	pages = {371--382},
}

@misc{noauthor_nuclear_nodate,
	title = {Nuclear {Power} {Economics} {\textbar} {Nuclear} {Energy} {Costs} - {World} {Nuclear} {Association}},
	url = {https://world-nuclear.org/information-library/economic-aspects/economics-of-nuclear-power.aspx#:~:text=Nuclear%20power%20plants%20are%20more,built%20in%20about%20two%20years.},
	abstract = {Nuclear power is cost competitive with other forms of electricity generation. Nuclear fuel costs for nuclear plants are a minor proportion of total generating costs, though capital costs are greater.},
	urldate = {2023-03-09},
}

@misc{noauthor_climate_2022,
	type = {Text},
	title = {Climate {Change} and {Nuclear} {Power} 2022},
	url = {https://www.iaea.org/resources/brochure/climate-change-and-nuclear-power-2022},
	language = {en},
	urldate = {2023-03-06},
	month = sep,
	year = {2022},
}

@misc{noauthor_nuclear_2011,
	title = {Nuclear {Reactors}: {Generation} to {Generation}},
	shorttitle = {Nuclear {Reactors}},
	url = {https://www.amacad.org/publication/nuclear-reactors-generation-generation},
	abstract = {This report provides background on the cost, safety, and security attributes of the major nuclear reactor designs, as well as their properties with regard to refueling and fuel disposition requirements.},
	language = {en},
	urldate = {2023-03-06},
	journal = {American Academy of Arts \& Sciences},
	month = jan,
	year = {2011},
}

@misc{noauthor_frequently_nodate,
	title = {Frequently {Asked} {Questions} ({FAQs}) - {U}.{S}. {Energy} {Information} {Administration} ({EIA})},
	url = {https://www.eia.gov/tools/faqs/faq.php},
	urldate = {2023-03-06},
}

@misc{noauthor_us_nodate,
	title = {U.{S}. {Nuclear} {Plants}},
	url = {https://www.nei.org/resources/fact-sheets/u-s-nuclear-plants},
	abstract = {Across the United States, 92 nuclear reactors power tens of millions of homes and anchor local communities. Navigate national and state statistics for nuclear energy with the tabs along the top, and select your state to see how nuclear energy benefits your community.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Nuclear Energy Institute},
}

@misc{noauthor_9_nodate,
	title = {9 {Notable} {Facts} {About} the {World}’s {First} {Nuclear} {Power} {Plant} - {EBR}-{I}},
	url = {https://www.energy.gov/ne/articles/9-notable-facts-about-worlds-first-nuclear-power-plant-ebr-i},
	abstract = {How Experimental Breeder Reactor-I (EBR-I) pioneered nuclear development.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Energy.gov},
}

@misc{noauthor_guidance_nodate,
	title = {Guidance for {Performance}-{Based} {Regulation} ({NUREG}/{BR}-0303)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/brochures/br0303/index.html},
	language = {en-US},
	urldate = {2023-03-03},
	journal = {NRC Web},
}

@book{danielsson_preventive_1985,
	address = {International Atomic Energy Agency (IAEA)},
	title = {Preventive maintenance at the {Forsmark} {Nuclear} {Power} {Plant}},
	isbn = {9789200500855},
	abstract = {The maintenance system at the Forsmark Nuclear Power Plant began in 1975, and was
drawn up in co-operation with other power stations within the control of the Swedish
State Power Board Preventive maintenance (PM) is part of the system and has been in
operation since 1978 Great efforts have been made to build up the system and to gather
input data Since 1981, the system has been in continuous use; follow-ups and system
and quality improvements in database contents have been carried out Great effort has
also been devoted to maintaining a high quality of database contents and to the interplay
between the different PM measures We believe that PM plays an important role in the
safety and economic operation of the power station and that it is essential that interest
in PM should exist at all levels of the power company (author)},
	publisher = {IAEA},
	author = {Danielsson, H.},
	year = {1985},
	note = {INIS Reference Number: 17013315},
}

@article{purser_optimizing_1990,
	title = {Optimizing spare parts inventories using {RAM} techniques},
	url = {https://www.osti.gov/biblio/6011253},
	abstract = {The perfect spare parts inventory is one which always has the component required to prevent a facility outage. Ideally, such an inventory would contain exactly enough of each component to maintain the facility in operating condition until replacements for the spare parts arrive. Real spare parts inventories have typically been specified using a combination of engineering judgement and manufacturer's recommendations, as modified by budgetary constraints. The development of reliability, availability and maintainability (RAM) techniques provides additional tools through which spare parts inventories can more effectively be used to improve the safety and availability of a facility. This paper presents an analysis performed at the INEL using the techniques resident in a Reliability-Centered-Maintenance (RCM) program to prioritize components based on contribution to risk and to availability. The fill rate model or the confidence level approach could then be performed for those critical components resulting in an optimum stock level for the facility.},
	language = {English},
	urldate = {2023-03-03},
	author = {Purser, F. E. and Farmer, F. G.},
	month = jan,
	year = {1990},
}

@book{noauthor_nuclear_2022,
	address = {Vienna},
	series = {Reference {Data} {Series}},
	title = {Nuclear {Power} {Reactors} in the {World}},
	isbn = {978-92-0-125122-0},
	url = {https://www.iaea.org/publications/15211/nuclear-power-reactors-in-the-world},
	number = {2},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2022},
}

@book{noauthor_reliability_1975,
	address = {Vienna},
	series = {Proceedings {Series}},
	title = {Reliability of {Nuclear} {Power} {Plants} ({Innsbruck}, 14-18 {April} 1975)},
	isbn = {92-0-050075-7},
	url = {https://www.iaea.org/publications/3172/reliability-of-nuclear-power-plants-innsbruck-14-18-april-1975},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {1975},
}

@article{jax_advanced_1988,
	title = {Advanced techniques for the surveillance of light water reactors using microprocessor based systems},
	volume = {21},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/0149197088900297},
	doi = {10.1016/0149-1970(88)90029-7},
	abstract = {Monitoring systems are based on complex and high-technology methods and - in the past - needed the full skill of well-trained engineers. A new generation of microprocessor based systems is presented which improve the reliability and quality of the techniques and relieve the efforts and number of the staff needed. The systems are stand-alone systems with automatic routines of calibration, measurement and defined evaluation procedures, with an improved data storage of the relevant measuring parameters and with special analysis software, which can be used by interactive access of the experts. An overview of the monitoring systems of KWU is given and the principal features are explained on two examples.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Progress in Nuclear Energy},
	author = {Jax, P. and Ruthrof, K.},
	month = jan,
	year = {1988},
	pages = {137--146},
}

@article{berndt_power_2016,
	title = {Power to the people or regulatory ratcheting? {Explaining} the success (or failure) of attempts to site commercial {US} nuclear power plants: 1954-1996: {Power} to the people or regulatory ratcheting},
	volume = {40},
	issn = {0363907X},
	shorttitle = {Power to the people or regulatory ratcheting?},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/er.3475},
	doi = {10.1002/er.3475},
	language = {en},
	number = {7},
	urldate = {2023-03-03},
	journal = {International Journal of Energy Research},
	author = {Berndt, Eric and Aldrich, Daniel P.},
	month = jun,
	year = {2016},
	pages = {903--923},
}

@article{nelkin_evolution_1978,
	title = {The {Evolution} of the {Nuclear} {Debate}: {The} {Role} of {Public} {Participation}},
	volume = {3},
	issn = {0362-1626},
	shorttitle = {The {Evolution} of the {Nuclear} {Debate}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.eg.03.110178.001423},
	doi = {10.1146/annurev.eg.03.110178.001423},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Annual Review of Energy},
	author = {Nelkin, Dorothy and Fallows, Susan},
	month = nov,
	year = {1978},
	pages = {275--310},
}

@techreport{wilson_evaluation_1974,
	title = {Evaluation of nuclear power plant availability},
	url = {https://www.osti.gov/biblio/4341855},
	abstract = {A study was made of nuclear and fossil power plant operating experience to compare plant availability and to determine the cause and safety significance of plant outages for nuclear plants. The availability of the nuclear power plants is lower than the general design objective during the first one to three years of commercial service. Following this period of operation, however, average availability has approached or exceeded 80\%. The average availability of nuclear plants has been nearly the same as fossil plants of approximately the same size during the twelve year period 1960 to 1971. Approximately half of the forced outages of nuclear plants has resulted from events that are considered to have safety significance. In no case, however, was there any injury to a member of the public or a release of radioactive materials in excess of permissible levels. (auth)},
	language = {English},
	number = {WASH-1298},
	urldate = {2023-03-03},
	institution = {USAEC Office of Operations Evaluation, Washington, D.C.},
	author = {Wilson, T. R. and Gower, G. C.},
	month = jan,
	year = {1974},
	doi = {10.2172/4341855},
}

@techreport{griffith_us_2015,
	title = {U.{S}. {Forward} {Operating} {Base} {Applications} of {Nuclear} {Power}},
	url = {https://www.osti.gov/biblio/1184083},
	abstract = {This paper provides a high level overview of current nuclear power technology and the potential use of nuclear power at military bases. The size, power ranges, and applicability of nuclear power units for military base power are reviewed. Previous and current reactor projects are described to further define the potential for nuclear power for military power.},
	language = {English},
	number = {INL/EXT-15-34351},
	urldate = {2023-03-03},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Griffith, George W.},
	month = jan,
	year = {2015},
	doi = {10.2172/1184083},
}

@article{brooks_application_1984,
	title = {The application of availability analysis to nuclear power plants},
	volume = {9},
	issn = {0143-8174},
	url = {https://www.sciencedirect.com/science/article/pii/0143817484900362},
	doi = {10.1016/0143-8174(84)90036-2},
	abstract = {The use of probabilistic risk analysis (PRA) to assess the risks from nuclear power plants is now well established. Considerably less attention has been given so far to the use of availability analysis techniques. The economics of power generation are now such that with nuclear power currently supplying a substantial fraction of power in many countries, increasing attention is being paid to improving plant availability. This paper presents a technique for systematically identifying the areas in which measures to improve plant availability will be most effective.},
	language = {en},
	number = {3},
	urldate = {2023-03-03},
	journal = {Reliability Engineering},
	author = {Brooks, A. C.},
	month = jan,
	year = {1984},
	pages = {127--131},
}

@book{faulin_simulation_2010,
	address = {London},
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Simulation {Methods} for {Reliability} and {Availability} of {Complex} {Systems}},
	isbn = {9781848822122 9781848822139},
	url = {http://link.springer.com/10.1007/978-1-84882-213-9},
	urldate = {2023-03-03},
	publisher = {Springer London},
	editor = {Faulin, Javier and Juan, Angel A. and Martorell, Sebastián and Ramírez-Márquez, José-Emmanuel and Pham, Hoang},
	year = {2010},
	doi = {10.1007/978-1-84882-213-9},
}

@book{noauthor_handbook_2009,
	address = {London},
	title = {Handbook of {Reliability}, {Availability}, {Maintainability} and {Safety} in {Engineering} {Design}},
	isbn = {9781848001749 9781848001756},
	url = {http://link.springer.com/10.1007/978-1-84800-175-6},
	language = {en},
	urldate = {2023-03-03},
	publisher = {Springer London},
	year = {2009},
	doi = {10.1007/978-1-84800-175-6},
}

@techreport{garrick_reliability_1967,
	title = {Reliability {Analysis} {Of} {Nuclear} {Power} {Plant} {Protective} {Systems}.},
	url = {https://www.osti.gov/biblio/4568767},
	abstract = {Data and analytical requirements for a reliability monitoring program in nuclear safety have been identified. A data management system is defined incorporating a method for equipment and event classification and a plan for data collection. Equipment classification is accomplished by use of a 9-digit generic code which identifies equipment type, environment, and operating load. The event classification provides coded identification of failure mode, effect, and cause, as well as an index of accumulated experience. The data collection plan uses a two-step recording process to enable use of existing plant practices and operating staffs. The first step entails in-plant recording of failure or repair data and operating and test data. The second step requires transferral of operating and failure data to coded input for a centralized data bank. Subsequently, data bank processing will convert and report accumulating experience as failure rate and repair data. The accuracy and flexibility of the Automatic Reliability Mathematical Model (ARMM) technique has been increased for evaluation of the reliability of engineered safety systems. A computer program. Systems Analysis by Fault Tree Evaluation (SAFTE-1), has been developed to implement the fault tree concept. Applications of both techniques to sample problems using estimated or available reliability data demonstrate that they provide useful reliability estimates. Results of these applications show that the quality of these estimates is determined more by the analyst's skill than the limitations of the techniques. It is revealed that the questioning and documentation process required in preparation for quantitative reliability estimates is of value in identifying potential trouble spots and suggesting procedural or design changes which can eliminate or reduce the adverse effects of component failures on safety. It is concluded that reliability analysis can contribute to a more quantitative, systems-oriented measure of safety; techniques adequate for safety analysis of nuclear power plants now exist; the data necessary to support these analyses can be obtained through the suggested data management scheme; find the resulting reliability monitoring program can be executed without need for expanding nuclear power plant operating staffs. It is recommended that the reliability monitoring program be instituted in operating nuclear power plants at the earliest possible date to enable the accumulation of data of quality appropriate to reliability analysis of engineered safety systems.},
	language = {English},
	number = {HN-190},
	urldate = {2023-03-03},
	institution = {Holmes and Narver, Inc., Los Angeles, CA (United States)},
	author = {Garrick, B. J. and Gekler, W. C. and Goldfisher, L. and Karcher, R. H. and Shimizu, B. and Wilson, J. H.},
	month = may,
	year = {1967},
	doi = {10.2172/4568767},
}

@book{pham_recent_2008,
	address = {London},
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Recent {Advances} in {Reliability} and {Quality} in {Design}},
	isbn = {9781848001121 9781848001138},
	url = {http://link.springer.com/10.1007/978-1-84800-113-8},
	language = {en},
	urldate = {2023-03-03},
	publisher = {Springer London},
	editor = {Pham, Hoang},
	year = {2008},
	doi = {10.1007/978-1-84800-113-8},
}

@article{ruijters_rare_2019,
	title = {Rare event simulation for dynamic fault trees},
	volume = {186},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832018305313},
	doi = {10.1016/j.ress.2019.02.004},
	abstract = {Fault trees (FT) are a popular industrial method for reliability engineering, for which Monte Carlo simulation is an important technique to estimate common dependability metrics, such as the system reliability and availability. A severe drawback of Monte Carlo simulation is that the number of simulations required to obtain accurate estimations grows extremely large in the presence of rare events, i.e., events whose probability of occurrence is very low, which typically holds for failures in highly reliable systems. This paper presents a novel method for rare event simulation of dynamic fault trees with complex repairs that requires only a modest number of simulations, while retaining statistically justified confidence intervals. Our method exploits the importance sampling technique for rare event simulation, together with a compositional state space generation method for dynamic fault trees. We demonstrate our approach using three parameterized sets of case studies, showing that our method can handle fault trees that could not be evaluated with either existing analytical techniques using stochastic model checking, nor with standard simulation techniques.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Ruijters, Enno and Reijsbergen, Daniël and de Boer, Pieter-Tjerk and Stoelinga, Mariëlle},
	month = jun,
	year = {2019},
	keywords = {Dynamic fault trees, Fault tree analysis, Importance sampling, Monte Carlo simulation, Rare event simulation},
	pages = {220--231},
}

@techreport{garrick_power_1982,
	title = {Power plant availability engineering: methods of analysis, program planning, and applications. {Final} report},
	shorttitle = {Power plant availability engineering},
	url = {https://www.osti.gov/biblio/5346900},
	abstract = {Availability engineering has its roots primarily in reliability work that is associated with the defense, communications, and aerospace industries. With respect to power plant applications, nuclear power plant risk analysis is an example of a more recent, important contributor to the technology of reliability and availability. This is particularly true in the systems modeling and data handling areas. Of course, the growing interest in more formal availability improvement programs in the power field has resulted in the most important resource for the advancement of power plant availability engineering. The keystone to contemporary availability analysis and engineering is its usefulness in making good decisions about power plant design and operations. The advocated approach fits the framework of a decision model, whereby different options for design, operations, etc., can be compared in terms of availability performance, costs, and benefits. The important building block needed for availability analysis to fit in a decision model is the quantification of uncertainty. Probability is adopted as the language of uncertainty. The concept of probability proposed is based on a state-of-knowledge approach. Such an approach provides the flexibility to model a plant and its systems at any point of the design or operations and with any data base (limited or comprehensive). The figures of merit (failure frequency, outage times, availability, etc.) are presented as probability distributions, thus communicating one's full state of knowledge about the parameters under study. The modeling techniques, data handling procedures, and analytic methods all reflect a probabilistic viewpoint. Finally, numerous examples, based on real-world power plant reliability and availability problems, are presented to illustrate specific applications.},
	language = {English},
	number = {EPRI-NP-2168},
	urldate = {2023-03-03},
	institution = {Pickard-Lowe and Garrick, Inc., Irvine, CA (USA)},
	author = {Garrick, B. J. and Kaplan, S.},
	month = may,
	year = {1982},
	doi = {10.2172/5346900},
}

@techreport{keller_power_1978,
	title = {Power plant performance analysis and guidelines study. {Appendix} {II}. {Reliability} and efficiency indices},
	url = {https://www.osti.gov/biblio/5578402},
	abstract = {Four indices of power plant performance have been identified for use by the CERCDC in the technical evaluation of cost-effective levels of reliability and efficiency of future power plants, to be sited in the State of California. The selected indices are Capacity Factor, Operating Availability, Equivalent Availability, and Heat Rate. The write-up on each index includes a discussion on the Index Definition, Historical Data Availability/Sources and Recommendations for Application by the Commission.},
	language = {English},
	number = {DOE/RA/08137-T1(App.2)},
	urldate = {2023-03-03},
	institution = {System Development Corp., Santa Monica, CA (USA)},
	author = {Keller, R. W. and Bhatla, A. and Smith, M. J.},
	month = jun,
	year = {1978},
	doi = {10.2172/5578402},
}

@inproceedings{marija_performance_1992,
	title = {Performance of nuclear power plant or automated system depends on operator's availability},
	doi = {10.1109/HFPP.1992.283345},
	abstract = {The levels of operator cognitive and sensomotor availability are measured during normal nuclear plant operation at full power four times a day. The time distribution of the average production level is a system performance indicator. Mathematical models of the connection between system performance and human availability have been developed. The level of operator real availability depends on the work complexity. The effectiveness of rule- and skill-based behavior is determined by the level of sensomotor availability. The effectiveness of knowledge-based behavior is determined by the level of cognitive capacity. The mathematical model explains the impact of human availability and behavior on system performance. Organizational analysis determines possible organizational paths for increasing human availability in everyday operational situations.{\textless}{\textgreater}},
	booktitle = {Conference {Record} for 1992 {Fifth} {Conference} on {Human} {Factors} and {Power} {Plants}},
	author = {Marija, S.},
	month = jun,
	year = {1992},
	keywords = {Accidents, Automatic control, Availability, Control systems, Humans, Power generation, Power system modeling, Production systems, System performance, Traffic control},
	pages = {548--552},
}

@incollection{sheikh_reliability_2000,
	address = {Boston, MA},
	title = {Reliability {Based} {Spare} {Parts} {Forecasting} and {Procurement} {Strategies}},
	isbn = {9781461543299},
	url = {https://doi.org/10.1007/978-1-4615-4329-9_4},
	abstract = {Spare parts procurement strategies based on the maintenance engineering techniques of reliability engineering are merged with materials management discipline to provide a practical method to manage and control spare parts for industry. The well-known techniques of reliability engineering are used to determine failure rates for equipment and related parts. Then this information from the maintenance discipline is linked to the data of the materials management discipline. The results of this work will provide a scientific method of spare parts forecasting based on reliability of the parts, and more rational inventory management and procurement strategies with a minimum risk of stock out. As a consequence overstocking can be eliminated, and spare parts management can be streamlined on a rationale basis.},
	language = {en},
	urldate = {2023-03-03},
	booktitle = {Maintenance, {Modeling} and {Optimization}},
	publisher = {Springer US},
	author = {Sheikh, A. K. and Younas, M. and Raouf, A.},
	editor = {Ben-Daya, Mohamed and Duffuaa, Salih O. and Raouf, Abdul},
	year = {2000},
	doi = {10.1007/978-1-4615-4329-9_4},
	keywords = {Failure Rates, Inventory Management, Loss Matrix, Nonrepairable Parts, Ordering Strategies, Rational Inventory, Reliability, Renewal Analysis, Spare Parts},
	pages = {81--110},
}

@techreport{swain_handbook_1983,
	title = {Handbook of human-reliability analysis with emphasis on nuclear power plant applications. {Final} report},
	url = {https://www.osti.gov/biblio/5752058},
	abstract = {The primary purpose of the Handbook is to present methods, models, and estimated human error probabilities (HEPs) to enable qualified analysts to make quantitative or qualitative assessments of occurrences of human errors in nuclear power plants (NPPs) that affect the availability or operational reliability of engineered safety features and components. The Handbook is intended to provide much of the modeling and information necessary for the performance of human reliability analysis (HRA) as a part of probabilistic risk assessment (PRA) of NPPs. Although not a design guide, a second purpose of the Handbook is to enable the user to recognize error-likely equipment design, plant policies and practices, written procedures, and other human factors problems so that improvements can be considered. The Handbook provides the methodology to identify and quantify the potential for human error in NPP tasks.},
	language = {English},
	number = {NUREG/CR-1278; SAND-80-0200},
	urldate = {2023-03-03},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Swain, A. D. and Guttmann, H. E.},
	month = aug,
	year = {1983},
	doi = {10.2172/5752058},
}

@misc{edson_determination_1985,
	type = {Report},
	title = {Determination of the availability of core exit thermocouples during severe accident situations},
	url = {https://digital.library.unt.edu/ark:/67531/metadc1064474/},
	abstract = {This report presents the findings and recommendations of the Nuclear Power Plant Instrumentation Evaluation (NPPIE) program concerning signal validation methods to determine the on-line availability of core exit thermocouples during accident situations. Methods of selecting appropriate signal validation techniques are discussed and sources of error identified. This report shows that through the use of these techniques the existence of high-temperature-caused errors may be detected as they occur. Specific recommendations for application of selected signal validation techniques to core exit thermocouples and other measurement systems are made. 23 refs., 22 figs., 3 tabs.},
	language = {English},
	urldate = {2023-03-03},
	journal = {UNT Digital Library},
	author = {Edson, J. L.},
	month = apr,
	year = {1985},
	doi = {10.2172/5344731},
}

@article{volkanovski_extension_2013,
	title = {Extension of station blackout coping capability and implications on nuclear safety},
	volume = {255},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549312005195},
	doi = {10.1016/j.nucengdes.2012.09.031},
	abstract = {The safety of the nuclear power plant depends on the availability of the continuous and reliable sources of electrical energy during all modes of operation of the plant. The station blackout corresponds to a total loss of all alternate current (AC) power as a result of complete failure of both offsite and on-site AC power sources. The electricity for the essential systems during station blackout is provided from the batteries installed in the nuclear power plant. The results of the probabilistic safety assessment show that station blackout is one of the main and frequently the dominant contributor to the core damage frequency. The accident in Fukushima Daiichi nuclear power plants demonstrates the vulnerability of the currently operating nuclear power plants during the extended station blackout events. The objective of this paper is, considering the identified importance of the station blackout initiating event, to assess the implications of the strengthening of the SBO mitigation capability on safety of the NPP. The assessment is done with state-of-art deterministic and probabilistic methods and tolls with application on reference models of nuclear power plants. The U.S. NRC Station Blackout Rule describes procedure for the assessment of the size and capacity of the batteries in the nuclear power plant. The description of the procedure with the application on the reference plant and identified deficiencies in the procedure is presented. The safety analysis is done on reference model of the nuclear power plant. Obtained results show large decrease of the core damage frequency with strengthening of the station blackout mitigation capability. The time extension of blackout coping capability results in the delay of the core heat up for at least the extension time interval. Availability and operation of the steam driven auxiliary feedwater system maintains core integrity up to 72h after the successful shutdown, even in the presence of the reactor coolant pumps seal leakage. The largest weighted decrease of the core damage frequency considering the costs for the modification is obtained for the modification resulting in extension of the station blackout coping capability. The importance of the common cause failures of the emergency diesel generators for the obtained decrease of the core damage frequency and overall safety of the plant is identified in the obtained results. The results of the analysis support the latest recommendations and expected revisions to the corresponding regulatory requirement by the U.S. Regulatory Commission considering the station blackout mitigation capability.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Nuclear Engineering and Design},
	author = {Volkanovski, Andrija and Prošek, Andrej},
	month = feb,
	year = {2013},
	pages = {16--27},
}

@article{zare_exergoeconomic_2016,
	title = {Exergoeconomic analysis with reliability and availability considerations of a nuclear energy-based combined cycle power plant},
	volume = {96},
	issn = {0360-5442},
	url = {https://www.sciencedirect.com/science/article/pii/S0360544215017053},
	doi = {10.1016/j.energy.2015.12.060},
	abstract = {The reliability and availability considerations are introduced in the exergoeconomic investigation of a combined cycle power plant in which an organic Rankine cycle is employed to recover the waste heat from a GT-MHR (Gas Turbine Modular Helium Reactor) power plant. The SPECO (specific exergy costing) theory is employed to investigate the exergoeconomic performance of the system and assess the specific cost of the output power. For the reliability analysis, however, the SSM (state-space method) along with the probabilistic analysis of Markov processes is employed. After conducting a parametric analysis, the performance of the cycle is optimized with respect to the specific cost of output power, with and without reliability considerations. The effects of the system failure and repair rates are examined on the cost of power and availability of the combined cycle by the sensitivity analysis. The optimization results show that, the specific cost of output power for the combined cycle is around 12\% lower than that for the stand alone GT-MHR. However, availability of the combined cycle is lower than that of the GT-MHR as the former has more components and a complicated system.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Energy},
	author = {Zare, V.},
	month = feb,
	year = {2016},
	keywords = {Availability, Exergoeconomics, GT-MHR (Gas Turbine Modular Helium Reactor), Organic Rankine cycle, Reliability},
	pages = {187--196},
}

@article{bastl_influence_1985,
	series = {Fourth {Specialists} {Meeting} on {Reactor} {Noise}},
	title = {The influence of noise diagnostic techniques on the safety and availability of nuclear power plants},
	volume = {15},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/0149197085900770},
	doi = {10.1016/0149-1970(85)90077-0},
	abstract = {Diagnostic techniques based on vibration and noise analysis have been developed in FRG with the aim of incipient failure and malfunction detection in nuclear power plants. On the basis of the Vibration Monitoring System in the nuclear power station GKN, the measuring system, the diagnosis concept and the interpretation results will be discussed in more detail. In order to achieve full acceptance for these methods a completely understanding of signal sources, long-term trends and alert levels is necessary. Some newer results of successful interpretation of signature deviations are described. Discussion of the benefits shows that noise diagnostic techniques can increase the plant availability and improve the operational safety.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Progress in Nuclear Energy},
	author = {Bastl, W. and Sunder, R. and Wach, D.},
	month = jan,
	year = {1985},
	keywords = {PWR, core barrel integrity, fuel pin vibrations, long-term trends, mechanical vibrations, neutron noise, shaft vibrations, spectra interpretations, subcooled boiling, vibration monitoring system},
	pages = {513--524},
}

@book{kummel_second_2011,
	address = {New York, NY},
	series = {The {Frontiers} {Collection}},
	title = {The {Second} {Law} of {Economics}},
	isbn = {9781441993649 9781441993656},
	url = {http://link.springer.com/10.1007/978-1-4419-9365-6},
	urldate = {2023-03-03},
	publisher = {Springer New York},
	author = {Kümmel, Reiner},
	year = {2011},
	doi = {10.1007/978-1-4419-9365-6},
}

@article{patri_investigations_2017,
	title = {Investigations on the availability of second shutdown system of {Indian} {FBR}},
	volume = {319},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549317302285},
	doi = {10.1016/j.nucengdes.2017.05.004},
	abstract = {Design and operating nuclear power plants with higher capacity factors is always desirable for improved economics and it is further more important in case of fast breeder reactors. It is well recognised that the availability of shutdown systems has an important bearing on the plant availability. In this paper, various investigations carried out on the availability of the second shutdown of Indian FBR are reported. The stability of the system performance against a range of anticipated disturbances was studied. Studies were designed to gain better technical insight into the system performance and to aid in finding out the performance bounds. Based on the design review of second shutdown system, in-house and international experiences, investigations related to the electromagnetic coupling, flow induced vibrations, subassembly bowing and the deterioration of electromagnet parting plane were carried out as part of the current experimental programme. Various innovative methods/schemes were adopted in the studies. These investigations helped in identifying the design vulnerabilities and thus in improving the system design, qualifying respective analytical/numerical studies, providing direction for further enhancement in system performance, demonstrating the margins available in the system design and more importantly much needed insights into various phenomenons to attend any unforeseen availability related issues of second shutdown system during their operation in reactor. Alternative design concepts were also discussed.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Nuclear Engineering and Design},
	author = {Patri, Sudheer and Vijayashree, R. and Suresh Kumar, S. and Anup Kumar, P. and Sabih, Muhammad and Chandramouli, S. and Narayana Rao, P. and Meikandamurthy, C. and Prakash, V. and Selvaraj, P.},
	month = aug,
	year = {2017},
	keywords = {Availability of shutdown systems, Fast breeder reactor, Flow induced vibrations, PFBR, Shut down system},
	pages = {91--105},
}

@book{levitin_universal_2005,
	address = {London},
	series = {Springer series in reliability engineering},
	title = {The universal generating function in reliability analysis and optimization},
	isbn = {9781852339272},
	publisher = {Springer},
	author = {Levitin, Gregory},
	year = {2005},
	keywords = {Mathematical models, Reliability (Engineering)},
}

@book{lisnianski_multi-state_2010,
	address = {London},
	title = {Multi-state {System} {Reliability} {Analysis} and {Optimization} for {Engineers} and {Industrial} {Managers}},
	isbn = {9781849963190 9781849963206},
	url = {http://link.springer.com/10.1007/978-1-84996-320-6},
	language = {en},
	urldate = {2023-03-03},
	publisher = {Springer London},
	author = {Lisnianski, Anatoly and Frenkel, Ilia and Ding, Yi},
	year = {2010},
	doi = {10.1007/978-1-84996-320-6},
}

@book{fedele_methodologies_2011,
	address = {London},
	title = {Methodologies and {Techniques} for {Advanced} {Maintenance}},
	isbn = {9780857291028 9780857291035},
	url = {https://link.springer.com/10.1007/978-0-85729-103-5},
	language = {en},
	urldate = {2023-03-03},
	publisher = {Springer London},
	author = {Fedele, Lorenzo},
	year = {2011},
	doi = {10.1007/978-0-85729-103-5},
}

@techreport{paggen_limiting_1979,
	title = {Limiting factor analysis of high availability nuclear plants. {Final} report},
	url = {https://www.osti.gov/biblio/5688845},
	abstract = {Between January 1978 and February 1979, a study to identify operational, regulatory, maintenance, and design factors which limited plant performance was conducted at Turkey Point 3. This nuclear power plant, built by Bechtel Corporation and owned by Florida Power and Light, has a design rating of 696 MW(e) and incorporates a Westinghouse three-loop Nuclear Steam Supply System. The plant began commercial operation in December 1972. During the Limiting Factor study period, field engineers stationed at the plant investigated the cause for each significant power reduction and quantified its impact on energy generated. Each event was categorized into one of three classes; either administrative, regulatory, or design. Those events attributed to plant design were further analyzed to detail their impact on plant performance and to identify means to mitigate such limitations.},
	language = {English},
	number = {EPRI-NP-1139(Vol.1)},
	urldate = {2023-03-03},
	institution = {Combustion Engineering, Inc., Windsor, CT (United States); Bechtel Corp., San Francisco, CA (USA); Florida Power and Light Co., Miami (USA)},
	author = {Paggen, V. A. and Patterson, T. L. and James, D. K. and Reddaway, T. R.},
	month = aug,
	year = {1979},
	doi = {10.2172/5688845},
}

@techreport{van_siclen_microcomputer-based_1987,
	title = {Microcomputer-based probabilistic risk assessment for nuclear power plant safety studies},
	url = {https://www.osti.gov/biblio/5226258},
	abstract = {Probabilistic risk assessment (PRA) information in the analysis of safety issues pertaining to nuclear power plant systems has been underutilized in the past due to the large effort required to input the PRA data and to the large size of the computers needed to run PRA codes. The microcomputer-based Integrated Reliability and Risk Analysis System (IRRAS) and the System Analysis and Risk Assessment System (SARA), recently developed at the Idaho National Engineering Laboratory, have greatly enhanced the ability of nuclear power plant analysts to use PRA techniques in their decision-making and analysis of safety issues. IRRAS is a tool for modeling and analyzing systems reliability and risk that allows the analyst to create, modify, update, and reanalyze a plant PRA to keep the risk assessment current with the plant's configuration and operation. The PRA is created and edited using a graphical fault tree editor, which significantly enhances the speed and accuracy with which the PRA data can be manipulated. The SARA system, incorporating the PRA data input in IRRAS, is used to analyze safety issues in nuclear power plants. To simulate changes to plant systems, SARA users alter the failure rates of basic events of the plant system models. They then evaluate the significance of these changes through the calculation of the resultant core damage and accident sequence probabilities and importance measures. IRRAS and SARA demonstrate that reliability and risk analysis studies of nuclear power plants, as well as of any other complex systems such as chemical plants or the space shuttle, can be performed very effectively on microcomputers, providing powerful and flexible tools for the safety analyst.},
	language = {English},
	number = {EGG-M-05387; CONF-870669-3},
	urldate = {2023-03-03},
	institution = {EG and G Idaho, Inc., Idaho Falls (USA)},
	author = {Van Siclen, V. S. and Russell, K. D. and Sattison, M. B. and Stewart, H. D.},
	month = jan,
	year = {1987},
}

@techreport{saurwein_next_2011,
	title = {Next {Generation} {Nuclear} {Plant} ({NGNP}) {Prismatic} {HTGR} {Conceptual} {Design} {Project} - {Final} {Technical} {Report}},
	url = {https://www.osti.gov/biblio/1019034},
	abstract = {This report is the Final Technical Report for the Next Generation Nuclear Plant (NGNP) Prismatic HTGR Conceptual Design Project conducted by a team led by General Atomics under DOE Award DE-NE0000245. The primary overall objective of the project was to develop and document a conceptual design for the Steam Cycle Modular Helium Reactor (SC-MHR), which is the reactor concept proposed by General Atomics for the NGNP Demonstration Plant. The report summarizes the project activities over the entire funding period, compares the accomplishments with the goals and objectives of the project, and discusses the benefits of the work. The report provides complete listings of the products developed under the award and the key documents delivered to the DOE.},
	language = {English},
	number = {NGNP-B00259},
	urldate = {2023-03-03},
	institution = {General Atomics, San Diego, CA (United States)},
	author = {Saurwein, John},
	month = jul,
	year = {2011},
	doi = {10.2172/1019034},
}

@article{lisboa_nuclear_1990,
	title = {Nuclear power plant availability and the role of human factors performance},
	volume = {37},
	issn = {1558-1578},
	doi = {10.1109/23.106746},
	abstract = {A qualitative method of reducing human error by integrating human engineering principles into man-machine systems is presented. The application of these principles is achieved by integrated action of those involved in the design and in the performance of a system, e.g. plant designers, operators, and maintenance personnel. Improved system availability can be achieved by the implementation of a comprehensive set of human factors engineering principles, computer systems, and cathode-ray-tube (CRT) displays that optimize the interface between the operator and the process. Advanced control room design using these principles and analysis can provide compact operating panels with comprehensive displays and minimal operator distraction. A successful man-machine interaction can be achieved with the implementation of a special task group of human factors specialists, control room operators, computer engineers, and control room designers, facilitating the design.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Lisboa, J.J.},
	month = apr,
	year = {1990},
	keywords = {Application software, Availability, Computer displays, Computer interfaces, Ergonomics, Human factors, Man machine systems, Personnel, Power generation, Systems engineering and theory},
	pages = {980--986},
}

@techreport{primer_advanced_2020,
	title = {Advanced {Sensors} and {Instrumentation} ({ASI}) {Program} {Plan}. {Nuclear} {Energy} {Enabling} {Technologies} ({NEET})},
	url = {https://www.osti.gov/servlets/purl/1616179/},
	number = {INL/EXT--20-57280-Rev000, 1616179},
	urldate = {2023-03-03},
	author = {Primer, Craig and Calderoni, Pattrick and Agarwal, Vivek and Ramahaulli, Pradeep and Vilim, Rick},
	month = jan,
	year = {2020},
	doi = {10.2172/1616179},
	pages = {INL/EXT--20--57280--Rev000, 1616179},
}

@book{falk_safety_2013,
	address = {Stockholm},
	title = {Safety reviews of technical system modifications in the nuclear industry},
	isbn = {9789175016658},
	language = {eng},
	publisher = {Royal Institute of Technology},
	author = {Falk, Thomas},
	year = {2013},
	note = {OCLC: 870617939},
}

@book{taylor_designing_2014,
	address = {Hoboken, New Jersey},
	title = {Designing high availability systems: design for {Six} {Sigma} and classical reliability techniques with practical real-life examples},
	isbn = {9781118551127},
	shorttitle = {Designing high availability systems},
	publisher = {Wiley},
	author = {Taylor, Zachary and Ranganathan, Subramanyam},
	year = {2014},
	keywords = {Case studies, Reliability (Engineering), Six sigma (Quality control standard), Systems engineering},
}

@article{wright_determining_1989,
	title = {Determining system maintainability as a probability},
	volume = {24},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/0951832089900550},
	doi = {10.1016/0951-8320(89)90055-0},
	abstract = {Maintainability has often been defined in principle as the probability that a system or component can be repaired in a specific time given that it is in a failed state, but presented in practice in terms of mean-time-to-repair. In this paper formulas are developed for maintainability as a probability, analogous to those for reliability and availability. This formulation is expressed in terms of cut sets, and leads to a natural definition of unmaintainability importance for cut sets and basic events.},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Wright, R. E. and Atwood, C. L.},
	month = jan,
	year = {1989},
	pages = {69--76},
}

@article{lee_evaluation_2019,
	title = {Evaluation of availability of nuclear power plant dynamic systems using extended dynamic reliability graph with general gates ({DRGGG})},
	volume = {51},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573318303425},
	doi = {10.1016/j.net.2018.10.009},
	abstract = {To assess the availability of a nuclear power plant’s dynamic systems, it is necessary to consider the impact of dynamic interactions, such as components, software, and operating processes. However, there is currently no simple, easy-to-use tool for assessing the availability of these dynamic systems. The existing method, such as Markov chains, derives an accurate solution but has difficulty in modeling the system. When using conventional fault trees, the reliability of a system with dynamic characteristics cannot be evaluated accurately because the fault trees consider reliability of a specific operating configuration of the system. The dynamic reliability graph with general gates (DRGGG) allows an intuitive modeling similar to the actual system configuration, which can reduce the human errors that can occur during modeling of the target system. However, because the current DRGGG is able to evaluate the dynamic system in terms of only reliability without repair, a new evaluation method that can calculate the availability of the dynamic system with repair is proposed through this study. The proposed method extends the DRGGG by adding the repair condition to the dynamic gates. As a result of comparing the proposed method with Markov chains regarding a simple verification model, it is confirmed that the quantified value converges to the solution.},
	language = {en},
	number = {2},
	urldate = {2023-03-03},
	journal = {Nuclear Engineering and Technology},
	author = {Lee, Eun Chan and Shin, Seung Ki and Seong, Poong Hyun},
	month = apr,
	year = {2019},
	keywords = {Dynamic system availability, Extended dynamic gates, Reliability graph with general gates},
	pages = {444--452},
}

@techreport{long_proceedings_1978,
	title = {Proceedings: workshop on {EPRI} availability engineering},
	shorttitle = {Proceedings},
	url = {https://www.osti.gov/biblio/6700428},
	abstract = {The proceedings of the EPRI Availability Engineering Workshop, held in Albuquerque, New Mexico, October 17 to 19, 1977 are recorded. The workshop evolved out of an EPRI-sponsored, eight-month study by Holmes and Narver, Inc., titled, ''Assessment of Methods for Implementing Availability Engineering in Electric Power Plants,'' EPRI Report NP-493, May, 1977. Availability engineering methods, implementation, and experience are discussed.},
	language = {English},
	number = {EPRI-NP-759-WS; CONF-7710147-},
	urldate = {2023-03-03},
	institution = {Electric Power Research Inst. (EPRI), Palo Alto, CA (United States)},
	author = {Long, R. L. and Cleveland, E. B. and Stiehl, Jr},
	month = mar,
	year = {1978},
}

@book{au_engineering_2014,
	address = {Singapore},
	title = {Engineering risk assessment and design with subset simulation},
	isbn = {9781118398074 9781118398067},
	abstract = {"A unique book giving a comprehensive coverage of Subset Simulation - a robust tool for general applicationsThe book starts with the basic theory in uncertainty propagation using Monte Carlo methods and the generation of random variables and stochastic processes for some common distributions encountered in engineering applications. It then introduces a class of powerful simulation method called Markov Chain Monte Carlo method (MCMC), an important machinery behind Subset Simulation that allows one to generate samples for investigating rare scenarios in a probabilistically consistent manner. The theory of Subset Simulation is then presented, addressing related practical issues encountered in the actual implementation. A number of variants of Subset Simulation that can lead to improved performance for specific classes of problems will also be covered. The second half the book introduces the reader to probabilistic failure analysis and reliability-based design, which are laid out in a context that can be efficiently tackled within the context of Subset Simulation or Monte Carlo simulation in general. The result is a general framework that allows the practitioner to investigate reliability sensitivity to uncertain parameters and to explore possible design scenarios systematically for selection of the final design in a convenient but computationally efficient manner via simulation.A unique feature of this book is that it is complemented with a VBA (Visual Basic for Applications) that implements Subset Simulation in the Excel spreadsheet environment. This allows the reader to experiment with the examples in the book and get hands-on experience with simulation. A chapter is devoted to the software framework that allows a practical solution by resolving the risk assessment problem into three uncoupled procedures, namely, deterministic modeling, uncertainty modeling and uncertainty propagation. Presents a powerful simulation method called Subset Simulation for efficient engineering risk assessment and reliability-based design Illustrates application examples with MS Excel spreadsheets allowing readers to gain hands-on experience with simulation techniques Covers theoretical fundamentals as well as advanced implementation issues in practical engineering problems A companion website is available to include the developments of the software ideas "--},
	publisher = {Wiley},
	author = {Au, Siu-Kui and Wang, Yu},
	year = {2014},
	keywords = {Engineering design, Mathematics, Risk assessment, Set theory, TECHNOLOGY \& ENGINEERING / Mechanical},
}

@article{porthin_effects_2020,
	series = {{SI}:{HRA} {FOUNDATIONS} \& {FUTURE}},
	title = {Effects of digitalization of nuclear power plant control rooms on human reliability analysis – {A} review},
	volume = {194},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017311973},
	doi = {10.1016/j.ress.2019.03.022},
	abstract = {The changes in the operating conditions of the main control room of nuclear power plants due to new digitalized human-system interfaces (HSIs) pose challenges to traditional human reliability analysis (HRA) methods. This paper reviews current knowledge about the effect of digital HSI on human behavior and reliability, relevant performance shaping factor (PSF) taxonomies as well as research on the effect of PSFs on human error probability estimates in advanced control rooms (ACRs). It cannot be generally concluded that either analog or digitalized control rooms would be always better than the other. ACRs have the potential to offer error reducing and supportive features to the user, but may also introduce increased complexity and interface management tasks as well as potentially error-prone team working practices. Some effects seem universal, but most depend on the specific design. The main PSF categories presented in HRA methods and international guidelines seem still relevant in ACRs. Quantitative empirical studies show that especially training and experience, availability and quality of procedures as well as task type or complexity are important factors. However, digitalization changes the way in which the PSFs should be defined and measured, and the effects of PSFs on the error estimates may be different.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Porthin, Markus and Liinasuo, Marja and Kling, Terhi},
	month = feb,
	year = {2020},
	keywords = {Advanced control room, Digitalization, Human reliability analysis, Nuclear power plant, Performance shaping factor, Review},
	pages = {106415},
}

@article{faghih-roohi_dynamic_2014,
	title = {Dynamic availability assessment and optimal component design of multi-state weighted k-out-of-n systems},
	volume = {123},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832013002780},
	doi = {10.1016/j.ress.2013.10.002},
	abstract = {Availability/reliability is a main feature of design and operation of all engineering systems. Recently, availability evaluation of multi-state systems with different structures is at the center of attention due to the wide applications in engineering. In this paper, a dynamic model is developed for the availability assessment of multi-state weighted k-out-of-n systems. Then, in a design optimization problem, the availability and capacity for the components of such systems are optimized by genetic algorithm. In the dynamic model, the probabilities and capacities of components in different states are allowed to be changed over time. For availability assessment, universal generating function and Markov process are adopted. Application of the proposed model is illustrated using a real-world marine transportation system in order to evaluate and compare the presented optimization problems in assessing system availability.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Faghih-Roohi, Shahrzad and Xie, Min and Ng, Kien Ming and Yam, Richard C. M.},
	month = mar,
	year = {2014},
	keywords = {Availability assessment, Dynamic modeling, Multi-state system, Optimal design, Weighted k-out-of-n system},
	pages = {57--62},
}

@book{hart_constructability_1985,
	address = {International Atomic Energy Agency (IAEA)},
	title = {Constructability and maintainability},
	isbn = {9789200500855},
	abstract = {A set of principles for minimizing the construction schedule was established at the
outset of the CANDU 300 programme Consideration of these principles and other factors
led to the development of the unique CANDU 300 station layout The paper discusses
the CANDU 300 station layout and construction methods In summary, the station layout
provides 360 deg construction access to all buildings, separation of nuclear and non-nuclear
systems, precise and minimal physical interfaces between buildings, accommodation
of many contractors and construction activities without interference, and maximum
flexibility in terms of constructional, financial and supply arrangements The CANDU
300 further employs modularization, shop fabrication and advanced instrumentation
(multiplexers, remote processors, data highways) to minimize construction time Many
of the CANDU 300 features that enhance constructability also contribute to maintainability
These include the 360 deg access to all principal buildings, the uncluttered and spacious
building layouts, the simplification of systems and the high level of modularization
The CANDU 300 has also been designed to facilitate the replacement of all key components,
thereby offering an essentially unlimited station life A prime example is a reduction
in the fuel channel inlet end-fitting diameter such that the fuel channels can be
shop assembled and easily replaced after the initial 40 years of operation, without
an extended unit outage Maintainability within the reactor building has been given
particular attention in the CANDU 300 design; key features of other CANDU reactors
(the ability to replace a heat transport system pump motor at power, for example)
have been incorporated, while accessibility and maintainability of all systems and
components have been enhanced These and other aspects of maintainability are discussed
(author)},
	publisher = {IAEA},
	author = {Hart, R.S.},
	year = {1985},
	note = {INIS Reference Number: 17013411},
}

@book{international_atomic_energy_agency_nuclear_1985,
	address = {Vienna : New York, NY},
	series = {Proceedings series},
	title = {Nuclear power plant availability, maintenance, and operation: proceedings of an {International} {Symposium} on {Advances} in {Nuclear} {Power} {Plant} {Availability}, {Maintainability}, and {Operation}},
	isbn = {9789200500855},
	shorttitle = {Nuclear power plant availability, maintenance, and operation},
	language = {engfrerus},
	publisher = {The Agency ; Sales agent, Unipub},
	editor = {{International Atomic Energy Agency}},
	year = {1985},
	keywords = {Maintainability Congresses, Nuclear power plants, Reliability Congresses},
}

@article{hart_candu_1988,
	title = {{CANDU} 300: {The} economic small reactor},
	volume = {109},
	issn = {0029-5493},
	shorttitle = {{CANDU} 300},
	url = {https://www.sciencedirect.com/science/article/pii/0029549388901409},
	doi = {10.1016/0029-5493(88)90140-9},
	abstract = {The CANDU nuclear power system has evolved in a carefully planned and systematic manner over the past 40 years. Thirty-one CANDU power stations are now in commercial operation, or under construction, world wide. Changes in the demands of the world power market, and growing interest in smaller nuclear units led AECL to develop the CANDU 300, which has a net electrical output in the range of 450 MW. AECL initiated design work on the CANDU 300 in 1982. The substantial effort devoted to this program over the past five years has produced a “small” CANDU power station that is economically competitive with both large nuclear and coal fired generating stations. The CANDU 300 makes substantial advances in the areas of station layout, constructability, maintainability, and operability and plant life extension capability while utilizing proven systems, components and concepts. All key components, including steam generators, pressure tubes, fuelling machine, fuel, and coolant pumps are essentially identical to those in service in the very successful CANDU 600 stations. This paper provides an overview of the CANDU 300 with emphasis on factors impacting economics and performance.},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Nuclear Engineering and Design},
	author = {Hart, R. S.},
	month = sep,
	year = {1988},
	pages = {47--53},
}

@book{levitin_computational_2007,
	address = {Berlin},
	series = {Studies in computational intelligence},
	title = {Computational intelligence in reliability engineering: new metaheuristics, neural anf fuzzy techniques in reliability},
	isbn = {9783540373711},
	shorttitle = {Computational intelligence in reliability engineering},
	language = {eng},
	number = {volume 40},
	publisher = {Springer},
	author = {Levitin, Gregory},
	year = {2007},
}

@article{sanzharova_changes_1994,
	title = {Changes in the forms of {137Cs} and its availability for plants as dependent on properties of fallout after the {Chernobyl} nuclear power plant accident},
	volume = {154},
	issn = {0048-9697},
	url = {https://www.sciencedirect.com/science/article/pii/0048969794906092},
	doi = {10.1016/0048-9697(94)90609-2},
	abstract = {The dynamics of exchangeable and acid soluble 137Cs content in soils, as well as 137Cs transfer factors for natural vegetation were studied for different sites within a 50-km zone around the Chernobyl nuclear power plant after the 1986 accident. Changes in 137Cs forms in soils during the 6 years after the accidental release of radioactive substances and availability of this radionuclide to plants at that time were dependent on the character of radioactive fallout (fuel particles, aerosols of different dispersion) and soil type. Transformation of different 137Cs species in soils with time after the accident was observed (destruction of fuel particles, ageing of 137Cs and changes in the 137Cs sorption strength of the soil solid phase). Behaviour of 137Cs in the ‘near’ and ‘remote’ zones was different. The content of exchangeable 137Cs in soils was found to have decreased after the accident. The average half-life of 137Cs in grass stand in dry meadow in the ‘remote’ zone is 3.5 years, and in the second (slower) period after the accident, this half-life for 137Cs will amount to about 17 years. The 137Cs transfer factors for peaty swamped soils were 3.7–6.6 times as high as for soils of automorphous series.},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Science of The Total Environment},
	author = {Sanzharova, N. I. and Fesenko, S. V. and Alexakhin, R. M. and Anisimov, V. S. and Kuznetsov, V. K. and Chernyayeva, L. G.},
	month = sep,
	year = {1994},
	keywords = {Availability, Chernobyl NPP, Ecological half line, Forms in soil, Radionuclide, Transfer factor},
	pages = {9--22},
}

@article{pariaman_availability_nodate,
	title = {Availability {Improvement} {Methodology} in {Thermal} {Power} {Plant}},
	url = {https://core.ac.uk/display/295718899?utm_source=pdf&utm_medium=banner&utm_campaign=pdf-decoration-v1},
	abstract = {Availability of a complex system of thermal power plant is strongly influenced by maintenance program and component reliability. Various maintenance techniques, likes RCM (reliability-centred maintenance), RBM (risk based maintenance) and CBM (condition-based maintenance), have been applied to improve the availability. Implementation of RCM, RBM, CBM alone or combined RCM and RBM or RCM and CBM is a maintenance technique used in thermal power plants. This study develops an new maintenance methodology integrating RCM, RBM and CBM  to increase the availability of thermal plants.  The method generates MPI (Priority Maintenance Index) and FDT (Failure Defense Task). MPI is used to determine the priority of components in maintenance program. FDT consists of the tasks of monitoring and assessment of conditions other than maintenance tasks. Both MPI and FDT obtained from development of functional tree, failure mode effects analysis, fault-tree analysis, and risk analysis (risk assessment and risk evaluation) were then used to develop and implement a plan and schedule maintenance, monitoring and assessment of the condition and ultimately perform availability analysis. The results of this study indicate that the reliability, risks and conditions-based maintenance methods, in an integrated manner can increase the availability of thermal power plant},
	urldate = {2023-03-03},
	author = {Pariaman, Henry and Garniwa, Iwa and Surjandari, Isti and Sugiarto, Bambang},
}

@article{khatab_availability_2014,
	title = {Availability optimisation for stochastic degrading systems under imperfect preventive maintenance},
	volume = {52},
	issn = {0020-7543, 1366-588X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207543.2013.835499},
	doi = {10.1080/00207543.2013.835499},
	language = {en},
	number = {14},
	urldate = {2023-03-03},
	journal = {International Journal of Production Research},
	author = {Khatab, A. and Ait-Kadi, D. and Rezg, N.},
	month = jul,
	year = {2014},
	pages = {4132--4141},
}

@article{ma_applications_2011,
	title = {Applications of fault detection and diagnosis methods in nuclear power plants: {A} review},
	volume = {53},
	issn = {01491970},
	shorttitle = {Applications of fault detection and diagnosis methods in nuclear power plants},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197010001769},
	doi = {10.1016/j.pnucene.2010.12.001},
	language = {en},
	number = {3},
	urldate = {2023-03-03},
	journal = {Progress in Nuclear Energy},
	author = {Ma, Jianping and Jiang, Jin},
	month = apr,
	year = {2011},
	pages = {255--266},
}

@inproceedings{wodka_applications_2013,
	address = {Boston, Massachusetts, USA},
	title = {Applications and {Benefits} of {RAM}},
	isbn = {9780791856062},
	url = {https://asmedigitalcollection.asme.org/POWER/proceedings/POWER2013/56062/Boston,%20Massachusetts,%20USA/282183},
	doi = {10.1115/POWER2013-98251},
	abstract = {This is a follow up article from last year’s ICONE/POWER Conference in Anaheim discussing the development of the new standard for ASME Codes and Standards Committee for the Reliability, Availability, and Maintainability (RAM) of Power Plants. The standard focuses on the priorities of safety, production, and efficiency, with the objective to create an availability program. This program defines an operating budget that supports an effective maintenance program, which in turn ensures the life span of the reliable equipment. The intent is to establish an industry recognized standard for RAM. Some general concepts of the new standard are presented here.},
	urldate = {2023-03-03},
	booktitle = {Volume 2: {Reliability}, {Availability} and {Maintainability} ({RAM}); {Plant} {Systems}, {Structures}, {Components} and {Materials} {Issues}; {Simple} and {Combined} {Cycles}; {Advanced} {Energy} {Systems} and {Renewables} ({Wind}, {Solar} and {Geothermal}); {Energy} {Water} {Nexus}; {Thermal} {Hydraulics} and {CFD}; {Nuclear} {Plant} {Design}, {Licensing} and {Construction}; {Performance} {Testing} and {Performance} {Test} {Codes}},
	publisher = {American Society of Mechanical Engineers},
	author = {Wodka, Brian M.},
	month = jul,
	year = {2013},
	pages = {V002T06A004},
}

@inproceedings{hui_analysis_2014,
	address = {Prague, Czech Republic},
	title = {Analysis of the {Availability} of {In}-{Vessel} {Retention} of {Molten} {Core} {Debris} {Strategy} for {AP1000}},
	isbn = {9780791845950},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE22/45950/Prague,%20Czech%20Republic/251715},
	doi = {10.1115/ICONE22-31185},
	abstract = {The availability of IVR (In-vessel Retention of Molten Core Debris) strategy at severe reactor accident depend upon the capacity of ERVC (External Reactor Vessel Cooling), i.e. the CHF (Critical Heat Flux) of the external reactor vessel should be higher than the related location heat flux. In this paper, an analysis model of CHF on the downward facing curved surface for pool boiling has been proposed, which adopts the Helmholtz instability analysis of vapor-liquid interface of the vapor jets which penetrating in the thin liquid film underneath the elongated bubble adhering to the lower head outer surface. When the heat flux closing to the CHF point, the vapor-liquid interface becomes highly distorted which resulted in obvious vapor blanket, it will block liquid to feed the thin liquid film underneath the vapor blanket from the bulk region. As a result, the thin liquid film will dry out gradually. As a consequence, the CHF occurs. Based upon this model, spatial variation of CHF about the downward facing curved surface in different subcooling are obtained, and the safety margin of IVR strategy for AP1000 increase with the increase of the subcooling. However, the IVR strategy may be invalid by comparing the CHF with the related local heat flux under the condition of saturated.},
	urldate = {2023-03-03},
	booktitle = {Volume 5: {Innovative} {Nuclear} {Power} {Plant} {Design} and {New} {Technology} {Application}; {Student} {Paper} {Competition}},
	publisher = {American Society of Mechanical Engineers},
	author = {Hui, He and Pan, Liang-ming},
	month = jul,
	year = {2014},
	pages = {V005T17A066},
}

@article{brouwers_analytical_1987,
	title = {Analytical system availability techniques},
	volume = {17},
	issn = {0143-8174},
	url = {https://www.sciencedirect.com/science/article/pii/0143817487900813},
	doi = {10.1016/0143-8174(87)90081-3},
	abstract = {Analytical techniques are presented to assess the probability distributions and related statistical parameters of loss of production from equipment networks subject to random failures and repairs. The techniques are based on a theoretical model for system availability, which was further developed into a microcomputer model for the analysis of complex systems. The techniques are illustrated by the analysis of the early design of an offshore field development.},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Reliability Engineering},
	author = {Brouwers, J. J. H. and Verbeek, P. H. J. and Thomson, W. R.},
	month = jan,
	year = {1987},
	pages = {9--22},
}

@misc{heddleson_summary_1978,
	type = {Report},
	title = {Summary data for {U}. {S}. commercial nuclear power plants in the {United} {States}},
	url = {https://digital.library.unt.edu/ark:/67531/metadc1054414/},
	abstract = {A compilation of data is presented for all United States commercial nuclear power plants for which a construction permit application was made through the Nuclear Regulatory Commission. The data are compiled in four separate tables with cross-referencing indexes: Table 1--General Data; Table 2--Reactor Data; Table 3--Site Data, and Table 4--Circulating-Water System Data. The power plants are listed in numerical order by docket number in all four tables.},
	language = {English},
	urldate = {2023-03-03},
	journal = {UNT Digital Library},
	author = {Heddleson, F. A.},
	month = mar,
	year = {1978},
	doi = {10.2172/5062376},
}

@article{penttinen_open_2019,
	title = {An open modelling approach for availability and reliability of systems},
	volume = {183},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832018307634},
	doi = {10.1016/j.ress.2018.11.026},
	abstract = {This paper introduces an Open Modelling approach for Availability and Reliability of Systems (OpenMARS), which is developed for risk and performance assessment of large and complex systems with dynamic behaviours. The approach allows for combining the most common risk assessment and operation modelling techniques. This ensures a high degree of freedom for the modeller to accurately describe the system without limitations imposed by an individual technique. OpenMARS uses a platform-independent tabular format to define the used modelling technique, to create the model structure, and to assign the parameter values. We developed the format to enable a straightforward manual model definition while maintaining database compatibility. This paper also presents our calculation engine for stochastic simulation-based analysis of OpenMARS models. Our intention is to use this approach as a basis for new software. We demonstrate the feasibility of OpenMARS with an example of a multi-state production process that is subject to failures. The example creates a comprehensive system model by combining interconnected failure logic, operation phase, and production function models. We believe that the advanced features of OpenMARS have wide ranging applications for analysis of reliability, performance, and energy efficiency of complex industrial processes.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Penttinen, Jussi-Pekka and Niemi, Arto and Gutleber, Johannes and Koskinen, Kari T. and Coatanéa, Eric and Laitinen, Jouko},
	month = mar,
	year = {2019},
	keywords = {Complex systems, Dynamic modelling, Fault tree analysis, Model data format, Risk assessment technique, System performance},
	pages = {387--399},
}

@book{khamis_advances_2012,
	address = {Vienna},
	title = {Advances in nuclear power process heat applications},
	abstract = {"Following an IAEA coordinated research project, this publication compiles the findings of research and development activities related to practical nuclear process heat applications. An overview of current progress on high temperature gas cooled reactors coupling schemes for different process heat applications, such as hydrogen production and desalination, is included. The associated safety aspects are also highlighted. The summary report documents the results and conclusions of the project."--Provided by publisher},
	language = {eng},
	publisher = {International Atomic Energy Agency},
	author = {Khamis, I.},
	year = {2012},
	note = {OCLC: 822977164},
}

@article{hartman_acoustic_1977,
	title = {Acoustic emission surveillance for improving availability of nuclear power plants},
	volume = {1},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0149197077901172},
	doi = {10.1016/0149-1970(77)90117-2},
	language = {en},
	number = {2-4},
	urldate = {2023-03-03},
	journal = {Progress in Nuclear Energy},
	author = {Hartman, William F. and McElroy, John W.},
	month = jan,
	year = {1977},
	pages = {673--680},
}

@article{chang_application_1983,
	title = {Application of {Availability} {Analysis} {Techniques} to {Improve} {Power} {Plant} {Productivity}},
	volume = {PER-3},
	issn = {0272-1724},
	url = {http://ieeexplore.ieee.org/document/5519016/},
	doi = {10.1109/MPER.1983.5519016},
	number = {6},
	urldate = {2023-03-03},
	journal = {IEEE Power Engineering Review},
	author = {Chang, N. E.},
	month = jun,
	year = {1983},
	pages = {28--28},
}

@book{rykov_mathematical_2010,
	address = {New York},
	series = {Statistics for industry and technology},
	title = {Mathematical and statistical models and methods in reliability: applications to medicine, finance, and quality control},
	isbn = {978-0-8176-4970-8},
	shorttitle = {Mathematical and statistical models and methods in reliability},
	publisher = {Birkhäuser},
	editor = {Rykov, V. V. and Balakrishnan, N. and Nikulin, M. S.},
	year = {2010},
	note = {Meeting Name: International Conference on Mathematical Methods in Reliability: Theory, Methods, Applications},
	keywords = {Congresses, Mathematical models, Reliability (Engineering), Statistical methods},
}

@book{khatri_advanced_2011,
	address = {New York},
	title = {Advanced techniques in logic synthesis, optimizations and applications},
	isbn = {978-1-4419-7517-1 978-1-4419-7518-8},
	publisher = {Springer},
	editor = {Khatri, Sunil P. and Gulati, Kanupriya},
	year = {2011},
	note = {OCLC: ocn662410246},
	keywords = {Computer-aided design, Data processing, Logic circuits, Logic design},
}

@misc{noauthor_dod_nodate,
	title = {{DoD} to {Build} {Project} {Pele} {Mobile} {Microreactor} and {Perform} {Demonstration} at {Idaho} {National}},
	url = {https://www.defense.gov/News/Releases/Release/Article/2998460/dod-to-build-project-pele-mobile-microreactor-and-perform-demonstration-at-idah/https%3A%2F%2Fwww.defense.gov%2FNews%2FReleases%2FRelease%2FArticle%2F2998460%2Fdod-to-build-project-pele-mobile-microreactor-and-perform-demonstration-at-idah%2F},
	abstract = {The Department of Defense's Strategic Capabilities Office released a Record of Decision for Project Pele, a program intended to design, build and demonstrate a mobile microreactor.},
	language = {en-US},
	urldate = {2023-03-02},
	journal = {U.S. Department of Defense},
}

@article{united_states_department_of_transportation_bureau_of_transportation_statistics_national_2019,
	title = {National {Transportation} {Statistics} ({NTS})},
	url = {https://tinyurl.com/rosapntlbtsNTS},
	doi = {10.21949/1503663},
	language = {en},
	urldate = {2023-02-27},
	author = {United States. Department of Transportation. Bureau of Transportation Statistics},
	year = {2019},
	note = {Publisher: Not Available},
}

@article{street_audrey_nodate,
	title = {{AUDREY} {STRAUSS} {Acting} {United} {States} {Attorney} for the {Southern} {District} of {New} {York} {By}: {ROBERT} {WILLIAM} {YALEN} {DOMINIKA} {TARCZYNSKA} {JENNIFER} {A}. {JUDE}},
	language = {en},
	author = {Street, Chambers},
}

@article{united_states_department_of_transportation_bureau_of_transportation_statistics_national_2019-1,
	title = {National {Transportation} {Statistics} ({NTS})},
	url = {https://tinyurl.com/rosapntlbtsNTS},
	doi = {10.21949/1503663},
	language = {en},
	urldate = {2023-02-25},
	author = {United States. Department of Transportation. Bureau of Transportation Statistics},
	year = {2019},
	note = {Publisher: Not Available},
}

@article{mohan_application_2020,
	title = {Application of {Bayesian} {Networks} in {Multi}-{Hazard} {Safety} {Assessment} of {Nuclear} {Power} {Plants}},
	url = {https://ui.adsabs.harvard.edu/abs/2020EGUGA..2221036M},
	doi = {10.5194/egusphere-egu2020-21036},
	abstract = {Low probability events occurring in sequence, within a limited operational time (damage and recovery window between events), are a key consideration in multi-hazard safety assessments of nuclear power plants (NPPs). Cascading effects from hazards and associated event sequences could potentially have a significant impact on risk estimates. The Bayesian network can act as a framework to consider aforementioned statistical dependencies between various hazards in multi-risk analyses of nuclear power plants.Within the EU project NARSIS (New Approach to Reactor Safety Improvements), a Bayesian network-based risk assessment framework was developed to perform multi-hazard risk assessment of NPPs.The Bayesian network method was applied for an external-event related station blackout (SBO) scenario at a NPP. Earthquake, flooding, and tornado were among the hazards considered at a decommissioned NPP site location in Europe. Both hazard dependency in time as well as a cascading scenario was also considered. The hazards, their interactions and the fragilities of selected systems, structures and components within the nuclear power plant were represented in the network and their probability distributions were obtained based on the multi-hazard and fragility approaches adopted within the NARSIS project.Sensitivity analyses in the network were used to identify key hazards and interactions. Most influential hazard combinations and ranges of intensity measures were identified through diagnostic inference in the network. Discretisation of continuous variables (hazard curves in this case) is a key aspect of performing inference in Bayesian networks. The effect of various levels of discretisation of hazard probability distributions was assessed, to identify suitable discretisations of hazard data.This application demonstrates the use and advantages of the Bayesian network methodology, developed in the NARSIS project, for probabilistic safety assessments of NPPs.},
	urldate = {2023-02-25},
	author = {Mohan, Varenya Kumar D. and Vardon, Philip and Daniell, James and Gehl, Pierre and Schafer, Andreas and van Gelder, Pieter and Natarajan, Venkat and Molenaar, Cor and Foerster, Evelyne and Ragon, Florence},
	month = may,
	year = {2020},
	note = {Conference Name: EGU General Assembly Conference Abstracts
ADS Bibcode: 2020EGUGA..2221036M},
	pages = {21036},
}

@article{choi_review_2021,
	title = {A review of multihazard risk assessment: {Progress}, potential, and challenges in the application to nuclear power plants},
	volume = {53},
	issn = {2212-4209},
	shorttitle = {A review of multihazard risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S2212420920314357},
	doi = {10.1016/j.ijdrr.2020.101933},
	abstract = {The risk of natural hazards is continuously increasing because of climate change and the ever-increasing population density. Therefore, understanding and mitigating the risks of natural hazards have become an essential task for critical infrastructure systems (CISs). Particularly, nuclear power plants (NPPs) exposed to multihazards, which are combinations of more than two natural hazards, can lead to severe outcomes. For example, the Fukushima NPP was damaged because of the Great East Japan earthquake and tsunami (2011) and is still at its recovery stage. Therefore, considering the significant consequences of these multihazards, it is essential to understand the phenomena and their effects on structure systems in a quantitative and probabilistic manner. However, compared with single hazard phenomena, concurrent and successive multihazards have not been relatively extensively studied because of their inherent complexity and limited availability of data. In this paper, we review multihazards in terms of the types of disaster combinations based on analysis level such as hazard, fragility, and risk assessment. Furthermore, state-of-the-art models have been reviewed and the progress, potential, and challenges in the application of multihazard risk research to NPPs are discussed.},
	language = {en},
	urldate = {2023-02-25},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Choi, Eujeong and Ha, Jeong-Gon and Hahm, Deagi and Kim, Min Kyu},
	month = feb,
	year = {2021},
	keywords = {Concurrent hazard, Multihazard, Natural hazards, Nuclear power plant, Risk assessment, Successive hazard},
	pages = {101933},
}

@misc{noauthor_3_nodate,
	title = {(3) ({PDF}) {The} {LOBO} {Nuclear} {CyberSecurity} {Platform}},
	url = {https://www.researchgate.net/publication/363084351_The_LOBO_Nuclear_CyberSecurity_Platform},
	urldate = {2023-02-24},
}

@article{fleming_systematic_nodate,
	title = {A {SYSTEMATIC} {PROCEDURE} {FOR} {THE} {INCORPORATION} {OF} {COMMON} {CAUSE} {EVENTS} {INTO} {RISK} {AND} {RELIABILITY} {MODELS}},
	language = {en},
	author = {Fleming, Karl N and Mosleh, Ali and Deremer, R Kenneth},
}

@article{thieme_incorporating_2020,
	title = {Incorporating software failure in risk analysis––{Part} 2: {Risk} modeling process and case study},
	volume = {198},
	issn = {09518320},
	shorttitle = {Incorporating software failure in risk analysis––{Part} 2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018307178},
	doi = {10.1016/j.ress.2020.106804},
	abstract = {The advent of autonomous cars, drones, and ships, the complexity of these systems is increasing, challenging risk analysis and risk mitigation, since the incorporation of software failures intro traditional risk analysis currently is difficult. Current methods that attempt software risk analysis, consider the interaction with hardware and software only superficially. These methods are often inconsistent regarding the level of analysis and cover often only selected software failures.},
	language = {en},
	urldate = {2023-02-24},
	journal = {Reliability Engineering \& System Safety},
	author = {Thieme, Christoph A. and Mosleh, Ali and Utne, Ingrid B. and Hegde, Jeevith},
	month = jun,
	year = {2020},
	pages = {106804},
}

@article{thieme_incorporating_2020-1,
	title = {Incorporating software failure in risk analysis – {Part} 1: {Software} functional failure mode classification},
	volume = {197},
	issn = {09518320},
	shorttitle = {Incorporating software failure in risk analysis – {Part} 1},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018307166},
	doi = {10.1016/j.ress.2020.106803},
	abstract = {Advanced technological systems consist of a combination of hardware and software, and they are often operated or supervised by a human operator. Failures in software-intensive systems may be difficult to identify, analyze, and mitigate, owing to system complexity, system interactions, and cascading effects. Risk analysis of such systems is necessary to ensure safe operation.},
	language = {en},
	urldate = {2023-02-24},
	journal = {Reliability Engineering \& System Safety},
	author = {Thieme, Christoph A. and Mosleh, Ali and Utne, Ingrid B. and Hegde, Jeevith},
	month = may,
	year = {2020},
	pages = {106803},
}

@misc{noauthor_risk_nodate,
	title = {Risk {Assessment}  {Chapter} 15  {Common} {Cause} {Failures}},
	language = {en},
}

@article{oconnor_extending_nodate,
	title = {Extending the {Alpha} {Factor} {Model} for {Cause} {Based} {Treatment} of {Common} {Cause} {Failure} {Events} in {PRA} and {Event} {Assessment}},
	abstract = {Common Cause Failure modeling for Probability Safety Assessments has become standard practice in many industries. Of the numerous models proposed to include common cause, one of the most widely adopted has been the Alpha Factor Model, which is supported by the US Nuclear Regulatory Commission CCF database and software tools.},
	language = {en},
	author = {O’Connor, Andrew and Mosleh, Ali},
}

@misc{noauthor_seismic_nodate,
	title = {Seismic {Fragility} and {Seismic} {Margin} {Guidance} for {Seismic} {Probabilistic} {Risk} {Assessments}},
	url = {https://www.epri.com/research/products/TR-103959},
	urldate = {2023-02-23},
}

@article{necci_accident_2014,
	title = {Accident scenarios triggered by lightning strike on atmospheric storage tanks},
	volume = {127},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832014000428},
	doi = {10.1016/j.ress.2014.02.005},
	abstract = {Severe Natech accidents may be triggered by lightning strike affecting storage tanks containing relevant inventories of hazardous materials. The present study focused on the identiﬁcation of event sequences and accident scenarios following lightning impact on atmospheric tanks. Reference event trees, validated using past accident analysis, are provided to describe the speciﬁc accident chains identiﬁed, accounting for reference protection and mitigation safety barriers usually adopted in current industrial practice. An overall methodology was outlined to allow the calculation of the expected frequencies of ﬁnal scenarios following lightning impact on atmospheric storage tanks, taking into account the expected performance of available safety barriers. The methodology was applied to a case study in order to better understand the data that may be obtained and their importance in the framework of quantitative risk assessment (QRA) and of the risk management of industrial facilities with respect to external hazards due to natural events.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Necci, Amos and Argenti, Francesca and Landucci, Gabriele and Cozzani, Valerio},
	month = jul,
	year = {2014},
	pages = {30--46},
}

@article{brown_how_2011,
	title = {How {Probabilistic} {Risk} {Assessment} {Can} {Mislead} {Terrorism} {Risk} {Analysts}},
	volume = {31},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.2010.01492.x},
	doi = {10.1111/j.1539-6924.2010.01492.x},
	abstract = {Traditional probabilistic risk assessment (PRA), of the type originally developed for engineered systems, is still proposed for terrorism risk analysis. We show that such PRA applications are unjustified in general. The capacity of terrorists to seek and use information and to actively research different attack options before deciding what to do raises unique features of terrorism risk assessment that are not adequately addressed by conventional PRA for natural and engineered systems—in part because decisions based on such PRA estimates do not adequately hedge against the different probabilities that attackers may eventually act upon. These probabilities may differ from the defender's (even if the defender's experts are thoroughly trained, well calibrated, unbiased probability assessors) because they may be conditioned on different information. We illustrate the fundamental differences between PRA and terrorism risk analysis, and suggest use of robust decision analysis for risk management when attackers may know more about some attack options than we do.},
	language = {en},
	number = {2},
	urldate = {2023-02-23},
	journal = {Risk Analysis},
	author = {Brown, Gerald G. and Cox, Jr., Louis Anthony (Tony)},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2010.01492.x},
	keywords = {Decision analysis, expert elicitation, terrorism risk analysis},
	pages = {196--204},
}

@article{karanki_dynamic_2015,
	title = {A dynamic event tree informed approach to probabilistic accident sequence modeling: {Dynamics} and variabilities in medium {LOCA}},
	volume = {142},
	issn = {09518320},
	shorttitle = {A dynamic event tree informed approach to probabilistic accident sequence modeling},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015001234},
	doi = {10.1016/j.ress.2015.04.011},
	abstract = {In Probability Safety Assessments, accident scenario dynamics are addressed in the accident sequence analysis task. In an analyst-driven, iterative process, assumptions are made about equipment responses and operator actions and simulations of the scenario evolution are performed. To calculate how scenario dynamics and stochastic variabilities may affect the results of this process in terms of estimated risk, this work applies Dynamic Event Trees (DETs) to more comprehensively examine the accident scenario space. Alternative event tree models are developed and the core damage frequency is quantiﬁed to reveal the effects of different delineations of the sequences and of the bounding assumptions underlying success criteria. The results from a case study on Medium-break Loss of Coolant Accident scenarios in a Pressurized Water Reactor are presented, considering the break size, available injection trains, and the timing of rapid cooldown and the switchover to recirculation. The results show not only that estimated risk can be very sensitive to the numerous assumptions made in current accident sequence analysis but also that bounding assumptions do not always result in conservative risk estimates, thereby conﬁrming the beneﬁts that DETs provide in terms of characterizing scenario dynamics.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Karanki, Durga Rao and Kim, Tae-Wan and Dang, Vinh N.},
	month = oct,
	year = {2015},
	pages = {78--91},
}

@article{nozhati_understanding_2019,
	title = {Understanding {Community} {Resilience} from a {PRA} {Perspective} {Using} {Binary} {Decision} {Diagrams}},
	volume = {39},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/risa.13321},
	doi = {10.1111/risa.13321},
	abstract = {Probabilistic risk assessment (PRA) is a useful tool to assess complex interconnected systems. This article leverages the capabilities of PRA tools developed for industrial and nuclear risk analysis in community resilience evaluations by modeling the food security of a community in terms of its built environment as an integrated system. To this end, we model the performance of Gilroy, CA, a moderate-size town, with regard to disruptions in its food supply caused by a severe earthquake. The food retailers of Gilroy, along with the electrical power network, water network elements, and bridges are considered as components of a system. Fault and event trees are constructed to model the requirements for continuous food supply to community residents and are analyzed efficiently using binary decision diagrams (BDDs). The study also identifies shortcomings in approximate classical system analysis methods in assessing community resilience. Importance factors are utilized to rank the importance of various factors to the overall risk of food insecurity. Finally, the study considers the impact of various sources of uncertainties in the hazard modeling and performance of infrastructure on food security measures. The methodology can be applicable for any existing critical infrastructure system and has potential extensions to other hazards.},
	language = {en},
	number = {10},
	urldate = {2023-02-23},
	journal = {Risk Analysis},
	author = {Nozhati, Saeed and Ellingwood, Bruce R. and Mahmoud, Hussam},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/risa.13321},
	keywords = {Binary decision diagram, community resilience, event trees, fault trees, food security},
	pages = {2127--2142},
}

@misc{analysis_mbsa-tudopenerrorpro_2022,
	title = {mbsa-tud/{OpenErrorPro}},
	copyright = {GPL-3.0},
	url = {https://github.com/mbsa-tud/OpenErrorPro},
	abstract = {Stochastic Error Propagation Analysis},
	urldate = {2023-02-20},
	author = {Analysis, Model-based System},
	month = jul,
	year = {2022},
	note = {original-date: 2018-04-05T16:17:06Z},
}

@misc{noauthor_operating_nodate,
	title = {Operating {Experience} {Results} and {Databases}},
	url = {https://nrcoe.inl.gov/ccf_pe/},
	language = {en},
	urldate = {2023-02-17},
	journal = {NRC Web},
}

@techreport{mosleh_guidelines_1998,
	address = {College Park, MD},
	title = {Guidelines on {Modeling} {Common}-{Cause} {Failures} in {PRA}},
	url = {https://nrcoe.inl.gov/publicdocs/CCF/NUREGCR-5485_Guidelines%20on%20Modeling%20Common-Cause%20Failures%20in%20PRA.pdf},
	abstract = {This report provides a set of guidelines to help probabilistic risk assessment (PRA) analysts in modeling common cause failure (CCF) events in commercial nuclear power plants. The aim is to enable the analyst to identify important common cause vulnerabilities, incorporate their impact into system reliability models, perform data analysis, and quantify system unavailability in the presence of CCFs. Much of the material in this report has been presented in previous reports issued by United States Nuclear Regulatory Commission (NRC). The present document brings together the key aspects of these procedural guidelines supplemented by additional insights gained from their application, and enhanced by the capabilities of the CCF software and its data analysis capabilities, recently developed by the NRC.},
	number = {NUREG/CR-5485},
	institution = {NRC},
	author = {Mosleh, Ali and Rasmussen, DM and Marshall, FM},
	year = {1998},
	pages = {212},
}

@techreport{noauthor_protecting_2009,
	address = {Vienna, Austria},
	type = {Technical {Report}},
	title = {Protecting against {Common} {Cause} {Failures} in {Digital} {I}\&{C} {Systems} of {Nuclear} {Power} {Plants}},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/Pub1410_web.pdf},
	language = {English},
	urldate = {2023-02-17},
	institution = {IAEA},
	year = {2009},
}

@inproceedings{arndt_digital_2010,
	address = {Xi’an, China},
	title = {Digital {Instrumentation} and {Control} {Systems} {Upgrades} in {Current} {Generation} {Nuclear} {Power} {Plants}},
	isbn = {978-0-7918-4929-3},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE18/49293/903/347335},
	doi = {10.1115/ICONE18-30358},
	abstract = {Over the past 20 years, the nuclear power industry in the United States (U.S.) has been slowly replacing old, obsolete, and difficult-to-maintain analog technology for its nuclear power plant protection, control, and instrumentation systems with digital systems. The advantages of digital technology, including more accurate and stable measurements and the ability to improve diagnostics capability and system reliability, have led to an ever increasing move to complete these upgrades. Because of the difficulties with establishing digital systems safety based on analysis or tests, the safety demonstration for these systems relies heavily on establishing the quality of the design and development of the hardware and software. In the United States, the U.S. Nuclear Regulatory Commission (NRC) has established detailed guidelines for establishing and documenting an appropriate safety demonstration for digital systems in NUREG-0800, “Standard Review Plan for the Review of Safety Analysis Reports for Nuclear Power Plants: LWR Edition,” Chapter 7, “Instrumentation and Controls,” Revision 5, issued March 2007 [1], and in a number of regulatory guides and interim staff guidance documents. However, despite the fact that the United States has a welldefined review process, a number of significant challenges associated with the design, licensing, and implementation of upgrades to digital systems for U.S. plants have emerged. Among these challenges have been problems with the quality of the systems and the supporting software verification and validation (V\&V) processes, challenges with determining the optimum balance between the enhanced capabilities for the new systems and the desire to maintain system simplicity, challenges with cyber security, and challenges with developing the information needed to support the review of new systems for regulatory compliance.},
	language = {en},
	urldate = {2023-02-17},
	booktitle = {18th {International} {Conference} on {Nuclear} {Engineering}: {Volume} 1},
	publisher = {ASMEDC},
	author = {Arndt, Steven A.},
	month = jan,
	year = {2010},
	pages = {903--910},
}

@book{pinto_models_2016,
	title = {Models for the {Reliability} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} for {Nuclear} {Power} {Plants}},
	isbn = {978-953-51-2671-3},
	url = {https://www.intechopen.com/chapters/51936},
	abstract = {The objective of this chapter is to discuss two approaches for reliability analysis of digital instrumentation and control systems in nuclear power plants taking into account the regulatory side. Dynamic Flowgraph Methodology (DFM) and Markov/Cell-to-Cell Mapping Technique (CCMT) are discussed and case studies developed are presented. These case studies involve simplified control systems for a steam generator and a pressurizer of a Pressurized Water Reactor (PWR) plant for the purpose of evaluating each method. Advantages and limitations of each approach are addressed. For the DFM approach, three concerns in the literature are addressed: modeling of the system itself, incorporation of the methodology results into existing Probabilistic Safety Assessments (PSA), and identification of software failures. The Markov/CCMT, which has been used in dynamic probabilistic safety assessments, is approached by means of a simplified digitally controlled water volume control system. The Markov/CCMT methodology results in detailed data of the system reliability behavior in relation to time. However, it demands a higher computational effort than usual as the complexity (i.e., number of components and failure states) of the system increases. As a regulatory research conclusion, the methodologies presented can be used on PSA risk informed assessment, contributing to the regulatory side.},
	language = {en},
	urldate = {2023-02-17},
	publisher = {IntechOpen},
	author = {Pinto, Jonathan M. O. and Gomes, Ian B. and Saldanha, Pedro L. C. and Furieri, Eustério B. and Melo, Paulo F. F. e and Pinto, Jonathan M. O. and Gomes, Ian B. and Saldanha, Pedro L. C. and Furieri, Eustério B. and Melo, Paulo F. F. e},
	month = oct,
	year = {2016},
	doi = {10.5772/64649},
	note = {Publication Title: Automation and Control Trends},
}

@incollection{pinto_models_2016-1,
	title = {Models for the {Reliability} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} for {Nuclear} {Power} {Plants}},
	isbn = {978-953-51-2670-6},
	abstract = {The objective of this chapter is to discuss two approaches for reliability analysis of digital instrumentation and control systems in nuclear power plants taking into account the regulatory side. Dynamic Flowgraph Methodology (DFM) and Markov/Cell-to-Cell Mapping Technique (CCMT) are discussed and case studies developed are presented. These case studies involve simplified control systems for a steam generator and a pressurizer of a Pressurized Water Reactor (PWR) plant for the purpose of evaluating each method. Advantages and limitations of each approach are addressed. For the DFM approach, three concerns in the literature are addressed: modeling of the system itself, incorporation of the methodology results into existing Probabilistic Safety Assessments (PSA), and identification of software failures. The Markov/CCMT, which has been used in dynamic probabilistic safety assessments, is approached by means of a simplified digitally controlled water volume control system. The Markov/CCMT methodology results in detailed data of the system reliability behavior in relation to time. However, it demands a higher computational effort than usual as the complexity (i.e., number of components and failure states) of the system increases. As a regulatory research conclusion, the methodologies presented can be used on PSA risk informed assessment, contributing to the regulatory side.},
	author = {Pinto, J.M.O. and Gomes, Ian and Saldanha, Pedro and Furieri, Eustério and Melo, Paulo},
	month = oct,
	year = {2016},
	doi = {10.5772/64649},
}

@misc{noauthor_light_nodate,
	title = {{LIGHT} {WATER} {REACTOR} {SUSTAINABILITY} {PROGRAM} - {Integrated} {Risk} {Assessment} for {Digital} {Instrumentation} and {Control}},
	url = {https://lwrs.inl.gov/SitePages/Integrated%20Risk%20Assessment%20for%20Digital%20Instrumentation%20and%20Control.aspx},
	urldate = {2023-02-17},
}

@techreport{noauthor_instrumentation_2008,
	title = {Instrumentation and {Control} ({I}\&{C}) {Systems} in {Nuclear} {Power} {Plants}: {A} {Time} of {Transition}},
	url = {https://www.iaea.org/sites/default/files/gc/gc52inf-3-att5_en.pdf},
	abstract = {Progress in electronics and information technology (IT) has created incentives to replace traditional analog instrumentation and control (I\&C) systems in nuclear power plants with digital I\&C systems, i.e. systems based on computers and microprocessors. Digital systems offer higher reliability, better plant performance and additional diagnostic capabilities. Analog systems will gradually become obsolete in the general IT shift to digital technology. About 40\% of the world’s operating reactors have been modernized to include at least some digital I\&C systems. Most newer plants also include digital I\&C systems.},
	number = {NTR2008 Supplement},
	urldate = {2023-02-17},
	institution = {IAEA},
	year = {2008},
}

@article{kumagai_pra-based_2007,
	title = {{PRA}-based {SMA}: {The} first tool toward a risk-informed approach to the seismic design of the {IRIS}},
	volume = {44},
	shorttitle = {{PRA}-based {SMA}},
	url = {https://www.osti.gov/etdeweb/biblio/20993612},
	doi = {10.1080/18811248.2007.9711370},
	abstract = {International Reactor Innovative and Secure (IRIS) is an advanced, modular, medium-power PWR with an integral primary system layout. As part of the 'safety-by-design\{sup TM\}' philosophy that inspired the project from the very beginning, a risk-informed approach to its design phase is being adopted and a probabilistic risk assessment (PRA) is being used as an active tool in pursuing an advanced level of safety. Within this framework, a preliminary PRA-based seismic margin assessment (SMA) has been conducted to assess the ability of the IRIS standard design to respond to seismic events. A high confidence of low probability of failure at the core damage sequence level and then at the entire plant level is the primary result of the SMA model; in the end, it will have to ensure that IRIS can withstand the review-level earthquake of 0.5 g which is consistent with the upper bin level of the NUREG/CR-4334. In this preliminary phase of its development, in which the core of the quantitative data is critically extracted from the SMA of other PWR designs, the IRIS SMA model can be seen as a first step toward the development of an extensive seismic PRA model. (author)},
	language = {English},
	urldate = {2023-02-17},
	journal = {Journal of Nuclear Science and Technology (Tokyo)},
	author = {Kumagai, Yuji and Ninokata, Hisashi and Maioli, Andrea and Carelli, Mario D. and Ricotti, Marco E.},
	month = oct,
	year = {2007},
}

@article{heising_risk_1987,
	title = {Risk assessment: {Controlling} hazardous materials},
	volume = {15},
	issn = {03043894},
	shorttitle = {Risk assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304389487870322},
	doi = {10.1016/0304-3894(87)87032-2},
	abstract = {Recent events such as the Bhopal chemical plant accident in India and the Chernobyl nuclear plant accident in the Soviet Union have demonstrated that technologies have the potential to release hazardous materials to the environment with catastrophic consequences. This paper discusses probabilistic risk assessment (PRA) , and suggests that this methodology can be useful in the regulatory arena. This conclusion is based both on previous experience (e.g. the Reactor Safety Study) and growing interest in the methodology from many different sectors, including regulatory agencies such as EPA, NASA, OSHA, and NRC, the military, in addition to the private sector, such as insurance companies. Since human error is a major contributor to accident risk in large technologies, this paper also discusses at some length how such error may be quantified in risk assessments, as well as how risk may be reduced through improved management practices. Finally, regulatory developments in this area, and future directions for change, are also highlighted.},
	language = {en},
	number = {1-2},
	urldate = {2023-02-16},
	journal = {Journal of Hazardous Materials},
	author = {Heising, Carolyn D.},
	month = jan,
	year = {1987},
	pages = {123--135},
}

@article{misra_use_1990,
	title = {Use of fuzzy set theory for level-{I} studies in probabilistic risk assessment},
	volume = {37},
	issn = {01650114},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0165011490900388},
	doi = {10.1016/0165-0114(90)90038-8},
	abstract = {At a post-Chernobyl conference on Probabilistic Safety Assessment and Risk management (PSA '87) held in September 1987, the inadequacies of the current Probabilistic Risk Assessment (PSA) came into sharp focus. Highlighting the importance of improvements in the current PSA, Professor Rasmussen - a pioneer in the PSA methodology - made a strong plea for reduction of rather large uncertainties in the results of current PSA. Obviously, amongst the ways to achieve this, one of the approaches would be to encourage collection and use of accurate failure data. However as the state of affairs is, a better alternative would be to develop a methodology which could handle imprecision of data and uncertainties of models which are existence in the current PSA.},
	language = {en},
	number = {2},
	urldate = {2023-02-16},
	journal = {Fuzzy Sets and Systems},
	author = {Misra, Krishna B. and Weber, Gunter G.},
	month = sep,
	year = {1990},
	pages = {139--160},
}

@article{jardine_risk_1989,
	title = {Risk assessment and optimization of a safety system using the maros simulation package},
	volume = {5},
	issn = {1099-1638},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qre.4680050207},
	doi = {10.1002/qre.4680050207},
	abstract = {The performance of a pressure-surge relief system which acts as a safety mechanism within the export facility of an oil terminal is analysed in detail. Dynamic simulation methods are integrated with failure mode effects analysis to establish the risk of catastrophic failure of the terminal. An optimization procedure is presented which demonstrates the use of simulation to establish suitable inspection, testing and preventive maintenance schedules which maximize the effectiveness of the surge relief system over its design life. The importance of such activities is evident — left unattended the surge-relief system will not meet minimum safety standards, whereas planned maintenance and testing is shown to improve safety standards above the minimum required.},
	language = {en},
	number = {2},
	urldate = {2023-02-16},
	journal = {Quality and Reliability Engineering International},
	author = {Jardine, I. J. A. and Jackson, D.},
	year = {1989},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qre.4680050207},
	keywords = {Dynamic simulation, Oil-terminal safety, Risk analysis},
	pages = {131--141},
}

@inproceedings{noauthor_instrumentation_2008-1,
	title = {Instrumentation and {Control} ({I}\&{C}) {Systems} in {Nuclear} {Power} {Plants}: {A} {Time} of {Transition} - {NTR2008} {Supplement}},
	shorttitle = {Instrumentation and {Control} ({I}\&{C}) {Systems} in {Nuclear} {Power} {Plants}},
	url = {https://www.semanticscholar.org/paper/Instrumentation-and-Control-(I%26C)-Systems-in-Power/758c39aceb5148ad7146037d6ad5356ded820cf0},
	abstract = {Progress in electronics and information technology (IT) has created incentives to replace traditional analog instrumentation and control (I\&C) systems in nuclear power plants with digital I\&C systems, i.e. systems based on computers and microprocessors. Digital systems offer higher reliability, better plant performance and additional diagnostic capabilities. Analog systems will gradually become obsolete in the general IT shift to digital technology. About 40\% of the world’s operating reactors have been modernized to include at least some digital I\&C systems. Most newer plants also include digital I\&C systems.},
	urldate = {2023-02-16},
	year = {2008},
}

@misc{noauthor_instrumentation_2017,
	type = {Text},
	title = {Instrumentation and {Control} {Systems} for {Nuclear} {Power} {Plants}},
	url = {https://www.iaea.org/topics/operation-and-maintenance/instrumentation-and-control-systems-for-nuclear-power-plants},
	abstract = {A nuclear power plant (NPP) contains thousands of components and equipment, such as motors, pumps or valves that have to be operated in a well-coordinated way. This coordination is performed by instrumentation and control (I\&C) systems. These systems allow plant personnel to monitor the status of the NPP more effectively, identify opportunities for improved performance of equipment and systems, and anticipate, understand and respond to potential problems. Essentially, the purpose of I\&C systems in NPPs is to enable and support safe and reliable power generation through controlling the plant processes.},
	language = {en},
	urldate = {2023-02-16},
	month = jan,
	year = {2017},
	note = {Publisher: IAEA},
}

@incollection{ponce_models_2016,
	title = {Models for the {Reliability} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} for {Nuclear} {Power} {Plants}},
	isbn = {978-953-51-2670-6 978-953-51-2671-3},
	url = {http://www.intechopen.com/books/automation-and-control-trends/models-for-the-reliability-analysis-of-digital-instrumentation-and-control-systems-for-nuclear-power},
	language = {en},
	urldate = {2023-02-15},
	booktitle = {Automation and {Control} {Trends}},
	publisher = {InTech},
	author = {Pinto, Jonathan M.O. and Gomes, Ian B. and Saldanha, Pedro L.C. and Furieri, Eustério B. and Melo, Paulo F.F.},
	editor = {Ponce, Pedro and Gutierrez, Arturo Molina and Ibarra, Luis M.},
	month = oct,
	year = {2016},
	doi = {10.5772/64649},
}

@article{bao_quantitative_2023,
	title = {Quantitative evaluation of common cause failures in high safety-significant safety-related digital instrumentation and control systems in nuclear power plants},
	volume = {230},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832022005889},
	doi = {10.1016/j.ress.2022.108973},
	abstract = {Digital instrumentation and control (DI\&C) systems at nuclear power plants (NPPs) have many advantages over analog systems. They are proven to be more reliable, cheaper, and easier to maintain given obsolescence of analog components. However, they also pose new engineering and technical challenges, such as possibility of common cause failures (CCFs) unique to digital systems. This paper proposes a Platform for Risk Assessment of DI\&C (PRADIC) that is developed by Idaho National Laboratory (INL). A methodology for evaluation of software CCFs in high safety-significant safety-related DI\&C systems of NPPs was developed as part of the framework. The framework integrates three stages of a typical risk assessment—qualitative hazard analysis and quantitative reliability and consequence analyses. The quantified risks compared with respective acceptance criteria provide valuable insights for system architecture alternatives allowing design optimization in terms of risk reduction and cost savings. A comprehensive case study performed to demonstrate the framework's capabilities is documented in this paper. Results show that the PRADIC is a powerful tool capable to identify potential digital-based CCFs, estimate their probabilities, and evaluate their impacts on system and plant safety.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Reliability Engineering \& System Safety},
	author = {Bao, Han and Zhang, Hongbin and Shorthill, Tate and Chen, Edward and Lawrence, Svetlana},
	month = feb,
	year = {2023},
	keywords = {Common cause failures, Digital instrumentation and control systems, High safety-significant safety-related, Nuclear power plants},
	pages = {108973},
}

@misc{noauthor_gosgen_2019,
	title = {Gösgen: {From} analog to digital instrumentation and control},
	shorttitle = {Gösgen},
	url = {https://www.framatome.com/medias/gosgen-from-analog-to-digital-instrumentation-and-control/},
	abstract = {Gösgen: From analog to digital instrumentation and control},
	language = {fr-FR},
	urldate = {2023-02-15},
	journal = {Framatome - Espace presse},
	year = {2019},
}

@inproceedings{arndt_digital_2010-1,
	title = {Digital {Instrumentation} and {Control} {Systems} {Upgrades} in {Current} {Generation} {Nuclear} {Power} {Plants}},
	doi = {10.1115/ICONE18-30358},
	abstract = {Over the past 20 years, the nuclear power industry in the United States (U.S.) has been slowly replacing old, obsolete, and difficult-to-maintain analog technology for its nuclear power plant protection, control, and instrumentation systems with digital systems. The advantages of digital technology, including more accurate and stable measurements and the ability to improve diagnostics capability and system reliability, have led to an ever increasing move to complete these upgrades. Because of the difficulties with establishing digital systems safety based on analysis or tests, the safety demonstration for these systems relies heavily on establishing the quality of the design and development of the hardware and software. In the United States, the U.S. Nuclear Regulatory Commission (NRC) has established detailed guidelines for establishing and documenting an appropriate safety demonstration for digital systems in NUREG-0800, “Standard Review Plan for the Review of Safety Analysis Reports for Nuclear Power Plants: LWR Edition,” Chapter 7, “Instrumentation and Controls,” Revision 5, issued March 2007 [1], and in a number of regulatory guides and interim staff guidance documents. However, despite the fact that the United States has a well-defined review process, a number of significant challenges associated with the design, licensing, and implementation of upgrades to digital systems for U.S. plants have emerged. Among these challenges have been problems with the quality of the systems and the supporting software verification and validation (V\&V) processes, challenges with determining the optimum balance between the enhanced capabilities for the new systems and the desire to maintain system simplicity, challenges with cyber security, and challenges with developing the information needed to support the review of new systems for regulatory compliance.},
	author = {Arndt, Steven},
	month = jan,
	year = {2010},
}

@misc{noauthor_benefits_nodate,
	title = {The benefits of digital {I}\&{C} - {Nuclear} {Engineering} {International}},
	url = {https://www.neimagazine.com/features/featurethe-benefits-of-digital-ic/},
	urldate = {2023-02-15},
}

@inproceedings{aras_benchmark_2022,
	address = {Columbus, Ohio, USA},
	title = {Benchmark {Study} of {XFTA} and {SCRAM} {Fault} {Tree} {Solvers} {Using} {Synthetically} {Generated} {Fault} {Trees} {Models}},
	isbn = {978-0-7918-8671-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2022/86717/V009T14A016/1157443},
	doi = {10.1115/IMECE2022-95783},
	abstract = {Abstract
            The development of the nuclear industry’s Probabilistic Risk Assessment (PRA) has significantly contributed to the design, reliability, and safety of nuclear power plants (NPP). Today, PRAs form integration in all nuclear power plant development stages, including design, licensing, operation, maintenance, and decommissioning. Many legacy PRA tools have been used in the nuclear field; however, more powerful tools are needed to cope with the rapid development of the nuclear industry and NPP designs. These tools are now required to analyze new aspects of the plants that were never envisioned before, and more computational resources are needed.
            This study uses synthetically generated fault trees of various sizes and specifications to benchmark fault tree solvers; XFTA version 1.3.1 and SCRAM version 0.16.2. The analysis is performed in two steps. The first step is to compare the probabilities, minimal cut sets, and importance factors. The second step is measuring CPU time, wall time, and the memory usage of each engine for benchmarking. The result for the first step for the same configuration is the same for each calculation engine. Overall, XFTA can complete most of the given runs in a shorter time with less memory usage than SCRAM. All computations and measurements are done on a specified computer.},
	urldate = {2023-02-15},
	booktitle = {Volume 9: {Mechanics} of {Solids}, {Structures}, and {Fluids}; {Micro}- and {Nano}-{Systems} {Engineering} and {Packaging}; {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Aras, Egemen M. and Farag, Asmaa S. and Earthperson, Arjun and Diaconeasa, Mihai A.},
	month = oct,
	year = {2022},
	pages = {V009T14A016},
}

@misc{noauthor_calculation_nodate,
	title = {Calculation and updating of {Common} {Cause} {Failure} unavailability by using alpha factor model {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0306454915300050?token=8EC367F72E45654D34D8EFF1318FD534FB1A551E7784BCEB65E29D2FA1005FC4D59105705A0355EF7126B9B0189E3779&originRegion=us-east-1&originCreation=20230214211707},
	language = {en},
	urldate = {2023-02-14},
	doi = {10.1016/j.anucene.2015.12.004},
}

@article{rasmuson_common-cause_2008,
	title = {Common-cause failure analysis in event assessment},
	volume = {222},
	issn = {1748-006X},
	url = {https://doi.org/10.1243/1748006XJRR121},
	doi = {10.1243/1748006XJRR121},
	abstract = {This paper reviews the basic concepts of modelling common-cause failures (CCFs) in reliability and risk studies and then applies these concepts to the treatment of CCF in event assessment. The cases of a failed component (with and without shared CCF potential) and a component being unavailable due to preventive maintenance or testing are addressed. The treatment of two related failure modes (e.g. failure to start and failure to run) is a new feature of this paper, as is the treatment of asymmetry within a common-cause component group.},
	language = {en},
	number = {4},
	urldate = {2022-10-29},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Rasmuson, D M and Kelly, D L},
	month = dec,
	year = {2008},
	note = {Publisher: SAGE Publications},
	pages = {521--532},
}

@article{mosleh_common_1991,
	title = {Common cause failures: {An} analysis methodology and examples},
	volume = {34},
	issn = {0951-8320},
	shorttitle = {Common cause failures},
	url = {https://www.sciencedirect.com/science/article/pii/095183209190104F},
	doi = {10.1016/0951-8320(91)90104-F},
	abstract = {This paper presents the framework developed for the treatment of common cause failures in risk and reliability analyses in a project jointly sponsored by the Electric Power Research Institute (EPRI) and the US Nuclear Regulatory Commission (NRC). The framework is developed as a systematic guide for identification, modeling, and quantification of common cause failures. It provides step-by-step procedures for performing each task of the analysis and allows the flexibility of choice among alternative acceptable models and analytical techniques. The major aspects of the analysis addressed in the framework include logic model development, screeing of common cause events, logical and probabilistic representation of common cause failure events, data analysis, system quantification, and interpretation of results. In addition to describing the framework, this paper presents certain key methodological developments that came about in the process of formulating the systematic procedure. The framework and several of the most important elements of the procedure are applied to an example involving common cause failure of nuclear power plant station batteries.},
	language = {en},
	number = {3},
	urldate = {2022-10-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Mosleh, Ali},
	month = jan,
	year = {1991},
	pages = {249--292},
}

@article{parry_common_1991,
	title = {Common cause failure analysis: {A} critique and some suggestions},
	volume = {34},
	issn = {0951-8320},
	shorttitle = {Common cause failure analysis},
	url = {https://www.sciencedirect.com/science/article/pii/095183209190106H},
	doi = {10.1016/0951-8320(91)90106-H},
	abstract = {This paper presents a critical review of a recently proposed procedure for a quantitative common cause failure analysis. Limitations resulting from the quality of the data base and the lack of guidance for event interpretation are highlighted. It is suggested that more effort needs to be made to understand and provide for a more consistent and detailed description of failure mechanisms. A review process, based on the assessment of the adequacy of the defensive strategy in place at a plant, is proposed as a supplement to the current approach based on a review of historical events to identify, in a more complete fashion, potential CCF mechanisms.},
	language = {en},
	number = {3},
	urldate = {2022-09-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Parry, Gareth W.},
	month = jan,
	year = {1991},
	pages = {309--326},
}

@article{oconnor_general_2016,
	title = {A general cause based methodology for analysis of common cause and dependent failures in system risk and reliability assessments},
	volume = {145},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015001829},
	doi = {10.1016/j.ress.2015.06.007},
	abstract = {Traditional Probabilistic Risk Assessments (PRAs) model dependencies through deterministic relationships in fault trees and event trees and parametric models of common cause failure (CCF) events. Popular CCF models do not recognize system speciﬁc defenses against dependencies and are restricted to identical components in redundant conﬁgurations. While this has allowed prediction of system reliability with little or no data, it is a limiting factor in many applications such as modeling the characteristics of a speciﬁc system design or incorporating the characteristics of failure when assessing a failure event's risk signiﬁcance (known as an Event Assessment, or Signiﬁcance Determination). This paper proposes the General Dependency Model (GDM), which uses Bayesian Network to model the probabilistic dependencies between components. This is done through the introduction of three parameters for each failure cause, which relate to physical attributes of the system being modeled, i.e., cause condition probability, component fragility, and coupling factor strength. Finally this paper demonstrates the development and use of the GDM in traditional applications of PRA, and for Event Assessments and Signiﬁcance Determination. Examples of the quantiﬁcation of the GDM model parameters for these applications are provided.},
	language = {en},
	urldate = {2022-08-31},
	journal = {Reliability Engineering \& System Safety},
	author = {O’Connor, Andrew and Mosleh, Ali},
	month = jan,
	year = {2016},
	pages = {341--350},
}

@article{hokstad_shock_1988,
	title = {A shock model for common-cause failures},
	volume = {23},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/095183208890018X},
	doi = {10.1016/0951-8320(88)90018-X},
	abstract = {This paper deals with the modeling of common-cause failures in redundant systems. Two of the well-known models for common-cause failures, the β-factor and the binomial failure rate (BFR) model, are discussed and evaluated. Applicability and shortcomings of these models are pinpointed. Further, a new parametric model for common-cause failures, here denoted the random probability shock (RPS) model, is suggested. The main feature of this model is the ability to model various degrees of dependence between the components of the system in a rather straightforward way. The β-factor and BFR models are special cases of this new model.},
	language = {en},
	number = {2},
	urldate = {2022-09-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Hokstad, Per},
	month = jan,
	year = {1988},
	pages = {127--145},
}

@article{le_duy_practical_2018,
	title = {A practical methodology for modeling and estimation of common cause failure parameters in multi-unit nuclear {PSA} model},
	volume = {170},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017300261},
	doi = {10.1016/j.ress.2017.10.018},
	abstract = {When assessing the risk related to Nuclear Power Plants in terms of impacts on the population health and on the environment, multi-unit issues should be taken into account. The specific aim of a Probabilistic Safety Assessment at site level is to deal with the dependencies existing between the units on that site. One of important dependency factors is the potential existence of the inter-unit common cause failures (CCF) that could affect identical systems (with or without interconnections) present in each unit. As they are identical this makes them potentially sensitive to "inter-unit" CCF, in addition to "intra-unit" CCF that are usually modeled for redundant systems. In this paper, we propose a practical methodology for modelling and estimation of CCF in a multi-unit PSA context. Two methods of modelling multi-unit CCF are firstly presented. A methodology for collecting and analyzing multi-unit CCF data is then proposed. This method is developed by extending the original impact vectors approach to the multi-unit context. Finally, in order to estimate the multi-unit CCF parameters in the case of incomplete data, we propose a CCF simulation method. The application of this method is considered in three different cases and compared with Bayesian and mapping up methods.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Le Duy, Tu Duong and Vasseur, Dominique},
	month = feb,
	year = {2018},
	keywords = {Inter unit common cause failures, Multi-unit, PSA},
	pages = {159--174},
}

@article{noauthor_model_2001,
	title = {A {MODEL} {OF} {THE} {DOSE} {RATE} {CALCULATION} {FOR} {A} {SPENT} {FUEL} {STORAGE} {STRUCTURE} {BY} {MONTE} {CARLO} {METHOD} {USING} {THE} {MODULATED} {CODE} {SYSTEM} {SCALE} 4.4a},
	abstract = {The modulated code system SCALE is used to perform a standardized shielding analysis for any facility containing spent fuel: handling devices, transport cask, intermediate and final storage facility. The neutron and gamma sources as well as the dose rates can be obtained using either discrete-ordinates or Monte Carlo methods.},
	language = {en},
	year = {2001},
}

@misc{us_epa_about_2016,
	type = {Overviews and {Factsheets}},
	title = {About {Exposure} and {Dose} {Rates}},
	url = {https://www.epa.gov/radnet/about-exposure-and-dose-rates},
	abstract = {Learn about radiation exposure and dose. Discover typical radiation exposure sources.},
	language = {en},
	urldate = {2023-02-14},
	author = {US EPA, OAR},
	month = may,
	year = {2016},
}

@misc{us_epa_what_2019,
	type = {Overviews and {Factsheets}},
	title = {What is the relationship between exposure rate and dose rate?},
	url = {https://www.epa.gov/radnet/what-relationship-between-exposure-rate-and-dose-rate},
	abstract = {Exposure rate is the amount of ionizing radiation per hour in a person’s vicinity (measured in milliRoentgen per hour, mR/h), whereas dose rate is the biological effect on the body from exposure to that radiation (measured in nanoSieverts per hour, nSv/h).},
	language = {en},
	urldate = {2023-02-14},
	author = {US EPA, OAR},
	month = feb,
	year = {2019},
}

@article{mkhonza_evaluation_nodate,
	title = {Evaluation of {MicroShield} {Build}-{Up} {Factors} and their {Limits} of {Applicability}},
	language = {en},
	author = {Mkhonza, L},
}

@article{marincel_microshield_2007,
	title = {{MICROSHIELD} {ANALYSIS} {TO} {CALCULATE} {EXTERNAL} {RADIATION} {DOSE} {RATES} {FOR} {SEVERAL} {SPENT} {FUEL} {CASKS}},
	abstract = {The purpose of this MicroShield analysis is to calculate the external radiation, primarily gamma, dose rate for spent fuel casks. The reason for making this calculation is that currently all analyses of transportation risk assume that this external dose rate is the maximum allowed by regulation, 10mrem/hr at 2m from the casks, and the risks of incident-free transportation are thus always overestimated to an unknown extent. In order to do this, the program by Grove Software, MicroShield 7.01, was used to model three Nuclear Regulatory Commission (NRC) approved casks: HI-STAR 100, GA-4, and NAC-STC, loaded with specific source material. Dimensions were obtained from NUREG/CR-6672 and the Certificates of Compliance for each respective cask. Detectors were placed at the axial point at 1m and 2m from the outer gamma shielding of the casks. In the April 8, 2004 publication of the Federal Register, a notice of intent to prepare a Supplemental Yucca Mountain Environmental Impact Statement (DOE/EIS-0250F-S1) was published by the Office of Civilian Radioactive Waste Management (OCRWM) in order to consider design, construction, operation, and transportation of spent nuclear fuel to the Yucca Mountain repository [1]. These more accurate estimates of the external dose rates could be used in order to provide a more risk-informed analysis.},
	language = {en},
	author = {Marincel, M K},
	year = {2007},
}

@misc{noauthor_radiation_nodate,
	title = {Radiation {Software} {\textbar} {Grove} {Software}},
	url = {https://radiationsoftware.com/microshield},
	urldate = {2023-02-14},
}

@article{mkhonza_evaluation_nodate-1,
	title = {Evaluation of {MicroShield} {Build}-{Up} {Factors} and their {Limits} of {Applicability}},
	language = {en},
	author = {Mkhonza, L},
}

@article{papadopoulos_uncertainty_2001,
	title = {Uncertainty estimation and {Monte} {Carlo} simulation method},
	volume = {12},
	issn = {0955-5986},
	url = {https://www.sciencedirect.com/science/article/pii/S0955598601000152},
	doi = {10.1016/S0955-5986(01)00015-2},
	abstract = {It has been reported that the Monte Carlo Method has many advantages over conventional methods in the estimation of uncertainty, especially that of complex measurement systems' outputs. The method, superficially, is relatively simple to implement, and is slowly gaining industrial acceptance. Unfortunately, very little has been published on how the method works. To those who are uninitiated, this powerful approach remains a ‘black art’. This paper demonstrates that the Monte Carlo simulation method is fully compatible with the conventional uncertainty estimation methods for linear systems and systems that have small uncertainties. Monte Carlo simulation has the ability to take account of partial correlated measurement input uncertainties. It also examines the uncertainties of the results of some basic manipulations e.g. addition, multiplication and division, of two input measured variables which may or may not be correlated. For correlated input measurements, the probability distribution of the result could be biased or skewed. These properties cannot be revealed using conventional methods.},
	language = {en},
	number = {4},
	urldate = {2023-02-13},
	journal = {Flow Measurement and Instrumentation},
	author = {Papadopoulos, Christos E. and Yeung, Hoi},
	month = aug,
	year = {2001},
	keywords = {Correlation, Monte Carlo, Uncertainty estimation, Uncertainty propagation},
	pages = {291--298},
}

@misc{zhang_modern_2020,
	title = {Modern {Monte} {Carlo} {Methods} for {Efficient} {Uncertainty} {Quantification} and {Propagation}: {A} {Survey}},
	shorttitle = {Modern {Monte} {Carlo} {Methods} for {Efficient} {Uncertainty} {Quantification} and {Propagation}},
	url = {http://arxiv.org/abs/2011.00680},
	doi = {10.48550/arXiv.2011.00680},
	abstract = {Uncertainty quantification (UQ) includes the characterization, integration, and propagation of uncertainties that result from stochastic variations and a lack of knowledge or data in the natural world. Monte Carlo (MC) method is a sampling-based approach that has widely used for quantification and propagation of uncertainties. However, the standard MC method is often time-consuming if the simulation-based model is computationally intensive. This article gives an overview of modern MC methods to address the existing challenges of the standard MC in the context of UQ. Specifically, multilevel Monte Carlo (MLMC) extending the concept of control variates achieves a significant reduction of the computational cost by performing most evaluations with low accuracy and corresponding low cost, and relatively few evaluations at high accuracy and correspondingly high cost. Multifidelity Monte Carlo (MFMC) accelerates the convergence of standard Monte Carlo by generalizing the control variates with different models having varying fidelities and varying computational costs. Multimodel Monte Carlo method (MMMC), having a different setting of MLMC and MFMC, aims to address the issue of uncertainty quantification and propagation when data for characterizing probability distributions are limited. Multimodel inference combined with importance sampling is proposed for quantifying and efficiently propagating the uncertainties resulting from small datasets. All of these three modern MC methods achieve a significant improvement of computational efficiency for probabilistic UQ, particularly uncertainty propagation. An algorithm summary and the corresponding code implementation are provided for each of the modern Monte Carlo methods. The extension and application of these methods are discussed in detail.},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Zhang, Jiaxin},
	month = nov,
	year = {2020},
	note = {arXiv:2011.00680 [stat]},
	keywords = {Statistics - Computation, Statistics - Methodology},
}

@misc{noauthor_full_nodate,
	title = {Full article: {Grizzly} and {BlackBear}: {Structural} {Component} {Aging} {Simulation} {Codes}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2020.1868278},
	urldate = {2023-02-13},
}

@article{gallina_review_2016,
	title = {A review of multi-risk methodologies for natural hazards: {Consequences} and challenges for a climate change impact assessment},
	volume = {168},
	issn = {0301-4797},
	shorttitle = {A review of multi-risk methodologies for natural hazards},
	url = {https://www.sciencedirect.com/science/article/pii/S0301479715303650},
	doi = {10.1016/j.jenvman.2015.11.011},
	abstract = {This paper presents a review of existing multi-risk assessment concepts and tools applied by organisations and projects providing the basis for the development of a multi-risk methodology in a climate change perspective. Relevant initiatives were developed for the assessment of multiple natural hazards (e.g. floods, storm surges, droughts) affecting the same area in a defined timeframe (e.g. year, season, decade). Major research efforts were focused on the identification and aggregation of multiple hazard types (e.g. independent, correlated, cascading hazards) by means of quantitative and semi-quantitative approaches. Moreover, several methodologies aim to assess the vulnerability of multiple targets to specific natural hazards by means of vulnerability functions and indicators at the regional and local scale. The overall results of the review show that multi-risk approaches do not consider the effects of climate change and mostly rely on the analysis of static vulnerability (i.e. no time-dependent vulnerabilities, no changes among exposed elements). A relevant challenge is therefore to develop comprehensive formal approaches for the assessment of different climate-induced hazards and risks, including dynamic exposure and vulnerability. This requires the selection and aggregation of suitable hazard and vulnerability metrics to make a synthesis of information about multiple climate impacts, the spatial analysis and ranking of risks, including their visualization and communication to end-users. To face these issues, climate impact assessors should develop cross-sectorial collaborations among different expertise (e.g. modellers, natural scientists, economists) integrating information on climate change scenarios with sectorial climate impact assessment, towards the development of a comprehensive multi-risk assessment process.},
	language = {en},
	urldate = {2023-02-13},
	journal = {Journal of Environmental Management},
	author = {Gallina, Valentina and Torresan, Silvia and Critto, Andrea and Sperotto, Anna and Glade, Thomas and Marcomini, Antonio},
	month = mar,
	year = {2016},
	keywords = {Climate change, Multi-hazard, Multi-hazard risk, Multi-risk},
	pages = {123--132},
}

@article{gallina_review_2016-1,
	title = {A review of multi-risk methodologies for natural hazards: {Consequences} and challenges for a climate change impact assessment},
	volume = {168},
	issn = {0301-4797},
	shorttitle = {A review of multi-risk methodologies for natural hazards},
	url = {https://www.sciencedirect.com/science/article/pii/S0301479715303650},
	doi = {10.1016/j.jenvman.2015.11.011},
	abstract = {This paper presents a review of existing multi-risk assessment concepts and tools applied by organisations and projects providing the basis for the development of a multi-risk methodology in a climate change perspective. Relevant initiatives were developed for the assessment of multiple natural hazards (e.g. floods, storm surges, droughts) affecting the same area in a defined timeframe (e.g. year, season, decade). Major research efforts were focused on the identification and aggregation of multiple hazard types (e.g. independent, correlated, cascading hazards) by means of quantitative and semi-quantitative approaches. Moreover, several methodologies aim to assess the vulnerability of multiple targets to specific natural hazards by means of vulnerability functions and indicators at the regional and local scale. The overall results of the review show that multi-risk approaches do not consider the effects of climate change and mostly rely on the analysis of static vulnerability (i.e. no time-dependent vulnerabilities, no changes among exposed elements). A relevant challenge is therefore to develop comprehensive formal approaches for the assessment of different climate-induced hazards and risks, including dynamic exposure and vulnerability. This requires the selection and aggregation of suitable hazard and vulnerability metrics to make a synthesis of information about multiple climate impacts, the spatial analysis and ranking of risks, including their visualization and communication to end-users. To face these issues, climate impact assessors should develop cross-sectorial collaborations among different expertise (e.g. modellers, natural scientists, economists) integrating information on climate change scenarios with sectorial climate impact assessment, towards the development of a comprehensive multi-risk assessment process.},
	language = {en},
	urldate = {2023-02-13},
	journal = {Journal of Environmental Management},
	author = {Gallina, Valentina and Torresan, Silvia and Critto, Andrea and Sperotto, Anna and Glade, Thomas and Marcomini, Antonio},
	month = mar,
	year = {2016},
	keywords = {Climate change, Multi-hazard, Multi-hazard risk, Multi-risk},
	pages = {123--132},
}

@misc{noauthor_reevaluation_nodate,
	title = {Reevaluation of {Station} {Blackout} {Risk} at {Nuclear} {Power} {Plants} ({NUREG}/{CR}-6890)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6890/index.html},
	language = {en-US},
	urldate = {2023-02-13},
	journal = {NRC Web},
}

@techreport{jow_melcor_1990,
	title = {{MELCOR} {Accident} {Consequence} {Code} {System} ({MACCS})},
	url = {https://www.osti.gov/biblio/7247757},
	abstract = {This report describes the MACCS computer code. The purpose of this code is to simulate the impact of severe accidents at nuclear power plants on the surrounding environment. MACCS has been developed for the US Nuclear Regulatory Commission to replace the previously used CRAC2 code, and it incorporates many improvements in modeling flexibility in comparison to CRAC2. The principal phenomena considered in MACCS are atmospheric transport, mitigative actions based on dose projection, dose accumulation by a number of pathways including food and water ingestion, early and latent health effects, and economic costs. The MACCS code can be used for a variety of applications. These include (1) probabilistic risk assessment (PRA) of nuclear power plants and other nuclear facilities, (2) sensitivity studies to gain a better understanding of the parameters important to PRA, and (3) cost-benefit analysis. This report is composed of three volumes. Volume I, the User's Guide, describes the input data requirements of the MACCS code and provides directions for its use as illustrated by three sample problems. Volume II, the Model Description, describes the underlying models that are implemented in the code, and Volume III, the Programmer's Reference Manual, describes the code's structure and database management. 59 refs., 14 figs., 15 tabs.},
	language = {English},
	number = {NUREG/CR-4691-Vol.2; SAND-86-1562-Vol.2},
	urldate = {2023-02-13},
	institution = {Nuclear Regulatory Commission, Washington, DC (USA). Div. of Systems Research; Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Jow, H. N. and Sprung, J. L. and Ritchie, L. T. and Rollstin, J. A. and Chanin, D. I.},
	month = feb,
	year = {1990},
	doi = {10.2172/7247757},
}

@article{alderton_riskman_nodate,
	title = {{RiskMan} {Default} {User} {Training} {Manual}},
	language = {en},
	author = {Alderton, Jessica},
}

@article{alderton_riskman_nodate-1,
	title = {{RiskMan} {Default} {User} {Training} {Manual}},
	language = {en},
	author = {Alderton, Jessica},
}

@article{metzroth_incorporation_2008,
	title = {Incorporation of a human reliability model into the {ADAPT} {PRA} methodology},
	volume = {2},
	abstract = {The ADAPT (Analysis of Dynamic Accident Progression Tree) software is a highly useful tool for the automatic generation of dynamic event trees. ADAPT is simulator agnostic and provides a simulator-independent means of generating dynamic event trees. Typically, ADAPT has utilized branching rules to model the probabilistic behavior of physical events that occur during the progression of an accident, such as the initiation of a hydrogen deflagration event, or hardware behavior, such as the failure of a valve to close after multiple cycles. This work demonstrates that the ADAPT approach can also be used to characterize the probabilistic behavior of human performance in an accident scenario. As an example of how a human reliability assessment model can be used as an element of a dynamic assessment, a SPAR-H human reliability model is incorporated into the probabilistic branching rules in the ADAPT analysis of a station blackout event.},
	journal = {9th International Conference on Probabilistic Safety Assessment and Management 2008, PSAM 2008},
	author = {Metzroth, Kyle and Denning, R. and Smidts, Carol and Aldemir, Tunc},
	month = jan,
	year = {2008},
	pages = {1326--1335},
}

@misc{noauthor_pra_nodate,
	title = {{PRA} {Procedures} {Guide}: {A} {Guide} to the {Performance} of {Probabilistic} {Risk} {Assessments} for {Nuclear} {Powe}},
	shorttitle = {{PRA} {Procedures} {Guide}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr2300/vol1/index.html},
	language = {en-US},
	urldate = {2023-02-13},
	journal = {NRC Web},
}

@article{agency_development_2010,
	title = {Development and {Application} of {Level} 1 {Probabilistic} {Safety} {Assessment} for {Nuclear} {Power} {Plants}},
	url = {https://www.iaea.org/publications/8235/development-and-application-of-level-1-probabilistic-safety-assessment-for-nuclear-power-plants},
	language = {en},
	urldate = {2023-02-13},
	journal = {Development and Application of Level 1 Probabilistic Safety Assessment for Nuclear Power Plants},
	author = {Agency, International Atomic Energy},
	year = {2010},
	note = {Publisher: IAEA},
}

@techreport{alfonsi_adaptive_2014,
	title = {Adaptive {Dynamic} {Event} {Tree} in {RAVEN} code},
	url = {https://www.osti.gov/biblio/1236822},
	abstract = {RAVEN is a software tool that is focused on performing statistical analysis of stochastic dynamic systems. RAVEN has been designed in a high modular and pluggable way in order to enable easy integration of different programming languages (i.e., C++, Python) and coupling with other applications (system codes). Among the several capabilities currently present in RAVEN, there are five different sampling strategies: Monte Carlo, Latin Hyper Cube, Grid, Adaptive and Dynamic Event Tree (DET) sampling methodologies. The scope of this paper is to present a new sampling approach, currently under definition and implementation: an evolution of the DET me},
	language = {English},
	number = {INL/CON-14-32595},
	urldate = {2023-02-13},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Alfonsi, Andrea and Rabiti, Cristian and Mandelli, Diego and Cogliati, Joshua Joseph and Kinoshita, Robert Arthur},
	month = nov,
	year = {2014},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {Adaptive} dynamic event tree in {RAVEN} code},
	url = {https://www.researchgate.net/publication/283327254_Adaptive_dynamic_event_tree_in_RAVEN_code},
	urldate = {2023-02-13},
}

@incollection{kumar_psa_2014,
	title = {A {PSA} {Level}-1 method with repairable components: {An} application to {ASTRID} {Decay} {Heat} {Removal} systems},
	isbn = {978-0-429-22682-3},
	shorttitle = {A {PSA} {Level}-1 method with repairable components},
	abstract = {The reliability problem of decay heat removal 
system falls into the category of a tolerable downtime reliability problem in which failure of safety 
barriers are hazardous if  the duration of failure 
exceeds its tolerable grace period determined by1 INTRODUCTIONSodium cooled Fast Reactors (SFRs) present the 
characteristic of the large thermal inertia of its 
coolant systems and high coolant temperature 
(Saez 2013, Lee \& McCormick 2011). This characteristic promotes usage of passive cooling systems 
and also allows for relatively long times for cooling recovery (Nayak \& Sinha 2007) during reactor 
accidents. Particularly, the large thermal inertia 
allows a sufficient grace period or tolerance time 
for the possibility to recover failed components in 
a DHR system. This possibility of repair within a 
tolerable downtime or grace period has been further boosted by recent developments in the area of 
sensor-based online maintenance. For instance, the 
tools of online integrated risk monitoring system 
can detect the problem rapidly and possible repair 
can be realized within the time window given by 
the thermal inertia of DHR systems (Hashemian 
2011, IAEA: TECDOC 1999). Robotic repair system in highly automated plants can restore the 
fault that was not possible by human interventions 
(Thomas 2012). Efforts are going on in the area of 
maintenance to repair a component without hampering the normal operation of a complex engineering system.},
	booktitle = {Safety and {Reliability}: {Methodology} and {Applications}},
	publisher = {CRC Press},
	author = {Kumar, R. and Bechta, S. and Kudinov, P. and Curnier, F. and Bertrand, M. Marquès \& F.},
	year = {2014},
	note = {Num Pages: 8},
}

@misc{noauthor_seamless_nodate,
	title = {Seamless {Level} 2/level 3 dynamic probabilistic risk assessment clustering {\textbar} {Request} {PDF}},
	url = {https://www.researchgate.net/publication/286835181_Seamless_Level_2level_3_dynamic_probabilistic_risk_assessment_clustering},
	urldate = {2023-02-13},
}

@article{swaminathan_identification_1999,
	title = {Identification of missing scenarios in {ESDs} using probabilistic dynamics},
	volume = {66},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832099000241},
	doi = {10.1016/S0951-8320(99)00024-1},
	abstract = {The event sequence diagram (ESD) framework can be used to qualitatively represent dynamic scenarios. The solution of ESDs can be performed in an analytical manner. Since the construction of ESDs has some inherent analyst dependence, there is scope for omitting scenarios due to certain simplifying assumptions. This is one of the prime drawbacks of the ESD framework. This paper presents an approach for identifying missing scenarios by combining ESDs with probabilistic dynamics. The approach also helps in reducing the variance of a Monte Carlo simulation procedures.},
	language = {en},
	number = {3},
	urldate = {2023-02-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Smidts, C.},
	month = dec,
	year = {1999},
	keywords = {Dynamic reliability, Event sequence diagrams, Monte Carlo simulation, Probabilistic dynamics, Variance reduction},
	pages = {275--279},
}

@article{swaminathan_event_1999,
	title = {The {Event} {Sequence} {Diagram} framework for dynamic {Probabilistic} {Risk} {Assessment}},
	volume = {63},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832098000271},
	doi = {10.1016/S0951-8320(98)00027-1},
	abstract = {Dynamic methodologies have become fairly established in academia. Their superiority over classical methods like Event Tree/Fault Tree techniques has been demonstrated. Despite this, dynamic methodologies have not enjoyed the support of the industry. One of the primary reasons for the lack of acceptance in the industry is that there is no easy way to qualitatively represent dynamic scenarios. This paper proposes to extend current Event Sequence Diagrams (ESDs) to allow modeling of dynamic situations. Under the proposed ESD representation, ESDs can be used in combination with dynamic methodology computational algorithms which will solve the underlying probabilistic dynamics equations. Once engineers are able to translate their knowledge of the system dynamics and accident evolution into simple ESDs, usage of dynamic methodologies will become more popular.},
	language = {en},
	number = {1},
	urldate = {2023-02-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Smidts, C.},
	month = jan,
	year = {1999},
	pages = {73--90},
}

@article{labeau_procedures_2002,
	title = {Procedures of {Monte} {Carlo} transport simulation for applications in system engineering},
	volume = {77},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832002000558},
	doi = {10.1016/S0951-8320(02)00055-8},
	abstract = {Monte Carlo (MC) simulation is the most promising tool for performing realistic reliability and availability analysis of complex systems. Yet, the efficient use of MC simulation technique is not trivial in large scale applications. This paper considers the two commonly adopted approaches to MC simulation: the direct, component-based approach and the indirect, system-based approach. The mathematical details of the two approaches are worked out in detail, so as to show their probabilistic equivalence. The proper formulation for biasing the simulation is introduced, thus leading to the correct expressions for the statistical weights. Both approaches are applied, in an analog as well as in a biased scheme, to a simple system of the literature and comparisons are made with respect to the computing time and the goodness of the estimate, as measured by the variance of the results.},
	language = {en},
	number = {3},
	urldate = {2023-02-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Labeau, P. E. and Zio, E.},
	month = sep,
	year = {2002},
	keywords = {Biasing techniques, Monte Carlo simulation, Transition time and transition probability},
	pages = {217--228},
}

@article{devooght_probabilistic_1996,
	series = {Reliability and safety analysis of dynamic process systems},
	title = {Probabilistic dynamics as a tool for dynamic {PSA}},
	volume = {52},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/0951832095001352},
	doi = {10.1016/0951-8320(95)00135-2},
	abstract = {The assumptions, scope and achievements of a probabilistic dynamics theory based on a Chapman-Kolmogorov formulation of mixed probabilistic and deterministic dynamics are reviewed. The formulation of the theory involves both physical (or process) variables and (semi-) Markovian states of the system under study allowing the inclusion of human error modelling. The problem of crossing a safety threshold is used to emphasize the role of timing in concurrent sequences. We show how the adjoint formulation can be used to obtain information on the outcomes of transients as a function of its starting characteristics. These outcomes may, for instance, be damage resulting from safety boundary crossing, or reliability functions. A comparison is made between a Monte-Carlo solution and a DYLAM analysis of a simple multicomponent benchmark problem which shows that for the same accuracy a Monte-Carlo method is much less sensitive to the size of the problem.},
	language = {en},
	number = {3},
	urldate = {2023-02-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Devooght, Jacques and Smidts, Carol},
	month = jun,
	year = {1996},
	pages = {185--196},
}

@article{izquierdo_relationship_1996,
	series = {Reliability and safety analysis of dynamic process systems},
	title = {Relationship between probabilistic dynamics and event trees},
	volume = {52},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/0951832095001344},
	doi = {10.1016/0951-8320(95)00134-4},
	abstract = {In this paper we prove that classical event trees can be derived rigorously from the theory of Probabilistic Dynamics only if we assume setpoint transitions, i.e., transitions that depend only on algebraic combinations of instantaneous values of the process variables (setpoints). Approximate formulae are also given in the more general case where the time of actuation after a setpoint is reached is stochastic, extending the classical event tree approach. The paper also reviews the theory of Probabilistic Dynamics and shows some important simplifications that can be used under certain common situations.},
	language = {en},
	number = {3},
	urldate = {2023-02-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Izquierdo, J. M. and Melendez, E. and Devooght, J.},
	month = jun,
	year = {1996},
	pages = {197--209},
}

@incollection{spitzer_stimulus-driven_2004,
	address = {London},
	title = {The {Stimulus}-{Driven} {Theory} of {Probabilistic} {Dynamics} as a {Framework} for {Probabilistic} {Safety} {Assessment}},
	isbn = {978-1-4471-1057-6 978-0-85729-410-4},
	url = {http://link.springer.com/10.1007/978-0-85729-410-4_112},
	abstract = {ID: 0414) The current version of the Theory of Probabilistic Dynamics (TPD) falls short in modeling essential aspects of PSAs, because automatic or manual actions that induce safety oriented events curbing undesired time evolutions, are always ”stimulated” by particular features of the situation. Typical stimulus examples are initiation safeguards setpoints or control room alarms, but many others, as the inﬂuence of organizations in the operator interventions are also to be accounted for. To incorporate the concept of stimulus covering all those circumstances into the TPD was the purpose of two recent papers that describe the resultant Stimulus-Driven Theory of Probabilistic Dynamics (SDTPD). However, the theory is still general and does not introduce the familiar concept of sequences. This summary paper shows how sequences may also be incorporated into SDTPD in order to better understand PSA. A set of equations derived from this new extension is able to provide exceedance frequency and sequence probability under the same assumptions as those of current PSA methods. SDTPD is also presented in a more reﬁned version with a symmetric treatment of stimulus activation and disactivation events, and allows the probabilities of the next event to depend on the state of all stimulus.},
	language = {en},
	urldate = {2023-02-13},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer London},
	author = {Izquierdo, José Maria and Labeau, Pierre-Etienne},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	doi = {10.1007/978-0-85729-410-4_112},
	pages = {687--693},
}

@book{stamatelatos_probabilistic_2011,
	edition = {2nd ed.},
	series = {{NASA} {SP} ;},
	title = {Probabilistic risk assessment procedures guide for {NASA} managers and practitioners},
	publisher = {National Aeronautics and Space Administration, NASA Headquarters, Office of Safety and Mission Assurance,},
	author = {Stamatelatos, Michaēl},
	year = {2011},
}

@article{fragola_probabilistic_1995,
	title = {Probabilistic risk assessment of the {Space} {Shuttle}. {Phase} 3: {A} study of the potential of losing the vehicle during nominal operation. {Volume} 5: {Auxiliary} shuttle risk analyses},
	volume = {5},
	shorttitle = {Probabilistic risk assessment of the {Space} {Shuttle}. {Phase} 3},
	url = {https://ui.adsabs.harvard.edu/abs/1995pras....5.....F},
	abstract = {Volume 5 is Appendix C, Auxiliary Shuttle Risk Analyses, and contains the following reports: Probabilistic Risk Assessment of Space Shuttle Phase 1 - Space Shuttle Catastrophic Failure Frequency Final Report; Risk Analysis Applied to the Space Shuttle Main Engine - Demonstration Project for the Main Combustion Chamber Risk Assessment; An Investigation of the Risk Implications of Space Shuttle Solid Rocket Booster Chamber Pressure Excursions; Safety of the Thermal Protection System of the Space Shuttle Orbiter - Quantitative Analysis and Organizational Factors; Space Shuttle Main Propulsion Pressurization System Probabilistic Risk Assessment, Final Report; and Space Shuttle Probabilistic Risk Assessment Proof-of-Concept Study - Auxiliary Power Unit and Hydraulic Power Unit Analysis Report.},
	urldate = {2023-02-13},
	journal = {Unknown},
	author = {Fragola, Joseph R. and Maggio, Gaspare and Frank, Michael V. and Gerez, Luis and McFadden, Richard H. and Collins, Erin P. and Ballesio, Jorge and Appignani, Peter L. and Karns, James J.},
	month = feb,
	year = {1995},
	note = {ADS Bibcode: 1995pras....5.....F},
	keywords = {Aerospace Safety, Auxiliary Power Sources, Combustion Chambers, Fuel Tank Pressurization, Hydraulic Equipment, Probability Theory, Reliability Analysis, Risk, Space Shuttle Boosters, Space Shuttle Main Engine, Space Shuttle Orbiters, Space Shuttles, Space Transportation, Spacecraft Reliability, System Failures, Thermal Protection},
}

@book{beavers_multihazard_2009,
	title = {Multihazard {Issues} in the {Central} {United} {States}},
	isbn = {978-0-7844-1015-8},
	url = {https://ascelibrary.org/doi/book/10.1061/9780784410158},
	language = {en},
	urldate = {2023-02-12},
	publisher = {American Society of Civil Engineers},
	author = {Beavers, James E.},
	month = jan,
	year = {2009},
	doi = {10.1061/9780784410158},
}

@article{ellingwood_acceptable_2001,
	title = {Acceptable risk bases for design of structures},
	volume = {3},
	issn = {1528-2716},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pse.78},
	doi = {10.1002/pse.78},
	abstract = {Structural design standards provide the foundation of good engineering practice and a framework for addressing safety and serviceability issues rationally. Structural reliability methods provide the tools for managing uncertainties in modern codified structural design. Current probability-based structural codes are based on performance measures expressed as notional reliabilities of structural components. These notional reliabilities, encapsulated in reliability indices, were obtained by calibrating the proposed codes to traditional practice rather than from quantitative risk analysis. Because the reliability estimates are based on models of real systems, they may not correspond to historical failure rates, and therefore confound the process of risk communication among structural engineers, building or regulatory officials, and the public. The research and professional engineering communities must work together to confront future challenges arising from new trends in structural engineering practice towards tailoring building design to performance expectations of the building owners, occupants and the public. In this context, the prospects of basing future codes on a quantitative acceptable risk measure warrant further examination.},
	language = {en},
	number = {2},
	urldate = {2023-02-12},
	journal = {Progress in Structural Engineering and Materials},
	author = {Ellingwood, Bruce R},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pse.78},
	keywords = {buildings (codes), design (structures), engineering mechanics, limit states design, loads (forces), performance-based engineering, probability, reliability, risk, structural engineering},
	pages = {170--179},
}

@article{ayyub_critical_2007,
	title = {Critical asset and portfolio risk analysis: an all-hazards framework},
	volume = {27},
	issn = {0272-4332},
	shorttitle = {Critical asset and portfolio risk analysis},
	doi = {10.1111/j.1539-6924.2007.00911.x},
	abstract = {This article develops a quantitative all-hazards framework for critical asset and portfolio risk analysis (CAPRA) that considers both natural and human-caused hazards. Following a discussion on the nature of security threats, the need for actionable risk assessments, and the distinction between asset and portfolio-level analysis, a general formula for all-hazards risk analysis is obtained that resembles the traditional model based on the notional product of consequence, vulnerability, and threat, though with clear meanings assigned to each parameter. Furthermore, a simple portfolio consequence model is presented that yields first-order estimates of interdependency effects following a successful attack on an asset. Moreover, depending on the needs of the decisions being made and available analytical resources, values for the parameters in this model can be obtained at a high level or through detailed systems analysis. Several illustrative examples of the CAPRA methodology are provided.},
	language = {eng},
	number = {4},
	journal = {Risk Analysis: An Official Publication of the Society for Risk Analysis},
	author = {Ayyub, Bilal M. and McGill, William L. and Kaminskiy, Mark},
	month = aug,
	year = {2007},
	pmid = {17958492},
	keywords = {Hazardous Substances, Humans, Probability, Risk Assessment},
	pages = {789--801},
}

@misc{noauthor_constrained_2016,
	title = {Constrained {Noninformative} {Distribution} {Method}},
	url = {https://nrcoe.inl.gov/publicdocs/Overview-and-Reference.pdf},
	urldate = {2023-02-12},
	month = feb,
	year = {2016},
}

@misc{noauthor_cafta_nodate,
	title = {{CAFTA} {Technology} {Package} {V} 10 - {Phoenix} {Architect}},
	url = {https://polestartechnicalservices.com/wp-content/uploads/2020/11/CAFTA-Factsheet-template-v-10-R1.pdf},
	urldate = {2023-02-11},
}

@misc{noauthor_program_2022,
	title = {Program 41.07.01: {Risk} and {Safety} {Management} {\textbar} {Product} {Abstract}},
	url = {https://www.epri.com/research/programs/061177/results/3002020050},
	urldate = {2023-02-11},
	journal = {Phoenix Architect - Version 2.0},
	month = may,
	year = {2022},
}

@techreport{el-genk_integration_2022,
	address = {Albuquerque, NM, USA.},
	title = {Integration and {Characterization} {Testing} of the {LOBO} {Nuclear} {CyberSecurity} ({LOBO} {NCS}) {Platform} and {OpenPLC}},
	url = {http://isnps.unm.edu/reports/ July},
	number = {UNM-ISNPS-01-2022},
	institution = {Institute for Space and Nuclear Power Studies, The University of New Mexico},
	author = {El-Genk, Mohamed and Schriener, Timothy and Salem Farag, Asmaa},
	month = jul,
	year = {2022},
}

@misc{noauthor_saphire_2014,
	title = {{SAPHIRE} 8.0.9: {Systems} {Analysis} {Programs} for {Hands}-{On} {Integrated} {Reliability} {Evaluations}},
	url = {https://rsicc.ornl.gov/codes/psr/psr6/psr-608.html},
	urldate = {2023-02-09},
	journal = {RSICC CODE PACKAGE PSR-608},
	month = jul,
	year = {2014},
}

@book{mazurok_baseline_2022,
	title = {Baseline {RELAP}/{SCDAPSIM} and {ASYST} {Calculations} -{Estimates} of the {Likely} {Reactor} {Behavior} in the event of an {SBO}-related {Event} for {Ukrainian} {VVER}-1000 {NPPs}},
	abstract = {After the Russian invasion of Ukraine in February 2022 and attack on their nuclear power plants
(NPPs), Innovative Systems Software LLC (ISS), contacted the Energy Safety Group LLC (ESG) in
Ukraine, and offered their support in the event that any accident management strategies might need
to be updated in light of the increased risk of station blackout (SBO) conditions. ESG had recently
published the results of their "Post-Fukushima" safety analysis of the Zaporizhzhya NPP Unit 1 using
a combination of RELAP5 and MELCOR. ISS, and other collaborators had provided similar support
for the emergency assessment of the Fukushima Daiichi accident using RELAP/SCDAPSIM. This
support was initially provided to the International Atomic Energy Agency (IAEA) emergency
response team during the Fukushima Daiichi accident, and later to the Japan Atomic Energy Agency
(JAEA), in support of their post-accident decommissioning research activities. Other collaborators
and co-authors have also performed a wide range of VVER-1000 safety assessments using
RELAP/SCDAPSIM and, more recently, the new best estimate integral system thermal-hydraulic
code, ASYST. Fortunately, much like the Fukushima Daiichi accident assessment support activities
where the Comision Nacional de Seguridad Nuclear y Salvaguardias (CNSNS), the Mexican Nuclear
Regulatory Authority, had provided access to their detailed RELAP/SCDAPSIM Laguna Verde
BWR input models, ISS, and their VVER-1000 collaborators, have representative
RELAP/SCDAPSIM VVER-1000 input models, derived from models originally provided by the
Institute for Nuclear Research and Nuclear Energy (INRNE) in Bulgaria.
In preparation for any analysis that might have been required on an accelerated time frame, it
was decided to perform a series of baseline calculations that could then be used to provide preliminary
assessments of the reactor and containment behavior in the event of an SBO with the added possibility
of externally caused damage to the containment, reactor coolant system (RCS), or associated safety
systems. This approach is similar to that used in support of the IAEA emergency response team as
the Fukushima Daiichi accident was in progress. It was also decided that a combination of
RELAP/SCDAPSIM and ASYST would be used. RELAP/SCDAPSIM/MOD3.4 would be used for
the initial baseline studies since it is the widely used version of RELAP/SCDAPSIM and has been
used in the analysis in the widest range of historical and ongoing experiments as well as our initial
Fukushima Daiichi calculations. However, it is limited in its ability to consider response of the
containment under severe accident conditions. ASYST VER 3.5, which has containment modelling
options being developed in conjunction with our Japanese collaborators, will be able to provide direct
comparisons with the original ESG calculations using RELAP5 and MELCOR. This paper describes
the basic features of RELAP/SCDAPSIM/MOD3.4 and ASYST VER 3.5, the VVER-1000 input
models that are being used, and a brief presentation and discussion of some of the key results from
these baseline calculations.},
	author = {Mazurok, Oleksandr and Allison, C. and Salem Farag, Asmaa and Elshahat, Ayah and Stefanova, Antoaneta},
	month = jun,
	year = {2022},
}

@article{paris_quantitative_2019,
	title = {Quantitative risk reduction by means of recovery strategies},
	volume = {182},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017311742},
	doi = {10.1016/j.ress.2018.09.024},
	abstract = {After the accident at Fukushima Dai-ichi, considerable efforts were put on enhancing the capability of the Nuclear Power Plants to cope with conditions resulting from the loss of plant safety-related systems. The most widespread solution adopted worldwide has been to define and implement new procedures and emergency actuation plans, the so called FLEX strategies. Among these strategies, there are several recovery strategies which involve the use of portable equipment for accomplishing the safety functions of the unavailable systems. In some cases, these strategies have been devised to be performed concurrently to the usual system recovery procedures included in the EOPs of most NPPs. In this regard, the heat sink recovery after the occurrence of a Total Loss of Feedwater (TLFW) in a Westinghouse 3-loop PWR design is a significant example, and it has been chosen in the present study to assess the quantitative risk reduction provided by the usual and FLEX recovery strategies in a Westinghouse 3-loop PWR design. With this aim, the Integrated Safety Assessment (ISA) methodology, developed by the Spanish Nuclear Safety Council (CSN), has been applied to TLFW sequences as part of the collaboration between Technical University of Madrid (UPM), NFQ Solutions and CSN.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {París, C. and Queral, C. and Mula, J. and Gómez-Magán, J. and Sánchez-Perea, M. and Meléndez, E. and Gil, J.},
	month = feb,
	year = {2019},
	keywords = {, Auxiliary feed water, , Beyond design basis external event, , Critical safety function, , Damage domain, , Damage exceedance frequency, , Damage exceedance probability, , Dynamic event tree, , Emergency operating procedure, , Event tree, , Fault tree, , Feed and bleed, , Full spectrum loss of coolant accident, , Generic event tree, , Generic event tree with uncertainties, , High pressure safety injection, , Initiating event, , Integrated safety assessment, , Loss of coolant accident, , Main feed water, , Spanish nuclear safety council, Damage domain, Dynamic event tree, Integrated safety assessment, Probabilistic safety analysis, Recovery and FLEX strategies},
	pages = {13--32},
}

@article{smidts_probabilistic_1992,
	title = {Probabilistic {Reactor} {Dynamics}—{II}: {A} {Monte} {Carlo} {Study} of a {Fast} {Reactor} {Transient}},
	volume = {111},
	issn = {0029-5639},
	shorttitle = {Probabilistic {Reactor} {Dynamics}—{II}},
	url = {https://doi.org/10.13182/NSE92-A23938},
	doi = {10.13182/NSE92-A23938},
	abstract = {The concept of how probabilistic reactor dynamics applies to a realistic problem, an accidental transient of the primary side of a fast reactor, is demonstrated. A full description of the reactor model, including physical variables, evolution laws, and failure rates with their dependence on physical variables, is given. Failure probabilities and failure and success time distributions are evaluated. Vectorized and nonvectorized versions of a Monte Carlo algorithm as well as biased and nonbiased versions of this algorithm are compared.},
	number = {3},
	urldate = {2023-02-10},
	journal = {Nuclear Science and Engineering},
	author = {Smidts, C. and Devooght, J.},
	month = jul,
	year = {1992},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.13182/NSE92-A23938},
	pages = {241--256},
}

@article{li_dynamic_2019,
	title = {Dynamic simulation of knowledge based reasoning of nuclear power plant operator in accident conditions: {Modeling} and simulation foundations},
	volume = {119},
	issn = {0925-7535},
	shorttitle = {Dynamic simulation of knowledge based reasoning of nuclear power plant operator in accident conditions},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753518303540},
	doi = {10.1016/j.ssci.2018.02.031},
	abstract = {This paper describes major additions to the modeling and simulation capabilities of the Accident Dynamic Simulator paired with the Information, Decision, and Action in a Crew context (ADS-IDAC), a platform for conducting dynamic probabilistic risk assessment (DPRA) of nuclear power plants. The new advancements are mostly in modeling of operator knowledge-based behavior in accident conditions, enhancing realism of the IDAC model, and simulation approach to Human Reliability Analysis (HRA). The focus is situation assessment and diagnosis of the accident cause. Knowledge-based reasoning plays an important role in this phase. A reasoning module has been developed and implemented in ADS-IDAC to simulate operators’ knowledge-based reasoning. This paper describes the cognitive architecture of the reasoning module, including knowledge representation (model of operator’s understanding of the plant systems and functions), a memory representation, information processing flow, reasoning sequence generation, and rules for accident diagnosis. Some theoretical and empirical insights for human error prediction are embedded in this causal model as simulation rules. Human cognitive limitations and heuristics that potentially contribute to human errors are explicitly modeled. Together with the model description, several example simulations are provided to demonstrate different features of the reasoning module. Examples of the simulation show that the reasoning module in ADS-IDAC produces realistic knowledge-based responses by capturing cognitive limitations, deliberative reasoning, and dynamic of accident progression.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Safety Science},
	author = {Li, Yuandan and Mosleh, Ali},
	month = nov,
	year = {2019},
	keywords = {ADS-IDAC, Attention, Cognitive simulation, Human reliability analysis, Knowledge-based behavior},
	pages = {315--329},
}

@article{hofer_approximate_2002,
	title = {An approximate epistemic uncertainty analysis approach in the presence of epistemic and aleatory uncertainties},
	volume = {77},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200200056X},
	doi = {10.1016/S0951-8320(02)00056-X},
	abstract = {Epistemic uncertainty analysis is an essential feature of any model application subject to ‘state of knowledge’ uncertainties. Such analysis is usually carried out on the basis of a Monte Carlo simulation sampling the epistemic variables and performing the corresponding model runs. In situations, however, where aleatory uncertainties are also present in the model, an adequate treatment of both types of uncertainties would require a two-stage nested Monte Carlo simulation, i.e. sampling the epistemic variables (‘outer loop’) and nested sampling of the aleatory variables (‘inner loop’). It is clear that for complex and long running codes the computational effort to perform all the resulting model runs may be prohibitive. Therefore, an approach of an approximate epistemic uncertainty analysis is suggested which is based solely on two simple Monte Carlo samples: (a) joint sampling of both, epistemic and aleatory variables simultaneously, (b) sampling of aleatory variables alone with the epistemic variables held fixed at their reference values. The applications of this approach to dynamic reliability analyses presented in this paper look quite promising and suggest that performing such an approximate epistemic uncertainty analysis is preferable to the alternative of not performing any.},
	language = {en},
	number = {3},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Hofer, Eduard and Kloos, Martina and Krzykacz-Hausmann, Bernard and Peschke, Jörg and Woltereck, Martin},
	month = sep,
	year = {2002},
	keywords = {Aleatory uncertainty, Dynamic PSA, Dynamic reliability analysis, Epistemic uncertainty, Monte Carlo simulation},
	pages = {229--238},
}

@article{hofer_approximate_2002-1,
	title = {An approximate epistemic uncertainty analysis approach in the presence of epistemic and aleatory uncertainties},
	volume = {77},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200200056X},
	doi = {10.1016/S0951-8320(02)00056-X},
	abstract = {Epistemic uncertainty analysis is an essential feature of any model application subject to ‘state of knowledge’ uncertainties. Such analysis is usually carried out on the basis of a Monte Carlo simulation sampling the epistemic variables and performing the corresponding model runs. In situations, however, where aleatory uncertainties are also present in the model, an adequate treatment of both types of uncertainties would require a two-stage nested Monte Carlo simulation, i.e. sampling the epistemic variables (‘outer loop’) and nested sampling of the aleatory variables (‘inner loop’). It is clear that for complex and long running codes the computational effort to perform all the resulting model runs may be prohibitive. Therefore, an approach of an approximate epistemic uncertainty analysis is suggested which is based solely on two simple Monte Carlo samples: (a) joint sampling of both, epistemic and aleatory variables simultaneously, (b) sampling of aleatory variables alone with the epistemic variables held fixed at their reference values. The applications of this approach to dynamic reliability analyses presented in this paper look quite promising and suggest that performing such an approximate epistemic uncertainty analysis is preferable to the alternative of not performing any.},
	language = {en},
	number = {3},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Hofer, Eduard and Kloos, Martina and Krzykacz-Hausmann, Bernard and Peschke, Jörg and Woltereck, Martin},
	month = sep,
	year = {2002},
	keywords = {Aleatory uncertainty, Dynamic PSA, Dynamic reliability analysis, Epistemic uncertainty, Monte Carlo simulation},
	pages = {229--238},
}

@article{alfonsi_dynamic_nodate,
	title = {Dynamic {Event} {Tree} {Analysis} {Through} {RAVEN}},
	abstract = {Conventional Event-Tree (ET) based methodologies are extensively used as tools to perform reliability and safety assessment of complex and critical engineering systems. One of the disadvantages of these methods is that timing/sequencing of events and system dynamics is not explicitly accounted for in the analysis. In order to overcome these limitations several techniques, also know as Dynamic Probabilistic Risk Assessment (DPRA), have been developed. Monte-Carlo (MC) and Dynamic Event Tree (DET) are two of the most widely used D-PRA methodologies to perform safety assessment of Nuclear Power Plants (NPP). In the past two years, the Idaho National Laboratory (INL) has developed its own tool to perform Dynamic PRA: RAVEN (Reactor Analysis and Virtual control ENvironment). RAVEN has been designed in a high modular and pluggable way in order to enable easy integration of different programming languages (i.e., C++, Python) and coupling with other application including the ones based on the MOOSE framework, developed by INL as well. RAVEN performs two main tasks: 1) control logic driver for the new Thermo-Hydraulic code RELAP-7 and 2) post-processing tool. In the ﬁrst task, RAVEN acts as a deterministic controller in which the set of control logic laws (user deﬁned) monitors the RELAP-7 simulation and controls the activation of speciﬁc systems. Moreover, RAVEN models also stochastic events, such as components failures, and performs uncertainty quantiﬁcation. Such stochastic modeling is employed by using both MC and DET algorithms. In the second task, RAVEN processes the large amount of data generated by RELAP-7 using data-mining based algorithms. This paper focuses on the ﬁrst task and shows how it is possible to perform the analysis of dynamic stochastic systems using the newly developed RAVEN DET capability. As an example, the Dynamic PRA analysis, using Dynamic Event Tree, of a simpliﬁed pressurized water reactor for a Station Black-Out scenario is presented.},
	language = {en},
	author = {Alfonsi, A and Rabiti, C and Mandelli, D and Cogliati, J J and Kinoshita, R A and Naviglio, A},
}

@article{maidana_supervised_2023,
	title = {Supervised dynamic probabilistic risk assessment: {Review} and comparison of methods},
	volume = {230},
	issn = {0951-8320},
	shorttitle = {Supervised dynamic probabilistic risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832022005063},
	doi = {10.1016/j.ress.2022.108889},
	abstract = {With the adoption of autonomous systems in higher levels of autonomy, large-scale, complex and dynamic systems are becoming commonplace. Ensuring safe operation of safety-critical autonomous systems is paramount, typically approached through risk assessment. Two challenges associated with using traditional risk assessment methods for complex systems are that these systems are dynamic (i.e., their state changes over time) and interactions between subsystems and components may lead to unpredictable behaviors and impact on the surrounding environment and other systems in the close vicinity. Dynamic probabilistic risk assessment (DPRA) methods are possible solutions to these challenges, where the dynamic and uncertain nature of the systems is considered. The methods, however, usually face combinatorial explosion related to hazards and scenarios, which make their practical application prohibitive; in the DPRA literature, this problem is known as the state explosion problem. In this paper, we present a literature review on methods for DPRA, with focus on the existing solutions to the state explosion problem. Specifically, we analyze and compare these solutions in terms of computational time complexity, traceability and state–space coverage. Finally, we discuss the comparisons and propose potential paths to improved solutions for the state explosion problem based on the knowledge gained in the study.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Maidana, Renan G. and Parhizkar, Tarannom and Gomola, Alojz and Utne, Ingrid B. and Mosleh, Ali},
	month = feb,
	year = {2023},
	keywords = {Dynamic probabilistic risk assessment, Literature review, State explosion, Supervised DPRA},
	pages = {108889},
}

@article{maidana_supervised_2023-1,
	title = {Supervised dynamic probabilistic risk assessment: {Review} and comparison of methods},
	volume = {230},
	issn = {0951-8320},
	shorttitle = {Supervised dynamic probabilistic risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832022005063},
	doi = {10.1016/j.ress.2022.108889},
	abstract = {With the adoption of autonomous systems in higher levels of autonomy, large-scale, complex and dynamic systems are becoming commonplace. Ensuring safe operation of safety-critical autonomous systems is paramount, typically approached through risk assessment. Two challenges associated with using traditional risk assessment methods for complex systems are that these systems are dynamic (i.e., their state changes over time) and interactions between subsystems and components may lead to unpredictable behaviors and impact on the surrounding environment and other systems in the close vicinity. Dynamic probabilistic risk assessment (DPRA) methods are possible solutions to these challenges, where the dynamic and uncertain nature of the systems is considered. The methods, however, usually face combinatorial explosion related to hazards and scenarios, which make their practical application prohibitive; in the DPRA literature, this problem is known as the state explosion problem. In this paper, we present a literature review on methods for DPRA, with focus on the existing solutions to the state explosion problem. Specifically, we analyze and compare these solutions in terms of computational time complexity, traceability and state–space coverage. Finally, we discuss the comparisons and propose potential paths to improved solutions for the state explosion problem based on the knowledge gained in the study.},
	language = {en},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Maidana, Renan G. and Parhizkar, Tarannom and Gomola, Alojz and Utne, Ingrid B. and Mosleh, Ali},
	month = feb,
	year = {2023},
	keywords = {Dynamic probabilistic risk assessment, Literature review, State explosion, Supervised DPRA},
	pages = {108889},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {ADAPT}-{MAAP4} {Coupling} for a {Dynamic} {Event} {Tree} {Study}},
	url = {https://www.researchgate.net/publication/276062439_ADAPT-MAAP4_Coupling_for_a_Dynamic_Event_Tree_Study},
	urldate = {2023-02-10},
}

@inproceedings{hofer_dynamic_2002,
	address = {Germany},
	title = {Dynamic event trees for probabilistic safety analysis},
	abstract = {In technical systems like nuclear power plants, an accident sequence starts with an
initiating event and evolves over time through the interaction of dynamics and stochastics
This interaction is capable of producing infinitely many different sequences Along
the time line they define a continuous dynamic event tree with infinitely many branch
points At each point of time, the stochastic variability of the accident consequences
is summarized by a multivariate probability distribution A probabilistic safety analysis
(PSA) requires an approximation to this distribution for selected consequence variables
It is felt that the conventional event tree analysis of Level 1 and of Level 2 PSA
does often not permit a satisfactory probabilistic representation for PSA purposes
For this reason various methods of probabilistic dynamics have been suggested over
the past decade This paper presents a recent development that combines dynamic event
tree analysis with Monte Carlo simulation The advantages of this combination are explained
and illustrated by a practical application involving MELCOR as the dynamics code (orig)},
	author = {Hofer, E. and Kloos, M. and Krzykacz-Hausmann, B. and Peschke, J. and Sonnenkalb, M.},
	year = {2002},
	note = {INIS Reference Number: 36065833},
	pages = {v},
}

@inproceedings{hakobyan_methodology_2006,
	title = {A methodology for generating dynamic accident progression event trees for level-2 {PRA}.},
	url = {https://www.semanticscholar.org/paper/A-methodology-for-generating-dynamic-accident-event-Hakobyan-Denning/7bb75c77e7443db606aecd0070e2948c319bcbd2},
	abstract = {Currently, the development and analysis of Accident Progression Event Trees (APETs) are performed in a manner that is computationally time consuming, difficult to reproduce and also can be phenomenologically inconsistent. A software tool (ADAPT) is described for automated APET generation using the concept of dynamic event trees. The tool determines the branching times from a severe accident analysis code based on user specified criteria for branching. It assigns user specified probabilities to every branch, tracks the total branch probability, and truncates branches based on the given pruning/truncation rules to avoid an unmanageable number of scenarios. While the software tool could be applied to any systems analysis code, the MELCOR code is used for this illustration. A case study is presented involving station blackout with the loss of auxiliary feedwater system for a pressurized water reactor.},
	urldate = {2023-02-10},
	author = {Hakobyan, A. and Denning, R. and Aldemir, T. and Dunagan, S. and Kunsman, D.},
	month = jul,
	year = {2006},
}

@article{cojazzi_dylam_1996,
	series = {Reliability and safety analysis of dynamic process systems},
	title = {The {DYLAM} approach for the dynamic reliability analysis of systems},
	volume = {52},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/0951832095001395},
	doi = {10.1016/0951-8320(95)00139-5},
	abstract = {In many real systems, failures occurring to the components, control failures and human interventions often interact with the physical system evolution in such a way that a simple reliability analysis, de-coupled from process dynamics, is very difficult or even impossible. In the last ten years many dynamic reliability approaches have been proposed to properly assess the reliability of these systems characterized by dynamic interactions. The DYLAM methodology, now implemented in its latest version, DYLAM-3, offers a powerful tool for integrating deterministic and failure events. This paper describes the main features of the DYLAM-3 code with reference to the classic fault-tree and event-tree techniques. Some aspects connected to the practical problems underlying dynamic event-trees are also discussed. A simple system, already analyzed with other dynamic methods is used as a reference for the numerical applications. The same system is also studied with a time-dependent fault-tree approach in order to show some features of dynamic methods vs classical techniques. Examples including stochastic failures, without and with repair, failures on demand and time dependent failure rates give an extensive overview of DYLAM-3 capabilities.},
	language = {en},
	number = {3},
	urldate = {2023-02-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Cojazzi, Giacomo},
	month = jun,
	year = {1996},
	pages = {279--296},
}

@article{neymotin_evaluation_1995,
	title = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit} 1: {Evaluation} of severe accident risk during mid-loop operations. {Main} report. {Volume} 6. {Part} 1},
	shorttitle = {Evaluation of potential severe accidents during low power and shutdown operations at {Surry}, {Unit} 1},
	url = {https://www.academia.edu/81269012/Evaluation_of_potential_severe_accidents_during_low_power_and_shutdown_operations_at_Surry_Unit_1_Evaluation_of_severe_accident_risk_during_mid_loop_operations_Main_report_Volume_6_Part_1},
	abstract = {Evaluation of potential severe accidents during low power and shutdown operations at Surry, Unit 1: Evaluation of severe accident risk during mid-loop operations. Main report. Volume 6. Part 1},
	urldate = {2023-02-10},
	author = {Neymotin, Lev},
	month = jan,
	year = {1995},
}

@incollection{cooke_fault_2001,
	address = {Cambridge},
	title = {Fault and event trees},
	isbn = {978-0-521-77320-1},
	url = {https://www.cambridge.org/core/books/probabilistic-risk-analysis/fault-and-event-trees/62A2C6C43D9D57A29D3CF9C1ABA614C4},
	abstract = {Fault and event treesFault and event trees are modeling tools used as part of a quantitative analysis of a system. Other semi-quantitative or qualitative tools such as failure modes and effects analysis (FMEA) are often performed in preparation for a more exact analysis. Such tools are outside the (quantitative) scope of this book, and the interested reader is referred to [Kumamoto and Henley, 1996], [Andrews and Moss, 1993]. These books also provide further information and more examples on fault tree modeling as does the Fault Tree Handbook [Vesely et al., 1981].Fault tree and event tree analyses are two of the basic tools in system analysis. Both methodologies give rise to a pictorial representation of a statement in Boolean logic. We shall concentrate on fault tree analysis, but briefly explain the difference in the situations modeled by event trees and fault trees.Event trees use ‘forward logic’. They begin with an initiating event (an abnormal incident) and ‘propagate’ this event through the system under study by considering all possible ways in which it can effect the behaviour of the (sub)system. The nodes of an event tree represent the possible functioning or malfunctioning of a (sub)system. If a sufficient set of such systems functions normally then the plant will return to normal operating conditions. A path through an event tree resulting in an accident is called an accident sequence.},
	urldate = {2023-02-09},
	booktitle = {Probabilistic {Risk} {Analysis}: {Foundations} and {Methods}},
	publisher = {Cambridge University Press},
	editor = {Cooke, Roger and Bedford, Tim},
	year = {2001},
	doi = {10.1017/CBO9780511813597.007},
	pages = {99--120},
}

@incollection{cooke_probabilistic_2001,
	address = {Cambridge},
	title = {Probabilistic {Risk} {Analysis} {Foundations} and {Methods}},
	isbn = {978-0-521-77320-1},
	url = {https://www.cambridge.org/core/books/probabilistic-risk-analysis/fault-and-event-trees/62A2C6C43D9D57A29D3CF9C1ABA614C4},
	abstract = {Fault and event treesFault and event trees are modeling tools used as part of a quantitative analysis of a system. Other semi-quantitative or qualitative tools such as failure modes and effects analysis (FMEA) are often performed in preparation for a more exact analysis. Such tools are outside the (quantitative) scope of this book, and the interested reader is referred to [Kumamoto and Henley, 1996], [Andrews and Moss, 1993]. These books also provide further information and more examples on fault tree modeling as does the Fault Tree Handbook [Vesely et al., 1981].Fault tree and event tree analyses are two of the basic tools in system analysis. Both methodologies give rise to a pictorial representation of a statement in Boolean logic. We shall concentrate on fault tree analysis, but briefly explain the difference in the situations modeled by event trees and fault trees.Event trees use ‘forward logic’. They begin with an initiating event (an abnormal incident) and ‘propagate’ this event through the system under study by considering all possible ways in which it can effect the behaviour of the (sub)system. The nodes of an event tree represent the possible functioning or malfunctioning of a (sub)system. If a sufficient set of such systems functions normally then the plant will return to normal operating conditions. A path through an event tree resulting in an accident is called an accident sequence.},
	urldate = {2023-02-09},
	booktitle = {Probabilistic {Risk} {Analysis}: {Foundations} and {Methods}},
	publisher = {Cambridge University Press},
	editor = {Cooke, Roger and Bedford, Tim},
	year = {2001},
	doi = {10.1017/CBO9780511813597.007},
	pages = {99--120},
}

@article{kwag_probabilistic_2017,
	title = {Probabilistic risk assessment framework for structural systems under multiple hazards using {Bayesian} statistics},
	volume = {315},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549317300584},
	doi = {10.1016/j.nucengdes.2017.02.009},
	abstract = {Conventional probabilistic risk assessment (PRA) methodologies (USNRC, 1983; IAEA, 1992; EPRI, 1994; Ellingwood, 2001) conduct risk assessment for different external hazards by considering each hazard separately and independent of each other. The risk metric for a speciﬁc hazard is evaluated by a convolution of the fragility and the hazard curves. The fragility curve for basic event is obtained by using empirical, experimental, and/or numerical simulation data for a particular hazard. Treating each hazard as an independently can be inappropriate in some cases as certain hazards are statistically correlated or dependent. Examples of such correlated events include but are not limited to ﬂooding induced ﬁre, seismically induced internal or external ﬂooding, or even seismically induced ﬁre. In the current practice, system level risk and consequence sequences are typically calculated using logic trees to express the causative relationship between events. In this paper, we present the results from a study on multi-hazard risk assessment that is conducted using a Bayesian network (BN) with Bayesian inference. The framework can consider statistical dependencies among risks from multiple hazards, allows updating by considering the newly available data/information at any level, and provide a novel way to explore alternative failure scenarios that may exist due to vulnerabilities.},
	language = {en},
	urldate = {2023-02-09},
	journal = {Nuclear Engineering and Design},
	author = {Kwag, Shinyoung and Gupta, Abhinav},
	month = apr,
	year = {2017},
	pages = {20--34},
}

@article{karanki_dynamic_2015,
	title = {A dynamic event tree informed approach to probabilistic accident sequence modeling: {Dynamics} and variabilities in medium {LOCA}},
	volume = {142},
	issn = {09518320},
	shorttitle = {A dynamic event tree informed approach to probabilistic accident sequence modeling},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015001234},
	doi = {10.1016/j.ress.2015.04.011},
	abstract = {In Probability Safety Assessments, accident scenario dynamics are addressed in the accident sequence analysis task. In an analyst-driven, iterative process, assumptions are made about equipment responses and operator actions and simulations of the scenario evolution are performed. To calculate how scenario dynamics and stochastic variabilities may affect the results of this process in terms of estimated risk, this work applies Dynamic Event Trees (DETs) to more comprehensively examine the accident scenario space. Alternative event tree models are developed and the core damage frequency is quantiﬁed to reveal the effects of different delineations of the sequences and of the bounding assumptions underlying success criteria. The results from a case study on Medium-break Loss of Coolant Accident scenarios in a Pressurized Water Reactor are presented, considering the break size, available injection trains, and the timing of rapid cooldown and the switchover to recirculation. The results show not only that estimated risk can be very sensitive to the numerous assumptions made in current accident sequence analysis but also that bounding assumptions do not always result in conservative risk estimates, thereby conﬁrming the beneﬁts that DETs provide in terms of characterizing scenario dynamics.},
	language = {en},
	urldate = {2023-02-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Karanki, Durga Rao and Kim, Tae-Wan and Dang, Vinh N.},
	month = oct,
	year = {2015},
	pages = {78--91},
}

@article{cho_quantification_2017,
	title = {Quantification of {LOCA} core damage frequency based on thermal-hydraulics analysis},
	volume = {315},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549317300791},
	doi = {10.1016/j.nucengdes.2017.02.023},
	abstract = {A loss-of-coolant accident (LOCA) has always been signiﬁcantly considered one of the most important initiating events. However, most probabilistic safety assessment models, up to now, have undoubtedly adopted the three groups of LOCA, and even an exact break size boundary that used in WASH-1400 reports was published in 1975. With an awareness of the importance of a realistic PSA for a riskinformed application, several studies have tried to ﬁnd the realistic thermal-hydraulic behavior of a LOCA, and improve the PSA model. The purpose of this research is to obtain realistic results of the LOCA core damage frequency based on a success criteria analysis using the best-estimate thermalhydraulics code. To do so, the Korea Standard Nuclear Power Plant (KSNP) was selected for this study. The MARS code was used for a thermal hydraulics analysis and the AIMS code was used for the core damage quantiﬁcation. One of the major ﬁndings in the thermal hydraulics analysis was that the decay power is well removed by only a normal secondary cooling in LOCAs of below 1.4 in and by only a high pressure safety injection in LOCAs of 0.8–9.4 in. Based on the thermal hydraulics results regarding new break size boundaries and new success criteria, ﬁve new event trees (ETs) were developed. The core damage frequency of new LOCA ETs is 5.80EÀ07 (/y), which is 12\% less than the conventional PSA ETs. In this research, we obtained not only thermal-hydraulics characteristics for the entire break size of a LOCA in view of the deterministic safety assessment, but also a more realistic core damage frequency of the LOCAs using updated information. The difference between the results of the present study and the conventional knowledge can be used to modify the current emergency operator procedures and to design another nuclear power plant type.},
	language = {en},
	urldate = {2023-02-09},
	journal = {Nuclear Engineering and Design},
	author = {Cho, Jaehyun and Park, Jin Hee and Kim, Dong-San and Lim, Ho-Gon},
	month = apr,
	year = {2017},
	pages = {77--92},
}

@article{qiu_qualitative_2018,
	series = {Knowledge-{Based} and {Intelligent} {Information} \& {Engineering} {Systems}: {Proceedings} of the 22nd {International} {Conference}, {KES}-2018, {Belgrade}, {Serbia}},
	title = {A qualitative knowledge representation model and application for crisis events},
	volume = {126},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050918313723},
	doi = {10.1016/j.procs.2018.08.094},
	abstract = {Emergency management information system requires lots of qualitative knowledge of crisis events, such as empirical knowledge, common-sense knowledge, etc., but as to the complexity of the crisis events, existing studies about qualitative knowledge have not formed systematic modeling method, and the knowledge representation model established cannot get personalized extension or their extendibility is not very well. In addition, relationships between any two crisis events cannot be supported and connected by the qualitative knowledge. Therefore, based on the system engineering point of view, this paper abstracts the common elements, that is, the ontology model of the evolutionary process of the crisis events, and creates the corresponding meta-model. Based on the above two models, by using framework structure and production rules, a personalized and extensible general qualitative knowledge representation model for crisis events is constructed, and then, according to the causal relationships between crisis events, the crisis events chain model which can realize the evolutionary process automatically is also constructed. Finally, a well-designed prototype system shows the application of the proposed model.},
	language = {en},
	urldate = {2023-02-08},
	journal = {Procedia Computer Science},
	author = {Qiu, Jiangnan and Zuo, Min and Yang, Shuning and Shi, Huayan},
	month = jan,
	year = {2018},
	keywords = {Crisis events, qualitative knowledge representation, qualitative knowledge system},
	pages = {1828--1836},
}

@article{shannon_mathematical_nodate,
	title = {A {Mathematical} {Theory} of {Communication}},
	language = {en},
	author = {Shannon, C E},
}

@article{munoz_dendros_1999,
	title = {{DENDROS}: {A} second generation scheduler for dynamic event trees},
	journal = {Mathematics and Computation, M\&C’99—Madrid},
	author = {Munoz, R and Minguez, E and Melendez, E and Izquierdo, JM and Sanchez-Perea, M},
	year = {1999},
	note = {Publisher: Senda Editorial Madrid, Spain},
	pages = {1358--1367},
}

@incollection{aldemir_automatic_1994,
	address = {Berlin, Heidelberg},
	title = {Automatic {Generation} of {Dynamic} {Event} {Trees}: {A} {Tool} for {Integrated} {Safety} {Assessment} ({ISA})},
	isbn = {978-3-642-08178-1 978-3-662-03041-7},
	shorttitle = {Automatic {Generation} of {Dynamic} {Event} {Trees}},
	url = {http://link.springer.com/10.1007/978-3-662-03041-7_10},
	language = {en},
	urldate = {2023-02-07},
	booktitle = {Reliability and {Safety} {Assessment} of {Dynamic} {Process} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Izquierdo, José M. and Hortal, Javier and Sánchez, Miguel and Meléndez, Enrique},
	editor = {Aldemir, Tunc and Siu, Nathan O. and Mosleh, Ali and Cacciabue, P. Carlo and Göktepe, B. Gül},
	year = {1994},
	doi = {10.1007/978-3-662-03041-7_10},
	pages = {135--150},
}

@techreport{ma_ccf_2022,
	title = {{CCF} {Parameter} {Estimations} 2020 {Update}},
	url = {https://www.osti.gov/biblio/1846976},
	abstract = {This report documents the quantitative results of the common-cause failure (CCF) data collection effort (which included data through 2020) and summarizes the results of the parameter estimation quantification process performed on CCF data in the U.S. Nuclear Regulatory Commission (NRC) CCF database. This is the 2020 update to NUREG/CR-5497, updating data and parameter estimations for CCFs. This release, CCF Parameter Estimation 2020, reflects the CCF data contained within the CCF database, https://rads.inl.gov/Pages/CCF.aspx, by executing (in August 2021) the CCF query rules in the folder SPAR Rules 2020. The data covers the period from 1/1/2006 to 12/31/2020, the most recent 15-year period in which data are available. The use of the most recent rolling 15-year data in parameter estimation differs from previous updates, in which 1/1/1997 was used as the starting date (e.g., 1/1/1997 to 12/31/2015 for the 2015 update, 1/1/1997 to 12/31/2012 for the 2012 update). The new date range (i.e., the most recent 15-year period), was selected for this CCF update so as to be consistent with the date range chosen for the component reliability parameter estimation, and with the effort to include sufficient data for analysis while simultaneously reflecting the most recent industry performance. These results are appropriate for use in probabilistic risk assessment (PRA) studies, including the Standardized Plant Analysis Risk (SPAR) models of commercial nuclear power plants (NPPs) in the U.S. This update may be referred as: U.S. Nuclear Regulatory Commission, "CCF Parameter Estimations, 2020 Update," https://nrcoe.inl.gov/publicdocs/CCF/ccfparamest2020.pdf, November 2021.},
	language = {English},
	number = {INL/EXT-21-62940-Rev000},
	urldate = {2023-02-07},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Ma, Zhegang and Kvarfordt, Kellie J.},
	month = feb,
	year = {2022},
	doi = {10.2172/1846976},
}

@techreport{ma_developing_2021,
	title = {Developing {Generic} {Prior} {Distributions} for {Common} {Cause} {Failure} {Alpha} {Factors} and {Causal} {Alpha} {Factors}},
	url = {https://www.osti.gov/biblio/1835896},
	abstract = {This report is a revision of the original report, INL/LTD-17-43723. Distribution of the original report was to the Nuclear Regulatory Commission (NRC) only, and the report was not made available to the public. The original report was revised as this report for public distribution. This report presents the latest update of generic prior distributions for common cause failure (CCF) alpha factors, as well as the development of new generic prior distributions for CCF causal alpha factors. The history of CCF treatment and parameter estimations is reviewed. The existing process for developing generic prior distributions is reviewed and used to develop new priors for CCF alpha factors and causal alpha factors. For causal alpha factors, different priors are developed for the five different CCF cause groups: Component (GC), Design (GD), Environment (GE), Human (GH), and Other (GO). These generic prior distributions could be used in the Standardized Plant Analysis Risk (SPAR) models for CCF parameter estimation. The issues and preliminary thoughts regarding prior distribution development are documented. Potential future work is then proposed for improving the process of developing priors.},
	language = {English},
	number = {INL/EXT-21-43723-Rev001},
	urldate = {2023-02-07},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Ma, Zhegang and Atwood, Corwin L. and Schroeder, John A.},
	month = aug,
	year = {2021},
	doi = {10.2172/1835896},
}

@techreport{noauthor_common-cause_nodate,
	title = {Common-{Cause} {Failure} {Database} and {Analysis} {System}.pdf},
	url = {https://www.nrc.gov/docs/ML0729/ML072970404.pdf},
	urldate = {2021-02-26},
}

@mastersthesis{dister_leroy_deoss_simulation_1989,
	title = {A {Simulation} {Model} for {Dynamic} {System} {Availability} {Analysis}},
	url = {https://apps.dtic.mil/sti/citations/ADA213499},
	abstract = {A dynamic Monte Carlo system availability simulation model is developed. DYMCAM is based on three fundamental modeling objectives. First, to provide the ability to analyze time-dependent availability of dynamic systems. Second, to provide a model which is easy to apply and interpret. And third, to create a model which can easily be modified to incorporate additional features as needed. The output generated by the program includes time-dependent system unavailability information and average system unavailability over the duration of the simulated time period. DYMCAM is tested on several basic availability analysis problems to demonstrate program capabilities. These tests include a single component with exponential failure and repair times, a single component with two repair states, a two-out-of-three pump failure system, and a phased mission problem requiring the forced change of a system component state after the start of the analysis. A modification of the DYMCAM program was also developed to demonstrate the capability of treating continuous process variables in a dynamic simulation model. Results were compared with analytical results where possible, and with Markovian analysis techniques in other cases. The simulation model provided accurate unavailability results on all example problems tested. Further work needs to be done to expand the capabilities of the basic DYMCAM model and to continue program testing on more complex problems. Keywords Theses Computer programs.},
	language = {en},
	urldate = {2023-02-06},
	school = {MIT},
	author = {{Dister LeRoy Deoss}},
	month = may,
	year = {1989},
	note = {Section: Technical Reports},
}

@article{marseguerra_monte_1996,
	title = {Monte {Carlo} approach to {PSA} for dynamic process systems},
	volume = {52},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209500131X},
	doi = {10.1016/0951-8320(95)00131-X},
	language = {en},
	number = {3},
	urldate = {2023-02-07},
	journal = {Reliability Engineering \& System Safety},
	author = {Marseguerra, M. and Zio, E.},
	month = jun,
	year = {1996},
	pages = {227--241},
}

@article{labeau_survey_1998,
	title = {A survey on {Monte} {Carlo} estimation of small failure risks in dynamic reliability},
	volume = {52},
	issn = {1434-8411},
	url = {http://hdl.handle.net/2013/},
	abstract = {DI-fusion, le Dépôt institutionnel numérique de l'ULB, est l'outil de référencementde la production scientifique de l'ULB.L'interface de recherche DI-fusion permet de consulter les publications des chercheurs de l'ULB et les thèses qui y ont été défendues.},
	language = {en},
	number = {3},
	urldate = {2023-02-07},
	journal = {AEÜ. International journal of electronics and communications},
	author = {Labeau, Pierre-Etienne},
	year = {1998},
	pages = {205--211},
}

@article{labeau_probabilistic_1996,
	title = {Probabilistic dynamics: {Estimation} of generalized unreliability through efficient {Monte} {Carlo} simulation},
	volume = {23},
	issn = {03064549},
	shorttitle = {Probabilistic dynamics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0306454995001204},
	doi = {10.1016/0306-4549(95)00120-4},
	language = {en},
	number = {17},
	urldate = {2023-02-07},
	journal = {Annals of Nuclear Energy},
	author = {Labeau, P.E.},
	month = nov,
	year = {1996},
	pages = {1355--1369},
}

@article{mohantyl_sensitivity_2002,
	title = {Sensitivity analysis methods for identifying influential parameters in a problem with a large number of random variables},
	abstract = {This paper compares the ranking of the ten most influential variables among a possible 330 variables for a model describing the performance of a repository for radioactive waste, using a variety of statistical and non-statistical sensitivity analysis methods. Results from the methods demonstrate substantial dissimilarities in the ranks of the most important variables. However, using a composite scoring system, several important variables appear to have been captured successfully.},
	language = {en},
	journal = {Risk Analysis III},
	author = {Mohantyl, S},
	year = {2002},
}

@book{mit_critical_data_secondary_2016,
	address = {Cham},
	title = {Secondary {Analysis} of {Electronic} {Health} {Records}},
	isbn = {978-3-319-43740-8 978-3-319-43742-2},
	url = {http://link.springer.com/10.1007/978-3-319-43742-2},
	language = {en},
	urldate = {2023-02-07},
	publisher = {Springer International Publishing},
	author = {{MIT Critical Data}},
	year = {2016},
	doi = {10.1007/978-3-319-43742-2},
}

@article{agency_progress_2014,
	title = {Progress in {Methodologies} for the {Assessment} of {Passive} {Safety} {System} {Reliability} in {Advanced} {Reactors}},
	url = {https://www.iaea.org/publications/10783/progress-in-methodologies-for-the-assessment-of-passive-safety-system-reliability-in-advanced-reactors},
	language = {en},
	urldate = {2023-02-06},
	journal = {Progress in Methodologies for the Assessment of Passive Safety System Reliability in Advanced Reactors},
	author = {Agency, International Atomic Energy},
	year = {2014},
	note = {Publisher: IAEA},
}

@article{tombuyses_continuous_1997,
	title = {{CONTINUOUS} {CELL}-{TO}-{CELL} {MAPPING}},
	volume = {202},
	issn = {0022460X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022460X96908354},
	doi = {10.1006/jsvi.1996.0835},
	language = {en},
	number = {3},
	urldate = {2023-02-06},
	journal = {Journal of Sound and Vibration},
	author = {Tombuyses, B. and Aldemir, T.},
	month = may,
	year = {1997},
	pages = {395--415},
}

@article{cacciabue_dynamic_1986,
	title = {Dynamic {Logical} {Analytical} {Methodology} {Versus} {Fault} {Tree}: {The} {Case} {Study} of the {Auxiliary} {Feedwater} {System} of a {Nuclear} {Power} {Plant}},
	volume = {74},
	issn = {0029-5450, 1943-7471},
	shorttitle = {Dynamic {Logical} {Analytical} {Methodology} {Versus} {Fault} {Tree}},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT86-A33804},
	doi = {10.13182/NT86-A33804},
	language = {en},
	number = {2},
	urldate = {2023-02-05},
	journal = {Nuclear Technology},
	author = {Cacciabue, P. C. and Amendola, A. and Cojazzi, G.},
	month = aug,
	year = {1986},
	pages = {195--208},
}

@article{kumamoto_top-down_1978,
	title = {Top-down {Algorithm} for {Obtaining} {Prime} {Implicant} {Sets} of {Non}-{Coherent} {Fault} {Trees}},
	volume = {R-27},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/5220351/},
	doi = {10.1109/TR.1978.5220351},
	number = {4},
	urldate = {2023-02-05},
	journal = {IEEE Transactions on Reliability},
	author = {Kumamoto, Hiromitsu and Henley, Ernest J.},
	month = oct,
	year = {1978},
	pages = {242--249},
}

@article{pk_fault_1981,
	title = {{FAULT} {TREES} {AND} {FAILURE} {ANALYSES}: {DISCRETE} {STATE} {REPRESENTATION} {PROBLEMS}},
	volume = {59},
	language = {English},
	number = {0046-9858},
	journal = {TRANS. INST. CHEM. ENG},
	author = {PK, ANDOW},
	year = {1981},
	pages = {125--128},
}

@article{kumamoto_safety_1979,
	title = {Safety and reliability synthesis of systems with control loops},
	volume = {25},
	issn = {0001-1541, 1547-5905},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/aic.690250112},
	doi = {10.1002/aic.690250112},
	language = {en},
	number = {1},
	urldate = {2023-02-05},
	journal = {AIChE Journal},
	author = {Kumamoto, Hiromitsu and Henley, Ernest J.},
	month = jan,
	year = {1979},
	pages = {108--113},
}

@techreport{gonzalez_regulatory_2022,
	address = {Washington, D.C. (USA)},
	type = {Notice},
	title = {Regulatory {Guide} 1.247, "{Acceptability} of {Probabilistic} {Risk} {Assessment} {Results} for {Advanced} {Non}-{Light} {Water} {Reactor} {Risk}-{Informed} {Activities}"},
	shorttitle = {{RG} 1.2467},
	abstract = {RG 1.247 is acceptable for release on a trial basis. It would be beneficial if the staff could modify it as suggested in our report at this time. However, we would not object to delaying the improvements for the final version, if such changes would lead to substantial delay in its issuance for trial use. Lessons learned from the trial applications will be important and we look forward to continuing interactions with the staff.},
	language = {en},
	institution = {Nuclear Regulatory Commission},
	author = {Gonzalez, Michelle},
	month = mar,
	year = {2022},
	pages = {16770--16772},
}

@book{noauthor_probabilistic_2021,
	title = {Probabilistic {Risk} {Assessment} {Standard} for {Advanced} {Non}-{Light} {Water} {Reactor} {Nuclear} {Power} {Plants}},
	isbn = {978-0-7918-7437-0},
	url = {https://www.asme.org/codes-standards/find-codes-standards/ra-s-1-4-probabilistic-risk-assessment-standard-advanced-non-light-water-reactor-nuclear-power-plants/2021/drm-enabled-pdf},
	abstract = {ASME/ANS RA-S-1.4 - 2021 is a joint ASME/American Nuclear Society (ANS) standard that provides requirements for Probabilistic Risk Assessment (PRAs) used to support risk-informed decisions in commercial nuclear power plants. It prescribes a method for applying these requirements for specific applications in Advanced non-Light Water Reactor Nuclear Power Plants.},
	publisher = {ASME Press},
	year = {2021},
}

@article{national_archives_and_records_administration_office_of_the_federal_register_use_1995,
	series = {Notices},
	title = {Use of {Probabilistic} {Risk} {Assessment} {Methods} in {Nuclear} {Regulatory} {Activities}; {Final} {Policy} {Statement}. {Notices}},
	volume = {60},
	issn = {0097-6326, 0042-1219, 0364-1406},
	url = {https://www.govinfo.gov/app/details/FR-1995-08-16/95-20237},
	abstract = {This statement presents the policy that the Nuclear Regulatory Commission (NRC) will follow in the use of probabilistic risk assessment (PRA) methods in nuclear regulatory matters. The Commission believes that an overall policy on the use of PRA methods in nuclear regulatory activities should be established so that the many potential applications of PRA can be implemented in a consistent and predictable manner that would promote regulatory stability and efficiency. In addition, the Commission believes that the use of PRA technology in NRC regulatory activities should be increased to the extent supported by the state-of-the-art in PRA methods and data and in a manner that complements the NRC's deterministic approach. The pertinent comments received from the published draft policy statement are reflected in this final policy statement. This policy statement will be implemented through the execution of the NRC's PRA Implementation Plan.},
	language = {eng},
	number = {158},
	urldate = {2023-02-04},
	journal = {Federal Register. Vol. 60, no. 158},
	author = {{National Archives and Records Administration: Office of the Federal Register} and {Nuclear Regulatory Commission}},
	month = aug,
	year = {1995},
	note = {Publisher: Office of the Federal Register, National Archives and Records Administration},
	pages = {42425--42766},
}

@article{smith_saphire_nodate,
	title = {{SAPHIRE} 8 {Advanced} {Workbook}},
	language = {en},
	author = {Smith, Curtis and Knudsen, James and Vedros, Kurt and Wood, Ted},
}

@article{smith_saphire_nodate-1,
	title = {{SAPHIRE} 8 {Advanced} {Workbook}},
	language = {en},
	author = {Smith, Curtis and Knudsen, James and Vedros, Kurt and Wood, Ted},
}

@techreport{perumalla_computer_2022,
	title = {Computer {Science} {Research} {Needs} for {Parallel} {Discrete} {Event} {Simulation} ({PDES})},
	url = {https://www.osti.gov/servlets/purl/1855247/},
	language = {en},
	number = {None, 1855247},
	urldate = {2023-02-03},
	author = {Perumalla, Kalyan and Bremer, Maximilian and Brown, Kevin and Chan, Cy and Eidenbenz, Stephan and Hemmert, K. Scott and Hoisie, Adolfy and Newton, Benjamin and Nutaro, James and Oppelstrup, Tomas and Ross, Robert and Schordan, Markus and Urban, Nathan},
	month = may,
	year = {2022},
	doi = {10.2172/1855247},
	pages = {None, 1855247},
}

@inproceedings{hess_risk-informed_2009,
	address = {Brussels, Belgium},
	title = {Risk-{Informed} {Safety} {Margin} {Characterization}},
	isbn = {978-0-7918-4351-2 978-0-7918-3852-5},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE17/43512/11/339352},
	doi = {10.1115/ICONE17-75064},
	abstract = {The concept of safety margins has served as a fundamental principle in the design and operation of commercial nuclear power plants (NPPs). Defined as the minimum distance between a system’s “loading” and its “capacity”, plant design and operation is predicated on ensuring an adequate safety margin for safety-significant parameters (e.g., fuel cladding temperature, containment pressure, etc.) is provided over the spectrum of anticipated plant operating, transient and accident conditions. To meet the anticipated challenges associated with extending the operational lifetimes of the current fleet of operating NPPs, the United States Department of Energy (USDOE), the Idaho National Laboratory (INL) and the Electric Power Research Institute (EPRI) have developed a collaboration to conduct coordinated research to identify and address the technological challenges and opportunities that likely would affect the safe and economic operation of the existing NPP fleet over the postulated long-term time horizons. In this paper we describe a framework for developing and implementing a Risk-Informed Safety Margin Characterization (RISMC) approach to evaluate and manage changes in plant safety margins over long time horizons.},
	language = {en},
	urldate = {2023-02-03},
	booktitle = {Volume 1: {Plant} {Operations}, {Maintenance}, {Engineering}, {Modifications} and {Life} {Cycle}; {Component} {Reliability} and {Materials} {Issues}; {Next} {Generation} {Systems}},
	publisher = {ASMEDC},
	author = {Hess, Stephen M. and Dinh, Nam and Gaertner, John P. and Szilard, Ronaldo},
	month = jan,
	year = {2009},
	pages = {11--17},
}

@article{dhulipala_seismic_2021,
	title = {Seismic {Risk} {Assessment} of {Safety}-{Critical} {Nuclear} {Facilities} for the {Purpose} of {Risk}-{Informed} {Periodic} {Reevaluation}},
	volume = {207},
	issn = {0029-5450},
	url = {https://doi.org/10.1080/00295450.2020.1792743},
	doi = {10.1080/00295450.2020.1792743},
	abstract = {Following U.S. Department of Energy Order 420.1 C for the mitigation of natural phenomena hazards, such as earthquakes, to nuclear facilities through periodic reassessments, Idaho National Laboratory (INL) has developed the Seismic Hazard Periodic Re-Evaluation Methodology (SHPRM). The SHPRM involves seven criteria that evaluate changes to the seismic hazard at a site due to changes in the input models/data over time. Should these changes to the seismic hazard result in an increase in the design or licensing-basis ground motion of the facility from that which the facility was designed for, the SHPRM includes a criterion for reevaluating the facility risk objectives. While the criteria corresponding to the reevaluation of the seismic hazard and the design basis have been previously demonstrated and published, there is currently no guidance on reevaluating seismic risk for the purpose of SHPRM. This paper complements the published reports and papers on the application of SHPRM by demonstrating the risk objectives criterion for a generic nuclear facility (GNF), thereby closing the loop on the application of the SHPRM. The GNF is assumed to be located at the INL site and designated as a Seismic Design Category-3 facility as per American Society of Civil Engineers (ASCE)/Structural Engineering Institute (SEI) 43-05. The demonstration includes a risk assessment for a baseline seismic hazard calculated in 2006 and an updated seismic hazard calculated in 2015. After presenting the baseline and the updated seismic hazard curves at this site, the state-of-practice methodology for calculating fragility functions for the facility is presented, along with the fragilities calculated for the GNF. Employing a fault tree analysis using the INL in-house seismic analysis and risk assessment software MASTODON, the seismic risks of collapse of the GNF for the baseline and updated seismic hazards are computed to be 5.27E−05 and 5.2E−06, respectively. The results show that not only the reevaluated seismic risk is smaller, but more importantly, that it meets the risk objectives set by ASCE/SEI 43-05.},
	number = {11},
	urldate = {2023-02-03},
	journal = {Nuclear Technology},
	author = {Dhulipala, Somayajulu L. N. and Bolisetti, Chandrakanth and Yorg, Richard and Hashimoto, Philip and Coleman, Justin L. and Cox, Mark},
	month = nov,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295450.2020.1792743},
	keywords = {Seismic risk assessment, natural hazards risk assessment, seismic fragility analysis, seismic reevaluation},
	pages = {1712--1724},
}

@article{dhulipala_seismic_2021-1,
	title = {Seismic {Risk} {Assessment} of {Safety}-{Critical} {Nuclear} {Facilities} for the {Purpose} of {Risk}-{Informed} {Periodic} {Reevaluation}},
	volume = {207},
	issn = {0029-5450},
	url = {https://doi.org/10.1080/00295450.2020.1792743},
	doi = {10.1080/00295450.2020.1792743},
	abstract = {Following U.S. Department of Energy Order 420.1 C for the mitigation of natural phenomena hazards, such as earthquakes, to nuclear facilities through periodic reassessments, Idaho National Laboratory (INL) has developed the Seismic Hazard Periodic Re-Evaluation Methodology (SHPRM). The SHPRM involves seven criteria that evaluate changes to the seismic hazard at a site due to changes in the input models/data over time. Should these changes to the seismic hazard result in an increase in the design or licensing-basis ground motion of the facility from that which the facility was designed for, the SHPRM includes a criterion for reevaluating the facility risk objectives. While the criteria corresponding to the reevaluation of the seismic hazard and the design basis have been previously demonstrated and published, there is currently no guidance on reevaluating seismic risk for the purpose of SHPRM. This paper complements the published reports and papers on the application of SHPRM by demonstrating the risk objectives criterion for a generic nuclear facility (GNF), thereby closing the loop on the application of the SHPRM. The GNF is assumed to be located at the INL site and designated as a Seismic Design Category-3 facility as per American Society of Civil Engineers (ASCE)/Structural Engineering Institute (SEI) 43-05. The demonstration includes a risk assessment for a baseline seismic hazard calculated in 2006 and an updated seismic hazard calculated in 2015. After presenting the baseline and the updated seismic hazard curves at this site, the state-of-practice methodology for calculating fragility functions for the facility is presented, along with the fragilities calculated for the GNF. Employing a fault tree analysis using the INL in-house seismic analysis and risk assessment software MASTODON, the seismic risks of collapse of the GNF for the baseline and updated seismic hazards are computed to be 5.27E−05 and 5.2E−06, respectively. The results show that not only the reevaluated seismic risk is smaller, but more importantly, that it meets the risk objectives set by ASCE/SEI 43-05.},
	number = {11},
	urldate = {2023-02-03},
	journal = {Nuclear Technology},
	author = {Dhulipala, Somayajulu L. N. and Bolisetti, Chandrakanth and Yorg, Richard and Hashimoto, Philip and Coleman, Justin L. and Cox, Mark},
	month = nov,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295450.2020.1792743},
	keywords = {Seismic risk assessment, natural hazards risk assessment, seismic fragility analysis, seismic reevaluation},
	pages = {1712--1724},
}

@article{budnitz_current_1998,
	title = {Current status of methodologies for seismic probabilistic safety analysis},
	volume = {62},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832097001580},
	doi = {10.1016/S0951-8320(97)00158-0},
	language = {en},
	number = {1-2},
	urldate = {2023-02-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Budnitz, Robert J},
	month = oct,
	year = {1998},
	pages = {71--88},
}

@inproceedings{hejase_dynamic_2018,
	address = {Kissimmee, Florida},
	title = {Dynamic {Probabilistic} {Risk} {Assessment} of {Unmanned} {Aircraft} {Adaptive} {Flight} {Control} {Systems}},
	isbn = {978-1-62410-527-2},
	url = {https://arc.aiaa.org/doi/10.2514/6.2018-1982},
	doi = {10.2514/6.2018-1982},
	language = {en},
	urldate = {2023-02-02},
	booktitle = {2018 {AIAA} {Information} {Systems}-{AIAA} {Infotech} @ {Aerospace}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Hejase, Mohammad and Kurt, Arda and Aldemir, Tunc and Ozguner, Umit and Guarro, Sergio and Yau, Michael K. and Knudson, Matt},
	month = jan,
	year = {2018},
}

@incollection{aldemir_probabilistic_1994,
	address = {Berlin, Heidelberg},
	title = {Probabilistic {Dynamics} : {The} {Mathematical} and {Computing} {Problems} {Ahead}},
	isbn = {978-3-642-08178-1 978-3-662-03041-7},
	shorttitle = {Probabilistic {Dynamics}},
	url = {http://link.springer.com/10.1007/978-3-662-03041-7_7},
	language = {en},
	urldate = {2023-02-02},
	booktitle = {Reliability and {Safety} {Assessment} of {Dynamic} {Process} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Devooght, Jacques and Smidts, Carol},
	editor = {Aldemir, Tunc and Siu, Nathan O. and Mosleh, Ali and Cacciabue, P. Carlo and Göktepe, B. Gül},
	year = {1994},
	doi = {10.1007/978-3-662-03041-7_7},
	pages = {85--100},
}

@article{maidana_supervised_2023-2,
	title = {Supervised dynamic probabilistic risk assessment: {Review} and comparison of methods},
	volume = {230},
	issn = {09518320},
	shorttitle = {Supervised dynamic probabilistic risk assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022005063},
	doi = {10.1016/j.ress.2022.108889},
	language = {en},
	urldate = {2023-02-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Maidana, Renan G. and Parhizkar, Tarannom and Gomola, Alojz and Utne, Ingrid B. and Mosleh, Ali},
	month = feb,
	year = {2023},
	pages = {108889},
}

@article{alfonsi_risk_2022,
	title = {Risk analysis virtual {ENvironment} for dynamic event tree-based analyses},
	volume = {165},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921006307},
	doi = {10.1016/j.anucene.2021.108754},
	language = {en},
	urldate = {2023-02-02},
	journal = {Annals of Nuclear Energy},
	author = {Alfonsi, Andrea and Mandelli, Diego and Parisi, Carlo and Rabiti, Cristian},
	month = jan,
	year = {2022},
	pages = {108754},
}

@article{antonello_methodology_2022,
	title = {A methodology to perform dynamic risk assessment using system theory and modeling and simulation: {Application} to nuclear batteries},
	volume = {228},
	issn = {09518320},
	shorttitle = {A methodology to perform dynamic risk assessment using system theory and modeling and simulation},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022003921},
	doi = {10.1016/j.ress.2022.108769},
	language = {en},
	urldate = {2023-02-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Antonello, Federico and Buongiorno, Jacopo and Zio, Enrico},
	month = dec,
	year = {2022},
	pages = {108769},
}

@article{devooght_probabilistic_1992,
	title = {Probabilistic {Reactor} {Dynamics}—{I}: {The} {Theory} of {Continuous} {Event} {Trees}},
	volume = {111},
	issn = {0029-5639, 1943-748X},
	shorttitle = {Probabilistic {Reactor} {Dynamics}—{I}},
	url = {https://www.tandfonline.com/doi/full/10.13182/NSE92-A23937},
	doi = {10.13182/NSE92-A23937},
	language = {en},
	number = {3},
	urldate = {2023-02-02},
	journal = {Nuclear Science and Engineering},
	author = {Devooght, J. and Smidts, C.},
	month = jul,
	year = {1992},
	pages = {229--240},
}

@article{siu_dynamic_1990,
	title = {Dynamic accident sequence analysis in {PRA}: {A} comment on ‘{Human} reliability analysis—{Where} shoudst thou turn?’},
	volume = {29},
	issn = {09518320},
	shorttitle = {Dynamic accident sequence analysis in {PRA}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209090019J},
	doi = {10.1016/0951-8320(90)90019-J},
	language = {en},
	number = {3},
	urldate = {2023-02-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Siu, N.},
	month = jan,
	year = {1990},
	pages = {359--364},
}

@mastersthesis{wiltbank_dynamic_2022,
	title = {Dynamic {Probabilistic} {Risk} {Assessment} {Using} {ADAPT}/{RELAP5}-{3D} for {Cybersecurity} {Threat} {Analysis}},
	url = {http://id.loc.gov/vocabulary/iso639-2/eng},
	language = {English},
	school = {Oregon State University},
	author = {Wiltbank, Nathan E.},
	collaborator = {Camille, Palmer J.},
	month = jun,
	year = {2022},
	note = {Type: Masters Thesis},
}

@article{bolbot_vulnerabilities_2019,
	title = {Vulnerabilities and safety assurance methods in {Cyber}-{Physical} {Systems}: {A} comprehensive review},
	volume = {182},
	issn = {09518320},
	shorttitle = {Vulnerabilities and safety assurance methods in {Cyber}-{Physical} {Systems}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018302709},
	doi = {10.1016/j.ress.2018.09.004},
	language = {en},
	urldate = {2023-02-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Bolbot, Victor and Theotokatos, Gerasimos and Bujorianu, Luminita Manuela and Boulougouris, Evangelos and Vassalos, Dracos},
	month = feb,
	year = {2019},
	pages = {179--193},
}

@article{aldemir_computer-assisted_1987,
	title = {Computer-{Assisted} {Markov} {Failure} {Modeling} of {Process} {Control} {Systems}},
	volume = {R-36},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/5222318/},
	doi = {10.1109/TR.1987.5222318},
	number = {1},
	urldate = {2023-02-02},
	journal = {IEEE Transactions on Reliability},
	author = {Aldemir, Tunc},
	month = apr,
	year = {1987},
	pages = {133--144},
}

@incollection{aldemir_probabilistic_1994-1,
	address = {Berlin, Heidelberg},
	title = {Probabilistic {Dynamics} : {The} {Mathematical} and {Computing} {Problems} {Ahead}},
	isbn = {978-3-642-08178-1 978-3-662-03041-7},
	shorttitle = {Probabilistic {Dynamics}},
	url = {http://link.springer.com/10.1007/978-3-662-03041-7_7},
	language = {en},
	urldate = {2023-02-02},
	booktitle = {Reliability and {Safety} {Assessment} of {Dynamic} {Process} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Devooght, Jacques and Smidts, Carol},
	editor = {Aldemir, Tunc and Siu, Nathan O. and Mosleh, Ali and Cacciabue, P. Carlo and Göktepe, B. Gül},
	year = {1994},
	doi = {10.1007/978-3-662-03041-7_7},
	pages = {85--100},
}

@article{siu_risk_1994,
	title = {Risk assessment for dynamic systems: {An} overview},
	volume = {43},
	issn = {09518320},
	shorttitle = {Risk assessment for dynamic systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832094900957},
	doi = {10.1016/0951-8320(94)90095-7},
	language = {en},
	number = {1},
	urldate = {2023-02-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Siu, N.},
	month = jan,
	year = {1994},
	pages = {43--73},
}

@article{nielsen_optimization_2014,
	title = {Optimization method to branch-and-bound large {SBO} state spaces under dynamic probabilistic riskassessment via use of {LENDIT} scales and {S2R2} sets},
	volume = {51},
	abstract = {Traditional probabilistic risk assessment (PRA) methods have been developed to evaluate risk associatedwith complex systems; however, PRA methods lack the capability to evaluate complex dynamic systems. Inthese systems, time and energy scales associated with transient events may vary as a function of transitiontimes and energies to arrive at a different physical state. Dynamic PRA (DPRA) methods provide a morerigorous analysis of complex dynamic systems. Unfortunately DPRA methods introduce issues associatedwith combinatorial explosion of states. In order to address this combinatorial complexity, a branch-and-bound optimization technique is applied to the DPRA formalism to control the combinatorial state ex-plosion. In addition, a new characteristic scaling metric (LENDIT – length, energy, number, distribution,information and time) is proposed as linear constraints that are used to guide the branch-and-bound algo-rithm to limit the number of possible states to be analyzed. The LENDIT characterization is divided intofour groups or sets – ‘state, system, resource and response’ (S2R2) – describing reactor operations (normaland off-normal). In this paper we introduce the branch-and-bound DPRA approach and the applicationof LENDIT scales and S2R2 sets to a station blackout (SBO) transient.},
	number = {10},
	journal = {Journal of Nuclear Science and Technology},
	author = {Nielsen, Joseph and Tokuhiro, Akira and Hiromoto, Robert and Khatry, Jivan},
	year = {2014},
	pages = {1212--1230},
}

@article{irvana_risk_2020,
	title = {Risk {Assessment} {Shipping} {Accident} of {Fishing} {Vessel}},
	volume = {557},
	issn = {1755-1307, 1755-1315},
	url = {https://iopscience.iop.org/article/10.1088/1755-1315/557/1/012028},
	doi = {10.1088/1755-1315/557/1/012028},
	abstract = {The fisheries industry continues to be one of the main contributors to economic growth. The Ministry of Maritime Affairs and Fisheries Republic of Indonesia reports that the total capture fisheries production rises every year. In 2016 it was recorded to produce 6.83 million tons. Comparison of safety records from the fishing industry with other industrial sectors shows that it continues to be the most dangerous occupation with a sizeable margin. The safety and efficiency of fishing vessel fleet activities is highly dependent on the quality of management decisions. The causal relationships from accidents involving fishing vessels are identified through an analysis of emergencies and fishing incidents. The purpose of this study is to improve the safety of shipping by applying the risk of accidents of fishing vessel by using Formal Safety Assessment (FSA) methodology. The result show that Mechanical failure has a highest risk followed by Vessel Foundering, Falling Overboard and Other. With the right control measure the cost can be minimized 10 – 50 \%. The cause of accident is caused by human factor. Increasing the safety of the shipping is necessary with increase the competence of human and law enforcement of shipping activities especially.},
	language = {en},
	number = {1},
	urldate = {2023-02-02},
	journal = {IOP Conference Series: Earth and Environmental Science},
	author = {Irvana, R and Fadillah, A and Manullang, S},
	month = aug,
	year = {2020},
	pages = {012028},
}

@article{alsuwaidi_studies_2021,
	title = {Studies on the optimal mitigation strategy of extended {SBO} for the isolated multi-unit {NPP} site},
	volume = {164},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921004916},
	doi = {10.1016/j.anucene.2021.108615},
	abstract = {The Nuclear Power Plant in the isolated Multi-Unit site eventually reaches the core damage if it undergoes the extended Station Blackout with the depletion of available resources. However, the coping time can be maximized by the optimal strategy with proper operator’s actions so that the operator can prepare further mitigation action to prevent core damage. The resources-based mitigation strategy framework was developed from the insights of the probabilistic model and deterministic model, which consider monitoring of plant conditions, available decay heat removal systems, available power sources, and water sources depending on the time. The maximum coping time is estimated for various cases with MARSKS1.4 code for APR1400 and combined with a corresponding probabilistic model for each accident sequence based on the accident conditions and the resources with additional human actions.},
	language = {en},
	urldate = {2023-02-02},
	journal = {Annals of Nuclear Energy},
	author = {Alsuwaidi, Jamila Khamis and Kang, Hyun Gook and Yoon, Ho Joon},
	month = dec,
	year = {2021},
	pages = {108615},
}

@misc{noauthor_bwx_nodate,
	title = {{BWX} {Technologies}, {Inc}. {\textbar} {People} {Strong}, {Innovation} {Driven}},
	url = {http://www.bwxt.com/news},
	abstract = {BWX Technologies, Inc. is a leading supplier of nuclear components and fuel to the U.S. government, also providing components and services to the commercial nuclear power industry.},
	language = {en},
	urldate = {2023-02-01},
}

@article{zhang_common_2017,
	title = {Common cause failure model updating for risk monitoring in nuclear power plants based on alpha factor model},
	volume = {231},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X16689542},
	doi = {10.1177/1748006X16689542},
	abstract = {Common cause failure model updating (both qualitatively and quantitatively) is a key factor in risk monitoring for nuclear power plants when configuration changes (e.g. components become unavailable) occur among a redundant configuration. This research focuses on the common cause failure updating based on the alpha factor model method, which is commonly used in the living probabilistic safety assessment models for nuclear power plant risk monitoring. This article first discusses the common cause failure model updating in an ideal condition, which evaluates the common cause failure model parameters for the configurationally changed system in different ways, based on the causes of the detected failures. Then, two alternative updating processes are proposed considering the difficulty to identify failure causes immediately during plant operation: one is to update the common cause failure models with the assumption that the failures detected are independent failures and the other is to update the common cause failure models with the parameters as expectations of the values for all possible failure causes. Finally, a case study is given to illustrate the common cause failure updating process and to compare these two alternative processes. The results show that (1) common cause failures can be reevaluated automatically by the methods proposed in this article and (2) the second process is more conservative and reasonable but with more data requirements compared with the first approach. Considering limitations in accessibility of the data, the first strategy is suggested currently. More future work on data acquisition is demanded for better assessment of common cause failures during nuclear power plant risk monitoring.},
	language = {en},
	number = {3},
	urldate = {2023-01-31},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Zhang, Min and Zhang, Zhijian and Mosleh, Ali and Chen, Sijuan},
	month = jun,
	year = {2017},
	pages = {209--220},
}

@article{strategic_capabilities_office_record_2022,
	title = {Record of {Decision} for the {Final} {Construction} and {Demonstration} of a {Prototype} {Mobile} {Microreactor} {Environmental} {Impact} {Statement}},
	volume = {87},
	number = {73},
	journal = {Federal Register},
	author = {{Strategic Capabilities Office}},
	month = apr,
	year = {2022},
}

@misc{noauthor_fuel_nodate,
	title = {Fuel {Qualification} {Guidance} for {TRi}-structural {ISOtropic} ({TRISO}) {Fuel}},
	url = {https://www.nrc.gov/reactors/new-reactors/advanced/rulemaking-and-guidance/fuel-qualification/triso-fuel.html},
	language = {en-US},
	urldate = {2023-01-31},
	journal = {NRC Web},
}

@techreport{park_evaluation_1993,
	title = {Evaluation of severe accident risks, {Zion}, {Unit} 1: {Appendices} {B}, {C}, {D}, and {E}. {Volume} 7, {Revision} 1, {Part} {2B}},
	shorttitle = {Evaluation of severe accident risks, {Zion}, {Unit} 1},
	url = {https://www.osti.gov/biblio/10142375},
	abstract = {In support of the Nuclear Regulatory Commission`s (NRC`s) assessment of this risk from severe accidents at commercial nuclear power plants in the US reported in NUREG-1150, revised calculation of the risk to the general public from severe accidents at the Zion Power Station, Unit 1 has been completed. This power plant, located on the western shore of the Lake Michigan on the outskirts of Zion, is operated by the Commonwealth Edison Company. The emphasis in this risk analysis was not on determining a ``so-called`` point estimate of risk. Rather, it was to determine the distribution of risk, and to discover the uncertainties that account for the breadth of this distribution. Off-site risk initiation by events, both internal to the power station and external to the power station was assessed. This document, Vol. 7, Rev. 1, Part 2B contains appendices B, C, D, and E.},
	language = {English},
	number = {NUREG/CR-4551-Vol.7-Rev.1-Pt.2B; BNL-NUREG-52029-Vol.7-Rev.1-Pt.2B},
	urldate = {2023-01-31},
	institution = {Nuclear Regulatory Commission, Washington, DC (United States). Div. of Safety Issue Resolution; Brookhaven National Lab., Upton, NY (United States); National Tsing Hua Univ., Hsinchu (Taiwan, Province of China). Dept. of Nuclear Engineering},
	author = {Park, C. K. and Cazzoli, E. G. and Grimshaw, C. A. and Tingle, A. and Pratt, W. T. and Lee, M.},
	month = mar,
	year = {1993},
}

@misc{noauthor_title_nodate,
	title = {Title 10 of the {Code} of {Federal} {Regulations} (10 {CFR}) {PART} 100—{REACTOR} {SITE} {CRITERIA}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part100/index.html},
	language = {en-US},
	urldate = {2023-01-30},
	journal = {NRC Web},
}

@article{zhou_multi-unit_2021,
	title = {Multi-unit nuclear power plant probabilistic risk assessment: {A} comprehensive survey},
	volume = {213},
	issn = {09518320},
	shorttitle = {Multi-unit nuclear power plant probabilistic risk assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832021003070},
	doi = {10.1016/j.ress.2021.107782},
	abstract = {A growing concern regarding probabilistic risk assessments (PRA) is the impact of dependencies among reactor units co-located at a nuclear power site, especially after the March 2011 Fukushima Daiichi accident. To address these dependencies and identify the critical contributors to the entire site risk, multi-unit probabilistic risk assessment (MUPRA) has been actively developed by various research and regulatory agencies. However, possible inter-unit dependencies in MUPRA have led to some technical issues and challenges associated with the development and modeling of initiating events, accident sequences, end states, and risk metrics relevant to multiunit sites. This paper provides a comprehensive survey and assessment of the state of current knowledge in MUPRA. The critical recent literature is synthesized and discussed, focusing on three facets: multi-unit event characterization, MUPRA methodological development, and site-based risk metrics and risk aggregation. This survey aims to identify the key issues addressed and challenges faced by the research and development activities of MUPRA, and identifies gaps and opportunities for future research and developments.},
	language = {en},
	urldate = {2023-01-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Zhou, Taotao and Modarres, Mohammad and Droguett, Enrique López},
	month = sep,
	year = {2021},
	pages = {107782},
}

@article{kumar_integrated_2015,
	title = {Integrated risk assessment for multi-unit {NPP} sites—{A} comparison},
	volume = {293},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549315003416},
	doi = {10.1016/j.nucengdes.2015.06.025},
	language = {en},
	urldate = {2023-01-29},
	journal = {Nuclear Engineering and Design},
	author = {Kumar, C. Senthil and Hassija, Varun and Velusamy, K. and Balasubramaniyan, V.},
	month = nov,
	year = {2015},
	pages = {53--62},
}

@article{le_duy_probabilistic_2016,
	title = {Probabilistic {Safety} {Assessment} of twin-unit nuclear sites: {Methodological} elements},
	volume = {145},
	issn = {09518320},
	shorttitle = {Probabilistic {Safety} {Assessment} of twin-unit nuclear sites},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015002161},
	doi = {10.1016/j.ress.2015.07.014},
	abstract = {When assessing the risk related to Nuclear Power Plants in terms of impacts on the population health and on the environment, multi units issues should be taken into account. Generally speaking, to date mainly models relating to a single unit have been developed by operators. The purpose of this paper is to present possible solutions or methodological options, suggested by EDF (Electricity of France) R\&D, in order to switch from a risk assessment for the unit to a risk assessment for the site. The case of a site with two units is addressed here. A review of practices and standards showed that the speciﬁc aim of a PSA at site level was to deal with the dependencies existing between the units on that site. The risk calculation for the site is therefore proposed for six conﬁgurations resulting from the combination of two types of scenarios and three types of systems which are deﬁned. The treatment of CCF events and the adaption of the assessment of the Human Errors Probabilities to the case of multiple units are also addressed in this paper. The proposed approach is illustrated using a simpliﬁed case inspired by the EDF 900 MWe units level 1 PSA model.},
	language = {en},
	urldate = {2023-01-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Le Duy, Tu Duong and Vasseur, Dominique and Serdet, Emmanuel},
	month = jan,
	year = {2016},
	pages = {250--261},
}

@incollection{noauthor_origen_nodate,
	title = {{ORIGEN} 2.1},
	url = {https://ocw.mit.edu/courses/22-251-systems-analysis-of-the-nuclear-fuel-cycle-fall-2009/a01281aff8acc20475ecb35555f2ffbf_MIT22_251F09_ORIGEN.pdf},
	urldate = {2023-01-27},
	booktitle = {22.351 {Systems} {Analysis} of the {Nuclear} {Fuel} {Cycle}},
}

@techreport{sailor_severe_1987,
	title = {Severe accidents in spent fuel pools in support of generic safety, {Issue} 82},
	url = {https://www.osti.gov/biblio/6135335},
	abstract = {This investigation provides an assessment of the likelihood and consequences of a severe accident in a spent fuel storage pool - the complete draining of the pool. Potential mechanisms and conditions for failure of the spent fuel, and the subsequent release of the fission products, are identified. Two older PWR and BWR spent fuel storage pool designs are considered based on a preliminary screening study which tried to identify vulnerabilities. Internal and external events and accidents are assessed. Conditions which could lead to failure of the spent fuel Zircaloy cladding as a result of cladding rupture or as a result of a self-sustaining oxidation reaction are presented. Propagation of a cladding fire to older stored fuel assemblies is evaluated. Spent fuel pool fission product inventory is estimated and the releases and consequences for the various cladding scenarios are provided. Possible preventive or mitigative measures are qualitatively evaluated. The uncertainties in the risk estimate are large, and areas where additional evaluations are needed to reduce uncertainty are identified.},
	language = {English},
	number = {NUREG/CR-4982; BNL-NUREG-52093},
	urldate = {2023-01-26},
	institution = {Brookhaven National Lab. (BNL), Upton, NY (United States); Nuclear Regulatory Commission, Washington, DC (USA). Div. of Reactor and Plant Systems},
	author = {Sailor, V. L. and Perkins, K. R. and Weeks, J. R. and Connell, H. R.},
	month = jul,
	year = {1987},
	doi = {10.2172/6135335},
}

@techreport{noauthor_population-related_2019,
	type = {{NRC} {Staff} {Prepared} {White} {Paper}},
	title = {Population-{Related} {Siting} {Considerations} for {Advanced} {Reactors}},
	institution = {U.S. Nuclear Regulatory Commission},
	year = {2019},
}

@article{fraize_risk_1990,
	title = {Risk {Associated} with the {Demilitarization} of the {United} {States} {Chemical} {Weapons} {Stockpile} {G}. {F}. {Flanagan}},
	volume = {29},
	doi = {10.1016/0951-8320(90)90074-W},
	abstract = {A risk assessment was performed in support of the Programmatic
Environmental Impact Statement for the Demilitarization of the US
Chemical Weapons Stockpile. The risks of five disposal alternatives were
assessed. These were: (1) continued storage for 25 more years; (2) a single
disposal site (national alternative); (3) two disposal sites (regional);
(4) disposal at each of eight storage sites (on-site alternative); and (5)
on-site disposal except for two sites located near high population areas,
where the stockpiles from these sites would be shipped to Tooele Army Depot
for disposal (partial relocation).
The shipping off-site was assumed by rail except for partial relocation
which was assumed to be by air. The on-site shipping was by truck. Specially
designed packaging was provided similar to that used to ship nuclear
materials.
The assessment examined the risks associated with transportation,
incinerator operation, and handling and included both risks from internally
initiated events as well as externally initiated events such as earthquakes and
tornadoes.},
	language = {en},
	journal = {Reliability Engineering and System Safety},
	author = {Fraize, W and Flanagan, G.F. and Kartachak, T},
	year = {1990},
	pages = {103--131},
}

@article{yu_seismic_1989,
	title = {Seismic probabilistic risk assessment and its application to utility safety decisions},
	volume = {24},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832089900926},
	doi = {10.1016/0951-8320(89)90092-6},
	abstract = {The lack 01‘ completc{\textasciitilde} field dutu, the current {\textasciitilde}{\textasciitilde}glw knowlrdgr uhaut the phJ{\textless}sicul phenomena during und ufto- un rurthquukr, and the c.Yten.siw use of’ ,judgnwn t huw crrutrd wrvrul prohicm ureas in the wismic probabilistic risk u.s.ses.smcnt ( PRA ). A.s u rrsult. the estimuted risk i.ru.ruall{\textgreater}{\textasciitilde}c{\textasciitilde}huracteri{\textasciitilde}c{\textasciitilde}dby. grcut uncertainty. H{\textasciitilde}ith the di.strihution.s qj’ core melt ,freyuenq{\textasciitilde} .sometim{\textasciitilde}{\textasciitilde}.s .spunning mow thun .swrrul ordws of’mugnitude. For the utilitjs munugrrs of’ nucleur power plants in nAich .wi.rmic risk cannot hc ocerlooked (especiull{\textasciitilde}{\textasciitilde} the locuted in ureus qf’lzigh scismicit{\textasciitilde}{\textasciitilde}) ( muking risk munugement dty{\textasciitilde}isinns uhicli must he bused on jbct0r.r und assessments qfgrrut uncertuint\_v is wrjx ch/lcnging. Tuiwun Po{\textbackslash}tw Compan?. ( TPC) has carried out PRA studies forKuo.sho{\textasciitilde}g und Muunshun; i.c. t1c.oof’ its three nucl{\textasciitilde}wr poljw plun t.s. Thi.s pupcr ptrscnts u dc{\textasciitilde}tuiI\& disc{\textasciitilde}r.whri of’ rixk manugcmcnt dt{\textasciitilde}ci.riox{\textasciitilde}, fuced b!s TPC’ munugers bawd on their .srismic PRA finding.s. It ulso discu.ssc.s .somc .so{\textasciitilde}{\textasciitilde}w.s of‘ risk idcnt{\textasciitilde}fificd in the rc{\textasciitilde}xrlts of‘ the ttl’o PRAs: thrsr ,@ctor.s urc .sign(jicunt on!,, .fiw plun t.s Iocutt4 in urcus of’ hi,@ .sc{\textasciitilde}i.smicitj{\textasciitilde}.},
	language = {en},
	number = {2},
	urldate = {2023-01-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Yu, F.L. and Chen, P.C. and Lin, E. and Wu, J.S.},
	month = jan,
	year = {1989},
	pages = {199--221},
}

@article{liu_bayesian_2022,
	title = {A {Bayesian} belief network framework for nuclear power plant human reliability analysis accounting for dependencies among performance shaping factors},
	volume = {228},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022003891},
	doi = {10.1016/j.ress.2022.108766},
	abstract = {A challenge to Human Reliability Analysis (HRA) for Nuclear Power Plants (NPPs) lies in the fact that de­ pendencies among Performance Shaping Factors (PSFs) are difficult to deal with due to insufficient knowledge, information and data available. Existing treatment relies heavily on the subjective expert judgment and the dependencies are compromised with the quantities of PSFs, simultaneously, neglects their uncertain interactions. This study proposes a Bayesian Belief Network (BBN) framework for structuring the uncertain dependencies among PSFs and estimate the Human Error Probabilities (HEPs) giving due account to such dependencies. An Exploratory Factor Analysis (EFA) technique is used to analyze human error events and cluster the dependent PSFs into clusters, which serve as the nodes connecting the parent PSF nodes with the child HEP node. Monte Carlo (MC) sampling operationalizes the framework, accounting for the uncertainty that affects PSF clustering and the data filling of conditional probability tables is performed by a Fenton approach.},
	language = {en},
	urldate = {2023-01-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Liu, Jianqiao and Zou, Yanhua and Wang, Wei and Zio, Enrico and Yuan, Chengwei and Wang, Taorui and Jiang, Jianjun},
	month = dec,
	year = {2022},
	pages = {108766},
}

@inproceedings{xu_combining_2004,
	title = {Combining dynamic fault trees and event trees for probabilistic risk assessment},
	doi = {10.1109/RAMS.2004.1285450},
	abstract = {As system analysis methodologies, both event tree analysis (ETA) and fault tree analysis (FTA) are used in probabilistic risk assessment (PRA), especially in identifying system interrelationships due to shared events. Although there are differences between them, ETA and FTA, are so closely linked that fault trees (FT) are often used to quantify system events that are part of event tree (ET) sequences (J.D. Andrew et al., 2000). The logical processes employed to evaluate ET sequences and quantify the consequences are the same as those used in FTA. Although much work has been done to combine FT and ET, traditional methods only concentrate on combining static fault trees (SFT) and ET. Our main concern is considering how to combine dynamic fault trees (DFT) and ET. We proposed a reasonable approach in this paper, which is illustrated through a hypothetical example. Because of the complexity of dynamic systems, including the huge size and complicated dependencies, there may exist contradictions among different dynamic subsystems. The key benefit of our approach is that we avoid the generation of such contradictions in our model. Another benefit is that efficiency may be improved through modularization.},
	booktitle = {Annual {Symposium} {Reliability} and {Maintainability}, 2004 - {RAMS}},
	author = {Xu, Hong and Dugan, J.B.},
	month = jan,
	year = {2004},
	keywords = {Event detection, Fault trees, Hydrogen, Logic, Risk analysis, Risk management, Time of arrival estimation, Tree graphs, US Department of Transportation, Valves},
	pages = {214--219},
}

@article{jankovsky_application_2016,
	title = {{APPLICATION} {OF} {DYNAMIC} {PROBABILISTIC} {RISK} {ASSESSMENT} {TO} {A} {SEISMICALLY}-{INDUCED} {INTERNAL} {FLOOD} {EVENT}},
	language = {en},
	author = {Jankovsky, Z and Denning, R and Aldemir, T and Sezen, H and Hur, J},
	year = {2016},
}

@article{farag_pool_2023,
	title = {Pool inlet {LOCA} safety analysis in support of the emergency core spray system success criteria development of the {PULSTAR} research reactor},
	volume = {403},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549323000122},
	doi = {10.1016/j.nucengdes.2023.112163},
	abstract = {The PULSTAR pool-type research reactor has been operating at power levels up to 1 MWth since initial criticality in 1972 on the North Carolina State University (NCSU) campus. At the current power level, there is no need for an emergency core cooling system to provide additional cooling during abnormal conditions since, at this power level, the peak cladding temperature (PCT) cannot reach the maximum allowable temperature. The range of experiments possible could be extended if the reactor is to be licensed by the U.S. Nuclear Regulatory Commission (NRC) to run up to higher power levels. However, the maximum allowable PCT at higher power levels could be exceeded during abnormal conditions. In this study, a best estimate transient simulation model is used to inform the design of an emergency core spray system to the PULSTAR research reactor. We provide the analysis results of the most limiting scenario of a pool inlet large break loss of coolant accident (LOCA) while operating at higher power levels. Currently, NCSU’s research reactor program is developing a plan to increase the operating power to 2 MWth, thus most of the analysis performed in this paper is prepared at 2 MWth. In addition, a parametric study was carried out to obtain the maximum achievable operating power by having the emergency core spray system installed with the current coolant system arrangement.},
	language = {en},
	urldate = {2023-01-24},
	journal = {Nuclear Engineering and Design},
	author = {Farag, Asmaa S. and Alzahrani, Yahya A. and Diaconeasa, Mihai A.},
	month = mar,
	year = {2023},
	pages = {112163},
}

@article{rabiti_raven_2013,
	title = {{RAVEN}: a {GUI} and an {Artificial} {Intelligence} {Engine} in a {Dynamic} {PRA} {Framework}},
	volume = {108},
	language = {en},
	journal = {Transactions of the American Nuclear Society},
	author = {Rabiti, C and Mandelli, D and Alfonsi, A and Cogliati, J and Kinoshita, R and Gaston, D and Martineau, R and Smith, C},
	year = {2013},
	pages = {4},
}

@inproceedings{kwag_bayesian_2016,
	address = {Charlotte, North Carolina, USA},
	title = {Bayesian {Network} {Technique} in {Probabilistic} {Risk} {Assessment} for {Multiple} {Hazards}},
	isbn = {978-0-7918-5004-6},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE24/50046/Charlotte,%20North%20Carolina,%20USA/251856},
	doi = {10.1115/ICONE24-60723},
	abstract = {Conventional probabilistic risk assessment (PRA) methodologies (USNRC, 1983; IAEA, 1992; EPRI, 1994; Ellingwood, 2001) conduct risk assessment for different external hazards by considering each hazard separately and independent of each other. The risk metric for a specific hazard is evaluated by a convolution of the fragility and the hazard curves. The fragility curve for basic event is obtained by using empirical, experimental, and/or numerical simulation data for a particular hazard. Treating each hazard as an independent mutually exclusive event can be inappropriate in some cases as certain hazards are statistically correlated or dependent. Examples of such correlated events include but are not limited to flooding induced fire, seismically induced internal or external flooding, or even seismically induced fire. In the current practice, system level risk and consequence sequences are typically calculated using a Fault Tree Analysis (FTA) that uses logic gates to express the causative relationship between events. Furthermore, the basic events in an FTA are considered as independent. Therefore, conducting a multi-hazard PRA using a Fault Tree is quite impractical. In some cases using an FTA to conduct a multi-hazard PRA can even be inaccurate because an FTA cannot account for uncertainties in events and the use of logic gates limits the consideration of statistical correlations or dependencies between the events. An additional limitation of an FTA based PRA is embedded in its inability to easily accommodate newly observed data and calculation of updated risk or accident scenarios under the newly available information. Finally, FTA is not best suited for addressing beyond design basis vulnerabilities. Therefore, in this paper, we present the results from a study on multi-hazard risk assessment that is conducted using a Bayesian network (BN) with Bayesian inference. The framework can consider general relationships among risks from multiple hazards, allows updating by considering the newly available data/information at any level, and evaluate scenarios for vulnerabilities due to beyond design bases events.},
	language = {en},
	urldate = {2021-12-06},
	booktitle = {Volume 4: {Computational} {Fluid} {Dynamics} ({CFD}) and {Coupled} {Codes}; {Decontamination} and {Decommissioning}, {Radiation} {Protection}, {Shielding}, and {Waste} {Management}; {Workforce} {Development}, {Nuclear} {Education} and {Public} {Acceptance}; {Mitigation} {Strategies} for {Beyond} {Design} {Basis} {Events}; {Risk} {Management}},
	publisher = {American Society of Mechanical Engineers},
	author = {Kwag, Shinyoung and Gupta, Abhinav},
	month = jun,
	year = {2016},
	pages = {V004T14A016},
}

@book{noauthor_nuclear_2009,
	address = {Paris},
	title = {Nuclear fuel behaviour in loss-of-coolant accident ({LOCA}) conditions: state -of-the-art report},
	isbn = {978-92-64-99091-3},
	shorttitle = {Nuclear fuel behaviour in loss-of-coolant accident ({LOCA}) conditions},
	language = {en},
	publisher = {OECD},
	year = {2009},
	note = {OCLC: 1039314998},
}

@article{rauzy_new_1993,
	title = {New algorithms for fault trees analysis},
	volume = {40},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209390060C},
	doi = {10.1016/0951-8320(93)90060-C},
	language = {en},
	number = {3},
	urldate = {2021-09-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Rauzy, Antoine},
	month = jan,
	year = {1993},
	pages = {203--211},
}

@article{epstein_can_2005,
	title = {Can we trust {PRA}?},
	volume = {88},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832004001504},
	doi = {10.1016/j.ress.2004.07.013},
	abstract = {The Fault-Tree/Event-Tree method is widely used in industry as the underlying formalism of probabilistic risk assessment. Almost all of the tools available to assess Event-Tree models implement the ‘classical’ assessment technique based on minimal cutsets and the rare event approximation. Binary decision diagrams (BDDs) are an alternative approach, but they were up to now limited to medium size models because of the exponential blow up of the memory requirements. We have designed a set of heuristics, which make it possible to quantify, by means of BDD, all of the sequences of a large Event-Tree model coming from the nuclear industry. For the ﬁrst time, it was possible to compare results of the classical approach with those of the BDD approach, i.e. with exact results. This article reports this comparison and shows that the minimal cutsets technique gives overestimated results in a signiﬁcant proportion of cases and underestimated results in some cases as well. Hence, the (indeed provocative) question in the title of this article.},
	language = {en},
	number = {3},
	urldate = {2022-05-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Epstein, S. and Rauzy, A.},
	month = jun,
	year = {2005},
	keywords = {Binary decision diagrams, Event-Trees, Minimal cutsets, Probabilistic risk assessment},
	pages = {195--205},
}

@book{noauthor_thermophysical_2006,
	address = {Vienna},
	title = {Thermophysical properties database of materials for light water reactors and heavy water reactors: final report of a coordinated research project, 1999-2005},
	shorttitle = {Thermophysical properties database of materials for light water reactors and heavy water reactors},
	abstract = {The thermophysical properties database for materials of light water reactors and heavy water reactors described in this technical document was established within the framework of an IAEA Coordinated Research Project. he database is intended to serve as a useful source of information on thermophysical properties data for water cooled reactor analyses. In particular, it aims at achieving improvements in safety and economics of future plants by helping to remove the need for large design margins to account for limitations of data and methods. It has been developed into an internationally available Internet database (THERPRO) at Hanyang University (Republic of Korea), and now provides various materials properties data and an interactively accessible information resource and communications medium for researchers and engineers.--Publisher's description},
	language = {en},
	publisher = {International Atomic Energy Agency},
	year = {2006},
	note = {OCLC: 607831827},
}

@article{forsberg_fission_2022,
	title = {Fission battery economics-by-design},
	volume = {152},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197022002414},
	doi = {10.1016/j.pnucene.2022.104366},
	language = {en},
	urldate = {2023-01-23},
	journal = {Progress in Nuclear Energy},
	author = {Forsberg, Charles and Foss, Andrew and Abou-Jaoude, Abdalla},
	month = oct,
	year = {2022},
	pages = {104366},
}

@article{borgonovo_differential_2007,
	title = {Differential, criticality and {Birnbaum} importance measures: {An} application to basic event, groups and {SSCs} in event trees and binary decision diagrams},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Differential, criticality and {Birnbaum} importance measures},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200600216X},
	doi = {10.1016/j.ress.2006.09.023},
	abstract = {Recent works [Epstein S, Rauzy A. Can we trust PRA? Reliab Eng Syst Safety 2005; 88:195–205] have questioned the validity of traditional fault tree/event tree (FTET) representation of probabilistic risk assessment problems. In spite of whether the risk model is solved through FTET or binary decision diagrams (BDDs), importance measures need to be calculated to provide risk managers with information on the risk/safety significance of system structures and components (SSCs). In this work, we discuss the computation of the Fussel–Vesely (FV), criticality, Birnbaum, risk achievement worth (RAW) and differential importance measure (DIM) for individual basic events, basic event groups and components. For individual basic events, we show that these importance measures are linked by simple relations and that this enables to compute basic event DIMs both for FTET and BDD codes without additional model runs. We then investigate whether/how importance measures can be extended to basic event groups and components. Findings show that the estimation of a group Birnbaum or criticality importance is not possible. On the other hand, we show that the DIM of a group or of a component is exactly equal to the sum of the DIMs of the corresponding basic events and can therefore be found with no additional model runs. The above findings hold for both the FTET and the BDD methods.},
	language = {en},
	number = {10},
	urldate = {2023-01-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Borgonovo, E.},
	month = oct,
	year = {2007},
	keywords = {Binary decision diagrams, Event trees, Importance measures, Probabilistic risk assessment},
	pages = {1458--1467},
}

@article{bowman_scale_2011,
	title = {{SCALE} 6: {Comprehensive} {Nuclear} {Safety} {Analysis} {Code} {System}},
	volume = {174},
	issn = {0029-5450, 1943-7471},
	shorttitle = {{SCALE} 6},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT10-163},
	doi = {10.13182/NT10-163},
	language = {en},
	number = {2},
	urldate = {2023-01-21},
	journal = {Nuclear Technology},
	author = {Bowman, S. M.},
	month = may,
	year = {2011},
	pages = {126--148},
}

@article{zheng_development_2014,
	title = {Development of a {MCNP}–{ORIGEN} burn-up calculation code system and its accuracy assessment},
	volume = {63},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454913004283},
	doi = {10.1016/j.anucene.2013.08.020},
	abstract = {An MCNP–ORIGEN burn-up calculation code system, named MCORE (MCNP and ORIGEN burn-up Evaluation code), is developed in this work. MCORE makes use of the Monte Carlo neutron and photon transport code MCNP4C and nuclides depletion and decay calculation code ORIGEN2.1. MCNP and ORIGEN are coupled by data processing and linking subroutines. In MCORE, a so called ‘‘modiﬁed predictor corrector’’ approach is used. MCORE provides the capability of using different depletion calculation schemes and simulating fuel shufﬂing. Total nuclide density changes in active cells are considered in MCORE. The validity and applicability of the developed code are tested by investigating and predicting the neutronic and isotopic behavior of a ‘‘VVER-1000 LEU Assembly Computational Benchmark’’ at lattice level and a ‘‘Physics of Plutonium Recycling’’ fast reactor at core level (OECD-NEA).},
	language = {en},
	urldate = {2023-01-21},
	journal = {Annals of Nuclear Energy},
	author = {Zheng, Meiyin and Tian, Wenxi and Wei, Hongyang and Zhang, Dalin and Wu, Yingwei and Qiu, Suizheng and Su, Guanghui},
	month = jan,
	year = {2014},
	pages = {491--498},
}

@article{zio_processing_2009,
	title = {Processing dynamic scenarios from a reliability analysis of a nuclear power plant digital instrumentation and control system},
	volume = {36},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454909001893},
	doi = {10.1016/j.anucene.2009.06.012},
	language = {en},
	number = {9},
	urldate = {2023-01-19},
	journal = {Annals of Nuclear Energy},
	author = {Zio, Enrico and Maio, Francesco Di},
	month = sep,
	year = {2009},
	pages = {1386--1399},
}

@article{saji_safety_2003,
	title = {Safety goals in ‘risk-informed, performance-based’ regulation},
	volume = {80},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832003000267},
	doi = {10.1016/S0951-8320(03)00026-7},
	abstract = {The recent overall improvement in key operational safety indices in the United States, combined with ‘risk-informed, performance-based’ regulation by the US Nuclear Regulatory Commission (NRC), has indicated that ‘safety goals’ are indispensable; thereby both licensee and regulator can share common objectives and common indicators of safety performance. Recognizing these, the author proposes a new concept of safety goals1 to facilitate engineering application, while removing some of the uncertainties often encountered in implementing the safety goals, by extending a framework of the International Nuclear Event Scales (INES) being widely used in the world. In this article, safety goals are characterized from a point of view of nuclear regulation by oversight, as established by the US NRC. This is a new tendency of nuclear regulation to motivate initiatives of licensees to improve safety and operational performance and to minimize potential nuclear risks, without the regulatory side specifying how the speciﬁc safety requirements should be met. Whereas in the ‘compliance-based regulation,’ which is a more widely used approach of nuclear regulation in many countries, detailed prescriptive safety requirements are speciﬁed to enforce the licensees to strictly follow them. The author observes, through the past experience of the US NRC, the latter approach has a basic limitation in improving total safety of nuclear facilities, and supports the new direction to be taken more widely in the nuclear community.},
	language = {en},
	number = {2},
	urldate = {2023-01-19},
	journal = {Reliability Engineering \& System Safety},
	author = {Saji, Genn},
	month = may,
	year = {2003},
	pages = {163--172},
}

@article{jang_development_2020,
	title = {Development of a regulatory framework for risk-informed decision making},
	volume = {52},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573319302475},
	doi = {10.1016/j.net.2019.06.029},
	abstract = {After the Fukushima Daiichi accidents, public concerns on nuclear safety and the corresponding burden of nuclear power plant licensees are increasing. In order to secure public trust and enhance the rationality of current safety regulation, we develop a risk-informed decision making (RIDM) framework for the Korean regulatory body. By analyzing all the regulatory activities for nuclear power plants in Korea, eight action items are selected for RIDM implementation, with appropriate procedures developed for each. For two items in particular e the accident sequence precursor analysis (ASPA) and the signiﬁcance determination process (SDP) e two customized risk evaluation software has been developed for ﬁeld inspectors and probabilistic safety assessment experts, respectively. The effectiveness of the proposed RIDM framework is demonstrated by applying the ASPA procedure to 35 unplanned scrams and the SDP to 24 ﬁndings from periodic inspections.},
	language = {en},
	number = {1},
	urldate = {2023-01-19},
	journal = {Nuclear Engineering and Technology},
	author = {Jang, Dong Ju and Shim, Hyung Jin},
	month = jan,
	year = {2020},
	pages = {69--77},
}

@article{sakurahara_developing_2014,
	title = {Developing a {New} {Fire} {PRA} {Framework} by {Integrating} {Probabilistic} {Risk} {Assessment} with a {Fire} {Simulation} {Module}},
	language = {en},
	author = {Sakurahara, Tatsuya and Reihani, Seyed A and Mohaghegh, Zahra and Brandyberry, Mark and Kee, Ernie and Johnson, David and Rodgers, Shawn and Billings, Mary Anne},
	year = {2014},
	pages = {13},
}

@article{sezen_mechanistic_2015,
	title = {{MECHANISTIC} {AND} {PROBABILISTIC} {SEISMIC} {ASSESSMENT} {OF} {STRUCTURES} {AND} {COMPONENTS} {IN} {NUCLEAR} {POWER} {PLANTS}},
	abstract = {The purpose of this current research project at the Ohio State University is to perform realistic assessment of risk from seismic and other external and internal events by performing structural analyses and uncertainty analyses for commercial nuclear power plants (NPP). This paper summarizes the overall research project and then describes dynamic response of two- and three-dimensional models of a containment structure. The effects of number and type of elements used in the detailed finite element (FE) models are discussed. Dynamic and modal responses of the FE models, continuous mass stick model, and lumped mass stick model are compared. The goal is to develop sufficiently accurate and simple structural models so that they can be quickly analyzed under multiple input ground motions for seismic probabilistic risk assessment (SPRA). The project aims to integrate SPRA with internal events PRA for NPP structures and to estimate the failure probabilities of nonstructural components under specified ground motions.},
	language = {en},
	author = {Sezen, Halil and Hur, Jieun and Kose, Mehmet Metin and Denning, Richard S and Aldemir, Tunc},
	year = {2015},
}

@article{henneaux_two-level_2016,
	title = {A {Two}-{Level} {Probabilistic} {Risk} {Assessment} of {Cascading} {Outages}},
	volume = {31},
	doi = {10.1109/TPWRS.2015.2439214},
	abstract = {Cascading outages in power systems can lead to major
power disruptions and blackouts and involve a large number of different
mechanisms. The typical development of a cascading outage
can be split in two phases with different dominant cascading mechanisms.
As a power system is usually operated in security,
an initiating contingency cannot entail a fast collapse of the grid.
However, it can trigger a thermal transient, increasing significantly
the likelihood of additional contingencies, in a “slow cascade.” The
loss of additional elements can then trigger an electrical instability.
This is the origin of the subsequent “fast cascade,” where a rapid
succession of events can lead to a major power disruption. Several
models of probabilistic simulations exist, but they tend to focus either
on the slow cascade or on the fast cascade, according to mechanisms
considered, and rarely on both. We propose in this paper a
decomposition of the analysis in two levels, able to combine probabilistic
simulations for the slow and the fast cascades. These two
levels correspond to these two typical phases of a cascading outage.
Models are developed for each of these phases. A simplification of
the overall methodology is applied to two test systems to illustrate
the concept.
Index Terms—},
	number = {3},
	journal = {IEEE Transactions on Power Systems},
	author = {Henneaux, Pierre and Labeau, Pierre-Etienne and Maun, Jean-Claude and Haarla, Liisa},
	year = {2016},
}

@article{mujeed-ahmed_probabilistic_2022,
	title = {Probabilistic {Damage} {Stability} for {Passenger} {Ships}—{The} p-{Factor} {Illusion} and {Reality}},
	volume = {10},
	doi = {https://doi.org/10.3390/jmse10030348},
	abstract = {The paper complements an earlier publication by the authors addressing the probability of
survival in the IMO framework for damage stability assessment, the s-factor. The focus here is on the
probability of occurrence of a certain damage scenario (breach), conditional on its dimensions and
location (centre and port or starboard side), the p-factor. Pertinent assumptions and limitations are
explained, following its evolution for specific application to passenger ships. Attempts to provide
analytical descriptions of the damage breach distributions as tetrahedra shapes positioned along the
ship length whilst accounting for changes in ship geometry, structural arrangements, and subdivision
for consumption by the wider profession has led to misconceptions and misunderstandings of what
exactly the p-factor is in the context of probabilistic damage stability calculations. This is evidenced
by the fact that the same original damage breach distributions, derived in Project HARDER, based
on largely cargo ships with the age spread over the last three decades of the previous century, are
still being used today for all ship types, including modern passenger ships. Filling this gap, a new
database for passenger ships developed in the EC-funded Project FLARE, is briefly presented, leading
to new damage breach distributions specifically for passenger ships. It is believed that this paper will
throw considerable light in enhancing understanding on the p-factor, which has been cluttered with
unnecessary complexity from the outset.},
	number = {348},
	journal = {Journal of Marine Science and Engineering},
	author = {Mujeed-Ahmed, M.P. and Paterson, Donald and Mauro, Francesco and Conti, Fabien},
	year = {2022},
}

@article{eem_seismic_2021,
	title = {Seismic response correlation coefficient for the structures, systems and components of the {Korean} nuclear power plant for seismic probabilistic safety assessment},
	volume = {150},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454920304576},
	doi = {10.1016/j.anucene.2020.107759},
	abstract = {The seismic probabilistic safety assessments of nuclear power plants (NPPs) conservatively assume that the correlation between the seismic failure to structures, systems, and components (SSCs) is independent or fully dependent. This, however, is an extreme assumption, and so a more appropriate seismic failure correlation should be considered for accurate safety assessments. Quantification of the correlation of seismic failure can be expressed with a correlation coefficient; to calculate this, correlation coefficients for both seismic response and seismic performance between SSCs are required. This study suggests a seismic response correlation coefficient for the OPR1000 Korean NPPs. To this end, a probabilistic seismic response analysis was performed considering the randomness and uncertainty of earthquakes and structures. Based on this in-structure spectrum, the seismic response correlation coefficient between the SSCs was derived and databased. Seismic response correlation coefficient values are also suggested that can easily be applied to auxiliary buildings of NPPs.},
	language = {en},
	urldate = {2023-01-13},
	journal = {Annals of Nuclear Energy},
	author = {Eem, Seunghyun and Choi, In Kil and Cha, Sang Lyul and Kwag, Shinyoung},
	month = jan,
	year = {2021},
	keywords = {Nuclear power plants, Probabilistic seismic response analysis, Seismic correlation, Seismic probabilistic safety assessment, Seismic response correlation},
	pages = {107759},
}

@article{strand_human_2016,
	title = {Human factors modelling in offshore drilling operations},
	volume = {43},
	issn = {09504230},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950423016301668},
	doi = {10.1016/j.jlp.2016.06.013},
	abstract = {The main principle for risk control during offshore well activities is to always maintain two independent and tested well barriers towards any potential source of inﬂow. The short lifespan and dynamic nature of well drilling operations makes this a challenge. Experiences from several industry accidents the last decade reveal that two well barriers were not properly maintained by the drilling personnel during the operation and thus that safety was compromised. Probabilistic risk assessments are considered key for risk management of low probability and high consequence activities such as offshore oil and gas well drilling. The objective of this article is to present a method that can be used to address human factors modelling as an integral part of a well drilling operation risk assessment. The method represents an adoption and extension made to the human reliability analysis part of an existing method denoted ‘Risk OMT’. Risk OMT is a risk inﬂuence modelling method with a modelling principle that includes human factors assessment. Risk OMT has been demonstrated for purpose of analysis of leak scenarios related to planning or execution and control of offshore process maintenance activities.},
	language = {en},
	urldate = {2023-01-19},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {Strand, Geir-Ove and Lundteigen, Mary Ann},
	month = sep,
	year = {2016},
	pages = {654--667},
}

@inproceedings{pandit_assessing_2022,
	title = {Assessing  the {Potential} for {Implementation} of {Distributed} {Ledger} {Technology} in the {Nuclear} {Power} {Plant} {Lifecycle}},
	doi = {10.1115/IMECE2022-95225},
	abstract = {The Nuclear Power Plant (NPP) project lifecycle consists of multiple organizations, private and public, that work together to carry out the licensing and regulation, commissioning, construction, supply chain management, decommissioning, and non-proliferation of nuclear power plants. Each stage of the lifecycle generates a considerable amount of documentation that needs to be archived and made available on request. In this paper, we examined the current frameworks employed by the stakeholders of nuclear power plant lifecycles for data generation, classification, archival, and exchange and we evaluated the use of distributed ledger technology for data management. We further demonstrated the implementation of distributed ledger technology to capturing and immutable recording nuclear supply chain structure, production, and failure data.},
	language = {en},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Pandit, Priyanka and Nevius, Daniel and Srivaths, Vibhav and Diaconeasa, Mihai A},
	year = {2022},
}

@article{zio_integrated_2014,
	title = {Integrated deterministic and probabilistic safety assessment: {Concepts}, challenges, research directions},
	volume = {280},
	issn = {00295493},
	shorttitle = {Integrated deterministic and probabilistic safety assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549314004968},
	doi = {10.1016/j.nucengdes.2014.09.004},
	language = {en},
	urldate = {2023-01-18},
	journal = {Nuclear Engineering and Design},
	author = {Zio, Enrico},
	month = dec,
	year = {2014},
	pages = {413--419},
}

@article{di_maio_dynamic_2016,
	title = {A dynamic probabilistic safety margin characterization approach in support of {Integrated} {Deterministic} and {Probabilistic} {Safety} {Analysis}},
	volume = {145},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015002586},
	doi = {10.1016/j.ress.2015.08.016},
	language = {en},
	urldate = {2023-01-18},
	journal = {Reliability Engineering \& System Safety},
	author = {Di Maio, Francesco and Rai, Ajit and Zio, Enrico},
	month = jan,
	year = {2016},
	pages = {9--18},
}

@misc{noauthor_dynamic_nodate,
	title = {Dynamic response of dry cask storage systems for spent nuclear fuel to near field blast loading {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0306454921000311?token=BF0B4C93EF4323ED8CA936DCBE2BC647A4D63694E6630BC00F6C7DBC8E704AFF4089E063461456472E6D95F2A5BB08B0&originRegion=us-east-1&originCreation=20230115045621},
	language = {en},
	urldate = {2023-01-15},
	doi = {10.1016/j.anucene.2021.108155},
}

@article{bartlett_ordering_2001,
	title = {An ordering heuristic to develop the binary decision diagram based on structural importance},
	volume = {72},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832000001034},
	doi = {10.1016/S0951-8320(00)00103-4},
	abstract = {Fault tree analysis is often used to assess risks within industrial systems. The technique is commonly used although there are associated limitations in terms of accuracy and efficiency when dealing with large fault tree structures. The most recent approach to aid the analysis of the fault tree diagram is the Binary Decision Diagram (BDD) methodology. To utilise the technique the fault tree structure needs to be converted into the BDD format. Converting the fault tree requires the basic events of the tree to be placed in an ordering. The ordering of the basic events is critical to the resulting size of the BDD, and ultimately affects the performance and benefits of this technique. A number of heuristic approaches have been developed to produce an optimal ordering permutation for a specific tree. These heuristic approaches do not always yield a minimal BDD structure for all trees. This paper looks at a heuristic that is based on the structural importance measure of each basic event. Comparing the resulting size of the BDD with the smallest generated from a set of six alternative ordering heuristics, this new structural heuristic produced a BDD of smaller or equal dimension on 77\% of trials.},
	language = {en},
	number = {1},
	urldate = {2023-01-15},
	journal = {Reliability Engineering \& System Safety},
	author = {Bartlett, L. M. and Andrews, J. D.},
	month = apr,
	year = {2001},
	keywords = {Binary decision diagrams, Fault tree analysis, Structural importance, Variable ordering heuristics},
	pages = {31--38},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: {S0951}-8320(00)00103-4 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832000001034?token=EB356D40A8E8151F02165809DB1A43BAE2D343C64B33B72190A53631BB6CCFCBEF0D030CFA7AD3F445AE638905427E1A&originRegion=us-east-1&originCreation=20230115021607},
	language = {en},
	urldate = {2023-01-15},
	doi = {10.1016/S0951-8320(00)00103-4},
}

@article{sauerhoff_optimal_2000,
	title = {Optimal ordered binary decision diagrams for read-once formulas},
	volume = {103},
	issn = {0166-218X},
	url = {https://www.sciencedirect.com/science/article/pii/S0166218X99002103},
	doi = {10.1016/S0166-218X(99)00210-3},
	abstract = {In many applications like verification or combinatorial optimization, ordered binary decision diagrams (OBDDs) are used as a representation or data structure for Boolean functions. Efficient algorithms exist for the important operations on OBDDs, and many functions can be represented in reasonable size if a good variable ordering is chosen. In general, it is NP-hard to compute optimal or near-optimal variable orderings, and already simple classes of Boolean functions contain functions whose OBDD size is exponential for each variable ordering. For the class of Boolean functions representable by fan-in 2 read-once formulas the structure of optimal variable orderings is described, leading to a linear time algorithm for the construction of optimal variable orderings and the size of the corresponding OBDD. Moreover, it is proved that the hardest read-once formula has an OBDD size of order nβ where β=log4(3+5){\textless}1.1943.},
	language = {en},
	number = {1},
	urldate = {2023-01-15},
	journal = {Discrete Applied Mathematics},
	author = {Sauerhoff, Martin and Wegener, Ingo and Werchner, Ralph},
	month = jul,
	year = {2000},
	keywords = {Boolean function, Efficient algorithms, Ordered binary decision diagram, Read-once formula, Variable ordering},
	pages = {237--258},
}

@book{duderstadt_nuclear_1976,
	address = {New York},
	title = {Nuclear reactor analysis},
	isbn = {978-0-471-22363-4},
	language = {eng},
	publisher = {Wiley},
	author = {Duderstadt, James J. and Hamilton, Louis J.},
	year = {1976},
}

@article{farag_pool_2023,
	title = {Pool inlet {LOCA} safety analysis in support of the emergency core spray system success criteria development of the {PULSTAR} research reactor},
	volume = {403},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549323000122},
	doi = {10.1016/j.nucengdes.2023.112163},
	language = {en},
	urldate = {2023-01-13},
	journal = {Nuclear Engineering and Design},
	author = {Farag, Asmaa S. and Alzahrani, Yahya A. and Diaconeasa, Mihai A.},
	month = mar,
	year = {2023},
	pages = {112163},
}

@article{aghassi_fault_2012,
	title = {Fault {Tree} {Analysis} {Speed}-up with {GPU} {Parallel} {Computing}},
	abstract = {The reliability analysis of critical systems can be performed using fault tree analysis. One of the common approaches used for fault tree analysis is Monte Carlo simulation. The purpose of this paper is therefore to show an algorithm to speed up Monte Carlo simulation for analyzing fault tree with parallel computing in GPU. To this end, we use time-to-failure tree to model fault tree with Compute Unified Device Architecture (CUDA) which is used to accelerate the execution of loops with many repetitions. We also use this technique to accelerate Monte Carlo simulations. In addition, we visualize fault tree so that the user is able to generate fault tree in detail using our developed software and can execute it. The computational outcomes validate the effectiveness of the suggested approach, as we approached about 310 times speedup in large fault trees.},
	language = {en},
	author = {Aghassi, Hadi and Aghassi, Farrokh},
	year = {2012},
}

@techreport{noauthor_multi-purpose_2000,
	title = {Multi-purpose container technologies for spent fuel management},
	number = {IAEA-TECDOC-1192},
	institution = {IAEA},
	year = {2000},
}

@misc{arjun_earthperson_supporting_2023,
	title = {Supporting {Tools} and {Models}: {A} {Combined} {Strategy} for {Dynamic} {Probabilistic} {Risk} {Assessment} of {Fission} {Battery} {Designs} using {Integrated} {EMRALD} and {DEPM}},
	url = {https://gitlab.openpra.org/published-tools-and-methods/a-combined-strategy-for-dynamic-probabilistic-risk-assessment-of-fission-battery-designs-using-integrated-emrald-and-depm},
	journal = {OpenPRA Git Repository},
	author = {{Arjun Earthperson} and {Courtney M. Otani} and {Daniel M. Nevius} and {Steven R. Prescott} and {Mihai A. Diaconeasa}},
	month = jan,
	year = {2023},
}

@article{arjun_earthperson_supporting_2023-1,
	title = {Supporting {Tools} and {Models}: {A} {Combined} {Strategy} for {Dynamic} {Probabilistic} {Risk} {Assessment} of {Fission} {Battery} {Designs} using {Integrated} {EMRALD} and {DEPM}},
	url = {https://gitlab.openpra.org/published-tools-and-methods/a-combined-strategy-for-dynamic-probabilistic-risk-assessment-of-fission-battery-designs-using-integrated-emrald-and-depm},
	doi = {10.5281/zenodo.7504760},
	author = {{Arjun Earthperson} and {Courtney M. Otani} and {Daniel M. Nevius} and {Steven R. Prescott} and {Mihai A. Diaconeasa}},
	month = jan,
	year = {2023},
}

@article{worrell_fire_2016,
	title = {Fire {Probabilistic} {Risk} {Assessment} and its {Applications} in the {Nuclear} {Power} {Industry}},
	doi = {https://doi-org.prox.lib.ncsu.edu/10.1007/s10694-015-0493-y},
	abstract = {Advancement of fire risk analysis methods has resulted in widespread development of detailed fire probabilistic risk assessments (PRA) at nuclear power
plants. The PRA models are maintained and frequently exercised to help ensure safe,
reliable, and cost-effective operation of nuclear power plants. Quantitative risk metrics and criteria have been established for total plant risk (for example less than 10-4
per year total plant core damage frequency across all hazards) and change in risk
associated with proposed plant changes (for example less than 10-6 per year increase
in core damage frequency), and these quantitative metrics are used to support risk-informed decision-making. A brief overview of fire PRA and its applications is provided, with the intended audience being the general fire protection community who may
not be familiar with the risk analysis methods and applications used by the nuclear
power industry. At a high level, the fire PRA process can be organized into three
tasks: fire scenario definition, plant response model development, and quantification.
The fire PRA process is performed iteratively, with increasing levels of modeling realism commensurate with risk significance. At the end of the process, the PRA includes
conservative modeling of low risk fire scenarios, very detailed modeling (and understanding) of the most risk significant scenarios, and a sliding scale of modeling detail
for scenarios of intermediate risk significance. These analyses have provided meaningful qualitative and quantitative insights that are readily used for the identification and
management of risk. Fire PRA has achieved sufficient credibility and value within the
nuclear industry that the United States federal regulation was amended to allow implementation of the risk-informed, performance-based fire protection standard NFPA
805 as an alternative to the traditionally prescriptive fire protection requirements.},
	number = {52},
	journal = {Fire Technology},
	author = {Worrell, Clarence and Rochon, Christopher},
	year = {2016},
	pages = {443--467},
}

@article{kim_probabilistic_2021,
	title = {Probabilistic {Flood} {Assessment} {Methodology} for {Nuclear} {Power} {Plants} {Considering} {Extreme} {Rainfall}},
	volume = {14},
	doi = {https://doi.org/10.3390/en14092600},
	abstract = {Abnormal weather conditions due to climate change are currently increasing on both global
and local scales. It is therefore important to ensure the safety of the areas where major national
facilities are located by analyzing risk quantitatively and re-evaluating the existing major facilities,
such as nuclear power plants, considering the load and capacity of extreme flood conditions. In this
study, a risk analysis method is developed that combines flood hazard curves with fragility curves
using hydraulic and hydrological models by GIS tools and the @RISK model for the probabilistic
flood analysis of nuclear power plant sites. A two-dimensional (2D) analysis is first carried out to
estimate flood depths in various watershed scenarios, and a representative hazard curve for both
external and internal flooding is made by applying a verified probability distribution type for the
flood watersheds. For the analysis of flooding within buildings, an internal grid is constructed
using GIS with related design drawings, and based on the flood depth results of the 2D analysis,
a hazard curve for the representative internal inundation using a verified probability distribution
type is presented. In the present study, walkdowns with nuclear experts are conducted around the
nuclear power plant area to evaluate the fragile structures and facilities under possible flooding.
After reviewing the 2D inundation analysis results based on the selected major equipment and
facilities, the zones requiring risk assessment are re-assigned. A fragility curve applying probability
distribution for the site’s major equipment and facilities is also presented. Failure risk analysis of the
major facilities is then conducted by combining the proposed hazard and fragility curves. Results in
the form of quantitative values are obtained, and the indicators for risks as well as the reliability and
optimal measures to support decision-making are also presented. Through this study, it is confirmed
that risk assessment based on the proposed probabilistic flood analysis technique is possible for flood
events occurring at nuclear power plant sites.},
	number = {9},
	journal = {Energies},
	author = {Kim, Beom-Jin and Kim, Minkyu and Hahm, Daegi and Park, Junhee and Han, Kun-Yeun},
	month = may,
	year = {2021},
	pages = {2600--2627},
}

@article{van_dyck_probabilistic_2013,
	title = {Probabilistic flood risk assessment over large geographical regions},
	volume = {49},
	issn = {1944-7973},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wrcr.20149},
	doi = {10.1002/wrcr.20149},
	abstract = {We develop a probabilistic model to estimate the rate of flood-induced losses for a set of properties distributed over a large geographical region (e.g., a portfolio of insured properties within a country). The use of detailed physically based models over large areas becomes difficult due to the vast amount of data needed and the high implementation cost. The proposed model allows one to incorporate results from such detailed models but can also be used in regions that have not been studied in much detail. Minimal required information includes the rate and spatial extent of severe precipitation, the topography and river network from which regions at risk of flooding can be identified, and information on historical floods with an approximate delineation of the flooded area, and associated aggregate losses for at least a few major events. An application to river flood loss from residential buildings in Belgium is presented.},
	language = {en},
	number = {6},
	urldate = {2023-01-12},
	journal = {Water Resources Research},
	author = {Van Dyck, Jozef and Willems, Patrick},
	year = {2013},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/wrcr.20149},
	keywords = {flood damage, flood loss, probabilistic modeling, river flooding},
	pages = {3330--3344},
}

@misc{rakhimov_scram_nodate,
	title = {{SCRAM}, https://github.com/rakhimov/scram},
	copyright = {GPL-3.0 License         ,                 GPL-3.0 License},
	url = {https://github.com/rakhimov/scram},
	abstract = {Probabilistic Risk Analysis Tool (fault tree analysis, event tree analysis, etc.)},
	urldate = {2021-02-11},
	author = {Rakhimov, Olzhas},
	note = {original-date: 2014-03-21T01:19:49Z},
	keywords = {bdd, c-plus-plus, cpp17, event-tree, fault-tree, fta, pra, psa, python, qt5, reliability-engineering, risk-analysis, zbdd},
}

@misc{rakhimov_scram_nodate-1,
	title = {{SCRAM}},
	url = {https://gitlab.openpra.org/scram/ (accessed Jan.1.2023)scram},
	abstract = {Probabilistic Risk Analysis Tool (fault tree analysis, event tree analysis, etc.)},
	urldate = {2022-02-02},
	author = {Rakhimov, Olzhas},
}

@misc{noauthor_xfta_nodate,
	title = {{XFTA} - {Fault} {Tree} {Analysis}},
	url = {http://www.altarica-association.org/members/arauzy/Software/XFTA/XFTA2.html},
	urldate = {2022-04-25},
	publisher = {alatrica association},
}

@misc{noauthor_saphire_nodate,
	title = {{SAPHIRE} - {Systems} analysis programs for hands-on integrated reliability evaluations},
	url = {https://saphire.inl.gov/ (accessed Jan.11.2023)},
	publisher = {Idaho National Laboratory (INL)},
}

@misc{noauthor_computer_nodate,
	title = {Computer {Aided} {Fault} {Tree} {Analysis} {System} ({CAFTA})},
	url = {http://www.epri.com/abstracts/Pages/ProductAbstract.aspx?ProductId=000000000001015514 (accessed Jan.11.2023)},
	publisher = {Electric Power Research Institute (EPRI)},
}

@inproceedings{jung_ftrex_2008,
	title = {{FTREX} {FEATURES} {FOR} {AN} {EFFICIENT} {PSA}},
	abstract = {This paper presents the advanced features of a fault tree solver FTREX (Fault Tree Reliability Evaluation eXpert). The current paper provides a FTREX algorithm, advanced features, limitations, and approximations. FTREX solves coherent and non-coherent fault trees by using a Zero-suppressed Binary Decision Diagram (ZBDD) algorithm. Negates of a non-coherent fault tree are solved with an approximation of a delete-term operation. FTREX can solve large coherent fault trees with a small memory usage in a short time. FTREX has special features such as an automatic logical loop break, rule-based post processing, special negate handling, quick test of important minimal cut sets (MCSs), estimation of a truncation error, automated MCS propagation tests, top event prevention analysis, and a parallel computing.},
	language = {en},
	author = {Jung, Woo Sik and Canavan, Ken and Riley, Jeff},
	year = {2008},
	pages = {11},
}

@article{hawari_pulstar_nodate,
	title = {{PULSTAR} {Reactor} {Power} {Upgrade} from 1- to 2-{MWth}},
	abstract = {An upgrade of the North Carolina State University PULSTAR reactor systems has been completed. The new systems are capable of supporting the increase in the reactor power from 1-MWth to 2-MWth. The PULSTAR is an open pool reactor fueled with uranium dioxide that is enriched to 4\% in U-235. Its design characteristics (that include a significant negative power coefficient of reactivity) render it inherently safe during normal operations and under the most sever of potential accidents. The PULSTAR is used in various applications including training and education, radiation testing, neutron activation analysis, and materials nondestructive examination using radiation beams. The completed upgrade included replacement of the primary and secondary cooling systems, a major refurbishment of instrumentation and control systems and installing a new facilitywide radiation monitoring system. In addition, due to increased operational demands, fresh PULSTAR fuel that is enriched to 6\% in U-235 will be utilized in the core. The required neutronic and thermal-hydraulic analysis is on-going to support the application to the US Nuclear Regulatory Commission for a license amendment for 2-MW operations. Consequently, it is expected that the introduced system upgrades and core modifications will result in enhancing the core lifetime and in effectively doubling the available radiation (neutron and gamma-ray) flux at the PULSTAR’s various in-pool and beam irradiation facilities.},
	language = {en},
	author = {Hawari, Ayman I},
}

@article{krajewska_front-end_2021,
	title = {Front-end investigations of the coated particles of nuclear fuel samples – ion polishing method},
	doi = {10.1016/j.net.2021.12.003},
	abstract = {The investigations of the coated-particles of nuclear fuel samples are carried out in three stages: front-end, irradiation in the reactor core, and post-irradiation examination. The front-end stage is the initial analysis of the failures rates of produced samples before they are placed in the reactor core. The purpose of the verification is to prepare the particles for an experiment that will determine the degree of damage to the coated particles at each stage. Before starting experiments with the samples, they must be properly prepared. Polishing the samples in order to uncover the inner layers is an important, initial experimental step. The authors of this paper used a novel way to prepare samples for testing - by applying an ion polisher. Mechanical polishing used frequently for sample preparations generates additional mechanical damages in the studied fuel particle, thus directly affecting the experimental results. The polishing methods were compared for three different coated particles using diagnostic methods such as Raman spectroscopy, scanning electron microscopy, and confocal laser scanning microscopy. Based on the obtained results, it was concluded that the ion polishing method is better because the level of interference with the structures of the individual layers of the tested samples is much lower than with the mechanical method. The same technique is used for the fuel particles undergone ion implantation simulating radiation damage that can occur in the reactor core.},
	journal = {Nuclear Engineering and Technology},
	author = {Krajewska, Zuzanna and Buchwald, Tomasz and Tokarski, Tomasz and Gudowski, Waclaw},
	month = dec,
	year = {2021},
}

@inproceedings{bouissou_bdd_1997,
	title = {{BDD} based fault-tree processing: a comparison of variable ordering heuristics},
	abstract = {In this paper, we set up a method to compare and evaluate variable ordering heuristics for BDD based analyses of fault-trees, and give the results obtained with this method on 6 diﬀerent heuristics, tried on a large benchmark of real-life fault-trees. Some of these heuristics were already proposed in the literature, some are original. As a ﬁnal synthesis of all these results, we give the two strategies one can choose to process a new fault-tree, depending on the objective of this processing. This objective may be either to obtain a ﬁrst BDD as soon as possible, or to minimize the size of the BDD, for further intensive use.},
	language = {en},
	author = {Bouissou, M and Bruyere, F and Rauzy, A},
	year = {1997},
}

@article{myles_introduction_2004,
	title = {An introduction to decision tree modeling},
	volume = {18},
	issn = {1099-128X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.873},
	doi = {10.1002/cem.873},
	abstract = {In this tutorial, traditional decision tree construction and the current state of decision tree modeling are reviewed. Emphasis is placed on techniques that make decision trees well suited to handle the complexities of chemical and biochemical applications. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {6},
	urldate = {2023-01-11},
	journal = {Journal of Chemometrics},
	author = {Myles, Anthony J. and Feudale, Robert N. and Liu, Yang and Woody, Nathaniel A. and Brown, Steven D.},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cem.873},
	keywords = {classification, decision tree modeling, ensemble modeling, pattern recognition},
	pages = {275--285},
}

@book{waller_low-probability_1984,
	address = {Boston, MA},
	title = {Low-{Probability} {High}-{Consequence} {Risk} {Analysis}: {Issues}, {Methods}, and {Case} {Studies}},
	isbn = {978-1-4757-1820-1 978-1-4757-1818-8},
	shorttitle = {Low-{Probability} {High}-{Consequence} {Risk} {Analysis}},
	url = {http://link.springer.com/10.1007/978-1-4757-1818-8},
	language = {en},
	urldate = {2023-01-10},
	publisher = {Springer US},
	editor = {Waller, Ray A. and Covello, Vincent T.},
	year = {1984},
	doi = {10.1007/978-1-4757-1818-8},
}

@book{kugeler_modular_2019,
	address = {Berlin, Heidelberg},
	title = {Modular {High}-temperature {Gas}-cooled {Reactor} {Power} {Plant}},
	isbn = {978-3-662-57710-3 978-3-662-57712-7},
	url = {http://link.springer.com/10.1007/978-3-662-57712-7},
	language = {en},
	urldate = {2023-01-10},
	publisher = {Springer Berlin Heidelberg},
	author = {Kugeler, Kurt and Zhang, Zuoyi},
	year = {2019},
	doi = {10.1007/978-3-662-57712-7},
}

@book{kugeler_modular_2019-1,
	address = {Berlin, Heidelberg},
	title = {Modular {High}-temperature {Gas}-cooled {Reactor} {Power} {Plant}},
	isbn = {978-3-662-57710-3 978-3-662-57712-7},
	url = {http://link.springer.com/10.1007/978-3-662-57712-7},
	language = {en},
	urldate = {2023-01-10},
	publisher = {Springer Berlin Heidelberg},
	author = {Kugeler, Kurt and Zhang, Zuoyi},
	year = {2019},
	doi = {10.1007/978-3-662-57712-7},
}

@article{vietti-cook_staff_nodate,
	title = {{STAFF} {REQUIREMENTS} - {SECY}-98-144 - {WHITE} {PAPER} {ON} {RISK}-{INFORMED} {AND} {PERFORMANCE}-{BASED} {REGULATION}.},
	language = {en},
	author = {Vietti-Cook, Annette L},
}

@article{kerntopf_new_nodate,
	title = {New {Generalizations} of {Shannon} {Decomposition}},
	abstract = {New types of functional decompositions are presented which we call function-driven decompositions. Namely, it is shown in the paper that in the well-known Shannon formula it is possible to replace a variable by an arbitrary function having the property of self-duality with respect to a variable of the decomposed function. In this way a generalization of recently studied linear decompositions (used for constructing Linearly Transformed Binary Decision Diagrams) is obtained. Further extensions of functiondriven decompositions are also mentioned. These extensions can be defined by combining the functiondriven decompositions with other known decompositions, e.g. Reed-Muller (Davio) decompositions. It is also shown how to extend function-driven decompositions to multiple-valued functions.},
	language = {en},
	author = {Kerntopf, Pawel},
}

@book{chopra_supply_2013,
	address = {Boston},
	edition = {5th ed},
	title = {Supply chain management: strategy, planning, and operation},
	isbn = {978-0-13-274395-2},
	shorttitle = {Supply chain management},
	language = {en},
	publisher = {Pearson},
	author = {Chopra, Sunil and Meindl, Peter},
	year = {2013},
	note = {OCLC: ocn755904451},
	keywords = {Customer services, Delivery of goods, Industrial procurement, Management, Marketing channels, Materials management, Physical distribution of goods},
}

@techreport{noauthor_high-temperature_nodate,
	type = {Status report},
	title = {High-{Temperature} {Gas} {Cooled} {Reactor} - {Pebble}-{Bed} {Module} ({HTR}-{PM})},
	url = {https://aris.iaea.org/PDF/HTR-PM.pdf},
	number = {96},
	urldate = {2023-01-08},
}

@misc{noauthor_source_nodate,
	title = {Source term},
	url = {https://www.nrc.gov/reading-rm/basic-ref/glossary/source-term.html},
	language = {tr},
	urldate = {2023-01-08},
	journal = {NRC Web},
}

@misc{noauthor_severe_nodate,
	title = {Severe {Accident} {Risks}: {An} {Assessment} for {Five} {U}.{S}. {Nuclear} {Power} {Plants} — {Final} {Summary} {Report} ({NUR}},
	shorttitle = {Severe {Accident} {Risks}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1150/v1/index.html},
	language = {en-US},
	urldate = {2023-01-06},
	journal = {NRC Web},
}

@misc{noauthor_severe_nodate-1,
	title = {Severe {Accident} {Risks}: {An} {Assessment} for {Five} {U}.{S}. {Nuclear} {Power} {Plants} ({NUREG}-1150)},
	shorttitle = {Severe {Accident} {Risks}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1150/index.html},
	language = {en-US},
	urldate = {2023-01-06},
	journal = {NRC Web},
}

@article{ismail_rtp_nodate,
	title = {{RTP}: {RADIONUCLIDES} {INVENTORIES} {CALCULATION} {USING} {ORIGEN} {CODE}},
	abstract = {ORIGEN is a widely used computer code for calculating the buildup, decay, and processing o f radioactive materials. The ORIGEN code was created by famous and reputable nuclear institution in United States, Oak Ridge National Laboratory (ORNL). For a nuclear reactor, either it is a nuclear power reactor or nuclear research reactor, the radionuclide inventories data is important. This data is acquired by performing source term modelling. A fresh nuclear fuel could not cause any harm to human. However, used nuclear fuel could pose danger threat to human. The fission products particularly long-lived radionuclides i.e.H-3, Co-60, Cs-137 that are generated inside the fuel yield a significance amount o f radioactivity. Therefore, there is no doubt that for a facility having a nuclear reactor, it is vital to anticipate the amount o f fission products inside the fuel together with the radioactivity that it may emit. Sufficient information on the radionuclide inventories allows the facility to provide adequate shielding protection and ensure safe transportation o f nuclear fuel, when it is needed. This paper briefly describes application o f ORIGEN code to calculate the radionuclides inventories o f TRIGA-PUSPATI REACTOR (RTP) fuel.},
	language = {en},
	author = {Ismail, Ariff Shah and Takip, Khaironie Mohd and Mustafa, Muhammad Khairul Ariff and Anwar, Adli},
}

@article{youngblood_heartbeat_2011,
	title = {Heartbeat {Model} for {Component} {Failure} in {Simulation} of {Plant} {Behavior}},
	url = {https://www.osti.gov/biblio/1017877},
	author = {Youngblood, R W and Nourgaliev, R R and Kelly, D L and Smith, C L and Dinh, T-N},
	month = mar,
	year = {2011},
}

@article{tsukamoto_study_2019,
	title = {Study on modeling of spray cooling for spent fuel pool accidents},
	volume = {56},
	issn = {0022-3131, 1881-1248},
	url = {https://www.tandfonline.com/doi/full/10.1080/00223131.2019.1626778},
	doi = {10.1080/00223131.2019.1626778},
	language = {en},
	number = {11},
	urldate = {2023-01-03},
	journal = {Journal of Nuclear Science and Technology},
	author = {Tsukamoto, Naofumi},
	month = nov,
	year = {2019},
	pages = {945--952},
}

@techreport{guertin_system_2010,
	address = {Pasadena, CA, USA},
	type = {{JPL} {Publication} 10-20 12/10},
	title = {System on a {Chip} {Devices}—{FY10}},
	url = {https://hdl.handle.net/2014/41773},
	number = {2014/41773},
	institution = {Jet Propulsion Laboratory, NASA},
	author = {Guertin, Steven M},
	year = {2010},
}

@inproceedings{hawari_pulstar_2013,
	address = {Korea, Republic of},
	title = {{PULSTAR} {Reactor} {Power} {Upgrade} from 1- to 2-{MWth}},
	abstract = {A power upgrade of the North Carolina State University PULSTAR reactor from 1-MWth
to 2-MWth has been initiated and is nearing conclusion The PULSTAR is an open pool
reactor fueled with uranium dioxide enriched to 4\% in U-235 It is used in various
radiation testing and materials nondestructive examination applications The upgrade
includes a complete replacement of the primary and secondary cooling systems, a major
refurbishment of I and C systems and installing a new facility-wide radiation monitoring
system It is expected that it will result in effectively doubling the available radiation
flux at the PULSTAR's various in-pool and beam irradiation facilities},
	publisher = {IGORR},
	author = {Hawari, Ayman I.},
	year = {2013},
	note = {INIS Reference Number: 45103482},
	pages = {1CD--ROM},
}

@misc{meehan_pulstar_2019,
	title = {{PULSTAR} {Reactor} - a {Research} {Reactor} for the 21st {Century}},
	url = {https://neup.inl.gov.},
	publisher = {U.S. Department of Energy},
	author = {Meehan, Kate},
	month = dec,
	year = {2019},
}

@misc{noauthor_pulstar_2017,
	title = {{PULSTAR} reactor updated safety analysis report},
	url = {www.nrc.gov/docs/ML1904/ML19046A033.pdf},
	language = {en},
	publisher = {North Carolina State University},
	month = mar,
	year = {2017},
}

@article{van_dam_anomalous_2008,
	title = {Anomalous coolant temperature feedback effect in {LWRs}},
	volume = {35},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454908001163},
	doi = {10.1016/j.anucene.2008.04.006},
	abstract = {In neutronically large cores of power reactors anomalous reactivity effects can occur due to space-dependent coolant temperature feedback. These effects are contrary to reactor physical intuition, e.g. power increase after control rod insertion. A quantitative analysis and physical interpretation of these anomalies is presented, based on two relatively simple reactor models and application of adjoint function theory.},
	language = {en},
	number = {10},
	urldate = {2023-01-02},
	journal = {Annals of Nuclear Energy},
	author = {van Dam, Hugo},
	month = oct,
	year = {2008},
	pages = {1849--1856},
}

@article{karoutas_maturing_2018,
	title = {The maturing of nuclear fuel: {Past} to {Accident} {Tolerant} {Fuel}},
	volume = {102},
	issn = {01491970},
	shorttitle = {The maturing of nuclear fuel},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197017301853},
	doi = {10.1016/j.pnucene.2017.07.016},
	abstract = {Nuclear fuel has made great strides from the advent of the nuclear industry at Shippingport to the ongoing development of Accident Tolerant Fuel (ATF) for potential implementation in commercial nuclear plants. The development of Zircaloy-2 fuel with UO2 pellets at Shippingport was revolutionary. Incremental advancements have been made from Zircaloy-2 cladding to Zircaloy-4, and more advanced cladding materials for PWRs and BWRs to signiﬁcantly improve fuel rod performance over the years. Today, signiﬁcant steps are being made to further improve nuclear safety by developing cladding materials that could possibly survive severe accidents similar to those that occurred at Three Mile Island Unit 2 and the Fukushima Daiichi Nuclear Power Plant, where release of ﬁssion products and hydrogen can be signiﬁcantly reduced, if not eliminated. This could make existing plants more passively safe in the event of a severe accident. The implementation of ATF cladding, together with advanced pellet materials, will improve safety and can also produce signiﬁcant economic beneﬁts for the fuel cycle and plants.},
	language = {en},
	urldate = {2023-01-02},
	journal = {Progress in Nuclear Energy},
	author = {Karoutas, Zeses and Brown, Jeffery and Atwood, Andrew and Hallstadius, Lars and Lahoda, Edward and Ray, Sumit and Bradfute, Jeffrey},
	month = jan,
	year = {2018},
	pages = {68--78},
}

@incollection{middleburgh_ceramics_2020,
	title = {Ceramics in the nuclear fuel cycle},
	isbn = {978-0-08-102726-4},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780081027264000028},
	language = {en},
	urldate = {2023-01-02},
	booktitle = {Advanced {Ceramics} for {Energy} {Conversion} and {Storage}},
	publisher = {Elsevier},
	author = {Middleburgh, Simon C. and Lee, William E. and Rushton, Michael J.D.},
	year = {2020},
	doi = {10.1016/B978-0-08-102726-4.00002-8},
	pages = {63--87},
}

@incollection{middleburgh_ceramics_2020-1,
	title = {Ceramics in the nuclear fuel cycle},
	isbn = {978-0-08-102726-4},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780081027264000028},
	language = {en},
	urldate = {2023-01-02},
	booktitle = {Advanced {Ceramics} for {Energy} {Conversion} and {Storage}},
	publisher = {Elsevier},
	author = {Middleburgh, Simon C. and Lee, William E. and Rushton, Michael J.D.},
	year = {2020},
	doi = {10.1016/B978-0-08-102726-4.00002-8},
	pages = {63--87},
}

@article{pearce_doppler_1961,
	title = {The {Doppler} effect in thermal reactors},
	volume = {13},
	issn = {03683265},
	url = {https://linkinghub.elsevier.com/retrieve/pii/036832656190007X},
	doi = {10.1016/0368-3265(61)90007-X},
	abstract = {Experimental and theoretical work on the Doppler effect in thermal reactors is reviewed for uranium metal, UOa, thorium metal, and ThO,. The experimental values of a, the fractional increase in resonance capture per “C, have a spread many times the quoted errors. The use of different slowing-down spectra has contributed to the discrepancies. For uranium metal, approximate corrections are made to obtain the coefficient a,, appropriate to a l/E spectrum. The spread in the corrected values a, is smaller than that for a, but remains unsatisfactory. Other experimental difficulties arise in reactivity normalizations, in obtaining the statistical weight of samples and from spurious temperature effects. Theory and experiment agree on an increase of a0 with increasing surface-to-mass ratio and that this is caused by an increase in the contribution of lower-energy resonances to the Doppler effect. It is also in agreement with the theoretical interpretation of theradial dependence of the Doppler effect in a lump. However in the region of practical interest where the surface-to-mass ratio is small, a0 is almost constant. Experimental evidence on the temperature behaviour of a0 is unsatisfactory but indicates that a0 decreases with increasing temperature. Theory predicts that a,, will vary approximately as T-l/* where T is the Kelvin temperature. In the case of non-uniform temperature distribution in a fuel element, both experimental and theoretical effort is needed.},
	language = {en},
	number = {3-4},
	urldate = {2023-01-02},
	journal = {Journal of Nuclear Energy. Part A. Reactor Science},
	author = {Pearce, R.M.},
	month = jan,
	year = {1961},
	pages = {150--175},
}

@article{pearce_doppler_1961-1,
	title = {The {Doppler} effect in thermal reactors},
	volume = {13},
	issn = {03683265},
	url = {https://linkinghub.elsevier.com/retrieve/pii/036832656190007X},
	doi = {10.1016/0368-3265(61)90007-X},
	abstract = {Experimental and theoretical work on the Doppler effect in thermal reactors is reviewed for uranium metal, UOa, thorium metal, and ThO,. The experimental values of a, the fractional increase in resonance capture per “C, have a spread many times the quoted errors. The use of different slowing-down spectra has contributed to the discrepancies. For uranium metal, approximate corrections are made to obtain the coefficient a,, appropriate to a l/E spectrum. The spread in the corrected values a, is smaller than that for a, but remains unsatisfactory. Other experimental difficulties arise in reactivity normalizations, in obtaining the statistical weight of samples and from spurious temperature effects. Theory and experiment agree on an increase of a0 with increasing surface-to-mass ratio and that this is caused by an increase in the contribution of lower-energy resonances to the Doppler effect. It is also in agreement with the theoretical interpretation of theradial dependence of the Doppler effect in a lump. However in the region of practical interest where the surface-to-mass ratio is small, a0 is almost constant. Experimental evidence on the temperature behaviour of a0 is unsatisfactory but indicates that a0 decreases with increasing temperature. Theory predicts that a,, will vary approximately as T-l/* where T is the Kelvin temperature. In the case of non-uniform temperature distribution in a fuel element, both experimental and theoretical effort is needed.},
	language = {en},
	number = {3-4},
	urldate = {2023-01-02},
	journal = {Journal of Nuclear Energy. Part A. Reactor Science},
	author = {Pearce, R.M.},
	month = jan,
	year = {1961},
	pages = {150--175},
}

@article{karoutas_maturing_2018-1,
	title = {The maturing of nuclear fuel: {Past} to {Accident} {Tolerant} {Fuel}},
	volume = {102},
	issn = {01491970},
	shorttitle = {The maturing of nuclear fuel},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197017301853},
	doi = {10.1016/j.pnucene.2017.07.016},
	abstract = {Nuclear fuel has made great strides from the advent of the nuclear industry at Shippingport to the ongoing development of Accident Tolerant Fuel (ATF) for potential implementation in commercial nuclear plants. The development of Zircaloy-2 fuel with UO2 pellets at Shippingport was revolutionary. Incremental advancements have been made from Zircaloy-2 cladding to Zircaloy-4, and more advanced cladding materials for PWRs and BWRs to signiﬁcantly improve fuel rod performance over the years. Today, signiﬁcant steps are being made to further improve nuclear safety by developing cladding materials that could possibly survive severe accidents similar to those that occurred at Three Mile Island Unit 2 and the Fukushima Daiichi Nuclear Power Plant, where release of ﬁssion products and hydrogen can be signiﬁcantly reduced, if not eliminated. This could make existing plants more passively safe in the event of a severe accident. The implementation of ATF cladding, together with advanced pellet materials, will improve safety and can also produce signiﬁcant economic beneﬁts for the fuel cycle and plants.},
	language = {en},
	urldate = {2023-01-02},
	journal = {Progress in Nuclear Energy},
	author = {Karoutas, Zeses and Brown, Jeffery and Atwood, Andrew and Hallstadius, Lars and Lahoda, Edward and Ray, Sumit and Bradfute, Jeffrey},
	month = jan,
	year = {2018},
	pages = {68--78},
}

@incollection{olander_light_2001,
	address = {Oxford},
	title = {Light {Water} {Reactor} {Fuel} {Design} and {Performance}},
	isbn = {978-0-08-043152-9},
	url = {https://www.sciencedirect.com/science/article/pii/B0080431526007877},
	language = {en},
	urldate = {2023-01-02},
	booktitle = {Encyclopedia of {Materials}: {Science} and {Technology}},
	publisher = {Elsevier},
	author = {Olander, D. R.},
	editor = {Buschow, K. H. Jürgen and Cahn, Robert W. and Flemings, Merton C. and Ilschner, Bernhard and Kramer, Edward J. and Mahajan, Subhash and Veyssière, Patrick},
	month = jan,
	year = {2001},
	doi = {10.1016/B0-08-043152-6/00787-7},
	pages = {4490--4504},
}

@article{hawari_pulstar_nodate-1,
	title = {{PULSTAR} {Reactor} {Power} {Upgrade} from 1- to 2-{MWth}},
	abstract = {An upgrade of the North Carolina State University PULSTAR reactor systems has been completed. The new systems are capable of supporting the increase in the reactor power from 1-MWth to 2-MWth. The PULSTAR is an open pool reactor fueled with uranium dioxide that is enriched to 4\% in U-235. Its design characteristics (that include a significant negative power coefficient of reactivity) render it inherently safe during normal operations and under the most sever of potential accidents. The PULSTAR is used in various applications including training and education, radiation testing, neutron activation analysis, and materials nondestructive examination using radiation beams. The completed upgrade included replacement of the primary and secondary cooling systems, a major refurbishment of instrumentation and control systems and installing a new facilitywide radiation monitoring system. In addition, due to increased operational demands, fresh PULSTAR fuel that is enriched to 6\% in U-235 will be utilized in the core. The required neutronic and thermal-hydraulic analysis is on-going to support the application to the US Nuclear Regulatory Commission for a license amendment for 2-MW operations. Consequently, it is expected that the introduced system upgrades and core modifications will result in enhancing the core lifetime and in effectively doubling the available radiation (neutron and gamma-ray) flux at the PULSTAR’s various in-pool and beam irradiation facilities.},
	language = {en},
	author = {Hawari, Ayman I},
}

@techreport{hawari_neutronic_2015,
	address = {Japan},
	title = {Neutronic analysis of the {PULSTAR} reactor using {Monte} {Carlo} simulations},
	abstract = {Neutronic analysis of the PULSTAR nuclear reactor was performed in support of its
utilization and power upgrade from 1-MWth to 2-MWth The PULSTAR is an open pool research
reactor that is currently fueled with UO\_2 enriched to 4\% in U-235 Detailed models
were constructed of its core using the MCNP6 Monte Carlo code and its standard nuclear
data libraries The models covered all eight variations of the core starting with the
first critical core in 1972 to the current core that was configured in 2011 Three
dimensional heterogeneous models were constructed that faithfully reflected the geometry
of the core and its surroundings using the original as-built engineering drawings
The Monte Carlo simulations benefited extensively from measurements that were performed
upon the loading of each core and its subsequent operation This includes power distribution
and peaking measurements, depletion measurements (reflecting a core's excess reactivity),
and measurements of reactivity feedback coefficients Furthermore, to support the PULSTAR's
fuel needs, the simulations explored the utilization of locally existing inventory
of fresh UO\_2 fuel that is enriched to 6\% in U-235 The analysis shows reasonable agreement
between the results of the MCNP6 simulations and the available measured data In general,
most discrepancies between simulations and measurements may be attributed to the limited
knowledge of the exact conditions of the historical measurements and the procedures
used to analyze the measured data Nonetheless, the results indicate the ability of
the constructed models to support safety analysis and licensing action in relation
to the on-going upgrades of the PULSTAR reactor (author)},
	author = {Hawari, Ayman I. and Wormald, Jonathan L. and Gillette, Victor H.},
	year = {2015},
	note = {JAEA-Conf--2014-003
INIS Reference Number: 47042899},
	pages = {9},
}

@article{van_dam_anomalous_2008-1,
	title = {Anomalous coolant temperature feedback effect in {LWRs}},
	volume = {35},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454908001163},
	doi = {10.1016/j.anucene.2008.04.006},
	abstract = {In neutronically large cores of power reactors anomalous reactivity effects can occur due to space-dependent coolant temperature feedback. These effects are contrary to reactor physical intuition, e.g. power increase after control rod insertion. A quantitative analysis and physical interpretation of these anomalies is presented, based on two relatively simple reactor models and application of adjoint function theory.},
	language = {en},
	number = {10},
	urldate = {2023-01-02},
	journal = {Annals of Nuclear Energy},
	author = {van Dam, Hugo},
	month = oct,
	year = {2008},
	pages = {1849--1856},
}

@misc{european_organization_for_nuclear_research_zenodo_2013,
	title = {Zenodo},
	url = {https://www.zenodo.org/},
	language = {en},
	publisher = {CERN},
	author = {{European Organization For Nuclear Research} and {OpenAIRE}},
	year = {2013},
	doi = {10.25495/7GXK-RD71},
	keywords = {Dataset, FOS: Physical sciences, Publication},
}

@book{clarke_model_1999,
	address = {Cambridge, Mass},
	title = {Model checking},
	isbn = {978-0-262-03270-4},
	publisher = {MIT Press},
	author = {Clarke, Edmund M. and Grumberg, Orna and Peled, Doron A.},
	year = {1999},
	keywords = {Computer systems, Verification},
}

@book{schneider_verification_2004,
	address = {Berlin ; New York},
	series = {Texts in theoretical computer science},
	title = {Verification of reactive systems: formal methods and algorithms},
	isbn = {978-3-540-00296-3},
	shorttitle = {Verification of reactive systems},
	publisher = {Springer-Verlag},
	author = {Schneider, Klaus},
	year = {2004},
	keywords = {Computer algorithms, Computer systems, Formal methods (Computer science), Verification},
}

@book{baier_principles_2008,
	address = {Cambridge, Mass},
	title = {Principles of model checking},
	isbn = {978-0-262-02649-9},
	publisher = {The MIT Press},
	author = {Baier, Christel and Katoen, Joost-Pieter},
	year = {2008},
	note = {OCLC: ocn171152628},
	keywords = {Computer software, Computer systems, Verification},
}

@article{kripke_semantical_1963,
	title = {Semantical {Considerations} on {Modal} {Logic}},
	volume = {16},
	url = {http://saulkripkecenter.org/wp-content/uploads/2019/03/Semantical-Considerations-on-Modal-Logic-PUBLIC.pdf},
	journal = {Acta Philosophica Fennica},
	author = {Kripke, Saul A.},
	year = {1963},
	pages = {83--94},
}

@inproceedings{bragg-sitton_reactor_2004,
	address = {Albuquerque, New Mexico (USA)},
	title = {Reactor {Start}-up and {Control} {Methodologies}: {Consideration} of the {Space} {Radiation} {Environment}},
	volume = {699},
	shorttitle = {Reactor {Start}-up and {Control} {Methodologies}},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1649623},
	doi = {10.1063/1.1649623},
	language = {en},
	urldate = {2022-12-29},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Bragg-Sitton, Shannon M.},
	year = {2004},
	note = {ISSN: 0094243X},
	pages = {614--622},
}

@incollection{bernardo_stochastic_2007,
	address = {Berlin, Heidelberg},
	title = {Stochastic {Model} {Checking}},
	volume = {4486},
	isbn = {978-3-540-72482-7 978-3-540-72522-0},
	url = {http://link.springer.com/10.1007/978-3-540-72522-0_6},
	language = {en},
	urldate = {2022-12-28},
	booktitle = {Formal {Methods} for {Performance} {Evaluation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David},
	editor = {Bernardo, Marco and Hillston, Jane},
	year = {2007},
	doi = {10.1007/978-3-540-72522-0_6},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {220--270},
}

@inproceedings{lal_bayesian_2020,
	address = {Jaipur, India},
	title = {Bayesian {Statistical} {Model} {Checking} for {Continuous} {Stochastic} {Logic}},
	isbn = {978-1-72819-148-5},
	url = {https://ieeexplore.ieee.org/document/9315001/},
	doi = {10.1109/MEMOCODE51338.2020.9315001},
	urldate = {2022-12-28},
	booktitle = {2020 18th {ACM}-{IEEE} {International} {Conference} on {Formal} {Methods} and {Models} for {System} {Design} ({MEMOCODE})},
	publisher = {IEEE},
	author = {Lal, Ratan and Duan, Weikang and Prabhakar, Pavithra},
	month = dec,
	year = {2020},
	pages = {1--11},
}

@article{aziz_model-checking_2000,
	title = {Model-checking continuous-time {Markov} chains},
	volume = {1},
	issn = {1529-3785, 1557-945X},
	url = {https://dl.acm.org/doi/10.1145/343369.343402},
	doi = {10.1145/343369.343402},
	abstract = {We present a logical formalism for expressing properties of continuous-time Markov chains. The semantics for such properties arise as a natural extension of previous work on discrete-time Markov chains to continuous time. The major result is that the verification problem is decidable; this is shown using results in algebraic and transcendental number theory.},
	language = {en},
	number = {1},
	urldate = {2022-12-28},
	journal = {ACM Transactions on Computational Logic},
	author = {Aziz, Adnan and Sanwal, Kumud and Singhal, Vigyan and Brayton, Robert},
	month = jul,
	year = {2000},
	pages = {162--170},
}

@article{kwiatkowska_controller_2007,
	title = {Controller dependability analysis by probabilistic model checking},
	volume = {15},
	issn = {09670661},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0967066106001262},
	doi = {10.1016/j.conengprac.2006.07.003},
	language = {en},
	number = {11},
	urldate = {2022-12-28},
	journal = {Control Engineering Practice},
	author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David},
	month = nov,
	year = {2007},
	pages = {1427--1434},
}

@incollection{bai_chapter_2014,
	address = {Boston},
	title = {Chapter 13 - {Risk}- and {Reliability}-{Based} {Fitness} for {Service}},
	isbn = {978-0-12-394432-0},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123944320000135},
	abstract = {The risk and reliability based fitness for service (FFS) discussed in this chapter focuses on pipeline corrosion defects, especially internal CO2 corrosion defects. First of all, quantitative risk assessment (QRA) is performed to derive the pipeline target reliability taking into account pipeline safety, environmental and economic consequences. Then, the capacity of each defect will be assessed based on a structure reliability assessment (SRA) method and the target reliability. By comparing pipeline retaining pressure capacity with a given MAOP, whether the pipeline is fit for service or not will be evaluated. An example of risk and reliability-based FFS given for a subsea oil export pipeline is presented in this chapter.},
	language = {en},
	urldate = {2022-12-27},
	booktitle = {Subsea {Pipeline} {Integrity} and {Risk} {Management}},
	publisher = {Gulf Professional Publishing},
	author = {Bai, Yong and Bai, Qiang},
	editor = {Bai, Yong and Bai, Qiang},
	month = jan,
	year = {2014},
	doi = {10.1016/B978-0-12-394432-0.00013-5},
	keywords = {Fitness for Service, Pipeline Corrosion Defects, Quantitative Risk Assessment, Risk and Reliability, Structure Reliability Assessment},
	pages = {289--305},
}

@incollection{basu_chapter_2017,
	title = {Chapter {III} - {Qualitative} {Hazard} {Analysis}},
	isbn = {978-0-12-803763-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128037638000030},
	abstract = {Qualitative hazard analysis is mainly utilized during the early stage of the project in its life cycle. Preliminary hazard analysis has been used extensively for early-stage hazard analysis in many industrial plants. In preliminary hazard analysis, hazards are identified, listed, and then analyzed with respect to their occurrence, frequencies, and consequences. Based on the risk matrix, risks are ranked. Based on risk ranking, control measures are developed. “What if” is based around brainstorming analysis by a small team of highly experienced engineers, but it is not systematic. Here, hazards are identified with the help of answering a set of questions asked in the form of “What if.” After frequency and consequence analysis, control measures are developed, to bring down the risk level to as low as reasonably practicable. A more structured method of analysis is checklist analysis, which uses a set of checklist points. Against this checklist, the design and operation of the plant are assessed. For deficiencies, necessary control measures are prescribed. There is another kind of qualitative hazard analysis: the “what if” checklist, where both methods are combined so that it is structured and uses the experience of the team to analyze the system. In all cases, suitable team selection, timing, and scope boundary definitions are very useful.},
	language = {en},
	urldate = {2022-12-27},
	booktitle = {Plant {Hazard} {Analysis} and {Safety} {Instrumentation} {Systems}},
	publisher = {Academic Press},
	author = {Basu, Swapan},
	editor = {Basu, Swapan},
	month = jan,
	year = {2017},
	doi = {10.1016/B978-0-12-803763-8.00003-0},
	keywords = {Control measures, Decision making, Facility-related issues, Hazard inventory, Hazard log, Preliminary hazard list, Qualitative hazard analysis, Risk matrix, Risk ranking, Scenario development},
	pages = {169--200},
}

@misc{noauthor_chapter_nodate,
	title = {Chapter {III} - {Qualitative} {Hazard} {Analysis} {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/B9780128037638000030?token=1C1DA52B3B1DB78F3A9B2EEA5D9D6166F841DDC86F84A23B4E7D33351C529A4B51612275885B92062FF625153273BA46&originRegion=us-east-1&originCreation=20221227200834},
	language = {en},
	urldate = {2022-12-27},
	doi = {10.1016/B978-0-12-803763-8.00003-0},
}

@misc{noauthor_industry-average_nodate,
	title = {Industry-{Average} {Performance} for {Components} and {Initiating} {Events} at {U}.{S}. {Commercial} {Nuclear} {Power} {P}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6928/index.html},
	language = {en-US},
	urldate = {2022-12-26},
}

@misc{us_epa_guidelines_2014,
	type = {Other {Policies} and {Guidance}},
	title = {Guidelines for {Exposure} {Assessment}},
	url = {https://www.epa.gov/risk/guidelines-exposure-assessment},
	abstract = {1992 final guidelines for exposure assessment.},
	language = {en},
	urldate = {2022-12-26},
	author = {US EPA, ORD},
	month = nov,
	year = {2014},
}

@misc{us_epa_uncertainty_2015,
	title = {Uncertainty and {Variability}},
	url = {https://www.epa.gov/expobox/uncertainty-and-variability},
	abstract = {EPA ExpoBox is a toolbox for exposure assessors. Its purpose is to provide a compendium of exposure assessment and risk characterization tools that will present comprehensive step-by-step guidance and links to relevant exposure assessment data bases},
	language = {en},
	urldate = {2022-12-26},
	author = {US EPA, ORD},
	month = may,
	year = {2015},
}

@techreport{hoffman_introductory_1992,
	title = {An introductory guide to uncertainty analysis in environmental and health risk assessment},
	url = {http://www.osti.gov/servlets/purl/7048843-w3b7uo/},
	language = {en},
	number = {ES/ER/TM-35, 7048843},
	urldate = {2022-12-23},
	author = {Hoffman, F.O. and Hammonds, J.S.},
	month = oct,
	year = {1992},
	doi = {10.2172/7048843},
	pages = {ES/ER/TM--35, 7048843},
}

@techreport{hicks_modular_2011,
	title = {Modular {HTGR} {Safety} {Basis} and {Approach}},
	number = {INL/EXT-11-22708},
	institution = {Idaho National Laboratory (INL)},
	author = {Hicks, Thomas and Petti, David and Kinsey, Jim and Gibbs, Greg},
	year = {2011},
}

@article{zheng_dynamic_2022,
	title = {Dynamic probabilistic risk assessment of nuclear power plants using multi-fidelity simulations},
	volume = {223},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022001636},
	doi = {10.1016/j.ress.2022.108503},
	abstract = {Dynamic probabilistic risk assessment (PRA) more explicitly treats timing issues and stochastic elements of risk models. It extensively resorts to iterative simulations of accident progressions for the quantification of risk triplets including accident scenarios, probabilities and consequences. Dynamic PRA leverages the level of detail for risk modeling while intricately increases computational complexities, which result in heavy computational cost. This paper proposes to apply multi-fidelity simulations for a cost-effective dynamic PRA. It applies and improves the multi-fidelity importance sampling (MFIS) algorithm to generate cost-effective samples of nuclear reactor accident sequences. Sampled accident sequences are simulated in a parallel manner by using mechanistic code, which is treated as a high-fidelity model. Adaptively trained by using high-fidelity data, low-fidelity model is used to predicting simulation results. Interested predictions with reactor core damages are sorted out to build density functions of the biased distribution for importance sampling. After when collect enough number of highfidelity data, risk triplets can be estimated. By solving a demonstration problem and a practical PRA problem by using MELCOR 2.2, the approach has been proven to be effective for risk assessment. Comparing with previous studies, the proposed multi-fidelity approach provides comparative estimation of risk triplets, while significantly reduces computational cost.},
	language = {en},
	urldate = {2022-12-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Zheng, Xiaoyu and Tamaki, Hitoshi and Sugiyama, Tomoyuki and Maruyama, Yu},
	month = jul,
	year = {2022},
	pages = {108503},
}

@misc{noauthor_epri_nodate,
	title = {{EPRI} {Guidelines} for {PRA} {Data} {Analysis}},
	url = {https://www.epri.com/research/products/3002000774},
	urldate = {2022-12-19},
}

@book{meeker_statistical_1998,
	address = {New York},
	series = {Wiley series in probability and statistics. {Applied} probability and statistics section},
	title = {Statistical methods for reliability data},
	isbn = {978-0-471-14328-4},
	publisher = {Wiley},
	author = {Meeker, William Q. and Escobar, Luis A.},
	year = {1998},
	keywords = {Reliability (Engineering), Statistical methods},
}

@book{lawless_statistical_2011,
	address = {Hoboken},
	edition = {2nd ed},
	title = {Statistical {Models} and {Methods} for {Lifetime} {Data}},
	isbn = {978-1-118-03125-4},
	abstract = {Praise for the First Edition"An indispensable addition to any serious collection on lifetime data analysis and ... a valuable contribution to the statistical literature. Highly recommended . . ."--Choice"This is an important book, which will appeal to statisticians working on survival analysis problems."-Biometrics"A thorough, unified treatment of statistical models and methods used in the analysis of lifetime data ... this is a highly competent and agreeable statistical textbook."-Statistics in MedicineThe statistical analysis of lifetime or response time data is a key tool in engineering},
	language = {eng},
	publisher = {John Wiley \& Sons},
	author = {Lawless, Jerald F.},
	year = {2011},
	note = {OCLC: 769341655},
}

@book{peacock_statistical_2013,
	address = {Hoboken, N.J.},
	title = {Statistical distributions},
	isbn = {978-1-118-09782-3},
	abstract = {BA new edition of the trusted guide on commonly used statistical distributions/b Fully updated to reflect the latest developments on the topic, iStatistical Distributions/i, Fourth Edition continues to serve as an authoritative guide on the application of statistical methods to research across various disciplines. The book provides a concise presentation of popular statistical distributions along with the necessary knowledge for their successful use in data modeling and analysis. Following a basic introduction, forty popular distributions are outlined in individual chapters that are complete with related facts and formulas. Reflecting the latest changes and trends in statistical distribution theory, the iFourth Edition/i features:ulliA new chapter on queuing formulas that discusses standard formulas that often arise from simple queuing systemsliMethods for extending independent modeling schemes to the dependent case, covering techniques for generating complex distributions from simple distributionsliNew coverage of conditional probability, including conditional expectations and joint and marginal distributionsliCommonly used tables associated with the normal (Gaussian), student-t, F and chi-square distributionsliAdditional reviewing methods for the estimation of unknown parameters, such as the method of percentiles, the method of moments, maximum likelihood inference, and Bayesian inference/ul bStatistical Distributions/b, Fourth Edition is an excellent supplement for upper-undergraduate and graduate level courses on the topic. It is also a valuable reference for researchers and practitioners in the fields of engineering, economics, operations research, and the social sciences who conduct statistical analyses},
	language = {eng},
	publisher = {Wiley},
	author = {Peacock, Brian and Hastings, Nicholas and Evans, Merran and Forbes, C. S.},
	year = {2013},
	note = {OCLC: 865010948},
}

@article{moormann_caution_2018,
	title = {Caution {Is} {Needed} in {Operating} and {Managing} the {Waste} of {New} {Pebble}-{Bed} {Nuclear} {Reactors}},
	volume = {2},
	issn = {25424351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2542435118303350},
	doi = {10.1016/j.joule.2018.07.024},
	language = {en},
	number = {10},
	urldate = {2022-12-15},
	journal = {Joule},
	author = {Moormann, Rainer and Kemp, R. Scott and Li, Ju},
	month = oct,
	year = {2018},
	pages = {1911--1914},
}

@techreport{morris_triso-coated_2004,
	title = {{TRISO}-{Coated} {Particle} {Fuel} {Phenomenon} {Identification} and {Ranking} {Tables} ({PIRTs}) for {Fission} {Product} {Transport} {Due} to {Manufacturing}, {Operations} and {Accidents}},
	language = {en},
	number = {NUREG/CR-6844, Vol. 1},
	institution = {US NRC},
	author = {Morris, R. N. and Petti, David A and Powers, D. A. and Boyack, B. E.},
	year = {2004},
}

@techreport{wells_triso_2021,
	type = {Code {Description} {Document}},
	title = {{TRISO} {Fuel}: {Properties} and {Failure} {Modes}},
	abstract = {This report documents the TRISO (TRi-structural ISOtropic) fuel particle properties for FAST (Fuel Analysis under Steady-state and Transients) analysis of TRISO fuel. An overview of the TRISO particle design and production process is provided, and material property data and recommended property selections are presented for each TRISO layer. TRISO particle failure mechanisms are summarized, and model codes that include these mechanisms are listed. Identification of failure limits is made where possible and is specific to the current thermalmechanical FAST model.},
	language = {en},
	number = {PNNL- 31427},
	institution = {Pacific Northwest National Laboratory},
	author = {Wells, BE and Phillips, NR and Geelhood, KJ},
	year = {2021},
}

@article{kwapis_tracking_2021,
	title = {Tracking of individual {TRISO}-fueled pebbles through the application of {X}-ray imaging with deep metric learning},
	volume = {140},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197021002742},
	doi = {10.1016/j.pnucene.2021.103913},
	abstract = {Modern pebble-bed reactor concepts utilizing TRISO-fueled pebbles use on-line continuous refueling, where fuel pebbles are continuously circulated through the reactor core. Presently, no method exists for the tagging, identification, and tracking of individual TRISO-fueled pebbles as they enter and exit the reactor core. This leaves room for improvement in the nuclear material accountability and nuclear safeguards of TRISO-fueled pebbles. This work presents a methodology to identify individual TRISO-fueled pebbles by exploiting the unique distribution of the TRISO-coated particles, which is imprinted during the manufacturing process, within individual TRISO-fueled pebbles. By combining X-ray imaging and deep learning, our method learns a mapping from radiographic images to a compact Euclidean space where distances provide a direct measurement of the similarity of pebble radiographs. A deep convolutional neural network is trained to optimize the image mapping and triplet loss is implemented to enforce a greater distance between mappings that identify different fuel pebbles. A dataset consisting of 1,250 radiographic Monte Carlo N-Particle (MCNP) Transport simulations of unique TRISO-fueled pebbles is generated for training and testing the deep learning algorithm, which achieves an accuracy of 93.49\% ± 9.35\% and by first transforming the dataset with Gaussian blur transformations it achieves an accuracy of 98.70\% ± 2.60\%.},
	language = {en},
	urldate = {2022-12-15},
	journal = {Progress in Nuclear Energy},
	author = {Kwapis, Emily H. and Liu, Hongcheng and Hartig, Kyle C.},
	month = oct,
	year = {2021},
	pages = {103913},
}

@article{seibert_production_2019,
	title = {Production and characterization of {TRISO} fuel particles with multilayered {SiC}},
	volume = {515},
	issn = {00223115},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002231151831198X},
	doi = {10.1016/j.jnucmat.2018.12.024},
	language = {en},
	urldate = {2022-12-15},
	journal = {Journal of Nuclear Materials},
	author = {Seibert, Rachel L. and Jolly, Brian C. and Balooch, Mehdi and Schappel, Daniel P. and Terrani, Kurt A.},
	month = mar,
	year = {2019},
	pages = {215--226},
}

@article{moore_studies_2002,
	title = {{STUDIES} {ON} {AIR} {INGRESS} {FOR} {PEBBLE} {BED} {REACTORS}},
	abstract = {A loss-of-coolant accident (LOCA) has been considered a critical event for helium-cooled pebbled bed reactors. Following helium depressurization, it is anticipated that unless countermeasures are taken air will enter the core through the break and then by molecular diffusion and ultimately by natural convection leading to oxidation of the in-core graphite structure and graphite pebbles. Thus, without any mitigating features a LOCA will lead to an air ingress event. The INEEL is studying such an event with two well-respected light water reactor transient response codes: RELAP5/ATHENA and MELCOR.},
	language = {en},
	author = {Moore, Richard L and Oh, Chang H and Merrill, Brad J and Petti, David A},
	year = {2002},
}

@article{hadad_modeling_2013,
	title = {{MODELING} {OF} {LAMINAR} {FORCED} {CONVECTION} {HEAT} {TRANSFER} {IN} {PACKED} {BEDS} {WITH} {PEBBLES} {OF} {ARBITRARY} {GEOMETRY}},
	volume = {16},
	issn = {1091-028X},
	url = {http://www.dl.begellhouse.com/journals/49dcde6d4c0809db,77e040f312e75763,7c3bd0526647de09.html},
	doi = {10.1615/JPorMedia.v16.i11.80},
	abstract = {Porous media are excessively well-known because of their frequent presence in nature and their special characteristics which make them appropriate for many scientiﬁc and technological purposes. High convection heat transfer coefﬁcient is one of the inherent worthwhile properties that has been investigated extensively. Porosity and pebble geometry have signiﬁcant effects on convection heat transfer in packed beds due to the fact that they are two important parameters which form the ﬂow pattern and local ﬂow conditions. Three different pebble geometries, namely sphere, cylinder, and cone, have been considered for studying the role of pebble geometry in the current work. Here, a general familiar model of convection heat transfer from isothermal bodies, next to some reliable experimental data from previous experiments, have been used as a basis to develop some comprehensive and more accurate correlations. On the other hand, previous works have not dealt with geometry thoroughly; additionally they do not typically cover the entire range of porosity and do not likewise preserve their accuracy over a wide range of Reynolds and Prandtl numbers. Thus, the present study includes different correlations for packed beds with spherical, cylindrical, and conical pebbles. Furthermore, general correlations for evaluation of forced convection heat transfer from isothermal beds with arbitrary pebble geometry and aspect ratio are also developed. In the end, results have been corroborated by comparison with previous works showing very good agreement for laminar ﬂows over all porosities and Prandtl numbers.},
	language = {en},
	number = {11},
	urldate = {2022-12-15},
	journal = {Journal of Porous Media},
	author = {Hadad, Yaser and Jafarpur, Khosrow},
	year = {2013},
	pages = {1049--1061},
}

@techreport{bruna_overview_2012,
	title = {Overview of {Generation} {IV} ({Gen} {IV}) {Reactor} {Designs}},
	language = {en},
	number = {IRSN Report 2012/158},
	institution = {IRSN},
	author = {Bruna, Giovanni B. and Bourgois, Thierry and Ivanov, Evgeny and Monhardt, Daniel},
	year = {2012},
}

@article{naghedolfeizi_x-ray_1998,
	title = {X-{Ray} {Fluorescence} {Microtomography} on a {SiC} {Nuclear} {Fuel} {Shell}},
	volume = {524},
	issn = {0272-9172, 1946-4274},
	url = {http://link.springer.com/10.1557/PROC-524-233},
	doi = {10.1557/PROC-524-233},
	abstract = {ABSTRACT
            
              TRISO fuel particles contain a small kernel of nuclear fuel encapsulated by alternating layers of C and a barrier layer of SiC. The TRISO fuel particle is used in an advanced nuclear fuel where the SiC shell provides the primary barrier for radioactive elements in the kernel. The performance of this barrier is key to containment. We have used x-ray fluorescence microtomography to measure the trace element distribution in a SiC shell. Prior to our measurements the nuclear fuel and C layers were leached from the particle. The shell was then encapsulated by kapton tape to simplify handling. The shell was mounted on a glass fiber and measurements were made with an ∼1 x3 ωm
              2
              x-ray probe on beamline 2-ID at the APS. The distribution of trace elements in the SIC shell was reconstructed after correcting the data for artifacts arising from absorption and scattering off the kapton tape. The observed trace elements are distributed in small {\textless}1ωm regions through the SiC shell. The trace elements can be attributed to radiation enhanced diffusion of elements in the kernel or to trace elements introduced during fabrication. X-ray fluorescence microtomography is an ideal tool for this work because it is a penetrating nondestructive probe sensitive to trace elements in a low Z matrix and because it provides a picture of the elemental distribution in the shell.},
	language = {en},
	urldate = {2022-12-14},
	journal = {MRS Proceedings},
	author = {Naghedolfeizi;, M. and Chung, J.-S. and Ice, G. E. and Yun, W. B. and Cai, Z. and Lai, B.},
	year = {1998},
	pages = {233},
}

@article{phillips_fabrication_2012,
	title = {Fabrication of uranium oxycarbide kernels and compacts for {HTR} fuel},
	volume = {251},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002954931100906X},
	doi = {10.1016/j.nucengdes.2011.10.033},
	language = {en},
	urldate = {2022-12-14},
	journal = {Nuclear Engineering and Design},
	author = {Phillips, Jeffrey A. and Nagley, Scott G. and Shaber, Eric L.},
	month = oct,
	year = {2012},
	pages = {261--281},
}

@techreport{rice_ceramography_2016,
	title = {Ceramography of {Irradiated} {TRISO} {Fuel} from the {AGR}-2 {Experiment}},
	number = {INL/EXT-16-39462},
	institution = {Idaho National Laboratory (INL)},
	author = {Rice, F. J. and Stempien, J. D. and Demkowicz, P. A.},
	year = {2016},
}

@article{swaminathan_event_1999,
	title = {The {Event} {Sequence} {Diagram} framework for dynamic {Probabilistic} {Risk} {Assessment}},
	volume = {63},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832098000271},
	doi = {10.1016/S0951-8320(98)00027-1},
	abstract = {Dynamic methodologies have become fairly established in academia. Their superiority over classical methods like Event Tree/Fault Tree techniques has been demonstrated. Despite this, dynamic methodologies have not enjoyed the support of the industry. One of the primary reasons for the lack of acceptance in the industry is that there is no easy way to qualitatively represent dynamic scenarios. This paper proposes to extend current Event Sequence Diagrams (ESDs) to allow modeling of dynamic situations. Under the proposed ESD representation, ESDs can be used in combination with dynamic methodology computational algorithms which will solve the underlying probabilistic dynamics equations. Once engineers are able to translate their knowledge of the system dynamics and accident evolution into simple ESDs, usage of dynamic methodologies will become more popular.},
	language = {en},
	number = {1},
	urldate = {2022-12-14},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Smidts, C.},
	month = jan,
	year = {1999},
	pages = {73--90},
}

@inproceedings{xie_layered_2010,
	title = {Layered {Modeling} of {Event} {Sequence} {Diagram} for {Dynamic} {Reliability} {Analysis} of {Nuclear} {Power} {Plant}},
	doi = {10.1109/APPEEC.2010.5448555},
	abstract = {As the event sequence diagram (ESD) methodology is used for modeling the complex system, the event simply describes system configuration and status in order to control the size of the model, so the model can't directly reflect the design and operation limitation. According to the hierarchy feature for the structure of nuclear power plant, a layered modeling of ESD is presented for marine nuclear power plant. Through introducing the fault tree analysis method and combining it with ESD, the weakness of the system can be found out. The ESD constructed through layered modeling is well arranged, distinct and with proper size, suitable for dynamic reliability analysis of nuclear power plant.},
	booktitle = {2010 {Asia}-{Pacific} {Power} and {Energy} {Engineering} {Conference}},
	author = {Xie, Hai-yan and Cai, Qi and Zhang, Yang-wei},
	month = mar,
	year = {2010},
	note = {ISSN: 2157-4847},
	keywords = {Delay effects, Design engineering, Educational institutions, Electrostatic discharge, Fault trees, Power engineering and energy, Power generation, Power system modeling, Power system reliability, Reliability engineering},
	pages = {1--3},
}

@article{rauzy_mathematical_2001,
	title = {Mathematical foundations of minimal cutsets},
	volume = {50},
	issn = {1558-1721},
	doi = {10.1109/24.983400},
	abstract = {Since their introduction in the reliability field, binary decision diagrams have proved to be the most efficient tool to assess Boolean models such as fault trees. Their success increases the need of sound mathematical foundations for the notions that are involved in reliability and dependability studies. This paper clarifies the mathematical status of the notion of minimal cutsets which have a central role in fault-tree assessment. Algorithmic issues are discussed. Minimal cutsets are distinct from prime implicants and they have a great interest from both a computation complexity and practical viewpoint. Implementation of BDD algorithms is explained. All of these algorithms are implemented in the Aralia software, which is widely used. These algorithms and their mathematical foundations were designed to assess efficiently a very large noncoherent fault tree that models the emergency shutdown system of a nuclear reactor.},
	number = {4},
	journal = {IEEE Transactions on Reliability},
	author = {Rauzy, A.},
	month = dec,
	year = {2001},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Algorithm design and analysis, Binary decision diagrams, Boolean algebra, Boolean functions, Data structures, Equations, Fault diagnosis, Fault trees, Mathematical model, Software algorithms},
	pages = {389--396},
}

@techreport{moe_risk-informed_2019,
	title = {Risk-{Informed} {Performance}-{Based} {Technology} {Inclusive} {Guidance} for {Advanced} {Reactor} {Licensing} {Basis} {Development}},
	url = {https://www.osti.gov/biblio/1557649},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-19-55375-Rev000},
	urldate = {2020-02-21},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Moe, Wayne L.},
	month = apr,
	year = {2019},
	doi = {10.2172/1557649},
}

@techreport{noauthor_white_2009,
	title = {White {Paper} on {Options} for {Risk} {Metrics} for {New} {Reactors}.},
	language = {en},
	institution = {US NRC},
	year = {2009},
}

@misc{boyer_probabilistic_2017,
	address = {NASA Johnson Space Center},
	title = {Probabilistic {Risk} {Assessment} ({PRA}): {Analytical} {Process} for {Recognizing} {Design} and {Operational} {Risks}},
	language = {en},
	author = {Boyer, Roger L},
	year = {2017},
}

@techreport{forrest_summary_2018,
	title = {Summary of a {Sandia} {National} {Laboratories} {Workshop} on {Extended} {Probabilistic} {Risk} {Assessment} ({ePRA})},
	language = {en},
	number = {SAND2018-6151C},
	institution = {Sandia National Lab.},
	author = {Forrest, Robert and Reinhardt, Jason and Wheeler, Timothy and Williams, Adam D},
	year = {2018},
}

@book{us_army_mdmp_2015,
	series = {Handbook},
	title = {{MDMP}: {Lessons} and {Best} {Practices}},
	url = {extension://elhekieabhbkpmcefcoobjddigjcaadp/https://usacac.army.mil/sites/default/files/publications/15-06_0.pdf},
	number = {15-06},
	publisher = {Center for Army Lessons Learned},
	author = {U.S. Army},
	month = mar,
	year = {2015},
}

@book{lee_risk_2011,
	address = {Hoboken, New Jersey},
	title = {Risk and {Safety} {Analysis} of {Nuclear} {Systems}},
	isbn = {978-0-470-90756-6},
	publisher = {Wiley},
	author = {Lee, John C. and McCormick, Norman J.},
	year = {2011},
	keywords = {Nuclear engineering, Nuclear facilities, Risk assessment, Safety measures, Security measures, TECHNOLOGY \& ENGINEERING / Chemical \& Biochemical},
}

@techreport{kim_nuclear_2022,
	title = {Nuclear {Waste} {Attributes} of {SMRs} {Scheduled} for {Near}-{Term} {Deployment}},
	url = {https://www.osti.gov/servlets/purl/1900154/},
	abstract = {The purpose of this study is to evaluate the nuclear waste attributes of Small Modular Reactors (SMRs) scheduled for deployment within this decade using available data and established nuclear waste metrics, with the results compared to a reference large Pressurized Water Reactor (PWR).},
	language = {en},
	number = {ANL/NSE-22/98 Rev. 1, 1900154, 179973},
	urldate = {2022-12-12},
	author = {Kim, T. and Boing, L. and Halsey, B and Dixon, B.},
	month = nov,
	year = {2022},
	doi = {10.2172/1900154},
	pages = {ANL/NSE--22/98 Rev. 1, 1900154, 179973},
}

@techreport{taylor_issues_1993,
	title = {{ISSUES} {PERTAINING} {TO} {THE} {ADVANCED} {REACTOR} ({PRISM}, {MHTGR}, {AND} {PIUS}) {AND} {CANDU} 3 {DESIGNS} {AND} {THEIR} {RELATIONSHIP} {TO} {CURRENT} {REGULATORY} {REQUIREMENTS}},
	language = {en},
	number = {SECY-93-092},
	institution = {US NRC},
	author = {Taylor, James M},
	year = {1993},
	pages = {92},
}

@article{taylor_issues_nodate,
	title = {{ISSUES} {PERTAINING} {TO} {THE} {ADVANCED} {REACTOR} ({PRISM}, {MHTGR}, {AND} {PIUS}) {AND} {CANDU} 3 {DESIGNS} {AND} {THEIR} {RELATIONSHIP} {TO} {CURRENT} {REGULATORY} {REQUIREMENTS}},
	language = {en},
	author = {Taylor, James M},
	pages = {92},
}

@misc{noauthor_ml19249b632pdf_nodate,
	title = {{ML19249B632}.pdf},
}

@techreport{andrews_mechanistic_2020,
	title = {Mechanistic {Source} {Term} {Considerations} for {Advanced} {Non}-{LWRs}},
	url = {https://www.osti.gov/servlets/purl/1638572/},
	language = {en},
	number = {SAND--2020-6730, 1638572, 687170},
	urldate = {2022-12-09},
	author = {Andrews, Nathan and Nenoff, Tina and Luxat, David and Clark, Andrew and Leute, Jennifer},
	month = jul,
	year = {2020},
	doi = {10.2172/1638572},
	pages = {SAND--2020--6730, 1638572, 687170},
}

@incollection{reventos_parameters_2017,
	title = {Parameters and concepts},
	isbn = {978-0-08-100662-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780081006627000038},
	abstract = {Parameters and concepts are introduced in order to provide a view of nuclear thermal hydraulics covering from the bases to the application of the discipline. Namely, selected cross-cutting issues from the thermal hydraulics universe are defined. This view is essential for understanding the content of the book and for self-confirming the level of understanding of thermal hydraulics by the reader. Two phase flows and heat transfer are concerned together with safety concepts. Examples moving from bases to applications are the fundamental relationship of thermal hydraulics involving quality, void fraction, slip ratio and pressure, the steam binding phenomenon, the design basis accident, the defense in depth, and the final safety analysis report.},
	language = {en},
	urldate = {2022-12-09},
	booktitle = {Thermal-{Hydraulics} of {Water} {Cooled} {Nuclear} {Reactors}},
	publisher = {Elsevier},
	author = {Reventos, F.},
	year = {2017},
	doi = {10.1016/B978-0-08-100662-7.00003-8},
	pages = {89--141},
}

@inproceedings{joubert_south_2008,
	address = {Washington, DC, USA},
	title = {South {African} {Safety} {Assessment} {Framework} for the {Pebble} {Bed} {Modular} {Reactor}},
	isbn = {978-0-7918-4855-5},
	url = {https://asmedigitalcollection.asme.org/HTR/proceedings/HTR2008/48555/193/335288},
	doi = {10.1115/HTR2008-58192},
	abstract = {It is planned to construct a first of a kind Pebble Bed Modular Reactor (PBMR) in South Africa. A need has been recognized to accompany the licensing process for the PBMR with independent safety assessments to ensure that the safety case submitted by the applicant complies with the licensing requirements of the NNR. At the HTR 2006 Conference, the framework and major challenges on safety assessment that the South African National Nuclear Regulator (NNR) faces in developing and applying appropriate strategies and tools were presented. This paper discusses the current status of the various NNR assessment activities and describes how this will be considered in the NNR Final Report on the PBMR Safety Case.},
	language = {en},
	urldate = {2022-12-08},
	booktitle = {Fourth {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology}, {Volume} 2},
	publisher = {ASMEDC},
	author = {Joubert, Jean and Kohtz, Norbert and Coe, Ian},
	month = jan,
	year = {2008},
	pages = {193--203},
}

@techreport{afzali_molten_2019,
	title = {Molten {Salt} {Reactor} {Experiment} ({MSRE}) {Case} {Study} {Using} {Risk}‐{Informed}, {Performance} - {Based} {Technical} {Guidance} to {Inform} {Future} {Licensing} for {Advanced} {Non}‐{Light} {Water} {Reactors}},
	number = {EPRI AR LR 2019‐06},
	institution = {Southern Company},
	author = {Afzali, Amir},
	year = {2019},
}

@techreport{sowder_program_2018,
	type = {2018 {Technical} {Report}},
	title = {Program on {Technology} {Innovation}: {Early} {Integration} of {Safety} {Assessment} into {Advanced} {Reactor} {Design} - {Preliminary} {Body} of {Knowledge} and {Methodology}},
	language = {en},
	number = {3002011801},
	institution = {Electric Power Research Institute},
	author = {Sowder, A.},
	year = {2018},
	pages = {120},
}

@techreport{marciulescu_program_2019,
	type = {2019 {Technical} {Report}},
	title = {Program on {Technology} {Innovation}: {Early} {Integration} of {Safety} {Assessment} into {Advanced} {Reactor} {Design} - {Project} {Capstone} {Report}},
	language = {en},
	number = {3002015752},
	institution = {Electric Power Research Institute},
	author = {Marciulescu, C.},
	year = {2019},
	pages = {188},
}

@article{oberkampf_what_2001,
	title = {{WHAT} {ARE} {VALIDATION} {EXPERIMENTS}?},
	volume = {25},
	issn = {0732-8818, 1747-1567},
	url = {http://doi.wiley.com/10.1111/j.1747-1567.2001.tb00023.x},
	doi = {10.1111/j.1747-1567.2001.tb00023.x},
	language = {en},
	number = {3},
	urldate = {2022-12-07},
	journal = {Experimental Techniques},
	author = {Oberkampf, W.L.},
	month = may,
	year = {2001},
	pages = {35--40},
}

@incollection{noauthor_hazard_2012,
	title = {Hazard {Assessment}},
	isbn = {978-0-12-397189-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780123971890000094},
	language = {en},
	urldate = {2022-12-07},
	booktitle = {Lees' {Loss} {Prevention} in the {Process} {Industries}},
	publisher = {Elsevier},
	year = {2012},
	doi = {10.1016/B978-0-12-397189-0.00009-4},
	pages = {284--404},
}

@techreport{noauthor_apr_nodate,
	title = {{APR} 1400 {Design} {Control} {Document} : {Chapter} 7 {Instrumentation} and {Control}},
	url = {https://www.nrc.gov/docs/ML1822/ML18228A654.pdf},
	urldate = {2022-10-03},
}

@misc{noauthor_mechatronic_nodate,
	title = {Mechatronic {Systems} {Design} {Methods}, {Models}, {Concepts} by {Klaus} {Janschek} {\textbar} {Technical} {Books} {Pdf} {\textbar} {Download} {Free} {PDF} {Books}, {Notes}, and {Study} {Material}...},
	url = {https://www.technicalbookspdf.com/mechatronic-systems-design-methods-models-concepts-by-klaus-janschek/},
	language = {en-US},
	urldate = {2022-12-07},
}

@techreport{cadwallader_preliminary_2007,
	title = {Preliminary {Failure} {Modes} and {Effects} {Analysis} of the {US} {DCLL} {Test} {Blanket} {Module}},
	language = {en},
	number = {INL/EXT-07-13115},
	institution = {Idaho National Laboratory (INL)},
	author = {Cadwallader, Lee C},
	year = {2007},
	pages = {158},
}

@techreport{aldemir_dynamic_2007,
	title = {Dynamic {Reliability} {Modeling} of {Digital} {Instrumentation} and {Control} {Systems} for {Nuclear} {Reactor} {Probabilistic} {Risk} {Assessments}},
	language = {en},
	number = {NUREG/CR-6942},
	institution = {Ohio State University},
	author = {Aldemir, T. and Stovsky, M. P. and Kirschenbaum, J. and Mandelli, D. and Bucci, P. and Mangan, L. A. and Miller, D. W. and Sun, X. and Ekici, E. and Guarro, S. and Yau, M. and Johnson, B. and Elks, C. and {Arndt}},
	year = {2007},
	pages = {290},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC}: {Package} {ML12067A245} - 0554 - {F201S} - {Fuel} {Cycle} {Processes}.},
	url = {https://www.nrc.gov/docs/ML1206/ML12067A245.html},
	urldate = {2022-12-06},
}

@article{noauthor_containment_2014,
	title = {Containment integrity evaluation of {MSF}-type cask for interim storage and transport of {PWR} spent fuel},
	volume = {117-118},
	issn = {0308-0161},
	url = {http://www.sciencedirect.com/science/article/pii/S0308016113001518},
	doi = {10.1016/j.ijpvp.2013.10.007},
	abstract = {Many spent fuel storage pools in nuclear plant facilities are now reaching their full capacity in Japan. As a solution of this issue, Mitsubishi Heavy…},
	language = {en},
	urldate = {2022-12-06},
	journal = {International Journal of Pressure Vessels and Piping},
	month = may,
	year = {2014},
	note = {Publisher: Elsevier},
	pages = {33--41},
}

@article{rimkevicius_hazop_2016,
	title = {{HAZOP} application for the nuclear power plants decommissioning projects},
	volume = {94},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454916301906},
	doi = {10.1016/j.anucene.2016.04.027},
	abstract = {Decommissioning of nuclear facilities involves different types of activities, tools, equipment and systems. There is a potential for a wide range of radiological and industrial accidents during various stages of a decommissioning project creating risk for workers and the environment. The occurrence of accidents is possible due to many different operations involving movement and handling of large pieces of equipment and contaminated items. In addition, size reduction and decontamination processes are capable of producing hazards. One of the ﬁrst steps in developing a safety assessment for decommissioning activities is the identiﬁcation of hazards that can affect workers, members of the public and the environment during decommissioning activities, and then to identify engineered and administrative control measures to prevent, eliminate or mitigate the hazards and their consequences. Fault and hazard identiﬁcation can be undertaken in several ways using a range of tools and techniques, including Hazard and Operability Study (HAZOP).},
	language = {en},
	urldate = {2022-12-05},
	journal = {Annals of Nuclear Energy},
	author = {Rimkevičius, Sigitas and Vaišnoras, Mindaugas and Babilas, Egidijus and Ušpuras, Eugenijus},
	month = aug,
	year = {2016},
	pages = {461--471},
}

@article{noauthor_layers_nodate,
	title = {Layers of {Protection} {Analysis}},
	language = {en},
	pages = {104},
}

@book{gaol_proceedings_2012,
	address = {Berlin, Heidelberg},
	series = {Advances in {Intelligent} and {Soft} {Computing}},
	title = {Proceedings of the 2011 2nd {International} {Congress} on {Computer} {Applications} and {Computational} {Science}},
	volume = {144},
	isbn = {978-3-642-28313-0 978-3-642-28314-7},
	url = {http://link.springer.com/10.1007/978-3-642-28314-7},
	language = {en},
	urldate = {2022-12-05},
	publisher = {Springer Berlin Heidelberg},
	editor = {Gaol, Ford Lumban and Nguyen, Quang Vinh},
	year = {2012},
	doi = {10.1007/978-3-642-28314-7},
}

@article{li_risk_2016,
	title = {Risk analysis for the supplier selection problem using failure modes and effects analysis ({FMEA})},
	volume = {27},
	issn = {0956-5515, 1572-8145},
	url = {http://link.springer.com/10.1007/s10845-014-0953-0},
	doi = {10.1007/s10845-014-0953-0},
	abstract = {While seeking for global suppliers is a general trend for lower cost and better quality, it is not trivial for a company to assess the corresponding risks in supplier selection. This paper proposes the supplier selection method that applies failures modes and effects analysis (FMEA) to assess the risks in the decision process. As each supplier is evaluated under the common multi-criteria framework, risks are viewed as the possible deviations from expected performance, and they are interpreted as failure modes in risk analysis. Following the concepts of FMEA, each failure mode is examined with respect to the possible causes and effects. This method generates two technical deliverables for supporting risk analysis. Firstly, the FMEA document is developed to support the team’s discussion of supplier risks and accumulate the risk knowledge within the company. Secondly, the ranking numbers based on FMEA (i.e., risk priority numbers) are utilized to evaluate a discount on a supplier’s performance according to their risk level. A real-case example about selecting methanol suppliers in the global market is used to demonstrate the proposed method for risk analysis in practice.},
	language = {en},
	number = {6},
	urldate = {2022-12-05},
	journal = {Journal of Intelligent Manufacturing},
	author = {Li, Simon and Zeng, Wei},
	month = dec,
	year = {2016},
	pages = {1309--1321},
}

@article{koike_combining_2022,
	title = {Combining failure modes and effects analysis and cause–effect analysis: a novel method of risk analysis to reduce anaphylaxis due to contrast media},
	volume = {34},
	issn = {1353-4505, 1464-3677},
	shorttitle = {Combining failure modes and effects analysis and cause–effect analysis},
	url = {https://academic.oup.com/intqhc/article/doi/10.1093/intqhc/mzac002/6506183},
	doi = {10.1093/intqhc/mzac002},
	abstract = {Background: Contrast media agents are essential for computed tomography (CT)-based diagnoses. However, they can cause fatal adverse effects such as anaphylaxis in patients. Although it is rare, the chances of anaphylaxis increase with the number of examinations.
Objective: We aimed to design a quality improvement initiative to reduce patient risk to contrast media agents.
Methods: We analysed CT processes using contrast iodine in a tertiary-care academic hospital that performs approximately 14 000 CT scans per year in Japan. We applied a combination of failure modes and effects analysis (FMEA) and cause–effect analysis to reduce the risk of patients developing allergic reactions to iodine-based contrast agents during CT imaging.
Results: Our multidisciplinary team comprising seven professionals analysed the data and designed a 56-process flowchart of CT imaging with iodine. We obtained 177 failure modes, of which 15 had a risk-probability number higher than 100. We identified the two riskiest processes and developed cause-and-effect diagrams for both: one was related to the exchange of information between the radiation and hospital information system regarding the patient’s allergy, the other was due to education and structural deficiencies in observation following the exam.
Conclusion: The combined method of FMEA and cause-and-effect analysis reveals high-risk processes and suggests measures to reduce these risks. FMEA is not well-known in healthcare but has significant potential for improving patient safety. Our findings emphasise the importance of adopting new techniques to reduce patient risk and carry out best practices in radiology.},
	language = {en},
	number = {1},
	urldate = {2022-12-05},
	journal = {International Journal for Quality in Health Care},
	author = {Koike, Daisuke and Yamakami, Junichi and Miyashita, Terumi and Kataoka, Yumi and Nishida, Hiroshi and Hattori, Hidekazu and Yasuda, Ayuko},
	month = feb,
	year = {2022},
}

@article{chi_classification_2020,
	title = {Classification {Scheme} for {Root} {Cause} and {Failure} {Modes} and {Effects} {Analysis} ({FMEA}) of {Passenger} {Vehicle} {Recalls}},
	volume = {200},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832019311123},
	doi = {10.1016/j.ress.2020.106929},
	abstract = {This study analysed 345 passenger vehicle recalls that were reported to the National Highway Traffic Safety Administration. The root cause analysis was applied to analyse each recall event in order to derive the cause of the recall, i.e., the defect type. Classification schemes were developed to organize the defective components and defect type into useful categories. The defect types were classified into manufacturing defects, design flaws, and mislabelling. Each of the above categories was expanded into smaller subcategories and items. Following the root cause analysis, the functional block diagram, and failure modes and effects analysis (FMEA) were applied to translate defective recall cases into FMEA tabular statements. Cramer's V and Phi coefficient analyses were applied to identify significant associations between defective components and defect types to prevent the future recurrence of recalls and improve vehicle quality. This study demonstrated that root cause and FMEA, based on an orthogonal classification scheme, can be applied to derive feasible solutions for reducing vehicle safety recalls, and such analysis can be generalized to other products or manufacturing processes.},
	language = {en},
	urldate = {2022-12-05},
	journal = {Reliability Engineering \& System Safety},
	author = {Chi, Chia-Fen and Sigmund, Davin and Astardi, Martin Octavianus},
	month = aug,
	year = {2020},
	pages = {106929},
}

@article{huq_report_2016,
	title = {The report of {Task} {Group} 100 of the {AAPM}: {Application} of risk analysis methods to radiation therapy quality management: {TG} 100 report},
	volume = {43},
	issn = {00942405},
	shorttitle = {The report of {Task} {Group} 100 of the {AAPM}},
	url = {http://doi.wiley.com/10.1118/1.4947547},
	doi = {10.1118/1.4947547},
	language = {en},
	number = {7},
	urldate = {2022-12-05},
	journal = {Medical Physics},
	author = {Huq, M. Saiful and Fraass, Benedick A. and Dunscombe, Peter B. and Gibbons, John P. and Ibbott, Geoffrey S. and Mundt, Arno J. and Mutic, Sasa and Palta, Jatinder R. and Rath, Frank and Thomadsen, Bruce R. and Williamson, Jeffrey F. and Yorke, Ellen D.},
	month = jun,
	year = {2016},
	pages = {4209--4262},
}

@article{bright_failure_2022,
	title = {Failure modes and effects analysis for surface-guided {DIBH} breast radiotherapy},
	number = {Radiation Oncology Physics},
	journal = {Journal of Applied Clinical Medical Physics},
	author = {Bright, Megan and Foster, Ryan and Hampton, Carnell and Ruiz, Justn and Moeller, Benjamin},
	year = {2022},
}

@article{liu_risk_2013,
	title = {Risk evaluation approaches in failure mode and effects analysis: {A} literature review},
	volume = {40},
	issn = {09574174},
	shorttitle = {Risk evaluation approaches in failure mode and effects analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417412009712},
	doi = {10.1016/j.eswa.2012.08.010},
	abstract = {Failure mode and effects analysis (FMEA) is a risk assessment tool that mitigates potential failures in systems, processes, designs or services and has been used in a wide range of industries. The conventional risk priority number (RPN) method has been criticized to have many deﬁciencies and various risk priority models have been proposed in the literature to enhance the performance of FMEA. However, there has been no literature review on this topic. In this study, we reviewed 75 FMEA papers published between 1992 and 2012 in the international journals and categorized them according to the approaches used to overcome the limitations of the conventional RPN method. The intention of this review is to address the following three questions: (i) Which shortcomings attract the most attention? (ii) Which approaches are the most popular? (iii) Is there any inadequacy of the approaches? The answers to these questions will give an indication of current trends in research and the best direction for future research in order to further address the known deﬁciencies associated with the traditional FMEA.},
	language = {en},
	number = {2},
	urldate = {2022-12-05},
	journal = {Expert Systems with Applications},
	author = {Liu, Hu-Chen and Liu, Long and Liu, Nan},
	month = feb,
	year = {2013},
	pages = {828--838},
}

@inproceedings{grabaskas_methodology_2016,
	address = {Charlotte, North Carolina, USA},
	title = {A {Methodology} for the {Integration} of a {Mechanistic} {Source} {Term} {Analysis} in a {Probabilistic} {Framework} for {Advanced} {Reactors}},
	isbn = {978-0-7918-5002-2},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE24/50022/Charlotte,%20North%20Carolina,%20USA/252180},
	doi = {10.1115/ICONE24-60759},
	abstract = {GE Hitachi Nuclear Energy (GEH) and Argonne National Laboratory are currently engaged in a joint effort to modernize and develop probabilistic risk assessment (PRA) techniques for advanced non-light water reactors. At a high level, the primary outcome of this project will be the development of nextgeneration PRA methodologies that will enable risk-informed prioritization of safety- and reliability-focused research and development, while also identifying gaps that may be resolved through additional research. A subset of this effort is the development of PRA methodologies to conduct a mechanistic source term (MST) analysis for event sequences that could result in the release of radionuclides. The MST analysis seeks to realistically model and assess the transport, retention, and release of radionuclides from the reactor to the environment. The MST methods developed during this project seek to satisfy the requirements of the Mechanistic Source Term element of the ASME/ANS Non-LWR PRA standard. The MST methodology consists of separate analysis approaches for risksignificant and non-risk significant event sequences that may result in the release of radionuclides from the reactor. For risksignificant event sequences, the methodology focuses on a detailed assessment, using mechanistic models, of radionuclide release from the fuel, transport through and release from the primary system, transport in the containment, and finally release to the environment. The analysis approach for non-risk significant event sequences examines the possibility of large radionuclide releases due to events such as re-criticality or the complete loss of radionuclide barriers. This paper provides details on the MST methodology, including the interface between the MST analysis and other elements of the PRA, and provides a simplified example MST calculation for a sodium fast reactor.},
	language = {en},
	urldate = {2022-12-05},
	booktitle = {Volume 2: {Smart} {Grids}, {Grid} {Stability}, and {Offsite} and {Emergency} {Power}; {Advanced} and {Next} {Generation} {Reactors}, {Fusion} {Technology}; {Safety}, {Security}, and {Cyber} {Security}; {Codes}, {Standards}, {Conformity} {Assessment}, {Licensing}, and {Regulatory} {Issues}},
	publisher = {American Society of Mechanical Engineers},
	author = {Grabaskas, Dave and Brunett, Acacia J. and Bucknor, Matthew},
	month = jun,
	year = {2016},
	pages = {V002T06A030},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/servlets/purl/1700670/},
	language = {en},
	number = {INL/EXT--20-60395, SC--29980-101-Rev.01, 1700670},
	urldate = {2022-12-05},
	author = {Moe, Wayne and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700670},
	pages = {INL/EXT--20--60395, SC--29980--101--Rev.01, 1700670},
}

@inproceedings{lee_analysis_2017,
	title = {Analysis of {Initiating} {Events} for {SMART} using {Heat} {Balance} {Fault} {Tree} {Method}},
	language = {en},
	author = {Lee, Hansul and Park, Jinhee},
	year = {2017},
	pages = {4},
}

@techreport{noauthor_defining_1993,
	title = {Defining initiating events for purposes of probabilistic safety assessment},
	language = {en},
	number = {IAEA-TECDOC-719},
	institution = {IAEA},
	year = {1993},
	pages = {152},
}

@inproceedings{cho_initiating_2005,
	title = {Initiating {Events} {Identification} of the {IS} {Process} {Using} the {Master} {Logic} {Diagram}},
	language = {en},
	booktitle = {Proceedings of the {Korean} {Nuclear} {Society} {Conference}},
	author = {Cho, Nam-Chul and Jae, Moosung and Joon-Eon, Yang},
	year = {2005},
	pages = {55--56},
}

@article{hamza_identifying_nodate,
	title = {Identifying and {Quantifying} a {Complete} {Set} of {Full}-{Power} {Initiating} {Events} {During} {Early} {Design} {Stages} of {High}-{Temperature} {Gas}-{Cooled} {Reactors}},
	language = {en},
	author = {Hamza, Mostafa and Joslin, Nick and McSweeney, Luke and Liao, Huafei and Vivanco, Alaina and Lawson, Glen and Diaconeasa, A},
	pages = {19},
}

@techreport{han_identification_2003,
	title = {Identification of {Initiating} {Events} {Using} the {Master} {Logic} {Diagram} in {Low}-{Power} and {Shutdown} {PSA} for {Nuclear} {Power} {Plant}},
	abstract = {In probabilistic safety assessment (PSA) for nuclear power plants (NPP), the initiating event analysis should provide a reasonably complete set of abnormal events that potentially
can lead to a consequential risk to be caused by challenging normal plant operation. For this purpose, generally an empirical approach utilizing operational experiences has been mainly
used for the low-power and shutdown (LPSD) PSA, while a systematic approach such as a
master logic diagram (MLD) for the full-power PSA. The empirical approach facilitates the
process for an identification of initiating events, but on the other hand it can not guarantee the completeness of initiating events sufficiently. A new methodology, in this study, was explored to improve the completeness of initiating events to be identified for LPSD PSA.
The proposed method is an approach of MLD reflecting the characteristics of LPSD operations. The MLD technique is a deductive tool using a top-down approach, which can do a formal and logical identification of initiating events. It is expected that the new approach can help PSA analyst facilitate the identification process of initiating events, as well as
guarantee reasonably completeness of initiating events for LPSD PSA},
	language = {en},
	number = {KAERI/TR-2497/2003},
	institution = {KAERI},
	author = {Han, Seokjung and Park, Jinhee and Jang, Seungchul},
	year = {2003},
	pages = {45},
}

@techreport{garrick_seabrook_1982,
	title = {Seabrook {Station} {Probabilistic} {Safety} {Assessment}},
	language = {en},
	number = {PLG-0242},
	institution = {Pickard, Lowe and Garrick, Inc.},
	author = {Garrick, B. J. and Fleming, K. N.},
	year = {1982},
	pages = {226},
}

@techreport{usdoe_washington_dc_united_states_process_1996,
	title = {Process safety management for highly hazardous chemicals},
	url = {http://www.osti.gov/servlets/purl/215874-qC510F/webviewable/},
	language = {en},
	number = {DOE-HDBK--1101-96, 215874},
	urldate = {2022-12-04},
	author = {{USDOE, Washington, DC (United States)}},
	month = feb,
	year = {1996},
	doi = {10.2172/215874},
	pages = {DOE--HDBK--1101--96, 215874},
}

@article{botev_kernel_2010,
	title = {Kernel density estimation via diffusion},
	volume = {38},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-38/issue-5/Kernel-density-estimation-via-diffusion/10.1214/10-AOS799.full},
	doi = {10.1214/10-AOS799},
	number = {5},
	urldate = {2022-12-02},
	journal = {The Annals of Statistics},
	author = {Botev, Z. I. and Grotowski, J. F. and Kroese, D. P.},
	month = oct,
	year = {2010},
}

@techreport{han_identification_2003-1,
	title = {Identification of {Initiating} {Events} {Using} the {Master} {Logic} {Diagram} in {Low}-{Power} and {Shutdown} {PSA} for {Nuclear} {Power} {Plant}},
	language = {en},
	number = {KAERI/TR-2497/2003},
	author = {Han, seok-joong and Park, Jinhee and Jang, Seungchul},
	year = {2003},
	pages = {45},
}

@article{__nodate,
	title = {본 보고서를 2002년도 “정지/저출력 및 디지털 계통 위험도 평가기술 개발”},
	language = {en},
	author = {귀하, 한국원자력연구소장},
	pages = {45},
}

@article{papazoglou_master_2003,
	title = {Master {Logic} {Diagram}: method for hazard and initiating event identification in process plants},
	volume = {97},
	issn = {03043894},
	shorttitle = {Master {Logic} {Diagram}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304389402002443},
	doi = {10.1016/S0304-3894(02)00244-3},
	abstract = {Master Logic Diagram (MLD), a method for identifying events initiating accidents in chemical installations, is presented. MLD is a logic diagram that resembles a fault tree but without the formal mathematical properties of the latter. MLD starts with a Top Event “Loss of Containment” and decomposes it into simpler contributing events. A generic MLD has been developed which may be applied to all chemical installations storing toxic and/or ﬂammable substances. The method is exempliﬁed through its application to an ammonia storage facility.},
	language = {en},
	number = {1-3},
	urldate = {2022-12-01},
	journal = {Journal of Hazardous Materials},
	author = {Papazoglou, I.A and Aneziris, O.N},
	month = feb,
	year = {2003},
	pages = {11--30},
}

@article{oberkampf_verification_nodate,
	title = {Verification and {Validation} in {Scientific} {Computing}},
	language = {en},
	author = {Oberkampf, William L and Roy, Christopher J},
	pages = {791},
}

@article{oberkampf_verification_nodate-1,
	title = {Verification and {Validation} in {Scientific} {Computing}},
	language = {en},
	author = {Oberkampf, William L and Roy, Christopher J},
	pages = {791},
}

@article{braverman_impact_2003,
	title = {{IMPACT} {ANALYSIS} {OF} {SPENT} {FUEL} {DRY} {CASKS} {UNDER} {ACCIDENTAL} {DROP} {SCENARIOS}},
	volume = {BNL-NUREG-71196-2003-CP},
	abstract = {A series of analyses were performed to assess the structural response of spent nuclear fuel dry casks subjected to various handling and on-site transfer events. The results of these analyses are being used by the Nuclear Regulatory Commission (NRC) to perform a probabilistic risk assessment (PRA). Although the PRA study is being performed for a specific nuclear plant, the PRA study is also intended to provide a framework for a general methodology that could also be applied to other dry cask systems at other nuclear plants.},
	language = {en},
	author = {Braverman', J. I. and Morante', R. J. and Xu', J. and Hofmayer, C. H. and Shaukat, S. K.},
	year = {2003},
	pages = {8},
}

@techreport{noauthor_nrc_2020,
	title = {{NRC} {Non}-{Light} {Water} {Reactor} ({Non}-{LWR}) {Vision} and {Strategy}, {Volume} 3 - {Computer} {Code} {Development} {Plans} for {Severe} {Accident} {Progression}, {Source} {Term}, and {Consequence} {Analysis}},
	institution = {US NRC},
	year = {2020},
}

@techreport{herczeg_probabilistic_1987,
	title = {{PROBABILISTIC} {RISK} {ASSESSMENT} {FOR} {THE} {STANDARD} {MODULAR} {HIGH} {TEMPERATURE} {GAS}-{COOLED} {REACTOR}},
	number = {DOE-HTGR-86-011},
	institution = {Civilian Reactor Development, Office of Nuclear Energy},
	author = {Herczeg, John},
	year = {1987},
}

@techreport{noauthor_gif_2021,
	title = {{GIF} {Annual} {Report} 2021},
	institution = {Gen IV International Forum},
	year = {2021},
}

@techreport{laboure_fy21_2021,
	title = {{FY21} {Status} {Report} on the {ART}-{GCR} {CMVB} and {CNWG} {International} {Collaborations}},
	number = {ART-M3AT-21IN0603011},
	institution = {Idaho National Laboratory (INL)},
	author = {Laboure, Vincent and Ortensi, Javier and Hermosillo, Andrew and Strydom, Gerhard and Balestra, Paolo},
	year = {2021},
}

@techreport{kovacic_model_2020,
	title = {Model {MC}\&{A} {Plan} for {Pebble} {Bed} {Reactors}},
	language = {en},
	institution = {OAK RIDGE NATIONAL LABORATORY},
	author = {Kovacic, Donald and Gibbs, Philip and Scott, Logan},
	year = {2020},
	pages = {89},
}

@techreport{kovacic_advanced_2021,
	title = {Advanced {Reactor} {Safeguards}: {Nuclear} {Material} {Control} and {Accounting} for {Pebble} {Bed} {Reactors}},
	language = {en},
	institution = {OAK RIDGE NATIONAL LABORATORY},
	author = {Kovacic, Donald and Gibbs, Philip and Worrall, Louise and Hunneke, Rachel and Harp, Jason and Hu, Jianwei},
	year = {2021},
	pages = {27},
}

@article{nayak_passive_2008,
	title = {Passive system reliability analysis using the {APSRA} methodology},
	volume = {238},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002954930700564X},
	doi = {10.1016/j.nucengdes.2007.11.005},
	abstract = {In this paper, we present a methodology known as APSRA (Assessment of Passive System ReliAbility) for evaluation of reliability of passive systems. The methodology has been applied to the boiling natural circulation system in the Main Heat Transport System of the Indian AHWR concept. In the APSRA methodology, the passive system reliability is evaluated from the evaluation of the failure probability of the system to carryout the desired function. The methodology ﬁrst determines the operational characteristics of the system and the failure conditions by assigning a predetermined failure criteria. The failure surface is predicted using a best estimate code considering deviations of the operating parameters from their nominal states, which affect the natural circulation performance. Since applicability of the best estimate codes to passive systems are neither proven nor understood enough, APSRA relies more on experimental data for various aspects of natural circulation such as steady-state natural circulation, ﬂow instabilities, CHF under oscillatory condition, etc. APSRA proposes to compare the code predictions with the test data to generate the uncertainties on the failure parameter prediction, which is later considered in the code for accurate prediction of failure surface of the system. Once the failure surface of the system is predicted, the cause of failure is examined through root diagnosis, which occurs mainly due to failure of mechanical components. The failure probability of these components are evaluated through a classical PSA treatment using the generic data. Reliability of the natural circulation system is evaluated from the probability of availability of the components for the success of natural circulation in the system.},
	language = {en},
	number = {6},
	urldate = {2022-11-28},
	journal = {Nuclear Engineering and Design},
	author = {Nayak, A.K. and Gartia, M.R. and Antony, A. and Vinod, G. and Sinha, R.K.},
	month = jun,
	year = {2008},
	pages = {1430--1440},
}

@techreport{noauthor_current_2001,
	address = {Nuclear Power Technology Development Section},
	title = {Current status and future development of modular high temperature gas cooled reactor technology},
	institution = {IAEA},
	year = {2001},
}

@techreport{noauthor_modular_2011,
	title = {Modular {HTGR} {Safety} {Basis} and {Approach}},
	number = {INL/EXT-11-22708},
	institution = {Idaho National Laboratory (INL)},
	year = {2011},
}

@misc{noauthor_ml15223a414pdf_nodate,
	title = {{ML15223A414}.pdf},
}

@article{gursel_using_2022,
	title = {Using artificial intelligence to detect human errors in nuclear power plants: {A} case in operation and maintenance},
	issn = {1738-5733},
	shorttitle = {Using artificial intelligence to detect human errors in nuclear power plants},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573322005137},
	doi = {10.1016/j.net.2022.10.032},
	abstract = {Human error (HE) is an important concern in safety-critical systems such as nuclear power plants (NPPs). HE has played a role in many accidents and outage incidents in NPPs. Despite the increased automation in NPPs, HE remains unavoidable. Hence, the need for HE detection is as important as HE prevention efforts. In NPPs, HE is rather rare. Hence, anomaly detection, a widely used machine learning technique for detecting rare anomalous instances, can be repurposed to detect potential HE. In this study, we develop an unsupervised anomaly detection technique based on generative adversarial networks (GANs) to detect anomalies in manually collected surveillance data in NPPs. More specifically, our GAN is trained to detect mismatches between automatically recorded sensor data and manually collected surveillance data, and hence, identify anomalous instances that can be attributed to HE. We test our GAN on both a real-world dataset and an external dataset obtained from a testbed, and we benchmark our results against state-of-the-art unsupervised anomaly detection algorithms, including one-class support vector machine and isolation forest. Our results show that the proposed GAN provides improved anomaly detection performance. Our study is promising for the future development of artificial intelligence based HE detection systems.},
	language = {en},
	urldate = {2022-11-28},
	journal = {Nuclear Engineering and Technology},
	author = {Gursel, Ezgi and Reddy, Bhavya and Khojandi, Anahita and Madadi, Mahboubeh and Coble, Jamie Baalis and Agarwal, Vivek and Yadav, Vaibhav and Boring, Ronald L.},
	month = oct,
	year = {2022},
	keywords = {anomaly detection, human error detection, machine learning, nuclear power plants},
}

@inproceedings{cadwallader_preliminary_2002,
	address = {Atlantic City, NJ, USA},
	title = {Preliminary identification of accident initiating events for {IFE} power plants},
	isbn = {978-0-7803-7073-9},
	url = {http://ieeexplore.ieee.org/document/1027658/},
	doi = {10.1109/FUSION.2002.1027658},
	abstract = {This paper presents initial results of a task to identify accident initiating events for inertial fusion energy (IFE) power plant designs. Initiating events (IEs) are a fundamental building block of a probabilistic risk assessment; they are the ‘accident starters’ that are analyzed to determine the risks posed to members of the public in the vicinity of the power plant. The IE results for the SOMBRERO design are presented in tabular form. The SOMBRERO design was analyzed since it is representative of dry chamber wall, laser driven designs. This work is used to characterize IFE plant risk and to identify potential design changes that would mitigate the plant risk.},
	language = {en},
	urldate = {2022-11-26},
	booktitle = {Proceedings of the 19th {IEEE}/{IPSS} {Symposium} on {Fusion} {Engineering}. 19th {SOFE} ({Cat}. {No}.{02CH37231})},
	publisher = {IEEE},
	author = {Cadwallader, L.C. and Latkowski, J.F.},
	year = {2002},
	pages = {122--125},
}

@article{papazoglou_master_2003-1,
	title = {Master {Logic} {Diagram}: method for hazard and initiating event identification in process plants},
	volume = {97},
	issn = {03043894},
	shorttitle = {Master {Logic} {Diagram}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304389402002443},
	doi = {10.1016/S0304-3894(02)00244-3},
	abstract = {Master Logic Diagram (MLD), a method for identifying events initiating accidents in chemical installations, is presented. MLD is a logic diagram that resembles a fault tree but without the formal mathematical properties of the latter. MLD starts with a Top Event “Loss of Containment” and decomposes it into simpler contributing events. A generic MLD has been developed which may be applied to all chemical installations storing toxic and/or ﬂammable substances. The method is exempliﬁed through its application to an ammonia storage facility.},
	language = {en},
	number = {1-3},
	urldate = {2022-11-26},
	journal = {Journal of Hazardous Materials},
	author = {Papazoglou, I.A and Aneziris, O.N},
	month = feb,
	year = {2003},
	pages = {11--30},
}

@misc{noauthor_bdd_nodate,
	title = {{BDD} {BASED} {FAULT}-{TREE} {PROCESSING}: {A} {COMPARISON} {OF} {VARIABLE} {ORDERING} {HEURISTICS} {Abstract} {Keywords} 1 {Introduction}},
	url = {http://scholar.googleusercontent.com/scholar?q=cache:faSxTr8wbQwJ:scholar.google.com/+based+fault+tree+processing+&hl=en&as_sdt=0,47},
	urldate = {2022-11-26},
}

@article{hu_guided_2022,
	title = {Guided simulation for dynamic probabilistic risk assessment of complex systems: {Concept}, method, and application},
	volume = {217},
	issn = {09518320},
	shorttitle = {Guided simulation for dynamic probabilistic risk assessment of complex systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832021005512},
	doi = {10.1016/j.ress.2021.108047},
	abstract = {Probabilistic risk assessment (PRA) is a systematic process of examining how engineered systems work to ensure safety. With the growth of the size of dynamic systems and the complexity of the interactions between hardware, software, and humans, it is extremely difficult to enumerate risky scenarios by the traditional PRA methods. In this study, a new dynamic probabilistic risk assessment methodology is proposed that employs a new exploration strategy to generate risky scenarios. The proposed methodology consists of three main modules, including simulation, planner, and scheduler. In this methodology, the engineering knowledge of the system is explicitly used to guide the simulation module to achieve higher efficiency and accuracy. The engineering knowledge is reflected in the planner module which is responsible for generating plans as a high-level map to guide the simulation. The scheduler module is responsible for guiding the simulation by controlling the timing and occurrence of the random events. In this paper, modules of the proposed methodology, and their interactions are explained in detail. The developed methodology is used to perform risk assessment of a Space Shuttle ascent phase, and results show the effectiveness of the proposed platform.},
	language = {en},
	urldate = {2022-11-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Hu, Yunwei and Parhizkar, Tarannom and Mosleh, Ali},
	month = jan,
	year = {2022},
	pages = {108047},
}

@article{lederman_probabilistic_1996,
	title = {Probabilistic safety assessment past, present and future {An} {IAEA} perspective},
	volume = {160},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549395011072},
	doi = {10.1016/0029-5493(95)01107-2},
	abstract = {Despite the high level of development that probabilistic safety assessment (PSA) methods have reached, a number of issues place constraints on its use in supporting decision making on safety matters. A recent publication of the International Nuclear Safety Advisory Group (INSAG) represents an important step in reaching international consensus on the use of PSA. PSA is "strongly encouraged" by INSAG; however, it is noted that "PSA methodology is not sufficiently mature for its present status to be frozen". The main aspects of the report are discussed in this paper. The paper next discusses three main categories of PSA application, namely the adequacy of design and procedures, optimization of operational activities and regulatory applications. For each of the applications, the objectives, specific modelling requirements and the prospects for implementation are presented.},
	language = {en},
	number = {3},
	urldate = {2022-11-26},
	journal = {Nuclear Engineering and Design},
	author = {Lederman, L. and Niehaus, F. and Tomic, B.},
	month = feb,
	year = {1996},
	pages = {273--285},
}

@article{heo_recent_2021,
	title = {Recent research towards integrated deterministic-probabilistic safety assessment in {Korea}},
	volume = {53},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573321002667},
	doi = {10.1016/j.net.2021.05.015},
	abstract = {For a long time, research into integrated deterministic-probabilistic safety assessment has been continuously conducted to point out and overcome the limitations of classical ET (event tree)/FT (fault tree) based PSA (probabilistic safety assessment). The current paper also attempts to assert the reason why a technical transformation from classical PSA is necessary with a re-interpretation of the categories of risk. In this study, residual risk was classiﬁed into interpolating- and extrapolating-censored categories, which represent risks that are difﬁcult to identify through an interpolation or extrapolation of representative scenarios due to potential nonlinearity between hardware and human behaviors intertwined in time and space. The authors hypothesize that such risk can be dealt with only if the classical ETs/FTs are freely relocated, entailing large-scale computation associated with physical models. The functional elements that are favorable to ﬁnd residual risk were inferred from previous studies. The authors then introduce their under-development enabling techniques, namely DICE (Dynamic Integrated Consequence Evaluation) and DeBATE (Deep learningeBased Accident Trend Estimation). This work can be considered as a preliminary initiative to ﬁnd the bridging points between deterministic and probabilistic assessments on the pillars of big data technology.},
	language = {en},
	number = {11},
	urldate = {2022-11-26},
	journal = {Nuclear Engineering and Technology},
	author = {Heo, Gyunyoung and Baek, Sejin and Kwon, Dohun and Kim, Hyeonmin and Park, Jinkyun},
	month = nov,
	year = {2021},
	pages = {3465--3473},
}

@article{he_real-time_2022,
	title = {A real-time probabilistic risk assessment method for the petrochemical industry based on data monitoring},
	volume = {226},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022003234},
	doi = {10.1016/j.ress.2022.108700},
	abstract = {Safety is of high societal concern in the petrochemical industry. With advancing digitalization, the techniques of probabilistic risk assessment (PRA), which provide a system-level perspective for industrial risk analysis, have become increasingly dynamic. This paper provides a further advancement in this direction by proposing a risk updating method based on the dynamic Bayesian network (DBN) to incorporate data monitoring into PRA in realtime. We update the probabilistic risk for basic events in Bayesian networks based on their prior probability and the probability of their online monitoring signals exceeding the alarm threshold. The key idea behind this approach is that if the signal of a basic event exceeds the alarm threshold, the corresponding risk should increase. Otherwise, the basic event should have a low risk. The contribution in this paper is twofold. First, residual methods are developed to estimate signal probabilities exceeding abnormal thresholds. Second, a DBN model is proposed to integrate prior risk with data monitoring for risk analysis. The proposed DBN model does not require additional expert knowledge and historical accident data to define the conditional relationship between data monitoring and prior risk. The proposed approach is validated using the RT 580 experimental setup and managed pressure drilling operations.},
	language = {en},
	urldate = {2022-11-26},
	journal = {Reliability Engineering \& System Safety},
	author = {He, Rui and Zhu, Jingyu and Chen, Guoming and Tian, Zhigang},
	month = oct,
	year = {2022},
	pages = {108700},
}

@inproceedings{sakurahara_enhancing_2020,
	title = {Enhancing {Realism} in {Fire} {Probabilistic} {Risk} {Assessment} of {Nuclear} {Power} {Plants}},
	isbn = {9789811485930},
	url = {http://rpsonline.com.sg/proceedings/9789811485930/html/4482.xml},
	doi = {10.3850/978-981-14-8593-0_4482-cd},
	language = {en},
	urldate = {2022-11-26},
	booktitle = {Proceedings of the 30th {European} {Safety} and {Reliability} {Conference} and 15th {Probabilistic} {Safety} {Assessment} and {Management} {Conference}},
	publisher = {Research Publishing Services},
	author = {Sakurahara, Tatsuya and Bui, Ha and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	year = {2020},
	pages = {1836--1843},
}

@article{lee_representation_1959,
	title = {Representation of switching circuits by binary-decision programs},
	volume = {38},
	issn = {0005-8580},
	doi = {10.1002/j.1538-7305.1959.tb01585.x},
	abstract = {A binary-decision program is a program consisting of a string of two-address conditional transfer instructions. The paper shows the relationship between switching circuits and binary-decision programs and gives a set of simple rules by which one can transform binary-decision programs to switching circuits. It then shows that, in regard to the computation of switching functions, binary-decision programming representation is superior to the usual Boolean representation.},
	number = {4},
	journal = {The Bell System Technical Journal},
	author = {Lee, C. Y.},
	month = jul,
	year = {1959},
	note = {Conference Name: The Bell System Technical Journal},
	pages = {985--999},
}

@article{birnbaum_modules_1965,
	title = {Modules of {Coherent} {Binary} {Systems}},
	volume = {13},
	issn = {0368-4245},
	url = {https://epubs.siam.org/doi/abs/10.1137/0113027},
	doi = {10.1137/0113027},
	abstract = {The concept of a “module”, i.e., a package of components of a system which can be removed and replaced as a whole, has been long in use in systems design and analysis. In this paper a formal definition of this concept is given and its properties are studied.

Most of the results are obtained for “coherent” systems, i.e., for systems whose performance improves as the performance of their components improves. For such systems the relationship between modules and minimal paths can be fully clarified, and the results obtained lead to a criterion for deciding whether or not a given set of components constitutes a module of a given system. It is shown that a coherent system always has uniquely determined maximal modules which have the property that either all are disjoint or no two of them are disjoint. These maximal modules determine uniquely a decomposition of the system into disjoint modular factors. Furthermore, a theorem on the union of modules (the “three modules theorem”), which has been previously known for general systems, is obtained by a rather simple argument for coherent systems.},
	number = {2},
	urldate = {2022-11-25},
	journal = {Journal of the Society for Industrial and Applied Mathematics},
	author = {Birnbaum, Z. W. and Esary, J. D.},
	month = jun,
	year = {1965},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {444--462},
}

@article{locks_modularizing_1981,
	title = {Modularizing, {Minimizing}, and {Interpreting} the {K}\&{H} {Fault}-{Tree}},
	volume = {R-30},
	issn = {1558-1721},
	doi = {10.1109/TR.1981.5221150},
	abstract = {The verification by Worrell \& Stack (W\&S) of results previously obtained by Kumamoto \& Henley (K\&H) for a fault tree of an s-noncoherent system and its inverse and their correction of the three errors in the tree makes it possible to simplify the analysis by forming modules; this facilitates Boolean algebraic operations, so that both sets are described economically in their minimal forms, a subset of the prime implicants (p.i.'s). Quine's consensus operation is used to minimize and to find the p.i.'s. Corresponding to the MOCUS output for the inverse reported by K\&H, which is neither minimal nor the set of p.i.'s, instead of 32 terms, there are 15 in the modularized set. Instead of the 42 p.i.'s obtained by both K\&h; W\&S, we have 17; 13 of these are a unique minimal form. Instead of 352 p.i.'s for the tree per both K\&h; W\&S, we have a 15-term minimal form, identical to the list of p.i.'s. The results are further analyzed as a contribution to the continuing discussion of the utility of minimal forms vis-a-vis the p.i.'s and of the consensus method.},
	number = {5},
	journal = {IEEE Transactions on Reliability},
	author = {Locks, Mitchell O.},
	month = dec,
	year = {1981},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Boolean algebra, Boolean functions, Boolean methods, Consensus, Duality, Error correction, Fail safe, Fault tree, Fault trees, Minimization, Minimization methods, Modularization, Prime implicant, Reliability, s-Noncoherence},
	pages = {411--415},
}

@incollection{yllera_modularization_1988,
	title = {Modularization {Methods} for {Evaluating} {Fault} {Trees} of {Complex} {Technical} {Systems}},
	isbn = {978-1-351-07171-0},
	abstract = {Fault tree analysis is one of the most important techniques for system modeling and has been widely used in risk assessments together with event tree models. A fault tree is a graphic representation of the logical relationships between events in a system which result in a prespecified undesired state of it, defined as the top-event of the fault tree. Modularization is performed in a bottom-up tree traversal, and the modules are numbered in the order in which they are created. The modularization theory exposed is quite general and includes any other module concept for binary systems presented up to date. The algorithm for modularization consists of two parts. First, the system structure is handled and optimized. Second, the modularization is carried out. The most frequently used analytical methods for fault tree analysis are based on the determination of the minimal cut sets. The resulting fault tree serves as input to the modularization process.},
	booktitle = {Engineering {Risk} and {Hazard} {Assessment}},
	publisher = {CRC Press},
	author = {Yllera, Javier},
	year = {1988},
	note = {Num Pages: 20},
}

@article{kohda_finding_1989,
	title = {Finding modules in fault trees},
	volume = {38},
	issn = {1558-1721},
	doi = {10.1109/24.31101},
	abstract = {A new method for identifying all possible modules is presented. There are two kinds of modules: (1) those whose output events are expressed by gate events, and (2) those whose output events are not expressed by gate events. The latter are logical OR or AND combinations of basic events and modules. The method requires as input only fault-tree structure data representing gate event output-input relations. The output is a hierarchical decomposition of the fault tree into modules. The order in which the modules are identified corresponds to both the hierarchy established when the gates are numbered and the order in which modules are analyzed. The method can be applied to noncoherent fault trees. Illustrative examples are given. It is demonstrated that, by modular decomposition, 100-fold reductions in computation time are obtained for a 70-gate, 67-basic-event problem.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Reliability},
	author = {Kohda, T. and Henley, E.J. and Inoue, K.},
	month = jun,
	year = {1989},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Fault trees, Microcomputers, Prototypes, Reliability engineering, Runtime},
	pages = {165--176},
}

@article{gerigk_application_2014,
	title = {{APPLICATION} {OF} {QUANTITATIVE} {RISK} {ASSESSMENT} {TO} {SHIPS} {IN} {EMERGENCY} {CONDITIONS}},
	abstract = {The paper is devoted to safety of ships in emergency conditions The currently valid prescriptive method of safety assessment of ships in damage conditions is included in the SOLAS 2009 Part B-2 Ch.II-1 regulations. It is devoted to the design stage and difficult to apply in operation. A possible alternative described in this paper is a method based on assessment of performance of ships and risk assessment. Type of risk evaluation is the quantitative risk assessment. The matrix type risk model has been applied for estimation the risk and the measure of safety of ships level is based on the risk acceptance criteria from the risk matrix. After the risk assessment the method may be used for the safety management purposes using the risk control options.},
	language = {en},
	author = {Gerigk, M K and Szulczewski, P},
	month = nov,
	year = {2014},
	pages = {13},
}

@article{ibanez-llano_variable_2008,
	title = {Variable ordering schemes to apply to the binary decision diagram methodology for event tree sequences assessment},
	volume = {222},
	issn = {1748-006X},
	url = {https://doi.org/10.1243/1748006XJRR67},
	doi = {10.1243/1748006XJRR67},
	abstract = {Binary decision diagram (BDD) methodology is the most recent approach to improve Boolean reliability models assessment. The final size of the BDD, and therefore the ultimate benefits of this technique, are very sensitive to the initial variable ordering that has to be fixed prior to conversion. Several variable ordering strategies have been proposed in the literature, all of them focused on the treatment of single fault tree models. This paper proposes some extensions of existing variable ordering schemes for the case of combinations of non-disjoint fault trees, as is the case in quantifying sequences of event trees. These extensions work by combining ordering schemes applied to each fault tree, and exploring the cases where variables within the domains intersection are kept together or not. They have been specifically designed to be applied together with an incremental procedure to compute the BDD of the sequence accumulatively and to be used to quantify sequences of dynamic event trees. Preliminary results show the potential of this approach.},
	language = {en},
	number = {1},
	urldate = {2022-11-25},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Ibáñez-Llano, C and Meléndez, E and F, Nieto},
	month = mar,
	year = {2008},
	note = {Publisher: SAGE Publications},
	pages = {7--16},
}

@inproceedings{friedman_finding_1987,
	title = {Finding the {Optimal} {Variable} {Ordering} for {Binary} {Decision} {Diagrams}},
	doi = {10.1145/37888.37941},
	abstract = {The ordered binary decision diagram is a canonical representation for Boolean functions, presented by Bryant as a compact representation for a broad class of interesting functions derived from circuits. However, the size of the diagram is very sensitive to the choice of ordering on the variables; hence for some applications, such as Differential Cascode Voltage Switch (DCVS) trees, it becomes extremely important to find the ordering leading to the most compact representation. We present an algorithm for this problem with time complexity O(n/sup 2/3/sup n/), an improvement over the previous best, which required O(n!2/sup n/).},
	booktitle = {24th {ACM}/{IEEE} {Design} {Automation} {Conference}},
	author = {Friedman, S.J. and Supowit, K.J.},
	month = jun,
	year = {1987},
	note = {ISSN: 0738-100X},
	keywords = {Boolean functions, Circuits, Computer science, Data structures, Decision trees, Logic testing, Permission, Scholarships, Switches, Voltage},
	pages = {348--356},
}

@article{bollig_improving_1996,
	title = {Improving the variable ordering of {OBDDs} is {NP}-complete},
	volume = {45},
	issn = {1557-9956},
	doi = {10.1109/12.537122},
	abstract = {Ordered binary decision diagrams are a useful representation of Boolean functions, if a good variable ordering is known. Variable orderings are computed by heuristic algorithms and then improved with local search and simulated annealing algorithms. This approach is based on the conjecture that the following problem is NP-complete. Given an OBDD G representing f and a size bound s, does there exist an OBDD G* (respecting an arbitrary variable ordering) representing f with at most s nodes? This conjecture is proved.},
	number = {9},
	journal = {IEEE Transactions on Computers},
	author = {Bollig, B. and Wegener, I.},
	month = sep,
	year = {1996},
	note = {Conference Name: IEEE Transactions on Computers},
	keywords = {Algorithm design and analysis, Boolean functions, Circuit synthesis, Circuit testing, Computational modeling, Data structures, Heuristic algorithms, Pattern analysis, Simulated annealing, Test pattern generators},
	pages = {993--1002},
}

@inproceedings{rudell_dynamic_1993,
	title = {Dynamic variable ordering for ordered binary decision diagrams},
	doi = {10.1109/ICCAD.1993.580029},
	abstract = {The ordered binary decision diagram (OBDD) has proven useful in many applications as an efficient data structure for representing and manipulating Boolean functions. A serious drawback of OBDD's is the need for application-specific heuristic algorithms to order the variables before processing. Further, for many problem instances in logic synthesis, the heuristic ordering algorithms which have been proposed are insufficient to allow OBDD operations to complete within a limited amount of memory. The paper proposes a solution to these problems based on having the OBDD package itself determine and maintain the variable order. This is done by periodically applying a minimization algorithm to reorder the variables of the OBDD to reduce its size. A new OBDD minimization algorithm, called the sifting algorithm, is proposed and appears especially effective in reducing the size of the OBDD. Experiments with dynamic variable ordering on the problem of forming the OBDD's for the primary outputs of a combinational circuit show that many computations complete using dynamic variable ordering when the same computation fails otherwise.},
	booktitle = {Proceedings of 1993 {International} {Conference} on {Computer} {Aided} {Design} ({ICCAD})},
	author = {Rudell, R.},
	month = nov,
	year = {1993},
	keywords = {Boolean functions, Circuit synthesis, Combinational circuits, Data structures, Heuristic algorithms, Logic, Manipulator dynamics, Minimization, Packaging, Sequential circuits},
	pages = {42--47},
}

@article{demkowicz_coated_2019,
	title = {Coated particle fuel: {Historical} perspectives and current progress},
	volume = {515},
	issn = {00223115},
	shorttitle = {Coated particle fuel},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022311518310213},
	doi = {10.1016/j.jnucmat.2018.09.044},
	abstract = {Coated particle fuel concepts date back some 60 years, and have evolved signiﬁcantly from the relatively primitive pyrocarbon-coated kernels envisioned by the ﬁrst pioneers. Improvements in particle design, coating layer properties, and kernel composition have produced the modern tristructural isotropic (TRISO) particle, capable of low statistical coating failure fractions and good ﬁssion product retention under extremely severe conditions, including temperatures of 1600  C for hundreds of hours. The fuel constitutes one of the key enabling technologies for high-temperature gas-cooled reactors, allowing coolant outlet temperatures approaching 1000  C and contributing to enhanced reactor safety due to the hardiness of the particles. TRISO fuel development has taken place in a number of countries worldwide, and several fuel qualiﬁcation programs are currently in progress. In this paper, we discuss the unique history of particle fuel development and some key technology advances, concluding with some of the latest progress in UO2 and UCO TRISO fuel qualiﬁcation.},
	language = {en},
	urldate = {2022-11-24},
	journal = {Journal of Nuclear Materials},
	author = {Demkowicz, Paul A. and Liu, Bing and Hunn, John D.},
	month = mar,
	year = {2019},
	pages = {434--450},
}

@article{fleming_use_2018,
	title = {Use of {PRA} to {Select} {Licensing} {Basis} {Events}},
	abstract = {The purpose of this paper is to summarize key elements of the risk-informed and performance-based methods developed within the Industry led Licensing Modernization Project (LMP). The LMP is jointly sponsored by the U.S. Department of Energy and the U.S. nuclear industry to assist the U.S. Nuclear Regulatory Commission (NRC) in the development of regulatory guidance for advanced non-light water reactors currently under development in the U.S. The purpose of this paper is to summarize a risk-informed and performance based approach for the selection and evaluation of LBEs for advanced non-LWRs. This paper summarizes the approach which builds on a PRA model that is introduced early in the design process and provides examples for selected advanced non-LWR technologies.},
	language = {en},
	journal = {Los Angeles},
	author = {Fleming, Karl and Wallace, Edward and Afzali, Amir},
	year = {2018},
	pages = {12},
}

@techreport{moe_modernization_2020-1,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/servlets/purl/1700670/},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Probabilistic Risk Assessment Approach,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs). It is the result of a Licensing Modernization Project (LMP) led by Southern Company and cost-shared by the U.S. Department of Energy (DOE). The LMP has developed detailed proposals for establishing licensing technical requirements to facilitate risk-informed and performance-based design and licensing of advanced non-LWRs. Such a methodology acknowledges enhancements in safety achievable with advanced designs and reflects more recent states of knowledge regarding safety and design innovation, creating an opportunity for reduced regulatory complexity with increased levels of safety. The project builds on best practices, as well as previous activities through DOE and industry-sponsored advanced reactor licensing initiatives.},
	language = {en},
	number = {INL/EXT--20-60395, SC--29980-101-Rev.01, 1700670},
	urldate = {2022-11-23},
	author = {Moe, Wayne and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700670},
	pages = {INL/EXT--20--60395, SC--29980--101--Rev.01, 1700670},
}

@techreport{moe_modernization_2020-2,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/servlets/purl/1700670/},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Probabilistic Risk Assessment Approach,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs). It is the result of a Licensing Modernization Project (LMP) led by Southern Company and cost-shared by the U.S. Department of Energy (DOE). The LMP has developed detailed proposals for establishing licensing technical requirements to facilitate risk-informed and performance-based design and licensing of advanced non-LWRs. Such a methodology acknowledges enhancements in safety achievable with advanced designs and reflects more recent states of knowledge regarding safety and design innovation, creating an opportunity for reduced regulatory complexity with increased levels of safety. The project builds on best practices, as well as previous activities through DOE and industry-sponsored advanced reactor licensing initiatives.},
	language = {en},
	number = {INL/EXT--20-60395, SC--29980-101-Rev.01, 1700670},
	urldate = {2022-11-23},
	author = {Moe, Wayne and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700670},
	pages = {INL/EXT--20--60395, SC--29980--101--Rev.01, 1700670},
}

@techreport{moses_very_2011,
	title = {Very {High}-{Temperature} {Reactor} ({VHTR}) {Proliferation} {Resistance} and {Physical} {Protection} ({PR}\&{PP})},
	url = {http://www.osti.gov/servlets/purl/1027406/},
	language = {en},
	number = {ORNL/TM-2010/163, 1027406},
	urldate = {2022-11-23},
	author = {Moses, David Lewis},
	month = oct,
	year = {2011},
	doi = {10.2172/1027406},
	pages = {ORNL/TM--2010/163, 1027406},
}

@techreport{hu_fy20_2020,
	title = {{FY20} {SAM} {Code} {Developments} and {Validations} for {Transient} {Safety} {Analysis} of {Advanced} non-{LWRs}},
	url = {https://www.osti.gov/servlets/purl/1716517/},
	language = {en},
	number = {ANL/NSE--20/50, 1716517, 162791},
	urldate = {2022-11-22},
	author = {Hu, R. and Hu, G. and Zou, L. and Klingberg, A. and Fei, T. and Nunez, D.},
	month = sep,
	year = {2020},
	doi = {10.2172/1716517},
	pages = {ANL/NSE--20/50, 1716517, 162791},
}

@article{novak_pronghorn_2021,
	title = {Pronghorn: {A} {Multidimensional} {Coarse}-{Mesh} {Application} for {Advanced} {Reactor} {Thermal} {Hydraulics}},
	volume = {207},
	issn = {0029-5450, 1943-7471},
	shorttitle = {Pronghorn},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2020.1825307},
	doi = {10.1080/00295450.2020.1825307},
	abstract = {This paper presents an overview of Pronghorn, a multiscale thermal-hydraulic (T/H) application developed by Idaho National Laboratory and the University of California, Berkeley. Pronghorn, built on the opensource finite element Multiphysics Object-Oriented Simulation Environment (MOOSE), leverages state-of-the-art physical models, numerical methods, and nonlinear solvers to deliver fast-running advanced reactor T/H simula­ tion capabilities within a modern software engineering environment. This work summarizes the physical models, multiphysics and multiscale coupling, and numerical discretization in Pronghorn with emphasis on our initial target application to pebble bed reactors (PBRs). A diverse set of applications are shown to depressurized natural circulation in the SANA experiments, forced convection in the Pebble Bed Modular Reactor, three-dimensional (3-D)/one-dimensional coupling of Pronghorn and RELAP-7 systems T/H for loop analysis in the High Temperature Reactor Power Module, and forced convection in the Mark-1 Pebble Bed Fluoride-Salt-Cooled HighTemperature Reactor. A multiphysics coupling of Pronghorn, RELAP-7, and Griffin deterministic neutronics for a gas-cooled PBR demonstrates the capability of the MOOSE framework for reactor design calculations. These applications highlight the verification and validation underlying Pronghorn’s software development while empha­ sizing features that improve upon capabilities offered by legacy tools in areas such as 3-D unstructured meshing, physics modeling, and multiphysics coupling.},
	language = {en},
	number = {7},
	urldate = {2022-11-22},
	journal = {Nuclear Technology},
	author = {Novak, A. J. and Carlsen, R. W. and Schunert, S. and Balestra, P. and Reger, D. and Slaybaugh, R. N. and Martineau, R. C.},
	month = jul,
	year = {2021},
	pages = {1015--1046},
}

@article{balestra_initial_nodate,
	title = {Initial study on cross section generation requirements for a {PBR} equilibrium core},
	language = {en},
	author = {Balestra, Paolo},
	pages = {19},
}

@book{boer_optimized_2008,
	address = {Amsterdam},
	title = {Optimized core design and fuel management of a pebble-bed type nuclear reactor},
	isbn = {978-1-58603-966-0},
	language = {en},
	publisher = {IOS Press},
	author = {Boer, Brian},
	year = {2008},
	note = {OCLC: ocn313644241},
	keywords = {Cores, Management, Nuclear fuels, Nuclear reactors},
}

@article{moormann_caution_2018,
	title = {Caution {Is} {Needed} in {Operating} and {Managing} the {Waste} of {New} {Pebble}-{Bed} {Nuclear} {Reactors}},
	volume = {2},
	issn = {25424351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2542435118303350},
	doi = {10.1016/j.joule.2018.07.024},
	language = {en},
	number = {10},
	urldate = {2022-11-22},
	journal = {Joule},
	author = {Moormann, Rainer and Kemp, R. Scott and Li, Ju},
	month = oct,
	year = {2018},
	pages = {1911--1914},
}

@article{zhang_shandong_2016,
	title = {The {Shandong} {Shidao} {Bay} 200 {MW} e {High}-{Temperature} {Gas}-{Cooled} {Reactor} {Pebble}-{Bed} {Module} ({HTR}-{PM}) {Demonstration} {Power} {Plant}: {An} {Engineering} and {Technological} {Innovation}},
	volume = {2},
	issn = {20958099},
	shorttitle = {The {Shandong} {Shidao} {Bay} 200 {MW} e {High}-{Temperature} {Gas}-{Cooled} {Reactor} {Pebble}-{Bed} {Module} ({HTR}-{PM}) {Demonstration} {Power} {Plant}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2095809916301552},
	doi = {10.1016/J.ENG.2016.01.020},
	language = {en},
	number = {1},
	urldate = {2022-11-22},
	journal = {Engineering},
	author = {Zhang, Zuoyi and Dong, Yujie and Li, Fu and Zhang, Zhengming and Wang, Haitao and Huang, Xiaojin and Li, Hong and Liu, Bing and Wu, Xinxin and Wang, Hong and Diao, Xingzhong and Zhang, Haiquan and Wang, Jinhua},
	month = mar,
	year = {2016},
	pages = {112--118},
}

@misc{noauthor_national_nodate,
	title = {National {Rail} {Network} {Map} - {Overview}},
	url = {https://www.arcgis.com/home/item.html?id=96ec03e4fc8546bd8a864e39a2c3fc41},
	urldate = {2022-11-21},
}

@inproceedings{remenyte_simple_2006,
	title = {A simple component connection approach for fault tree conversion to binary decision diagram},
	doi = {10.1109/ARES.2006.17},
	abstract = {Fault tree analysis (FTA) is commonly used when conducting risk assessments of industrial systems. A number of computer packages based on conventional analysis methods are available to perform the analysis. However, dealing with large (possibly non-coherent) fault trees can expose the limitations of the technique in terms of accuracy of the solutions and the processing time required. Over recent years the binary decision diagram (BDD) method has been developed for the solution of the fault tree and overcomes the disadvantages of the conventional FTA approaches. The usual way of taking advantage of the BDD structure is to construct a fault tree and then convert it to a BDD. This paper focuses on the fault tree to BDD conversion process. Converting the fault tree requires the basic events of the fault tree to be placed in an ordering. This is critical to the size of the final BDD and ultimately affects the qualitative and quantitative analysis of the system and benefits of this method. Once the ordering is established several approaches can be used for the BDD generation. One approach is to apply a set of rules developed by Rauzy which are repeatedly applied to each gate in the fault tree to generate the BDD. An alternative approach can be used when BDD constructs for each of the gate types are first built and then connected together. A sub-node sharing feature in the second of these approaches and a third, hybrid, combined approach is presented. Some remarks on the effectiveness of these techniques are provided.},
	booktitle = {First {International} {Conference} on {Availability}, {Reliability} and {Security} ({ARES}'06)},
	author = {Remenyte, R. and Andrews, J.D.},
	month = apr,
	year = {2006},
	keywords = {Automotive engineering, Binary decision diagrams, Boolean functions, Data structures, Fault trees, Logic functions, Performance analysis, Risk analysis, Risk management, US Department of Transportation},
	pages = {8 pp.--457},
}

@book{vesely_prep_1970,
	title = {Prep and {Kitt}: {Computer} {Codes} for the {Automatic} {Evaluation} of a {Fault} {Tree}},
	shorttitle = {Prep and {Kitt}},
	language = {en},
	publisher = {U.S. Atomic Energy Commission},
	author = {Vesely, W. E. and Narum, R. E.},
	year = {1970},
}

@article{carrasco_algorithm_1999,
	title = {An algorithm to find minimal cuts of coherent fault-trees with event-classes, using a decision tree},
	volume = {48},
	issn = {1558-1721},
	doi = {10.1109/24.765925},
	abstract = {A new algorithm, the Carrasco-Sune minimal cuts (CS-MC) algorithm for computing the minimal cuts of s-coherent fault trees is presented. Input events of the fault tree are assumed classified into classes, where events of the same class are indistinguishable. This allows capturing some symmetries which some systems exhibit. CS-MC uses a decision tree. The search implemented by the decision tree is guided by heuristics which try to make the CS-MC algorithm as efficient as possible. In addition, an irrelevance test on the inputs of the fault tree is used to prune the search. The performance of CS-MC is illustrated and compared with the basic top-down and bottom-up algorithms using a set of fault trees, some of which are very difficult. The CS-MC performs very well even in the difficult examples, and the memory requirements of CS-MC are small.},
	number = {1},
	journal = {IEEE Transactions on Reliability},
	author = {Carrasco, J.A. and Sune, V.},
	month = mar,
	year = {1999},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Automatic test pattern generation, Automatic testing, Circuit faults, Circuit testing, Classification tree analysis, Decision trees, Digital circuits, Fault trees, Performance evaluation, Test pattern generators},
	pages = {31--41},
}

@inproceedings{miao_new_2013,
	title = {A new generation algorithm of fault tree minimal cut sets and its application in {CBTC} system},
	doi = {10.1109/ICIRT.2013.6696297},
	abstract = {Fault Tree Analysis (FTA) is a classic method in reliability and safety engineering. With the increase of system scale and complexity, the amount of work is heavily loaded. Thus the computer aided FTA method is important for related analysis. Existing computer aided FTA analysis methods invariably confront combinatorial problems which are computationally expensive and often with exponential increase of complexity, especially when it comes to large scale fault trees. In this paper, we propose a method based on the Binary Decision Diagram (BDD) with new conversion rules which are derived from the Component Connection Method. Besides, the Depth First Search (DFS) is applied to generate MCSs (Minimal Cut Sets). In the end, the Zone Controller of the CBTC (Communication Based Train Control) system is analyzed in case study. The result proves that the application of our new algorithm, of linear complexity, is more efficient than the algorithm of verifying all possible basic event combinations, both in computation speed and memory usage.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Intelligent} {Rail} {Transportation} {Proceedings}},
	author = {Miao, Zuoyu and Niu, Ru and Tang, Tao and Liu, Jieyu},
	month = aug,
	year = {2013},
	keywords = {Binary Decision Diagram, Boolean functions, Complexity theory, Data structures, Fault Tree Analysis, Fault trees, Logic gates, Minimal Cut Set, Reliability, Safety},
	pages = {221--226},
}

@inproceedings{xiang_efficient_2011,
	title = {Efficient {Analysis} of {Fault} {Trees} with {Voting} {Gates}},
	doi = {10.1109/ISSRE.2011.23},
	abstract = {The voting gate, or k-out-of-n (k/n) gate, is a standard logic gate used in fault trees modelling fault-tolerant systems. It is traditionally expanded into a combination of AND and OR gates, and this expansion may result in combinatorial explosion problem in the calculation of minimal cut sets (MCSs) of the fault tree for even a not very big n, especially when the voting gate inputs are intermediate rather than basic events. In this paper we propose a set of reduction rules to simplify the voting gates without direct expanding, and also propose a concept of minimal cut vote (MCV) denoting a k/n gate whose inputs are all basic events and whose k-combinations are all MCSs of the fault tree. With the proposed reduction rules and MCV concept, the MCSs of fault trees can be evaluated and weeded more efficiently and the result can be represented in a more compact form. The results of experiments on practical fault trees with voting gates show that our method not only outperforms conventional MCS evaluation methods by several orders of magnitude but also provides performance comparably to that provided by binary decision tree (BDD) based algorithms.},
	booktitle = {2011 {IEEE} 22nd {International} {Symposium} on {Software} {Reliability} {Engineering}},
	author = {Xiang, Jianwen and Yanoo, Kazuo and Maeno, Yoshiharu and Tadano, Kumiko and Machida, Fumio and Kobayashi, Atsushi and Osaki, Takao},
	month = nov,
	year = {2011},
	note = {ISSN: 2332-6549},
	keywords = {Algorithm design and analysis, Boolean functions, Complexity theory, Data structures, Equations, Fault trees, Logic gates},
	pages = {230--239},
}

@inproceedings{codetta-raiteri_bdd_2006,
	title = {{BDD} based analysis of parametric fault trees},
	doi = {10.1109/RAMS.2006.1677414},
	abstract = {Several extensions of the fault tree (FT) formalism have been proposed in the literature. One of them is called parametric fault tree (PFT) and is oriented to the modeling of redundant systems, and provides a compact form to model the redundant parts of the system. Using PFTs instead of FTs to model systems with replicated parts, the model design is simplified since the analyst can fold subtrees with the same structure in a single parametric subtree, reducing the number of elements in the model. The method based on binary decision diagrams (BDD) for the quantitative analysis of FTs, is adapted in this paper to cope with the parametric form of PFTs: an extension of BDDs called parametric BDD (pBDD) is used to analyze PFTs. The solution process is simplified by using pBDDs: comparing the pBDD obtained from a PFT, with the ordinary BDD obtained from the unfolded FT, we can observe a reduction of the number of nodes inside the pBDD. Such reduction is proportional to the level of redundancy inside the PFT and leads to a consequent reduction of the number of steps necessary to perform the analysis. Concerning the qualitative analysis, we can observe that several minimal cut sets (MCS) obtained from the FT model of a redundant system, involve basic events relative to similar components. A parametric MCS (pMCS) allows to group such MCSs in an equivalence class, and consequently, to evidence only the failure pattern, regardless the identity of replicated components. A method to derive pMCSs from a PFT is provided in the paper},
	booktitle = {{RAMS} '06. {Annual} {Reliability} and {Maintainability} {Symposium}, 2006.},
	author = {Codetta-Raiteri, D.},
	month = jan,
	year = {2006},
	note = {ISSN: 0149-144X},
	keywords = {Binary decision diagrams, Boolean functions, Data structures, Fault trees, Performance analysis, Petri nets, Redundancy, State-space methods, Stochastic processes, System testing},
	pages = {442--449},
}

@article{dutuit_linear-time_1996,
	title = {A linear-time algorithm to find modules of fault trees},
	volume = {45},
	issn = {1558-1721},
	doi = {10.1109/24.537011},
	abstract = {A module of a fault tree is a subtree whose terminal events do not occur elsewhere in the tree. Modules, which are independent subtrees, can be used to reduce the computational cost of basic operations on fault trees, such as the computation of the probability of the root event or the computation of the minimal cut sets. This paper presents a linear time algorithm to detect modules of a fault tree, coherent or not, that is derived from the Tarjan algorithm to find strongly connected components of a graph. The authors show, on a benchmark of real fault trees, that their method detects modules of trees with several hundred gates and events within few milliseconds on a personal computer.},
	number = {3},
	journal = {IEEE Transactions on Reliability},
	author = {Dutuit, Y. and Rauzy, A.},
	month = sep,
	year = {1996},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Algorithm design and analysis, Equations, Fault trees, Tree graphs},
	pages = {422--425},
}

@inproceedings{tang_minimal_2004,
	title = {Minimal cut set/sequence generation for dynamic fault trees},
	doi = {10.1109/RAMS.2004.1285449},
	abstract = {This paper proposes a zero-suppressed binary decision diagrams (ZBDD) based solution for minimal cut set/sequence (MCS) generation of dynamic fault trees. ZBDD is an efficient data structure for combinational set representation and manipulation. Our solution is based on the basic ZBDD set manipulations (union, intersection, difference and product). Due to the nature of the ZBDD, our algorithm is more efficient than the algorithms based on the BDD, both in computation time and memory usage. In our solution, we also extend the concept of minimal cut set in static fault trees into minimal cut sequence (also with notation MCS) in dynamic fault trees. The is based on minimal cut set generation. It is also efficient compared with Markov model based methods. As an example, we apply our method to X2000 avionics architecture. The system is modeled using a dynamic fault tree and the minimal cut sets/sequences are generated and analyzed.},
	booktitle = {Annual {Symposium} {Reliability} and {Maintainability}, 2004 - {RAMS}},
	author = {Tang, Zhihua and Dugan, J.B.},
	month = jan,
	year = {2004},
	keywords = {Aerospace electronics, Binary decision diagrams, Boolean functions, Computer architecture, Data structures, Encoding, Failure analysis, Fault tolerant systems, Fault trees, Power system modeling},
	pages = {207--213},
}

@article{coudert_metaprime_1994,
	title = {{MetaPrime}: an interactive fault-tree analyzer},
	volume = {43},
	issn = {1558-1721},
	shorttitle = {{MetaPrime}},
	doi = {10.1109/24.285125},
	abstract = {The performances of almost all available fault tree analysis tools are limited by the performance of their prime implicant computation procedure. All these procedures manipulate the prime implicants of the fault trees in extension, so that the analysis costs are directly related to the number of prime implicants to be generated, which in practice makes these tools difficult to apply on fault trees with more than 20 000 prime implicants. This paper introduces an analysis method of coherent as well as noncoherent fault trees that overcomes this limitation because its computational cost is related to neither the number of basic events, nor the number of gates, nor the number of prime implicants of these trees. The authors present the concepts underlying the prototype tool MetaPrime, and the experimental results obtained with this tool on real fault trees. These results show that these concepts provide complete analysis in seconds on fault trees that no previously available technique could ever even partially analyze, for instance noncoherent fault trees with more than 10/sup 20/ prime implicants. These concepts can also be used to analyze event trees because such trees denote Boolean functions on which these concepts can be applied. Prime implicant computation is also critical in many other domains, in particular in expert system applications such as reasoning maintenance and multiple fault diagnosis. The application of the concepts underlying MetaPrime to the resolution of these problems is under study.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Reliability},
	author = {Coudert, O. and Madre, J.C.},
	month = mar,
	year = {1994},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Boolean functions, Chemical analysis, Computational efficiency, Costs, Failure analysis, Laboratories, Logic, Out of order, Performance analysis, Reliability engineering},
	pages = {121--127},
}

@inproceedings{sinnamon_fault_1996,
	title = {Fault tree analysis and binary decision diagrams},
	doi = {10.1109/RAMS.1996.500665},
	abstract = {Fault tree analysis is now commonly used to assess the adequacy, in reliability terms, of industrial systems. For complex systems, an analysis may produce thousands of combinations of events which can cause system failure (minimal cut sets). The determination of these minimal cut sets can be a very time consuming process even on modern high speed digital computers. Also, if the fault tree has many minimal cut sets, calculating the exact top event probability will require extensive calculations. For many complex fault trees this requirement is beyond the capability of the available machines, thus approximation techniques need to be introduced resulting in loss of accuracy. This paper describes the use of a binary decision diagram for fault tree analysis and some ways in which it can be efficiently implemented on a computer. The work to date shows a substantial improvement in computational effort for large, complex fault trees analysed with this method in comparison to the traditional approach. The binary decision diagram method has the additional advantage that as approximations are not required, exact calculations for the top event parameters can be performed.},
	booktitle = {Proceedings of 1996 {Annual} {Reliability} and {Maintainability} {Symposium}},
	author = {Sinnamon, R.M. and Andrews, J.D.},
	month = jan,
	year = {1996},
	note = {ISSN: 0149-144X},
	keywords = {Boolean functions, Computational efficiency, Data structures, Equations, Fault trees, Logic, Probability, Upper bound},
	pages = {215--222},
}

@inproceedings{coudert_fault_1993,
	title = {Fault tree analysis: 10/sup 20/ prime implicants and beyond},
	shorttitle = {Fault tree analysis},
	doi = {10.1109/RAMS.1993.296849},
	abstract = {The performances of almost all available fault tree analysis tools are limited by the performance of the prime implicant computation procedure used. All these products manipulate the prime implicants of the fault trees explicitly, so that their complexities are directly related to the number of prime implicants to be generated. The authors present a novel analysis method of coherent as well as noncoherent fault trees that overcomes this limitation because its computational cost is not related to the number of variables, gates, or prime implicants of these trees. The interactive fault tree analyzer MetaPrime based on this new method has been shown by experience to be able to perform in seconds the complete analysis of noncoherent fault trees with more than 10/sup 20/ prime implicants.{\textless}{\textgreater}},
	booktitle = {Annual {Reliability} and {Maintainability} {Symposium} 1993 {Proceedings}},
	author = {Coudert, O. and Madre, J.C.},
	month = jan,
	year = {1993},
	keywords = {Binary decision diagrams, Boolean functions, Compaction, Computational efficiency, Data structures, Fault trees, Performance analysis},
	pages = {240--245},
}

@article{way_simple_2000,
	title = {A simple component-connection method for building binary decision diagrams encoding a fault tree},
	volume = {70},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200000048X},
	doi = {10.1016/S0951-8320(00)00048-X},
	abstract = {A simple new method for building binary decision diagrams (BDDs) encoding a fault tree (FT) is provided in this study. We first decompose the FT into FT-components. Each of them is a single descendant (SD) gate-sequence. Following the node-connection rule, the BDD-component encoding an SD FT-component can each be found to be an SD node-sequence. By successively connecting the BDD-components one by one, the BDD for the entire FT is thus obtained. During the node-connection and component-connection, reduction rules might need to be applied. An example FT is used throughout the article to explain the procedure step by step. Our method proposed is a hybrid one for FT analysis. Some algorithms or techniques used in the conventional FT analysis or the newer BDD approach may be applied to our case; our ideas mentioned in the article might be referred by the two methods.},
	language = {en},
	number = {1},
	urldate = {2022-11-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Way, Yuan-Shun and Hsia, Der-Yu},
	month = oct,
	year = {2000},
	keywords = {Binary decision diagram, Boolean reduction, Fault tree},
	pages = {59--70},
}

@techreport{noauthor_computerized_nodate,
	title = {Computerized {Fault} {Tree} {Analysis}: {TREEL} and {MICSUP}.},
	shorttitle = {Computerized {Fault} {Tree} {Analysis}},
	url = {https://apps.dtic.mil/sti/citations/ADA010146},
	abstract = {Fault tree analysis has proven to be extremely useful in studying large scale systems in both industry and research.  Due to the size and complexity of most trees, it has been necessary to develop computer programs for efficient analysis.  Vessely and Narum developed a computer package called PREP and KITT in 1970.  In 1974, Fussell, Henry and Marshall produced a program called MOCUS.  The computer programs presented in this paper perform functions similar to the PREP and MOCUS codes, though the methodology and efficiency are greatly advanced.  In addition, this paper provides a basic understanding of the terminology and concepts of fault trees, discusses planned objectives, and gives some insight into a topic called Tree Trimming.  All concepts and explanations are illustrated by example.},
	language = {en},
	urldate = {2022-11-20},
	note = {Section: Technical Reports},
}

@techreport{noauthor_fault_nodate,
	title = {Fault {Tree} {Handbook}},
	url = {https://apps.dtic.mil/sti/citations/ADA354973},
	abstract = {This handbook describes a methodology for reliability analysis of complex systems such as those which comprise the engineered safety features of nuclear power generating stations. After an initial overview of the available system analysis approaches, the handbook focuses on a description of the deductive method known as fault tree analysis. The following aspects of fault tree analysis are covered 1 basic concepts for fault tree analysis 2 basic elements of a fault tree 3 fault tree construction 4 probability. statistics, and Boolean algebra for the fault tree analyst 5 qualitative and quantitative fault tree evaluation techniques and 6 computer codes for fault tree evaluation. Also discussed are several example problems illustrating the basic concepts of fault tree construction and evaluation.},
	language = {en},
	urldate = {2022-11-19},
	note = {Section: Technical Reports},
}

@article{akers_binary_1978,
	title = {Binary {Decision} {Diagrams}},
	volume = {C-27},
	issn = {1557-9956},
	doi = {10.1109/TC.1978.1675141},
	abstract = {This paper describes a method for defining, analyzing, testing, and implementing large digital functions by means of a binary decision diagram. This diagram provides a complete, concise, "implementation-free" description of the digital functions involved. Methods are described for deriving these diagrams and examples are given for a number of basic combinational and sequential devices. Techniques are then outlined for using the diagrams to analyze the functions involved, for test generation, and for obtaining various implementations. It is shown that the diagrams are especially suited for processing by a computer. Finally, methods are described for introducing inversion and for directly "interconnecting" diagrams to define still larger functions. An example of the carry look-ahead adder is included.},
	number = {6},
	journal = {IEEE Transactions on Computers},
	author = {{Akers}},
	month = jun,
	year = {1978},
	note = {Conference Name: IEEE Transactions on Computers},
	keywords = {Binary decision diagrams, digital functions, logic diagrams, logic synthesis, logical analysis, test generation},
	pages = {509--516},
}

@misc{noauthor_pre-conceptual_nodate,
	title = {Pre-conceptual high temperature gas-cooled microreactor design utilizing two-phase composite moderators. {Part} {I}: {Microreactor} design and reactor performance {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Pre-conceptual high temperature gas-cooled microreactor design utilizing two-phase composite moderators. {Part} {I}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0149197022001329?token=146EA375B87A6456066FDD2161EC62AEC485CA2EE7831021D50903F19FBF3D4BB3D7E29F40789A443F6BBF5BF9CE5557&originRegion=us-east-1&originCreation=20221118165516},
	language = {en},
	urldate = {2022-11-18},
	doi = {10.1016/j.pnucene.2022.104257},
}

@book{noauthor_evaluation_2013,
	address = {Vienna},
	title = {Evaluation of high temperature gas cooled reactor performance: benchmark analysis related to the {PBMR}-400, {PBMM}, {GT}-{MHR}, {HTR}-10 and the {ASTRA} critical facility},
	isbn = {978-92-0-137610-7},
	shorttitle = {Evaluation of high temperature gas cooled reactor performance},
	language = {en},
	publisher = {International Atomic Energy Agency},
	year = {2013},
	note = {OCLC: 853245014},
}

@techreport{noauthor_program_nodate,
	title = {Program on {Technology} {Innovation}: {Comprehensive} {Risk} {Assessment} {Requirements} for {Passive} {Safety} {Systems}},
	url = {https://www.epri.com/research/products/1016747},
	urldate = {2022-11-17},
}

@inproceedings{hu_entropy-based_2004,
	title = {An entropy-based exploration strategy in dynamic {PRA}},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer},
	author = {Hu, Yunwei and Groen, Frank and Mosleh, Ali},
	year = {2004},
	pages = {2391--2397},
}

@article{ballard_pra_1986,
	title = {{PRA} for decision making? — {Some} issues of the reliability data},
	volume = {93},
	issn = {0029-5493},
	shorttitle = {{PRA} for decision making?},
	url = {https://www.sciencedirect.com/science/article/pii/0029549386902323},
	doi = {10.1016/0029-5493(86)90232-3},
	abstract = {The development of probabilistic safety analysis methods offers the decision maker a potentially powerful tool to assist in the decision making process. In practice there is considerable discussion about the validity of PRA methodology and issues of uncertainty in the PRA results are raised as a possible barrier to its usefulness. In this paper some of the issues related to the use of reliability data in PRA are discussed and it is noted that while such data is uncertain a proper appreciation of the situation can still lead to useful results being produced.},
	language = {en},
	number = {2},
	urldate = {2022-11-15},
	journal = {Nuclear Engineering and Design},
	author = {Ballard, G. M.},
	month = may,
	year = {1986},
	pages = {335--339},
}

@article{mosleh_pra_2014,
	title = {{PRA}: {A} {PERSPECTIVE} {ON} {STRENGTHS}, {CURRENT} {LIMITATIONS}, {AND} {POSSIBLE} {IMPROVEMENTS}},
	volume = {46},
	issn = {1738-5733},
	shorttitle = {{PRA}},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573315300851},
	doi = {10.5516/NET.03.2014.700},
	abstract = {Probabilistic risk assessment (PRA) has been used in various technological fields to assist regulatory agencies, managerial decision makers, and systems designers in assessing and mitigating the risks inherent in these complex arrangements. Has PRA delivered on its promise? How do we gage PRA performance? Are our expectations about value of PRA realistic? Are there disparities between what we get and what we think we are getting form PRA and its various derivatives? Do current PRAs reflect the knowledge gained from actual events? How do we address potential gaps? These are some of the questions that have been raised over the years since the inception of the field more than forty years ago. This paper offers a brief assessment of PRA as a technical discipline in theory and practice, its key strengths and weaknesses, and suggestions on ways to address real and perceived shortcomings.},
	language = {en},
	number = {1},
	urldate = {2022-11-15},
	journal = {Nuclear Engineering and Technology},
	author = {Mosleh, ALI},
	month = feb,
	year = {2014},
	keywords = {Advanced PRA Methods, PRA Applications and Lesson Leaned, Probabilistic Risk Assessment},
	pages = {1--10},
}

@article{perryman_experiences_1995,
	series = {Failures '94 {An} {International} {Symposium} on {Risk}, {Economy} and {Safety}, {Failure} {Minimisation} and {Analysis}},
	title = {Experiences in using {PRA} as an operational tool},
	volume = {61},
	issn = {0308-0161},
	url = {https://www.sciencedirect.com/science/article/pii/0308016194001297},
	doi = {10.1016/0308-0161(94)00129-7},
	abstract = {The Probabilistic Risk Assessment (PRA) of Koeberg Nuclear Power Station has been used for a number of years to support operation decision making. The principle aim of this risk assessment of Koeberg is to determine the probability of a severe accident under varying operating conditions. This plant model is used by ourselves and our licensing authority to assess nuclear safety issues. Through this process, considerable practical experience has been gained in using a “living” PRA to improve plant safety and performance. This paper presents some of the insights obtained in using reliability engineering in such a dynamic way and demonstrates that by developing and using the “living” PRA considerable safety and financial gains can be obtained. These insights mainly concern the prerequisites required before optimal use of a “living” PRA can be made. Other insights concern how PRA results are best presented and interpreted. Finally, examples are presented of occurrences when PRA was used to aid operating decisions.},
	language = {en},
	number = {2},
	urldate = {2022-11-15},
	journal = {International Journal of Pressure Vessels and Piping},
	author = {Perryman, L. J. and Foster, N. A. S. and Nicholls, D. R.},
	month = jan,
	year = {1995},
	pages = {579--592},
}

@misc{noauthor_texas_nodate,
	title = {Texas {Instruments} - {Reliability} {Testing}},
	url = {https://www.ti.com/support-quality/reliability/reliability-testing.html},
	urldate = {2022-01-10},
	journal = {Texas Instruments Quality \& Reliability},
}

@book{noauthor_progress_2014,
	address = {Vienna},
	series = {{TECDOC} {Series}},
	title = {Progress in {Methodologies} for the {Assessment} of {Passive} {Safety} {System} {Reliability} in {Advanced} {Reactors}},
	isbn = {978-92-0-108614-3},
	url = {https://www.iaea.org/publications/10783/progress-in-methodologies-for-the-assessment-of-passive-safety-system-reliability-in-advanced-reactors},
	number = {1752},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2014},
}

@book{manners-bell_supply_2014,
	address = {London},
	title = {Supply {Chain} {Risk}: {Understanding} {Emerging} {Threats} to {Global} {Supply} {Chains}},
	isbn = {978-0-7494-7110-1},
	shorttitle = {Supply {Chain} {Risk}},
	url = {https://proxying.lib.ncsu.edu/index.php?url=https://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=732516&site=ehost-live},
	abstract = {Risk is at the very core of supply chain theory and is at the heart of every decision-making process. Supply chain risk is now becoming everyone's responsibility and over the last two years has become more important than ever, making its presence on the boardroom agenda of most big companies. Supply Chain Risk assesses the various sources of external threat to the supply chain and how multinational corporations should be dealing with them at a strategic level. In this book John Manners-Bell clearly shows how to implement risk strategies that minimize, even completely eliminate, supply chain risk, and outlines how to build resilient supply chains. Supply Chain Risk includes case studies of best practice and cites examples of when and how things go wrong. Each case study describes the company's supply chain strategy and production/sourcing strategy, outlines the catastrophic event which occurred, including the supply chain consequences and material losses, the management response, and resultant changes to company supply chain strategy. The book is accompanied by invaluable downloadable online resources, including a survey on companies'attitudes to supply chain risk. Supply Chain Risk has won the ACA-Bruel Special Mention prize for its contribution to the development of leading new concepts and methods in purchasing and supply chain. The prize is organised by the Association of Purchasing and Supply Chain (CESA) of HEC School of Management in Paris. Highly accessible with real practical application, Supply Chain Risk is for supply chain managers and anyone interfacing with the supply chain.},
	language = {English},
	urldate = {2022-04-20},
	publisher = {Kogan Page},
	author = {Manners-Bell, John},
	year = {2014},
	keywords = {BUSINESS \& ECONOMICS / Industries / Manufacturing, BUSINESS \& ECONOMICS / Insurance / Risk Assessment \& Management, BUSINESS \& ECONOMICS / Production \& Operations Management, Business logistics, Materials management, Risk management},
}

@article{standard_stress-test-driven_2018,
	title = {Stress-test-driven qualification of integrated circuits},
	shorttitle = {{JEDEC} {JESD47}},
	abstract = {This standard describes a baseline set of acceptance tests for use in qualifying electronic components as new products, a product family, or as products in a process which is being changed. 

These tests are capable of stimulating and precipitating semiconductor device and packaging failure modes on free-standing components not soldered to a printed wired board (PWB), or the like (base component reliability). The objective is to precipitate failures in an accelerated manner compared to use conditions. Failure Rate projections usually require larger sample sizes than are called out in qualification testing. For guidance on projecting failure rates, refer to JESD85 Methods for Calculating Failure Rates in Units of FITs. 

This qualification standard is aimed at a generic qualification for a range of use conditions, but


may not be applicable at extreme use conditions such as military applications, automotive under-thehood applications, or uncontrolled avionics environments


does not cover components assembled onto a PWB, or the like, which may affect the component reliability under assembled state. This is addressed in JEP150 and e.g., typically applies to TC on WLCSP devices


Additional qualification testing tailored to meet specific requirements such as solder joint interconnect reliability can be developed by applying JESD94. 

This set of tests should not be used indiscriminately. Each qualification project should be examined for: 

a) Any potential new and unique failure mechanisms. 

b) Any situations where these tests/conditions may induce invalid or overstress failures. 

If it is known or suspected that failures either are due to new mechanisms or are uniquely induced by the severity of the test conditions, then the application of the test condition as stated is not recommended. Alternatively, new mechanisms or uniquely problematic stress levels should be addressed by building an understanding of the mechanism and its behavior with respect to accelerated stress conditions (Ref. JESD91, “Method for Developing Acceleration Models for Electronic Component Failure Mechanisms” and JESD94, “Application Specific Qualification using Knowledge Based Test Methodology”). 

Consideration of PC board assembly-level effects may also be necessary. For guidance on this, refer to JEP150, Stress-Test-Driven Qualification of and Failure Mechanisms Associated with Assembled Solid State Surface-Mount Components. 

This document does not relieve the supplier of the responsibility to assure that a product meets the complete set of its requirements.},
	number = {47K},
	journal = {JEDEC Solid State Technology Association. JEDEC Standard},
	author = {Standard, JEDEC},
	year = {2018},
	pages = {1--26},
}

@article{hokenek_second-generation_1990,
	title = {Second-generation {RISC} floating point with multiply-add fused},
	volume = {25},
	issn = {00189200},
	url = {http://ieeexplore.ieee.org/document/62143/},
	doi = {10.1109/4.62143},
	number = {5},
	urldate = {2022-11-14},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Hokenek, E. and Montoye, R.K. and Cook, P.W.},
	month = oct,
	year = {1990},
	pages = {1207--1213},
}

@article{ferdous_methodology_2007,
	title = {Methodology for {Computer}-{Aided} {Fault} {Tree} {Analysis}},
	volume = {85},
	issn = {0957-5820},
	url = {https://www.sciencedirect.com/science/article/pii/S0957582007713885},
	doi = {10.1205/psep06002},
	abstract = {Fault tree analysis is a systematic, deductive and probabilistic risk assessment tool which elucidates the causal relations leading to a given undesired event. Quantitative fault tree (failure) analysis requires a fault tree and failure data of basic events. Development of a fault tree and subsequent analysis require a great deal of expertise, which may not be available all the time. Computer-aided fault tree analysis is an easy-to-use approach, which not only provides reliable results but also facilitates the validation and repeatability of the analysis. This enhances the overall results of the fault tree analysis and quantitative risk analysis. This paper presents a revised methodology for computer-aided fault tree analysis. The methodology includes fault tree development, minimal cutsets determination, cutsets optimization and probability analysis. The methodology uses advanced concepts of fault tree development and static and dynamic modularizing for complex and large fault trees. Furthermore, it enables sensitivity analysis of the system for design modification and risk-based decision making. Application of the proposed methodology to a process system is also discussed in the paper.},
	language = {en},
	number = {1},
	urldate = {2022-11-12},
	journal = {Process Safety and Environmental Protection},
	author = {Ferdous, R. and Khan, F. I. and Veitch, B. and Amyotte, P. R.},
	month = jan,
	year = {2007},
	keywords = {failure probability calculation, fault tree analysis, probability analysis, risk assessment},
	pages = {70--80},
}

@article{geymayr_fault-tree_1995,
	title = {Fault-tree analysis: a knowledge-engineering approach},
	volume = {44},
	issn = {1558-1721},
	shorttitle = {Fault-tree analysis},
	doi = {10.1109/24.376519},
	abstract = {This paper deals with the application of knowledge engineering and a methodology for the assessment and measurement of reliability, availability, maintainability, and safety of industrial systems using fault-tree representation. Object oriented structures, production rules representing the expert's heuristics, algorithms, and database structures are the basic elements of the system. The blackboard architecture of the system supports qualitative and quantitative evaluation of the fault tree. A fuzzy set approach analyzes problems with few failure data or much fuzziness or imprecision. Fault-tree analysis is a knowledge acquisition structure that has been extensively explored by knowledge engineers. Reliability engineers can apply the techniques developed by this area of computer science to: (1) improve the data acquisition process; (2) explore the benefits of object oriented expert systems for reliability applications; (3) integrate the several sources of knowledge into a unique system; (4) explore the approximate reasoning to handle uncertainty; and (5) develop hybrid solution strategies combining expert heuristics, conventional procedures, and available failure data.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Reliability},
	author = {Geymayr, J.A.B. and Ebecken, N.F.F.},
	month = mar,
	year = {1995},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Availability, Fault trees, Fuzzy sets, Heuristic algorithms, Knowledge engineering, Maintenance, Object oriented databases, Production systems, Reliability engineering, Safety},
	pages = {37--45},
}

@article{dutuit_efficient_2001,
	title = {Efficient algorithms to assess component and gate importance in fault tree analysis},
	volume = {72},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832001000047},
	doi = {10.1016/S0951-8320(01)00004-7},
	abstract = {One of the principal activities of risk assessment is either the ranking or the categorization of structures, systems and components with respect to their risk-significance or their safety-significance. Several measures, so-called importance factors, of such a significance have been proposed for the case where the support model is a fault tree. In this article, we show how binary decision diagrams can be use to assess efficiently a number of classical importance factors. This work completes the preliminary results obtained recently by Andrews and Sinnamon, and the authors. It deals also with the concept of joint reliability importance.},
	language = {en},
	number = {2},
	urldate = {2022-11-12},
	journal = {Reliability Engineering \& System Safety},
	author = {Dutuit, Y. and Rauzy, A.},
	month = may,
	year = {2001},
	keywords = {Binary decision diagrams, Fault trees, Importance factors},
	pages = {213--222},
}

@article{kabir_overview_2017,
	title = {An overview of fault tree analysis and its application in model based dependability analysis},
	volume = {77},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417417300714},
	doi = {10.1016/j.eswa.2017.01.058},
	language = {en},
	urldate = {2022-11-12},
	journal = {Expert Systems with Applications},
	author = {Kabir, Sohag},
	month = jul,
	year = {2017},
	pages = {114--135},
}

@article{wang_fault-tree-based_2016,
	title = {Fault-tree-based instantaneous risk computing core in nuclear power plant risk monitor},
	volume = {95},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454916300950},
	doi = {10.1016/j.anucene.2016.02.024},
	abstract = {Risk monitor is an application of Probabilistic Safety Assessment (PSA) methodology, which has been widely used to determine the instantaneous risk based on the actual conﬁguration of the nuclear power plant (NPP). The instantaneous risk model which has been converted from the baseline risk model of PSA is the fundament of instantaneous risk analysis in a risk monitor. However, the instantaneous risk model is usually very huge and complex, which is hard to be calculated and analyzed by hand. A fault-tree-based instantaneous risk computing core was developed by FDS Team. This code adopts the fast fault tree analysis method based on modiﬁed Zero-suppressed Binary Decision Diagram (ZBDD), which includes a set of algorithms such as fault tree importing, fault tree reduction, ZBDD variable ordering, ZBDD parallel manipulation and cut-sets-based ZBDD reconstruction, etc. Benchmarks of actual NPP instantaneous risk models compared with similar codes showed that this code was correct and efﬁcient. This computing core was applied in the Third Qinshan NPP risk monitor TQRM, and some cases based on the actual NPP instantaneous risk models are given.},
	language = {en},
	urldate = {2022-11-12},
	journal = {Annals of Nuclear Energy},
	author = {Wang, Jin and Wang, Fang and Chen, Shanqi and Wang, Jiaqun and Hu, Liqin and Yin, Yuan and Wu, Yican},
	month = sep,
	year = {2016},
	pages = {35--41},
}

@article{john_lekan_algorithms_2017,
	title = {Algorithms for {Reducing} {Cut} {Sets} in {Fault} {Tree} {Analysis}},
	volume = {6},
	doi = {10.17148/IJARCCE.2017.61207},
	abstract = {Fault Tree Analysis is a graphical and analytical model for identifying and accessing the relevant causes of a system risk or fault or undesired event. it is used in process system for identifying basic events or causes of an event, identifying common-cause(Minimal cut sets) failures, displaying causes and consequence of undesired event, evaluating design and investigating process accidents/incidents. The main aim of any fault-tree algorithm is to compute the minimal cut sets as quickly as possible. A cut set is a collection of component failure modes that could lead to a system failure. Cut Set Analysis (CSA) is applied to critical systems to identify and rank system vulnerabilities at design time. This paper presents a critical review of the various quantitative fault tree analysis techniques and also provide a formal procedure of each of the techniques.},
	author = {John Lekan, Akinode},
	month = dec,
	year = {2017},
	pages = {36--41},
}

@article{sinnamon_improved_1997,
	title = {Improved efficiency in qualitative fault tree analysis},
	volume = {13},
	issn = {1099-1638},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-1638%28199709/10%2913%3A5%3C293%3A%3AAID-QRE110%3E3.0.CO%3B2-Y},
	doi = {10.1002/(SICI)1099-1638(199709/10)13:5<293::AID-QRE110>3.0.CO;2-Y},
	abstract = {The fault tree diagram itself is an excellent way of deriving the failure logic for a system and representing it in a form which is ideal for communication to managers, designers, operators, etc. Since the method was first conceived, algorithms to derive the minimal cut sets have worked directly with the fault tree diagram using either bottom-up or top-down approaches. These conventional techniques have several disadvantages when it comes to analysing the fault tree. For complex systems an analysis may produce hundreds of thousands of minimal cut sets, the determination of which can be a very time-consuming process. Also, for large fault trees it may not be possible to evaluate all minimal cut sets, so methods to identify those event combinations which provide the most significant contributions to the system failure are evoked. Such methods include probabilistic or order culling to reduce the problem to a practical size, but they can also create considerable inaccuracies when it comes to evaluating top event probability parameters This paper describes how the binary decision diagram method can be employed to evaluate the minimal cut sets of a fault tree efficiently and without the need to use approximations such as order culling. © 1997 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {5},
	urldate = {2022-11-12},
	journal = {Quality and Reliability Engineering International},
	author = {Sinnamon, R. M. and Andrews, J. D.},
	year = {1997},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291099-1638\%28199709/10\%2913\%3A5\%3C293\%3A\%3AAID-QRE110\%3E3.0.CO\%3B2-Y},
	keywords = {binary decision diagrams, fault tree analyses, minimal cut sets},
	pages = {293--298},
}

@techreport{fort_thermal_2019,
	title = {Thermal {Modeling} of the {TN}-{32B} {Cask} for the {High} {Burnup} {Spent} {Fuel} {Data} {Project}},
	url = {https://www.osti.gov/servlets/purl/1566774/},
	abstract = {This report describes thermal modeling done for the High Burnup Spent Fuel Data Project that is being performed by the U.S. Department of Energy’s Spent Fuel and Waste Science and Technology (SFWST) research and development (R\&D) program. The purpose of this project is to investigate the performance of high-burnup spent nuclear fuel in dry storage. Part of this project is a demonstration test being performed with a storage module in the North Anna Nuclear Power Station’s Independent Spent Fuel Storage Installation (ISFSI). The storage module selected for this demonstration is an Orano TN-32B High Burnup cask (Figure S-1) which has been loaded with fuel assemblies from the North Anna spent fuel pool. The main goals of this test are to provide confirmatory data for model validation and potential improvement, support license renewals and new licenses for ISFSIs, and support transportation licensing for high burnup spent nuclear fuel (EPRI 2014).},
	language = {en},
	number = {PNNL--28915, 1566774},
	urldate = {2022-11-11},
	author = {Fort, James and Richmond, David and Cuta, Judith and Suffield, Sarah},
	month = jul,
	year = {2019},
	doi = {10.2172/1566774},
	pages = {PNNL--28915, 1566774},
}

@article{koskenranta_loviisa_2022,
	title = {Loviisa nuclear power plant spent fuel storage risk analysis},
	abstract = {Spent fuel of Loviisa NPP is stored submerged in water pools of spent fuel storage (SFS) at Loviisa site at least 10 years and up to many decades. First 1 – 2 years the spent fuel is cooled in refueling pools in reactor buildings. After SFS the spent fuel will be moved to final repository at Olkiluoto. Loviisa NPP PRA covers level 1 and level 2 PRA for reactors and refueling pools for both unit 1 and 2 and common spent fuel storage for both units. Loviisa NPP PRA covers also all operating and shutdown states and all types of initiating events. Current seismic PRA is outdated and under significant update. Loviisa SFS PRA models SFS with highest design basis decay heat rate of current operating license from 2030. Mission times vary from no time to recover to up to 2 months. Criteria for result evaluation is fuel exposure or mechanical break. Equipment failures have only minor impact to the risk because of low heating rate. Seismic initiating events cause over 50 \% of fuel damage frequency (FDF) and large release frequency. Also early release frequency (ERF) is considered. FDF 1,9E-7/a is about 1 \% of combined Loviisa unit 1 and 2 core damage frequency.},
	language = {en},
	author = {Koskenranta, Jukka and Paavola, Ilkka and Hotakainen, Rasmus and Laato, Taisto},
	year = {2022},
	pages = {12},
}

@article{olofsson_challenges_2022,
	title = {Challenges and {Lessons} {Learned} from a {PSA} on a {Spent} {Fuel} {Pool} {Facility}},
	abstract = {Performing a PSA on a spent fuel pool storage facility provides new challenges but also new insights. Even though the nuclear fuel is the common subject for the risk to be evaluated, the differences compared to a traditional PSA for a nuclear power plant are several.},
	language = {en},
	author = {Olofsson, Frida and Olsson, Anders},
	year = {2022},
	pages = {7},
}

@techreport{biersdorf_development_2020,
	title = {Development of {Dry} {Cask} {Risk} {Tools}},
	url = {http://www.osti.gov/servlets/purl/1603757/},
	language = {en},
	number = {INL/EXT-20-57570-Rev000, 1603757},
	urldate = {2022-11-11},
	author = {Biersdorf, John M and Eidelpes, Elmar Ferdinand},
	month = apr,
	year = {2020},
	doi = {10.2172/1603757},
	pages = {INL/EXT--20--57570--Rev000, 1603757},
}

@article{ma_causation_2018,
	title = {Causation {Analysis} of {Hazardous} {Material} {Road} {Transportation} {Accidents} by {Bayesian} {Network} {Using} {Genie}},
	volume = {2018},
	issn = {0197-6729, 2042-3195},
	url = {https://www.hindawi.com/journals/jat/2018/6248105/},
	doi = {10.1155/2018/6248105},
	abstract = {With the increase of hazardous materials (Hazmat) demand and transportation, frequent Hazmat road transportation accidents had arisen the widespread concern in the community. Thus, it is necessary to analyze the risk factors’ implications, which would make the safety of Hazmat transportation evolve from “passive type” to “active type”. In order to explore the influence of risk factors resulting in accidents and predict the occurrence of accidents under the combination of risk factors, 839 accidents that have occurred for the period 2015–2016 were collected and examined. The Bayesian network structure was established by experts’ knowledge using Dempster-Shafer evidence theory. Parameter learning was conducted by the Expectation-Maximization (EM) algorithm in Genie 2.0. The two main results could be likely to obtain the following. (1) The Bayesian network model can explore the most probable factor or combination leading to the accident, which calculated the posterior probability of each risk factor. For example, the importance of three or more vehicles in an accident leading to the severe accident is higher than less vehicles, and in the absence of other evidences, the most probable reasons for “explosion accident” are vehicles carrying flammable liquids, larger quantity Hazmat, vehicle failure, and transporting in autumn. (2) The model can predict the occurrence of accident by setting the influence degrees of specific factor. Such that the probability of rear-end accidents caused by “speeding” is 0.42, and the probability could reach up to 0.97 when the driver is speeding at the low-class roads. Moreover, the complex logical relationship in Hazmat road transportation accidents could be obtained, and the uncertain relation among various risk factors could be expressed. These findings could provide theoretical support for transportation corporations and government department on taking effective measures to reduce the risk of Hazmat road transportation.},
	language = {en},
	urldate = {2022-11-11},
	journal = {Journal of Advanced Transportation},
	author = {Ma, Xiaoli and Xing, Yingying and Lu, Jian},
	month = aug,
	year = {2018},
	pages = {1--12},
}

@article{iranitalab_probabilistic_2020,
	title = {Probabilistic classification of hazardous materials release events in train incidents and cargo tank truck crashes},
	volume = {199},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832019308932},
	doi = {10.1016/j.ress.2020.106914},
	abstract = {As two of the main modes of hazmat surface transportation, quantifying conditional probability of release of hazmat from trains in rail incidents and Cargo Tank Trucks (CTTs) in highway crashes is an important component of risk assessment. The objective of this study was identifying computational tools with reliable performance for quantifying probability of hazmat release in train incidents and CTT crashes, based on the type of the decision-making problem. Events of release of hazmat were probabilistically classified by statistical and machine learning methods (Mixed Logistic Regression, Naïve Bayes, Random Forests, and Support Vector Machines) using relevant explanatory variables. The datasets were Federal Railroad Administration rail equipment incident data, and combined Nebraska and Kansas police-reported traffic crash data. Given the rarity of these events, the classification performance of different methods was compared based on precision, recall and area under ROC curves (AUC). Random Forests had the best performance in classifying hazmat release for trains and railcars, based on different criteria. For CTTs, Support Vector Machines and Random Forests had the highest precision, while logistic regression and naïve Bayes performed better based on recall and AUC. The research provides recommendations regarding usage of the methods depending on the purpose of analysis.},
	language = {en},
	urldate = {2022-11-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Iranitalab, Amirfarrokh and Khattak, Aemal},
	month = jul,
	year = {2020},
	pages = {106914},
}

@article{meng_railway_2022,
	title = {Railway accident prediction strategy based on ensemble learning},
	volume = {176},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001457522002524},
	doi = {10.1016/j.aap.2022.106817},
	abstract = {Railway accident prediction is of great significance for establishing an early warning mechanism and preventing the occurrences of accidents. Safety agencies rely on prediction models to design railroad risk management strategies. Based on historical railway accident data, an ensemble learning strategy for accident prediction is proposed. Firstly, an improved K-nearest neighbors (KNN) data imputation algorithm is proposed to solve the problem of missing data in the dataset. Then, to reduce the impact of imbalanced data on prediction perfor­ mance, an AdaBoost-Bagging method is presented. Finally, according to the feature importance in the prediction model, accident features are ranked to identify new insights into the cause of the accident. The AdaBoost-Bagging prediction method is applied to the Federal Railroad Administration (FRA) dataset. The application results show that, compared with Artificial Neural Network (ANN), XGBoost, GBDT, Stacking and AdaBoost methods, AdaBoost-Bagging method has a smaller prediction error and faster inference time in predicting railway acci­ dents. Accuracy, Precision, Recall and F1–score are 0.879, 0.879, 0.883 and 0.881 respectively, and the inference time is reduced by 23.38\%, 12.15\%, 6.66\%, 3.17\% and 11.41\% respectively. The prediction method can well mine important features of railway accidents without knowing the accident mechanism or the relationship be­ tween various railway accidents and factors, e.g., the critic risk factors related to derailment and collision ac­ cidents are investigated in the prediction. The findings will be helpful to the prevention and management of railway accidents.},
	language = {en},
	urldate = {2022-11-11},
	journal = {Accident Analysis \& Prevention},
	author = {Meng, Haining and Tong, Xinyu and Zheng, Yi and Xie, Guo and Ji, Wenjiang and Hei, Xinhong},
	month = oct,
	year = {2022},
	pages = {106817},
}

@article{braverman_impact_nodate,
	title = {{IMPACT} {ANALYSIS} {OF} {SPENT} {FUEL} {DRY} {CASKS} {UNDER} {ACCIDENTAL} {DROP} {SCENARIOS}},
	abstract = {A series of analyses were performed to assess the structural response of spent nuclear fuel dry casks subjected to various handling and on-site transfer events. The results of these analyses are being used by the Nuclear Regulatory Commission (NRC) to perform a probabilistic risk assessment (PRA). Although the PRA study is being performed for a specific nuclear plant, the PRA study is also intended to provide a framework for a general methodology that could also be applied to other dry cask systems at other nuclear plants.},
	language = {en},
	author = {Braverman', J I and Morante', R J and Xu', J},
	pages = {8},
}

@article{sekiguchi_mitigating_nodate,
	title = {Mitigating the {Risks} of {Spent} {Nuclear} {Fuel} in {Japan}},
	language = {en},
	author = {Sekiguchi, Yukari},
	pages = {9},
}

@inproceedings{aziz_data_2021,
	title = {Data {Considerations} in {Graph} {Representation} {Learning} for {Supply} {Chain} {Networks}},
	url = {https://arxiv.org/abs/2107.10609},
	doi = {https://doi.org/10.48550/arXiv.2107.10609},
	abstract = {Supply chain network data is a valuable asset for businesses wishing to understand their ethical profile, security of supply, and efficiency. Possession of a dataset alone however is not a sufficient enabler of actionable decisions due to incomplete information. In this paper, we present a graph representation learning approach to uncover hidden dependency links that focal companies may not be aware of. To the best of our knowledge, our work is the first to represent a supply chain as a heterogeneous knowledge graph with learnable embeddings. We demonstrate that our representation facilitates state-of-the-art performance on link prediction of a global automotive supply chain network using a relational graph convolutional network. It is anticipated that our method will be directly applicable to businesses wishing to sever links with nefarious entities and mitigate risk of supply failure. More abstractly, it is anticipated that our method will be useful to inform representation learning of supply chain networks for downstream tasks beyond link prediction.},
	author = {Aziz, Ajmal and Kosasih, Edward and Griffiths, Ryan-Rhys and Brintrup, Alexandra},
	month = jul,
	year = {2021},
}

@article{kosasih_towards_2022,
	title = {Towards knowledge graph reasoning for supply chain risk management using graph neural networks},
	volume = {0},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2022.2100841},
	doi = {10.1080/00207543.2022.2100841},
	abstract = {Modern supply chains are complex, interconnected systems that contain emergent, invisible dependencies. Lack of visibility often hinders effective risk planning and results in delayed discovery of supply chain problems, with examples ranging from product contamination, unsustainable production practices, or exposure to suppliers clustered in geographical areas prone to natural or man-made disasters. Initiatives that rely on manual collection of data often fail due to supply chain complexity and unwillingness of suppliers to share data. In this paper, we propose a neurosymbolic machine learning technique to proactively uncover hidden risks in supply chains and discover new information. Our method uses a combination of graph neural networks and knowledge graph reasoning. Unlike existing research our model is able to infer multiple types of hidden relationship risks, presenting a step change in automated supply chain surveillance. The approach has been tested on two empirical datasets from the automotive and energy industries, illustrating that it can provide inference in multiple types of links such as companies, products, production capabilities, certifications; thereby facilitating complex queries that go beyond who-supplies-whom. As such, additional risk insights can emerge from graph structure, providing practitioners with new knowledge.},
	number = {0},
	urldate = {2022-11-10},
	journal = {International Journal of Production Research},
	author = {Kosasih, Edward Elson and Margaroli, Fabrizio and Gelli, Simone and Aziz, Ajmal and Wildgoose, Nick and Brintrup, Alexandra},
	month = jul,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2022.2100841},
	keywords = {artificial intelligence, knowledge graph, link prediction, machine learning, neurosymbolic, supply chain},
	pages = {1--17},
}

@article{kosasih_machine_2022,
	title = {A machine learning approach for predicting hidden links in supply chain with graph neural networks},
	volume = {60},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2021.1956697},
	doi = {10.1080/00207543.2021.1956697},
	abstract = {Supply chain business interruption has been identified as a key risk factor in recent years, with high-impact disruptions due to disease outbreaks, logistic issues such as the recent Suez Canal blockage showing examples of how disruptions could propagate across complex emergent networks. Researchers have highlighted the importance of gaining visibility into procurement interdependencies between suppliers to develop more informed business contingency plans. However, extant methods such as supplier surveys rely on the willingness or ability of suppliers to share data and are not easily verifiable. In this article, we pose the supply chain visibility problem as a link prediction problem from the field of Machine Learning (ML) and propose the use of an automated method to detect potential links that are unknown to the buyer with Graph Neural Networks (GNN). Using a real automotive network as a test case, we show that our method performs better than existing algorithms. Additionally, we use Integrated Gradient to improve the explainability of our approach by highlighting input features that influence GNN’s decisions. We also discuss the advantages and limitations of using GNN for link prediction, outlining future research directions.},
	number = {17},
	urldate = {2022-11-10},
	journal = {International Journal of Production Research},
	author = {Kosasih, Edward Elson and Brintrup, Alexandra},
	month = sep,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00207543.2021.1956697},
	keywords = {Supply chain, artificial intelligence, explainability, link prediction, machine learning, visibility},
	pages = {5380--5393},
}

@book{bode_supply_2020,
	address = {Wiesbaden},
	series = {Advanced {Studies} in {Supply} {Management}},
	title = {Supply {Management} {Research}: {Aktuelle} {Forschungsergebnisse} 2020},
	isbn = {978-3-658-31897-0 978-3-658-31898-7},
	shorttitle = {Supply {Management} {Research}},
	url = {http://link.springer.com/10.1007/978-3-658-31898-7},
	language = {de},
	urldate = {2022-11-10},
	publisher = {Springer Fachmedien Wiesbaden},
	editor = {Bode, Christoph and Bogaschewsky, Ronald and Eßig, Michael and Lasch, Rainer and Stölzle, Wolfgang},
	year = {2020},
	doi = {10.1007/978-3-658-31898-7},
}

@article{bassiouni_advanced_2023,
	title = {Advanced deep learning approaches to predict supply chain risks under {COVID}-19 restrictions},
	volume = {211},
	issn = {0957-4174},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9389854/},
	doi = {10.1016/j.eswa.2022.118604},
	abstract = {The ongoing COVID-19 pandemic has created an unprecedented predicament for global supply chains (SCs). Shipments of essential and life-saving products, ranging from pharmaceuticals, agriculture, and healthcare, to manufacturing, have been significantly impacted or delayed, making the global SCs vulnerable. A better understanding of the shipment risks can substantially reduce that nervousness. Thenceforth, this paper proposes a few Deep Learning (DL) approaches to mitigate shipment risks by predicting ”if a shipment can be exported from one source to another”, despite the restrictions imposed by the COVID-19 pandemic. The proposed DL methodologies have four main stages: data capturing, de-noising or pre-processing, feature extraction, and classification. The feature extraction stage depends on two main variants of DL models. The first variant involves three recurrent neural networks (RNN) structures (i.e., long short-term memory (LSTM), Bidirectional long short-term memory (BiLSTM), and gated recurrent unit (GRU)), and the second variant is the temporal convolutional network (TCN). In terms of the classification stage, six different classifiers are applied to test the entire methodology. These classifiers are SoftMax, random trees (RT), random forest (RF), k-nearest neighbor (KNN), artificial neural network (ANN), and support vector machine (SVM). The performance of the proposed DL models is evaluated based on an online dataset (taken as a case study). The numerical results show that one of the proposed models (i.e., TCN) is about 100\% accurate in predicting the risk of shipment to a particular destination under COVID-19 restrictions. Unarguably, the aftermath of this work will help the decision-makers to predict supply chain risks proactively to increase the resiliency of the SCs.},
	urldate = {2022-11-10},
	journal = {Expert Systems with Applications},
	author = {Bassiouni, Mahmoud M. and Chakrabortty, Ripon K. and Hussain, Omar K. and Rahman, Humyun Fuad},
	month = jan,
	year = {2023},
	pmid = {35999828},
	pmcid = {PMC9389854},
	pages = {118604},
}

@article{chan_bayesian_2018,
	title = {A {Bayesian} {Network} {Model} for {Reducing} {Accident} {Rates} of {Electrical} and {Mechanical} ({E}\&{M}) {Work}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1660-4601},
	url = {https://www.mdpi.com/1660-4601/15/11/2496},
	doi = {10.3390/ijerph15112496},
	abstract = {Accidents in Repair, Maintenance, Alteration, and Addition (RMAA) work have become a growing concern, in recent years. The repair and maintenance works of electrical and mechanical (E\&M) installations involves a variety of trades, a large number of practitioners and a series of high-risk activities. The uniqueness of E\&M work, in the RMAA sector, requires a discrete and specific research to improve its safety performance. Understanding the causal relationships between safety factors and the number of accidents becomes crucial to develop a more effective safety management strategy. The Bayesian Network (BN) model is proposed to establish a probabilistic relational network between the causal factors, including both safety climate factors and personal experience factors that have influences on the number of accidents related to E\&M RMAA work. The data were collected using a survey questionnaire, involving a hundred and fifty-five E\&M practitioners. The BN results demonstrated that safety attitude and safety procedures were the most important factors to reduce the number of accidents. The proposed BN provides the ability to find out the most effective strategy with the best utilization of resources, to reduce the chance of a high number of E\&M accidents, by controlling a single factor or simultaneously controlling, both, the safety climate and personal factors, to improve safety performance.},
	language = {en},
	number = {11},
	urldate = {2022-11-10},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Chan, Albert P. C. and Wong, Francis K. W. and Hon, Carol K. H. and Choi, Tracy N. Y.},
	month = nov,
	year = {2018},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Bayesian Networks, M) works, accident analysis, electrical and mechanical (E\&amp, safety management},
	pages = {2496},
}

@article{sergio_advantages_2006,
	title = {Advantages on {Dry} {Interim} {Storage} for {Spent} {Nuclear} {Fuel}},
	abstract = {When the nuclear fuel lose its ability to efficiently create energy it is removed from the core reactor and moved to a storage unit waiting for a final destination. Generally, the spent nuclear fuel (SNF) remains inside concrete basins with water within the reactors facility for the radioactive activity decay. Water cools the generated heat and shields radioactivity emissions. After some period of time in water basins the SNF can be sent to a definitive deposition in a geological repository and handled as radioactive waste or to reprocessing installations, or still wait for a future solution. Meanwhile, SNF remains stored for a period of time in dry or wet installations, depending on the method adopted by the nuclear power plant or other plans of the country. In many SNF wet storage sites the capacity can be fulfilled very quickly. If so, additional area or other alternative storage system should be given. There are many options to provide capacity increase in the wet storage area, but dry storages are worldwide preferred since it reduces corrosion concerns. In the wet storage the temperature and water purity should be constantly controlled whereas in the dry storage the SNF stands protected in specially designed canisters. Dry interim storages are practical and approved in many countries especially that have the “wait and see” philosophy (wait to see new technologies development). This paper shows the advantages of dry interim storages sites in comparison with the wet ones and the nowadays problems as terrorism.},
	language = {en},
	author = {Sergio, Luiz and Maria, Barbara},
	year = {2006},
	pages = {7},
}

@article{mahraz_machine_2022,
	title = {Machine {Learning} in {Supply} {Chain} {Management}: {A} {Systematic} {Literature} {Review}},
	shorttitle = {Machine {Learning} in {Supply} {Chain} {Management}},
	doi = {10.22034/ijsom.2021.109189.2279},
	abstract = {The supply chain ecosystem is currently benefiting from a great dynamic resulting from the digitalization of organizations and trades. For all the stakeholders in the area, this is a real breakthrough, and machine learning is at the core of this revolution. It has profoundly revolutionized companies in many aspects including the evolution of communication methods, the automation of many processes, the growing importance of information systems, etc. With shrinking margins and more demanding customers, supply chain management in increasingly becoming a source of competitive advantage. Its management and optimization requires a factual to Supply Chain decision making at strategique, tactical and operational levels. In this context and data rich environment, machine learning approaches and techniques find numerous useful applications for supply chain decision making. Today, companies have no choice but to apply Machine Learning solutions in almost every part of their processes. This fact seems even clearer in markets where competition is fierce. While Machine Learning does not redefine the enterprise, it is certainly a powerful asset for both marketing and process optimization purposes. It is so ingrained in the strategies of companies that now most of them rely heavily on it for all processes from creation, to product quality control, to public relations. In recent years, a series of practical applications of machine learning (ML) for supply chain decisions have been introduced. By interconnecting the ML methods applied for SC decision making, this paper identifies current SC applications and indicates potential research gaps. In this paper, we examine the general usability of machine learning techniques to assist with supply chain decisions. The main objective of this research is therefore to study how machine learning techniques can be integrated into the range of tools available to supply chain decision makers in order to take advantage of the increasing volume of data generated in the supply chain.},
	journal = {International Journal of Supply and Operations Management},
	author = {Mahraz, Mohamed-Iliasse and Benabbou, Loubna and Berrado, Abdelaziz},
	month = mar,
	year = {2022},
	pages = {xx--xx},
}

@article{tirkolaee_application_2021,
	title = {Application of {Machine} {Learning} in {Supply} {Chain} {Management}: {A} {Comprehensive} {Overview} of the {Main} {Areas}},
	volume = {2021},
	issn = {1024-123X},
	shorttitle = {Application of {Machine} {Learning} in {Supply} {Chain} {Management}},
	url = {https://www.hindawi.com/journals/mpe/2021/1476043/},
	doi = {10.1155/2021/1476043},
	abstract = {In today’s complex and ever-changing world, concerns about the lack of enough data have been replaced by concerns about too much data for supply chain management (SCM). The volume of data generated from all parts of the supply chain has changed the nature of SCM analysis. By increasing the volume of data, the efficiency and effectiveness of the traditional methods have decreased. Limitations of these methods in analyzing and interpreting a large amount of data have led scholars to generate some methods that have high capability to analyze and interpret big data. Therefore, the main purpose of this paper is to identify the applications of machine learning (ML) in SCM as one of the most well-known artificial intelligence (AI) techniques. By developing a conceptual framework, this paper identifies the contributions of ML techniques in selecting and segmenting suppliers, predicting supply chain risks, and estimating demand and sales, production, inventory management, transportation and distribution, sustainable development (SD), and circular economy (CE). Finally, the implications of the study on the main limitations and challenges are discussed, and then managerial insights and future research directions are given.},
	language = {en},
	urldate = {2022-11-08},
	journal = {Mathematical Problems in Engineering},
	author = {Tirkolaee, Erfan Babaee and Sadeghi, Saeid and Mooseloo, Farzaneh Mansoori and Vandchali, Hadi Rezaei and Aeini, Samira},
	month = jun,
	year = {2021},
	note = {Publisher: Hindawi},
	pages = {e1476043},
}

@article{belhadi_artificial_2021,
	title = {Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism: an empirical investigation},
	issn = {0254-5330},
	shorttitle = {Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7856338/},
	doi = {10.1007/s10479-021-03956-x},
	abstract = {Supply chain resilience (SCRes) and performance have become increasingly important in the wake of the recent supply chain disruptions caused by subsequent pandemics and crisis. Besides, the context of digitalization, integration, and globalization of the supply chain has raised an increasing awareness of advanced information processing techniques such as Artificial Intelligence (AI) in building SCRes and improving supply chain performance (SCP). The present study investigates the direct and indirect effects of AI, SCRes, and SCP under a context of dynamism and uncertainty of the supply chain. In doing so, we have conceptualized the use of AI in the supply chain on the organizational information processing theory (OIPT). The developed framework was evaluated using a structural equation modeling (SEM) approach. Survey data was collected from 279 firms representing different sizes, operating in various sectors, and countries. Our findings suggest that while AI has a direct impact on SCP in the short-term, it is recommended to exploit its information processing capabilities to build SCRes for long-lasting SCP. This study is among the first to provide empirical evidence on maximizing the benefits of AI capabilities to generate sustained SCP. The study could be further extended using a longitudinal investigation to explore more facets of the phenomenon.},
	urldate = {2022-11-08},
	journal = {Annals of Operations Research},
	author = {Belhadi, Amine and Mani, Venkatesh and Kamble, Sachin S. and Khan, Syed Abdul Rehman and Verma, Surabhi},
	month = feb,
	year = {2021},
	pmid = {33551534},
	pmcid = {PMC7856338},
	pages = {1--26},
}

@misc{noauthor_python_nodate,
	title = {Python {Tutorial} - {File} and {Text} {Processing}},
	url = {https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html},
	urldate = {2022-11-08},
}

@article{bridges_standardized_nodate,
	title = {{STANDARDIZED} {DOE} {SPENT} {NUCLEAR} {FUEL} {CANISTER} {AND} {TRANSPORTATION} {SYSTEM} {FOR} {SHIPMENT} {TO} {THE} {NATIONAL} {REPOSITORY}},
	language = {en},
	author = {Bridges, T L and Lengyel, A L and Morton, D K and Pincock, D L},
	pages = {14},
}

@article{bunn_project_nodate,
	title = {Project on {Managing} the {Atom}},
	language = {en},
	author = {Bunn, Matthew and Holdren, John P and Macfarlane, Allison and Pickett, Susan E and Suzuki, Atsuyuki and Suzuki, Tatsujiro and Weeks, Jennifer},
	pages = {146},
}

@article{werner_us_nodate,
	title = {U.{S}. {Spent} {Nuclear} {Fuel} {Storage}},
	abstract = {Regardless of the outcome of the ongoing debate about the proposed Yucca Mountain geologic waste repository in Nevada, the storage of spent nuclear fuel (SNF)—also referred to as “highlevel nuclear waste”—will continue to be needed and the issue will continue to be debated. The need for SNF storage, even after the first repository is opened, will continue for a few reasons.},
	language = {en},
	author = {Werner, James D},
	pages = {57},
}

@techreport{pearl_limitations_2019,
	address = {New York},
	type = {Technical {Report}},
	title = {The limitations of opaque learning machines, in: {J}. {Brockman} ({Ed}.), {Possible} {Minds}: 25 {Ways} of {Looking} at {AI}},
	url = {https://ftp.cs.ucla.edu/pub/stat_ser/r489.pdf},
	language = {en},
	institution = {Penguin Press},
	author = {Pearl, Judea},
	month = may,
	year = {2019},
	pages = {13--19},
}

@article{holzinger_towards_2021,
	title = {Towards multi-modal causability with {Graph} {Neural} {Networks} enabling information fusion for explainable {AI}},
	volume = {71},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253521000142},
	doi = {10.1016/j.inffus.2021.01.008},
	abstract = {AI is remarkably successful and outperforms human experts in certain tasks, even in complex domains such as medicine. Humans on the other hand are experts at multi-modal thinking and can embed new inputs almost instantly into a conceptual knowledge space shaped by experience. In many fields the aim is to build systems capable of explaining themselves, engaging in interactive what-if questions. Such questions, called counterfactuals, are becoming important in the rising field of explainable AI (xAI). Our central hypothesis is that using conceptual knowledge as a guiding model of reality will help to train more explainable, more robust and less biased machine learning models, ideally able to learn from fewer data. One important aspect in the medical domain is that various modalities contribute to one single result. Our main question is “How can we construct a multi-modal feature representation space (spanning images, text, genomics data) using knowledge bases as an initial connector for the development of novel explanation interface techniques?”. In this paper we argue for using Graph Neural Networks as a method-of-choice, enabling information fusion for multi-modal causability (causability – not to confuse with causality – is the measurable extent to which an explanation to a human expert achieves a specified level of causal understanding). The aim of this paper is to motivate the international xAI community to further work into the fields of multi-modal embeddings and interactive explainability, to lay the foundations for effective future human–AI interfaces. We emphasize that Graph Neural Networks play a major role for multi-modal causability, since causal links between features can be defined directly using graph structures.},
	language = {en},
	urldate = {2022-11-07},
	journal = {Information Fusion},
	author = {Holzinger, Andreas and Malle, Bernd and Saranti, Anna and Pfeifer, Bastian},
	month = jul,
	year = {2021},
	keywords = {Counterfactuals, Explainable AI, Graph Neural Networks, Information fusion, Knowledge graphs, Multi-modal causability, xAI},
	pages = {28--37},
}

@inproceedings{holzinger_next_2021,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {The {Next} {Frontier}: {AI} {We} {Can} {Really} {Trust}},
	isbn = {978-3-030-93736-2},
	shorttitle = {The {Next} {Frontier}},
	doi = {10.1007/978-3-030-93736-2_33},
	abstract = {Enormous advances in the domain of statistical machine learning, the availability of large amounts of training data, and increasing computing power have made Artificial Intelligence (AI) very successful. For certain tasks, algorithms can even achieve performance beyond the human level. Unfortunately, the most powerful methods suffer from the fact that it is difficult to explain why a certain result was achieved on the one hand, and that they lack robustness on the other. Our most powerful machine learning models are very sensitive to even small changes. Perturbations in the input data can have a dramatic impact on the output and lead to entirely different results. This is of great importance in virtually all critical domains where we suffer from low data quality, i.e. we do not have the expected i.i.d. data. Therefore, the use of AI in domains that impact human life (agriculture, climate, health, ...) has led to an increased demand for trustworthy AI. Explainability is now even mandatory due to regulatory requirements in sensitive domains such as medicine, which requires traceability, transparency and interpretability capabilities. One possible step to make AI more robust is to combine statistical learning with knowledge representations. For certain tasks, it can be advantageous to use a human in the loop. A human expert can - sometimes, of course not always - bring experience, domain knowledge and conceptual understanding to the AI pipeline. Such approaches are not only a solution from a legal point of view, but in many application areas the “why” is often more important than a pure classification result. Consequently, both explainability and robustness can promote reliability and trust and ensure that humans remain in control, thus complementing human intelligence with artificial intelligence.},
	language = {en},
	booktitle = {Machine {Learning} and {Principles} and {Practice} of {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Holzinger, Andreas},
	editor = {Kamp, Michael and Koprinska, Irena and Bibal, Adrien and Bouadi, Tassadit and Frénay, Benoît and Galárraga, Luis and Oramas, José and Adilova, Linara and Krishnamurthy, Yamuna and Kang, Bo and Largeron, Christine and Lijffijt, Jefrey and Viard, Tiphaine and Welke, Pascal and Ruocco, Massimiliano and Aune, Erlend and Gallicchio, Claudio and Schiele, Gregor and Pernkopf, Franz and Blott, Michaela and Fröning, Holger and Schindler, Günther and Guidotti, Riccardo and Monreale, Anna and Rinzivillo, Salvatore and Biecek, Przemyslaw and Ntoutsi, Eirini and Pechenizkiy, Mykola and Rosenhahn, Bodo and Buckley, Christopher and Cialfi, Daniela and Lanillos, Pablo and Ramstead, Maxwell and Verbelen, Tim and Ferreira, Pedro M. and Andresini, Giuseppina and Malerba, Donato and Medeiros, Ibéria and Fournier-Viger, Philippe and Nawaz, M. Saqib and Ventura, Sebastian and Sun, Meng and Zhou, Min and Bitetta, Valerio and Bordino, Ilaria and Ferretti, Andrea and Gullo, Francesco and Ponti, Giovanni and Severini, Lorenzo and Ribeiro, Rita and Gama, João and Gavaldà, Ricard and Cooper, Lee and Ghazaleh, Naghmeh and Richiardi, Jonas and Roqueiro, Damian and Saldana Miranda, Diego and Sechidis, Konstantinos and Graça, Guilherme},
	year = {2021},
	keywords = {Artificial intelligence, Explainable AI, Human-in-the-loop, Robustness, Trust},
	pages = {427--440},
}

@article{stott_common_nodate,
	title = {Common {Cause} {Failure} {Modeling}: {Aerospace} vs. {Nuclear}},
	abstract = {Aggregate nuclear plant failure data is used to produce generic common-cause factors that are specifically for use in the common-cause failure models of NUREG/CR-5485. Furthermore, the models presented in NUREG/CR-5485 are specifically designed to incorporate two significantly distinct assumptions about the methods of surveillance testing from whence this aggregate failure data came. What are the implications of using these NUREG generic factors to model the common-cause failures of aerospace systems? Herein, the implications of using the NUREG generic factors in the modeling of aerospace systems are investigated in detail and strong recommendations for modeling the common-cause failures of aerospace systems are given.},
	language = {en},
	author = {Stott, James E and Britton, Paul T and Ring, Robert W and Hark, Frank and Spencer, G},
	pages = {12},
}

@article{barros_estimation_2009,
	title = {Estimation of common cause failure parameters with periodic tests},
	volume = {239},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549308006286},
	doi = {10.1016/j.nucengdes.2008.12.013},
	abstract = {In the specific case of safety systems, CCF parameters estimators for standby components depend on the periodic test schemes. Classically, the testing schemes are either staggered (alternation of tests on redundant components) or non-staggered (all components are tested at the same time). In reality, periodic tests schemes performed on safety components are more complex and combine staggered tests, when the plant is in operation, to non-staggered tests during maintenance and refueling outage periods of the installation. Moreover, the CCF parameters estimators described in the US literature are derived in a consistent way with US Technical Specifications constraints that do not apply on the French Nuclear Power Plants for staggered tests on standby components. Given these issues, the evaluation of CCF parameters from the operating feedback data available within EDF implies the development of methodologies that integrate the testing schemes specificities. This paper aims to formally propose a solution for the estimation of CCF parameters given two distinct difficulties respectively related to a mixed testing scheme and to the consistency with EDF’s specific practices inducing systematic non-simultaneity of the observed failures in a staggered testing scheme.},
	language = {en},
	number = {4},
	urldate = {2022-11-02},
	journal = {Nuclear Engineering and Design},
	author = {Barros, Anne and Grall, Antoine and Vasseur, Dominique},
	month = apr,
	year = {2009},
	pages = {761--768},
}

@article{kovacic_nrchq2514d0004-nrchq2517t0001_nodate,
	title = {{NRCHQ2514D0004}-{NRCHQ2517T0001} {NON}-{LIGHT} {WATER} {REACTOR} {POLICY} {AND} {TECHNICAL} {GUIDANCE} {SUPPORT}},
	language = {en},
	author = {Kovacic, Donald and Gibbs, Philip and Scott, Logan},
	pages = {89},
}

@article{owen_waste_nodate,
	title = {Waste {Characteristics} of {Spent} {Nuclear} {Fuel} from a {Pebble} {Bed} {Reactor}},
	abstract = {A preliminary comparative assessment is made of the spent fuel characteristics and disposal aspects between a high-temperature, gas cooled, reactor with a pebble bed core (PBR) and a pressurized water reactor (PWR). There are three significant differences which impact the disposal characteristics of PBR spent pebble fuel from PWR spent fuel assemblies. Pebble bed fuel has bum-up as high as 100,000 MWD(t)/MTHM and thus, there is significantly less activity and decay heat in the fuel when it is disposed. The large amount of graphite in the waste form leads to a low power density and more waste per unit volume than a typical PWR. Pebble Fuel contains a protective layer of Silicon Carbide. The theoretical spacing of waste packages of spent pebble fuel given its unique characteristics as applied to the conditions of Yucca Mountain is of major concern when determining the cost of disposing of the larger volumes of spent pebble fuel. Graphite is a unique waste form and atypical of waste designated for Yucca Mountain. The interactions of silicon carbide with uranium oxide fuel and its implications to long term storage at the repository are examined.},
	language = {en},
	author = {Owen, Paul E},
	pages = {137},
}

@article{kadak_comparison_nodate,
	title = {A {COMPARISON} {OF} {ADVANCED} {NUCLEAR} {TECHNOLOGIES}},
	language = {en},
	author = {Kadak, Andrew C},
	pages = {112},
}

@article{zhang_600-mwe_2022,
	title = {600-{MWe} high-temperature gas-cooled reactor nuclear power plant {HTR}-{PM600}},
	volume = {33},
	issn = {1001-8042, 2210-3147},
	url = {https://link.springer.com/10.1007/s41365-022-01089-9},
	doi = {10.1007/s41365-022-01089-9},
	abstract = {Abstract
            
              The HTR-PM600 high-temperature gas-cooled reactor nuclear power plant is based on the technology of the high-temperature gas-cooled reactor pebble-bed module (HTR-PM) demonstration project. It utilizes proven HTR-PM reactor and steam generator modules with a thermal power of 250 MW
              th
              and power generation of approximately 100 MW
              e
              per module. Six modules in parallel, connected to a steam turbine, form a 600-MW
              e
              nuclear power plant. In addition, its system configuration in the nuclear island is identical to that of the HTR-PM in which the technical risks are minimized. Under this principle, the HTR-PM600 achieves the same level of inherent safety as the HTR-PM. The concept of a ventilated low-pressure containment (VLPC) is unchanged; however, a large circular VLPC accommodating all six reactor modules is adopted rather than the previous small-cavity-type VLPC, which contains only one module, as defined for the HTR-PM. The layout of the nuclear island and its associated systems refer to single-unit pressurized water reactor (PWR) practices. With this layout, the HTR-PM600 achieves a volume size of the nuclear island that is comparable to a domestic PWR of the same power level. This will be a Generation IV nuclear energy technology that is economically competitive.},
	language = {en},
	number = {8},
	urldate = {2022-11-01},
	journal = {Nuclear Science and Techniques},
	author = {Zhang, Zuo-Yi and Dong, Yu-Jie and Shi, Qi and Li, Fu and Wang, Hai-Tao},
	month = aug,
	year = {2022},
	pages = {101},
}

@article{tang_analysis_2019,
	title = {Analysis of the pebble burnup profile in a pebble-bed nuclear reactor},
	volume = {345},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318310525},
	doi = {10.1016/j.nucengdes.2019.01.030},
	abstract = {In a pebble bed nuclear reactor, each fuel pebble draining through the core experiences a different amount of burnup depending on the precise trajectory that it follows. Understanding the burnup proﬁle of pebbles is essential for reactor safety, as well as for fuel economy. Here, we introduce a method for constructing the burnup proﬁle based on performing a discrete element simulation of the pebble drainage, followed by a burnup calculation in each individual pebble. This method is more accurate than previous approaches, and in particular it captures the extremal cases of pebble burnup. We demonstrate the method using the geometry, neutron ﬂux data, and thermal characteristics from the HTR-10 reactor being developed at Tsinghua University. We examine pebble burnup during a single drainage cycle, and over multiple drainage cycles characteristic of normal reactor operation. Our results show that the presence of slow-moving boundary layers of pebbles near the reactor wall strongly inﬂuences the burnup proﬁle. We perform a systematic study where the pebble–pebble and pebble–wall friction coefﬁcients are independently varied, and we show that the strength of the boundary layers is a complex interplay of these two parameters.},
	language = {en},
	urldate = {2022-11-01},
	journal = {Nuclear Engineering and Design},
	author = {Tang, Yushi and Zhang, Liguo and Guo, Qiuju and Xia, Bing and Yin, Zaizhe and Cao, Jianzhu and Tong, Jiejuan and Rycroft, Chris H.},
	month = apr,
	year = {2019},
	pages = {233--251},
}

@article{zuoyi_future_2014,
	title = {Future {Development} of {Modular} {HTGR} in {China} after {HTR}-{PM}},
	abstract = {The modular high temperature gas-cooled reactor (MHTGR) is an inherently safe nuclear energy technology for efficient electricity generation and process heat applications. The MHTGR is promising in China as it may replace fossil fuels in broader energy markets. In line with China’s long-term development plan of nuclear power, the Institute of Nuclear and New Energy Technology (INET) of Tsinghua University developed and designed a MHTGR demonstration plant, named high-temperature gas-cooled reactor-pebble bed module (HTR-PM). The HTR-PM came into the construction phase at the end of 2012.},
	language = {en},
	author = {Zuoyi, Zhang and Haitao, Wang and Yujie, Dong and Fu, Li},
	year = {2014},
	pages = {9},
}

@article{kovacic_nuclear_nodate,
	title = {Nuclear {Nonproliferation} {Division}},
	language = {en},
	author = {Kovacic, Don and Gibbs, Philip and Worrall, Louise and Hunneke, Rachel and Harp, Jason},
	pages = {27},
}

@article{wu_design_2022,
	title = {Design, {Experiment}, and {Commissioning} of the {Spent} {Fuel} {Conveying} and {Loading} {System} of {HTR}-{PM}},
	volume = {2022},
	issn = {1687-6083, 1687-6075},
	url = {https://www.hindawi.com/journals/stni/2022/1817191/},
	doi = {10.1155/2022/1817191},
	abstract = {The Chinese high-temperature gas-cooled reactor pebble-bed module, HTR-PM, began fuel loading in August 2021. The reactor refuels continuously, while the spent fuel is discharged from the core. The spent fuel conveying and loading system was designed to convey the spent fuel pebbles to the spent fuel building and load them into dry canisters for on-site interim storage. This study describes the operating principles of the main functions and introduces the experiments and commissioning tests of the system. Functional tests were carried out to indicate the items of mechanical and electrical equipment are functioning in accordance with the designed requirements. Experience learned from commissioning activities was also presented as feedback for future operation and design improvement.},
	language = {en},
	urldate = {2022-11-01},
	journal = {Science and Technology of Nuclear Installations},
	author = {Wu, Bin and Wang, Jinhua and Li, Yue and Wang, Haitao and Ma, Tao},
	editor = {Serikov, Arkady},
	month = apr,
	year = {2022},
	pages = {1--8},
}

@article{demkowicz_coated_2019,
	title = {Coated particle fuel: {Historical} perspectives and current progress},
	volume = {515},
	issn = {00223115},
	shorttitle = {Coated particle fuel},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022311518310213},
	doi = {10.1016/j.jnucmat.2018.09.044},
	abstract = {Coated particle fuel concepts date back some 60 years, and have evolved significantly from the relatively primitive pyrocarbon-coated kernels envisioned by the first pioneers. Improvements in particle design, coating layer properties, and kernel composition have produced the modern tristructural isotropic (TRISO) particle, capable of low statistical coating failure fractions and good fission product retention under extremely severe conditions, including temperatures of 1600°C for hundreds of hours. The fuel constitutes one of the key enabling technologies for high-temperature gas-cooled reactors, allowing coolant outlet temperatures approaching 1000°C and contributing to enhanced reactor safety due to the hardiness of the particles. TRISO fuel development has taken place in a number of countries worldwide, and several fuel qualification programs are currently in progress. In this paper, we discuss the unique history of particle fuel development and some key technology advances, concluding with some of the latest progress in UO2 and UCO TRISO fuel qualification.},
	language = {en},
	urldate = {2022-11-01},
	journal = {Journal of Nuclear Materials},
	author = {Demkowicz, Paul A. and Liu, Bing and Hunn, John D.},
	month = mar,
	year = {2019},
	pages = {434--450},
}

@misc{noauthor_ml20224a493pdf_nodate,
	title = {{ML20224A493}.pdf},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A493.pdf},
	urldate = {2022-10-17},
}

@article{li_machine_2022,
	title = {A machine learning methodology for probabilistic risk assessment of process operations: {A} case of subsea gas pipeline leak accidents},
	volume = {165},
	issn = {0957-5820},
	shorttitle = {A machine learning methodology for probabilistic risk assessment of process operations},
	url = {https://www.sciencedirect.com/science/article/pii/S0957582022003366},
	doi = {10.1016/j.psep.2022.04.029},
	abstract = {Subsea gas pipeline leak may cause the catastrophic consequences, e.g., offshore fire and explosion, and the overturning of floating offshore structures. Efficient risk assessment is critical to prevent the unexpected offshore accident due to subsea gas pipeline leak. The modern technology advancement urges the need for developing new risk assessment approach in the case that a large volume of data becomes available. A new methodology comprising of BRANN implemented with BN is proposed for dynamic risk assessment of process operations, which can capture the nonlinear and the non-sequential features of accident escalation. BN is used to model the accident scenario from causations to consequences considering the conditional dependencies among accident contributory factors. Subsequently, BN model as an informative base is mapped into BRANN model. The data-driven nature makes it better to capture the uncertainty among the cause-consequence relationships. The practicability of the methodology is illustrated by a case study of subsea gas pipeline leak accident. It is observed that BRANN model is superior in the network performance and prediction accuracy. This methodology can help to perform more effectively real-time risk assessment of process operations.},
	language = {en},
	urldate = {2022-10-30},
	journal = {Process Safety and Environmental Protection},
	author = {Li, Xinhong and Wang, Jingwen and Chen, Guoming},
	month = sep,
	year = {2022},
	keywords = {BN, BRANN, Dynamic risk assessment, Process operations, Subsea gas pipeline},
	pages = {959--968},
}

@article{ernst_use_1983,
	title = {Use of {PRA} and safety goals in nuclear power plant regulation},
	volume = {75},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/0029549383900110},
	doi = {10.1016/0029-5493(83)90011-0},
	abstract = {Probabilistic risk assessments (PRAs) have been performed on a number of nuclear power plants, both by the NRC and industry. The NRC has used risk perspectives gained from PRAs, both in an absolute as well as a relative sense, as an aid in making decisions on plant-specific as well as generic safety issues. However, substantial uncertainties pervade present-day risk assessments, which makes the application of the results of such analyses difficult at best in the regulation of nuclear power. Nonetheless, the Commission approved in January 1983 a policy statement on safety goals for public comment and a two year evaluation period. These safety goals include quantitative design objectives which could serve in the future as risk benchmarks for use by the NRC as part of the decision making process on matters relating to nuclear safety. While the Commission's policy statement explicitly excludes the safety goals from use both in licensing cases and in regulation for the two year evaluation period, PRA will be used generically and on a plant-specific basis more and more to assess the importance of new safety issues, prioritize resources within the agency, and test the adequacy of (or in some instances the need for) NRC's regulations.},
	language = {en},
	number = {3},
	urldate = {2022-10-30},
	journal = {Nuclear Engineering and Design},
	author = {Ernst, Malcolm L.},
	month = jun,
	year = {1983},
	pages = {453--462},
}

@article{burlet-vienney_design_2015,
	title = {Design and application of a 5 step risk assessment tool for confined space entries},
	volume = {80},
	issn = {0925-7535},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753515001927},
	doi = {10.1016/j.ssci.2015.07.022},
	abstract = {Many serious accidents related to work in confined spaces still occur. Despite all the regulatory and standard-setting efforts that have been made, organizations seem to have difficulties with risk assessment for interventions in confined spaces. Risk identification and estimation were not carried out in most of fatal accidents. This paper proposes a 5 step risk assessment tool for confined spaces based on risk management standards. The tool was tested by 22 experts in managing entries in confined spaces, including experts during 10 visits in different organizations. Step 1 consists of a questionnaire to describe the configuration of the selected confined space, its environment and the work situations. The answers generate predefined types of risk such as mechanical, atmospheric, falling, chemical, and biological. Step 2 describes the components of risks (i.e., hazards, hazardous activity, hazardous event, harm). Step 3 estimates risk using adapted risk parameters and matrix. Step 4 categorizes the intervention by class and level of risk. Step 5 is a feedback loop for estimating residual risks after risk reduction measures have been taken. This tool enables to (i) carry out comprehensive risk identification by analyzing all the risk factors during an intervention in a confined space, (ii) categorize interventions and rescue conditions by using specific criteria, (iii) determine if two situations are indeed identical in terms of risks, (iv) decide if intervention planned meets the permit required confined spaces definition, (v) evaluate if external rescue is feasible, and (iv) decide if the residual risks are acceptable.},
	language = {en},
	urldate = {2022-10-30},
	journal = {Safety Science},
	author = {Burlet-Vienney, Damien and Chinniah, Yuvin and Bahloul, Ali and Roberge, Brigitte},
	month = dec,
	year = {2015},
	keywords = {Confined space, Risk assessment, Risk estimation, Risk reduction},
	pages = {144--155},
}

@article{baybulatov_cybersecurity_2022,
	series = {11th {IFAC} {Symposium} on {Control} of {Power} and {Energy} {Systems} {CPES} 2022},
	title = {On {Cybersecurity} {Risk} {Assessment} in {Nuclear} {Power} {Systems}},
	volume = {55},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896322004268},
	doi = {10.1016/j.ifacol.2022.07.041},
	abstract = {Witnessing a present-day radical shift from carbonized power towards renewables and smart energy systems, one should recognize nuclear power to be an equal partner, not opponent, to the sustainable types of energy. However, in contrast to systems based on renewable resources, nuclear energy production is highly risky, and NPP industrial control systems (ICS) impose the growing demands on safety and security. In order to meet pressing security challenges and perform an effective risk management, one of the fundamental steps to be taken is to conduct a comprehensive risk assessment, which in the context of today's transition from conventional control to digital, aka digitalization, should more accurately refer to cybersecurity. To carry out a cybersecurity risk assessment, a standard assets-based CIA risk assessment approach operating with confidentiality, integrity, and availability attributes is commonly utilized. Nevertheless, for NPP ICS, the approach happens to be slightly different because, firstly, industrial control is normally established with the primary aim of performing functions, e.g., control and monitoring ones, but not dealing with and managing assets, and, secondly, the availability property of control takes the major priority over other CIA attributes. The article investigates the cybersecurity risk assessment in the NPP ICS perspective. Clarifying the priority of control systems performance, it presents an approach adapted to NPP ICS and a modified equation for the first iteration of the potential cybersecurity risk calculation where the assets are replaced by functions. For the assignment of values for the availability property of NPP ICS functions, a metric based on delay is recommended. The ICS availability reference model, in particular, the system domain and so the dependency between system components is utilized for the accurate metric calculation.},
	language = {en},
	number = {9},
	urldate = {2022-10-30},
	journal = {IFAC-PapersOnLine},
	author = {Baybulatov, A. A. and Promyslov, V. G.},
	month = jan,
	year = {2022},
	keywords = {ICS, NPP, availability, cybersecurity, function, metric, risk assessment},
	pages = {233--237},
}

@article{zubair_calculation_2016,
	title = {Calculation and updating of {Common} {Cause} {Failure} unavailability by using alpha factor model},
	volume = {90},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454915300050},
	doi = {10.1016/j.anucene.2015.12.004},
	abstract = {The most lethal role of Common Cause Failures (CCFs), which motivate the experts to investigate it, is the dependent behavior therein contained, which leads to simultaneous failure of the systems. Highly redundant systems are more susceptible to be affected by CCFs and also CCFs have been recognized as the principal contributor in the terrestrial reactor accidents. In the past, plenty of work has been done regarding the calculation of unavailability of different types of systems due to CCFs by using different techniques such as fault tree analysis (FTA). But the qualitative aspects such as human errors, maintenance faults and poor components quality cannot be updated by using FTA as the changes occur. So in order to overcome this problem, multinomial distribution function and its conjugate Dirichlet distribution function has been used as likelihood and prior, respectively, in Bayes theorem to obtain an updated posterior function of the same form as Dirichlet distribution function thus improving the working and monitoring capability of Probabilistic Safety Assessment (PSA). Furthermore, the presented research highlights a mathematical model to estimate system unavailability due to CCF by using alpha factor model. By using this model, we can calculate failure probability (unavailability) of the systems quite accurately through the two parameters αk and Qt. The ease of using the proposed model can be assessed through the brief analysis of a case study of Auxiliary Feed Water System (AFWS). AFWS is used in all designs of Pressurized Water Reactor (PWR). It plays a vital role in maintaining a heat sink by providing feedwater to the steam generators.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Annals of Nuclear Energy},
	author = {Zubair, Muhammad and Amjad, Qazi Muhammad Nouman},
	month = apr,
	year = {2016},
	keywords = {Auxiliary Feed Water System, Common Cause Failures, Failure probability, Reliability},
	pages = {106--114},
}

@article{muhammad_common_2013,
	title = {Common cause failure analysis of {PWR} containment spray system by {GO}-{FLOW} methodology},
	volume = {262},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549313002513},
	doi = {10.1016/j.nucengdes.2013.04.028},
	abstract = {Common cause failure (CCF) is the simultaneous failure of multiple components due to some particular cause of failure and has long been recognized as an important issue in the probabilistic safety assessment (PSA). Sometimes CCFs have an important contribution to system unreliability. In this study, Common Cause Failure has been considered in the reliability analysis and procedure of CCF analysis is treated by GO-FLOW methodology. As the sample system, PWR containment spray system has been taken. It is shown that dynamic reliability of the containment spray system has been significantly decreased by common cause failures.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Nuclear Engineering and Design},
	author = {Muhammad, Hashim and Hidekazu, Yoshikawa and Takeshi, Matsuoka and Ming, Yang},
	month = sep,
	year = {2013},
	pages = {350--357},
}

@article{xie_knowledge-based_1998,
	title = {A knowledge-based multi-dimension discrete common cause failure model},
	volume = {183},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S002954939800171X},
	doi = {10.1016/S0029-5493(98)00171-X},
	abstract = {Common cause failure (CCF) is analyzed as a manifestation of the probabilistic characteristics of component failure rate/probability stemming from stochastic environment load. CCF revolved concepts, such as ‘root cause’ and ‘coupling mechanism’ are interpreted mathematically from the viewpoint of random environment load bringing about failure dependency. Opinions about ‘inherent CCF’ and ‘additional CCF’, ‘absolute CCF’ and ‘relative CCF’ are presented and discussed. An easy-to-use CCF model is developed through multi-dimension environment load-component strength interference analysis and knowledge based parameter discretization. Owing to its strict statistical foundation, such a model has the ability of estimating component failure rate/probability and common cause failure rates/probabilities consistently, dealing with low redundancy system CCF and high redundancy system CCF uniformly, and predicting high multiplicity failure rate/probability based on low multiplicity failure data satisfactorily.},
	language = {en},
	number = {1},
	urldate = {2022-10-29},
	journal = {Nuclear Engineering and Design},
	author = {Xie, Liyang},
	month = jul,
	year = {1998},
	pages = {107--116},
}

@article{fan_modified_2016,
	title = {A modified {GO}-{FLOW} methodology with common cause failure based on {Discrete} {Time} {Bayesian} {Network}},
	volume = {305},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549316301583},
	doi = {10.1016/j.nucengdes.2016.06.010},
	abstract = {The GO-FLOW methodology is a success-oriented system reliability modelling technique for multi-phase missions involving complex time-dependent, multi-state and common cause failure (CCF) features. However, the analysis algorithm cannot easily handle the multiple shared signals and CCFs. In addition, the simulative algorithm is time consuming when vast multi-state components exist in the model, and the multiple time points of phased mission problems increases the difficulty of the analysis method. In this paper, the Discrete Time Bayesian Network (DTBN) and the GO-FLOW methodology are integrated by the unified mapping rules. Based on these rules, the multi operators can be mapped into DTBN followed by, a complete GO-FLOW model with complex characteristics (e.g. phased mission, multi-state, and CCF) can be converted to the isomorphic DTBN and easily analyzed by utilizing the DTBN. With mature algorithms and tools, the multi-phase mission reliability parameter can be efficiently obtained via the proposed approach without considering the shared signals and the various complex logic operation. Meanwhile, CCF can also arise in the computing process.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Nuclear Engineering and Design},
	author = {Fan, Dongming and Wang, Zili and Liu, Linlin and Ren, Yi},
	month = aug,
	year = {2016},
	pages = {476--488},
}

@article{hassija_pragmatic_2014,
	title = {A pragmatic approach to estimate alpha factors for common cause failure analysis},
	volume = {63},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S030645491300409X},
	doi = {10.1016/j.anucene.2013.07.053},
	abstract = {Most of the modern technological systems are deployed with high redundancy but still they fail mainly on account of common cause failures (CCF). Various models such as Beta Factor, Multiple Greek Letter, Binomial Failure Rate and Alpha Factor exists for estimation of risk from common cause failures. Amongst all, alpha factor model is considered most suitable for high redundant systems as it arrives at common cause failure probabilities from a set of ratios of failures and the total component failure probability QT. In the present study, alpha factor model is applied for the assessment of CCF of safety systems deployed at two nuclear power plants. A method to overcome the difficulties in estimation of the coefficients viz., alpha factors in the model, importance of deriving plant specific alpha factors and sensitivity of common cause contribution to the total system failure probability with respect to hazard imposed by various CCF events is highlighted. An approach described in NUREG/CR-5500 is extended in this study to provide more explicit guidance for a statistical approach to derive plant specific coefficients for CCF analysis especially for high redundant systems. The procedure is expected to aid regulators for independent safety assessment.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Annals of Nuclear Energy},
	author = {Hassija, Varun and Senthil Kumar, C. and Velusamy, K.},
	month = jan,
	year = {2014},
	keywords = {Alpha factor, Common cause failures, Highly redundant systems, Mapping up},
	pages = {317--325},
}

@misc{noauthor_pragmatic_nodate,
	title = {A pragmatic approach to estimate alpha factors for common cause failure analysis - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S030645491300409X?casa_token=cmINHFZ4m1AAAAAA:5uGDwRA_NtmyJWrOneJnDQMt9iZ7IUaKykUAeTA4Sg0PD9n9AkfqrjqW2R7yw9FrBrUl0ZQBTRw},
	urldate = {2022-10-29},
}

@article{kreuser_recent_2017,
	series = {Special {Issue} on the 13th {International} {Conference} on {Probabilistic} {Safety} {Assessment} and {Management} ({PSAM} 13)},
	title = {Recent {Insights} from the {International} {Common}-{Cause} {Failure} {Data} {Exchange} {Project}},
	volume = {49},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573316303461},
	doi = {10.1016/j.net.2017.01.012},
	abstract = {Common-cause failure (CCF) events can significantly impact the availability of safety systems of nuclear power plants. For this reason, the International Common Cause Data Exchange (ICDE) project was initiated by several countries in 1994. Since 1997 it has been operated within the Organisation for Economic Co-operation and Development (OECD)/Nuclear Energy Agency (NEA) framework and has successfully been operated over six consecutive terms (the current term being 2015–2017). The ICDE project allows multiple countries to collaborate and exchange CCF data to enhance the quality of risk analyses, which include CCF modeling. As CCF events are typically rare, most countries do not experience enough CCF events to perform meaningful analyses. Data combined from several countries, however, have yielded sufficient data for more rigorous analyses. The ICDE project has meanwhile published 11 reports on the collection and analysis of CCF events of specific component types (centrifugal pumps, emergency diesel generators, motor operated valves, safety and relief valves, check valves, circuit breakers, level measurement, control rod drive assemblies, and heat exchangers) and two topical reports. This paper presents recent activities and lessons learnt from the data collection and the results of topical analysis on emergency diesel generator CCF impacting entire exposed population.},
	language = {en},
	number = {2},
	urldate = {2022-10-29},
	journal = {Nuclear Engineering and Technology},
	author = {Kreuser, Albert and Johanson, Gunnar},
	month = mar,
	year = {2017},
	keywords = {CCF, Experience feedback, ICDE, OECD/NEA, PSA},
	pages = {327--334},
}

@article{matsuoka_go-flow_1997,
	title = {The {GO}-{FLOW} reliability analysis methodology—analysis of common cause failures with uncertainty},
	volume = {175},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549397000381},
	doi = {10.1016/S0029-5493(97)00038-1},
	abstract = {Common cause failures (CCFs) have long been recognized as an important issue in the probabilistic safety assessment (PSA) for nuclear power plants. Uncertainty ranges of system failure probabilities are important information for the evaluation of system reliability. The function of CCF analysis together with uncertainty analysis has been provided to the GO-FLOW methodology. Overview of the GO-FLOW methodology, the method to treat the CCFs in the GO-FLOW, the procedure of CCF analysis together with uncertainty are described. As the sample system, PWR auxiliary feedwater system has been taken and an analysis has been performed by the proposed analysis framework.},
	language = {en},
	number = {3},
	urldate = {2022-10-29},
	journal = {Nuclear Engineering and Design},
	author = {Matsuoka, Takeshi and Kobayashi, Michiyuki},
	month = nov,
	year = {1997},
	pages = {205--214},
}

@article{kang_estimation_2011,
	title = {Estimation of common cause failure parameters for essential service water system pump using the {CAFE}-{PSA}},
	volume = {53},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197010001496},
	doi = {10.1016/j.pnucene.2010.09.009},
	abstract = {This paper presents the estimation results of the common cause failure (CCF) parameters of essential service water system (ESWS) pump failure to run for KX nuclear power plant (NPP) in Korea. Until now, the generic values of the CCF parameters have been mainly used in most probabilistic safety assessment (PSA) projects for the Korean NPPs. The PSA results for KX NPP showed that the CCF events of ESWS pump failure to run was identified as one of dominant contributors to its internal event core damage frequency (CDF). Thus, we performed the plant specific detailed CCF analysis to estimate CCF parameters of ESWS pump failure to run for KX NPP with the CAFE-PSA, a program to analyze CCF events in the ICDE database. Reasonable values of CCF parameters were obtained through performing plant specific detailed CCF analysis. The estimated Alpha Factor with three out of three failure criterion was about one half of that for recent US NRC CCF parameters. The re-quantification results on the CDF of KX NPP with the new estimated Alpha Factor showed that originally estimated CDF with generic Alpha Factor decreased by 16.84\% and the contribution of the sum of cutsets for the CCF events of ESWS pump failure to run to internal event CDF decreased from 20\% to 3.29\%.},
	language = {en},
	number = {1},
	urldate = {2022-10-29},
	journal = {Progress in Nuclear Energy},
	author = {Kang, Dae Il and Hwang, Mee Jeong and Han, Sang Hoon},
	month = jan,
	year = {2011},
	keywords = {Alpha factor method, Common cause failure, Essential service water system, PSA},
	pages = {24--31},
}

@inproceedings{mattenberger_risk_2010,
	title = {Risk {Informed} {Design} modeling process \& design team - {Analyst} interaction},
	doi = {10.1109/RAMS.2010.5447997},
	abstract = {As demand for highly reliable complex systems increases, engineers are being forced to consider the risk implications of design decisions earlier in the conceptual phase of projects and with greater accuracy. Standard probabilistic risk assessments (PRA) usually employed to verify that a product meets requirements are too resource intensive and too slow to keep up with the speed at which the design is maturing; while classical qualitative methods do not provide the level of detail and granularity required by the designers to make high-quality risk informed decisions. The Altair design team was able to overcome these challenges by employing a process of Risk Informed Design utilizing the Valador Reliability Tool (VRT). This tool is able to quickly and accurately produce estimates of the risk of Loss of Mission (LOM) and Loss of Crew (LOC) per mission and provide insight to the designers as to how their decisions will impact overall mission success. The VRT employs a method or risk assessment that is unlike traditional PRA as it effectively engages the designers in the model building process and as a result of this increased Designer Analyst interaction both the quality of the design and the quality of the PRA model is increased. This method of PRA seeks to create a baseline model by first capturing a complete set of initiating failure events which can lead to LOM/LOC based upon the Master Equipment List (MEL), dynamic mission events and identified hazards. Next, the event trees of these failures are generated automatically by correctly identifying the response of the system to an initiating failure and the risk exposure times of each failure mode through the use of schematics, designer interviews, and a priori knowledge. Once a baseline configuration has been captured in the reliability model, the tool facilitates the isolation of specific subsets of risk for directed trade studies. Now, the flexibility and speed of the tool can be leveraged to rapidly produce a large number of design options guided by the initial LOM/LOC scoring of the subset of components. The VRT gives the analyst the capability to model, score and analyze options in real-time with the designer. This provides immediate feedback and allows for a rapid iterative process which gives the team more freedom to effectively search the risk design space and find the "differences that make a difference." Ultimately, a scatter plot of LOM/LOC vs. Delta-Mass can be used to compare the relative implications of each option to one another by highlighting the cost and benefit of each option and the overall trend of the curve. Furthermore, the design team is able to compare options across trade study boundary lines, enabling a global risk perspective. The insight into the risk reduction efficiency of each option aides the design team in determining the best ways to spend mass to increase reliability across the vehicle given a constrained mass budget. Moreover, the VRT serves as an excellent method for vehicle integration to capture cross system dependencies, to find errors in the MEL and schematics, and to identify synergistic relationships that may not be immediately apparent due to the 'stove piping' of the design into specific subsystems.},
	booktitle = {2010 {Proceedings} - {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	author = {Mattenberger, Chris},
	month = jan,
	year = {2010},
	note = {ISSN: 0149-144X},
	keywords = {Altair lunar lander, Buildings, Design engineering, Hazards, Lab-on-a-chip, Process design, Reliability engineering, Risk analysis, Risk management, Systems engineering and theory, Vehicle dynamics, probabilistic risk assessment, risk informed design, risk management},
	pages = {1--4},
}

@inproceedings{hsu_quantitative_2015,
	title = {Quantitative mission risk assessment for space: {Providing} an objective picture for decision-makers},
	shorttitle = {Quantitative mission risk assessment for space},
	doi = {10.1109/RAMS.2015.7105143},
	abstract = {Making decisions regarding risk is an inherently subjective activity, but it should be based on objective analysis. However, the qualitative risk assessment approaches that are widely used in the aerospace industry can easily lead to subjective judgments creeping into the analysis. This paper describes a quantitative risk assessment approach that allows decision-makers to consider and compare objective assessments of mission risks. Through the diagramming of risk scenarios, probabilistic risk assessment, and objective communication of the risk analysis, senior management can then make better-informed decisions. A “sanitized” case study of such a risk assessment for a satellite illustrates the approach.},
	booktitle = {2015 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	author = {Hsu, Andrew and Guarro, Sergio},
	month = jan,
	year = {2015},
	note = {ISSN: 0149-144X},
	keywords = {Aerospace industry, Probability distribution, Reliability engineering, Risk management, Satellites, Uncertainty, decision support, mission risk, quantitative, risk assessment, risk management},
	pages = {1--5},
}

@article{zhang_common_2017,
	title = {Common cause failure model updating for risk monitoring in nuclear power plants based on alpha factor model},
	volume = {231},
	issn = {1748-006X},
	url = {https://doi.org/10.1177/1748006X16689542},
	doi = {10.1177/1748006X16689542},
	abstract = {Common cause failure model updating (both qualitatively and quantitatively) is a key factor in risk monitoring for nuclear power plants when configuration changes (e.g. components become unavailable) occur among a redundant configuration. This research focuses on the common cause failure updating based on the alpha factor model method, which is commonly used in the living probabilistic safety assessment models for nuclear power plant risk monitoring. This article first discusses the common cause failure model updating in an ideal condition, which evaluates the common cause failure model parameters for the configurationally changed system in different ways, based on the causes of the detected failures. Then, two alternative updating processes are proposed considering the difficulty to identify failure causes immediately during plant operation: one is to update the common cause failure models with the assumption that the failures detected are independent failures and the other is to update the common cause failure models with the parameters as expectations of the values for all possible failure causes. Finally, a case study is given to illustrate the common cause failure updating process and to compare these two alternative processes. The results show that (1) common cause failures can be reevaluated automatically by the methods proposed in this article and (2) the second process is more conservative and reasonable but with more data requirements compared with the first approach. Considering limitations in accessibility of the data, the first strategy is suggested currently. More future work on data acquisition is demanded for better assessment of common cause failures during nuclear power plant risk monitoring.},
	language = {en},
	number = {3},
	urldate = {2022-10-29},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Zhang, Min and Zhang, Zhijian and Mosleh, Ali and Chen, Sijuan},
	month = jun,
	year = {2017},
	note = {Publisher: SAGE Publications},
	pages = {209--220},
}

@inproceedings{groth_hybrid_2008,
	title = {Hybrid methodology and software platform for probabilistic risk assessment},
	doi = {10.1109/RAMS.2008.4925831},
	abstract = {This paper introduces the software implementation of a hybrid methodology for probabilistic risk assessment (PRA) of complex systems. The software, called IRIS (Integrated Risk Information System) combines a user-friendly graphical interface with a powerful computational engine. The framework includes a multi-layered modeling approach, combining Event Sequence Diagrams, Fault Trees, and Bayesian Belief Networks in a Hybrid Causal Logic (HCL) model. This allows the most appropriate modeling techniques to be applied in the different domains of the system. At its core IRIS brings related perspectives of system safety, hazard analysis, and risk analysis into a unifying framework.},
	booktitle = {2008 {Annual} {Reliability} and {Maintainability} {Symposium}},
	author = {Groth, Katrina and Zhu, Dongfeng and Mosleh, Ali},
	month = jan,
	year = {2008},
	note = {ISSN: 0149-144X},
	keywords = {Bayesian methods, Computer interfaces, Engines, Fault trees, Information systems, Iris, PRA software, Power system modeling, Risk analysis, Risk management, Software systems, hazard identification, hybrid logic models, modeling, risk analysis},
	pages = {411--416},
}

@article{hagen_common-modecommon-cause_1980,
	title = {Common-mode/common-cause failure: {A} review},
	volume = {7},
	issn = {0306-4549},
	shorttitle = {Common-mode/common-cause failure},
	url = {https://www.sciencedirect.com/science/article/pii/0306454980900973},
	doi = {10.1016/0306-4549(80)90097-3},
	abstract = {Common-mode/common-cause (CM/CC) failure and its prevention has been a serious concern in the nuclear safety community during the past few years. Since redundancy was first used in an attempt to achieve high reliability in systems, the CM/CC failure phenomenon has been inherent in system designs. The concern is that high-reliability systems are subject to compromise by human error and environmental factors. Potential CM/CC failures are the result of adding complexity to system designs. They are the product of a supersafe philosophy. This article reviews the CM/CC failure phenomenon. Classes of CM/CC failures are compiled, and the defenses against such failures and their weaknesses are surveyed. Some regulatory considerations, operating experiences, and reliability analysis methodology are touched upon.},
	language = {en},
	number = {9},
	urldate = {2022-10-29},
	journal = {Annals of Nuclear Energy},
	author = {Hagen, E. W.},
	month = jan,
	year = {1980},
	pages = {509--517},
}

@article{mi_reliability_2018,
	title = {Reliability analysis of complex multi-state system with common cause failure based on evidential networks},
	volume = {174},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832016309553},
	doi = {10.1016/j.ress.2018.02.021},
	abstract = {With the increasing complexity and size of modern advanced engineering systems, the traditional reliability theory cannot characterize and quantify the complex characteristics of complex systems, such as multi-state properties, epistemic uncertainties, common cause failures (CCFs). This paper focuses on the reliability analysis of complex multi-state system (MSS) with epistemic uncertainty and CCFs. Based on the Bayesian network (BN) method for reliability analysis of MSS, the Dempster-Shafer (DS) evidence theory is used to express the epistemic uncertainty in system through the state space reconstruction of MSS, and an uncertain state used to express the epistemic uncertainty is introduced in the new state space. The integration of evidence theory with BN which called evidential network (EN) is achieved by adapting and updating the conditional probability tables (CPTs) into conditional mass tables (CMTs). When multiple CCF groups (CCFGs) are considered in complex redundant system, a modified β factor parametric model is introduced to model the CCF in system. An EN method is proposed for the reliability analysis and evaluation of complex MSSs in this paper. The reliability analysis of servo feeding control system for CNC heavy-duty horizontal lathes (HDHLs) by this proposed method has shown that CCFs have considerable impact on system reliability. The presented method has high computational efficiency, and the computational accuracy is also verified.},
	language = {en},
	urldate = {2022-10-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Mi, Jinhua and Li, Yan-Feng and Peng, Weiwen and Huang, Hong-Zhong},
	month = jun,
	year = {2018},
	keywords = {Bayesian network, Common cause failure group, Complex multi-state system, Evidence theory},
	pages = {71--81},
}

@article{tao_integrated_2022,
	title = {An integrated probabilistic risk assessment methodology for maritime transportation of spent nuclear fuel based on event tree and hydrodynamic model},
	volume = {227},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022003507},
	doi = {10.1016/j.ress.2022.108726},
	abstract = {Spent nuclear fuel maritime transportation (SNFMT) accident may cause radiation hazards to personnel, vessels, and the ocean environment. Current risk assessment methods of SNFMT lack full consideration and quantifi­ cation of the risk indicators. In this work, an integrated probabilistic risk assessment (IPRA) methodology incorporating multiple risk factors-based accident probability model and public dose-based radiological conse­ quence model quantitatively is proposed for SNFMT. First, from the sociotechnical-environmental risk perspective, the SMCETC (Ship, Management, Crew, Environment, Tank, Channel) comprehensive risk indicators are identified for ET-FT modeling. Second, considering the effects of continuous emissions, water depth, tidal cycle, and radioactive decay, a shallow water equations-based hydrodynamic model is established to simulate the radionuclide concentration in coastal water. Third, the ET-FT model-based accident frequency and the radio­ nuclide concentration-based population radiation consequence are integrated, and subsequently the public radioactive risks are obtained. Finally, a case study is presented to demonstrate the feasibility and value of the proposed method. The time-related public radioactive risks were quantified and 28 highly safety importance risk factors were found and ranked. The proposed IPRA methodology integrates deterministic and probabilistic modeling perspectives, and provides a comprehensive risk assessment tool for SNFMT.},
	language = {en},
	urldate = {2022-10-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Tao, Longlong and Chen, Liwei and Ge, Daochuan and Yao, Yuantao and Ruan, Fang and Wu, Jie and Yu, Jie},
	month = nov,
	year = {2022},
	pages = {108726},
}

@article{bonvicini_risk_1998,
	title = {Risk analysis of hazardous materials transportation: evaluating uncertainty by means of fuzzy logic},
	volume = {62},
	issn = {03043894},
	shorttitle = {Risk analysis of hazardous materials transportation},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304389498001587},
	doi = {10.1016/S0304-3894(98)00158-7},
	abstract = {This paper provides an application of fuzzy logic to the risk assessment of the transport of hazardous materials by road and pipeline in order to evaluate the uncertainties affecting both individual and societal risk estimates. In evaluating uncertainty by fuzzy logic, the uncertain input parameters are described by fuzzy numbers and calculations are performed using fuzzy arithmetic; the outputs will also be fuzzy numbers. This work is an attempt to justify some of the questions the use of fuzzy logic in the field of risk analysis stimulates. This study provides, first of all, a condensed description of the fundamentals of the mathematical procedures which perform the risk measures calculations. Then, some basic concepts about fuzzy logic and fuzzy arithmetic are introduced, after which an explanation on how the uncertain input data can be represented by fuzzy numbers is made. Finally, test results of combined uncertainty and sensitivity analysis in the risk evaluation of a toxic gas release are presented and extensively discussed, in order to show which effect each uncertain input has on the output uncertainty. q 1998 Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {1},
	urldate = {2022-10-28},
	journal = {Journal of Hazardous Materials},
	author = {Bonvicini, S. and Leonelli, P. and Spadoni, G.},
	month = sep,
	year = {1998},
	pages = {59--74},
}

@article{tao_risk-informed_2022,
	title = {Risk-informed based comprehensive path-planning method for radioactive materials road transportation},
	volume = {219},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832021007067},
	doi = {10.1016/j.ress.2021.108228},
	abstract = {The optimization of transportation routes of radioactive materials (RADMAT) is recognized as one of the most important measures to reduce the radioactive risks and costs during transportation. However, the route opti­ mization indicators have not been fully considered and quantified in current researches. Here, we propose a RiskInformed based Comprehensive Path-Planning method (RICPP) for RADMAT Road Transportation (RMRT) route optimization by considering radiological risk cost, time cost, and economical cost. Among which, the ET/FT based Probabilistic Safety Assessment (PSA) model is established to quantitatively assess the accident occurrence probability, and then the PEHR (personnel, environment, hazard target, and rescue force) comprehensive severity indexes considering vulnerability and resilience are established and quantified to characterize the ac­ cident radiological consequence. Finally, the gray relation analysis (GRA) model is employed to select an optimal path considering the multi-objective route planning indicators. The case study results show that the obtained path could reasonably reduce risks and costs during the transportation process, which demonstrates the effec­ tiveness of the proposed method. The proposed RICPP methodology is beneficial for selecting a safer and more economical route for radioactive materials road transportation.},
	language = {en},
	urldate = {2022-10-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Tao, Longlong and Wu, Jie and Ge, Daochuan and Chen, Liwei and Sun, Ming},
	month = mar,
	year = {2022},
	pages = {108228},
}

@article{catalyurek_development_2010,
	title = {Development of a code-agnostic computational infrastructure for the dynamic generation of accident progression event trees},
	volume = {95},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095183200900252X},
	doi = {10.1016/j.ress.2009.10.008},
	language = {en},
	number = {3},
	urldate = {2022-10-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Catalyurek, Umit and Rutt, Benjamin and Metzroth, Kyle and Hakobyan, Aram and Aldemir, Tunc and Denning, Richard and Dunagan, Sean and Kunsman, David},
	month = mar,
	year = {2010},
	pages = {278--294},
}

@techreport{jankovsky_how_2018,
	title = {How to {ADAPT}},
	url = {http://www.osti.gov/servlets/purl/1457610/},
	language = {en},
	number = {SAND2018--6660, 1457610},
	urldate = {2022-10-26},
	author = {Jankovsky, Zachary Kyle and Haskin, Troy Christopher and Denman, Matthew R.},
	month = jun,
	year = {2018},
	doi = {10.2172/1457610},
	pages = {SAND2018--6660, 1457610},
}

@misc{arturo_urquizo_pid_2011,
	title = {{PID} controller overview},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://upload.wikimedia.org/wikipedia/commons/4/43/PID_en.svg},
	abstract = {PID en.svg: PID controller overview},
	language = {English},
	author = {{Arturo Urquizo}},
	month = dec,
	year = {2011},
}

@article{bobbio_comparison_2001,
	title = {Comparison of methodologies for the safety and dependability assessment of an industrial programmable logic controller},
	url = {https://www.researchgate.net/publication/228459927_Comparison_of_methodologies_for_the_safety_and_dependability_assessment_of_an_industrial_programmable_logic_controller},
	author = {Bobbio, Andrea and Bologna, Sandro and Ciancamerla, Ester and Franceschinis, Giuliana and Gaeta, Rossano and Minichino, Michele and Portinale, Luigi},
	month = jan,
	year = {2001},
}

@article{paula_failure_1993,
	title = {Failure rates for programmable logic controllers},
	volume = {39},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209390007L},
	doi = {10.1016/0951-8320(93)90007-L},
	language = {en},
	number = {3},
	urldate = {2022-10-24},
	journal = {Reliability Engineering \& System Safety},
	author = {Paula, Henrique Martini},
	month = jan,
	year = {1993},
	pages = {325--328},
}

@article{moradi_modernizing_2020,
	title = {Modernizing risk assessment: {A} systematic integration of {PRA} and {PHM} techniques},
	volume = {204},
	issn = {0951-8320},
	shorttitle = {Modernizing risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020306955},
	doi = {10.1016/j.ress.2020.107194},
	abstract = {Recent advances in sensing and computing technologies have resulted in an abundance of data in various formats and more processing power for using this data. Consequently, there has been an interest in using these advances to enhance modeling and assessment techniques for safety and reliability of a variety of systems. To date, this has occurred under two distinct aspects of reliability engineering. Prognostics and Health Management (PHM) has developed powerful new algorithms for understanding and predicting the mechanical and electrical devices’ health. For complex systems, the techniques of Probabilistic Risk Assessment (PRA), which provide a system-level perspective, have become increasingly dynamic. Both PHM and PRA bring unique advantages and limitations. PHM excels at data handling and supports prediction, but the methods applicable at the component level are not suitable for modeling complex engineering systems (CES). PRA provides a comprehensive approach suitable for drawing together many types of data and assessing complex systems, but is limited in the ability to exploit advanced ML methods or enable prediction. In this paper, we explore how to systematically draw together the advances in PHM and PRA to provide a more forward-looking, model- and data-driven approach for assessing and predicting the risk and health of CES.},
	language = {en},
	urldate = {2022-10-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Moradi, Ramin and Groth, Katrina M.},
	month = dec,
	year = {2020},
	keywords = {Complex systems, Deep learning, Logic modeling, Probabilistic risk assessment, Prognostics and health management (PHM)},
	pages = {107194},
}

@article{mohaghegh_incorporating_2009,
	title = {Incorporating organizational factors into {Probabilistic} {Risk} {Assessment} ({PRA}) of complex socio-technical systems: {A} hybrid technique formalization},
	volume = {94},
	issn = {0951-8320},
	shorttitle = {Incorporating organizational factors into {Probabilistic} {Risk} {Assessment} ({PRA}) of complex socio-technical systems},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200800269X},
	doi = {10.1016/j.ress.2008.11.006},
	abstract = {This paper is a result of a research with the primary purpose of extending Probabilistic Risk Assessment (PRA) modeling frameworks to include the effects of organizational factors as the deeper, more fundamental causes of accidents and incidents. There have been significant improvements in the sophistication of quantitative methods of safety and risk assessment, but the progress on techniques most suitable for organizational safety risk frameworks has been limited. The focus of this paper is on the choice of “representational schemes” and “techniques.” A methodology for selecting appropriate candidate techniques and their integration in the form of a “hybrid” approach is proposed. Then an example is given through an integration of System Dynamics (SD), Bayesian Belief Network (BBN), Event Sequence Diagram (ESD), and Fault Tree (FT) in order to demonstrate the feasibility and value of hybrid techniques. The proposed hybrid approach integrates deterministic and probabilistic modeling perspectives, and provides a flexible risk management tool for complex socio-technical systems. An application of the hybrid technique is provided in the aviation safety domain, focusing on airline maintenance systems. The example demonstrates how the hybrid method can be used to analyze the dynamic effects of organizational factors on system risk.},
	language = {en},
	number = {5},
	urldate = {2022-10-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Mohaghegh, Zahra and Kazemi, Reza and Mosleh, Ali},
	month = may,
	year = {2009},
	keywords = {Bayesian Belief Network (BBN), Human Reliability Analysis (HRA), Organizational factors, Probabilistic Risk Assessment (PRA), Safety culture, Safety management, Socio-technical complex systems, System dynamics},
	pages = {1000--1018},
}

@article{rauzy_disturbing_2008,
	title = {Some disturbing facts about depth-first left-most variable ordering heuristics for binary decision diagrams},
	volume = {222},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR174},
	doi = {10.1243/1748006XJRR174},
	abstract = {Binary decision diagrams (BDDs) have proven to be a very efficient tool to assess fault trees. However, the size of the BDD, and therefore the efficiency of the whole methodology, is highly dependent on the choice of variable ordering. The determination of the best variable ordering is intractable. Therefore, heuristics have been designed to select reasonably good variable orderings. The most popular of these heuristics consists in numbering variables by means of a depth-first left-most (DFLM) traversal of the formula, after possibly some rearrangements of the inputs of the gates. In this article, this heuristic is studied in a systematic way. It is shown to be very sensitive to the way the formula is written. A series of experiments shows also that the notion of locality of variables, which was believed to be a key issue in the determination of good orderings, must be handled with care. These facts are quite disturbing and raise questions about the design of good variable ordering heuristics.},
	language = {en},
	number = {4},
	urldate = {2022-10-13},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Rauzy, A B},
	month = dec,
	year = {2008},
	pages = {573--582},
}

@misc{noauthor_tms320c6678_2014,
	title = {{TMS320C6678} {Multicore} {Fixed} and {Floating}-{Point} {Digital} {Signal} {Processor} datasheet},
	url = {https://www.ti.com/lit/ds/symlink/tms320c6678.pdf?ts=1666362122820&ref_url=https%253A%252F%252Fwww.ti.com%252Fproduct%252FTMS320C6678},
	language = {en-US},
	publisher = {Texas Instruments},
	month = mar,
	year = {2014},
}

@article{boyer_probabilistic_2016,
	title = {Probabilistic {Risk} {Assessment} ({PRA}): {Analytical} {Process} for {Recognizing} {Design} and {Operational} {Risks}},
	language = {en},
	author = {Boyer, Roger L},
	year = {2016},
	pages = {53},
}

@inproceedings{safie_reliability_2015,
	address = {Palm Harbor, FL, USA},
	title = {Reliability and probabilistic risk assessment-{How} they play together},
	isbn = {978-1-4799-6703-2},
	url = {http://ieeexplore.ieee.org/document/7105058/},
	doi = {10.1109/RAMS.2015.7105058},
	abstract = {CONCLUSIONS Since the Space Shuttle Challenger accident in 1986, NASA and aerospace industry has extensively used Probabilistic Risk Assessment (PRA) methods to assess, understand, and communicate the risk of space launch vehicles, especially manned space flight missions. Another area that was given a lot of emphasis at NASA is reliability engineering. Both PRA and reliability are probabilistic in nature; however; the reliability engineering is a broad design discipline that deals with loss of function, while PRA is a system scenario based risk assessment process that deals with Loss of Mission (LOM), Loss of Vehicle (LOV), and Loss of Crew (LOC). This paper discusses the PRA process and the reliability engineering discipline in details. It discusses their differences and similarities and how they are used as complementary analyses to support design and flight decisions. In summary:  Reliability Engineering is a discipline that involves the application of engineering principles to the design and processing of products; both hardware and software intended to minimize the loss of functions.  PRA at NASA is a process that deals with system risk focusing on understanding the system risk scenarios that could lead to LOM, LOV, and LOC.  PRA and reliability engineering are two different areas serving different functions in supporting the design and operation of launch vehicles. However, PRA as a risk assessment, and reliability as a metric could play together in a complementary manner in assessing the risk and reliability of launch vehicles.  In general, reliability analyses should be used as a critical data source for PRA.},
	language = {en},
	urldate = {2022-10-20},
	booktitle = {2015 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	publisher = {IEEE},
	author = {Safie, Fayssal M. and Stutts, Richard G. and Huang, Zhaofeng},
	month = jan,
	year = {2015},
	pages = {1--5},
}

@article{papazoglou_mathematical_1998,
	title = {Mathematical foundations of event trees},
	volume = {61},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832098000106?token=D60DAA26F46804F26445015C5CD4DE0AECF14130B21AB7DAB7DCD64D7212DA89F30084B5D0149C424CC17FF6B5DF3AB3&originRegion=us-east-1&originCreation=20221019192843},
	doi = {10.1016/S0951-8320(98)00010-6},
	language = {en},
	urldate = {2022-10-19},
	journal = {Reliability Engineering and System Safety},
	author = {Papazoglou, Ioannis A.},
	year = {1998},
	pages = {169 -- 183},
}

@inproceedings{gonzalez_using_2021,
	title = {Using {Operational} {Experience} to {Support} {Dynamic} {PRA} {Activities}},
	abstract = {Over the years, Dynamic PRA (DPRA) has been advocated on largely theoretical grounds as a potentially useful supplement to commonly used event tree/fault tree methods. However, there has been only limited formal investigation of dynamics observed during actual operating events that might be important to consider in a decision-support use of DPRA. This paper describes the status and preliminary results of an exploratory study that reviews a small number of past incidents to identify important dynamic behaviors.},
	language = {en},
	author = {Gonzalez, Michelle and Siu, Nathan},
	year = {2021},
	pages = {10},
}

@article{marhavilas_risk_2011,
	title = {Risk analysis and assessment methodologies in the work sites: {On} a review, classification and comparative study of the scientific literature of the period 2000–2009},
	volume = {24},
	issn = {0950-4230},
	shorttitle = {Risk analysis and assessment methodologies in the work sites},
	url = {https://www.sciencedirect.com/science/article/pii/S0950423011000325},
	doi = {10.1016/j.jlp.2011.03.004},
	abstract = {The objective of this work is to determine and study, analyze and elaborate, classify and categorize the main risk analysis and risk-assessment methods and techniques by reviewing the scientific literature. The paper consists of two parts: a) the investigation, presentation and elaboration of the main risk-assessment methodologies and b) the statistical analysis, classification, and comparative study of the corresponding scientific papers published by six representative scientific journals of Elsevier B.V. covering the decade 2000–2009. The scientific literature reviewing showed that the risk analysis and assessment techniques are classified into three main categories: (a) the qualitative, (b) the quantitative, and (c) the hybrid techniques (qualitative–quantitative, semi-quantitative). The qualitative techniques are based both on analytical estimation processes, and on the safety managers–engineers ability. According to quantitative techniques, the risk can be considered as a quantity, which can be estimated and expressed by a mathematical relation, under the help of real accidents’ data recorded in a work site. The hybrid techniques, present a great complexity due to their ad hoc character that prevents a wide spreading. The statistical analysis shows that the quantitative methods present the highest relative frequency (65.63\%) while the qualitative a lower one (27.68\%). Furthermore the hybrid methods remain constantly at a very low level (6.70\%) during the entire processing period.},
	language = {en},
	number = {5},
	urldate = {2022-10-17},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {Marhavilas, P. K. and Koulouriotis, D. and Gemeni, V.},
	month = sep,
	year = {2011},
	keywords = {Hybrid techniques, Qualitative, Quantitative, Risk analysis, Risk assessment, Risk estimation, Risk-assessment methodologies, Risk-assessment reviewing},
	pages = {477--523},
}

@misc{noauthor_risk_nodate,
	title = {Risk analysis and assessment methodologies in the work sites: {On} a review, classification and comparative study of the scientific literature of the period 2000-2009 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Risk analysis and assessment methodologies in the work sites},
	url = {https://reader.elsevier.com/reader/sd/pii/S0950423011000325?token=D249E4F24626743B4FB9487C9B8B2F9E23B67EB9727742BEA452F3FF02346C3F96AE2A130E704CFA598F9DF328F90F73&originRegion=us-east-1&originCreation=20221017184134},
	language = {en},
	urldate = {2022-10-17},
	doi = {10.1016/j.jlp.2011.03.004},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: {S0925}-7535(01)00047-9 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0925753501000479?token=6CE26A7F16C0764638D2476B14F3680CE58AA46E8352C0251855A921F55ED15BDECAF22FA26BC1721D0F9946C141E6E5&originRegion=us-east-1&originCreation=20221017184604},
	language = {en},
	urldate = {2022-10-17},
	doi = {10.1016/S0925-7535(01)00047-9},
}

@article{kabir_applications_2019,
	title = {Applications of {Bayesian} networks and {Petri} nets in safety, reliability, and risk assessments: {A} review},
	volume = {115},
	issn = {0925-7535},
	shorttitle = {Applications of {Bayesian} networks and {Petri} nets in safety, reliability, and risk assessments},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753518305435},
	doi = {10.1016/j.ssci.2019.02.009},
	abstract = {System safety, reliability and risk analysis are important tasks that are performed throughout the system life-cycle to ensure the dependability of safety-critical systems. Probabilistic risk assessment (PRA) approaches are comprehensive, structured and logical methods widely used for this purpose. PRA approaches include, but not limited to, Fault Tree Analysis (FTA), Failure Mode and Effects Analysis (FMEA), and Event Tree Analysis (ETA). Growing complexity of modern systems and their capability of behaving dynamically make it challenging for classical PRA techniques to analyse such systems accurately. For a comprehensive and accurate analysis of complex systems, different characteristics such as functional dependencies among components, temporal behaviour of systems, multiple failure modes/states for components/systems, and uncertainty in system behaviour and failure data are needed to be considered. Unfortunately, classical approaches are not capable of accounting for these aspects. Bayesian networks (BNs) have gained popularity in risk assessment applications due to their flexible structure and capability of incorporating most of the above mentioned aspects during analysis. Furthermore, BNs have the ability to perform diagnostic analysis. Petri Nets are another formal graphical and mathematical tool capable of modelling and analysing dynamic behaviour of systems. They are also increasingly used for system safety, reliability and risk evaluation. This paper presents a review of the applications of Bayesian networks and Petri nets in system safety, reliability and risk assessments. The review highlights the potential usefulness of the BN and PN based approaches over other classical approaches, and relative strengths and weaknesses in different practical application scenarios.},
	language = {en},
	urldate = {2022-10-17},
	journal = {Safety Science},
	author = {Kabir, Sohag and Papadopoulos, Yiannis},
	month = jun,
	year = {2019},
	keywords = {Bayesian networks, Petri nets, Reliability analysis, Risk assessment, Safety analysis},
	pages = {154--175},
}

@misc{noauthor_application_nodate,
	title = {On the application of near accident data to risk analysis of major accidents {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832014000258?token=0C1A510012B92F59E65AFBCF21F4B4D2A7FF94AB61AE212EBDC762A50E4ADD71640B09D1D566CE175F6640C9BD03A436&originRegion=us-east-1&originCreation=20221017183846},
	language = {en},
	urldate = {2022-10-17},
	doi = {10.1016/j.ress.2014.01.015},
}

@article{aven_considerations_2011,
	series = {Special {Issue} on {Safecomp} 2008},
	title = {Some considerations on the treatment of uncertainties in risk assessment for practical decision making},
	volume = {96},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832010001286},
	doi = {10.1016/j.ress.2010.06.001},
	abstract = {This paper discusses the challenges involved in the representation and treatment of uncertainties in risk assessment, taking the point of view of its use in support to decision making. Two main issues are addressed: (1) how to faithfully represent and express the knowledge available to best support the decision making and (2) how to best inform the decision maker. A general risk-uncertainty framework is presented which provides definitions and interpretations of the key concepts introduced. The framework covers probability theory as well as alternative representations of uncertainty, including interval probability, possibility and evidence theory.},
	language = {en},
	number = {1},
	urldate = {2022-10-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Aven, Terje and Zio, Enrico},
	month = jan,
	year = {2011},
	keywords = {Decision-making, Risk assessment, Uncertainty representations},
	pages = {64--74},
}

@article{francesco_time-dependent_2021,
	title = {Time-dependent reliability analysis of the reactor building of a nuclear power plant for accounting of its aging and degradation},
	volume = {205},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020306748},
	doi = {10.1016/j.ress.2020.107173},
	abstract = {The ultimate barrier to prevent contamination of the environment due to a release of radioactivity from a Nuclear Power Plant (NPP) is the reinforced concrete (RC) Reactor Building (RB) which encloses the nuclear reactor. The integrity of this barrier is the main focus of Probabilistic Risk Assessment (PRA)-Level 2, in which accident scenarios that might affect this barrier are modeled in terms of their consequences and their probabilities of occurrence. Traditionally, aging and degradation of the RB are not explicitly considered in the modeling. In this paper, a time-dependent reliability approach is adopted to explicitly model aging and degradation, and the effects on the RB resistance to the accidental stresses and eventually its failure probability. A Finite Element Model (FEM) of the RC is developed and coupled with a degradation model. By this, risk measures, like the Large Early Release Frequency (LERF) and its increase in time due to aging (ΔLERF), are actualized on the basis of the condition monitoring data related to the reactor building and the time-dependent risk of failure is quantified. A case study of an internal overpressure due to a hydrogen explosion is considered to exemplify the methodology.},
	language = {en},
	urldate = {2022-10-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Francesco, Di Maio and Matteo, Fumagalli and Carlo, Guerini and Federico, Perotti and Enrico, Zio},
	month = jan,
	year = {2021},
	keywords = {Aging, Degradation, Hydrogen combustion, Level 2 probabilistic risk assessment, Nuclear power plant, Reactor building, Reinforced concrete containment},
	pages = {107173},
}

@article{schroer_event_2013,
	title = {An event classification schema for evaluating site risk in a multi-unit nuclear power plant probabilistic risk assessment},
	volume = {117},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832013000756},
	doi = {10.1016/j.ress.2013.03.005},
	abstract = {Today, Probabilistic Risk Assessments (PRAs) at multi-unit nuclear power plants consider risk from each unit separately and consider dependencies and interactions between the units informally and on an ad hoc basis. The accident at the Fukushima nuclear power station underlined the importance and possibility of multi-unit accidents. These interactions make the operation of multiple units dependent on each other and should be formally accounted for in PRAs. In order to effectively account for these risks in a multi-unit PRA, six main dependence classifications have been identified: initiating events, shared connections, identical components, proximity dependencies, human dependencies, and organizational dependencies. This paper discusses these six classifications and the nature of their resulting dependence between multiple units. As a validation of the classification, this paper will also discuss multi-unit events that have occurred in operating plants. Finally, the paper will present existing methodologies that could be used to more formally quantify unit-to-unit dependencies in the PRAs for each classification.},
	language = {en},
	urldate = {2022-10-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Schroer, Suzanne and Modarres, Mohammad},
	month = sep,
	year = {2013},
	keywords = {Inter-unit dependencies, Multi-unit risk, Nuclear plant site, Probabilistic risk assessment, Site risk},
	pages = {40--51},
}

@article{himanen_risk-informed_2012,
	title = {Risk-{Informed} {Regulation} and {Safety} {Management} of {Nuclear} {Power} {Plants}—{On} the {Prevention} of {Severe} {Accidents}},
	volume = {32},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.2012.01904.x},
	doi = {10.1111/j.1539-6924.2012.01904.x},
	abstract = {There are four operating nuclear power plant (NPP) units in Finland. The Teollisuuden Voima (TVO) power company has two 840 MWe BWR units supplied by Asea-Atom at the Olkiluoto site. The Fortum corporation (formerly IVO) has two 500 MWe VVER 440/213 units at the Loviisa site. In addition, a 1600 MWe European Pressurized Water Reactor supplied by AREVA NP (formerly the Framatome ANP—Siemens AG Consortium) is under construction at the Olkiluoto site. Recently, the Finnish Parliament ratified the government Decision in Principle that the utilities' applications to build two new NPP units are in line with the total good of the society. The Finnish utilities, Fenno power company, and TVO company are in progress of qualifying the type of the new nuclear builds. In Finland, risk-informed applications are formally integrated in the regulatory process of NPPs that are already in the early design phase and these are to run through the construction and operation phases all through the entire plant service time. A plant-specific full-scope probabilistic risk assessment (PRA) is required for each NPP. PRAs shall cover internal events, area events (fires, floods), and external events such as harsh weather conditions and seismic events in all operating modes. Special attention is devoted to the use of various risk-informed PRA applications in the licensing of Olkiluoto 3 NPP.},
	language = {en},
	number = {11},
	urldate = {2022-10-17},
	journal = {Risk Analysis},
	author = {Himanen, Risto and Julin, Ari and Jänkälä, Kalle and Holmberg, Jan-Erik and Virolainen, Reino},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2012.01904.x},
	keywords = {Nuclear safety, PRA, PSA, risk-informed applications, risk-informed regulation},
	pages = {1978--1993},
}

@misc{noauthor_filtered_nodate,
	title = {Filtered {Containment} {Venting} {System}},
	copyright = {FNC Technology Co., Ltd.},
	shorttitle = {{FNC} {Technology} {Co}., {Ltd} {\textbar} {Nuclear} {Engineering} {Company}},
	url = {http://www.fnctech.com/product_1.html},
	language = {English},
	urldate = {2022-10-16},
	journal = {Filtered Containment Venting System},
}

@article{jian_geuo_risk_2022,
	title = {Risk assessment of hazardous materials transportation: {A} review of research progress in the last thirty years},
	volume = {9},
	shorttitle = {Risk assessment of hazardous materials transportation},
	url = {https://reader.elsevier.com/reader/sd/pii/S2095756422000563?token=2BC3E878A881DA150BEDDA345E3B9822EB87B2828D69C23CC6528C06E8BA7C32FC410DFD8A6B0547484DBD514B134E92&originRegion=us-east-1&originCreation=20220907203534},
	doi = {10.1016/j.jtte.2022.01.004},
	language = {en},
	number = {4},
	urldate = {2022-09-07},
	journal = {Journal of Traffic and Transportation Engineering},
	author = {{Jian Geuo} and {Cheng Luo}},
	month = aug,
	year = {2022},
	pages = {571--590},
}

@article{erkut_transport_2005,
	title = {Transport risk models for hazardous materials: revisited},
	volume = {33},
	issn = {01676377},
	shorttitle = {Transport risk models for hazardous materials},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167637704000410},
	doi = {10.1016/j.orl.2004.02.006},
	abstract = {Several proposed path evaluation functions for hazardous materials transport use an approximation. Modiÿed functions that avoid the approximation violate two reasonable axioms. We present new models by redeÿning the decision problem as one of satisfying demand at the destination. The new models satisfy the axioms and are relatively tractable.},
	language = {en},
	number = {1},
	urldate = {2022-10-14},
	journal = {Operations Research Letters},
	author = {Erkut, Erhan and Ingolfsson, Armann},
	month = jan,
	year = {2005},
	pages = {81--89},
}

@article{ambituuni_risk_2015,
	title = {Risk assessment of petroleum product transportation by road: {A} framework for regulatory improvement},
	volume = {79},
	issn = {09257535},
	shorttitle = {Risk assessment of petroleum product transportation by road},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753515001642},
	doi = {10.1016/j.ssci.2015.06.022},
	abstract = {Accidents involving transportation of petroleum products by road has been associated with high frequency of occurrence and high safety consequences in developing countries. Using Nigeria as case example, we analysed 2318 accidents involving truck tankers from 2007 to 2012 with a tailored risk assessment framework. The result shows 79\% of the accidents were caused by human factors, mainly dangerous driving. More than 70\% of the accident resulted in loss of containment leading to spills, ﬁres and explosions. 81\% of the accidents resulted in either injuries, fatalities or both. Most of the 972 accidents with fatalities recorded 1–5 fatalities with occurrence frequency of 0.89. The analysis ranks geographical regions (states) in order of accident consequences and frequencies to enhance regulatory distribution. About 7 million USD was estimated as the average cost per accident. Estimated costs are signiﬁcant and should motivate improved policy design.},
	language = {en},
	urldate = {2022-10-14},
	journal = {Safety Science},
	author = {Ambituuni, Ambisisi and Amezaga, Jaime M. and Werner, David},
	month = nov,
	year = {2015},
	pages = {324--335},
}

@article{kohda_simple_2006,
	title = {A simple method to derive minimal cut sets for a non-coherent fault tree},
	volume = {3},
	issn = {1751-8520},
	url = {https://doi.org/10.1007/s11633-006-0151-4},
	doi = {10.1007/s11633-006-0151-4},
	abstract = {Minimal cut sets (or prime implicants: minimal combinations of basic event conditions leading to system failure) are important information for reliability/safety analysis and design. To obtain minimal cut sets for general non-coherent fault trees, including negative basic events or multi-valued basic events, a special procedure such as the consensus rule must be applied to the results obtained by logical operations for coherent fault trees, which will require more steps and time. This paper proposes a simple method for a non-coherent fault tree, whose top event is represented as an AND combination of monotonic sub-trees. A “monotonic” sub-tree means that it does not have both positive and negative representations for each basic event. It is proven that minimal cut sets can be obtained by a conventional method for coherent fault trees. An illustrative example of a simple event tree analysis shows the detail and characteristics of the proposed method.},
	language = {en},
	number = {2},
	urldate = {2022-10-14},
	journal = {International Journal of Automation and Computing},
	author = {Kohda, Takehisa},
	month = apr,
	year = {2006},
	keywords = {Non-coherent fault trees, minimal cut sets, monotonic sub-trees},
	pages = {151--156},
}

@article{sharvia_non-coherent_2008,
	series = {17th {IFAC} {World} {Congress}},
	title = {Non-coherent {Modelling} in {Compositional} {Fault} {Tree} {Analysis}},
	volume = {41},
	issn = {1474-6670},
	url = {https://www.sciencedirect.com/science/article/pii/S1474667016395945},
	doi = {10.3182/20080706-5-KR-1001.00696},
	abstract = {The inclusion of NOT gates in a fault tree creates a “non-coherent” structure in which not only the failure of a component but also the negation of failure, i.e. the working state of the component, can contribute to the undesirable effects on a system. This type of non-coherent modelling remains controversial; its usefulness is still debated among academics, which explains why NOT gates have not been included in the Fault Tree Handbook. In this paper, we review work on non-coherent fault trees and highlight circumstances where non-coherent modelling is appropriate and useful. We then describe an extension to HiP-HOPS (Hierarchically Performed Hazard Origin and Propagation Studies), a recently proposed compositional safety analysis method, that enables model-based synthesis and analysis of non-coherent fault trees. A small example is given to illustrate application of the extended method and demonstrate how this type of non-coherent modelling can give a more precise and ultimately more correct insight into failure behaviour.},
	language = {en},
	number = {2},
	urldate = {2022-10-14},
	journal = {IFAC Proceedings Volumes},
	author = {Sharvia, Septavera and Papadopoulos, Yiannis},
	month = jan,
	year = {2008},
	pages = {4138--4143},
}

@article{contini_use_2008,
	series = {17th {European} {Safety} and {Reliability} {Conference}},
	title = {On the use of non-coherent fault trees in safety and security studies},
	volume = {93},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832008001117},
	doi = {10.1016/j.ress.2008.03.018},
	abstract = {This paper gives some insights on the usefulness of non-coherent fault trees in system modelling from both the point of view of safety and security. A safety-related system can evolve from the working states to failed states through degraded states, i.e. working state, but in a degraded mode. In practical applications the degraded states may be of particular interest due e.g. to the associated risk increase or the different types of consequent actions. The top events definitions of such states contain the working conditions of some sub-systems/components. How the use of non-coherent fault trees can greatly simplify both the modelling and quantification of these states is shown in this paper. Some considerations about the interpretation of the importance indexes of negated basic events are also briefly described. When dealing with security applications, there is a need to cope not only with stochastic events, such as component failures and human errors, but also with deliberate intentional actions, whose successes might be characterised by high probability values. Different mutually exclusive attack scenarios may be envisaged for a given system. Hence, the essential feature of a fault tree analyser is the capability to determine the exact value of the top event probability containing mutually exclusive events. It is also shown that in these cases the use of non-coherent fault trees allows solving the problem with limited effort.},
	language = {en},
	number = {12},
	urldate = {2022-10-14},
	journal = {Reliability Engineering \& System Safety},
	author = {Contini, S. and Cojazzi, G. G. M. and Renda, G.},
	month = dec,
	year = {2008},
	keywords = {Mutually exclusive events, Non-coherent fault trees, Safety, Security},
	pages = {1886--1895},
}

@article{rauzy_exact_1997,
	series = {{ESREL} '95},
	title = {Exact and truncated computations of prime implicants of coherent and non-coherent fault trees within {Aralia}},
	volume = {58},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832097000343},
	doi = {10.1016/S0951-8320(97)00034-3},
	abstract = {Aralia is a Binary Decision Diagram (BDD) package extended to handle fault trees. It is currently developed at the University of Bordeaux as a part of a partnership between university laboratories and several French companies. BDD's are the state of the art data structure to handle boolean functions. They have been recently used with success in the framework of safety and reliability analysis. The aim of this paper is to present how prime implicants (minimal cuts) of coherent and non-coherent fault trees are computed within Aralia. The used algorithms are mainly those proposed by J. C. Madre and O. Coudert on the one hand and A. Rauzy on the other hand. We introduce the notion of minimal p-cuts that is a sound extension of the notion of minimal cuts to the case of non-coherent fault trees. We propose two BDD based algorithms to compute them. We show how to modify these algorithms in order to compute only prime implicants (or minimal p-cuts) whose orders are less than a given constant or whose probabilities are greater than a given threshold. We report experiments showing that this improves significantly the methodology for this allows fast, accurate and incremental approximations of the desired result.},
	language = {en},
	number = {2},
	urldate = {2022-10-14},
	journal = {Reliability Engineering \& System Safety},
	author = {Rauzy, Antoine and Dutuit, Yves},
	month = nov,
	year = {1997},
	pages = {127--144},
}

@article{vaurio_importances_2016,
	title = {Importances of components and events in non-coherent systems and risk models},
	volume = {147},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832015003348},
	doi = {10.1016/j.ress.2015.11.007},
	abstract = {Component importance measures have been defined and applied so far mostly for coherent systems. This paper develops and compares possible extensions of the traditional measures to non-coherent systems. The focus is on Birnbaum- and Criticality-type importances, both with respect to system unavailability and system failure intensity. Several versions are suggested for both measure types, each with different interpretation and potential applications. The measures are presented in terms of Boolean system logic functions so that they can be quantified with usual fault tree techniques even for large systems without manually solving and derivation of lengthy analytical functions. Examples demonstrate the method and discover some potential problems in system design if a component can initiate an accident while it is also part of a safety function to prevent an accident. Results are compared to earlier published results obtained with different algorithms.},
	language = {en},
	urldate = {2022-10-14},
	journal = {Reliability Engineering \& System Safety},
	author = {Vaurio, Jussi K.},
	month = mar,
	year = {2016},
	keywords = {Birnbaum, Criticality, Fault tree, Importance measures, Non-coherent, Risk analysis},
	pages = {117--122},
}

@article{vaurio_ideas_2010,
	title = {Ideas and developments in importance measures and fault-tree techniques for reliability and risk analysis},
	volume = {95},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832009002105},
	doi = {10.1016/j.ress.2009.08.006},
	abstract = {This paper shows an efficient order for calculating importance measures and develops several new measures related to fault diagnostics, system failure intensity, system failure count, and configuration control. Definitions and relationships are extended to certain non-coherent systems and to models with mutually explicit events. Useful interpretations and applications are pointed out, and many roles of the Birnbaum importance are highlighted. Another important topic is the accuracy of various alternative methods used for quantification of accident sequence probabilities when negations or success branches of event trees are involved. Finally, the role of truncation errors is described, and criteria are developed for selecting truncation limits and cut-off errors so that importance measures can be estimated reliably and risk-informed decision making is robust, without unreasonable conservatism and without unwarranted optimism.},
	language = {en},
	number = {2},
	urldate = {2022-10-14},
	journal = {Reliability Engineering \& System Safety},
	author = {Vaurio, Jussi K.},
	month = feb,
	year = {2010},
	keywords = {Achievement, Birnbaum, Configuration, Criticality, Importance, Ranking, Risk, Risk increase, Risk reduction, Risk-gain, Risk-informed},
	pages = {99--107},
}

@article{ulmeanu_analytical_2012,
	title = {Analytical {Method} to {Determine} {Uncertainty} {Propagation} in {Fault} {Trees} by {Means} of {Binary} {Decision} {Diagrams}},
	volume = {61},
	issn = {1558-1721},
	doi = {10.1109/TR.2012.2182812},
	abstract = {An analytical method is presented which enables one to propagate uncertainties described by continuous probability density functions through fault trees from the lower level (basic event) to the higher level (top-event) of a stochastic binary system. It is based on calculating the expected value and the variance of the top-event probability by means of Binary Decision Diagrams (BDD). This method allows an accurate computation of both the expected value and the variance of the top-event probability. We show, on a benchmark of real fault trees, that our method results in a quantitative and qualitative improvement in safety analysis of industrial systems, especially those concerning accurate evaluation of Safety Integrity Levels (SIL), whenever different sources of uncertainties are present. The numerical results of the analytical method are in good agreement with those of the Monte Carlo method.},
	number = {1},
	journal = {IEEE Transactions on Reliability},
	author = {Ulmeanu, Anatoli Paul},
	month = mar,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Reliability},
	keywords = {Binary decision diagrams, Boolean functions, Data structures, Fault trees, Random variables, Safety, Shannon decomposition, Temperature measurement, Uncertainty, fault trees, safety analysis, safety integrity levels},
	pages = {84--94},
}

@inproceedings{adkins_mircroreactor_2021,
	address = {Pheonix, Arizona},
	title = {Mircroreactor {Transportability} {Challenges} - 21072},
	author = {Adkins, Harold and {Steven Maheras}},
	month = mar,
	year = {2021},
	pages = {19},
}

@misc{dong_design_2018,
	address = {INET, Tsinghua University, China},
	title = {{DESIGN}, {SAFETY} {FEATURES} \& {PROGRESS} {OF} {HTR}-{PM}},
	language = {English},
	author = {Dong, Yujie},
	month = jan,
	year = {2018},
}

@inproceedings{wang_design_2015,
	address = {Chiba, Japan},
	series = {International {Conference} on {Nuclear} {Engineering}, {Proceedings}, {ICONE}},
	title = {Design of the ground crane and shielding cask for the spent fuel canister of {HTR}-{PM}},
	volume = {2015-January},
	abstract = {The High Temperature gas cooled Reactor Pebble bed Module (HTR-PM) is in design and construction process in China, which is considered as one of the candidates for the Gen-IV nuclear power plant, and has advantage of inherent safety, avoiding nuclear proliferation, high temperature industry heat production and so on. The sphere fuel element is used in HTR-PM. The fuel particles are spread in the fuel element, and the sphere element's diameter is 60mm after oppression. After discharged from the HTR reactor core, the spent fuel element would be transferred into the spent fuel canister. The spent fuel canister would be stored in the spent fuel storage well after fully loaded. In the process of the spent fuel storage and operation, it is required to ensure the operation safety, subcritical, radiation shielding safety and residual heat removal safety. In order to decrease the price of the spent fuel canister, the canister was designed as a thin shell vessel, which has weak radiation shielding function, and cannot fulfill safety requirement of radiation shielding, so it is required to research and design a set of devices, which could provide enough radiation shielding for the spent fuel canister, and the device could also transfer the spent fuel canister safely and reliably, and then the safety of the operation staff and the facility could be ensured. The concrete shielding well lid is set on top of the storage well, when the spent fuel canister is needed to put into the storage well, the well lid would be taken out from its mounting position. In the operation process of the spent fuel canister and the concrete shielding well lid, the ground crane with accurate positioning function is required to position the spent fuel canister and the concrete shielding well lid to the operating position. The main components of the ground crane system includes: Crane bridge, shielding cask, neutron shielding boron barrel, canister hoisting mechanism, well lid hoisting mechanism, bottom plate opening mechanism, shielding strip mechanism, residual removal blowers, butterfly valves, ground rails, cable sliding bridge, encoder positioning scale and so on. The ground crane could satisfy the accurate positioning and safe operation of the spent fuel canister, and could ensure the operating reliability of the spent fuel canister and the concrete shielding well lid in HTR-PM operational period. Copyright  2015 by JSME.},
	booktitle = {23rd {International} {Conference} on {Nuclear} {Engineering}: {Nuclear} {Power} - {Reliable} {Global} {Energy}, {ICONE} 2015, {May} 17, 2015  -  {May} 21, 2015},
	publisher = {American Society of Mechanical Engineers (ASME)},
	author = {Wang, Jinhua and Liu, Xiang and Wang, Bing and Li, Yue and Wu, Bin},
	year = {2015},
	keywords = {Accident prevention, Concretes, Cranes, Design, Fuel storage, Gas cooled reactors, High temperature gas reactors, High temperature reactors, Nuclear energy, Nuclear fuel elements, Nuclear power plants, Pebble bed reactors, Radiation shielding, Radioactive waste storage, Spent fuels},
	pages = {et al.; GLSEQ, LLC/SCI Technologies. Inc; Hitachi--GE Nuclear Energy, Ltd.; Mitsubishi Heavy Industries, Ltd. (MHI); Toshiba Corporation; Westinghouse Electric Company},
}

@article{dauria_passive_2021,
	title = {Passive systems and nuclear thermal-hydraulics},
	volume = {385},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549321004659},
	doi = {10.1016/j.nucengdes.2021.111513},
	abstract = {Passive systems are in use within nuclear technology, noticeably those systems, which are capable of transferring thermal power from a heat source to a sink with the use of energy coming from gravity: Natural Circulation inside the vessel for Boiling Water Reactors (BWR) and between vessel and steam generators for Pressurized Water Reactor (PWR) constitutes noticeable examples. A stepwise, somewhat fashion-type, renewed interest followed, after the three major nuclear accidents in 1979, 1986 and 2011. The words thermal-hydraulic passive systems, design and safety, open to a myriad of research and application activities, which without surprise may appear contradictory and, at least, not converging into a common understanding. In the present paper, we used the word reliability in order to select a space in the design and safety assessment and to derive agreeable outcomes for the technology of passive systems. The key conclusions are: (a) Passive systems are not the panacea for protecting the core of nuclear reactors in each foreseeable accident condition. (b) Specific licensing rules are necessary. (c) Reliability of operation, for any assigned target mission, may reveal less than one. (d) Systems implying the use of active components like pumps shall not be discarded in future designed/built nuclear reactors.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Nuclear Engineering and Design},
	author = {D'Auria, F.},
	month = dec,
	year = {2021},
	keywords = {Innovative reactor design, Natural circulation, Passive systems thermal-hydraulics, Reliability of passive systems},
	pages = {111513},
}

@article{palomares_assessment_2020,
	title = {Assessment of near-term fuel screening and qualification needs for nuclear thermal propulsion systems},
	volume = {367},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549320302594},
	doi = {10.1016/j.nucengdes.2020.110765},
	abstract = {Nuclear thermal propulsion (NTP) is an in-space propulsion technology capable of both high specific impulse (850–1000 s) and thrust (44–1112 kN), which can help reduce trip times for crewed missions beyond low Earth orbit. NTP technology has been demonstrated during historic programs. Over 20 ground test reactor experiments were performed, which demonstrated the prototypic reactor operations, during the Nuclear Engine for Rocket Vehicle Application (NERVA)/Rover program (1955–1972). Although historical programs have shown that NTP is a viable in-space propulsion technology, developing NTP in modern programs is contingent on the development and qualification of ultrahigh-temperature nuclear fuel technologies that can withstand engine operating conditions. In historical NTP development programs such as NERVA/Rover, prototypic reactor/engine schemes were ground tested to assess the overall system feasibility and to qualify the reactor fuel forms for eventual flight systems. Although this approach is effective to verify fuel performance under prototypic conditions, relying solely on full-scale NTP reactor tests as the pathway for verifying or qualifying fuel is inefficient and cost prohibitive today. Additionally, modern nuclear licensing requirements state that before test reactor approval, reactor components and fuel elements should be qualified via non-nuclear (out-of-pile) and nuclear (in-pile) testing under representative operating conditions. Using this methodology, fuel matures as production scale fabrication methods are established, and as produced fuel performance is demonstrated. This paper provides an overview of historical approaches to NTP fuel performance maturation, including fuel screening and qualification needs, and provides insight for establishing an efficient testing paradigm that can be implemented to rapidly and affordably develop NTP fuel forms for eventual qualification.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Nuclear Engineering and Design},
	author = {Palomares, Kelsa and Howard, Richard and Steiner, Tyler},
	month = oct,
	year = {2020},
	pages = {110765},
}

@article{li_integrating_2005,
	title = {Integrating {Software} into {PRA}: {A} {Test}-{Based} {Approach}},
	volume = {25},
	issn = {0272-4332, 1539-6924},
	shorttitle = {Integrating {Software} into {PRA}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.2005.00638.x},
	doi = {10.1111/j.1539-6924.2005.00638.x},
	language = {en},
	number = {4},
	urldate = {2022-10-07},
	journal = {Risk Analysis},
	author = {Li, Bin and Li, Ming and Smidts, Carol},
	month = aug,
	year = {2005},
	pages = {1061--1077},
}

@article{pence_methodology_2018,
	title = {Methodology to evaluate the monetary benefit of {Probabilistic} {Risk} {Assessment} by modeling the net value of {Risk}-{Informed} {Applications} at nuclear power plants},
	volume = {175},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832018302540},
	doi = {10.1016/j.ress.2018.03.002},
	abstract = {Probabilistic Risk Assessment (PRA) used in Nuclear Power Plants serves as a pillar of the U.S. Nuclear Regulatory Commission's Risk-Informed Regulatory framework, and is required for new reactor licenses to satisfy regulatory safety compliance. The benefits of PRA are not only experienced in terms of safety, but also from the monetary value derived from Risk-Informed Performance-Based Applications (RIPBAs), where risk estimated from PRA is utilized in decision making to expand the safe operational envelope of plants, leading to either an increase in profits or a reduction in costs. This paper introduces a methodology to evaluate this monetary value by the systematic causal modeling of the net value of RIPBAs and demonstrates the methodology for one of the RIPBAs, called Risk-Managed Technical Specifications (RMTS). The key steps of this methodology are: (i) Cost-Benefit Analysis to formulate the net value of PRA based on the net value of RIPBAs, (ii) Causal modeling to systematically model the operational scenarios leading to costs and benefits associated with RIPBAs, (iii) Uncertainty analysis, and (iv) Sensitivity analysis and validation. The results of this research could help decision makers with evaluating investment strategies in PRA that go ‘beyond-compliance’ to maximize industry profit while maintaining regulatory safety goals.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Reliability Engineering \& System Safety},
	author = {Pence, Justin and Abolhelm, Marzieh and Mohaghegh, Zahra and Reihani, Seyed and Ertem, Mehmet and Kee, Ernie},
	month = jul,
	year = {2018},
	keywords = {Causal Modeling, Cost-Benefit Analysis, Decision Tree, Global Sensitivity Analysis, Probabilistic Risk Assessment, Risk-Informed Decision Making, Risk-Informed Performance-Based Applications, Risk-Managed Technical Specifications, Uncertainty Analysis},
	pages = {171--182},
}

@article{everline_comparison_2006,
	title = {Comparison of techniques for modeling accident progression in dynamic aerospace applications with and without repair},
	volume = {91},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832005000529},
	doi = {10.1016/j.ress.2005.01.016},
	abstract = {This paper discusses the use of the multiple event tree and single event tree approaches in Probabilistic Risk Assessments for aerospace applications. The issue is how repair can affect the modeling. Four simple examples are presented to show how even a seemingly simple system can become a complex PRA model if the less than optimum approach is used. In cases of repair, it is suggested that the multiple event tree approach is the more appropriate model. In cases of no repair, it is suggested that the single event tree approach is the easier PRA modeling solution.},
	language = {en},
	number = {3},
	urldate = {2022-10-07},
	journal = {Reliability Engineering \& System Safety},
	author = {Everline, Chester J. and Paulos, Todd},
	month = mar,
	year = {2006},
	pages = {370--377},
}

@techreport{s_a_eide_generic_1990,
	title = {{GENERIC}, {COMPONENT} {FAILURE} {DATA} {BASE} {FOR} {LIGHT} {WATER} {AND} {LIQUID} {SODIUM} {REACTOR} {PRAs}},
	url = {http://www.osti.gov/servlets/purl/975488-XeBiT7/},
	language = {en},
	number = {EGG-SSRE-8875, 975488},
	urldate = {2022-10-07},
	author = {{S. A. Eide} and {S. V. Chmielewski} and {T. D. Swantz}},
	month = feb,
	year = {1990},
	doi = {10.2172/975488},
	pages = {EGG--SSRE--8875, 975488},
}

@article{sainati_small_2015,
	title = {Small {Modular} {Reactors}: {Licensing} constraints and the way forward},
	volume = {82},
	issn = {03605442},
	shorttitle = {Small {Modular} {Reactors}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544215000250},
	doi = {10.1016/j.energy.2014.12.079},
	abstract = {SMR (Small Modular Reactor) is an acronym for a group of nuclear power plant designs receiving an increasing deal of attention from the industry and policy makers. A large number of SMRs need to be built in the same site and across the word to compensate diseconomies of scale and be cost competitive with large reactors and other base-load technologies. A major barrier is the licensing process, historically developed for large reactors, preventing the simply deployment of several identical units in different countries. This paper, discussing Ramana, Hopkins and Glaser [1], enlarges the view to all the SMRrelated implications on the licensing process, presenting their legislative implications and market effects. © 2015 Elsevier Ltd. All rights reserved.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Energy},
	author = {Sainati, Tristano and Locatelli, Giorgio and Brookes, Naomi},
	month = mar,
	year = {2015},
	pages = {1092--1095},
}

@article{jamali_use_2010,
	title = {Use of risk measures in design and licensing of future reactors},
	volume = {95},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010000797},
	doi = {10.1016/j.ress.2010.04.001},
	abstract = {Use of information and insights from probabilistic risk assessments (PRAs) in nuclear reactor safety applications has been increasing by the nuclear industry and the regulators, both domestically and internationally. This is a desirable trend, as PRAs have demonstrated capability to improve safety and operational ﬂexibility beyond that provided through deterministic approaches alone. But there can be potential pitfalls. The limitations of risk assessment technology can be lost through approaches that rely heavily on quantitative PRA results (referred to as risk measures in this paper), because of the unambiguous but potentially misleading message that can be delivered by risk-based numbers. This is particularly true for future reactors, where PRAs are used during the design and licensing processes. For these applications, it is important to ensure that the actual, de facto, or even perceived use of risk measures in the context of either regulatory or design acceptance criteria is avoided. While the issues discussed here can have a signiﬁcant inﬂuence on design certiﬁcation or combined license applications for future reactors, they can also have secondary impacts on currently operating reactors.},
	language = {en},
	number = {9},
	urldate = {2022-10-07},
	journal = {Reliability Engineering \& System Safety},
	author = {Jamali, Kamiar},
	month = sep,
	year = {2010},
	pages = {935--943},
}

@article{downer_empires_2021,
	title = {Empires built on sand: {On} the fundamental implausibility of reactor safety assessments and the implications for nuclear regulation},
	volume = {15},
	issn = {1748-5983, 1748-5991},
	shorttitle = {Empires built on sand},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/rego.12300},
	doi = {10.1111/rego.12300},
	abstract = {This paper explores the nature of expert knowledge-claims made about catastrophic reactor accidents and the processes through which they are produced. Using the contested approval of the AP1000 reactor by the US Nuclear Regulatory Commission (NRC) as a case study and drawing on insights from the Science and Technology Studies (STS) literature, it ﬁnds that the epistemological foundations of safety assessments are counterintuitively distinct from most engineering endeavors. As a result, it argues, those assessments (and thus their authority) are widely misconstrued by publics and policymakers. This misconstrual, it concludes, has far-reaching implications for nuclear policy, and it outlines how scholars, policymakers, and others might build on a revised understanding of expert reactor assessments to differently frame, and address, a range of questions pertaining to the risks and governance of atomic energy.},
	language = {en},
	number = {4},
	urldate = {2022-10-07},
	journal = {Regulation \& Governance},
	author = {Downer, John and Ramana, M. V.},
	month = oct,
	year = {2021},
	pages = {1304--1325},
}

@misc{iaea_spent_2021,
	type = {Text},
	title = {Spent {Fuel} {Storage} {Options}: {Challenges} and {Solutions}},
	url = {https://www.iaea.org/about/governance/general-conference/gc65/events/secretariat-side-events},
	language = {English},
	urldate = {2022-10-06},
	author = {IAEA, Spent Fuel Storage Options: Challenges {and} Solutions},
	month = sep,
	year = {2021},
	note = {Publisher: IAEA},
}

@article{remenyte-prescott_enhanced_2008,
	title = {An enhanced component connection method for conversion of fault trees to binary decision diagrams},
	volume = {93},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832007002232},
	doi = {10.1016/j.ress.2007.09.001},
	abstract = {Fault tree analysis (FTA) is widely applied to assess the failure probability of industrial systems. Many computer packages are available, which are based on conventional kinetic tree theory methods. When dealing with large (possibly non-coherent) fault trees, the limitations of the technique in terms of accuracy of the solutions and the efficiency of the processing time become apparent. Over recent years, the binary decision diagram (BDD) method has been developed that solves fault trees and overcomes the disadvantages of the conventional FTA approach. First of all, a fault tree for a particular system failure mode is constructed and then converted to a BDD for analysis. This paper analyses alternative methods for the fault tree to BDD conversion process. For most fault tree to BDD conversion approaches, the basic events of the fault tree are placed in an ordering. This can dramatically affect the size of the final BDD and the success of qualitative and quantitative analyses of the system. A set of rules is then applied to each gate in the fault tree to generate the BDD. An alternative approach can also be used, where BDD constructs for each of the gate types are first built and then merged to represent a parent gate. A powerful and efficient property, sub-node sharing, is also incorporated in the enhanced method proposed in this paper. Finally, a combined approach is developed taking the best features of the alternative methods. The efficiency of the techniques is analysed and discussed.},
	language = {en},
	number = {10},
	urldate = {2022-10-06},
	journal = {Reliability Engineering \& System Safety},
	author = {Remenyte-Prescott, R. and Andrews, J. D.},
	month = oct,
	year = {2008},
	keywords = {Binary decision diagrams, Fault tree analysis},
	pages = {1543--1550},
}

@article{ibanez-llano_reduction_2010,
	series = {19th {European} {Safety} and {Reliability} {Conference}},
	title = {A reduction approach to improve the quantification of linked fault trees through binary decision diagrams},
	volume = {95},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832010001420},
	doi = {10.1016/j.ress.2010.06.008},
	abstract = {Over the last two decades binary decision diagrams have been applied successfully to improve Boolean reliability models. Conversely to the classical approach based on the computation of the MCS, the BDD approach involves no approximation in the quantification of the model and is able to handle correctly negative logic. However, when models are sufficiently large and complex, as for example the ones coming from the PSA studies of the nuclear industry, it begins to be unfeasible to compute the BDD within a reasonable amount of time and computer memory. Therefore, simplification or reduction of the full model has to be considered in some way to adapt the application of the BDD technology to the assessment of such models in practice. This paper proposes a reduction process based on using information provided by the set of the most relevant minimal cutsets of the model in order to perform the reduction directly on it. This allows controlling the degree of reduction and therefore the impact of such simplification on the final quantification results. This reduction is integrated in an incremental procedure that is compatible with the dynamic generation of the event trees and therefore adaptable to the recent dynamic developments and extensions of the PSA studies. The proposed method has been applied to a real case study, and the results obtained confirm that the reduction enables the BDD computation while maintaining accuracy.},
	language = {en},
	number = {12},
	urldate = {2022-10-06},
	journal = {Reliability Engineering \& System Safety},
	author = {Ibáñez-Llano, Cristina and Rauzy, Antoine and Meléndez, Enrique and Nieto, Francisco},
	month = dec,
	year = {2010},
	keywords = {Binary decision diagrams, Dynamic event trees, Fault trees, Minimal cutsets, Probabilistic safety assessment},
	pages = {1314--1323},
}

@misc{noauthor_doi101016jress200709001_nodate,
	title = {doi:10.1016/j.ress.2007.09.001 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832007002232?token=9983EB08BCEB433D61B2BD5CA1040EEF489F718CE5791E281BAD2649D30928E0B663CA633BDB00247A50F6CD223A6DAE&originRegion=us-east-1&originCreation=20221006005305},
	language = {en},
	urldate = {2022-10-06},
	doi = {10.1016/j.ress.2007.09.001},
}

@inproceedings{morozov_stochastic_2016,
	address = {Leipzig, Germany},
	title = {Stochastic {Error} {Propagation} {Analysis} of {Model}-driven {Space} {Robotic} {Software} {Implemented} in {Simulink}},
	isbn = {978-1-4503-4259-9},
	url = {http://dl.acm.org/citation.cfm?doid=3022099.3022103},
	doi = {10.1145/3022099.3022103},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {Proceedings of the 3rd {Workshop} on {Model}-{Driven} {Robot} {Software} {Engineering} - {MORSE} '16},
	publisher = {ACM Press},
	author = {Morozov, Andrey and Janschek, Klaus and Krüger, Thomas and Schiele, André},
	year = {2016},
	pages = {24--31},
}

@article{bui_algorithm_2019,
	title = {An algorithm for enhancing spatiotemporal resolution of probabilistic risk assessment to address emergent safety concerns in nuclear power plants},
	volume = {185},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018302850},
	doi = {10.1016/j.ress.2019.01.004},
	language = {en},
	urldate = {2022-10-05},
	journal = {Reliability Engineering \& System Safety},
	author = {Bui, Ha and Sakurahara, Tatsuya and Pence, Justin and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	month = may,
	year = {2019},
	pages = {405--428},
}

@phdthesis{zhu_integrating_2005,
	address = {College Park, MD},
	title = {Integrating {Software} {Behavior} into {Dynamic} {PRA}},
	url = {https://drum.lib.umd.edu/bitstream/handle/1903/3305/umi-umd-3136.pdf?sequence=1&isAllowed=y},
	language = {en},
	school = {University of Maryland},
	author = {Zhu, Dongfeng},
	year = {2005},
}

@inproceedings{shorthill_bayesian_2021,
	title = {A {Bayesian} and {HRA} -aided {Method} for the {Novel} {Reliability} {Analysis} of {Software}},
	abstract = {Technological advancements and nuclear power plant modernization has inspired considerable research in the areas of safety and reliability, yet there remains a lack of consensus for the reliability assessment of digital instrumentation and control (I\&C) systems. Motivated by the lack of consensus for reliability analysis methods, this work employs a novel framework that incorporates Bayesian, human reliability, and common-cause failure (CCF) modeling techniques. The novel framework allows the use of state-of-the-art or classical modeling techniques when accounting for human and CCF effects on system reliability. The Bayesian and HRA-Aided Method for the Reliability Analysis of Software (BAHAMAS) is demonstrated by a case study for the quantification of software hazards found in a previous analysis of a digital reactor trip system. The results demonstrate the ability of BAHAMAS to account for human activities during the software development life cycle and their influence on software reliability. BAHAMAS is a flexible tool for extending the coverage of conventional probabilistic risk assessments to include modernized digital I\&C systems.},
	author = {Shorthill, Tate and Bao, Han and Zhang, Hongbin and Ban, Heng},
	month = nov,
	year = {2021},
}

@phdthesis{li_integrating_2004,
	address = {College Park, MD},
	title = {Integrating {Software} into {PRA}},
	url = {https://drum.lib.umd.edu/bitstream/handle/1903/1993/umi-umd-1946.pdf?sequence=1&isAllowed=y},
	language = {en},
	school = {University of Maryland},
	author = {Li, Bin},
	year = {2004},
}

@misc{brill_instrumentation_nodate,
	title = {Instrumentation and {Control} {System} {Failures} in {Nuclear} {Power} {Plants}},
	url = {https://www.nrc.gov/docs/ml0037/ML003757315.pdf},
	abstract = {Examination of the Licensee Event Report (LER) database, by the Office of Nuclear Regulatory Research, provides a snapshot of instrumentation and control (I\&C) impact on plant safety. The LER database consists of all reportable events that could affect the safety of Nuclear Power Plants. The LER database study uncovered digital I\&C vulnerabilities in nuclear power plants from operational experience. This study considered digital-related LERs for a five-year period, starting in 1994. The LER study places LERs in three categories: hardware, software, and human/system interface (HSI). Analysis showed an nearly equal distribution of events in each of the three categories. The analysis also showed that approximately 8\% of all LERs, from 1994 to 1999, contain digital I\&C failures, and 9\% of reactor trips for those years are attributed to digital I\&C failures. Detailed examination of the digital I\&C failures emphasizes that a significant percentage of the failures occurs as a result of failures in the requirements and Verification and Validation life-cycle stages. This database study shows I\&C systems, including digital I\&C systems, have a noticeable impact on nuclear power plant safety.},
	language = {en},
	publisher = {USNRC},
	author = {Brill, Robert W},
}

@book{bao_quantitative_2021,
	title = {Quantitative {Risk} {Analysis} of {High} {Safety}-significant {Safety}-related {Digital} {Instrumentation} and {Control} {Systems} in {Nuclear} {Power} {Plants} using {IRADIC} {Technology}},
	abstract = {This report documents the activities performed by Idaho National Laboratory (INL) during Fiscal Year (FY) 2021 for the U.S. Department of Energy (DOE) Light Water Reactor Sustainability (LWRS) Program, Risk Informed Systems Analysis (RISA) Pathway, digital instrumentation and control (DI\&C) risk assessment project. In FY-2019, the RISA Pathway initiated a project to develop a risk assessment strategy for delivering a strong technical basis to support effective, licensable, and secure DI\&C technologies for digital upgrades/designs. An integrated risk assessment technology for the DI\&C systems (IRADIC technology) was proposed for this strategy, which aims to (1) provide a best-estimate, risk-informed capability to quantitatively and accurately estimate the safety margin obtained from plant modernization, especially for the High Safety-significant Safety-related (HSSSR) DI\&C systems, (2) develop an advanced risk assessment technology to support transition from analog to DI\&C technologies for nuclear industry, (3) assure the long-term safety and reliability of vital HSSSR DI\&C systems, (4) reduce uncertainty in costs and support integration of DI\&C systems in the plant.
To achieve these technical goals and deal with the expensive licensing justifications from regulatory insights, the IRADIC technology is instructive for nuclear vendors and utilities on how to effectively lower the costs associated with digital compliance and speed industry advances by: (1) defining an integrated risk-informed analysis process for DI\&C upgrade, including hazard analysis, reliability analysis, and consequence analysis, (2) applying systematic and risk-informed tools to address common cause failures (CCFs) and quantify responding failure probabilities for DI\&C technologies, particularly software CCFs, (3) evaluating the impact of digital failures at the individual level, system level, and plant level, (4) providing insights and suggestions on designs to manage the risks, thus to support the development, licensing, and deployment of advanced DI\&C technologies on nuclear power plant (NPPs).
Many efforts from regulatory, industrial, and academic communities have been made for qualitatively addressing CCFs in DI\&C systems, especially software CCFs, given the increased designs and deployment of HSSSR DI\&C systems in NPPs. These efforts provide a technical basis for dealing with potential software CCF in the HSSSR DI\&C systems of NPPs; however, some technical challenges remain:
(1) Is qualitative evaluation sufficient for addressing software CCFs in HSSSR DI\&C systems?
(2) How to quantitatively evaluate CCF-related impacts to HSSSR DI\&C systems and entire plant response?
(3) How to efficiently identify the most significant CCFs, especially software CCFs?
(4) How to perform a complete reliability analysis for large-scale HSSSR DI\&C systems with small-scale software/digital units?
(5) Lastly, a need clearly exists to develop a risk assessment strategy to support quantitative defense-in-depth and diversity (D3) analyses for assuring the long-term safety and reliability of vital digital systems and reducing uncertainties in costs, time, and support the integration of digital systems during the plant’s design stage.
To deal with the technical issues in addressing potential software CCF in HSSSR DI\&C systems of NPPs, the IRADIC technology provides:
(1) An integrated and best-estimate, risk-informed capability to address new technical digital issues quantitatively, accurately, and efficiently in plan modernization progress, such as software CCFs in HSSSR DI\&C systems of NPPs.
(2) A common and modularized platform for DI\&C designers, software developers, plant engineers and risk analysts to efficiently prevent and mitigate risk by identifying crucial failure modes and system vulnerabilities, quantifying DI\&C system reliability, and evaluating the consequences of digital failures on the plant responses.
(3) A technical basis and risk-informed insights to assist Nuclear Regulatory Commission (NRC) and industry in formalizing relevant licensing processes relevant to CCF issues in HSSSR DI\&C systems.
(4) An integrated risk-informed tool for vendors and utilities to meet the regulatory requirements and optimize the D3 applications in the design of HSSSR DI\&C systems.
In this report, an approach for performing software CCF analysis, given limited data, is developed and demonstrated using a case study of a highly redundant digital reactor trip system. Consequence analysis is also performed based on different accident scenarios. Results indicate plant modernization including the improvement of HSSSR DI\&C systems will make great benefits to plant safety by providing more safety margins to accident management. In addition, a novel approach is proposed in this report for the quantification of software hazards when sufficient operational and testing data available. The method incorporates software development quality as well as strong analysis techniques to identify and link software defects to potential failure modes. The approach includes both semantic and test-based analysis to detect failures that can exist in different stages of the software development life cycle. This method is applied to an advanced human-system interface relevant to reactor trip safety developed from the design of Advanced Power Reactor 1400 MW (APR-1400).},
	author = {Bao, Han and Shorthill, Tate and Zhang, Hongbin},
	month = sep,
	year = {2021},
}

@article{shorthill_redundancy-guided_2021,
	title = {A {Redundancy}-{Guided} {Approach} for the {Hazard} {Analysis} of {Digital} {Instrumentation} and {Control} {Systems} in {Advanced} {Nuclear} {Power} {Plants}},
	volume = {208},
	doi = {10.1080/00295450.2021.1957659},
	abstract = {Digital instrumentation and control (I\&C) upgrades are a vital research area for the nuclear industry. Despite their performance benefits, deployment of digital I\&C in nuclear power plants (NPPs) has been limited. Digital I\&C systems exhibit complex failure modes including common cause failures (CCFs), which can be difficult to identify. This paper describes the development of a redundancy-guided application of the Systems-Theoretic Process Analysis and fault tree analysis for the hazard analysis of digital I\&C in advanced NPPs. The resulting Redundancy-Guided Systems-Theoretic Hazard Analysis (RESHA) is applied for the case study of a representative state-of-the-art digital reactor trip system. The analysis qualitatively and systematically identifies the most critical CCFs and other hazards of digital I\&C systems. Ultimately, the RESHA can help researchers make informed decisions for how, and to what degree, defensive measures such as redundancy, diversity, and defense in depth can be used to mitigate or eliminate the potential hazards of digital I\&C systems.},
	journal = {Nuclear Technology},
	author = {Shorthill, Tate and Bao, Han and Zhang, Hongbin and Ban, Heng},
	month = nov,
	year = {2021},
	pages = {1--20},
}

@inproceedings{bragg-sitton_reactor_2004,
	address = {Albuquerque, New Mexico (USA)},
	title = {Reactor {Start}-up and {Control} {Methodologies}: {Consideration} of the {Space} {Radiation} {Environment}},
	volume = {699},
	shorttitle = {Reactor {Start}-up and {Control} {Methodologies}},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1649623},
	doi = {10.1063/1.1649623},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Bragg-Sitton, Shannon M.},
	year = {2004},
	note = {ISSN: 0094243X},
	pages = {614--622},
}

@article{garg_human_2023,
	title = {Human reliability analysis studies from simulator experiments using {Bayesian} inference},
	volume = {229},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183202200463X},
	doi = {10.1016/j.ress.2022.108846},
	abstract = {Probabilistic Safety Assessment (PSA) of complex facilities is performed to arrive at the risk posed by them. PSA also accounts for the contribution of the human errors towards the overall risk through Human Reliability Analysis (HRA) in terms of Human Error Probability (HEP). Human operators are part of the system and do not work in isolation. Their performance is influenced by the context in which the actions are performed. As a result, quantification of HEP requires operator performance data under the given context. Some good sources of operator performance data are plant's operation data, simulator data and expert judgement. The plant operation data pertaining to HRA is generally sparse. In this situation, a full scope plant simulator provides a good alternative for operator performance data generation. Many of the currently practised HRA methods have been developed by combining the empirical evidence with expert judgement and contain a lot of uncertainty in their estimates. Bayesian inference is suitable for updating the prior HRA estimates with the simulator evidence to obtain the posterior HEP. In this study, posterior HEP has been calculated for postulated accident scenarios in advanced reactor (first of its kind) at design stage, using plant simulator.},
	language = {en},
	urldate = {2022-10-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Garg, Vipul and Vinod, Gopika and Prasad, Mahendra and Chattopadhyay, J. and Smith, Curtis and Kant, Vivek},
	month = jan,
	year = {2023},
	keywords = {Bayesian Inference, Human Reliability Analysis, Probabilistic Safety Assessment},
	pages = {108846},
}

@article{sakurahara_simulation-informed_2019,
	title = {Simulation-{Informed} {Probabilistic} {Methodology} for {Common} {Cause} {Failure} {Analysis}},
	volume = {185},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018302734},
	doi = {10.1016/j.ress.2018.12.007},
	abstract = {Common Cause Failures (CCFs) are critical risk contributors in complex technological systems as they challenge multiple redundant systems simultaneously. To improve the CCF analysis in Probabilistic Risk Assessment (PRA), this research develops the Simulation-Informed Probabilistic Methodology (S-IPM) for CCFs. This new methodology utilizes simulation models of physical failure mechanisms to capture underlying causalities and to generate simulation-based data for the CCF probability estimation. To operationalize the S-IPM in PRA, a computational algorithm is developed that generates simulation-based estimates of CCF parameters and, using the Bayesian approach, integrates them with the data-driven CCF parameters (if relevant data available) from the existing PRA. This computational algorithm is equipped with the Probabilistic Validation that quantiﬁes the degree of conﬁdence in the simulation-based parameter estimates by characterizing and propagating epistemic uncertainty in multiple levels of analysis. The S-IPM can (i) provide more realistic CCF probability estimates by considering CCF data generated from simulations; (ii) reﬂect as-built, as-operated plant conditions, considering the updates in design, operational, and maintenance policies; and (iii) contribute to more eﬀective prevention and mitigation of CCFs by providing “cause-speciﬁc” quantitative risk insights. The paper shows a case study that applies S-IPM to the CCFs of emergency service water pumps of NPPs.},
	language = {en},
	urldate = {2022-10-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Sakurahara, Tatsuya and Schumock, Grant and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	month = may,
	year = {2019},
	pages = {84--99},
}

@techreport{irfan_ahmed_implementation_nodate,
	title = {Implementation of {PID} and {Deadbeat} {Controllers} with the {TMS320} {Family}},
	url = {https://www.ti.com/lit/an/spra083/spra083.pdf},
	abstract = {This report discusses implementation of the PID and deadbeat controllers with the TMS320 family of DSPs. These application- specific processors are designed to process signals, including control signals, very efficiently.
The report covers the following topics:
q Control Systems
n Analog Controllers
n Digital Controllers
n Analog versus Digital Controllers
q Processor Selection Issues n DSP Architectures
q Design of Digital Control Systems
n Discretization of Analog Systems n Plant Modeling
n Digital Controller design
n Design and Implementation of PID Controllers n Deadbeat
q
q
q
Implementing Digital Controllers
n Finite Wordlength Effects
n Fixed-Point versus Floating-Point Arithmetic Processors n Sampling Rate Selection
n Controller Design Tools
n Hardware Design
Applications
n Computer Peripherals n Power Electronics
n Automotive
Summary and References
The report also q Appendix A q Appendix B q Appendix C q Appendix D q Appendix E
includes the following appendixes: Plant Modeling
PID Controller
Deadbeat Controller
PC-Matlab Design and Display Programs TMS320C15 Assembly Code},
	number = {SPRA083},
	institution = {Texas Instruments},
	author = {{Irfan Ahmed}},
	pages = {59},
}

@misc{the_westinghouse_nuclear_corporation_the_westinghouse_pressurized_water_reactpdf_2005,
	title = {the\_westinghouse\_pressurized\_water\_react.pdf},
	language = {English},
	publisher = {The Westinghouse Nuclear Corporation},
	author = {The Westinghouse Nuclear Corporation},
	year = {2005},
}

@article{groen_qrasquantitative_2006,
	title = {{QRAS}—the quantitative risk assessment system},
	volume = {91},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832005000463},
	doi = {10.1016/j.ress.2005.01.008},
	language = {en},
	number = {3},
	urldate = {2022-10-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Groen, Frank J. and Smidts, Carol and Mosleh, Ali},
	month = mar,
	year = {2006},
	pages = {292--304},
}

@phdthesis{morozov_dual-graph_2012,
	type = {{PhD} {Thesis}},
	title = {Dual-graph model for error propagation analysis of mechatronic systems},
	author = {Morozov, Andrey},
	month = jul,
	year = {2012},
}

@article{aldemir_survey_2013,
	title = {A survey of dynamic methodologies for probabilistic safety assessment of nuclear power plants},
	volume = {52},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645491200271X},
	doi = {10.1016/j.anucene.2012.08.001},
	abstract = {Dynamic methodologies for probabilistic safety assessment (PSA) are deﬁned as those which use a timedependent phenomenological model of system evolution along with its stochastic behavior to account for possible dependencies between failure events. Over the past 30 years, numerous concerns have been raised in the literature regarding the capability of the traditional static modeling approaches such as the event-tree/fault-tree methodology to adequately account for the impact of process/hardware/software/ﬁrmware/human interactions on the stochastic system behavior. A survey of the types of dynamic PSA methodologies proposed to date is presented, as well as a brief summary of an example application for the PSA modeling of a digital feedwater control system of an operating pressurized water reactor. The use of dynamic methodologies for PSA modeling of passive components and phenomenological uncertainties are also discussed.},
	language = {en},
	urldate = {2022-10-03},
	journal = {Annals of Nuclear Energy},
	author = {Aldemir, Tunc},
	month = feb,
	year = {2013},
	pages = {113--124},
}

@misc{noauthor_survey_nodate,
	title = {A survey of dynamic methodologies for probabilistic safety assessment of nuclear power plants {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S030645491200271X?token=8EFCCF91483ED7F2778051A5F3D7068129247DD0AF783E30B235A148C3C2304DA519BB5F14A1F4039002454849C24749&originRegion=us-east-1&originCreation=20221003170431},
	language = {en},
	urldate = {2022-10-03},
	doi = {10.1016/j.anucene.2012.08.001},
}

@article{kim_system_2021,
	title = {System risk quantification and decision making support using functional modeling and dynamic {Bayesian} network},
	volume = {215},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832021003999},
	doi = {10.1016/j.ress.2021.107880},
	abstract = {Risk-informed decision-making requires a probabilistic assessment of the likelihood of success of control action, given the system status. This paper presents a systematic state transition modeling approach integrating dynamic probabilistic risk assessment with a decision-making process using a dynamic Bayesian network (DBN) coupled with functional modeling. A functional model designed with multilevel flow modeling (MFM) technique was used to build a system state structure inferred by energy, mass, and information flow so that one can verify the developed model with respect to system functionality. The MFM model represents the causal relationship among the nodes, which captures the structure of process parameters and control units. Each node may have multiple possible states, and the DBN structured by the MFM model represents the time-domain transitions among the defined states. The MFM-DBN integrated state transition modeling is a white-box approach that allows one to draw the system's risk profile by updating the system states and supports the decisions probabilistically with physical inference. An example of a simple heating system has been used to illustrate this process, including decision-making support based on quantitative risk profile. For demonstrating its applicability to a complex system operational decision making, a case study of station blackout accident scenario leading to the seal loss of coolant accident in a nuclear power plant is presented. The proposed approach effectively provided the risk profile along time for each option so that the operators can make the best decision, which minimizes the plant risk.},
	language = {en},
	urldate = {2022-10-03},
	journal = {Reliability Engineering \& System Safety},
	author = {Kim, Junyung and Zhao, Xingang and Shah, Asad Ullah Amin and Kang, Hyun Gook},
	month = nov,
	year = {2021},
	keywords = {Decision-making, Dynamic Bayesian network, Dynamic PRA, Functional modeling, Multilevel Flow Modeling, Probabilistic mapping technique},
	pages = {107880},
}

@inproceedings{mattenberger_comparative_2015,
	title = {Comparative analysis of static and dynamic probabilistic risk assessment},
	doi = {10.1109/RAMS.2015.7105120},
	abstract = {This study examines three different methodologies for producing loss-of-mission (LOM) and loss-of-crew (LOC) risks estimates for probabilistic risk assessments (PRA) of crewed spacecraft. The three bottom-up, component-based PRA approaches examined are a traditional static fault tree, a dynamic Monte Carlo simulation, and a fault tree hybrid that incorporates some dynamic elements. These approaches were used to model the reaction control system thruster pod of a generic crewed spacecraft and mission, and a comparative analysis of the methods is presented. The methodologies are assessed in terms of the process of modeling a system, the actionable information produced for the design team, and the overall fidelity of the quantitative risk evaluation generated. The system modeling process is compared in terms of the effort required to generate the initial model, update the model in response to design changes, and support mass-versus-risk trade studies. The results are compared by examining the top-level LOM/LOC estimates and the relative risk driver rankings at the failure mode level. The fidelity of each modeling methodology is discussed in terms of its capability to handle real-world system dynamics such as cold-sparing, changes in mission operations due to loss of redundancy, and common cause failure modes. The paper also discusses the applicability of each methodology to different phases of system development and shows that a single methodology may not be suitable for all of the many purposes of a spacecraft PRA. The fault tree hybrid approach is shown to be best suited to the needs of early assessments during conceptual design phases. As the design begins to mature, the level of detail represented in the risk model must go beyond redundancy and nominal mission operations to include dynamic, time- and state-dependent system responses as well as diverse system capabilities. This is best accomplished using the dynamic simulation approach, since these phenomena are not easily captured by static methods. Ultimately, once the design has been finalized and the goal of the PRA is to provide design validation and requirement verification, more traditional, static fault tree approaches may become as appropriate as the simulation method.},
	booktitle = {2015 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	author = {Mattenberger, Chris and Mathias, Donovan L. and Go, Susie},
	month = jan,
	year = {2015},
	note = {ISSN: 0149-144X},
	keywords = {Crewed Spacecraft, Dynamic PRA, Fault trees, Monte Carlo methods, Orbits, Risk-Informed Design, Space Exploration, Space vehicles, Subspace constraints, Valves, Vehicle dynamics},
	pages = {1--6},
}

@article{mandelli_measuring_2019,
	title = {Measuring risk-importance in a {Dynamic} {PRA} framework},
	volume = {128},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454918306996},
	doi = {10.1016/j.anucene.2018.12.035},
	abstract = {Risk Importance Measures (RIMs) are indexes that are used to rank Structures, Systems, and Components (SSCs). The most used measures are: Risk Reduction Worth, Risk Achievement Worth, Birnbaum and Fussell-Vesely. Once obtained from Classical Probabilistic Risk Assessment (PRA), these risk measures can be effectively employed to identify the most risk-important SSCs. The objective of this paper is to present a series of methods that can be employed to measure risk importance of SSCs from Dynamic PRA. In contrast to Classical PRA methods, Dynamic PRA methods couple stochastic models with system simulators to determine risk associated to complex systems such as nuclear plants. Compared to Classical PRA methods, Dynamic PRA approaches can evaluate with higher resolution the safety impact of timing and sequencing of events on the accident progression. The developed set of RIMs are directly derived from Classical RIMs and adapted to deal with simulation-based data. We present a series of analytical tests to show how RIMs can be obtained from a Dynamic PRA data and a comparison of the RIMs obtained from Classical and Dynamic PRA for a Large Break Loss Of Coolant Accident (LB-LOCA) initiating event of a Pressurized Water Reactor (PWR). The obtained results have highlighted differences among the two PRA approaches in the predicted final outcome of few accident sequences. This have consequently affected the risk importance of a subset of basic events.},
	language = {en},
	urldate = {2022-10-03},
	journal = {Annals of Nuclear Energy},
	author = {Mandelli, D. and Ma, Z. and Parisi, C. and Alfonsi, A. and Smith, C.},
	month = jun,
	year = {2019},
	keywords = {Dynamic PRA, Probabilistic Risk Assessment, Risk Importance Measures},
	pages = {160--170},
}

@article{jensen_activation_1985,
	title = {Activation energies and the arrhenius equation},
	volume = {1},
	issn = {07488017, 10991638},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qre.4680010104},
	doi = {10.1002/qre.4680010104},
	language = {en},
	number = {1},
	urldate = {2022-10-01},
	journal = {Quality and Reliability Engineering International},
	author = {Jensen, Finn},
	month = jan,
	year = {1985},
	pages = {13--17},
}

@techreport{acosta_dynamic_1991,
	type = {Final {Report}},
	title = {Dynamic {Event} {Tree} {Analysis} {Method} ({DETAM}) for {Accident} {Sequence} {Analysis}},
	number = {NRC-04-88-143},
	institution = {Massachusetts Institute of Technology},
	author = {Acosta, C.G and Siu, N.O},
	month = oct,
	year = {1991},
	pages = {170},
}

@article{refaul_ferdous_handling_2009,
	title = {Handling {Data} {Uncertainties} in {Event} {Tree} {Analysis}},
	volume = {87},
	url = {https://pdf.sciencedirectassets.com/276831/1-s2.0-S0957582009X00054/1-s2.0-S095758200900072X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIAWFcd%2Fr6%2BxtTwmmcfgF2Syj2yqNOiXCyupwmbAcNzXdAiEA%2BzuMb%2BpybEqw77F6wcbWwMYatEMYkwGvDcKJpbfCM1cqzAQIXRAFGgwwNTkwMDM1NDY4NjUiDD73%2FGan5UNnrLVnvCqpBEyMMv5E06iBP04P%2Fuok4ghOe9mPIVbCbZ83VXk%2FbW1eUYdMDBI%2FRoHL5%2BWer3jwzUSmafKgr8s9wpvA8jgpeQk5Diuo%2BLKr9oHe2hSM79%2B49ldlBTNfkIe4gZYwOUikbI3wtkVjXWK7mILxD2%2BV6qD5eWX%2B1LHLJKooAqpGIrIv2RZr0yUBv2a6LKkbbsNF25LxKg35ATZ18d%2Bo6mzsoyuHsCHlgs7dpOM5jmIocjgMbJCSjTZBbAyCFgLVJBiClx5Forc9x3vi4aeLW7tX3pyHLXL3mqDILIsmDHU0gw5i8xI4DPpeD5aJ2KfVx8BLBgQK3H84AaUNVrR8CVAc%2BMP4Q6pCJ978WerPTVA3l9eIobw9pc1vavBAOL28ORhg%2B0l5zMVpdCE1JbBvfMx7M4CemOBPXvFqc%2FYIoglu96vHHqFJVIGzpqXYsbOmcvS1zCic7IaCNdgb3BcKOVpkab%2BJ3Z7g9VThKhGON7UlmMLBIDa9mIs2mPQDSR2%2FUuvWSE0eMBWZUdZiowomPEszIWIoXsZX%2B%2FpqZhwYydCV%2F%2FJI2FvlQ8kn3YqXK6bZiImtFdrbACj6kt0nBu4OK72qvv3%2F4daEq6uYZFRgnpZ4H5MiIHnT6uVcoDspqMNJV%2FQoXVHWlJggsJ90mJ%2FDJdsGR9ETkWlmkzKNDtevIYSrfx1VU4dF6r6fxNl%2B0ALsm1zALIP5FP891soxQ7y6aiqTE7KeRwgWTtLAmYswyrjbmQY6qQGBojgviKbEyLYY36Cb2guGvH47hOl19YGqU%2BOLJeaB2VuAB3orCjFBtWLPsIpxAoRueKy2Vt2UsDqj510Q%2BpOgNvHacGm3akj8fsuY7KvSzO6LkGSwVjQikN%2BFfFEFOBB9IrlNkc9ZrKj%2F5hAcm6PXAaqBmip%2BLK%2F8HYlfMDpTziX%2BJXLvjGrTZG%2B0g0MyJa2O85j7AhekRsFDcVNZDYv5ILuXa8V0yYZ9&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220930T134613Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYRWVUFY4R%2F20220930%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=22a7b6edfb5a7e567c0962f0a19de8ccac4be5b3c4740275df959235c7d10cdf&hash=1a36c82790479aa8dcd45881868952276ea5715189d640a7436c0b30e93994ba&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S095758200900072X&tid=spdf-67fc2db0-1471-473f-ab5e-f057a0b2ba9b&sid=f38a067e55bca24dd55b483199e967f65a65gxrqa&type=client&ua=515150055756545e5704&rr=752d67489c587fbb},
	doi = {10.1016/j.psep.2009.07.003},
	number = {5},
	journal = {Process Safety and Environmental Protection},
	author = {{Refaul Ferdous} and {Faisal Khan} and {Rehan Sadiq} and {Paul Amyotte} and {Brian Veitch}},
	month = sep,
	year = {2009},
	pages = {283--292},
}

@article{alfonsi_risk_2022,
	title = {Risk analysis virtual {ENvironment} for dynamic event tree-based analyses},
	volume = {165},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921006307},
	doi = {10.1016/j.anucene.2021.108754},
	abstract = {Conventional Event-Tree (ET) based methodologies are extensively used as tools to perform reliability and safety assessment of complex and critical engineering systems. One of the disadvantages of these methods is that timing/sequencing of events and system dynamics is not explicitly accounted for in the analysis. In order to overcome these limitations several techniques, also known as Dynamic Probabilistic Risk Assessment (DPRA), have been developed. Monte-Carlo (MC) and Dynamic Event Tree (DET) are two of the most widely used DPRA methodologies to perform safety assessment of Nuclear Power Plants (NPP). Since 2012, the Idaho National Laboratory (INL) is developing its own tool to perform Dynamic PRA: RAVEN (Risk Analysis and Virtual ENvironment). RAVEN has been designed in a high modular and pluggable way to enable easy integration of different programming languages (i.e., Python, C++) and coupling with other application including, among the others, several thermal–hydraulic and severe accident codes (e.g., RELAP5-3D, MELCOR, MAAP5, TRACE, etc.). RAVEN is aimed to provide a framework/container of capabilities for engineers and scientists to analyze the response of systems, physics and multi-physics, employing advanced numerical techniques and algorithms. Moreover, RAVEN models stochastic events, such as components failures, and performs uncertainty quantiﬁcation (UQ). Such stochastic modeling is employed by using sampling strategies among which both MC and DET algorithms, which are going to be employed in this paper. In addition, RAVEN processes the large amount of data generated by sampling the physical models using data-mining based algorithms and risk assessment techniques. This paper provides an overview of the DET methodologies that have been deployed within the RAVEN framework, showing the potential of such techniques for the analysis of complex systems. A brief background of classical methodologies and their limitation is also reported and represent the motivation for the deployment of such dynamic technique. In addition, results from a pressurized water reactor loss of coolant accident scenario, using RELAP5-3D as physical model, are reported.},
	language = {en},
	urldate = {2022-09-30},
	journal = {Annals of Nuclear Energy},
	author = {Alfonsi, Andrea and Mandelli, Diego and Parisi, Carlo and Rabiti, Cristian},
	month = jan,
	year = {2022},
	pages = {108754},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC}: {Package} {ML13261A532} - {AREVA} {Design} {Control} {Document} {Rev}. 5 - {Tier} 2 {Chapter} 06 - {Engineered} {Safety} {Features}},
	url = {https://www.nrc.gov/docs/ML1326/ML13261A532.html},
	urldate = {2022-09-29},
}

@article{caruso_approach_1999,
	title = {An approach for using risk assessment in risk-informed decisions on plant-specific changes to the licensing basis},
	volume = {63},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832098000386},
	doi = {10.1016/S0951-8320(98)00038-6},
	abstract = {This paper discusses an acceptable approach that the US Nuclear Regulatory Commission staff has proposed for using Probabilistic Risk Assessment in making decisions on changes to the licensing basis of a nuclear power plant. First, the overall philosophy of risk-informed decision-making, and the process framework are described. The philosophy is encapsulated in five principles, one of which states that, if the proposed change leads to an increase in core damage frequency or risk, the increases must be small and consistent with the intent of the Nuclear Regulatory Commission's Safety Goal Policy Statement. The second part of the paper discusses the use of PRA to demonstrate that this principle has been met. The discussion focuses on the acceptance guidelines, and on comparison of the PRA results with those guidelines. The difficulties that arise because of limitations in scope and analytical uncertainties are discussed and approaches to accommodate these difficulties in the decision-making are described.},
	language = {en},
	number = {3},
	urldate = {2022-09-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Caruso, Mark A and Cheok, Michael C and Cunningham, Mark A and Holahan, Gary M and King, Thomas L and Parry, Gareth W and Ramey-Smith, Ann M and Rubin, Mark P and Thadani, Ashok C},
	month = mar,
	year = {1999},
	keywords = {Acceptance criteria, Decision-making, Probability risk assessment, Risk informed regulation, Uncertainty},
	pages = {231--242},
}

@article{kadak_nuclear_2007,
	series = {Recent {Advances} in {Theory} \& {Applications} of {Stochastic} {Point} {Process} {Models} in {Reliability} {Engineering}},
	title = {The nuclear industry's transition to risk-informed regulation and operation in the {United} {States}},
	volume = {92},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183200600055X},
	doi = {10.1016/j.ress.2006.02.004},
	abstract = {This paper summarizes a study of the transition of the United States nuclear industry from a prescriptive regulatory structure to a more risk informed approach to operations and regulations. The transition occurred over a 20yr period in which gradual changes were made in the fundamental regulations and to the approach to nuclear safety and operations. While the number of actual regulatory changes were few, they are continuing. The utilities that embraced risk informed operations made dramatic changes in the way they approached operations and outage management. Those utilities that used risk in operations showed dramatic improvement in safety based on Institute of Nuclear Power Operations (INPO) performance indicators. It was also shown that the use of risk did not negatively affect safety performance of the plants compared to standard prescriptive approaches. This was despite having greater flexibility in compliance to regulatory standards and the use of the newly instituted risk-informed reactor oversight process. Key factors affecting the successful transition to a more risk-informed approach to regulations and operations are: strong top management support and leadership both at the regulator and the utility; education and training in risk principles and probabilistic risk Assessment tools for engineers, operators and maintenance staff; a slow and steady introduction of risk initiatives in areas that can show value to both the regulator and the industry; a transparent regulatory foundation built around a safety goal policy and the development of a strong safety culture at the utility to allow for more independence in safety compliance and risk management. The experience of the United States shows positive results in both safety and economics. The INPO and NRC metrics presented show that the use of risk information in operations and regulation is marginally better with no degradation in safety when plants that have embraced risk-informed approaches are compared to those that have not. The use of risk-informed approaches allows both the regulator and the industry to focus on important safety issues. The transition to risk-informed regulation also required a “culture change” by both the regulators and the utilities. Caution should be taken, however, since the basis of the US transition to risk-informed regulation is founded on a long history of a regulatory structure and practices that have matured the industry to a point where the next step could be taken.},
	language = {en},
	number = {5},
	urldate = {2022-09-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Kadak, Andrew C. and Matsuo, Toshihiro},
	month = may,
	year = {2007},
	keywords = {Configuration risk management, Risk-informed regulation, Safety metrics},
	pages = {609--618},
}

@article{turyshev_support_2012,
	title = {Support for the {Thermal} {Origin} of the {Pioneer} {Anomaly}},
	volume = {108},
	issn = {0031-9007, 1079-7114},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.108.241101},
	doi = {10.1103/PhysRevLett.108.241101},
	language = {en},
	number = {24},
	urldate = {2022-09-27},
	journal = {Physical Review Letters},
	author = {Turyshev, Slava G. and Toth, Viktor T. and Kinsella, Gary and Lee, Siu-Chun and Lok, Shing M. and Ellis, Jordan},
	month = jun,
	year = {2012},
	pages = {241101},
}

@article{reay_fault_2002,
	title = {A fault tree analysis strategy using binary decision diagrams},
	volume = {78},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832002001072},
	doi = {10.1016/S0951-8320(02)00107-2},
	abstract = {The use of binary decision diagrams (BDDs) in fault tree analysis provides both an accurate and efﬁcient means of analysing a system. There is a problem, however, with the conversion process of the fault tree to the BDD. The variable ordering scheme chosen for the construction of the BDD has a crucial effect on its resulting size and previous research has failed to identify any scheme that is capable of producing BDDs for all fault trees. This paper proposes an analysis strategy aimed at increasing the likelihood of obtaining a BDD for any given fault tree, by ensuring the associated calculations are as efﬁcient as possible. The method implements simpliﬁcation techniques, which are applied to the fault tree to obtain a set of ‘minimal’ subtrees, equivalent to the original fault tree structure. BDDs are constructed for each, using ordering schemes most suited to their particular characteristics. Quantitative analysis is performed simultaneously on the set of BDDs to obtain the top event probability, the system unconditional failure intensity and the criticality of the basic events. q 2002 Published by Elsevier Science Ltd.},
	language = {en},
	number = {1},
	urldate = {2022-09-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Reay, Karen A. and Andrews, John D.},
	month = oct,
	year = {2002},
	pages = {45--56},
}

@article{cojazzi_dylam_1996,
	title = {The {DYLAM} approach for the dynamic reliability analysis of systems},
	volume = {52},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832095001395},
	doi = {10.1016/0951-8320(95)00139-5},
	language = {en},
	number = {3},
	urldate = {2022-09-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Cojazzi, Giacomo},
	month = jun,
	year = {1996},
	pages = {279--296},
}

@inproceedings{farshadmanesh_risk-informed_2020,
	title = {Risk-{Informed} {Analysis} of {Nuclear} {Power} {Plant} {FLEX} {Storage} {Building}},
	isbn = {9789811485930},
	url = {http://rpsonline.com.sg/proceedings/9789811485930/html/4557.xml},
	doi = {10.3850/978-981-14-8593-0_4557-cd},
	language = {en},
	urldate = {2021-09-01},
	booktitle = {Proceedings of the 30th {European} {Safety} and {Reliability} {Conference} and 15th {Probabilistic} {Safety} {Assessment} and {Management} {Conference}},
	publisher = {Research Publishing Services},
	author = {Farshadmanesh, Pegah and Sakurahara, Tatsuya and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	year = {2020},
	pages = {2437--2443},
}

@book{todreas_nuclear_2011,
	title = {Nuclear {Systems} {Volume} {I}: {Thermal} {Hydraulic} {Fundamentals}, {Second} {Edition}},
	isbn = {978-1-4398-0888-7},
	shorttitle = {Nuclear {Systems} {Volume} {I}},
	abstract = {Nuclear power is in the midst of a generational change-with new reactor designs, plant subsystems, fuel concepts, and other information that must be explained and explored-and after the 2011 Japan disaster, nuclear reactor technologies are, of course, front and center in the public eye. Written by leading experts from MIT, Nuclear Systems Volume I:},
	language = {en},
	publisher = {CRC Press},
	author = {Todreas, Neil E. and Kazimi, Mujid},
	month = nov,
	year = {2011},
	note = {Google-Books-ID: SAvMBQAAQBAJ},
	keywords = {Arjun's Library - Physical Copy, Science / Energy, Science / Mechanics / Thermodynamics, Technology \& Engineering / Civil / General, Technology \& Engineering / Mechanical},
}

@book{sehgal_nuclear_2012,
	address = {Amsterdam; Boston},
	title = {Nuclear safety in light water reactors: severe accident phenomenology},
	isbn = {978-0-12-388446-6},
	shorttitle = {Nuclear safety in light water reactors},
	abstract = {This vital reference is the only one-stop resource on how to assess, prevent, and manage severe nuclear accidents in the light water reactors (LWRs) that pose the most risk to the public. LWRs are the predominant nuclear reactor in use around the world today, and they will continue to be the most frequently utilized in the near future. Therefore, accurate determination of the safety issues associated with such reactors is central to a consideration of the risks and benefits of nuclear power. This book emphasizes the prevention and management of severe accidents, in order to teach nuclear professionals how to mitigate potential risks to the public to the maximum extent possible. Engineers, researchers, students and the personnel of vendors, safety authorities and nuclear power generation organizations require the knowledge offered by this volume's globally renowned experts to ensure they obtain a core competency in nuclear safety. Organizes and presents all the latest thought on LWR nuc.},
	language = {English},
	publisher = {Elsevier/Academic Press},
	author = {Sehgal, Bal Raj},
	year = {2012},
	note = {OCLC: 731925452},
	keywords = {Arjun's Library - Physical Copy},
}

@book{lewis_fundamentals_2008,
	address = {Amsterdam ; Boston},
	title = {Fundamentals of nuclear reactor physics},
	isbn = {978-0-12-370631-7},
	publisher = {Academic Press},
	author = {Lewis, E. E.},
	year = {2008},
	note = {OCLC: ocn150330792},
	keywords = {Arjun's Library - Physical Copy, Nuclear physics, Problems, exercises, etc},
}

@book{shultis_fundamentals_2017,
	address = {Boca Raton},
	edition = {Third edition},
	title = {Fundamentals of nuclear science and engineering},
	isbn = {978-1-4987-6929-7},
	publisher = {CRC Press},
	author = {Shultis, J. Kenneth and Faw, Richard E.},
	year = {2017},
	keywords = {Arjun's Library - Physical Copy, Nuclear engineering},
}

@inproceedings{morozov_openerrorpro_2019,
	address = {Berlin, Germany},
	title = {{OpenErrorPro}: {A} {New} {Tool} for {Stochastic} {Model}-{Based} {Reliability} and {Resilience} {Analysis}},
	isbn = {978-1-72814-982-0},
	shorttitle = {{OpenErrorPro}},
	url = {https://ieeexplore.ieee.org/document/8987451/},
	doi = {10.1109/ISSRE.2019.00038},
	urldate = {2020-12-10},
	booktitle = {2019 {IEEE} 30th {International} {Symposium} on {Software} {Reliability} {Engineering} ({ISSRE})},
	publisher = {IEEE},
	author = {Morozov, Andrey and Ding, Kai and Steurer, Mikael and Janschek, Klaus},
	month = oct,
	year = {2019},
	pages = {303--312},
}

@book{chacon_pro_2014,
	address = {New York, NY},
	edition = {Second edition},
	series = {The expert's voice in software development},
	title = {Pro {Git}},
	isbn = {978-1-4842-0077-3},
	publisher = {Apress},
	author = {Chacon, Scott},
	year = {2014},
	keywords = {Distributed processing, Electronic data processing, Git (Computer file)},
}

@book{duerr_probabilistic_2020,
	title = {Probabilistic {Deep} {Learning}: {With} {Python}, {Keras} and {TensorFlow} {Probability}.},
	isbn = {978-1-61729-607-9},
	shorttitle = {Probabilistic {Deep} {Learning}},
	language = {English},
	publisher = {Manning Publications Company},
	author = {Duerr, Oliver},
	year = {2020},
	note = {OCLC: 1153054277},
	keywords = {Arjun's Library - Physical Copy},
}

@article{moormann_caution_2018,
	title = {Caution {Is} {Needed} in {Operating} and {Managing} the {Waste} of {New} {Pebble}-{Bed} {Nuclear} {Reactors}},
	volume = {2},
	issn = {25424351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2542435118303350},
	doi = {10.1016/j.joule.2018.07.024},
	language = {en},
	number = {10},
	urldate = {2021-10-10},
	journal = {Joule},
	author = {Moormann, Rainer and Kemp, R. Scott and Li, Ju},
	month = oct,
	year = {2018},
	pages = {1911--1914},
}

@article{siu_bayesian_1998,
	title = {Bayesian parameter estimation in probabilistic risk assessment},
	volume = {62},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832097001592},
	doi = {10.1016/S0951-8320(97)00159-2},
	language = {en},
	number = {1-2},
	urldate = {2022-08-28},
	journal = {Reliability Engineering \& System Safety},
	author = {Siu, Nathan O. and Kelly, Dana L.},
	month = oct,
	year = {1998},
	pages = {89--116},
}

@article{watanabe_development_2003,
	title = {Development of the {DQFM} method to consider the effect of correlation of component failures in seismic {PSA} of nuclear power plant},
	abstract = {This paper presents a new calculation method for considering the effect of correlation of component failures in seismic probabilistic safety assessment (PSA) of nuclear power plants (NPPs) by direct quantiﬁcation of Fault Tree (FT) using the Monte Carlo simulation (DQFM) and discusses the effect of correlation on core damage frequency (CDF).},
	language = {en},
	author = {Watanabe, Yuichi and Oikawa, Tetsukuni and Muramatsu, Ken},
	year = {2003},
	pages = {15},
}

@inproceedings{wang_design_2016,
	title = {Design of the {Spent} {Fuel} {Storage} {Well} of {HTR}-{PM}},
	url = {http://materialstechnology.asmedigitalcollection.asme.org/ICONE/proceedings/ICONE24/50015/V001T03A003/251531},
	doi = {10.1115/ICONE24-60051},
	language = {en},
	urldate = {2022-08-16},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Wang, Jinhua and Wang, Bing and Wu, Bin and Li, Yue},
	month = oct,
	year = {2016},
	keywords = {Accident prevention, Air intakes, Boiling water reactors, Coolants, Digital control systems, Fuel storage, Gas cooled reactors, Heat shielding, High temperature reactors, Hot air heating, Lakes, Loss of coolant accidents, Nuclear energy, Nuclear fuel elements, Nuclear power plants, Pebble bed modular reactors, Pressurized water reactors, Radioactive waste encapsulation, Radioactive waste storage, Residual fuels, Spent fuels, Statistical mechanics, Ventilation},
}

@techreport{diaconeasa_development_2017,
	address = {Los Angeles, CA},
	title = {Development and {Demonstration} of a {Software} {Platform} for {System} {Reliability} {Analysis}},
	number = {GIRS-2017-02},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Stewart, Theresa and Vaiz-Gomez, Joseph and Gupta, Nilesh and Poornaki, Z. M. and Mosleh, Ali},
	year = {2017},
}

@article{mandelli_scenario_2013,
	title = {Scenario clustering and dynamic probabilistic risk assessment},
	volume = {115},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832013000483},
	doi = {10.1016/j.ress.2013.02.013},
	language = {en},
	urldate = {2022-03-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Mandelli, Diego and Yilmaz, Alper and Aldemir, Tunc and Metzroth, Kyle and Denning, Richard},
	month = jul,
	year = {2013},
	keywords = {Dynamic PRA, Scenario clustering, Transient analysis},
	pages = {146--160},
}

@article{harp_analysis_2014,
	title = {An analysis of nuclear fuel burnup in the {AGR}-1 {TRISO} fuel experiment using gamma spectrometry, mass spectrometry, and computational simulation techniques},
	volume = {278},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549314004555},
	doi = {10.1016/j.nucengdes.2014.07.041},
	abstract = {AGR-1 was the first in a series of experiments designed to test US TRISO fuel under high temperature gas-cooled reactor irradiation conditions. This experiment was irradiated in the Advanced Test Reactor (ATR) at Idaho National Laboratory (INL) and is currently undergoing post-irradiation examination (PIE) at INL and Oak Ridge National Laboratory. One component of the AGR-1 PIE is the experimental evaluation of the burnup of the fuel by two separate techniques. Gamma spectrometry was used to non-destructively evaluate the burnup of all 72 of the TRISO fuel compacts that comprised the AGR-1 experiment. Two methods for evaluating burnup by gamma spectrometry were developed, one based on the Cs-137 activity and the other based on the ratio of Cs-134 and Cs-137 activities. Burnup values determined from both methods compared well with the values predicted from simulations. The highest measured burnup was 20.1\% FIMA (fissions per initial heavy metal atom) for the direct method and 20.0\% FIMA for the ratio method (compared to 19.56\% FIMA from simulations). An advantage of the ratio method is that the burnup of the cylindrical fuel compacts can be determined in small (2.5mm) axial increments and an axial burnup profile can be produced. Destructive chemical analysis by inductively coupled mass spectrometry (ICP-MS) was then performed on selected compacts that were representative of the expected range of fuel burnups in the experiment to compare with the burnup values determined by gamma spectrometry. The compacts analyzed by mass spectrometry had a burnup range of 19.3\% FIMA to 10.7\% FIMA. The mass spectrometry evaluation of burnup for the four compacts agreed well with the gamma spectrometry burnup evaluations and the expected burnup from simulation. For all four compacts analyzed by mass spectrometry, the maximum range in the three experimentally determined values and the predicted value was 6\% or less. The results confirm the accuracy of the nondestructive burnup evaluation from gamma spectrometry for TRISO fuel compacts across a burnup range of approximately 10–20\% FIMA and also validate the approach used in the physics simulation of the AGR-1 experiment.},
	language = {en},
	urldate = {2022-03-08},
	journal = {Nuclear Engineering and Design},
	author = {Harp, Jason M. and Demkowicz, Paul A. and Winston, Philip L. and Sterbentz, James W.},
	month = oct,
	year = {2014},
	pages = {395--405},
}

@article{moieni_advances_1994,
	title = {Advances in human reliability analysis methodology. {Part} {II}: {PC}-based {HRA} software},
	volume = {44},
	issn = {09518320},
	shorttitle = {Advances in human reliability analysis methodology. {Part} {II}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832094901066},
	doi = {10.1016/0951-8320(94)90106-6},
	language = {en},
	number = {1},
	urldate = {2021-11-08},
	journal = {Reliability Engineering \& System Safety},
	author = {Moieni, P. and Spurgin, A.J. and Singh, A.},
	month = jan,
	year = {1994},
	pages = {57--66},
}

@book{noauthor_advanced_2017,
	series = {Modern {Nuclear} {Energy} {Analysis} {Methods}},
	title = {Advanced {Concepts} in {Nuclear} {Energy} {Risk} {Assessment} and {Management}},
	volume = {Volume 1},
	isbn = {978-981-322-560-2},
	url = {https://doi.org/10.1142/10587},
	number = {Volume 1},
	urldate = {2021-09-13},
	publisher = {WORLD SCIENTIFIC},
	month = apr,
	year = {2017},
	doi = {10.1142/10587},
}

@article{kancev_plant-specific_2020,
	title = {A plant-specific {HRA} sensitivity analysis considering dynamic operator actions and accident management actions},
	volume = {52},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573319308988},
	doi = {10.1016/j.net.2020.02.021},
	abstract = {The human reliability analysis is a method by which, in general terms, the human impact to the safety and risk of a nuclear power plant operation can be modelled, quantified and analysed. It is an indispensable element of the PSA process within the nuclear industry nowadays. The paper herein presents a sensitivity study of the human reliability analysis performed on a real nuclear power plant–specific probabilistic safety assessment model. The analysis is performed on a pre-selected set of post-initiator operator actions. The purpose of the study is to investigate the impact of these operator actions on the plant risk by altering their corresponding human error probabilities in a wide spectrum. The results direct the fact that the future effort should be focused on maintaining the current human reliability level, i.e. not letting it worsen, rather than improving it.},
	language = {en},
	number = {9},
	urldate = {2021-09-17},
	journal = {Nuclear Engineering and Technology},
	author = {Kančev, Duško},
	month = sep,
	year = {2020},
	keywords = {Accident management actions, Dynamic operator actions, Human reliability analysis, Nuclear power plants, Probabilistic safety assessment},
	pages = {1983--1989},
}

@article{khalil_novel_2016,
	title = {A novel probabilistically timed dynamic model for physical security attack scenarios on critical infrastructures},
	volume = {102},
	issn = {0957-5820},
	url = {https://www.sciencedirect.com/science/article/pii/S0957582016300477},
	doi = {10.1016/j.psep.2016.05.001},
	abstract = {This study proposes a novel probabilistically timed dynamic model for physical security attack scenarios on critical infrastructures (CIs). The model simulates attacker's attempts to compromise exploitable vulnerabilities in targeted CIs. Attacker's times to successfully compromise physical barriers, intrusion detection systems, and standby safety systems are modeled as random variables represented by user-defined probability distributions. The model assumes a highly skilled attacker, tracks his cumulative time to compromise targeted assets relative to an estimated mission time, and calculates mission success probability under imperfect information. The model uses Monte Carlo sampling technique to propagate uncertainties of input parameters to calculate statistics of mission success probability. Model's utility is demonstrated by a postulated case study in which an attacker attempts to launch undetected and unmitigated fire in 1-out-of-4 protected areas within a chemical process plant. Destroying one of these protected areas represents attacker's mission success in disrupting plant operation in addition to causing property damage. Visual flowcharting and dynamic attack tree logic are used to describe systematic execution of the attack. Simulation results show 64.4\% mission success probability with 4.7\% standard deviation. Benefits of proposed model include its use in security training to quantify probabilistic outcomes of “what if” scenarios, uncover exploitable vulnerabilities, and implement defensive strategies to improve CI's resilience under attack. The modeling framework can be extended to cyber security applications.},
	language = {en},
	urldate = {2022-08-02},
	journal = {Process Safety and Environmental Protection},
	author = {Khalil, Y. F.},
	month = jul,
	year = {2016},
	keywords = {Critical infrastructures, High-value assets, Mission time, Physical security, Probabilistic models, Time to compromise},
	pages = {473--484},
}

@article{keller_historical_2005,
	title = {A historical overview of probabilistic risk assessment development and its use in the nuclear power industry: a tribute to the late {Professor} {Norman} {Carl} {Rasmussen}},
	volume = {89},
	issn = {09518320},
	shorttitle = {A historical overview of probabilistic risk assessment development and its use in the nuclear power industry},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832004002327},
	doi = {10.1016/j.ress.2004.08.022},
	abstract = {This paper reviews the historical development of the probabilistic risk assessment (PRA) methods and applications in the nuclear industry. A review of nuclear safety and regulatory developments in the early days of nuclear power in the United States has been presented. It is argued that due to technical difﬁculties for measuring and characterizing uncertainties and concerns over legal challenges, safety design and regulation of nuclear power plants has primarily relied upon conservative safety assessment methods derived based on a set of design and safety principles. Further, it is noted that the conservatism adopted in safety and design assessments has allowed the use of deterministic performance assessment methods. This approach worked successfully in the early years of nuclear power epoch as the reactor design proved to be safe enough. However, it has been observed that as the conservative approach to design and safety criteria proved arbitrary, and yielded inconsistencies in the degree to which different safety measures in nuclear power plants protect safety and public heath, the urge for a more consistent assessment of safety became apparent in the late 1960s. In the early 1970s, as a result of public and political pressures, then the US Atomic Energy Commission initiated a new look at the safety of the nuclear power plants through a comprehensive study called ‘Reactor Safety Study’ (WASH-1400, or ‘Rasmussen Study’—after its charismatic study leader Professor Norman Rasmussen of MIT) to demonstrate safety of the nuclear power plants. Completed in October 1975, this landmark study introduced a novel probabilistic, systematic and holistic approach to the assessment of safety, which ultimately resulted in a sweeping paradigm shift in safety design and regulation of nuclear power in the United States in the turn of the Century. Technical issues of historic signiﬁcance and concerns raised by the subsequent reviews of the Rasmussen Study have been discussed. Effect of major events and developments such as the Three Mile Island accident and the Nuclear Regulatory Commission and the Nuclear Industry sponsored studies on the tools, techniques and applications of the PRA that culminated in the present day risk-informed initiatives has been discussed.},
	language = {en},
	number = {3},
	urldate = {2022-02-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Keller, William and Modarres, Mohammad},
	month = sep,
	year = {2005},
	pages = {271--285},
}

@article{groth_hybrid_2019,
	title = {A hybrid algorithm for developing third generation {HRA} methods using simulator data, causal models, and cognitive science},
	volume = {191},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832018312456},
	doi = {10.1016/j.ress.2019.106507},
	abstract = {Over the past 10 years, there have been significant international efforts to modernize Human Reliability Analysis (HRA), with most efforts focused on one of two directions: developing new sources of HRA data from control room simulators, and developing new HRA methods based in cognitive science. However, these efforts have proceeded largely independently, and there has been little research into how to leverage these scientific advances in data together with the scientific advances in modeling and methods. This is a significant gap for HRA, and motivates a need for methodologies to unify the efforts of the modeling and data collection communities. In this paper we define a comprehensive hybrid algorithm for using causal models and multiple types of HRA data to provide a rigorous quantitative basis for cognitively based Human Reliability Analysis (HRA) methods such as PHOENIX and IDHEAS. The algorithm uses causal models built from and parameterized by a combination of data from cognitive literature, systems engineering, existing HRA methods, simulator data, and expert elicitation. The main elements of the hybrid algorithm include a comprehensive set of causal factors, human–machine team tasks and events, Bayesian Network causal models, and Bayesian parameter updating methods. The algorithm enhances both the qualitative and the quantitative basis of HRA, adding significant scientific depth and technical traceability to the highly complicated problem of modeling human–machine team failures in complex engineering systems.},
	language = {en},
	urldate = {2021-11-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina M. and Smith, Reuel and Moradi, Ramin},
	month = nov,
	year = {2019},
	keywords = {Bayesian networks, Bayesian updating, HRA Data, Human reliability analysis, Macro cognitive function},
	pages = {106507},
}

@article{zhang_dynamic_2019,
	title = {A dynamic human reliability assessment approach for manned submersibles using {PMV}-{CREAM}},
	volume = {11},
	issn = {2092-6782},
	url = {https://www.sciencedirect.com/science/article/pii/S2092678218302772},
	doi = {10.1016/j.ijnaoe.2019.03.002},
	abstract = {Safety is always acritical focus of exploration of ocean resources, and it is well recognized that human factor is one of the major causes of accidents and breakdowns. Our research developed a dynamic human reliability assessment approach, Predicted Mean Vote-Cognitive Reliability and Error Analysis Method (PMV-CREAM), that is applicable to monitoring the cognitive reliability of oceanauts during deep-sea missions. Taking into account the difficult and variable operating environment of manned submersibles, this paper analyzed the cognitive actions of oceanauts during the various procedures required by deep-sea missions, and calculated the PMV index using human factors and dynamic environmental data. The Cognitive Failure Probabilities (CFP) were calculated using the extended CREAM approach. Finally, the CFP were corrected using the PMV index. This PMV-CREAM hybrid model can be utilized to avoid human error in deep-sea research, thereby preventing injury and loss of life during undersea work. This paper verified the method with “Jiaolong” manned submersible 7,000 m dive test. The“Jiaolong” oceanauts CR(Corrected CFP) is dynamic from 3.0615E-3 to 4.2948E-3, the CR caused by the environment is 1.2333E-3. The result shown the PMV-CREAM method could describe the dynamic human reliability of manned submersible caused by thermal environment.},
	language = {en},
	number = {2},
	urldate = {2021-10-22},
	journal = {International Journal of Naval Architecture and Ocean Engineering},
	author = {Zhang, Shuai and He, Weiping and Chen, Dengkai and Chu, Jianjie and Fan, Hao},
	month = jul,
	year = {2019},
	keywords = {Cognitive behavior, Deep sea exploration, Human Reliability Analysis (HRA), Human factors, Manned submersible, Predicted Mean Vote (PMV)},
	pages = {782--795},
}

@article{garrick_decision_1999,
	title = {A {Decision} {Theory} {Perspective} on the {Disposal} of {High}-{Level} {Radioactive} {Waste}},
	volume = {19},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1999.tb00450.x},
	doi = {10.1111/j.1539-6924.1999.tb00450.x},
	abstract = {In this paper the problem of high level nuclear waste disposal is viewed as a five-stage, cascaded decision problem. The first four of these decisions having essentially been made, the work of recent years has been focused on the fifth stage which concerns specifics of the repository design. The probabilistic performance assessment (PPA) work is viewed as the outcome prediction for this stage, and the site characterization work as the information gathering option. This brief examination of the proposed Yucca Mountain repository through a decision analysis framework resulted in three conclusions: 1) a decision theory approach to the process of selecting and characterizing Yucca Mountain would enhance public understanding of the issues and solutions to high level waste management; 2) engineered systems are an attractive alternative to offset uncertainties in the containment capability of the natural setting and should receive greater emphasis in the design of the repository; 3) a strategy of “waste management” should be adopted, as opposed to “waste disposal,” as it allows for incremental confirmation and confidence building of a permanent solution to the high level waste problem.},
	language = {en},
	number = {5},
	urldate = {2022-02-14},
	journal = {Risk Analysis},
	author = {Garrick, B. John and Kaplan, Stan},
	month = oct,
	year = {1999},
	keywords = {Nuclear waste, Yucca Mountain, engineered barriers, highlevel waste, performance assessment, probability, repository, risk},
	pages = {903--913},
}

@article{gil_code_2011,
	series = {International {Conference} on {Nuclear} {Energy} for {New} {Europe} 2009},
	title = {A code for simulation of human failure events in nuclear power plants: {SIMPROC}},
	volume = {241},
	issn = {0029-5493},
	shorttitle = {A code for simulation of human failure events in nuclear power plants},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549310002529},
	doi = {10.1016/j.nucengdes.2010.03.040},
	abstract = {Over the past years, many Nuclear Power Plant organizations have performed Probabilistic Safety Assessments to identify and understand key plant vulnerabilities. As part of enhancing the PSA quality, the Human Reliability Analysis is essential to make a realistic evaluation of safety and about the potential facility's weaknesses. Moreover, it has to be noted that HRA continues to be a large source of uncertainty in the PSAs. Within their current joint collaborative activities, Indizen, Universidad Politécnica de Madrid and Consejo de Seguridad Nuclear have developed the so-called SIMulator of PROCedures (SIMPROC), a tool aiming at simulate events related with human actions and able to interact with a plant simulation model. The tool helps the analyst to quantify the importance of human actions in the final plant state. Among others, the main goal of SIMPROC is to check the Emergency Operating Procedures being used by operating crew in order to lead the plant to a safe shutdown plant state. Currently SIMPROC is coupled with the SCAIS software package (Izquierdo et al., 2008), but the tool is flexible enough to be linked to other plant simulation codes. SIMPROC–SCAIS applications are shown in the present article to illustrate the tool performance. The applications were developed in the framework of the Nuclear Energy Agency project on Safety Margin Assessment and Applications (SM2A). First an introductory example was performed to obtain the damage domain boundary of a selected sequence from a SBLOCA. Secondly, the damage domain area of a selected sequence from a loss of Component Cooling Water with a subsequent seal LOCA was calculated. SIMPROC simulates the corresponding human actions in both cases. The results achieved shown how the system can be adapted to a wide range of purposes such as Dynamic Event Tree delineation, Emergency Operating Procedures and damage domain search.},
	language = {en},
	number = {4},
	urldate = {2021-09-11},
	journal = {Nuclear Engineering and Design},
	author = {Gil, Jesús and Fernández, Iván and Murcia, Santiago and Gomez, Javier and Marrão, Hugo and Queral, César and Expósito, Antonio and Rodríguez, Gabriel and Ibañez, Luisa and Hortal, Javier and Izquierdo, José M. and Sánchez, Miguel and Meléndez, Enrique},
	month = apr,
	year = {2011},
	pages = {1097--1107},
}

@article{yoon_case_2018,
	title = {A case study of time-dependent risk informed integrated safety assessment under complex accident sequences},
	volume = {333},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318303820},
	doi = {10.1016/j.nucengdes.2018.03.044},
	abstract = {A time-dependent risk informed integrated safety assessment methodology is suggested to evaluate the response of nuclear power plants under complex accident sequences caused by failures of multiple safety features. Event propagation is modeled based on the combination of deterministic and probabilistic safety assessment methods, with results representing changes in plant risk over time. Operators can utilize the time-dependent risk information as a quantitative basis, and results can determine the degree of safety enhancement by the improvement of emergency operator action procedures or by strengthening the design of safety features. The concepts of consequential failure probability and point-estimate failure time are introduced. The consequential failure probability, calculated from central limit theorem, identiﬁes the key safety system and provides a precise risk calculation. The point-estimate failure time, using non-parametric order statistics, justiﬁes the crediting of emergency operator actions. As a case study, risk of large early radioactive release due to pressure-induced multiple steam generator tube rupture following main steam line break accident in Advanced Power Reactor 1400 is considered. Results are used to discuss the credibility of operator mitigation actions, and a remedy to enhance plant safety to satisfy safety goals is suggested.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Yoon, Kyung-min and Kang, Hyun-gook},
	month = jul,
	year = {2018},
	keywords = {Central limit theorem, Complex accident sequences, Consequential failure probability, Containment bypass accident, Design extension conditions, Failures of multiple engineered safety features, Non-parametric order statistics, Point-estimate failure time, Time-dependent risk informed integrated safety assessment},
	pages = {63--75},
}

@article{wang_bayesian_2021,
	title = {A {Bayesian} network for reliability assessment of man-machine phased-mission system considering the phase dependencies of human cognitive error},
	volume = {207},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020308735},
	doi = {10.1016/j.ress.2020.107385},
	abstract = {Existing researches on the reliability assessment of phased-mission systems (PMSs) focus mainly on the phase dependencies of the machine state. However, with regard to the man-machine PMS (MMPMS), it also has non-negligible phase dependencies of human cognitive error. For example, the error of omission in previous phase may result in an identical error if the operator experiences a similar working scenario in a subsequent phase. To address the phase dependencies of human cognitive error, a novel method for the reliability assessment of MMPMS is proposed. First, the phase dependencies of human cognitive error are analyzed and categorized into four types based on the framework of situation awareness. A decision tree is then developed to quantify the dependence level. Second, the Bayesian network (BN) is used to construct the system reliability model for each phase from the perspective of mental model. Subsequently, the phase dependencies of machine state and of human cognitive error are mapped to BN to integrate constructed single-phase models as a multi-phase system reliability model. Third, the reliability of MMPMS can be assessed based on the conditional probabilities of all the nodes. Finally, the proposed method is exemplified with a multi-phase reconnaissance mission of an unmanned aerial vehicle.},
	language = {en},
	urldate = {2021-09-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Wang, Zengkai and Zeng, Shengkui and Guo, Jianbin and Che, Haiyang},
	month = mar,
	year = {2021},
	keywords = {Bayesian network, Cognitive error, Man-machine system, Phased-mission system, Reliability assessment},
	pages = {107385},
}

@misc{noauthor_atlas_nodate,
	title = {Atlas {V}},
	url = {https://www.ulalaunch.com/rockets/atlas-v},
	urldate = {2021-07-23},
}

@article{ruijters_fault_2015,
	title = {Fault tree analysis: {A} survey of the state-of-the-art in modeling, analysis and tools},
	volume = {15-16},
	issn = {1574-0137},
	url = {https://www.sciencedirect.com/science/article/pii/S1574013715000027},
	doi = {10.1016/j.cosrev.2015.03.001},
	abstract = {Fault tree analysis (FTA) is a very prominent method to analyze the risks related to safety and economically critical assets, like power plants, airplanes, data centers and web shops. FTA methods comprise of a wide variety of modeling and analysis techniques, supported by a wide range of software tools. This paper surveys over 150 papers on fault tree analysis, providing an in-depth overview of the state-of-the-art in FTA. Concretely, we review standard fault trees, as well as extensions such as dynamic FT, repairable FT, and extended FT. For these models, we review both qualitative analysis methods, like cut sets and common cause failures, and quantitative techniques, including a wide variety of stochastic methods to compute failure probabilities. Numerous examples illustrate the various approaches, and tables present a quick overview of results.},
	journal = {Computer Science Review},
	author = {Ruijters, Enno and Stoelinga, Mariëlle},
	month = feb,
	year = {2015},
	keywords = {Dependability evaluation, Dynamic Fault Trees, Fault trees, Graphical models, Reliability, Risk analysis},
	pages = {29--62},
}

@article{mosleh_critique_1988,
	title = {A critique of current practice for the use of expert opinions in probabilistic risk assessment},
	volume = {20},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/0951832088900063},
	doi = {10.1016/0951-8320(88)90006-3},
	abstract = {This paper critically reviews and evaluates the elicitation and use of expert opinion in probabilistic risk assessment (PRA) of nuclear power plants in light of the available empirical and theoretical results on expert opinion use. PRA practice is represented by four case studies selected to represent a variety of aspects of the problem: 1.⊗ Assessments of component failure rates and maintenance data.2.⊗ An assessment of seismic hazard rates.3.⊗ Assessments of containment phenomenology.4.⊗ Accident precursor studies. The review has yielded mixed results. On the negative side, there appears to be little reliance on normative expertise in structuring the process of expert opinion elicitation and use; most applications instead rely primarily on the common sense of the experts involved in the analysis, which is not always an adequate guide. On the positive side, however, there is evidence that expert opinions can, in fact, be used well in practical settings.},
	language = {en},
	number = {1},
	urldate = {2022-09-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Mosleh, A. and Bier, V. M. and Apostolakis, G.},
	month = jan,
	year = {1988},
	pages = {63--85},
}

@article{bucci_construction_2008,
	title = {Construction of event-tree/fault-tree models from a {Markov} approach to dynamic system reliability},
	volume = {93},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832008000343},
	doi = {10.1016/j.ress.2008.01.008},
	abstract = {While the event-tree (ET)/fault-tree (FT) methodology is the most popular approach to probability risk assessment (PRA), concerns have been raised in the literature regarding its potential limitations in the reliability modeling of dynamic systems. Markov reliability models have the ability to capture the statistical dependencies between failure events that can arise in complex dynamic systems. A methodology is presented that combines Markov modeling with the cell-to-cell mapping technique (CCMT) to construct dynamic ETs/FTs and addresses the concerns with the traditional ET/FT methodology. The approach is demonstrated using a simple water level control system. It is also shown how the generated ETs/FTs can be incorporated into an existing PRA so that only the (sub)systems requiring dynamic methods need to be analyzed using this approach while still leveraging the static model of the rest of the system.},
	language = {en},
	number = {11},
	urldate = {2022-09-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Bucci, Paolo and Kirschenbaum, Jason and Mangan, L. Anthony and Aldemir, Tunc and Smith, Curtis and Wood, Ted},
	month = nov,
	year = {2008},
	pages = {1616--1627},
}

@article{zhang_current_2009,
	title = {Current status and technical description of {Chinese} 2 × 250 {MW} th {HTR}-{PM} demonstration plant},
	volume = {239},
	doi = {10.1016/j.nucengdes.2009.02.023},
	abstract = {After the nuclear accidents of Three Mile Island and Chernobyl the world nuclear community made great efforts to increase research on nuclear reactors and to develop advanced nuclear power plants with much improved safety features. Following the successful construction and a most gratifying operation of the 10 MWth high-temperature gas-cooled test reactor (HTR-10), the Institute of Nuclear and New Energy Technology (INET) of Tsinghua University has developed and designed an HTR demonstration plant, called the HTR-PM (high-temperature-reactor pebble-bed module). The design, having jointly been carried out with industry partners from China and in collaboration of experts worldwide, closely follows the design principles of the HTR-10.},
	journal = {Nuclear Engineering and Design - NUCL ENG DES},
	author = {Zhang, Zuoyi and Wu, Zongxin and Wang, Dazhong and Xu, Yuanhui and Sun, Yuliang and Li, Fu and Dong, Yujie},
	month = jul,
	year = {2009},
	pages = {1212--1219},
}

@techreport{hk_elder_assessment_1978,
	type = {Contract {Report}},
	title = {An {Assessment} of the {Risk} of {Transporting} {Spent} {Nuclear} {Fuel} by {Truck}},
	number = {PNL-2588},
	institution = {Pacific Northwest Laboratory},
	author = {{H.K Elder}},
	month = nov,
	year = {1978},
	pages = {318},
}

@phdthesis{michael_amos_nuclear_1975,
	title = {Nuclear {Aircraft} {Feasibility} {Study}},
	school = {Air Force Institute of Technology},
	author = {{Michael Amos} and {James Butt} and {Bruce Campbell} and {Richard Diehl} and {William Fanning}},
	month = mar,
	year = {1975},
}

@techreport{noauthor_hvac_1986,
	title = {{HVAC} [{Heating}, {Ventilation} and {Air} {Conditioning}] subsystem design description: 4 x 350 {MW}(t) {Modular} {HTGR} [{High}-{Temperature} {Gas}-{Cooled} {Reactor}] {Plant}},
	shorttitle = {{HVAC} [{Heating}, {Ventilation} and {Air} {Conditioning}] subsystem design description},
	url = {https://www.osti.gov/biblio/464351},
	abstract = {The HVAC system is a subsystem within the Mechanical Services Group (MSG). The HVAC system for the 4 x 350 MW(t) Modular HTGR Plant presently consists of ten, nonsafety-related subsystems located in the Nuclear Island (NI) and Energy Conversion Area (ECA) of the plant.},
	language = {English},
	number = {DOE/HTGR-87-055; HFD-49011},
	urldate = {2022-09-23},
	institution = {Stone and Webster Engineering Corp., Boston, MA (United States)},
	month = jun,
	year = {1986},
	doi = {10.2172/464351},
}

@article{deng_bdd_2015,
	title = {{BDD} algorithms based on modularization for fault tree analysis},
	volume = {85},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S014919701530024X},
	doi = {10.1016/j.pnucene.2015.06.019},
	abstract = {This paper explains a Binary Decision Diagram (BDD) algorithm based on modularization to solve a Fault Tree (FT) or Event Tree (ET) in Probabilistic Safety Assessment (PSA) of the nuclear power plant. Fault Tree Analysis (FTA) is a non-deterministic polynomial-time hard problem, both the complexity of the calculation and the large size of real models exponentially increase along with the number of variables, as well as the BDD structure which is transferred from FT model. When solving a large FT in BDD algorithm, two difﬁculties will be met: the memory is not enough to store large BDD structure and the process generates too much Minimal Cut Sets (MCSs) that is time consuming.},
	language = {en},
	urldate = {2022-09-21},
	journal = {Progress in Nuclear Energy},
	author = {Deng, Yunli and Wang, He and Guo, Biao},
	month = nov,
	year = {2015},
	pages = {192--199},
}

@article{sihombing_parallel_2018,
	title = {Parallel fault tree analysis for accurate reliability of complex systems},
	volume = {72},
	issn = {01674730},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167473017300875},
	doi = {10.1016/j.strusafe.2017.12.003},
	abstract = {Fault tree analysis is one of the methods for the probabilistic risk assessment of components and subsystems of nuclear power plants. The algorithms that solve a fault tree have been until now serial. Instead, this study presents new algorithms that handle and solve a fault tree by taking advantage of the new state of the art in parallel computing: general purpose graphic processor unit (GPGPU). The subsystems of nuclear power plants are the target of this study. However, the method can be used on many others, complex, engineering systems. The different, developed, parallel algorithms are: one builder, which assembles the topology matrix of the fault tree and leads the computation of the three, developed, new solvers. A bottom-up solver, a cut sets solver, and a Monte Carlo simulation solver. The probability of the top event, and the probabilities of each cut sets are computed. The results shows that, given the same investment, a GPU can handle larger fault trees than a CPU implementation. The developed solvers are the foundation of the next generation parallel algorithms for the tree-based analysis of complex systems.},
	language = {en},
	urldate = {2022-09-21},
	journal = {Structural Safety},
	author = {Sihombing, Fritz and Torbol, Marco},
	month = may,
	year = {2018},
	pages = {41--53},
}

@article{glickman_rerouting_1983,
	title = {Rerouting railroad shipments of hazardous materials to avoid populated areas},
	volume = {15},
	issn = {00014575},
	url = {https://linkinghub.elsevier.com/retrieve/pii/000145758390012X},
	doi = {10.1016/0001-4575(83)90012-X},
	abstract = {The casualty risk due to hazardous material releases from railroad cars in the U.S. is estimated for a recent year. Approximate flow patterns of hazardous materials in that year are generated using a national network model. Alternative flow patterns representing population-avoidance rerouting policies are also generated, and some aggregate impacts are estimated with and without track upgrading. We find that population exposure can be reduced 25-50\% by rerouting, at the cost of a 15-30\% increase in traffic circuity. We also formulate and apply a risk model which shows that extensive routing changes can reduce casualties by about 50\%, but that extensive upgrading with or without rerouting can be even more effective. The effects on urban areas of the hypothetical changes are discussed, but financial impacts on the railroads are not addressed.},
	language = {en},
	number = {5},
	urldate = {2022-09-21},
	journal = {Accident Analysis \& Prevention},
	author = {Glickman, Theodore S.},
	month = oct,
	year = {1983},
	pages = {329--335},
}

@misc{y_bechtel_saic_company_llc_bsc_canister_nodate,
	title = {Canister {Receipt} and {Closure} {Facility} {Reliability} and {Event} {Sequence} {Categorization} {Analysis}},
	url = {https://www.nrc.gov/docs/ML0921/ML092160697.pdf},
	language = {English},
	urldate = {2022-09-21},
	author = {y Bechtel SAIC Company, LLC (BSC)},
}

@article{wang_establishment_2019,
	title = {The {Establishment} of {Probabilistic} {Risk} {Assessment} {Analysis} {Methodology} for {Dry} {Storage} {Concrete} {Casks} {Using} {SAPHIRE} 8},
	volume = {13},
	url = {https://publications.waset.org/10009935/the-establishment-of-probabilistic-risk-assessment-analysis-methodology-for-dry-storage-concrete-casks-using-saphire-8},
	abstract = {The Establishment of Probabilistic Risk Assessment Analysis Methodology for Dry Storage Concrete Casks Using SAPHIRE 8},
	language = {en},
	number = {1},
	urldate = {2022-09-21},
	journal = {International Journal of Nuclear and Quantum Engineering},
	author = {Wang, J. R. and Cheng, W. Y. and Yeh, J. S. and Chen, S. W. and Ferng, Y. M. and Yang, J. H. and Hsu, W. S. and Shih, C.},
	month = jan,
	year = {2019},
	pages = {13--19},
}

@techreport{noauthor_chapter_nodate,
	title = {Chapter {One} {Introduction} and {General} {Description} of the {Plant}.pdf},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A481.pdf},
	urldate = {2022-09-20},
}

@techreport{noauthor_certified_nodate,
	title = {Certified {Design} {Descriptions} and {Inspections}, {Tests}, {Analyses}, \& {Acceptance} {Criteria} ({ITAAC}).pdf},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A480.pdf},
	urldate = {2022-09-20},
}

@article{amendola_accident_1988,
	title = {Accident sequence dynamic simulation versus event trees},
	volume = {22},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832088900658},
	doi = {10.1016/0951-8320(88)90065-8},
	language = {en},
	number = {1-4},
	urldate = {2022-09-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Amendola, A.},
	month = jan,
	year = {1988},
	pages = {3--25},
}

@book{petrangeli_nuclear_2020,
	address = {Oxford},
	edition = {Second edition},
	title = {Nuclear safety},
	isbn = {978-0-12-818326-7},
	language = {en},
	publisher = {Butterworth-Heinemann},
	author = {Petrangeli, Gianni},
	year = {2020},
}

@article{george_advanced_1987,
	title = {Advanced space propulsion concepts},
	volume = {16},
	issn = {0094-5765},
	url = {https://www.sciencedirect.com/science/article/pii/0094576587900993},
	doi = {10.1016/0094-5765(87)90099-3},
	abstract = {Demands are being made for higher performance, more durable, more flexible and lower cost propulsion systems to satisfy spacecraft launch and orbit transfer requirements. The Air Force Rocket Propulsion Laboratory is developing space propulsion having various attributes to meet the transport challenges imposed by modern spacecraft. Propulsion concepts, both chemical and nonchemical, are being developed and demonstrated to provide advanced systems for increasing the capabilities of existing and new spacecraft. Cryogenic (oxygen/hydrogen) propellant concepts that are being developed include a low thrust engine and compact cryogenic feed system. These provide substantial benefit to orbit transfer vehicles since they maximize both volume and weight to the payload carrying capability of the stage from low-earth to geosynchronous orbit. Studies and analyses indicate that this technology can provide a deployment stage that is 36 percent shorter than the Shuttle compatible Centaur and transfer nearly twice the payload to GEO. A modular storable space propulsion concept provides flexibility to size stages in a building block manner to satisfy payload requirements. Further, individual stage and integral propulsion options are made available. Analyses show that payload delivery capability can be increased over that of the Inertial Upper Stage by 140 percent while decreasing the transfer cost to GEO to 15. Nonchemical propulsion concept technologies include arcjet and solar thermal propulsion systems which can provide increased payload delivery to various orbits. The arcjet can provide 40 percent greater payload per launch than Centaur G'. Solar thermal can deliver at least twice the payload of an advanced cryogenic stage to GEO. Overview descriptions of the various propulsion concepts and their corresponding benefits to orbit transfer vehicles are presented.},
	language = {en},
	urldate = {2022-09-17},
	journal = {Acta Astronautica},
	author = {George, Daweel},
	month = jan,
	year = {1987},
	keywords = {Space propulsion, arcjet, cryogenic space engine, electric propulsion, modular storable, orbit transfer propulsion, solar thermal rocket propulsion},
	pages = {113--123},
}

@article{garshnek_crucial_1989,
	title = {Crucial factor: human: {Safely} extending the human presence in space},
	volume = {5},
	issn = {0265-9646},
	shorttitle = {Crucial factor},
	url = {https://www.sciencedirect.com/science/article/pii/0265964689900878},
	doi = {10.1016/0265-9646(89)90087-8},
	abstract = {The concept of advanced manned space missions has captured the interest and imagination of spacefaring nations. However, the physiological and psychological effects of space flight increase in magnitude and significance in the ‘extended time-in-space’ context. The unencumbered weightless condition enjoyed during short flights might compromise crew productivity upon return to a gravity field and extremely effective countermeasures may be essential. Missions remote from Earth require careful consideration of the medical facilities, psychological support and life support needed. The author discusses pressing issues that must be resolved before the visions of bolder human missions can be realistically fulfilled.},
	language = {en},
	number = {3},
	urldate = {2022-09-17},
	journal = {Space Policy},
	author = {Garshnek, V.},
	month = aug,
	year = {1989},
	pages = {201--216},
}

@article{solem_mission_1990,
	series = {11th {IFAC} {World} {Congress} on {Automatic} {Control}, {Tallinn}, 1990 - {Volume} 3, {Tallinn}, {Finland}},
	title = {Mission {Success} {Factor} {Determination}: {A} {New} {Method} for {Predicting} the {Probability} of {Achieving} {Successful} {Implementation} of {Missions} in {Space}},
	volume = {23},
	issn = {1474-6670},
	shorttitle = {Mission {Success} {Factor} {Determination}},
	url = {https://www.sciencedirect.com/science/article/pii/S1474667017518923},
	doi = {10.1016/S1474-6670(17)51892-3},
	abstract = {A recent Study (Ref. /1/) for the European Space Agency (ESA) carried out by the Norwegian Company DNV INDUSTRIAL DEVELOPMENT A/S - a subsidiary of Det norske Veritas - and the UK company VEGA Space Systems Engineering Ltd, resulted in a definition of a generic method for predicting the success probabilities of space missions. The end product of the prediction process is the so-called "Mission Success Factor" which is being labelled with confidence information. Mission success is defined as the complete fulfilment of all objectives of a space mission within a time and budget frame, without any loss of life or any unplanned loss of property. The Paper introduces:-Mission Success as a concept, and a definition of the Mission Success Factor (MSF) as a numerical utility measure as well as its way of computation,-the concept of Utilisation Factors (UF), how they are computed, and a procedure for the determination of source data,-a concept for consideration of Human Reliability contributions by means of Performance Shaping Factors (PSF) and their characterisation. It is expected that the Mission Success Factor method will, after possible final adjustments, become a tool for the systematic follow up of the evolution of the success probability of space missions throughout their entire life cycle, i.e. from the initial design stages of a spacecraft and the corresponding Ground Segment until completion of the mission.},
	language = {en},
	number = {8, Part 3},
	urldate = {2022-09-17},
	journal = {IFAC Proceedings Volumes},
	author = {Solem, R. R. and Wright, J. F. and Wimmer, W. H.},
	month = aug,
	year = {1990},
	keywords = {Ground support systems, hierarchical decision making, human factors, multiobjective optimization, probabilistic logic, sensitivity analysis, space vehicles, system failure and recovery},
	pages = {47--52},
}

@article{perek_safety_1985,
	title = {Safety of space activities},
	volume = {12},
	issn = {0094-5765},
	url = {https://www.sciencedirect.com/science/article/pii/0094576585900116},
	doi = {10.1016/0094-5765(85)90011-6},
	abstract = {Measures for the safety of space activities have to be elaborated by the scientific community. They should include principles for collision avoidance, possibly in the form of traffic separation schemes. A reduction of collision probabilities could be achieved by systematic removal of inactive satellites, by establishing disposal orbital belts and by reduction of space debris. Safety of space activities would be enhanced by the adoption of standards for the quality of technical equipment and for the competence of personnel. Also timely information on satellite movement should be made available.},
	language = {en},
	number = {1},
	urldate = {2022-09-17},
	journal = {Acta Astronautica},
	author = {Perek, Luboš},
	month = jan,
	year = {1985},
	pages = {67--69},
}

@article{baccini_hermes_1989,
	title = {Hermes safety and rescue},
	volume = {19},
	issn = {0094-5765},
	url = {https://www.sciencedirect.com/science/article/pii/0094576589900374},
	doi = {10.1016/0094-5765(89)90037-4},
	abstract = {The objective of this paper is to present the Hermes Flight Safety approach and to detail some of the solutions studied and currently envisaged for the crew rescue. The authors have on purpose limited the scope of such a wide subject to the following topics: safety policy, requirements and organization,preliminary analysis results,envisaged solutions: current status. Some significant results of studies carried out in industry are presented. They include a description of the most critical safety phases and the presentation of solutions, under analysis and evaluation, to reduce the identified risks. Specific attention is given to a crew escape and rescue system. The contents of this paper are the results of a joint effort made by the Agencies—ESA and CNES—and the two major Hermes contractors—Aerospatiale and Avions Marcel Dassault.},
	language = {en},
	number = {3},
	urldate = {2022-09-17},
	journal = {Acta Astronautica},
	author = {Baccini, H. and Charles, J. and Colrat, J. and Georges, J. F. and Marcoux, J. and Herholz, J.},
	month = mar,
	year = {1989},
	pages = {251--257},
}

@article{buden_nuclear_1988,
	title = {Nuclear rocket safety},
	volume = {18},
	issn = {00945765},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0094576588901026},
	doi = {10.1016/0094-5765(88)90102-6},
	language = {en},
	urldate = {2022-09-17},
	journal = {Acta Astronautica},
	author = {Buden, David},
	month = jan,
	year = {1988},
	pages = {217--224},
}

@phdthesis{sakurahara_integrated_nodate,
	title = {{INTEGRATED} {PROBABILISTIC} {RISK} {ASSESSMENT} ({I}-{PRA}) {METHODOLOGY} {AND} {COMPUTATIONAL} {PLATFORM} {FOR} {FIRE} {PRA} {OF} {NUCLEAR} {POWER} {PLANTS}},
	language = {en},
	author = {Sakurahara, Tatsuya},
}

@article{mercurio_for_nodate,
	title = {for the degree of {Doctor} of {Sciences}},
	language = {en},
	author = {Mercurio, Davide},
	pages = {266},
}

@article{zhan_hybrid_2022,
	title = {A hybrid method for signal probability and reliability estimation with combinational circuits},
	volume = {87},
	issn = {01679260},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167926022000876},
	doi = {10.1016/j.vlsi.2022.07.006},
	language = {en},
	urldate = {2022-09-13},
	journal = {Integration},
	author = {Zhan, Suoyue and Chen, Chunhong},
	month = nov,
	year = {2022},
	pages = {275--283},
}

@misc{noauthor_newsroom_nodate,
	title = {Newsroom — {X}-energy: {HTGR} {\textbar} {Nuclear} {Reactors} ({SMR}) \& {TRISO} {Fuel}},
	url = {https://x-energy.com/newsroom},
	urldate = {2022-09-12},
}

@article{noauthor_electric_nodate,
	title = {Electric {Power} {Annual} 2020},
	language = {en},
	pages = {239},
}

@misc{noauthor_us_nodate,
	title = {{US} {DOE} sets out supply chain strategy : {Energy} \& {Environment} - {World} {Nuclear} {News}},
	url = {https://www.world-nuclear-news.org/Articles/US-DOE-sets-out-supply-chain-strategy},
	urldate = {2022-09-09},
}

@techreport{usdoe_office_of_energy_efficiency_and_renewable_energy_eere_solar_technologies_office_americas_2022,
	title = {America's {Strategy} to {Secure} the {Supply} {Chain} for a {Robust} {Clean} {Energy} {Transition}},
	url = {https://www.osti.gov/servlets/purl/1871491/},
	language = {en},
	number = {None, 1871491},
	urldate = {2022-09-09},
	author = {{USDOE Office of Energy Efficiency and Renewable Energy (EERE), Solar Technologies Office} and {USDOE Office of Fossil Energy and Carbon Management, Division of Minerals Sustainability} and {USDOE Office of International Affairs, Office of International Market Development} and {USDOE Office of Cybersecurity, Energy Security, and Emergency Response} and {EERE Wind Energy Technology Office} and {USDOE Office of Nuclear Energy} and {USDOE Office of Technology Transitions} and {Office of the Under Secretary for Science and Energy} and {Hydrogen and Fuel Cell Technologies Office} and {USDOE Office of Electricity} and {Loan Programs Office} and {USDOE Office of the General Counsel} and Igogo, Tsisilile},
	month = feb,
	year = {2022},
	doi = {10.2172/1871491},
	pages = {None, 1871491},
}

@article{corynen_fast_nodate,
	title = {A {FAST} {BOTTOM}-{UP} {ALGORITHM} {FOR} {COMPUTING} {THE} {CUT} {SETS} {OF} {NONCOHERENT} {FAULT} {TREES}},
	abstract = {An efficient procedure for finding the cut sets of large fault trees has been developed. Designed to address coherent or noncoherent systems, dependent events, shared or common-cause events, the method-called SHORTCUT-is based on a fast algorithm for transforming a noncoherent tree into a quasi-coherent tree (COHERE), and on a new algorithm for reducing cut sets (SUBSET). To assure sufficient clarity and precision, the procedure is discussed in the language of simple sets, which is also developed in this report. Although the new method has not yet been fully implemented on the computer, we report theoretical worst-case estimates of its computational complexity.},
	language = {en},
	author = {Corynen, G C},
	pages = {64},
}

@article{ghaleh_pattern_2019,
	title = {Pattern of safety risk assessment in road fleet transportation of hazardous materials (oil materials)},
	volume = {116},
	url = {https://reader.elsevier.com/reader/sd/pii/S0925753518307422?token=0FFC6E6F86BBCDB6FECD8FCE149F735DB0E7EADF7F8046C904824A1B6EB93AB85B102914E46E77C908A3CF493F5B89E4&originRegion=us-east-1&originCreation=20220907203653},
	doi = {https://doi.org/10.1016/j.ssci.2019.02.039},
	language = {en},
	urldate = {2022-09-07},
	journal = {Safety Science},
	author = {Ghaleh, Sahar and {Manouchehr Omidvari} and {Parvin Nassiri} and Momeni, Mansour and Mohammadreza Miri Lavasani, Seyed},
	year = {2019},
	doi = {10.1016/j.ssci.2019.02.039},
	pages = {1--12},
}

@article{allen_transportation_1998,
	title = {Transportation of hazardous wastes},
	volume = {17},
	issn = {1547-5913},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/prs.680170112},
	doi = {10.1002/prs.680170112},
	abstract = {Risk assessments have been performed to determine the risk associated with the transportation of hazardous wastes through a city. In the course of these assessments, a number of modeling issues arose relating to transportation accident rates, the characterization of incidents, the effect of thermal radiation, the impact of exposure to toxic chemicals, and the threshold for acceptable risk. This paper discusses these issues.},
	language = {en},
	number = {1},
	urldate = {2022-09-07},
	journal = {Process Safety Progress},
	author = {Allen, David J. and Wolkstein, Melvin},
	year = {1998},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/prs.680170112},
	pages = {61--67},
}

@article{barkan_railroad_2003,
	title = {Railroad {Derailment} {Factors} {Affecting} {Hazardous} {Materials} {Transportation} {Risk}},
	volume = {1825},
	issn = {0361-1981},
	url = {https://doi.org/10.3141/1825-09},
	doi = {10.3141/1825-09},
	abstract = {U.S. freight railroad accident and hazardous materials release rates have declined substantially since 1980. Ironically, this trend has made the identification and implementation of further safety improvement options more challenging because less empirical information exists on which accident causes present the greatest risks. Consequently, more sophisticated methods are needed to identify the best options for transportation risk reduction. Of particular interest is identifying the principal causes of accidents that can result in a tank car release of hazardous materials, which can harm people, property, and the environment. Because large hazardous materials release accidents are relatively rare, railroads cannot effectively manage safety improvement efforts solely in response to the causes of specific accidents. Instead, a risk-based approach is needed to better understand predictive factors for conditions that can cause a release. Railroad derailment data were analyzed to identify the conditions most likely to lead to a release accident. The objective was to identify proxy variables that can be used as performance measures. The speed of derailment and number of derailed cars highly correlated with hazardous materials releases. Some accident causes are much more likely to lead to release conditions than others. Accident prevention efforts to reduce these causes are more likely to reduce the risk of major railroad hazardous materials release accidents.},
	number = {1},
	urldate = {2022-09-07},
	journal = {Transportation Research Record},
	author = {Barkan, Christopher P. L. and Dick, C. Tyler and Anderson, Robert},
	month = jan,
	year = {2003},
	note = {Publisher: SAGE Publications Inc},
	pages = {64--74},
}

@article{glickman_benchmark_1988,
	title = {Benchmark {Estimates} of {Release} {Accident} {Rates} in {Hazardous} {Materials} {Transportation} by {Rail} and {Truck}},
	volume = {1193},
	url = {https://onlinepubs.trb.org/Onlinepubs/trr/1988/1193/1193-003.pdf},
	language = {en},
	number = {1},
	journal = {TRANSPORTATION RESEARCH RECORD},
	author = {Glickman, Theodore S},
	year = {1988},
	pages = {22--28},
}

@article{ardeshir_faghri_reliability_1988,
	title = {Reliability and {Risk} {Assessment} in the {Prediction} of {Hazards} at {Rail}-{Highway} {Grade} {Crossings}},
	volume = {1160},
	url = {https://onlinepubs.trb.org/Onlinepubs/trr/1988/1160/1160-006.pdf},
	number = {1},
	journal = {Transportation Research Record},
	author = {{Ardeshir Faghri} and {Michael J. Demetsky}},
	year = {1988},
	pages = {45 -- 51},
}

@article{gabriele_landucci_hazmat_2017,
	title = {{HazMat} transportation risk assessment: {A} revisitation in the perspective of the {Viareggio} {LPG} accident},
	volume = {49},
	issn = {0950-4230},
	shorttitle = {{HazMat} transportation risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S0950423016302145},
	doi = {https://doi.org/10.1016/j.jlp.2016.08.009},
	abstract = {The Seveso accident triggered a virtuous process towards the development of methods, models and tools for safety and risk assessment and management. Among the more relevant results of such process was the stemming of methods and tools addressing the transportation of hazardous substances in the framework of a holistic approach to the control of major accident hazards related to dangerous substances. The present study aims at the analysis of reference procedures and tools available for the analysis of the risk in the transportation of dangerous substances in the light of the Viareggio accident. The Viareggio accident represents a paradigmatic event involving the transportation of dangerous substances. The accident, that took place in Italy in 2009, was analyzed in the perspective of current approaches to the analysis of risk in the transportation of hazardous materials. The results pointed out that the Viareggio scenario, although of particular severity, is comprised within those accounted in quantitative risk analysis.},
	language = {en},
	number = {A},
	urldate = {2022-09-07},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {{Gabriele Landucci} and {Giacomo Antonioni} and {Alessandro Tugnoli} and {Sarah Bonvicini} and {Menso Molag} and {Valerio Cozzani}},
	year = {2017},
	doi = {10.1016/j.jlp.2016.08.009},
	pages = {36--46},
}

@article{adrian_v_gheorghe_comprehensive_2005,
	title = {Comprehensive risk assessment for rail transportation of dangerous goods: a validated platform for decision support},
	volume = {88},
	issn = {0951-8320},
	shorttitle = {doi},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832004001826},
	doi = {https://doi.org/10.1016/j.ress.2004.07.017},
	abstract = {Currently, the most advanced and well documented risk assessments for the transportation of dangerous goods by railway take into account:(i)statistics-based loss of containment frequencies,(ii)specification of potential consequences for a given release situations using event tree methodology as an organisational tool and(iii)consequence calculation models to determine a risk figure known as CCDF (Complementary Cumulative Distribution Function). Such procedures for the risk assessment (including for example decision-making on preventive measures) may offer only a limited insight into the causes and sequences leading to an accident and do not allow for any kind of predictive analysis. The present work introduces an enhanced solution, and a related software platform, which attempts to integrate loss of containment causes and consequences with system's infrastructure and its environment. The solution features:(i)the use of a detailed Master Logical Diagram, including fault/event tree analysis to determine a loss of containment frequency based on different initiating events, scenarios and specific basic data,(ii)the characterization of a resulting source term following a release situation, and(iii)the calculation of various potential impacts on the neighbouring site. Results are wrapped into a CCDF format for each selected traffic segment. The risk-related results are integrated on a software platform, structured as a decision support system using intelligent maps and a variety of GIS (Geographical Information System) data processing procedures. The introduction of the hot spot approach, allows us to focus on the most risk-relevant areas and to use information on various railway infrastructure elements (e.g. points, tunnels), are the basis of the new models employed. The software is applicable to any railway transportation system, comprising its technical infrastructure, rolling stock, human actions, regulation and management procedures. It provides the determination of the annual societal risk due to potential accident scenarios, while also revealing information on the potential causes of an accident taking into account spatial parameters. The approach and software have been validated by a case study done for a particular traffic segment of the Swiss Federal Railway company.},
	language = {en},
	number = {3},
	urldate = {2022-09-07},
	journal = {Reliability Engineering \& System Safety},
	author = {{Adrian V. Gheorghe} and {Jürg Birchmeier} and {Dan Vamanu} and {Ioannis Papazoglou} and {Wolfgang Kröger}},
	year = {2005},
	doi = {10.1016/j.ress.2004.07.017},
	pages = {247--272},
}

@article{noauthor_finite_2009,
	title = {Finite element modelling of the one meter drop test on a steel bar for the {CASTOR} cask},
	volume = {239},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/S0029549308005384},
	doi = {10.1016/j.nucengdes.2008.10.010},
	abstract = {This paper presents a numerical analysis of the 1m drop test on a steel bar of a CASTOR AVR cask where the impact is in a region with cooling fins as …},
	language = {en},
	number = {2},
	urldate = {2022-09-06},
	journal = {Nuclear Engineering and Design},
	month = feb,
	year = {2009},
	note = {Publisher: North-Holland},
	pages = {201--213},
}

@article{noauthor_demonstration_2011,
	title = {Demonstration drop test and design enhancement of the {CANDU} spent fuel storage basket in dry storage facility},
	volume = {241},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/S0029549311000422},
	doi = {10.1016/j.nucengdes.2010.12.024},
	abstract = {A dry interim storage facility has been constructed at the Wolsung power plant in Korea. This dry storage facility has seven separated modules. There …},
	language = {en},
	number = {3},
	urldate = {2022-09-06},
	journal = {Nuclear Engineering and Design},
	month = mar,
	year = {2011},
	note = {Publisher: North-Holland},
	pages = {723--730},
}

@article{eidelpes_fission_2022,
	title = {Fission {Battery} transportation and siting aspects},
	volume = {152},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197022002372},
	doi = {10.1016/j.pnucene.2022.104362},
	abstract = {Fission Batteries (FBs) are envisioned to be highly mobile, autonomously operating, and economically competitive small nuclear power reactor systems useable for generating electric power or heat. Such novel systems will face unique challenges pertaining to siting and transportation. This paper presents the findings and recommendations of the 2021 Idaho National Laboratory FB Initiative workshop on the transportation and siting of FBs. Regulatory and technical subject matter experts on the transportation and storage of radioactive materials, licensing of nuclear power plants, innovative sensing technologies, etc., participated in this workshop and shared their professional experiences and perspectives. Based on these conversations, the paper describes the lessons learned from nuclear reactor siting and licensing, as well as from the siting and transportation of radioactive materials such as fresh or spent nuclear fuel. It then explores the applicability of these lessons and practices to FB siting and transportation. In addition, associated regulatory and technological challenges are identified, such as a changing FB source term, criticality safety aspects, neutron activation and embrittlement of structural components, site development, transportation uncertainties, the current regulatory framework, modeling and simulation uncertainties, and limited inspections. Additionally, research and development activities are suggested to address these gaps and challenges, including the development of modeling and simulation tools for FB design, strategies for rapid FB transportation, innovative FB shell materials, procedures for onsite handling of FBs, transportation-accident-proof criticality control mechanisms, self-monitoring and self-testing capabilities, regulatory requirements, and probabilistic risk assessment tools. Carrying out these research initiatives is expected to help accelerate the evolution of FBs and facilitate their design, licensing, and deployment.},
	language = {en},
	urldate = {2022-09-05},
	journal = {Progress in Nuclear Energy},
	author = {Eidelpes, E. and Bolisetti, C. and Gupta, A. and Shafieezadeh, A.},
	month = oct,
	year = {2022},
	keywords = {Advanced reactors, Fission batteries, Siting, Transportation},
	pages = {104362},
}

@article{zubair_sensitivity_2018,
	title = {Sensitivity analysis of {APR}-1400’s {Reactor} {Protection} {System} by using {RiskSpectrum} {PSA}},
	volume = {339},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318308197},
	doi = {10.1016/j.nucengdes.2018.09.019},
	language = {en},
	urldate = {2022-09-02},
	journal = {Nuclear Engineering and Design},
	author = {Zubair, Muhammad and Ishag, Ahmed},
	month = dec,
	year = {2018},
	pages = {225--234},
}

@article{lee_exhaustive_2020,
	title = {Exhaustive testing of safety-critical software for reactor protection system},
	volume = {193},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832019307586},
	doi = {10.1016/j.ress.2019.106667},
	language = {en},
	urldate = {2022-09-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Lee, Sang Hun and Lee, Seung Jun and Shin, Sung Min and Lee, Eun-chan and Kang, Hyun Gook},
	month = jan,
	year = {2020},
	pages = {106667},
}

@article{jee_automated_2014,
	title = {Automated test case generation for {FBD} programs implementing reactor protection system software: {AUTOMATED} {TEST} {CASE} {GENERATION} {FOR} {FBD} {PROGRAMS}},
	volume = {24},
	issn = {09600833},
	shorttitle = {Automated test case generation for {FBD} programs implementing reactor protection system software},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/stvr.1548},
	doi = {10.1002/stvr.1548},
	language = {en},
	number = {8},
	urldate = {2022-09-02},
	journal = {Software Testing, Verification and Reliability},
	author = {Jee, Eunkyoung and Shin, Donghwan and Cha, Sungdeok and Lee, Jang-Soo and Bae, Doo-Hwan},
	month = sep,
	year = {2014},
	pages = {608--628},
}

@article{yoo_research_2013,
	title = {A {RESEARCH} {ON} {SEAMLESS} {PLATFORM} {CHANGE} {OF} {REACTOR} {PROTECTION} {SYSTEM} {FROM} {PLC} {TO} {FPGA}},
	volume = {45},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573315300334},
	doi = {10.5516/NET.04.2012.078},
	language = {en},
	number = {4},
	urldate = {2022-09-02},
	journal = {Nuclear Engineering and Technology},
	author = {Yoo, Junbeom and Lee, Jong-Hoon and Lee, Jang-Soo},
	month = aug,
	year = {2013},
	pages = {477--488},
}

@techreport{noauthor_ml12160a320pdf_nodate,
	title = {{ML12160A320}.pdf},
	url = {https://www.nrc.gov/docs/ML1216/ML12160A320.pdf},
	urldate = {2022-09-01},
}

@article{soares_risk-based_2010,
	title = {Risk-{Based} {Approaches} to {Maritime} {Safety}},
	url = {http://www.crcnetbase.com/doi/book/10.1201/b10572},
	doi = {10.1201/b10572},
	abstract = {This paper reflects the status of application of risk-based approaches in the maritime transportation and ship-building industry. It presents the main risk-based instruments that have been introduced in the last years in the regulatory framework for maritime safety. A list of key publications is also provided.},
	language = {en},
	urldate = {2022-09-01},
	journal = {Safety and Reliability of Industrial Products, Systems and Structures},
	author = {Soares, Carlos and Teixeira, A.P and Antao, Pedro},
	month = nov,
	year = {2010},
}

@article{bolat_risk_2013,
	title = {Risk assessment of potential catastrophic accidents for transportation of special nuclear materials through {Turkish} {Straits}},
	volume = {56},
	issn = {03014215},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421512010555},
	doi = {10.1016/j.enpol.2012.12.010},
	abstract = {Turkish Straits Region (TS) comprises of two straits, Dardanelles and Bosphorus, and the Marmara Sea. It is a historical marine trade route between the former Soviet countries and the western world. From the perspective of special nuclear materials transportation, this route can also be a nuclear materials trade route due to the nuclear policy of former Soviet countries and world nuclear market. In addition, TS can also be an optional route of integrated transportation ways for the shipping states that pursue to reach the destination points using the Black Sea countries or the North-Eastern Part of Turkey. Consequently maritime transportation of special nuclear materials has arisen as a critical concept for TS, where the risks should be understood and analyzed effectively. Accordingly, this study will aim at conducting a risk assessment for the TS from the special nuclear material transportations perspective via two hypothesized scenarios which are (i) ship collision accident in the case of special nuclear materials (SNM) Transportation through TS (ii) ship ﬁre accident in the case of nuclear smuggling through TS with oil tanker. These scenarios are modelled and analyzed via RADTRAN 5 code and the results are presented in the paper.},
	language = {en},
	urldate = {2022-09-01},
	journal = {Energy Policy},
	author = {Bolat, Pelin and Yongxing, Jin},
	month = may,
	year = {2013},
	pages = {126--135},
}

@incollection{spitzer_application_2004,
	address = {London},
	title = {Application of {Probabilistic} {Risk} {Assessment} ({PRA}) {During} {Conceptual} {Design} for the {NASA} {Orbital} {Space} {Plane} ({OSP})},
	isbn = {9781447110576 9780857294104},
	url = {http://link.springer.com/10.1007/978-0-85729-410-4_313},
	language = {en},
	urldate = {2022-09-01},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer London},
	author = {Rogers, James H. and Safie, Fayssal M. and Stott, James E. and Lo, Yunnhon},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	doi = {10.1007/978-0-85729-410-4_313},
	pages = {1950--1955},
}

@book{gerstein_developing_2016,
	address = {Santa Monica, Calif},
	series = {Research report},
	title = {Developing a risk assessment methodology for the {National} {Aeronautics} and {Space} {Administration}},
	isbn = {9780833095633},
	abstract = {"The National Aeronautics and Space Administration (NASA) confronts a variety of organizational-level risks within its programs that could influence the success of its missions or programs. Comparing, contrasting, and mitigating these risks require developing a common lens through which to view them. Such an evaluation can increase overall understanding of the risks associated with NASA-level decisions. This report provides NASA's Office of Strategy and Plans with a risk assessment methodology that integrates risk factors and risk management approaches tailored to NASA's management, operations, and acquisition structures. While NASA has deep experience in conducting risk assessments on highly technical issues for individual programs and projects, it has not developed an overarching methodology for thinking about overall NASA-level risk associated with its decisions. For this effort, a methodology was developed for normalizing and comparing supply chain, external dependency, cost and schedule, human capital, organizational and managerial, political, and technical risks. The goal ultimately was to develop a single, overarching, risk-informed decision support methodology for looking at disparate risks through a common lens. The methodology presented is for a non-expert audience so that any practitioner or decisionmaker with any level of training can use it"--},
	number = {RR-1537-NASA},
	publisher = {RAND Corporation},
	author = {Gerstein, Daniel M. and Kallimani, James G. and Mayer, Lauren A. and Meshkat, Leila and Osburg, Jan and Davis, Paul K. and Cignarella, Blake and Grammich, Clifford A.},
	collaborator = {{Rand Corporation} and {United States}},
	year = {2016},
	note = {OCLC: ocn953631403},
	keywords = {Aeronautics, Decision making, Management, National Aeronautics and Space Administration, Risk assessment Methodology, Risk management Methodology, United States},
}

@article{noauthor_method_2022,
	title = {A {Method} for {Analog} {Space} {Missions} {Risk} {Analysis}},
	volume = {9},
	issn = {2468-8967},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S2468896722000088},
	doi = {10.1016/j.jsse.2022.02.004},
	abstract = {In this paper, we provide a general risk evaluation method for analog simulation missions, in terms of identification of potential hazards and risks, …},
	language = {en},
	number = {2},
	urldate = {2022-09-01},
	journal = {Journal of Space Safety Engineering},
	month = jun,
	year = {2022},
	pages = {132--144},
}

@article{knight_probabilistic_2003,
	title = {Probabilistic {Risk} {Assessment} {Strategy} for {Damage}-{Tolerant} {Composite} {Spacecraft} {Component} {Structural} {Design}},
	volume = {40},
	issn = {0022-4650, 1533-6794},
	url = {https://arc.aiaa.org/doi/10.2514/2.3917},
	doi = {10.2514/2.3917},
	language = {en},
	number = {1},
	urldate = {2022-09-01},
	journal = {Journal of Spacecraft and Rockets},
	author = {Knight, Norman F. and Glaessgen, Edward H. and Sleight, David W.},
	month = jan,
	year = {2003},
	pages = {72--82},
}

@article{ding_probabilistic_2020,
	title = {Probabilistic {Assessment} of the {Failure} {Risk} of the {Europa} {Clipper} {Spacecraft} due to {Radiations}},
	volume = {40},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/risa.13439},
	doi = {10.1111/risa.13439},
	language = {en},
	number = {4},
	urldate = {2022-09-01},
	journal = {Risk Analysis},
	author = {Ding, Yiqing and Duggan, Sean and Ferranti, Matthew and Jagadpramana, Michael and Rege, Rushal and Zhovtobryukh, Yuriy and Paté‐Cornell, M.‐Elisabeth},
	month = apr,
	year = {2020},
	pages = {842--857},
}

@article{noauthor_upgrade_2019,
	title = {Upgrade of {ESA}'s {Debris} {Risk} {Assessment} and {Mitigation} {Analysis} ({DRAMA}) tool: {Spacecraft} {Entry} {Survival} {Analysis} {Module}},
	volume = {158},
	issn = {0094-5765},
	shorttitle = {Upgrade of {ESA}'s {Debris} {Risk} {Assessment} and {Mitigation} {Analysis} ({DRAMA}) tool},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S009457651731216X},
	doi = {10.1016/j.actaastro.2017.12.001},
	abstract = {In 2015, ESA's “ESA Space Debris Mitigation Compliance Verification Guidelines” handbook was released, dealing with the practical aspects of how missi…},
	language = {en},
	urldate = {2022-09-01},
	journal = {Acta Astronautica},
	month = may,
	year = {2019},
	pages = {148--160},
}

@article{noauthor_cost_2015,
	title = {Cost and risk assessment for spacecraft operation decisions caused by the space debris environment},
	volume = {113},
	issn = {0094-5765},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0094576515001289},
	doi = {10.1016/j.actaastro.2015.03.028},
	abstract = {Space debris is a topic of concern among many in the space community. Most forecasting analyses look centuries into the future to attempt to predict h…},
	language = {en},
	urldate = {2022-09-01},
	journal = {Acta Astronautica},
	month = aug,
	year = {2015},
	pages = {66--79},
}

@article{noauthor_challenges_2017,
	title = {Challenges of {Debris}-{Impact} {Risk} {Assessment} for {Robotic} {Spacecraft}},
	volume = {204},
	issn = {1877-7058},
	url = {https://www.sciencedirect.com/science/article/pii/S1877705817342923},
	doi = {10.1016/j.proeng.2017.09.738},
	abstract = {This paper describes an orbital debris impact risk assessment performed on the command and data subsystem electronics box of QuikSCAT, a functioning s…},
	language = {en},
	urldate = {2022-09-01},
	journal = {Procedia Engineering},
	month = jan,
	year = {2017},
	pages = {437--444},
}

@article{putney_application_2008,
	title = {Application of risk assessment for the {NASA} {Vision} for {Space} {Exploration}},
	volume = {222},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR122},
	doi = {10.1243/1748006XJRR122},
	abstract = {Many quantitative reliability analyses and risk assessments of space systems have been criticized for unrealistic results. One reason for this may be that the analysis usually assumes that systems are mature. Unfortunately, limited budgets reduce the flight rates for systems to a level where maturity is never reached before a new design is proffered. If quantitative studies are to be depended upon for programmatic decisions, new methods must be applied to improve the usefulness and credibility of the analysis. Probabilistic risk analysis is becoming an integral part of decision making for NASA's Vision for Space Exploration (VSE). Since the Exploration Systems Architecture Study (ESAS), a number of high-level trade studies have been performed to evaluate options concerning NASA's architecture to support the transportation needs of the international space station and lunar missions including potential lunar bases. The risk analysis described here blended heritage information from existing systems and design features to create models that reflected mature reliability and assessed the effects of the flight manifest on maturing risk critical systems. This paper describes a multiple mission campaign model that illustrates the need for incorporating maturity into quantitative reliability and risk assessments.},
	language = {en},
	number = {3},
	urldate = {2022-09-01},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Putney, B F and Fragola, J R},
	month = sep,
	year = {2008},
	pages = {431--438},
}

@book{national_materials_advisory_board_application_1982,
	address = {Washington, D.C.},
	title = {Application of {Quantitative} {Risk} {Assessment} {Techniques} in the {U}.{S}. {Coast} {Guard} {Regulatory} {Process}},
	isbn = {978-0-309-32851-7},
	url = {https://www.nap.edu/catalog/19588},
	language = {en},
	urldate = {2022-09-01},
	publisher = {National Academies Press},
	author = {{National Materials Advisory Board}},
	month = jan,
	year = {1982},
	doi = {10.17226/19588},
	note = {Pages: 19588},
}

@inproceedings{lindsey_reliability_2020,
	address = {Palm Springs, CA},
	title = {Reliability {Analysis} of {Complex} {NASA} {Systems} with {Model}-{Based} {Engineering}},
	url = {https://ntrs.nasa.gov/citations/20200000582},
	abstract = {The emergence of model-based engineering, with Model- Based Systems Engineering (MBSE) leading the way, is transforming design and analysis methodologies. The recognized benefits to systems development include moving from document-centric information systems and document-centric project communication to a model-centric environment in which control of design changes in the life cycles is facilitated. In addition, a “single source of truth” about the system, that is up-to-date in all respects of the design, becomes the authoritative source of data and information about the system. This promotes consistency and efficiency in regard to integration of the system elements as the design emerges and thereby may further optimize the design. Therefore Reliability Engineers (REs) supporting NASA missions must be integrated into model-based engineering to ensure the outputs of their analyses are relevant and value-needed to the design, development, and operational processes for failure risks assessment and communication.},
	urldate = {2022-09-01},
	author = {Lindsey, Nancy J. and Alimardani, Mahdi and Gallo, Luis D.},
	month = jan,
	year = {2020},
	note = {NTRS Author Affiliations: NASA Goddard Space Flight Center
NTRS Report/Patent Number: GSFC-E-DAA-TN73827
NTRS Document ID: 20200000582
NTRS Research Center: Goddard Space Flight Center (GSFC)},
	keywords = {Quality Assurance and Reliability},
}

@techreport{stewart_architectural_2021,
	title = {Architectural {Modeling} and {Analysis} for {Safety} {Engineering}},
	url = {https://ntrs.nasa.gov/citations/20210017388},
	abstract = {Model-based development tools are increasingly being used for system-level development of safety-critical systems. Architectural and behavioral models provide important information that can be leveraged to improve the system safety analysis process. Model-based design artifacts produced in early stage development activities can be used to perform system safety analysis, reducing costs and providing accurate results throughout the system life-cycle. In this report we describe an extension to the Architecture Analysis and Design Language (AADL) that supports modeling of system behavior under failure conditions. This Safety Annex enables the independent modeling of component failures and allows safety engineers to weave various types of fault behavior into the nominal system model. The accompanying tool support uses model checking to propagate errors from their source to their effect on safety properties without the need to add separate propagation specifications. The tool also captures all minimal set of fault combinations that can cause violation of the safety properties, that can be compared to qualitative and quantitative objectives as part of the safety assessment process. We describe the Safety Annex, illustrate its use with a representative example, and discuss and demonstrate the tool support enabling an analyst to investigate the system behavior under failure conditions.},
	urldate = {2022-09-01},
	author = {Stewart, Danielle and Liu, Jing and Cofer, Darren and Heimdahl, Mats and Whalen, Michael W. and Peterson, Michael},
	month = jun,
	year = {2021},
	note = {NTRS Author Affiliations: University of Minnesota, Collins Aerospace
NTRS Document ID: 20210017388
NTRS Research Center: Langley Research Center (LaRC)},
	keywords = {Air Transportation and Safety},
}

@inproceedings{knizhnik_realized_2019,
	address = {Tokushima},
	title = {Realized {Benefits} from the {Model}-{Based} {Systems} {Engineering} {Infusion} and {Modernization} {Initiative}},
	url = {https://ntrs.nasa.gov/citations/20200002823},
	abstract = {Although Model-Based Systems Engineering (MBSE) as a concept has existed for over a decade, overall acceptance within the National Aeronautics and Space Administration (NASA) has been slow and is now growing. Since 2016, NASA’s MBSE Infusion And Modernization Initiative (MIAMI) has proven MBSE’s value to and increased its adoption at NASA. MBSE Pathfinder projects provided focused use cases that demonstrated both qualitative and quantitative benefits for systems engineering activities, and demonstrated the ability to connect MBSE models with discipline models such as structural loads and safety and mission assurance. MIAMI assisted NASA’s field centers to establish or enhance an MBSE presence. MIAMI partners with JAXA’s Systems Technology Unit to share lessons learned and demonstrate how MBSE can be used across organizations. Following its successful test cases, MIAMI is using design thinking, lean startup, and high technology marketing methodologies to implement a targeted deployment of its Community of Practice and other resources.},
	urldate = {2022-09-01},
	author = {Knizhnik, Jessica R. and Weiland, Karen J. and Grondin, Trevor A. and Jones-McDowall, Kelley M. and Holladay, Jon B.},
	month = nov,
	year = {2019},
	note = {NTRS Author Affiliations: Goddard Space Flight Center, Glenn Research Center, Langley Research Center, Kennedy Space Center
NTRS Report/Patent Number: NF1676L-33895
NTRS Document ID: 20200002823
NTRS Research Center: Langley Research Center (LaRC)},
	keywords = {Engineering (General)},
}

@techreport{klein_operational_2021,
	title = {Operational {Considerations} for {Fission} {Reactors} {Utilized} on {Nuclear} {Thermal} {Propulsion} {Missions} to {Mars}},
	url = {https://ntrs.nasa.gov/citations/20210000387},
	abstract = {This report is aimed at identifying the implications associated with the operation of space nuclear power reactors that would be utilized for Nuclear Thermal Propulsion (NTP) missions to Mars. The objective of this study is to evaluate the operational features of reactors that could provide propulsion and possibly electrical power for future crewed and cargo missions to Mars. This report follows upon an initial report  looking at the generic considerations for operating fission reactors in space applications and is intended as a deeper dive into the operational features related to specific Mars NTP applications.},
	number = {NASA/CR-20210000387},
	urldate = {2022-09-01},
	author = {Klein, Andrew C. and Camp, Allen and McClure, Patrick and Voss, Susan},
	month = jan,
	year = {2021},
	note = {NTRS Author Affiliations: Consultant, LARC, Los Alamos National Laboratory, Global Nuclear Analysis, LLC
NTRS Document ID: 20210000387
NTRS Research Center: Langley Research Center (LaRC)},
	keywords = {Spacecraft Propulsion and Power},
}

@inproceedings{jones_new_2020,
	address = {Palm Springs, CA},
	title = {The {New} {NASA} {Approach} to {Reliability} and {Maintainability}},
	url = {https://ntrs.nasa.gov/citations/20200000609},
	abstract = {In 2017, after 20 years, NASA issued a major revision of its reliability and maintainability (R\&M) policy, NASA-STD- 8729.1A. Formerly NASA required certain specific R\&M activities during each succeeding phase of project development. Now NASA requires a project to start by including the initial development of R\&M requirements and the devising of strategies to implement and verify them. Rather than resolving all the requirements first and then designing the system, as has been usual in systems design, the design process now is to work top down by layers. It begins by first identifying the top level requirements and suggesting top level design strategies for those, then making these higher strategies the basis for a lower level set of requirements, and so on down to the lowest components. This approach is intended to ensure that R\&M is designed in from the beginning rather than added later with difficulty to a completed design concept. The new R\&M standard uses an innovative and effective top-down system design approach intended to effectively implement R\&M.},
	urldate = {2022-09-01},
	author = {Jones, Harry W.},
	month = jan,
	year = {2020},
	note = {NTRS Author Affiliations: NASA Ames Research Center
NTRS Report/Patent Number: ARC-E-DAA-TN75561-1
NTRS Document ID: 20200000609
NTRS Research Center: Ames Research Center (ARC)},
	keywords = {Systems Analysis and Operations Research},
}

@inproceedings{stott_common_2010,
	address = {Seattle, WA},
	title = {Common {Cause} {Failure} {Modeling}: {Aerospace} {Versus} {Nuclear}},
	shorttitle = {Common {Cause} {Failure} {Modeling}},
	url = {https://ntrs.nasa.gov/citations/20100025991},
	abstract = {Aggregate nuclear plant failure data is used to produce generic common-cause factors that are specifically for use in the common-cause failure models of NUREG/CR-5485. Furthermore, the models presented in NUREG/CR-5485 are specifically designed to incorporate two significantly distinct assumptions about the methods of surveillance testing from whence this aggregate failure data came. What are the implications of using these NUREG generic factors to model the common-cause failures of aerospace systems? Herein, the implications of using the NUREG generic factors in the modeling of aerospace systems are investigated in detail and strong recommendations for modeling the common-cause failures of aerospace systems are given.},
	urldate = {2022-09-01},
	author = {Stott, James E. and Britton, Paul and Ring, Robert W. and Hark, Frank and Hatfield, G. Spencer},
	month = jun,
	year = {2010},
	note = {NTRS Author Affiliations: NASA Marshall Space Flight Center, Bastion Technologies, Inc.
NTRS Report/Patent Number: M10-0548
NTRS Document ID: 20100025991
NTRS Research Center: Marshall Space Flight Center (MSFC)},
	keywords = {Quality Assurance and Reliability},
}

@misc{lindsey_reliability_2013,
	title = {Reliability {Prediction} {Using} {Bayesian} {Updating} of {On}-{Orbit} {Performance}},
	url = {https://ntrs.nasa.gov/citations/20130009069},
	urldate = {2022-09-01},
	author = {Lindsey, nancy J. and Rackley, Nancy and Brall, Aron and Mosleh, Ali},
	month = jan,
	year = {2013},
	note = {NTRS Author Affiliations: NASA Goddard Space Flight Center, B-Line Express, Inc., ARES Corp., Maryland Univ.
NTRS Meeting Information: Annual Reliability and Maintainability Symposium (RAMS); 2013-01-28 to 2013-01-31; undefined
NTRS Report/Patent Number: GSFC.CPR.7515.2012
NTRS Document ID: 20130009069
NTRS Research Center: Goddard Space Flight Center (GSFC)},
	keywords = {Quality Assurance and Reliability},
}

@misc{noauthor_cl18-0355pdf_nodate,
	title = {{CL18}-0355.pdf - {JPL} {Open} {Repository}},
	url = {https://dataverse.jpl.nasa.gov/file.xhtml?fileId=53345&version=1.0},
	urldate = {2022-09-01},
}

@misc{wetherholt_software_2018,
	title = {Software {Formal} {Inspections} {Standard}},
	url = {https://ntrs.nasa.gov/citations/20180004877},
	abstract = {The purpose of this Standard is to define the requirements for a software inspection process aimed at detecting and eliminating defects as early as possible in the software life cycle. This process can be used for any documented product; however, this Standard focuses on its use for software products - i.e., software code, plans, manuals, etc. The process provides for the collection and analysis of inspection data to improve the inspection process as well as the quality of the software.},
	urldate = {2022-09-01},
	author = {Wetherholt, Martha S.},
	month = apr,
	year = {2018},
	note = {NTRS Author Affiliations: NASA Headquarters
NTRS Report/Patent Number: NASA-STD-8739.9
NTRS Document ID: 20180004877
NTRS Research Center: Headquarters (HQ)},
	keywords = {Computer Programming and Software, NASA, Techinal Standard},
}

@book{bentaib_nuclear_2020,
	title = {Nuclear {Power} {Reactor} {Core} {Melt} {Accidents}: {Current} {State} of {Knowledge}},
	isbn = {978-2-7598-1930-0},
	shorttitle = {Nuclear {Power} {Reactor} {Core} {Melt} {Accidents}},
	url = {https://www.degruyter.com/document/doi/10.1051/978-2-7598-1930-0/html},
	language = {en},
	urldate = {2022-08-31},
	publisher = {EDP Sciences},
	author = {Bentaïb, Ahmed and Bonneville, Hervé and Cénérino, Gérard},
	month = nov,
	year = {2020},
	doi = {10.1051/978-2-7598-1930-0},
}

@article{groth_smart_2014,
	title = {“{Smart} {Procedures}”: {Using} dynamic {PRA} to develop dynamic, context- specific severe accident management guidelines ({SAMGs})},
	abstract = {Developing a big picture understanding of a severe accident is extremely challenging. Operating crews and emergency response teams are faced with rapidly evolving circumstances, uncertain information, distributed expertise, and a large number of conflicting goals and priorities. Severe accident management guidance (SAMGs) provides support for collecting information and assessing the state of a nuclear power plant during severe accidents. However, SAMGs developers cannot anticipate every possible accident scenario. Advanced Probabilistic Risk Assessment (PRA) methods can be used to explore an extensive space of possible accident sequences and consequences. Using this advanced PRA to develop a decision support system can provide expanded support for diagnosis and response. In this paper, we present an approach that uses dynamic PRA to develop riskinformed “Smart SAMGs”. Bayesian Networks form the basis of the faster-than-real-time decision support system. The approach leverages best-available information from plant physics simulation codes (e.g., MELCOR). Discrete Dynamic Event Trees (DDETs) are used to provide comprehensive coverage of the potential accident scenario space. This paper presents a methodology to develop Smart procedures and provides an example model created for diagnosing the status of the ECCS valves in a generic iPWR design.},
	language = {en},
	author = {Groth, Katrina M and Denman, Matthew R and Cardoni, Jeffrey N and Wheeler, Timothy A},
	year = {2014},
	pages = {13},
}

@article{donorio_severe_2022,
	title = {Severe accident sensitivity and uncertainty estimation using {MELCOR} and {RAVEN}},
	volume = {2177},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2177/1/012021},
	doi = {10.1088/1742-6596/2177/1/012021},
	abstract = {Today, using a best-estimate approach is a key factor in the simulation and prediction of thermal-hydraulic and other multi-physics phenomena occurring during nuclear severe accidents. The best-estimate approach requires the quantification of both epistemic and stochastic uncertainties of safety codes to be effective. This safety assessment approach, named Best Estimate Plus Uncertainty (BEPU), is being pursued as an alternative to traditional deterministic analyses that are intrinsically conservative with not clearly defined safety margins. While in a conservative approach, the results are expressed in terms of a set of calculated conservative values of parameters, in a best-estimate methodology, the results are expressed in terms of uncertainty ranges for the calculated parameters. The International Technical Nuclear Community has made great efforts to develop methods and tools for uncertainty and sensitivity analyses of severe accident codes. In this framework, Sapienza University of Rome has developed a new Python script to use RAVEN as a tool for the application of the BEPU methods within the safety analyses performed with MELCOR. The aim of this paper is to show the capabilities of the coupling between RAVEN and MELCOR by performing a statistical analysis to estimate the range of evolution of a severe accident scenario.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {Journal of Physics: Conference Series},
	author = {D’Onorio, M. and Giampaolo, A. and Giannetti, F. and Mascari, F. and Caruso, G.},
	month = apr,
	year = {2022},
	pages = {012021},
}

@article{denman_proof_2013,
	title = {Proof of {Principle} {Framework} for risk informed {Severe} {Accident} {Management} {Guidelines}},
	language = {en},
	author = {Denman, M R and Groth, K M and Wheeler, T A},
	year = {2013},
	pages = {4},
}

@article{liao_leveraging_nodate,
	title = {Leveraging {Existing} {Tools} for {Simulating} {Operator} {Performance} in {Discrete} {Dynamic} {Event} {Trees}},
	language = {en},
	author = {Liao, Huafei and Cardoni, Jeffrey and Wheeler, Timothy and Denman, Matthew R},
	pages = {17},
}

@article{jankovsky_extension_nodate,
	title = {Extension of the {ADAPT} {Framework} for {Multiple} {Simulators}},
	language = {en},
	author = {Jankovsky, Zachary K and Denman, Matthew R and Aldemir, Tunc},
	pages = {4},
}

@article{vittitow_discrete_nodate,
	title = {Discrete {Dynamic} {Event} {Tree} {Analysis} of {Small} {Modular} {Reactor} {Severe} {Accident} {Management}},
	language = {en},
	author = {Vittitow, Michael P},
	pages = {79},
}

@article{darling_intelligent_2018,
	title = {Intelligent {Modeling} for {Nuclear} {Power} {Plant} {Accident} {Management}},
	volume = {27},
	issn = {0218-2130, 1793-6349},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218213018500033},
	doi = {10.1142/S0218213018500033},
	abstract = {This paper explores the viability of using counterfactual reasoning for impact analyses when understanding and responding to “beyond-design-basis” nuclear power plant accidents. Currently, when a severe nuclear power plant accident occurs, plant operators rely on Severe Accident Management Guidelines. However, the current guidelines are limited in scope and depth: for certain types of accidents, plant operators would have to work to mitigate the damage with limited experience and guidance for the particular situation. We aim to ﬁll the need for comprehensive accident support by using a dynamic Bayesian network to aid in the diagnosis of a nuclear reactor’s state and to analyze the impact of possible response measures.},
	language = {en},
	number = {02},
	urldate = {2022-08-31},
	journal = {International Journal on Artificial Intelligence Tools},
	author = {Darling, Michael C. and Luger, George F. and Jones, Thomas B. and Denman, Matthew R. and Groth, Katrina M.},
	month = mar,
	year = {2018},
	pages = {1850003},
}

@inproceedings{lin_enhancing_2021,
	title = {Enhancing the {Operational} {Resilience} of {Advanced} {Reactors} with {Digital} {Twins} by {Recurrent} {Neural} {Networks}},
	doi = {10.1109/RWS52686.2021.9611796},
	abstract = {Because of a lack of operation data during abnormal and accident scenarios, along with the existence of uncertainty in the evaluation model for transient and accident analysis, the established abnormal and emergency operating procedures can be biased in characterizing the reactor states and ensuring operational resilience. To improve state awareness and ensure operational flexibility for minimizing effects on the system due to anomaly, digital twin (DT) technology is suggested to support operator's decision-making by effectively extracting and using knowledge of the current and future plant states from the knowledge base. To demonstrate DT's capability for recovering the complete states of reactors and for predicting the future reactor behaviors, this paper develops and assesses both the diagnosis and prognosis DTs in a nearly autonomous management and control system for an Experimental Breeder Reactor-II simulator during different loss-of-flow scenarios.},
	booktitle = {2021 {Resilience} {Week} ({RWS})},
	author = {Lin, Linyu and Lee, Joomyung and Poudel, Bikash and McJunkin, Timothy and Dinh, Nam and Agarwal, Vivek},
	month = oct,
	year = {2021},
	keywords = {Control systems, Databases, Decision making, Digital twin, Inductors, Knowledge based systems, Uncertainty, diagnosis, digital twin, prognosis, resilience},
	pages = {1--9},
}

@article{crowder_digital_2022,
	title = {Digital {Engineering} for {Integrated} {Modeling} and {Simulation} for {Building}-{Piping} {Systems} {Through} {Interoperability} {Solutions}},
	volume = {0},
	issn = {0029-5639},
	url = {https://doi.org/10.1080/00295639.2022.2055705},
	doi = {10.1080/00295639.2022.2055705},
	abstract = {Designing piping systems for nuclear power plants involves engineers from multiple disciplines (i.e., thermal hydraulics, mechanical engineering, and structural/seismic) and close coordination with the contractors who build the plant. Any design changes during construction need to be carefully communicated and managed with all stakeholders in order to assess risks associated with the design changes. To allow the quick assessment of building and piping design changes through a streamlined building-piping coupled analysis, this paper presents a novel interoperability solution that converts bidirectionally between building information models (BIMs) and pipe stress models. Any design changes during construction that are shown in an as-built BIM are automatically converted into a pipe stress model. Any further design changes due to building-piping interaction analyses are converted back to the BIM for the contractor and other designers to access the latest model. Two case studies are presented to illustrate the bidirectional conversion that allows an integrated coupled analysis of the building-piping system to account for their interactions.},
	number = {0},
	urldate = {2022-08-31},
	journal = {Nuclear Science and Engineering},
	author = {Crowder, Nicholas and Lee, Joomyung and Gupta, Abhinav and Han, Kevin and Bodda, Saran and Ritter, Christopher},
	month = may,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295639.2022.2055705},
	keywords = {Building information model, building-piping interaction, coupled analysis, interoperability, piping},
	pages = {1--18},
}

@inproceedings{lee_development_nodate,
	title = {Development of {aSevere} {Accident} {Analysis} {Engine} {Using} {Approximate} {Reasoning}},
	url = {https://epubs.ans.org/?a=39303&_ga=2.251375814.1175766833.1661956525-1691346433.1661956525},
	urldate = {2022-08-31},
	author = {Lee, Joomyung},
}

@phdthesis{lee_development_nodate-1,
	title = {Development of the {Machine} {Learning}-based {Safety} {Significant} {Factor} {Inference} {Model} for {Advanced} {Diagnosis} {System}},
	url = {https://repository.lib.ncsu.edu/bitstream/handle/1840.20/37325/etd.pdf?sequence=1&isAllowed=y},
	urldate = {2022-08-31},
	author = {Lee, Joomyung},
}

@article{lee_development_2021,
	title = {Development of the {Machine} {Learning}-based {Safety} {Significant} {Factor} {Inference} {Model} for {Diagnosis} in {Autonomous} {Control} {System}},
	volume = {162},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454921003194},
	doi = {10.1016/j.anucene.2021.108443},
	abstract = {As a critical component to the autonomous control system, Digital Twin for Diagnosis (DT-D) is a virtual replica of physical systems for an accurate understanding of reactor states. Since the physical damage state cannot be measured directly in transient or accident conditions, safety significant factor (SSF) is introduced as a surrogate index for physical damage states to support safety-related decision making. This study develops a machine learning (ML) based SSF inference model (SSFIM) using the Recurrent Neural Network (RNN) with acceptable accuracy, generalization capability, effectiveness, and robustness against sensor errors. To demonstrate the capability of the ML-based SSFIM, case studies are implemented on a plant simulator for Experimental Breeder Reactor – II. For partial loss of flow accident scenarios, the SSFIM is able to infer the peak fuel centerline temperature with minimally one sensor. Meanwhile the SSFIM is also found to be robust against manipulated sensor drifts and/or random noises.},
	language = {en},
	urldate = {2022-08-31},
	journal = {Annals of Nuclear Energy},
	author = {Lee, Joomyung and Lin, Linyu and Athe, Paridhi and Dinh, Nam},
	month = nov,
	year = {2021},
	keywords = {Diagnosis, Digital twin, Machine Learning, Recurrent Neural Network, Safety significant factor},
	pages = {108443},
}

@article{mathias_engineering_2016,
	title = {Engineering {Risk} {Assessment} of a dynamic space propulsion system benchmark problem},
	volume = {145},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832015001933},
	doi = {10.1016/j.ress.2015.07.003},
	abstract = {The Engineering Risk Assessment (ERA) team at NASA Ames Research Center develops dynamic models with linked physics-of-failure analyses to produce quantitative risk assessments of space exploration missions. This paper applies the ERA approach to the 2014 Probabilistic Safety Assessment and Management conference Space Propulsion System Benchmark Problem, which investigates dynamic system risk for a deep space ion propulsion system over three missions with time-varying thruster requirements and operations schedules. The dynamic missions are simulated using commercial software to generate integrated loss-of-mission (LOM) probability results via Monte Carlo sampling. The simulation model successfully captured all dynamics aspects of the benchmark missions, and convergence studies are presented to illustrate the sensitivity of integrated LOM results to the number of Monte Carlo trials. In addition, to evaluate the relative importance of dynamic modeling, the Ames Reliability Tool (ART) was used to build a series of quasi-dynamic, deterministic models that incorporated varying levels of the problem׳s dynamics. The ART model did a reasonable job of matching the simulation results for the simpler mission case, while auxiliary dynamic models were required to adequately capture risk-driver rankings for the more dynamic cases. This study highlights how state-of-the-art techniques can adapt to a range of dynamic problems.},
	language = {en},
	urldate = {2022-08-31},
	journal = {Reliability Engineering \& System Safety},
	author = {Mathias, Donovan L. and Mattenberger, Christopher J. and Go, Susie},
	month = jan,
	year = {2016},
	keywords = {Dynamic PSA, PRA, PSAM space propulsion system benchmark problem, RISK simulation},
	pages = {316--328},
}

@misc{noauthor_twg_2019,
	address = {Boise State University},
	title = {{TWG} {Report} on {Fuel} {RD}\&{D} {Needs}},
	url = {https://gain.inl.gov/2019AdvFuelsWorkshopPresentations/03-Hackett_GAIN_TWG_survey_v5.pdf},
	abstract = {Design of TRISO Fuel for HTRs},
	language = {English},
	urldate = {2022-08-29},
	month = mar,
	year = {2019},
}

@misc{frank_preclosure_2007,
	address = {Las Vegas, Nevada},
	title = {Preclosure {Saftety} {Analysis} {Event} {Sequence} {Analysis} {Summary}},
	copyright = {U.S. Department of Energy},
	url = {https://www.nwtrb.gov/docs/default-source/meetings/2007/september/frank.pdf?sfvrsn=7},
	language = {English},
	urldate = {2022-08-29},
	author = {Frank, Michael V},
	month = sep,
	year = {2007},
}

@article{siu_pra_2008,
	title = {{PRA} {RESEARCH} {AND} {THE} {DEVELOPMENT} {OF} {RISK}-{INFORMED} {REGULATION} {AT} {THE} {U}.{S}. {NUCLEAR} {REGULATORY} {COMMISSION}},
	volume = {40},
	issn = {1738-5733},
	url = {http://koreascience.or.kr/journal/view.jsp?kj=OJRHBJ&py=2008&vnc=v40n5&sp=349},
	doi = {10.5516/NET.2008.40.5.349},
	language = {en},
	number = {5},
	urldate = {2022-08-28},
	journal = {Nuclear Engineering and Technology},
	author = {Siu, Nathan and Collins, Dorothy},
	month = aug,
	year = {2008},
	pages = {349--364},
}

@article{siu_treating_1989,
	title = {Treating {Data} {Uncertainties} in {Common}-{Cause} {Failure} {Analysis}},
	volume = {84},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT89-A34210},
	doi = {10.13182/NT89-A34210},
	language = {en},
	number = {3},
	urldate = {2022-08-28},
	journal = {Nuclear Technology},
	author = {Siu, Nathan and Mosleh, Ali},
	month = mar,
	year = {1989},
	pages = {265--281},
}

@article{friedensen_space_1998,
	title = {Space nuclear power: {Technology}, policy, and risk considerations in human missions to {Mars}},
	volume = {42},
	issn = {00945765},
	shorttitle = {Space nuclear power},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0094576598001349},
	doi = {10.1016/S0094-5765(98)00134-9},
	language = {en},
	number = {1-8},
	urldate = {2022-08-26},
	journal = {Acta Astronautica},
	author = {Friedensen, Victoria Pidgeon},
	month = jan,
	year = {1998},
	pages = {395--409},
}

@inproceedings{petitgenet_coupled_2020,
	address = {VIRTUAL EVENT},
	title = {A {Coupled} {Approach} to the {Design} {Space} {Exploration} of {Nuclear} {Thermal} {Propulsion} {Systems}},
	isbn = {9781624106026},
	url = {https://arc.aiaa.org/doi/10.2514/6.2020-3846},
	doi = {10.2514/6.2020-3846},
	language = {en},
	urldate = {2022-08-26},
	booktitle = {{AIAA} {Propulsion} and {Energy} 2020 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Petitgenet, Victor and Roper, Christopher D. and Krecicki, Matthew and Yatsko, Andrew J. and Kotlyar, Dan and Mavris, Dimitri N. and Shalat, David},
	month = aug,
	year = {2020},
}

@article{mason_nuclear_2022,
	title = {Nuclear {Power} {Concepts} and {Development} {Strategies} for {High}-{Power} {Electric} {Propulsion} {Missions} to {Mars}},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2022.2045180},
	doi = {10.1080/00295450.2022.2045180},
	language = {en},
	urldate = {2022-08-26},
	journal = {Nuclear Technology},
	author = {Mason, Lee and Oleson, Steve and Jacobson, David and Schmitz, Paul and Qualls, Lou and Smith, Michael and Ade, Brian and Navarro, Jorge},
	month = may,
	year = {2022},
	pages = {1--15},
}

@article{mazaheri_towards_2016,
	title = {Towards an evidence-based probabilistic risk model for ship-grounding accidents},
	volume = {86},
	url = {https://reader.elsevier.com/reader/sd/pii/S092575351630008X?token=CA036073758914EB7D04DA644CB79E093CACAB4760E69EB6BFA3698505390FC39C3A14A546210D14604604B89545763D&originRegion=us-east-1&originCreation=20220826174807},
	doi = {10.1016/j.ssci.2016.03.002},
	language = {en},
	urldate = {2022-08-26},
	journal = {Safety Science},
	author = {Mazaheri, Arsham and Montewka, Jakub and Kujala, Pentti},
	year = {2016},
	pages = {195--210},
}

@article{montewka_framework_2014,
	title = {A framework for risk assessment for maritime transportation systems—{A} case study for open sea collisions involving {RoPax} vessels},
	volume = {124},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832013003116?token=66F48B4BE5423DF521D73A57D09E77849C5A05C8F61E116E5A33CCA248044C38F80FBB9B27DB6F9FBB5BCA901AFEF06C&originRegion=us-east-1&originCreation=20220826174701},
	doi = {10.1016/j.ress.2013.11.014},
	language = {en},
	urldate = {2022-08-26},
	journal = {Reliability Engineering and System Safety},
	author = {Montewka, Jakub and Ehlers, Soren and Goerlandt, Floris and Hinz, Tomasz and Tabri, Kristjan and Kujala, Pentti},
	year = {2014},
	doi = {10.1016/j.ress.2013.11.014},
	pages = {142--157},
}

@article{panahi_developing_2022,
	title = {Developing a resilience assessment model for critical infrastructures: {The} case of port in tackling the impacts posed by the {Covid}-19 pandemic},
	volume = {226},
	issn = {0964-5691},
	shorttitle = {Developing a resilience assessment model for critical infrastructures},
	url = {https://reader.elsevier.com/reader/sd/pii/S0964569122002162?token=05FF7975D744E65ABCD3AF543AD443FE0F7B74389C6633A33FFBF30C1E413F39DC36A5B7F6FE3449CF06B3A62D6A774A&originRegion=us-east-1&originCreation=20220826174446},
	doi = {10.1016/j.ocecoaman.2022.106240},
	language = {en},
	urldate = {2022-08-26},
	journal = {Ocean \& Coastal Management},
	author = {Panahi, Roozbeh and Sadeghi Gargari, Negar and Lau, Yui-yip and Ng, Adolf},
	month = jul,
	year = {2022},
}

@article{eller_global_nodate,
	title = {{GLOBAL} {PERSISTENT} {ATTACK}: {A} {SYSTEMS} {ARCHITECTURE}, {PROCESS} {MODELING}, {AND} {RISK} {ANALYSIS} {APPROACH}},
	abstract = {This research developed a defendable and traceable Global Persistent Attack (GPA) risk analysis methodology and designed integrated architectural products based on GPA and Battlespace Awareness (BA) concepts of operation. The detailed architecture illustrates the commonality of capabilities and associated activities along with their critical relationships within Global Persistent Attack (GPA). The additional insight provided will allow the Air Force (AF) to better understand and quantify essential capabilities with associated activities to improve the decisions during the development of the future force construct. In order to accomplish risk identification and analysis, a Process Sequence Model (PSM) was developed to display the logical sequencing necessary for conducting GPA operations. Each activity and decision point was given a nodal probability of success and evaluated using Monte Carlo simulation to determine the overall mission probability of success. Sensitivity analysis was also accomplished to identify the capabilities most critical to the success of GPA operations. The identification of critical capabilities is essential to the proper development of the fiscally constrained force structure with respect to minimizing risk. Systems Engineering (SE) methodology and tools provide a structured, traceable process for identifying the critical relationships required to sustain the GPA concept. This insight will provide Air Combat Command (ACC) an improved decision making process to ensure the objectives of the national defense strategy can be attained while minimizing risk associated with the fiscally constrained force structure.},
	language = {en},
	author = {Eller, John and Hazel, Brian and Rooney, Brendan},
	pages = {245},
}

@techreport{chakravarthy_distributed_1999,
	address = {Fort Belvoir, VA},
	title = {Distributed {Events} in {Sentinel}: {Design} and {Implementation} of a {Global} {Event} {Detector}:},
	shorttitle = {Distributed {Events} in {Sentinel}},
	url = {http://www.dtic.mil/docs/citations/ADA360712},
	language = {en},
	urldate = {2022-08-26},
	institution = {Defense Technical Information Center},
	author = {Chakravarthy, S. and Liao, H. and Kim, H.},
	month = jan,
	year = {1999},
	doi = {10.21236/ADA360712},
}

@article{fussell_how_1975,
	title = {How to {Hand}-{Calculate} {System} {Reliability} and {Safety} {Characteristics}},
	volume = {R-24},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/5215142/},
	doi = {10.1109/TR.1975.5215142},
	abstract = {A simple method is given for calculating a) reliability char- are usually acceptable if they are in minimal cut sets also conacteristics of repairable and nonrepairable systems, and b) the import- taining rare events. "No primary event being failed at t = 0" ance of the individual system components. Assumptions made include independent component failures and constant failure and repair rates for the components. The methods can easily be implemented in a computer program that would be inexpensive to execute and would always overpredict (usually very slightly) the system failure characteristics. is assumed.},
	language = {en},
	number = {3},
	urldate = {2022-07-05},
	journal = {IEEE Transactions on Reliability},
	author = {Fussell, J.B.},
	month = aug,
	year = {1975},
	pages = {169--174},
}

@article{poucet_modular_1981,
	title = {Modular fault tree synthesis—{A} new method for computer-aided fault tree construction},
	volume = {2},
	issn = {01438174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0143817481900317},
	doi = {10.1016/0143-8174(81)90031-7},
	abstract = {A new methodology for the construction oJfault trees is developed. The methodology is based on fault tree modules constructed for different types of component circuits and stored in a module library.},
	language = {en},
	number = {1},
	urldate = {2022-07-05},
	journal = {Reliability Engineering},
	author = {Poucet, A. and De Meester, P.},
	month = jan,
	year = {1981},
	pages = {65--76},
}

@article{modarres_truncation_1984,
	title = {A {Truncation} {Methodology} for {Evaluating} {Large} {Fault} {Trees}},
	volume = {R-33},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/5221845/},
	doi = {10.1109/TR.1984.5221845},
	language = {en},
	number = {4},
	urldate = {2022-07-13},
	journal = {IEEE Transactions on Reliability},
	author = {Modarres, M. and Dezfuli, H.},
	month = oct,
	year = {1984},
	pages = {325--328},
}

@inproceedings{groen_algorithm_2006,
	address = {New Orleans, Louisiana, USA},
	title = {An {Algorithm} for the {Quantification} of {Hybrid} {Causal} {Logic} {Models}},
	abstract = {ABSTRACT This paper presents a new computational procedure for the quantification of fault trees containing dependent basic events. The quantification procedure expands the modeling power of fault trees, by allowing such enhancements as the quantification of multiple basic events in a fault tree by connecting them to different variables in a single Bayesian Belief Network (BBN) structure. The procedure was developed to support the analysis of Hybrid Causal Logic models, which are comprised of Event Sequence Diagrams (ESD), Fault Trees, and BBNs, and which are investigated as a way of modeling of causal factors with widespread influences in risk models.},
	language = {en},
	author = {Groen, Frank J and Mosleh, Ali},
	year = {2006},
	pages = {7},
}

@article{vaurio_treatment_2002,
	title = {Treatment of general dependencies in system fault-tree and risk analysis},
	volume = {51},
	issn = {0018-9529},
	url = {http://ieeexplore.ieee.org/document/1028400/},
	doi = {10.1109/TR.2002.801848},
	language = {en},
	number = {3},
	urldate = {2022-07-13},
	journal = {IEEE Transactions on Reliability},
	author = {Vaurio, J.K.},
	month = sep,
	year = {2002},
	pages = {278--287},
}

@article{choi_practical_2007,
	title = {A practical method for accurate quantification of large fault trees},
	volume = {92},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832006001608},
	doi = {10.1016/j.ress.2006.07.005},
	abstract = {This paper describes a practical method to accurately quantify top event probability and importance measures from incomplete minimal cut sets (MCS) of a large fault tree. The MCS-based fault tree method is extensively used in probabilistic safety assessments. Several sources of uncertainties exist in MCS-based fault tree analysis. The paper is focused on quantiﬁcation of the following two sources of uncertainties: (1) the truncation neglecting low-probability cut sets and (2) the approximation in quantifying MCSs. The method proposed in this paper is based on a Monte Carlo simulation technique to estimate probability of the discarded MCSs and the sum of disjoint products (SDP) approach complemented by the correction factor approach (CFA). The method provides capability to accurately quantify the two uncertainties and estimate the top event probability and importance measures of large coherent fault trees. The proposed fault tree quantiﬁcation method has been implemented in the CUTREE code package and is tested on the two example fault trees.},
	language = {en},
	number = {7},
	urldate = {2022-07-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Choi, Jong Soo and Cho, Nam Zin},
	month = jul,
	year = {2007},
	pages = {971--982},
}

@inproceedings{zvoncek_comparison_2018,
	title = {Comparison of {MCUB} and {MCS} {BDD} {Fault} {Tree} {Solution} {Algorithms} using {Leibstadt} {Nuclear} {Power} {Plant} {Model}},
	abstract = {This paper summarizes the benchmark calculations recently undertaken at Leibstadt nuclear power plant (KKL) with a goal of comparing two fault tree quantification algorithms available in the RiskSpectrum PSA software, namely Min Cut Upper Bound (MCUB) and the more recently implemented Minimal Cut Set Binary Decision Diagram (MCS BDD) approach.},
	language = {en},
	booktitle = {Los {Angeles}},
	author = {Zvoncek, Pavol and Nusbaumer, Olivier},
	year = {2018},
	pages = {12},
}

@inproceedings{wang_quantification_2014,
	address = {Honolulu, Hawaii},
	title = {Quantification of {MCS} with {BDD}, {Accuracy} and {Inclusion} of {Success} in the {Calculation} – the {RiskSpectrum} {MCS} {BDD} {Algorithm}},
	abstract = {A quantification of a PSA can be performed through different techniques, of which the Minimal Cut Set (MCS) generation technique and Binary Decision Diagrams (BDD) are the most well known. There is only one advantage with the MCS approach compared to the BDD approach calculation time, or rather, the capability to always solve the problem. In most cases the MCS approach is fully sufficient. But as the number of high probability events increases, e.g. due to seismic risk assessments, more accurate methods may be necessary. In some applications, a relevant numerical treatment of success in event trees may also be required to avoid overly conservative results.},
	language = {en},
	author = {Wang, Wei and Bäckström, Ola and Krcal, Pavel},
	year = {2014},
	pages = {12},
}

@inproceedings{modarres_review_2019,
	address = {Charleston, SC},
	title = {A {REVIEW} {OF} {SELECTED} {MULTI}-{UNIT} {PRA} {ISSUES}},
	language = {en},
	author = {Modarres, Mohammad},
	month = may,
	year = {2019},
	pages = {5},
}

@inproceedings{marie_lanore_international_2008,
	address = {Knoxville, TN, USA},
	title = {International {Review} of the {Use} and {Development} of {PSA}},
	abstract = {The main objective of the Working Group on Risk Assessment (WGRisk) of the Nuclear Energy Agency (NEA)/Committee on the Safety of Nuclear Installations (CSNI) is to advance the PSA understanding and to enhance its utilisation for improving the safety of nuclear installations. To accomplish this mission, WGRisk performs a number of activities to exchange PSA-related information between member countries. The results of a recent exchange have been compiled in a CSNI report entitled “The Use and Development of Probabilistic Safety Assessment.” Responses were received from 20 countries totalling several hundred pages of information.},
	language = {en},
	booktitle = {{ANS} {International} {Topical} {Meeting} on {Probabilistic} {Safety} {Assessment} and {Analysis}},
	author = {Marie Lanore, Jeanne and Pyy, Pekka and Siu, Nathan},
	year = {2008},
	pages = {13},
}

@techreport{morissette_canister_2001,
	title = {Canister {Transfer} {System} {Event} {Sequence} {Calculation}},
	url = {https://www.osti.gov/biblio/790349-canister-transfer-system-event-sequence-calculation},
	abstract = {The ''Department of Energy Spent Nuclear Fuel Canister, Transportation, and Monitored Geologic Repository Systems, Structures, and Components Performance Allocation Study'' (CRWMS M\&O 2000b) allocated performance to both the canisters received at the Monitored Geologic Repository (MGR) and the MGR Canister Transfer System (CTS). The purpose of this calculation is to evaluate an assumed range of canister and CTS performance allocation failure probabilities and determine the effect of these failure probabilities on the frequency of a radionuclide release. Five canister types are addressed in this calculation; high-level radioactive waste (HLW) canisters containing vitrified borosilicate glass, HLW canisters containing immobilized plutonium surrounded by borosilicate glass (Pu/HLW canisters), Department of Energy (DOE) spent nuclear fuel (DSNF) standard canisters (4 sizes), DSNF multi-canister overpacks (MCOs) for N-reactor fuel and other selected DSNF, and naval spent nuclear fuel (SNF) canisters (2 sizes). The quality assurance program applies to this calculation, and the work is performed in accordance with procedure AP-3.12Q, ''Calculations''. The work done for this calculation was evaluated according to AP-2.21Q, ''Quality Determinations and Planning for Scientific, Engineering, and Regulatory Compliance Activities'' that determined this activity to be subject to the requirements of DOE/RW-0333P, ''Quality Assurance Requirements and Description'' (DOE 2000a). This work was performed in accordance with the ''Technical Work Plan for: Department of Energy Nuclear Fuel Work Packages'' (CRWMS M\&O 2000c) for this activity.},
	language = {English},
	number = {MOL.20010905.0142},
	urldate = {2022-08-25},
	institution = {Yucca Mountain Project, Las Vegas, NV (United States)},
	author = {Morissette, Richard},
	month = aug,
	year = {2001},
	doi = {10.2172/790349},
}

@techreport{hardin_methodology_2017,
	title = {Methodology for {Radiological} {Risk} {Assessment} of {Deep} {Borehole} {Disposal} {Operations}},
	url = {https://www.osti.gov/biblio/1365475},
	abstract = {The primary purpose of the preclosure radiological safety assessment (that this document supports) is to identify risk factors for disposal operations, to aid in design for the deep borehole field test (DBFT) engineering demonstration.},
	language = {English},
	number = {SAND2017-3281R},
	urldate = {2022-08-25},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Hardin, Ernest and Su, Jiann-Cherng and Peretz, Fred},
	month = mar,
	year = {2017},
	doi = {10.2172/1365475},
}

@inproceedings{xie_layered_2010,
	title = {Layered {Modeling} of {Event} {Sequence} {Diagram} for {Dynamic} {Reliability} {Analysis} of {Nuclear} {Power} {Plant}},
	doi = {10.1109/APPEEC.2010.5448555},
	abstract = {As the event sequence diagram (ESD) methodology is used for modeling the complex system, the event simply describes system configuration and status in order to control the size of the model, so the model can't directly reflect the design and operation limitation. According to the hierarchy feature for the structure of nuclear power plant, a layered modeling of ESD is presented for marine nuclear power plant. Through introducing the fault tree analysis method and combining it with ESD, the weakness of the system can be found out. The ESD constructed through layered modeling is well arranged, distinct and with proper size, suitable for dynamic reliability analysis of nuclear power plant.},
	booktitle = {2010 {Asia}-{Pacific} {Power} and {Energy} {Engineering} {Conference}},
	author = {Xie, Hai-yan and Cai, Qi and Zhang, Yang-wei},
	month = mar,
	year = {2010},
	note = {ISSN: 2157-4847},
	keywords = {Delay effects, Design engineering, Educational institutions, Electrostatic discharge, Fault trees, Power engineering and energy, Power generation, Power system modeling, Power system reliability, Reliability engineering},
	pages = {1--3},
}

@article{paglioni_dependency_2022,
	title = {Dependency definitions for quantitative human reliability analysis},
	volume = {220},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183202100747X},
	doi = {10.1016/j.ress.2021.108274},
	abstract = {Human reliability analysis (HRA) identifies the causal factors impacting the occurrence of human failure events and quantifies probabilities based on those causal factors. Quantification requires understanding the dependency structures that exist between failure events and causal factors. Most HRA methods incorporate the dependency framework established in the Technique for Human Error Rate Prediction (THERP), which approaches dependency as a simple multiplier on HEPs resulting from considering only a few factors. Accordingly, modern HRA methods have a limited ability and accuracy when characterizing dependency. The fundamental concept of dependency in HRA methods is approaching 60 years without a serious assessment of its veracity or applicability. Misconceptions and confusion surrounding fundamental concepts in HRA are largely responsible for the lack of substantive improvement in the technical basis of dependency. This paper defines dependency for HRA and provides clarification and unification around related concepts. We propose a standardized library of key terms and mathematics to provide a basis for the development of a dependency framework. We clarify the meaning of, and difference between, critical dependency concepts and propose a general lexicography for decomposing scenarios. We present a holistic linguistic and mathematical definition for dependency in HRA.},
	language = {en},
	urldate = {2022-08-19},
	journal = {Reliability Engineering \& System Safety},
	author = {Paglioni, Vincent P. and Groth, Katrina M.},
	month = apr,
	year = {2022},
	keywords = {Dependency, Human error probability, Human failure event, Human reliability analysis, Keywords, Performance influencing factor},
	pages = {108274},
}

@techreport{noauthor_reactor_1975,
	title = {Reactor {Safety} {Study}: {An} {Assessment} of {Accident} {Risks} in {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr75-014/},
	number = {NUREG-75/014 (WASH-1400)},
	urldate = {2019-02-02},
	institution = {United States Nuclear Regulatory Commission},
	month = oct,
	year = {1975},
}

@article{purba_master_2018,
	title = {Master {Logic} {Diagram}: {An} {Approach} to {Identify} {Initiating} {Events} of {HTGRs}},
	volume = {962},
	issn = {1742-6596},
	shorttitle = {Master {Logic} {Diagram}},
	url = {https://doi.org/10.1088/1742-6596/962/1/012036},
	doi = {10.1088/1742-6596/962/1/012036},
	abstract = {Initiating events of a nuclear power plant being evaluated need to be firstly identified prior to applying probabilistic safety assessment on that plant. Various types of master logic diagrams (MLDs) have been proposedforsearching initiating events of the next generation of nuclear power plants, which have limited data and operating experiences. Those MLDs are different in the number of steps or levels and different in the basis for developing them. This study proposed another type of MLD approach to find high temperature gas cooled reactor (HTGR) initiating events. It consists of five functional steps starting from the top event representing the final objective of the safety functions to the basic event representing the goal of the MLD development, which is an initiating event. The application of the proposed approach to search for two HTGR initiating events, i.e. power turbine generator trip and loss of offsite power, is provided. The results confirmed that the proposed MLD is feasiblefor finding HTGR initiating events.},
	language = {en},
	urldate = {2022-08-18},
	journal = {Journal of Physics: Conference Series},
	author = {Purba, J. H.},
	month = feb,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {012036},
}

@inproceedings{wang_numerical_2014,
	title = {Numerical {Analysis} of the {Residual} {Heat} {Removal} for the {Spent} {Fuel} {Canister} of {HTR}-{PM} in {Fuel} {Loading} {Process}},
	url = {http://thermalscienceapplication.asmedigitalcollection.asme.org/ICONE/proceedings/ICONE22/45943/V004T10A006/251679},
	doi = {10.1115/ICONE22-30284},
	language = {en},
	urldate = {2022-08-16},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Wang, Jinhua and Wang, Bing and Wu, Bin},
	month = nov,
	year = {2014},
}

@inproceedings{wang_cfd_2016,
	title = {{CFD} {Simulation} of {Natural} {Ventilation} {Performance} of the {Interim} {Region} in {Spent} {Fuel} {Dry}-{Storage} {System} of {HTR}-{PM}},
	url = {http://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE24/50046/V004T10A010/251786},
	doi = {10.1115/ICONE24-60238},
	language = {en},
	urldate = {2022-08-16},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Wang, Bing and Wang, Jinhua and Jia, Haijun},
	month = oct,
	year = {2016},
}

@inproceedings{wang_jinhua_design_2014,
	address = {China},
	title = {Design of the {HTR}-{PM} {Spent} {Fuel} {Storage} {Facility}},
	isbn = {978-7-89395-349-1},
	abstract = {The Pebble bed Modular High Temperature gas cooled Reactor (HTR-PM) making use of
spherical fuel elements, distinguish from pressurized water reactor The Spent Fuel
elements (SF) discharged from the reactor core should be stored in the appropriate
storage canisters, and the canisters filled with spent fuel elements should be stored
in the appropriate interim storage facility at first decades The main functions of
the HTR-PM spent fuel storage system (SFSS) is transporting the spent fuel elements
from the fuel handling system to the spent fuel canister, and then load the storage
canister into the storage compartment, which have sufficient capacity to store the
fuel elements produced in the whole life of the plant, including spent fuel, graphite
fuel, partially burnt fuel and the fuel out of commission The spent fuel storage system
is an important system holding huge radiation elements, in process of handling fuel
storage canister and in storage period, it should be ensured that the handling operation
is safe all the time, the fuel pebbles are in subcritical condition, the radiation
should be shielded sufficiently, and the decay heat should be discharged from the
spent fuel canister and the storage facility safely in all supposed conditions The
spent fuels store in the spent fuel canisters, which could be loaded into the transport
cask; it is convenient to transfer the spent fuel canister from the interim storage
facility to other sites The canisters could be ordered by stages with the operation
of the plant Type 304L stainless steel would be used as the material of the spent
fuel canisters, which could last several decades with only slight corrosion on the
outside surface in the marine atmosphere The spent fuel discharged from the reactor
core would decay for a long time; the decay heat should be cooled after the spent
fuel canister is stored in the storage facility In the first 30 months of the storage
period, the decay heat is discharged by active cooling method, after that, the decay
heat could be cooled passively by natural chimney effect In supposed extreme conditions,
the decay heat could be discharged from the spent fuel canisters and the storage facility
safely When it is required to transfer the spent fuels from the interim storage facility
to other sites, the spent fuel canisters could be taken out from the storage facility
conveniently, and could be lifted into the transport cask directly through the operation
of the hoister The facility and the equipment could be dismantled and out of commission
conveniently without radioactive contamination (author)},
	publisher = {Tsinghua University},
	author = {{Wang Jinhua} and {Zhang Zuoyi} and {Wu Bin} and {Li Yue}},
	year = {2014},
	note = {INIS Reference Number: 48076909},
	pages = {v},
}

@techreport{farley_global_2020,
	title = {Global {Trends} of {ASME} ?{N}-{Stamp}? {Certifications} for {Nuclear} {Component} {Vendors}.},
	shorttitle = {Global {Trends} of {ASME} ?},
	url = {https://www.osti.gov/servlets/purl/1813661/},
	language = {en},
	number = {SAND2020-14254, 1813661, 697718},
	urldate = {2022-08-15},
	author = {Farley, David},
	month = dec,
	year = {2020},
	doi = {10.2172/1813661},
	pages = {SAND2020--14254, 1813661, 697718},
}

@misc{noauthor_saphire_nodate,
	title = {{SAPHIRE} {\textbar} {Training} {Info}},
	url = {https://saphire.inl.gov/#/},
	urldate = {2022-08-09},
}

@article{wang_icone23-1444_2015,
	title = {{ICONE23}-1444 {DESIGN} {OF} {THE} {GROUND} {CRANE} {AND} {SHIELDING} {CASK} {FOR} {THE} {SPENT} {FUEL} {CANISTER} {OF} {HTR}-{PM}},
	volume = {2015.23},
	doi = {10.1299/jsmeicone.2015.23._ICONE23-1_204},
	abstract = {The High Temperature gas cooled Reactor Pebble bed Module (HTR-PM) is in design and construction process in China, which is considered as one of the candidates for the Gen-IV nuclear power plant, and has advantage of inherent safety, avoiding nuclear proliferation, high temperature industry heat production and so on. The sphere fuel element is used in HTR-PM. The fuel particles are spread in the fuel element, and the sphere element's diameter is 60mm after oppression. After discharged from the HTR reactor core, the spent fuel element would be transferred into the spent fuel canister. The spent fuel canister would be stored in the spent fuel storage well after fully loaded. In the process of the spent fuel storage and operation, it is required to ensure the operation safety, subcritical, radiation shielding safety and residual heat removal safety. In order to decrease the price of the spent fuel canister, the canister was designed as a thin shell vessel, which has weak radiation shielding function, and cannot fulfill safety requirement of radiation shielding, so it is required to research and design a set of devices, which could provide enough radiation shielding for the spent fuel canister, and the device could also transfer the spent fuel canister safely and reliably, and then the safety of the operation staff and the facility could be ensured. The concrete shielding well lid is set on top of the storage well, when the spent fuel canister is needed to put into the storage well, the well lid would be taken out from its mounting position. In the operation process of the spent fuel canister and the concrete shielding well lid, the ground crane with accurate positioning function is required to position the spent fuel canister and the concrete shielding well lid to the operating position. The main components of the ground crane system includes: Crane bridge, shielding cask, neutron shielding boron barrel, canister hoisting mechanism, well lid hoisting mechanism, bottom plate opening mechanism, shielding strip mechanism, residual removal blowers, butterfly valves, ground rails, cable sliding bridge, encoder positioning scale and so on. The ground crane could satisfy the accurate positioning and safe operation of the spent fuel canister, and could ensure the operating reliability of the spent fuel canister and the concrete shielding well lid in HTR-PM operational period.},
	journal = {The Proceedings of the International Conference on Nuclear Engineering (ICONE)},
	author = {WANG, Jinhua and LIU, Xiang and WANG, Bing and LI, Yue and WU, Bin},
	month = may,
	year = {2015},
	pages = {\_ICONE23--1},
}

@article{kiegiel_management_2022,
	title = {Management of {Radioactive} {Waste} from {HTGR} {Reactors} including {Spent} {TRISO} {Fuel}—{State} of the {Art}},
	volume = {15},
	doi = {10.3390/en15031099},
	abstract = {In light of the increasing demand for energy sources in the world and the need to meet climate goals set by countries, there is growing global interest in high temperature gas cooled reactors (HTGRs), especially as they are known to be inherently safe nuclear reactors. The safety of HTGRs results, among other, from the nature of the nuclear fuel used in them in the form of coated TRISO particles (tri-structural-isotropic) and the reduction of the total amount of radioactive waste generated. This paper reviews numerous methods used to ensure the sustainable, feasible management and long-term storage of HTGR nuclear waste for the protection of the environment and society. The types of waste generated in the HTGR cycle are presented as well as the methods of their characterization, which are important for long-time storage and final disposal. Two leading nuclear fuel cycle strategies, the once-through cycle (direct disposal or open cycle) and the twice-through cycle (recycling or partially closed cycle), are discussed also in relation to TRISO spent fuel. A short review of the possibilities of treatment of TRISO spent nuclear fuel from HTGR reactors is made.},
	journal = {Energies},
	author = {Kiegiel, Katarzyna and Herdzik, Irena and Fuks, Leon and Zakrzewska, Grazyna},
	month = feb,
	year = {2022},
	pages = {1099},
}

@phdthesis{lee_probabilistic_2022,
	title = {A {Probabilistic} {Risk} {Assessment} {Model} for the {Transportation} of {Fission} {Batteries} with {Preliminary} {Licensing} {Considerations} for {Civilian} {Applications} and {Deployment} {Considerations} for {Military} {Applications}.},
	url = {https://repository.lib.ncsu.edu/bitstream/handle/1840.20/39668/etd.pdf?sequence=1&isAllowed=y},
	urldate = {2022-08-09},
	school = {North Carolina State University},
	author = {Lee, Daeho},
	month = apr,
	year = {2022},
}

@misc{arafat_westinghouse_2019,
	address = {Idaho National Laboratory},
	title = {Westinghouse {eVinci}™ {Micro}-{Reactor} {Program}},
	url = {https://gain.inl.gov/SiteAssets/Micro-ReactorWorkshopPresentations/Presentations/13-Arafat-GAINMicro-reactorWorkshop_June2019_Westinghouse_RSB.pdf},
	language = {en},
	author = {Arafat, Yasir},
	month = jun,
	year = {2019},
}

@inproceedings{nguyen_distributed_2017,
	title = {Distributed {MPI} cluster with {Docker} {Swarm} mode},
	doi = {10.1109/CCWC.2017.7868429},
	abstract = {MPI is a well-established technology that is used widely in high-performance computing environment. However, setting up an MPI cluster can be challenging and time-consuming. This paper tackles this challenge by using modern containerization technology, which is Docker, and container orchestration technology, which is Docker Swarm mode, to automate the MPI cluster setup and deployment. We created a ready-to-use solution for developing and deploying MPI programs in a cluster of Docker containers running on multiple machines, orchestrated with Docker Swarm mode, to perform high computation tasks. We explain the considerations when creating Docker image that will be instantiated as MPI nodes, and we describe the steps needed to set up a fully connected MPI cluster as Docker containers running in a Docker Swarm mode. Our goal is to give the rationale behind our solution so that others can adapt to different system requirements. All pre-built Docker images, source code, documentation, and screencasts are publicly available.},
	booktitle = {2017 {IEEE} 7th {Annual} {Computing} and {Communication} {Workshop} and {Conference} ({CCWC})},
	author = {Nguyen, Nikyle and Bein, Doina},
	month = jan,
	year = {2017},
	keywords = {Cloud computing, Cluster Automation, Computers, Container, Containers, Distributed System, Docker, Docker Swarm mode, File systems, HPC, Linux, MPI, Operating systems},
	pages = {1--7},
}

@techreport{apostolakis_proposed_2012,
	title = {A {Proposed} {Risk} {Management} {Regulatory} {Framework}},
	url = {https://www.nrc.gov/docs/ML1210/ML12109A277.pdf},
	number = {NUREG-2150},
	urldate = {2021-11-24},
	author = {Apostolakis, G. and Lui, C. and Cunningham, M.},
	month = apr,
	year = {2012},
}

@techreport{parisi_risk-informed_2017,
	title = {Risk-{Informed} {External} {Hazards} {Analysis} for {Seismic} and {Flooding} {Phenomena} for a {Generic} {PWR}},
	url = {http://www.osti.gov/servlets/purl/1376899/},
	language = {en},
	number = {INL/EXT-17-42666, 1376899},
	urldate = {2022-08-05},
	author = {Parisi, Carlo and Prescott, Steve and Ma, Zhegang and Spears, Bob and Szilard, Ronaldo and Coleman, Justin and Kosbab, Ben},
	month = jul,
	year = {2017},
	doi = {10.2172/1376899},
	pages = {INL/EXT--17--42666, 1376899},
}

@article{pande_estimation_2019,
	title = {{ESTIMATION} {OF} {THE} {RADIOACTIVE} {SOURCE} {TERM} {FROM} {RDE} {ACCIDENT} {POSTULATION}},
	volume = {21},
	doi = {10.17146/tdm.2019.21.3.5583},
	abstract = {The design process of Experimental Power Reactor (Reaktor Daya Eksperimental/RDE) has been carried out by BATAN for the last five years, adopting HTGR-type reactor with thermal power of 10 MW. RDE is designed with the reference of similar reactor, namely HTR-10. During this process, source term estimation is required to prove the safety of RDE design, as well as to fulfill the concept of As Low As Reasonably Achievable (ALARA) in radiation protection. The source term is affected by the magnitude of the radioactive substances released from the reactor core due to an accident. Conservative accident postulations on the RDE are water ingress and depressurization accidents. Based on these postulations, source term estimation was performed. It follows the mechanistic source term flow, with conservative assumptions for the radioactive release of fuel into the coolant, reactor building, and finally discharged into the environment. Assumptions for the calculation are taken from conservative removable parameters.The result of source term calculation due to the water ingress accident for Xe-133 noble gas is 8.97E+12 Bq, Cs-137 is 3.59E+07 Bq, and I-131 is 4.34E+10 Bq. As for depressurization accident, the source term activity for Xe-133 is 3.90E+13Bq, Cs-137 is 1.56E+07 Bq, and I-131 is 1.89E+10Bq. The source term calculation results obtained in this work shows a higher number compared to the HTR-10 source term used as a reference. The difference is possibly due to the differences in reactor inventory calculations and the more conservative assumptions for source term calculation.Keywords: RDE, HTGR, Radioactive, Source term, accident},
	journal = {JURNAL TEKNOLOGI REAKTOR NUKLIR TRI DASA MEGA},
	author = {Pande, Udiyani and Husnayani, Ihda and Setiawan, Muhammad Budi and Kuntjoro, Sri and Adrial, Hery and Hamzah, Amir},
	month = nov,
	year = {2019},
	pages = {113},
}

@techreport{smith_generic_2021,
	title = {Generic {Pressurized} {Water} {Reactor} {Model} for {SAPHIRE}},
	url = {https://www.osti.gov/servlets/purl/1804754/},
	language = {en},
	number = {INL/EXT-21-62553-Rev000, 1804754},
	urldate = {2022-08-04},
	author = {Smith, Curtis},
	month = apr,
	year = {2021},
	doi = {10.2172/1804754},
	pages = {INL/EXT--21--62553--Rev000, 1804754},
}

@misc{noauthor_backgrounder_nodate,
	title = {Backgrounder on {Nuclear} {Power} {Plant} {Licensing} {Process}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/fact-sheets/licensing-process-fs.html},
	urldate = {2022-08-03},
	journal = {NRC Web},
}

@article{seang_proof_nodate,
	title = {Proof of {Work} and {Proof} of {Stake} consensus protocols: a blockchain application for local complementary currencies},
	url = {https://www.gate.cnrs.fr/IMG/pdf/seang_torre.pdf},
	abstract = {This paper examines with the help of a theoretical setting the properties of two blockchains’ consensus protocols (Proof of Work and Proof of Stake) in the management of a local (or networks of local) complementary currency(ies). The model includes the control by the issuer of advantages of the use of the currency by heterogeneous consumers, and the determination of rewards of also heterogeneous validators (or miners). It considers also the resilience of the validation protocols to malicious attacks conducted by an individual or pools of validators. Results exhibit the interest of the Proof of Stake protocol for small communities of users of the complementary currency, despite the Proof of Work Bitcoin like system could have advantages when the size of the community increases.},
	language = {en},
	author = {Seang, Sothearath and Torre, Dominique},
	pages = {21},
}

@misc{noauthor_backgrounder_nodate-1,
	title = {Backgrounder on {Decommissioning} {Nuclear} {Power} {Plants}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/fact-sheets/decommissioning.html},
	urldate = {2022-08-03},
	journal = {NRC Web},
}

@techreport{noauthor_terminology_nodate,
	title = {Terminology {Used} in {Nuclear} {Safety} and {Radiation} {Protection} 2018 {Edition}},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/PUB1830_web.pdf},
	urldate = {2020-09-05},
}

@inproceedings{cleary_integration_nodate,
	title = {Integration of the {Advanced} {Transparency} {Framework} to {Advanced} {Nuclear} {Systems}},
	url = {https://www.osti.gov/servlets/purl/1143216},
	abstract = {The advent of the nuclear renaissance gives rise to a concern for the effective design of nuclear fuel cycle systems that are safe, secure, nonproliferating and cost-effective. We propose to integrate the monitoring of the four major factors of nuclear facilities by focusing on the interactions between Safeguards, Operations, Security, and Safety (SOSS). We proposed to develop a framework that monitors process information continuously and can demonstrate the ability to enhance safety, operations, security, and safeguards by measuring and reducing relevant SOSS risks, thus ensuring the safe and legitimate use of the nuclear fuel cycle facility. A real-time comparison between expected and observed operations provides the foundation for the calculation of SOSS risk. The automation of new nuclear facilities requiring minimal manual operation provides an opportunity to utilize the abundance of process information for monitoring SOSS risk. A framework that monitors process information continuously can lead to greater transparency of nuclear fuel cycle activities and can demonstrate the ability to enhance the safety, operations, security and safeguards associated with the functioning of the nuclear fuel cycle facility.},
	language = {en},
	author = {Cleary, Virginia D},
	pages = {7},
}

@techreport{noauthor_addressing_nodate,
	title = {Addressing {Verfication} {Challenges}.},
	url = {https://cvt.engin.umich.edu/wp-content/uploads/sites/173/2014/10/ADDRESSING-VERIFICATION-CHALLENGES-IAEA-2007.pdf},
	urldate = {2020-09-14},
}

@techreport{noauthor_iaea_nodate,
	title = {{IAEA} {Safeguards} {Information} {Systems}.},
	url = {https://inis.iaea.org/collection/NCLCollectionStore/_Public/16/022/16022428.pdf?r=1&r=1},
	language = {en},
	institution = {IAEA},
	pages = {42},
}

@techreport{noauthor_iaea_nodate-1,
	title = {{IAEA} {Safety} {Standards}: {Leadership} and {Management} for {Safety}},
	url = {https://www.iaea.org/publications/11070/leadership-and-management-for-safety},
	language = {en},
	institution = {IAEA},
	pages = {42},
}

@techreport{noauthor_us_nodate,
	title = {The {U}.{S}. {Nuclear} {Energy} {Enterprise}: {A} {Key} {National} {Security} {Enabler}},
	url = {https://static1.squarespace.com/static/58ec123cb3db2bd94e057628/t/5992f7e0bf629ad8f9d575ec/1502803938248/EFI+Nuclear+Report+FINAL+08.2017.pdf},
	institution = {Energy Futures Initiative},
}

@misc{tannenbaum_nuclear_nodate,
	title = {Nuclear supply chain challenges and opportunities},
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwi2nJHAuqv5AhWjFjQIHenkCbgQFnoECAYQAQ&url=https%3A%2F%2Fwww.ans.org%2Fpubs%2Fmagazines%2Fdownload%2Farticle-1157%2F&usg=AOvVaw10rh2lshtDozMulV4YPsOX},
	author = {Tannenbaum, Marc},
}

@misc{kaser_world_2014,
	title = {The {World} {Nuclear} {Supply} {Chain} – {An} {Overview}},
	url = {https://www.oecd-nea.org/upload/docs/application/pdf/2020-07/wpne_workshop_2._1_the_world_nuclear_supply_chain_an_overview.pdf},
	language = {en},
	author = {Kaser, Greg},
	year = {2014},
}

@techreport{noauthor_commissioning_nodate,
	title = {Commissioning {Guidelines} for {Nuclear} {Power} {Plants}.pdf},
	url = {https://www.iaea.org/publications/10975/commissioning-guidelines-for-nuclear-power-plants},
	institution = {IAEA},
}

@misc{uhrig_construction_nodate,
	title = {Construction of {Nuclear} {Power} {Plants}},
	url = {May 8, 2008},
	language = {en},
	author = {Uhrig, Robert E},
}

@techreport{noauthor_construction_2015,
	title = {Construction for {Nuclear} {Installations}: {Safety} {Specific} {Guide}.},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/Pub1693Web-54107132.pdf},
	language = {en},
	institution = {IAEA},
	year = {2015},
	note = {OCLC: 1039255292},
}

@techreport{noauthor_lic-115_nodate,
	title = {{LIC}-115, "{Processing} {Requests} for {Additional} {Information}"},
	url = {https://www.nrc.gov/docs/ML1924/ML19242B237.pdf},
	abstract = {This is the initial issuance of LIC-115, which consolidates guidance from NRO Office Instruction NRO-REG-101, “Development, Review and Approval Process for Requests for Additional Information,” and NRR Office Instruction LIC-101, “License Amendment Review Procedures,” regarding requests for additional information (RAIs). This consolidation is due to the NRR/NRO reunification. The staff will update this office instruction after implementation of the electronic RAI (eRAI) system across the reunified office in October 2020. This issuance incorporates and rescinds the related NRO instruction NRO-REG-101.},
	language = {en},
	institution = {Office of Nuclear Reactor Regulation, U.S. Nuclear Regulatory Commission},
	pages = {35},
}

@techreport{noauthor_iaea_2016,
	title = {{IAEA} {Safety} {Glossary}},
	url = {https://www-ns.iaea.org/downloads/standards/glossary/iaea-safety-glossary-draft-2016.pdf},
	urldate = {2020-09-04},
	institution = {IAEA},
	year = {2016},
}

@techreport{noauthor_alternative_2014,
	title = {Alternative contracting and ownership approaches for new nuclear power plants.},
	url = {http://www-pub.iaea.org/MTCD/Publications/PDF/TE-1750_web.pdf},
	abstract = {"This publication examines alternative contracting and ownership approaches for the development, construction, commissioning, operation, and decommissioning of new nuclear power plants. It identifies issues faced by IAEA Member States considering the applicability of such approaches to their respective national programmes. Two new approaches to nuclear project development are analysed. These are, firstly, the Build-Own-Operate (BOO)/Build-Own-Operate-Transfer (BOO(T)) and, secondly, Regional approaches. The information includes practical examples, current practices, and case studies, and reflects the presentations and discussions that took place in a series of IAEA meetings on this topic."--Résumé de l'éditeur.},
	language = {en},
	urldate = {2020-09-04},
	year = {2014},
	note = {OCLC: 1132029960},
}

@misc{noauthor_part_nodate,
	title = {Part 50: {Domestic} {Licensing} of {Production} and {Utilization} {Facilities}.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/full-text.html},
	urldate = {2022-08-03},
	journal = {NRC Web},
}

@misc{noauthor_p_nodate,
	title = {P},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part052/full-text.html},
	urldate = {2022-08-03},
	journal = {NRC Web},
}

@misc{noauthor_nuscale_nodate,
	title = {{NuScale} {Receives} {NRC} {Design} {Approval} {\textbar} {NUCLEUS} {Fall} 2020 {\textbar} {NuScale} {Power} {\textbar} {NuScale} {Power}},
	url = {https://www.nuscalepower.com/newsletter/nucleus-fall-2020/program-development-update},
	urldate = {2022-08-03},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC} to certify {NuScale} small modular reactor design for use in the {US}},
	url = {https://www.utilitydive.com/news/nrc-certifies-nuscale-small-modular-reactor-design-SMR-nuclear-us/628519/},
	abstract = {The first small modular nuclear reactor design to be approved in the U.S. is expected to go online at an Energy Department laboratory in Idaho in 2029.},
	language = {en-US},
	urldate = {2022-08-03},
	journal = {Utility Dive},
}

@misc{noauthor_idaho_nodate,
	title = {Idaho {National} {Laboratory} {Builds} {Full}-{Scale} {Prototype} for {Microreactor} {Project}},
	url = {https://www.energy.gov/ne/articles/idaho-national-laboratory-builds-full-scale-prototype-microreactor-project},
	abstract = {INL built a full-scale, electrically heated prototype to support the U.S. Department of Energy’s new MARVEL microreactor project.},
	language = {en},
	urldate = {2022-08-03},
	journal = {Energy.gov},
}

@misc{noauthor_westinghouse_nodate,
	title = {Westinghouse {Nuclear} {\textgreater} {Energy} {Systems} {\textgreater} {eVinci}™ {Micro}-{Reactor}},
	url = {https://www.westinghousenuclear.com/energy-systems/evinci-micro-reactor},
	urldate = {2022-08-03},
}

@misc{noauthor_bwx_nodate,
	title = {{BWX} {Technologies}, {Inc}. {\textbar} {People} {Strong}, {Innovation} {Driven}},
	url = {http://www.bwxt.com/news},
	abstract = {BWX Technologies, Inc. is a leading supplier of nuclear components and fuel to the U.S. government, also providing components and services to the commercial nuclear power industry.},
	language = {en},
	urldate = {2022-08-03},
}

@misc{noauthor_reactor_nodate,
	title = {Reactor: {Xe}-100 — {X}-energy: {HTGR} {\textbar} {Nuclear} {Reactors} ({SMR}) \& {TRISO} {Fuel}},
	shorttitle = {Reactor},
	url = {https://x-energy.com/reactors/xe-100},
	abstract = {We’re focused on Gen-IV High-Temperature Gas-cooled Reactors (HTGR) as the technology of choice, with advantages in sustainability, economics, reliability and safety.},
	language = {en-US},
	urldate = {2022-08-03},
	journal = {X-energy},
}

@misc{noauthor_technology_nodate,
	title = {Technology {\textbar} {NuScale} {Power}},
	url = {https://www.nuscalepower.com/technology},
	urldate = {2022-08-03},
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {Small} {Modular} {Reactors} ({SMRs})},
	url = {https://www.energy.gov/ne/advanced-small-modular-reactors-smrs},
	abstract = {Information on advanced small modular reactors and the Department of Energy's Small Modular Reactor Licensing Technical Support (SMR-LTS) Program.},
	language = {en},
	urldate = {2022-08-03},
	journal = {Energy.gov},
}

@article{atserias_bounded-width_2014,
	title = {Bounded-width {QBF} is {PSPACE}-complete},
	volume = {80},
	issn = {00220000},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022000014000580},
	doi = {10.1016/j.jcss.2014.04.014},
	language = {en},
	number = {7},
	urldate = {2022-08-02},
	journal = {Journal of Computer and System Sciences},
	author = {Atserias, Albert and Oliva, Sergi},
	month = nov,
	year = {2014},
	pages = {1415--1429},
}

@inproceedings{bryant_generating_2021,
	title = {Generating extended resolution proofs with a {BDD}-based {SAT} solver},
	booktitle = {International {Conference} on {Tools} and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
	publisher = {Springer},
	author = {Bryant, Randal E and Heule, Marijn JH},
	year = {2021},
	pages = {76--93},
}

@inproceedings{marques-silva_practical_2008,
	title = {Practical applications of boolean satisfiability},
	booktitle = {In {Workshop} on {Discrete} {Event} {Systems} ({WODES}},
	publisher = {IEEE Press},
	author = {Marques-silva, Joao},
	year = {2008},
}

@inproceedings{ding_-line_2019,
	address = {Naples, Italy},
	title = {On-{Line} {Error} {Detection} and {Mitigation} for {Time}-{Series} {Data} of {Cyber}-{Physical} {Systems} using {Deep} {Learning} {Based} {Methods}},
	isbn = {9781728139296},
	url = {https://ieeexplore.ieee.org/document/8893390/},
	doi = {10.1109/EDCC.2019.00015},
	urldate = {2022-08-02},
	booktitle = {2019 15th {European} {Dependable} {Computing} {Conference} ({EDCC})},
	publisher = {IEEE},
	author = {Ding, Kai and Ding, Sheng and Morozov, Andrey and Fabarisov, Tagir and Janschek, Klaus},
	month = sep,
	year = {2019},
	pages = {7--14},
}

@article{fabarisov_model-based_2021,
	title = {Model-based {Fault} {Injection} {Experiments} for the {Safety} {Analysis} of {Exoskeleton} {System}},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2101.01283},
	doi = {10.48550/ARXIV.2101.01283},
	abstract = {Model-based fault injection methods are widely used for the evaluation of fault tolerance in safety-critical control systems. In this paper, we introduce a new model-based fault injection method implemented as a highlycustomizable Simulink block called FIBlock. It supports the injection of typical faults of essential heterogeneous components of Cyber-Physical Systems, such as sensors, computing hardware, and network. The FIBlock GUI allows the user to select a fault type and configure multiple parameters to tune error magnitude, fault activation time, and fault exposure duration. Additional trigger inputs and outputs of the block enable the modeling of conditional faults. Furthermore, two or more FIBlocks connected with these trigger signals can model chained errors. The proposed fault injection method is demonstrated with a lower-limb EXO-LEGS exoskeleton, an assistive device for the elderly in everyday life. The EXO-LEGS model-based dynamic control is realized in the Simulink environment and allows easy integration of the aforementioned FIBlocks. Exoskeletons, in general, being a complex CPS with multiple sensors and actuators, are prone to hardware and software faults. In the case study, three types of faults were investigated: 1) sensor freeze, 2) stuck-at-0, 3) bit-flip. The fault injection experiments helped to determine faults that have the most significant effects on the overall system reliability and identify the fine line for the critical fault duration after that the controller could no longer mitigate faults.},
	urldate = {2022-08-02},
	author = {Fabarisov, Tagir and Mamaev, Ilshat and Morozov, Andrey and Janschek, Klaus},
	year = {2021},
	keywords = {FOS: Electrical engineering, electronic engineering, information engineering, Systems and Control (eess.SY)},
}

@article{vidineev_improved_2018,
	title = {Improved stochastic control flow model for {LLVM}-based software reliability analysis},
	volume = {3},
	url = {https://stumejournals.com/journals/i4/2018/4/172},
	abstract = {Recently we have proposed a new method for error propagation analysis of the safety-critical software using the transformation of the source code to the Dual-graph Error Propagation Model (DEPM) based on the Low-Level Virtual Machine (LLVM) compiler framework, that allows the automatic analysis of C-code or another LLVM supported front-end. The source code is compiled into the LLVM Intermediate Representation and instrumented in order to analyze control and data flow structures of the software and the control flow transition probabilities between the basic blocks. Based on this information a DEPM for further analysis is generated. The DEPM is a stochastic model that captures system properties relevant to error propagation processes such as control and data flow structures and reliability characteristics of single components, LLVM instructions in this particular case. The DEPM helps to estimate the impact of a fault in a particular instruction on the overall system reliability, e.g. to compute the mean number of erroneous values in a critical system output during given operation time. The feasibility of the method has been proven on several case studies and also reveals several limitations of the current control flow model. This paper address the improvement of the control flow model using a new customizable heuristic method for the analysis of control flow sequences and their mapping into discrete-time Markov chain models. The method is designed in a way to keep a required tradeoff between the model size and precision.},
	language = {en-US},
	number = {4},
	urldate = {2022-08-02},
	journal = {Industry 4.0},
	author = {Vidineev, V. and Yusupova, N. and Ding, K. and Morozov, A. and Janschek, K.},
	year = {2018},
	note = {Publisher: Scientific Technical Union of Mechanical Engineering "Industry 4.0"},
	pages = {172--174},
}

@inproceedings{osborn_risk-informed_nodate,
	title = {Risk-{Informed} {Approaches} for {Physical} {Security}},
	abstract = {This paper’s focus on risk-informed physical security is to incorporate dynamic risk processes, for use by the full range of light water reactor stakeholders including the regulator, into making physical security decisions that reduce uncertainties and optimize physical security postures. This paper reviews different risk-informed approaches for application to physical security such as System Theoretic Process Analysis (STPA), Risk Informed Management of Enterprise Security (RIMES), dynamic Probabilistic Risk Assessment (PRA), and Multi Objective Decision Analysis (MODA). Commonalities, advantages, and unique differences are evaluated to help establish a method for developing an integrated risk-informed solution for security. One goal of such an integrated riskinformed method is to develop a structured approach to that can simultaneously support consistency in security-related decision-making and address the unique security-related concerns for each nuclear power facility. Ultimately, insights from advances in risk assessment and complex systems analysis provide a framing to leverage the advantages of various cutting-edge risk-informed approaches to help improve physical security for modernizing and expanding nuclear facilities against a 21st century threat environment.},
	language = {en},
	author = {Osborn, Douglas M.},
	pages = {9},
}

@misc{arafat_technology_2021,
	title = {Technology {Innovation} for {Fission} {Batteries}: {Autonomous} {Controls} and {Operation}},
	url = {https://nuc1.inl.gov/SiteAssets/Fission%20Battery%20Initiative/Presentations/01-20-21%20Technology%20Innovation%20for%20Fission%20Batteries.pdf},
	urldate = {2022-08-02},
	author = {Arafat, Yasir},
	month = jan,
	year = {2021},
}

@techreport{noauthor_taxonomy_2021,
	title = {Taxonomy and {Definitions} for {Terms} {Related} to {Driving} {Automation} {Systems} for {On}-{Road} {Motor} {Vehicles}},
	shorttitle = {J3016\_202104},
	url = {https://www.sae.org/standards/content/j3016_202104/},
	abstract = {This document describes [motor] vehicle driving automation systems that perform part or all of the dynamic driving task (DDT) on a sustained basis. It provides a taxonomy with detailed definitions for six levels of driving automation, ranging from no driving automation (Level 0) to full driving auto},
	urldate = {2022-08-02},
	institution = {SAE International},
	year = {2021},
}

@inproceedings{hamza_methodology_2022,
	address = {Honolulu, O'ahu, Hawaii, USA},
	title = {Methodology and {Demonstration} of {Git}-{Based} {Configuration} {Control} in {Probabilistic} {Risk} {Assessment}},
	abstract = {Probabilistic Risk Assessment (PRA) has been an integral part of large-scale, high-risk industries, like the aerospace, chemical, and nuclear industries. Both fault tree (FT) and event tree (ET) modeling techniques are essential parts of any PRA model. FTs are used to model the possible causes of system failures, whereas ETs are developed to track the progression of postulated initiating events and their associated system responses. FTs and ETs can be built, modified, updated, and tracked for simple systems and associated event progressions with minimal effort. However, as the complexity of the system or event progression increases, their associated models become more complex. For models developed, modified, and updated by a single analyst, increasing complexity does not necessarily present a challenge for model development. However, if multiple analysts contribute to developing the same PRA model, keeping track of the changes becomes critical to avoid conflicting or replicating work. In addition, rigorous configuration control is imperative to keeping track of PRA model modifications during iterative design stages in which system configurations evolve dynamically. Under current configuration control requirements, PRA standards in the nuclear industry, including ASME/ANS Probabilistic Risk Assessment Standard for Advanced Non-Light Water Reactor Nuclear Power Plants, require an explicit process for monitoring design changes, tracking associated model modifications, and tracing model progression. Though some existing PRA tools, such as CAFTA, implement minimal version control, multi-user collaboration and model-tracking capabilities are limited. To address this unmet need, we present a methodology that utilizes Git to fulfill the configuration control requirements and enable preliminary multi-user collaboration. We then demonstrate the presented methodology on representative models using the MAR-D file format for SAPHIRE and CAFTA. Finally, we offer a brief discussion of the limitations within the proposed methodology and propose improvements for future work.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Hamza, Mostafa and Tezbasaran, Alp and Diaconeasa, Mihai A.},
	year = {2022},
	pages = {10},
}

@inproceedings{otani_probabilistic_2022,
	address = {Honolulu, O'ahu, Hawaii, USA},
	title = {Probabilistic {Methods} for {Cyclical} and {Coupled} {Systems} with {Changing} {Failure} {Rates}},
	abstract = {Advancements in nuclear system designs with automated control features provide many benefits, but can lead to complex coupled systems and dynamic failure scenarios. This is especially true for microreactor designs where components are not expected to be replaced during the reactor’s lifetime. Hence, the life of the system, in addition to the safety, needs to be evaluated. Modeling these sequences of time-dependent events requires addressing cyclical processes and changing failure rates in ways that represent the actual system dynamics in contrast to a single sampling for a component’s time to failure. This research presents two distinct analytical methods for several failure distributions that evaluate a final time to failure used for different scenarios where the time to failure must be sampled multiple times. The first method is used when evaluating a component whose failure rate increases due to an outside event after the initial sampling but before the initially sampled time to failure. The second method is used when evaluating multiple identical components or a component that has been replaced with a new identical version before the second sampling. The two methods were implemented in a few representative case studies developed in the dynamic probabilistic risk assessment tool Event Modeling Risk Assessment using Linked Diagrams. Overall, this paper provides guidelines on how these approaches give a more realistic and accurate dynamic probabilistic risk assessment of complex systems.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Otani, Courtney and Christian, Robby and Earthperson, Arjun and Prescott, Steven and Diaconeasa, Mihai A.},
	year = {2022},
	pages = {11},
}

@inproceedings{medina_skill_2022,
	title = {A skill fault model for autonomous systems},
	url = {https://hal.laas.fr/hal-03609377},
	doi = {10.1145/3526071.3527513},
	abstract = {Autonomous systems are now deployed for many applications to perform more and more complex tasks in open environments. To manage complexity of their control software architecture, a current trend is to use a 3-layers approach, with a decisional layer (able to formulate decisions), a functional layer (low level control actions), and between them a skill layer. This layer is dedicated to convert high level plan objectives into low level atomic actions, sent to the functional layer. In order to deal with failures that may happen at runtime, detection mechanisms and reaction strategies may be implemented in these layers, or even in external devices. However, no generic technique is available to guarantee that all these mechanisms will be consistent. We present in this paper an approach that focus on the skill layer, with a proposal of a generic skill fault model used to design and analyze failure detection and reactions mechanisms. This approach has been successfully applied to a real drone application, and we present an extract of the resulting fault analysis models. CCS CONCEPTS • Computer systems organization → Embedded systems; Redundancy; Robotics; • Software and its engineering → Fault tree analysis; Software fault tolerance.},
	language = {en},
	urldate = {2022-08-02},
	author = {Medina, Gabriela and Guiochet, Jérémie and Lesire, Charles and Manecy, Augustin},
	month = may,
	year = {2022},
}

@techreport{christian_methodology_2020,
	title = {Methodology and {Application} of {Physical} {Security} {Effectiveness} {Based} on {Dynamic} {Force}-on-{Force} {Modeling}},
	url = {https://www.osti.gov/biblio/1670433-methodology-application-physical-security-effectiveness-based-dynamic-force-force-modeling},
	abstract = {This report describes the research and development being performed at INL towards a dynamic modeling and simulation framework to enable physical security optimization at commercial nuclear power plants. The framework is based on the dynamic modeling tool EMRALD and is demonstrated for applications that can result in physical security optimization. Two main applications are presented: 1. Integrating FLEX portable equipment performance with FOF models of a plant’s physical security posture, and 2. Location optimization of bullet resistant enclosure. The generic framework for modeling FLEX portable equipment is described in detail, followed by a case study modeling an adversarial attack aimed at causing a radiological release by sabotaging the plant’s power supply and its ultimate heat sink capabilities at a hypothetical PWR. Two distinct FLEX deployment strategies, series and parallel, are modeled with distinct timelines. The results of the adversarial attack modeled in a commercial FOF tool, AVERT, are integrated with the FLEX deployment model in EMRALD. Monte Carlo simulation is used to model the distribution of the timeline in FLEX deployment strategies. Thermal-hydraulic analysis of FLEX performance is performed in RELAP5 and integrated with the EMRALD simulations to provide more realistic timelines in the models. The results demonstrate that, even in the extreme case of a successful adversarial attack, deployment of FLEX equipment can result in a significantly high likelihood of preventing radiological release. The modeling and simulation framework of integrating FLEX equipment with FOF models enables the NPPs to credit FLEX portable equipment in the plant security posture, resulting in an efficient and optimized physical security. The objective of location optimization of BRE is to determine the best location in the plant for a new BRE being planned by the plant to enhance their physical security effectiveness. The plant physical security FOF model is integrated with EMRALD that performs Monte Carlo simulation to run different attack scenarios and a discrete set of potential BRE locations. Sensitivity analysis is used to determine the most effective location for the BRE. The optimization approach can be extended to wide applications such as location optimization of remotely operated weapons and other strategic fixed assets.},
	language = {English},
	number = {INL/EXT-20-59891-Rev000},
	urldate = {2022-08-02},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Christian, Robby and Yadav, Vaibhav and St Germain, Shawn W. and Weathersby, John H. and Prescott, Steven R.},
	month = sep,
	year = {2020},
}

@misc{parker_prism_2001,
	title = {{PRISM} - {Probabilistic} {Symbolic} {Model} {Checker}},
	url = {https://www.prismmodelchecker.org/},
	author = {Parker, D.},
	year = {2001},
}

@misc{bernauer_radiant_2021,
	title = {Radiant introduction},
	author = {Bernauer, Doug},
	year = {2021},
}

@inproceedings{kwiatkowska_advances_2010,
	title = {Advances and challenges of probabilistic model checking},
	doi = {10.1109/ALLERTON.2010.5707120},
	abstract = {Probabilistic model checking is a powerful technique for formally verifying quantitative properties of systems that exhibit stochastic behaviour. Such systems are found in many domains: probabilistic behaviour may arise, for example, due to failures of unreliable components, communication across lossy media, or through the use of randomisation in distributed protocols. In this paper, we give a short overview of probabilistic model checking and of PRISM (www.prismmodelchecker.org), currently the leading software tool in this area. We then mention some of the limitations of these techniques, describe some of the advances that are being made to overcome them, and outline key challenges that remain in this research area.},
	booktitle = {2010 48th {Annual} {Allerton} {Conference} on {Communication}, {Control}, and {Computing} ({Allerton})},
	author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David},
	month = sep,
	year = {2010},
	keywords = {Biological system modeling, Computational modeling, IP networks, Markov processes, Mathematical model, Probabilistic logic, Protocols},
	pages = {1691--1698},
}

@article{lin_dynamic_2021,
	title = {Dynamic analysis of dry storage canister and the spent fuels inside under vertical drop in {HTR}-{PM}},
	volume = {154},
	doi = {10.1016/j.anucene.2020.108030},
	abstract = {High-temperature gas cooled reactor pebble-bed modular (HTR-PM) uses a dry storage system based on steel storage canisters to store and transport spent fuels on-site. For the canister, one of the key equipment, it is necessary to verify the reliability of the structural design in extreme events, especially under the accidental drop. Since there are 40,000 fuel elements in a canister, interfacial coupling effect between thin-walled storage canister and pebble bed cannot be ignored under the impact. Here, pebble bed and storage canister are modelled by discrete element model and finite element model, respectively. Using this interfacial coupling model, dynamic interactions between the inner surface of canister and spent fuel elements and inside the pebble bed self were analysed numerically. Interactive forces calculated during impact is well applied to diagnose the failure behaviour of fuel elements. The computation results are validated by the full-scale drop test of HTR-PM spent fuel canister.},
	journal = {Annals of Nuclear Energy},
	author = {Lin, Musen and Wang, Jinhua and Wu, Bin and Li, Yue},
	month = may,
	year = {2021},
	pages = {108030},
}

@article{brace_efficient_nodate,
	title = {Efficient {Implementation} of a {BDD} {Package}},
	abstract = {Efficient manipulation of Boolean functions is an important component of many computer-aided design tasks. This paper describes a package for manipulating Boolean functions based on the reduced, ordered, binary decision diagram (ROBDD) representation. The package is based on an efficient implementation of the if-then-else (ITE) operator. A hash table is used to maintain a strong carwnical form in the ROBDD, and memory use is improved by merging the hash table and the ROBDD into a hybrid data structure. A memory funcfion for the recursive ITE algorithm is implemented using a hash-based cache to decrease memory use. Memory function efficiency is improved by using rules that detect. when equivalent functions are computed. The usefulness of the package is enhanced by an automatic and low-cost scheme for rec:ycling memory. Experimental results are given to demonstrate why various implementation trade-offs were made. These results indicate that the package described here is significantly faster and more memory-efficient than other ROBDD implementations described in the literature.},
	language = {en},
	author = {Brace, Karl S and Rudell, Richard L and Bryant, Randal E},
	pages = {6},
}

@inproceedings{tran_phu_graph_2021,
	address = {Online},
	title = {Graph {Convolutional} {Networks} for {Event} {Causality} {Identification} with {Rich} {Document}-level {Structures}},
	url = {https://aclanthology.org/2021.naacl-main.273},
	doi = {10.18653/v1/2021.naacl-main.273},
	language = {en},
	urldate = {2022-07-27},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Tran Phu, Minh and Nguyen, Thien Huu},
	year = {2021},
	pages = {3480--3490},
}

@article{noauthor_nureg-1338_nodate,
	title = {{NUREG}-1338, "{Draft} {Preapplication} {Safety} {Evaluation} {Report} for the {Modular} {High}-{Temperature} {Gas}-{Cooled} {Reactor}."},
	language = {en},
	pages = {315},
}

@article{cai_framework_2021,
	title = {A framework analyzing system status and human activities: {Illustrated} using 2011 {Fukushima} nuclear power plant accident scenarios},
	volume = {373},
	issn = {0029-5493},
	shorttitle = {A framework analyzing system status and human activities},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549320305197},
	doi = {10.1016/j.nucengdes.2020.111025},
	abstract = {Systematically modeling human activities and their interactions with complex systems is important in decision making processes. In order to determine appropriate human activities bringing systems to some desired status, integrated analyses combining both components are necessary. However, this can be difficult due to the complexity of the problems and the lack of adequate data. In this work, a framework capable of analyzing system status and human activities as an integrated set is proposed based upon use of a time-dependent Bayesian Network. The 2011 Fukushima Daiichi nuclear power plant accident scenarios are utilized in this work in order to illustrate the framework. Scenarios presented in this work are developed based upon the authors’ interviews with Tokyo Electric Power Company (TEPCO) staff who were directly engaged in Fukushima accident mitigation. In this work, we focus upon problems that TEPCO staff found challenging during the Fukushima accident. Two types of tasks, mitigation activities during ongoing accidents and preparation tasks before potential accidents, are considered. The capability of the framework for providing system status, based upon rapidly changing human activities, can enable decision-makers to select appropriate mitigation strategies for use during emergencies. The capability of the framework in comparing multiple preparation efforts can enable decision-makers to identify appropriate strategies in order to prepare for similar future situations. Beyond the examples illustrated here, the proposed framework can be applied to broader fields and support corresponding decisions as long as corresponding human activity and system models are available.},
	language = {en},
	urldate = {2022-07-25},
	journal = {Nuclear Engineering and Design},
	author = {Cai, Yinan and Golay, Michael W.},
	month = mar,
	year = {2021},
	pages = {111025},
}

@article{cai_formulation_2020,
	title = {Formulation of {A} {Risk} {Assessment} {Framework} {Capable} of {Analyzing} {Nuclear} {Power} {Multiunit} {Accident} {Scenarios}},
	volume = {202},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183202030541X},
	doi = {10.1016/j.ress.2020.107040},
	abstract = {During the 2011 Fukushima Daiichi and Daini accidents, the interactions of multiple units at the same nuclear power plant site made accident mitigation more difficult compared to single unit sites. The accidents revealed important multiunit risk factors that typically are not identified by risk assessments for single-unit sites. Therefore, in order to obtain an integrated risk evaluation for multiunit sites, it is important to analyze accident scenarios involving interactions of multiple reactor units. However, such analyses are difficult due to the complexity of potential multiunit interactions. In the work reported here, a framework for analyzing multiunit accident scenarios involving inter-unit interactions is presented. The major steps of the framework are illustrated using a simplified two-unit site. The framework is capable of providing accident mitigation suggestions based upon analysis results. In this work, accident scenarios inspired by the Fukushima Daiichi and Daini experiences are selected as analysis subjects. By analyzing these scenarios and providing corresponding accident mitigation suggestions, the capabilities of the framework are illustrated.},
	language = {en},
	urldate = {2022-07-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Cai, Yinan and Golay, Michael W.},
	month = oct,
	year = {2020},
	pages = {107040},
}

@article{cai_multiunit_2020,
	title = {Multiunit nuclear power plant accident scenarios and improvements including those based upon interviews with {TEPCO} engineers concerning the 2011 {Fukushima} accidents},
	volume = {365},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549320302016},
	doi = {10.1016/j.nucengdes.2020.110707},
	abstract = {In this work, we identify important multiunit risk factors based upon interviews with Tokyo Electric Power Company (TEPCO) engineers. These results provide first-hand information on multiunit risk factors that were important during the 2011 Fukushima accidents. Majority of the interviewees were involved in Fukushima Daiichi and Daini accident mitigation during March 2011. Interviewees worked at Daiichi and Daini sites and headquarters provided views of the accidents from different perspectives. They explained difficulties during the accident mitigation response phase due to lack of multiunit accident experience, and lack of necessary resources. In addition to the risk factors, corresponding site improvement suggestions are discussed based upon our reviews of the interview results. The identified risk factors and site improvement suggestions can be utilized as analysis subjects in future multiunit risk studies as well as references for nuclear sites to identify important multiunit risk vulnerabilities.},
	language = {en},
	urldate = {2022-07-25},
	journal = {Nuclear Engineering and Design},
	author = {Cai, Yinan and Golay, Michael W.},
	month = aug,
	year = {2020},
	keywords = {Fukushima accident scenarios, Multiunit nuclear power plant risk, Multiunit resource competition, Severe accident improvisation, Situational uncertainty, TEPCO engineer interviews},
	pages = {110707},
}

@misc{noauthor_infographic_nodate,
	title = {{INFOGRAPHIC}: {Advanced} {Reactor} {Development} {\textbar} {Department} of {Energy}},
	url = {https://www.energy.gov/ne/articles/infographic-advanced-reactor-development},
	urldate = {2022-07-25},
}

@misc{noauthor_pris_nodate,
	title = {{PRIS} - {Home}},
	url = {https://pris.iaea.org/PRIS/home.aspx},
	urldate = {2022-07-25},
}

@article{fang_shielding_2021,
	title = {Shielding {Design} and {Dose} {Evaluation} for {HTR}-{PM} {Fuel} {Transport} {Pipelines} by {QAD}-{CGA} {Program}},
	volume = {2021},
	issn = {1687-6075},
	url = {https://www.hindawi.com/journals/stni/2021/6686919/},
	doi = {10.1155/2021/6686919},
	abstract = {The spherical fuel elements are adopted in the high-temperature gas-cooled reactor pebble-module (HTR-PM). The fuel elements will be discharged continuously from the reactor core and transported into the fuel transport pipelines during the reactor operation, leading to spatially varying dose outside the pipeline. In this case, the dose evaluation faces two major challenges, including dynamic source terms and pipelines with varying lengths and shapes. This study tries to handle these challenges for HTR-PM through comprehensive calculations using the QAD-CGA program and to design the corresponding shielding of the pipeline. During the calculation, it is assumed that a spherical fuel element stays in different positions of the pipelines in turn, and the corresponding dose contributions were calculated. By integrating the dose contributions at different positions, the dose at the points of interest can be obtained. The total dose is further determined according to the assumed fuel elements transport speed of 5 m/s and total 6000 fuel elements transportation per day. Two types of fuel transport pipelines and two source terms were considered, i.e., the spent fuel element transport pipelines with corresponding spent fuel source term and the different burn-up fuel element transport pipelines with the average burn-up fuel source term. Doses at different points of interest were calculated with no shielding scenario and with lead shielding of different thicknesses scenario. To evaluate the shielding effect, the dose limit of the orange radiation zone of HTR-PM and the radiation damage thresholds from NCRP report No.51 were both adopted. The calculated results show that, for pipelines that transport the spent fuel, a 4 cm lead shielding will be enough. And for pipelines that transport fuel elements with different burn-up, a 5 cm lead shielding will be added. The method and results can provide valuable reference for other work of HTR-PM.},
	language = {en},
	urldate = {2022-07-24},
	journal = {Science and Technology of Nuclear Installations},
	author = {Fang, Sheng and Cao, Jianzhu and Li, Wenqian and Luo, Chen and Yao, Feng and Li, Xiaofan and Li, Kai},
	month = may,
	year = {2021},
	note = {Publisher: Hindawi},
	pages = {e6686919},
}

@article{du_simulation-aided_2019,
	title = {Simulation-aided design of the negative-pressure exhaust system in {HTGR} nuclear power plants},
	volume = {343},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318306265},
	doi = {10.1016/j.nucengdes.2018.12.023},
	abstract = {High-temperature gas-cooled reactor (HTGR) nuclear power plants adopt an unpressurized vented confinement due to their inherent security. Negative-pressure exhaust systems (NPES) are therefore designed to maintain vacuum in the confinement so that radioactive gas and aerosol cannot pollute the atmosphere through exfiltration. For engineering applications, NPES should be shared by more than one cabin. The control strategy of NPES in the hightemperature reactor pebble bed module (HTR-PM), an HTGR demonstration project, is considered in this work. After describing the exhaust system with a mathematical model, a modular Simulink® simulation model is developed to aid in the design of the exhaust systems of HTGR nuclear power plants. Analysis of simulation results shows that (1) the volumes and airtightness of the cabins play dominant roles in the effectiveness of the control strategy. The time required to cut over between cases (time constant) can also affect effectiveness. (2) The control strategy of HTR-PM is effective, but when power plants increase in size, the control strategy becomes difficult to copy directly. (3) When an exhaust system with HTR-PM’s control strategy is applied to serve only one cabin with standard airtightness, its volume should be between 1300 and 46,000 m3 to avoid misjudging accidents. (4) When an exhaust system with HTR-PM’s control strategy is applied to serve two cabins with standard airtightness simultaneously, the cabins’ volumes should be within the aforementioned range. (5) When three or more cabins with standard airtightness are served by one exhaust system simultaneously, the case can be simplified into the case with two cabins, and preliminary judgment of the effectiveness of HTR-PM’s control strategy can be obtained. (6) Our Simulink® model can be applied to study cases in which airtightness and the control strategy vary. Therefore, this model can be applied in the design of NPES of HTGR nuclear power plants.},
	language = {en},
	urldate = {2022-07-24},
	journal = {Nuclear Engineering and Design},
	author = {Du, Ruiming and Zhang, Zhenzhong and Jiang, Feng},
	month = mar,
	year = {2019},
	pages = {43--56},
}

@article{noauthor_simulation-aided_2019,
	title = {Simulation-aided design of the negative-pressure exhaust system in {HTGR} nuclear power plants},
	volume = {343},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/S0029549318306265},
	doi = {10.1016/j.nucengdes.2018.12.023},
	abstract = {High-temperature gas-cooled reactor (HTGR) nuclear power plants adopt an unpressurized vented confinement due to their inherent security. Negative-pre…},
	language = {en},
	urldate = {2022-07-24},
	journal = {Nuclear Engineering and Design},
	month = mar,
	year = {2019},
	note = {Publisher: North-Holland},
	pages = {43--56},
}

@article{sun_optimization_2017,
	title = {The {Optimization} of {Radiation} {Protection} in the {Design} of the {High} {Temperature} {Reactor}-{Pebble}-{Bed} {Module}},
	volume = {2017},
	issn = {1687-6075},
	url = {https://www.hindawi.com/journals/stni/2017/3984603/},
	doi = {10.1155/2017/3984603},
	abstract = {The optimization of radiation protection is an important task in both the design and operation of a nuclear power plant. Although this topic has been considerably investigated for pressurized water reactors, there are very few public reports on it for pebble-bed reactors. This paper proposes a routine that jointly optimizes the system design and radiation protection of High Temperature Reactor-Pebble-Bed Module (HTR-PM) towards the As Low As Reasonably Achievable (ALARA) principle. A systematic framework is also established for the optimization of radiation protection for pebble-bed reactors. Typical calculations for the radiation protection of radioactivity-related systems are presented to quantitatively evaluate the efficiency of the optimization routine, which achieve 23.3\%{\textasciitilde}90.6\% reduction of either dose rate or shielding or both of them. The annual collective doses of different systems are reduced through iterative optimization of the dose rates, designs, maintenance procedures, and work durations and compared against the previous estimates. The comparison demonstrates that the annual collective dose of HTR-PM is reduced from 0.490 man-Sv/a before optimization to 0.445 man-Sv/a after optimization, which complies with the requirements of the Chinese regulatory guide and proves the effectiveness of the proposed routine and framework.},
	language = {en},
	urldate = {2022-07-24},
	journal = {Science and Technology of Nuclear Installations},
	author = {Sun, Sida and Li, Hong and Fang, Sheng},
	month = jul,
	year = {2017},
	note = {Publisher: Hindawi},
	pages = {e3984603},
}

@inproceedings{wang_jinhua_design_2015,
	address = {Japan},
	title = {Design of the ground crane and shielding cask for the spent fuel canister of {HTR}-{PM}},
	abstract = {The High Temperature gas cooled Reactor Pebble bed Module (HTR-PM) is in design and
construction process in China, which is considered as one of the candidates for the
Gen-IV nuclear power plant, and has advantage of inherent safety, avoiding nuclear
proliferation, high temperature industry heat production and so on The sphere fuel
element is used in HTR-PM The fuel particles are spread in the fuel element, and the
sphere element's diameter is 60 mm after oppression After discharged from the HTR
reactor core, the spent fuel element would be transferred into the spent fuel canister
The spent fuel canister would be stored in the spent fuel storage well after fully
loaded In the process of the spent fuel storage and operation, it is required to ensure
the operation safety, subcritical, radiation shielding safety and residual heat removal
safety In order to decrease the price of the spent fuel canister, the canister was
designed as a thin shell vessel, which has weak radiation shielding function, and
cannot fulfill safety requirement of radiation shielding, so it is required to research
and design a set of devices, which could provide enough radiation shielding for the
spent fuel canister, and the device could also transfer the spent fuel canister safely
and reliably, and then the safety of the operation staff and the facility could be
ensured The concrete shielding well lid is set on top of the storage well, when the
spent fuel canister is needed to put into the storage well, the well lid would be
taken out from its mounting position In the operation process of the spent fuel canister
and the concrete shielding well lid, the ground crane with accurate positioning function
is required to position the spent fuel canister and the concrete shielding well lid
to the operating position The main components of the ground crane system includes:
Crane bridge, shielding cask, neutron shielding boron barrel, canister hoisting mechanism,
well lid hoisting mechanism, bottom plate opening mechanism, shielding strip mechanism,
residual removal blowers, butterfly valves, ground rails, cable sliding bridge, encoder
positioning scale and so on The ground crane could satisfy the accurate positioning
and safe operation of the spent fuel canister, and could ensure the operating reliability
of the spent fuel canister and the concrete shielding well lid in HTR-PM operational
period (author)},
	author = {{Wang Jinhua} and {Liu Xiang} and {Wang Bing} and {Li Yue} and {Wu Bin}},
	year = {2015},
	note = {INIS Reference Number: 48051332},
	pages = {3737},
}

@article{wu_comprehensive_2021,
	title = {A {Comprehensive} {Survey} of {Inverse} {Uncertainty} {Quantification} of {Physical} {Model} {Parameters} in {Nuclear} {System} {Thermal}-{Hydraulics} {Codes}},
	volume = {384},
	issn = {00295493},
	url = {http://arxiv.org/abs/2104.12919},
	doi = {10.1016/j.nucengdes.2021.111460},
	abstract = {Uncertainty Quantification (UQ) is an essential step in computational model validation because assessment of the model accuracy requires a concrete, quantifiable measure of uncertainty in the model predictions. The concept of UQ in the nuclear community generally means forward UQ (FUQ), in which the information flow is from the inputs to the outputs. Inverse UQ (IUQ), in which the information flow is from the model outputs and experimental data to the inputs, is an equally important component of UQ but has been significantly underrated until recently. FUQ requires knowledge in the input uncertainties which has been specified by expert opinion or user self-evaluation. IUQ is defined as the process to inversely quantify the input uncertainties based on experimental data. This review paper aims to provide a comprehensive and comparative discussion of the major aspects of the IUQ methodologies that have been used on the physical models in system thermal-hydraulics codes. IUQ methods can be categorized by three main groups: frequentist (deterministic), Bayesian (probabilistic), and empirical (design-of-experiments). We used eight metrics to evaluate an IUQ method, including solidity, complexity, accessibility, independence, flexibility, comprehensiveness, transparency, and tractability. Twelve IUQ methods are reviewed, compared, and evaluated based on these eight metrics. Such comparative evaluation will provide a good guidance for users to select a proper IUQ method based on the IUQ problem under investigation.},
	urldate = {2022-07-22},
	journal = {Nuclear Engineering and Design},
	author = {Wu, Xu and Xie, Ziyu and Alsafadi, Farah and Kozlowski, Tomasz},
	month = dec,
	year = {2021},
	note = {arXiv:2104.12919 [stat]},
	keywords = {Statistics - Applications, Statistics - Other Statistics},
	pages = {111460},
}

@misc{noauthor_benchmarking_nodate,
	title = {benchmarking / {Fault} {Tree} {Generator} · {GitLab}},
	url = {https://gitlab.openpra.org/benchmarking/fault-tree-generator},
	urldate = {2022-07-21},
}

@article{wu_design_2022,
	title = {Design, {Experiment}, and {Commissioning} of the {Spent} {Fuel} {Conveying} and {Loading} {System} of {HTR}-{PM}},
	volume = {2022},
	issn = {1687-6075},
	url = {https://www.hindawi.com/journals/stni/2022/1817191/},
	doi = {10.1155/2022/1817191},
	abstract = {The Chinese high-temperature gas-cooled reactor pebble-bed module, HTR-PM, began fuel loading in August 2021. The reactor refuels continuously, while the spent fuel is discharged from the core. The spent fuel conveying and loading system was designed to convey the spent fuel pebbles to the spent fuel building and load them into dry canisters for on-site interim storage. This study describes the operating principles of the main functions and introduces the experiments and commissioning tests of the system. Functional tests were carried out to indicate the items of mechanical and electrical equipment are functioning in accordance with the designed requirements. Experience learned from commissioning activities was also presented as feedback for future operation and design improvement.},
	language = {en},
	urldate = {2022-07-21},
	journal = {Science and Technology of Nuclear Installations},
	author = {Wu, Bin and Wang, Jinhua and Li, Yue and Wang, Haitao and Ma, Tao},
	month = apr,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e1817191},
}

@article{han_appearance-based_2015,
	title = {Appearance-based material classification for monitoring of operation-level construction progress using {4D} {BIM} and site photologs},
	volume = {53},
	issn = {0926-5805},
	url = {https://www.sciencedirect.com/science/article/pii/S0926580515000266},
	doi = {10.1016/j.autcon.2015.02.007},
	abstract = {This paper presents a new appearance-based material classification method for monitoring construction progress deviations at the operational-level. The method leverages 4D Building Information Models (BIM) and 3D point cloud models generated from site photologs using Structure-from-Motion techniques. To initialize, a user manually assigns correspondences between the point cloud model and BIM, which automatically brings in the photos and the 4D BIM into alignment from all camera viewpoints. Through reasoning about occlusion, each BIM element is back-projected on all images that see that element. From these back-projections, several 2D patches are sampled per element and are classified into different material types. To perform material classification, the expected material type information is derived from BIM. Then the image patches are convolved with texture and color filters and their concatenated vector-quantized responses are compared with multiple discriminative material classification models that are relevant to the expected progress of that element. For each element, a quantized histogram of the observed material types is formed and the material type with the highest appearance frequency infers the appearance and thus the state of progress. To validate, four new datasets of incomplete and noisy point cloud models are introduced which are assembled from real-world construction site images and BIMs. An extended version of the Construction Material Library (CML) is also introduced for training/testing the material classifiers. The material classification shows an average accuracy of 92.4\% for CML image patches of 100×100pixels. The experiments on those four datasets show an accuracy of 95.9\%, demonstrating the potential of appearance-based recognition method for inferring the actual state of construction progress for BIM elements.},
	language = {en},
	urldate = {2022-07-15},
	journal = {Automation in Construction},
	author = {Han, Kevin K. and Golparvar-Fard, Mani},
	month = may,
	year = {2015},
	keywords = {3D point cloud models, Building Information Models, Construction progress monitoring, Material classification, Structure from Motion},
	pages = {44--57},
}

@phdthesis{polat_probabilistic_2022,
	title = {A {Probabilistic} {Risk} {Assessment} {Framework} for {Wildfire}-{Induced} {Releases} from {Radiologically} {Contaminated} {Forests} for {Risk}-{Informed} {Emergency} {Planning} {Purposes}},
	school = {North Carolina State University},
	author = {Polat, Damla},
	year = {2022},
}

@phdthesis{polat_model-based_2022,
	title = {A {Model}-{Based} {Human} {Reliability} {Analysis} {Methodology} for the {Physical} {Protection} of {Nuclear} {Facilities}},
	school = {North Carolina State University},
	author = {Polat, Burak},
	year = {2022},
}

@article{rasmuson_common-cause_2008,
	title = {Common-cause failure analysis in event assessment},
	volume = {222},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR121},
	doi = {10.1243/1748006XJRR121},
	abstract = {This paper describes the approach taken by the U. S. Nuclear Regulatory Commission to the treatment of common-cause failure in probabilistic risk assessment of operational events. The approach is based upon the Basic Parameter Model for common-cause failure, and examples are illustrated using the alpha-factor parameterization, the approach adopted by the NRC in their Standardized Plant Analysis Risk (SPAR) models. The cases of a failed component (with and without shared common-cause failure potential) and a component being unavailable due to preventive maintenance or testing are addressed. The treatment of two related failure modes (e.g., failure to start and failure to run) is a new feature of this paper. These methods are being applied by the NRC in assessing the risk significance of operational events for the Significance Determination Process (SDP) and the Accident Sequence Precursor (ASP) program.},
	language = {en},
	number = {4},
	urldate = {2022-07-12},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Rasmuson, D M and Kelly, D L},
	month = dec,
	year = {2008},
	pages = {521--532},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {LMP} {Lessons} {Learned}, {Best} {Practices}, and {Frequently} {Asked} {Questions}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1700534-modernization-technical-requirements-licensing-advanced-non-light-water-reactors-lmp-lessons-learned-best-practices-frequently-asked-questions},
	abstract = {This report captures lessons learned, best practices, and frequently asked questions with responses gleaned from the experiences of early adopters of the LMP RIPB process. Interviews were conducted in late 2019 with five non-LWR design organizations to gather their feedback on the application of the LMP RIPB process under real production conditions. The overall feedback from the reactor developers is that the LMP RIPB process can be successfully implemented with material benefits to the designer. As with any new processes, numerous challenges and questions were relayed by the designers. These challenges have been translated into lessons learned and best practices. Those two sections address both technical and organizational aspects of implementing the LMP RIPB process. Questions that were asked by multiple designers were turned into “frequently asked questions” and responses were provided by the LMP team.},
	language = {English},
	number = {INL/EXT-20-60392-Rev000},
	urldate = {2022-07-06},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1700534},
}

@article{hamza_framework_2022,
	title = {A framework to implement human reliability analysis during early design stages of advanced reactors},
	volume = {146},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197022000518},
	doi = {10.1016/j.pnucene.2022.104171},
	abstract = {Nuclear power plants require human actions throughout their lifecycle from design, construction, operation, and decommissioning. However, for advanced reactors (e.g., Generation IV), the reliance on human intervention in safety-related actions is expected to be reduced or completely replaced by automated actions. The Probabilistic Risk Assessment (PRA) Standard for Advanced Non-LWR Nuclear Power Plants requires that the impacts of all operator actions are captured and incorporated in the risk of the modeled plant. Moreover, the Modernization of Technical Requirements for Licensing Advanced Reactors requires human reliability analysis (HRA) to be included throughout all design and PRA development stages. However, due to the lack of details during the early design stages, HRA is often postponed until the design is mature enough. Conducting HRA in later design stages, though it may be adequate in capturing pre-, at-, and post-initiators comes short of informing the design itself in the iterative design lifecycle. Hence, this paper presents a framework to include HRA during the design's early stages, pre-conceptual or conceptual. The proposed framework provides a process for the removal of operator actions that do not contribute to the risk and the identification of all key operator actions that are critical to the safety of the design. The results of this framework are then used to inform the design of those safety-related operator actions to update the design further. Then, using information from the updated design, this framework can be reapplied to investigate the impact of the design update on human reliability. The PRA model of the X-energy's pre-conceptual Xe-100 high-temperature gas-cooled pebble-bed reactor (HTGR-PB) design is used to demonstrate the approach. In the pre-conceptual Xe-100 PRA model, also called Phase 0 PRA model, human actions were considered an integral part of analyzing the plant response to different initiating events. Hence, in this paper, all possible human actions in the Xe-100 PRA model are identified, analyzed, and removed to emulate a design relying only on the available automated control systems. The preliminary results of this assessment show how safe the Xe-100 design is even without crediting any human actions. The results also list necessary sequences in which operator actions are critical to the risk profile of the design.},
	language = {en},
	urldate = {2022-07-11},
	journal = {Progress in Nuclear Energy},
	author = {Hamza, Mostafa and Diaconeasa, Mihai A.},
	month = apr,
	year = {2022},
	keywords = {Advanced reactors, HRA, HTGR-PB, PRA},
	pages = {104171},
}

@misc{noauthor_wildfires_nodate,
	title = {Wildfires and {Acres} {\textbar} {National} {Interagency} {Fire} {Center}},
	url = {https://www.nifc.gov/fire-information/statistics/wildfires},
	urldate = {2022-07-08},
}

@article{russell_fault_1993,
	title = {Fault tree reduction and quantification—an overview of {IRRAS} algorithms},
	volume = {40},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832093901058},
	doi = {10.1016/0951-8320(93)90105-8},
	language = {en},
	number = {2},
	urldate = {2022-06-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Russell, Kenneth D. and Rasmuson, Dale M.},
	month = jan,
	year = {1993},
	pages = {149--164},
}

@article{noauthor_scalable_nodate,
	title = {Scalable {Multi}-core {Model} {Checking}:  {Technology} \& {Applications} of {Brute} {Force}  {Part} {III}: {Symbolic}},
	language = {en},
	pages = {61},
}

@misc{noauthor_risk_2019,
	title = {Risk {Management}: {A} {Tool} for {Improving} {Nuclear} {Power} {Plant} {Performance}},
	shorttitle = {Risk {Management}},
	url = {https://www.iaea.org/publications/6201/risk-management-a-tool-for-improving-nuclear-power-plant-performance},
	language = {en},
	urldate = {2022-06-29},
	publisher = {IAEA},
	month = feb,
	year = {2019},
	note = {Publisher: IAEA},
}

@book{bloem_handbook_2018,
	address = {Cham},
	edition = {1st ed. 2018},
	title = {Handbook of {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	abstract = {Model checking is a computer-assisted method for the analysis of dynamical systems that can be modeled by state-transition systems. Drawing from research traditions in mathematical logic, programming languages, hardware design, and theoretical computer science, model checking is now widely used for the verification of hardware and software in industry. The editors and authors of this handbook are among the world's leading researchers in this domain, and the 32 contributed chapters present a thorough view of the origin, theory, and application of model checking. In particular, the editors classify the advances in this domain and the chapters of the handbook in terms of two recurrent themes that have driven much of the research agenda: the algorithmic challenge, that is, designing model-checking algorithms that scale to real-life problems; and the modeling challenge, that is, extending the formalism beyond Kripke structures and temporal logic. The book will be valuable for researchers and graduate students engaged with the development of formal methods and verification tools. "This handbook is an authoritative, comprehensive description of the state of the art in model checking. It belongs on the bookshelf of every researcher and practitioner in computer-aided verification." [Moshe Y. Vardi, George Distinguished Service Professor in Computational Engineering, Rice University] "With chapters written by the world's leading experts from academia and industry, this authoritative book on model checking should be on the shelf of every computer science graduate student and every hardware and software engineer. As the scale and complexity of digital systems grow, and they must work in the presence of uncertainty in the physical world, verification techniques such as model checking will become increasingly important to ensure system reliability, safety, and security." [Jeannette Wing, Corporate Vice President, Microsoft Research]},
	publisher = {Springer International Publishing : Imprint: Springer},
	editor = {Bloem, Roderick and Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8},
	keywords = {Computer science, Computer software, Computers, Industrial safety, Mathematical Logic and Foundations, Mathematical logic, Mathematics, Mathematics of Computing, Performance and Reliability, Quality Control, Reliability, Safety and Risk, Quality control, Reliability, Reusability, Software Engineering/Programming and Operating Systems, Software engineering, Theory of Computation},
}

@article{prestemon_wildfire_2013,
	title = {Wildfire {Ignitions}: {A} {Review} of the {Science} and {Recommendations} for {Empirical} {Modeling}},
	volume = {171},
	shorttitle = {Wildfire {Ignitions}},
	url = {https://www.srs.fs.usda.gov/pubs/42766},
	abstract = {Publication from the USDA Forest Service Southern Research Station},
	language = {en},
	urldate = {2022-06-28},
	journal = {Gen. Tech. Rep. SRS-GTR-171. Asheville, NC: USDA-Forest Service, Southern Research Station. 20 p.},
	author = {Prestemon, Jeffrey P. and Hawbaker, Todd J. and Bowden, Michael and Carpenter, John and Brooks, Maureen T. and Abt, Karen L. and Sutphen, Ronda and Scranton, Samuel},
	year = {2013},
	pages = {1--20},
}

@techreport{prestemon_wildfire_2013-1,
	address = {Asheville, NC},
	title = {Wildfire {Ignitions}: {A} {Review} of the {Science} and {Recommendations} for {Empirical} {Modeling}},
	shorttitle = {Wildfire {Ignitions}},
	url = {https://www.fs.usda.gov/treesearch/pubs/42766},
	abstract = {Deriving from original work under the National Cohesive Wildland Fire Management Strategy completed in 2011, this report summarizes the state of knowledge regarding the underlying causes and the role of wildfire prevention efforts on all major categories of wildfires, including findings from research that have sought to model wildfire occurrences over fine and broad spatial and temporal scales. The report also describes a conceptual model of wildfire ignitions, which is designed to provide a modeling framework for analysts who seek to better understand wildfire ignition processes or develop statistical models that can predict wildfire occurrences across any spatial or temporal scale.},
	language = {en},
	number = {SRS-GTR-171},
	urldate = {2022-06-28},
	institution = {U.S. Department of Agriculture, Forest Service, Southern Research Station},
	author = {Prestemon, Jeffrey P. and Hawbaker, Todd J. and Bowden, Michael and Carpenter, John and Brooks, Maureen T. and Abt, Karen L. and Sutphen, Ronda and Scranton, Samuel},
	year = {2013},
	doi = {10.2737/SRS-GTR-171},
	pages = {SRS--GTR--171},
}

@misc{noauthor_doses_nodate,
	title = {Doses in {Our} {Daily} {Lives}},
	url = {https://www.nrc.gov/about-nrc/radiation/around-us/doses-daily-lives.html},
	urldate = {2022-06-28},
	journal = {NRC Web},
}

@article{noauthor_international_nodate,
	title = {International {Nuclear} and {Radiological} {Event} {Scale}},
	language = {en},
	pages = {4},
}

@article{kato_determining_2018,
	title = {Determining the initial {Fukushima} reactor accident-derived cesium-137 fallout in forested areas of municipalities in {Fukushima} {Prefecture}},
	volume = {23},
	issn = {1341-6979, 1610-7403},
	url = {https://www.tandfonline.com/doi/full/10.1080/13416979.2018.1448566},
	doi = {10.1080/13416979.2018.1448566},
	abstract = {This study determined the initial distribution of Fukushima reactor-derived radiocesium fallout in forest areas of Fukushima Prefecture based on analysis of airborne monitoring surveys by the Japanese Ministry of Education, Culture, Sports, Science and Technology (MEXT). The results of the fifth airborne monitoring surveys were compared with the third airborne survey data in order to correct for variation of deposition density due to multiple factors such as weathering processes and measurement uncertainties between two surveys. Finally, the results of the third and the corrected fifth airborne surveys were combined to reconstruct the initial radiocesium fallout map over the whole Fukushima Prefecture area following the Fukushima reactor accident. Our calculation results showed that forest areas accumulated 72\% of the total atmospheric input of 137Cs to the land of Fukushima Prefecture. The deposition density in forest areas showed significant variability among municipalities. Nevertheless, forest areas accumulated a large percentage of atmospherically deposited radiocesium in many municipalities. Statistical analysis of the variability in 137Cs deposition density indicated that deposition density varied significantly, even within a municipality. Furthermore, the inconsistency in the probability distributions of measured deposition density among municipalities makes it difficult to obtain a representative initial radiocesium fallout input following the accident. To reduce uncertainty in environmental parameters related to radiocesium transfer in forest environments, we strongly recommend that the deposition density of initial 137Cs fallout at each location is determined by in-situ sampling survey and using the reconstructed 137Cs fallout map presented in this study.},
	language = {en},
	number = {2},
	urldate = {2022-06-26},
	journal = {Journal of Forest Research},
	author = {Kato, Hiroaki and Onda, Yuichi},
	month = mar,
	year = {2018},
	pages = {73--84},
}

@book{united_nations_sources_2011,
	title = {Sources and {Effects} of {Ionizing} {Radiation}, {UNSCEAR} 2008 {Report}.},
	url = {https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=434231},
	language = {en},
	urldate = {2022-06-26},
	author = {{United Nations} and {United Nations}},
	year = {2011},
	note = {OCLC: 1154572830},
}

@book{international_atomic_energy_agency_environmental_2020,
	title = {Environmental {Transfer} of {Radionuclides} in {Japan} following the {Accident} at the {Fukushima} {Daiichi} {Nuclear} {Power} {Plant}: {Report} of {Working} {Group} 4 : {Transfer} {Processes} and {Data} for {Radiological} {Impact} {Assessment} {Subgroup} 2 on {Fukushima} {Data} : {IAEA} {Programme} on {Modelling} and {Data} for {Radiological} {Impact} {Assessments} ({MODARIA} {II}).},
	isbn = {978-92-0-117920-3},
	shorttitle = {Environmental {Transfer} of {Radionuclides} in {Japan} following the {Accident} at the {Fukushima} {Daiichi} {Nuclear} {Power} {Plant}},
	abstract = {"The publication focuses on radioecologjcal experience and data acquired and lessons learned in Japan following the nuclear accident at the Fukushima Daiichi nuclear power plant in March 2011. The publication brings together outcomes of the extensive studies, done by Japanese scientists and their colleagues from other countries, on characterization of radioecological transfer parameters in the terrestrial and aquatic environments of Japan affected by radionuclides released in the accident. The Japan specific data are systematically presented and compared to the global experience gained from the earlier nuclear accidents, military or industrial activities. Climate, landscape, agriculture and food processing practices, lifestyle and national dietary customs are shown as factors influencing transfer of radionuclides through the environment and human food chains. The publication summarizes country specific experience and puts it into existing global radioecological contexts."--Publisher's description.},
	language = {en},
	author = {{International Atomic Energy Agency}},
	year = {2020},
	note = {OCLC: 1224513481},
}

@inproceedings{satoh_study_2004,
	address = {Zaragoza, Spain},
	title = {A study of forest fire danger prediction system in {Japan}},
	isbn = {978-0-7695-2195-4},
	url = {http://ieeexplore.ieee.org/document/1333540/},
	doi = {10.1109/DEXA.2004.1333540},
	language = {en},
	urldate = {2022-06-23},
	booktitle = {Proceedings. 15th {International} {Workshop} on {Database} and {Expert} {Systems} {Applications}, 2004.},
	publisher = {IEEE},
	author = {Satoh, K. and {Song Weiguo} and Yang, K.T.},
	year = {2004},
	pages = {598--602},
}

@misc{vizzuality_kiev_nodate,
	title = {Kiev, {Ukraine} {Deforestation} {Rates} \& {Statistics} {\textbar} {GFW}},
	url = {https://www.globalforestwatch.org/dashboards/country/UKR/12?category=fires},
	abstract = {In 2010, Kiev had 747kha of tree cover, extending over 27\% of its land area. In \{year\}, it lost 7.10kha of tree cover.},
	language = {en},
	urldate = {2022-06-23},
	author = {Vizzuality},
}

@misc{vizzuality_japan_nodate,
	title = {Japan {Deforestation} {Rates} \& {Statistics} {\textbar} {GFW}},
	url = {https://www.globalforestwatch.org/dashboards/country/JPN?category=fires},
	abstract = {In 2010, Japan had 17.2Mha of natural forest, extending over 71\% of its land area. In \{year\}, it lost 18.6kha of natural forest, equivalent to 8.96Mt of CO₂ emissions.},
	language = {en},
	urldate = {2022-06-23},
	author = {Vizzuality},
}

@misc{noauthor_global_nodate,
	title = {{GLOBAL} {FOREST} {FIRE} {ASSESSMENT} 1990-2000 - {FRA} {WP} 55},
	url = {https://www.fao.org/3/ad653e/ad653e56.htm#P6731_454901},
	urldate = {2022-06-23},
}

@misc{noauthor_forestry_nodate,
	title = {Forestry {Agency} / {How} many wildfires are there in {Japan}? : {Forestry} {Agency}},
	url = {https://www.rinya.maff.go.jp/j/hogo/yamakaji/con_1.htm},
	urldate = {2022-06-23},
}

@misc{noauthor_effis_nodate,
	title = {{EFFIS} - {Annual} {Fire} {Reports}},
	url = {https://effis.jrc.ec.europa.eu/reports-and-publications/annual-fire-reports},
	urldate = {2022-06-23},
}

@misc{noauthor_wildfires_nodate-1,
	title = {Wildfires and {Acres} {\textbar} {National} {Interagency} {Fire} {Center}},
	url = {https://www.nifc.gov/fire-information/statistics/wildfires},
	urldate = {2022-06-22},
}

@inproceedings{queral_application_2013,
	address = {Chengdu, China},
	title = {Application of {Integrated} {Safety} {Assessment} {Methodology} to {SBO} {Sequences}},
	isbn = {978-0-7918-5583-6},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE21/55836/Chengdu,%20China/250597},
	doi = {10.1115/ICONE21-16332},
	abstract = {The integrated Safety Assessment (ISA) methodology, developed by the Spanish Nuclear Safety Council (CSN), has been applied to a thermal-hydraulic analysis of PWR Station Blackout (SBO) sequences in the context of the IDPSA (Integrated Deterministic-Probabilistic Safety Assessment) network objectives. The ISA methodology allows obtaining the damage domain (the region of the uncertain parameters space where the damage limit is exceeded) for each sequence of interest as a function of the operator actuations times (recovery of AC). Given a particular safety limit or damage limit, several data of every sequence are necessary in order to obtain the exceedance frequency of that limit. In this application these data are obtained from the results of the simulations performed with MAAP code transients inside each damage domain and the time-density probability distributions of the manual actions. Several damage limits have been taken into account within the analysis: local cladding damage (PCT{\textgreater}1477 K); local fuel melting (T{\textgreater}2499 K); fuel relocation in lower plenum and vessel failure. Therefore, to every one of these damage variables corresponds a different damage domain. The results show the capability and necessity of the ISA methodology, or similar, in order to obtain accurate results that take into account time uncertainties.},
	language = {en},
	urldate = {2022-06-22},
	booktitle = {Volume 6: {Beyond} {Design} {Basis} {Events}; {Student} {Paper} {Competition}},
	publisher = {American Society of Mechanical Engineers},
	author = {Queral, C. and Mena-Rosell, L. and Jiménez Varas, G. and Sánchez-Perea, M. and Hortal, J. and Meléndez, E. and Gómez-Magán, J. and Gil, J. and Fernández, I.},
	month = jul,
	year = {2013},
	pages = {V006T15A017},
}

@techreport{garrick_power_1982,
	title = {Power plant availability engineering: methods of analysis, program planning, and applications. {Final} report},
	shorttitle = {Power plant availability engineering},
	url = {https://www.osti.gov/biblio/5346900-power-plant-availability-engineering-methods-analysis-program-planning-applications-final-report},
	abstract = {Availability engineering has its roots primarily in reliability work that is associated with the defense, communications, and aerospace industries. With respect to power plant applications, nuclear power plant risk analysis is an example of a more recent, important contributor to the technology of reliability and availability. This is particularly true in the systems modeling and data handling areas. Of course, the growing interest in more formal availability improvement programs in the power field has resulted in the most important resource for the advancement of power plant availability engineering. The keystone to contemporary availability analysis and engineering is its usefulness in making good decisions about power plant design and operations. The advocated approach fits the framework of a decision model, whereby different options for design, operations, etc., can be compared in terms of availability performance, costs, and benefits. The important building block needed for availability analysis to fit in a decision model is the quantification of uncertainty. Probability is adopted as the language of uncertainty. The concept of probability proposed is based on a state-of-knowledge approach. Such an approach provides the flexibility to model a plant and its systems at any point of the design or operations and with any data base (limited or comprehensive). The figures of merit (failure frequency, outage times, availability, etc.) are presented as probability distributions, thus communicating one's full state of knowledge about the parameters under study. The modeling techniques, data handling procedures, and analytic methods all reflect a probabilistic viewpoint. Finally, numerous examples, based on real-world power plant reliability and availability problems, are presented to illustrate specific applications.},
	language = {English},
	number = {EPRI-NP-2168},
	urldate = {2022-06-22},
	institution = {Pickard-Lowe and Garrick, Inc., Irvine, CA (USA)},
	author = {Garrick, B. J. and Kaplan, S.},
	month = may,
	year = {1982},
	doi = {10.2172/5346900},
}

@phdthesis{morozov_dual-graph_2012,
	type = {{PhD} {Thesis}},
	title = {Dual-graph model for error propagation analysis of mechatronic systems},
	author = {Morozov, Andrey},
	month = jul,
	year = {2012},
}

@phdthesis{li_integrating_2004,
	title = {{INTEGRATING} {SOFTWARE} {INTO} {PRA} ({PROBABILISTIC} {RISK} {ASSESSMENT})},
	language = {en},
	author = {Li, Bin},
	year = {2004},
}

@techreport{noauthor_nureg-75014_1975,
	title = {{NUREG}-75/014, "{Reactor} {Safety} {Study}, {An} {Assessment} of {Accident} {Risks} in {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}, {Appendix} {VI}."},
	language = {en},
	year = {1975},
	pages = {500},
}

@misc{noauthor_fukushima_nodate,
	title = {The {Fukushima} {Daiichi} {Accident}},
	url = {https://www.irsn.fr/EN/publications/thematic-safety/fukushima/Pages/overview.aspx},
	urldate = {2022-06-21},
}

@article{noauthor_fukushima_nodate-1,
	title = {Fukushima, one year later - {Initial} analyses of the accident and its consequences},
	language = {en},
	pages = {188},
}

@misc{baes_hpsorg_nodate,
	title = {hps.org},
	url = {http://hps.org/},
	abstract = {Health Physics Society},
	urldate = {2022-06-21},
	journal = {Health Physics Society},
	author = {Baes, Fred},
}

@misc{noauthor_part_nodate,
	title = {{PART} 50—{DOMESTIC} {LICENSING} {OF} {PRODUCTION} {AND} {UTILIZATION} {FACILITIES}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/index.html},
	urldate = {2022-06-21},
	journal = {NRC Web},
}

@misc{noauthor_tepco_nodate,
	title = {{TEPCO} : {Press} {Release} {\textbar} {Payment} of {Temporary} {Compensation} for damages caused by evacuation},
	url = {https://www.tepco.co.jp/en/press/corp-com/release/11041501-e.html},
	urldate = {2022-06-21},
}

@misc{noauthor_fukushima_2011,
	type = {Text},
	title = {Fukushima {Nuclear} {Accident} {Update} {Log}},
	url = {https://www.iaea.org/newscenter/news/fukushima-nuclear-accident-update-log-15},
	language = {en},
	urldate = {2022-06-21},
	month = apr,
	year = {2011},
	note = {Publisher: IAEA},
}

@article{de_meutter_assessment_2021,
	title = {The assessment of the {April} 2020 chernobyl wildfires and their impact on {Cs}-137 levels in {Belgium} and {The} {Netherlands}},
	volume = {237},
	issn = {0265-931X},
	url = {https://www.sciencedirect.com/science/article/pii/S0265931X21001600},
	doi = {10.1016/j.jenvrad.2021.106688},
	abstract = {In April 2020, several wildfires took place in and around the Chernobyl exclusion zone. These fires reintroduced radioactive particles deposited during the 1986 Chernobyl disaster into the atmosphere, causing concern about a possible radiation hazard. Several countries and several stations of the International Monitoring System measured increased Cs137 levels. This study presents the analyses made by RIVM and SCK CEN/RMI during the April 2020 wildfires. Furthermore, more in-depth research was performed after the wildfires. A statistical analysis of Cs137 detections is presented, comparing the April 2020 detections with historical detections. Inverse atmospheric transport modelling is applied to infer the total released Cs137 during the wildfires. Finally, it is assessed whether the Cs137 detections in Belgium and the Netherlands can be attributed to the wildfires.},
	language = {en},
	urldate = {2022-06-21},
	journal = {Journal of Environmental Radioactivity},
	author = {De Meutter, Pieter and Gueibe, Christophe and Tomas, Jasper and Outer, Peter den and Apituley, Arnoud and Bruggeman, Michel and Camps, Johan and Delcloo, Andy and Knetsch, Gert-Jan and Roobol, Lars and Verheyen, Leen},
	month = oct,
	year = {2021},
	keywords = {ATM, Chernobyl wildfires, Cs-137, Resuspension},
	pages = {106688},
}

@misc{noauthor__nodate,
	title = {§ 50.47 {Emergency} plans.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/part050-0047.html},
	urldate = {2022-06-21},
	journal = {NRC Web},
}

@misc{noauthor_iaea_2021,
	type = {Text},
	title = {{IAEA} {Annual} {Report} for 2020},
	url = {https://www.iaea.org/opic/annual-report-2020},
	language = {en},
	urldate = {2022-06-21},
	month = nov,
	year = {2021},
	note = {Publisher: IAEA},
}

@article{lerko_simulation_2021,
	title = {Simulation study of radionuclide atmospheric transport after wildland fires in the {Chernobyl} {Exclusion} {Zone} in {April} 2020},
	volume = {12},
	issn = {1309-1042},
	url = {https://www.sciencedirect.com/science/article/pii/S1309104221000210},
	doi = {10.1016/j.apr.2021.01.010},
	abstract = {This paper presents model results for the dispersion of radionuclides released into the atmosphere by intense forest fires in the Chernobyl Exclusion Zone in April 2020. The 137Cs activity concentration in the surface air is calculated on a regional scale (in Ukraine) and a local scale (within the Chernobyl Exclusion Zone). The 137Cs activity in the surface air of Kyiv was found to have reached 2–4 mBq m−3 during the period April 4–20. The results presented in this paper are generally consistent with measured data pertaining to radioactive contamination in Kyiv and areas around several nuclear power plants in Ukraine. The total effective dose to the population of Kyiv during the fire period was estimated to be 5.7 nSv from external exposure and the inhalation of 137Cs and 90Sr, rising to 30 nSv by the end of 2020. This is about 0.003\% of the annual permissible level of exposure of the population. A committed effective dose of about 16 nSv was estimated for the personnel of the Chernobyl nuclear power plant from the inhalation of 137Cs and 90Sr during the 2020 forest fires. A method for estimating the radionuclide activity emissions during wildland fires in radioactively contaminated areas is proposed. This method is based on satellite measurement data of the fire radiative power, the radionuclide inventory in the fire area, and an emission factor for radioactive particles.},
	language = {en},
	number = {3},
	urldate = {2022-06-21},
	journal = {Atmospheric Pollution Research},
	author = {Таlerko, Mykola and Коvalets, Ivan and Lev, Тatiana and Igarashi, Yasunori and Romanenko, Olexandr},
	month = mar,
	year = {2021},
	keywords = {Atmospheric transport, Chernobyl exclusion zone, Modeling, Radionuclide, Satellite monitoring, Wildland fire},
	pages = {193--204},
}

@article{hashimoto_total_2012,
	title = {The total amounts of radioactively contaminated materials in forests in {Fukushima}, {Japan}},
	volume = {2},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep00416},
	doi = {10.1038/srep00416},
	language = {en},
	number = {1},
	urldate = {2022-06-21},
	journal = {Scientific Reports},
	author = {Hashimoto, Shoji and Ugawa, Shin and Nanko, Kazuki and Shichi, Koji},
	month = dec,
	year = {2012},
	pages = {416},
}

@article{noauthor_simexec_nodate,
	title = {{SimExec} {User} {Guide} [},
	pages = {404},
}

@article{seto_jstation_nodate,
	title = {{JStation} {User} {Guide}},
	language = {en},
	author = {Seto, Karen},
	pages = {594},
}

@article{seto_jdesigner_nodate,
	title = {{JDesigner} {User} {Guide}},
	language = {en},
	author = {Seto, Karen},
	pages = {601},
}

@article{seto_jdesigner_nodate-1,
	title = {{JDesigner} {Object} {Editor}},
	language = {en},
	author = {Seto, Karen},
	pages = {190},
}

@article{karimi_core_2021,
	title = {Core calculations for small modular reactor during burnup cycle},
	issn = {1556-7036},
	url = {https://doi.org/10.1080/15567036.2021.1963883},
	doi = {10.1080/15567036.2021.1963883},
	journal = {Energy Sources, Part A: Recovery, Utilization, and Environmental Effects},
	author = {Karimi, Javad and Shayesteh, Mohsen and Zangian, Mehdi},
	month = aug,
	year = {2021},
	note = {Publisher: Taylor \& Francis},
	pages = {1--18},
}

@misc{noauthor_health_nodate,
	title = {Health {Effects} of {Radiation}: 5 {Themes} - (vi) {Comparison} of exposure doses in daily life},
	url = {https://www.env.go.jp/en/chemi/rhm/portal/digest/travel/detail_006.html},
	urldate = {2022-06-20},
}

@misc{cnn_chernobyl_nodate,
	title = {Chernobyl radiation levels spike as forest fires rage},
	url = {https://www.cnn.com/2020/04/06/europe/chernobyl-fire-radiation-scli-intl-scn/index.html},
	abstract = {Radiation levels near the site of the Chernobyl nuclear reactor disaster have spiked as firefighters battle to contain two forest fires in the area.},
	urldate = {2022-06-20},
	journal = {CNN},
	author = {CNN, Rob Picheta},
}

@misc{roach_chernobyl_2022,
	title = {Chernobyl forest fires raise radiation fears},
	url = {https://www.protocol.com/bulletins/forest-fire-chernobyl-radiation},
	abstract = {The site of the world's worst nuclear disaster continues to be a source of worry after Russian forces took over the defunct nuclear power plant.},
	language = {en},
	urldate = {2022-06-20},
	journal = {Protocol},
	author = {Roach, Sarah},
	month = mar,
	year = {2022},
	note = {Section: Bulletins},
}

@article{milman_forest_2022,
	chapter = {World news},
	title = {Forest fires erupt around {Chernobyl} nuclear plant in {Ukraine}},
	issn = {0261-3077},
	url = {https://www.theguardian.com/world/2022/mar/22/chernobyl-forest-fires-ukraine-nuclear-plant},
	abstract = {Ukrainian authorities say Russian control of plant is hampering efforts to control the blazes},
	language = {en-GB},
	urldate = {2022-06-20},
	journal = {The Guardian},
	author = {Milman, Oliver},
	month = mar,
	year = {2022},
	keywords = {Chernobyl nuclear disaster, Environment, Europe, Ukraine, Wildfires, World news},
}

@misc{noauthor_international_2019,
	type = {Text},
	title = {International {Nuclear} and {Radiological} {Event} {Scale} ({INES})},
	url = {https://www.iaea.org/resources/databases/international-nuclear-and-radiological-event-scale},
	abstract = {The International Nuclear and Radiological Event Scale (INES) is a tool for communicating the safety significance of nuclear and radiological events to the public.},
	language = {en},
	urldate = {2022-06-18},
	month = may,
	year = {2019},
	note = {Publisher: IAEA},
}

@misc{noauthor_chernobyl_nodate,
	title = {The {Chernobyl} {Accident}},
	url = {//www.unscear.org/unscear/en/areas-of-work/chernobyl.html},
	abstract = {The Chernobyl Accident},
	language = {en},
	urldate = {2022-06-17},
	journal = {United Nations : Scientific Committee on the Effects of Atomic Radiation},
}

@misc{noauthor_backgrounder_nodate,
	title = {Backgrounder on {Biological} {Effects} of {Radiation}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/fact-sheets/bio-effects-radiation.html},
	urldate = {2022-06-17},
	journal = {NRC Web},
}

@misc{noauthor__nodate,
	title = {林野庁/日本では山火事はどの位発生しているの？：林野庁},
	url = {https://www.rinya.maff.go.jp/j/hogo/yamakaji/con_1.htm},
	urldate = {2022-06-15},
}

@misc{vizzuality_forest_nodate,
	title = {Forest {Fires} \& {Climate} {Change} {\textbar} {Effects} of {Deforestation} on {Wildfires} {\textbar} {GFW}},
	url = {https://www.globalforestwatch.org/topics/fires/},
	abstract = {Explore the relationship between forests and fires, the effect of climate change on wildfires and how protection against deforestation can help prevent forest fires.},
	language = {en},
	urldate = {2022-06-14},
	author = {Vizzuality},
}

@misc{vizzuality_japan_nodate,
	title = {Japan {Deforestation} {Rates} \& {Statistics} {\textbar} {GFW}},
	url = {https://www.globalforestwatch.org/dashboards/country/JPN?category=fires},
	abstract = {In 2010, Japan had 17.2Mha of natural forest, extending over 71\% of its land area. In \{year\}, it lost 18.6kha of natural forest, equivalent to 8.96Mt of CO₂ emissions.},
	language = {en},
	urldate = {2022-06-14},
	author = {Vizzuality},
}

@techreport{bozoki_review_1994,
	title = {Review of the {Diablo} {Canyon} probabilistic risk assessment},
	url = {http://www.osti.gov/servlets/purl/10181672-Ey7ByA/native/},
	language = {en},
	number = {NUREG/CR--5726, BNL-NUREG--52288, 10181672},
	urldate = {2022-06-14},
	author = {Bozoki, G.E. and Fitzpatrick, R.G. and Bohn, M.P. and Sabek, M.G. and Ravindra, M.K. and Johnson, J.J.},
	month = aug,
	year = {1994},
	doi = {10.2172/10181672},
	pages = {NUREG/CR--5726, BNL--NUREG--52288, 10181672},
}

@misc{noauthor_wildfires_nodate,
	title = {Wildfires and {Acres} {\textbar} {National} {Interagency} {Fire} {Center}},
	url = {https://www.nifc.gov/fire-information/statistics/wildfires},
	urldate = {2022-06-14},
}

@misc{noauthor_national_nodate,
	title = {National {Fire} {News} {\textbar} {National} {Interagency} {Fire} {Center}},
	url = {https://www.nifc.gov/fire-information/nfn},
	urldate = {2022-06-14},
}

@article{noauthor_fires_nodate,
	title = {Fires in {Ukraine} in the exclusion zone around the {Chernobyl} power plant: {Latest} measurement results and assessment of environmental and health consequences},
	language = {en},
	pages = {10},
}

@article{ager_wildfire_2019,
	title = {The wildfire problem in areas contaminated by the {Chernobyl} disaster},
	volume = {696},
	issn = {00489697},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0048969719339245},
	doi = {10.1016/j.scitotenv.2019.133954},
	language = {en},
	urldate = {2022-06-13},
	journal = {Science of The Total Environment},
	author = {Ager, Alan A. and Lasko, Richard and Myroniuk, Viktor and Zibtsev, Sergiy and Day, Michelle A. and Usenia, Uladzimir and Bogomolov, Vadym and Kovalets, Ivan and Evers, Cody R.},
	month = dec,
	year = {2019},
	pages = {133954},
}

@article{lasko_forest_2020,
	title = {Forest {Service} {Assistance} to {Ukraine}},
	volume = {78},
	copyright = {Copyright Superintendent of Documents 2020},
	issn = {15548996},
	url = {http://www.proquest.com/docview/2448440016/abstract/A39DAE73934D4E66PQ/1},
	abstract = {Wildfire suppression training began in 2012 with an onsite Incident Command System seminar and exercise involving Chernobyl Exclusion Zone emergency managers and Forest Service fire specialists, supported in part by the U.S. Agency for International Development. Continued training in wildland fire management included onsite Incident Command System sessions and tabletop exercises in 2015 and 2016 and a study tour to the United States in 2013 for emergency response personnel to look at all-hazards response operations. Training included: * An introduction to basic wildland firefighting, * An introduction to incident command coordination, * Strategies for initial and extended attack on wildfires, * Wildland fire safety, * Basic fire behavior, * After-action reviews, and * Building partnerships with the media and local communities. Seven senior leaders from the Agency for Management of the Chernobyl Exclusion Zone and the State Emergency Services of Ukraine took the National Wildfire Coordinating Group's Gettysburg Staff Ride (L-580), a senior-level leadership course for both wildland and structural firefighters.},
	language = {English},
	number = {2},
	urldate = {2022-06-13},
	journal = {Fire Management Today},
	author = {Lasko, Rich and Ager, Alan and Slemp, Shelia},
	year = {2020},
	note = {Num Pages: 5-10
Place: Washington, United States
Publisher: Superintendent of Documents},
	keywords = {Cooperation, Disasters, Emergency management, Emergency preparedness, Emergency procedures, Emergency response, Emergency services, Environmental science, Exclusion zones, Fire Prevention, Fire fighting, Fire prevention, Fire protection, Fire safety, Firefighter services, Firefighters, Forest \& brush fires, Forest fires, Forest management, Forests And Forestry, Leadership, Local communities, Managers, Nuclear power plants, Onsite, Operational hazards, Personal protective equipment, Public Health And Safety, Training, Vegetation, Wildfires},
	pages = {5--10},
}

@misc{noauthor_okuma_nodate,
	title = {Okuma climate: {Average} {Temperature}, weather by month, {Okuma} weather averages - {Climate}-{Data}.org},
	url = {https://en.climate-data.org/asia/japan/fukushima/okuma-50675/},
	urldate = {2022-06-10},
}

@article{rasmuson_comparison_1992,
	title = {A comparison of the small and large event tree approaches used in {PRAs}},
	volume = {37},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209290062P},
	doi = {10.1016/0951-8320(92)90062-P},
	language = {en},
	number = {1},
	urldate = {2022-06-02},
	journal = {Reliability Engineering \& System Safety},
	author = {Rasmuson, Dale M.},
	month = jan,
	year = {1992},
	pages = {79--90},
}

@techreport{garrick_probabilistic_nodate,
	title = {Probabilistic {Risk} {Assessment} of {Nuclear} {Power} {Plant} {Spent} {Fuel} {Handling} and {Storage} {Programs}: {Methodology} and {Application} to the {Diablo} {Canyon} {Power} {Plant}},
	language = {en},
	author = {Garrick, B John and Wakefield, Donald J},
	pages = {161},
}

@techreport{smith_advanced_2014,
	title = {Advanced {Small} {Modular} {Reactor} ({SMR}) {Probabilistic} {Risk} {Assessment} ({PRA}) {Demonstration}},
	url = {http://www.osti.gov/servlets/purl/1149017/},
	language = {en},
	number = {INL/EXT-14-31876, 1149017},
	urldate = {2022-06-01},
	author = {Smith, Curtis and Prescott, Steven and Koonce, Tony},
	month = apr,
	year = {2014},
	doi = {10.2172/1149017},
	pages = {INL/EXT--14--31876, 1149017},
}

@misc{us_epa_radiation_2015,
	type = {Overviews and {Factsheets}},
	title = {Radiation {Sources} and {Doses}},
	url = {https://www.epa.gov/radiation/radiation-sources-and-doses},
	abstract = {Radiation dose and source information the U.S., including doses from common radiation sources.},
	language = {en},
	urldate = {2022-05-31},
	author = {US EPA, OAR},
	month = apr,
	year = {2015},
}

@article{draxler_noaa_nodate,
	title = {{NOAA} {Technical} {Memorandum} {ERL} {ARL}-224},
	abstract = {The HYSPLIT (HYbrid Single-Particle Lagrangian Integrated Trajectory) model is a complete system for computing simple trajectories to complex dispersion and deposition simulations using either puff or particle approaches. The model uses previously gridded meteorological data on one of three conformal map projections (Polar, Lambert, Mercator). Air concentration calculations associate the mass of the pollutant species with the release of either puffs, particles, or a combination of both. The dispersion rate is calculated from the vertical diffusivity profile, wind shear, and horizontal deformation of the wind field. Air concentrations are calculated at a specific grid point for puffs and as cellaverage concentrations for particles.},
	language = {en},
	author = {Draxler, Roland R and Hess, G D},
	pages = {31},
}

@article{cornell_engineering_1968,
	title = {Engineering {Seismic} {Risk} {Analysis}},
	volume = {58},
	number = {5},
	journal = {Bulletin of Seismological Society of America},
	author = {Cornell, C. Allin},
	month = oct,
	year = {1968},
	pages = {1583--1606},
}

@article{kaplan_matrix_1982,
	title = {Matrix {Theory} {Formalism} for {Event} {Tree} {Analysis}  {Application} to {Nuclear}‐{Risk} {Analysis}},
	volume = {2},
	number = {1},
	journal = {Risk Analysis},
	author = {Kaplan, Stanley},
	year = {1982},
}

@article{papazoglou_mathematical_1998,
	title = {Mathematical foundations of event trees},
	volume = {61},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832098000106},
	doi = {10.1016/S0951-8320(98)00010-6},
	language = {en},
	number = {3},
	urldate = {2022-05-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Papazoglou, Ioannis A.},
	month = sep,
	year = {1998},
	pages = {169--183},
}

@book{noauthor_generic_2000,
	address = {Vienna},
	series = {{TECDOC} {Series}},
	title = {Generic {Procedures} for {Assessment} and {Response} {During} a {Radiological} {Emergency}},
	url = {https://www.iaea.org/publications/5926/generic-procedures-for-assessment-and-response-during-a-radiological-emergency},
	number = {1162},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2000},
}

@techreport{noauthor_department_2011,
	title = {Department of {Defense} {Handbook} {Reliability} {Growth} {Management}},
	url = {https://www.dote.osd.mil/Portals/97/docs/TEMPGuide/MIL-HDBK-189C.pdf?ver=2019-12-27-180112-903},
	number = {MIL-HDBK-189C},
	urldate = {2022-05-19},
	institution = {U.S. Army Materiel System Analysis Activity},
	month = jun,
	year = {2011},
}

@article{stein_noaas_2015,
	title = {{NOAA}’s {HYSPLIT} {Atmospheric} {Transport} and {Dispersion} {Modeling} {System}},
	volume = {96},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/doi/10.1175/BAMS-D-14-00110.1},
	doi = {10.1175/BAMS-D-14-00110.1},
	abstract = {Abstract
            The Hybrid Single-Particle Lagrangian Integrated Trajectory model (HYSPLIT), developed by NOAA’s Air Resources Laboratory, is one of the most widely used models for atmospheric trajectory and dispersion calculations. We present the model’s historical evolution over the last 30 years from simple hand-drawn back trajectories to very sophisticated computations of transport, mixing, chemical transformation, and deposition of pollutants and hazardous materials. We highlight recent applications of the HYSPLIT modeling system, including the simulation of atmospheric tracer release experiments, radionuclides, smoke originated from wild fires, volcanic ash, mercury, and wind-blown dust.},
	language = {en},
	number = {12},
	urldate = {2022-05-19},
	journal = {Bulletin of the American Meteorological Society},
	author = {Stein, A. F. and Draxler, R. R. and Rolph, G. D. and Stunder, B. J. B. and Cohen, M. D. and Ngan, F.},
	month = dec,
	year = {2015},
	pages = {2059--2077},
}

@article{zoellick_source_nodate,
	title = {Source {Term} {Estimation} of {Atmospheric} {Pollutants} {Using} an {Ensemble} of {HYSPLIT} {Concentration} {Simulations}},
	language = {en},
	author = {Zoellick, Casey L},
	pages = {111},
}

@phdthesis{kwag_probabilistic_2016,
	address = {Raleigh, North Carolina},
	title = {Probabilistic {Approaches} for {Multi}-{Hazard} {Risk} {Assessment} of {Structures} and {Systems}},
	language = {English},
	school = {North Carolina State University},
	author = {KWAG, SHINYOUNG},
	year = {2016},
}

@article{alrammah_application_2022,
	title = {Application of probabilistic safety assessment ({PSA}) to the power reactor innovative small module ({PRISM})},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573322001863},
	doi = {10.1016/j.net.2022.04.001},
	abstract = {Several countries show interest in the Generation-IV power reactor innovative small module (PRISM), including: Canada, Japan, Korea, Saudi Arabia and the United Kingdom. Generation IV International Forum (GIF) has recommended the utilizing of probabilistic safety assessment (PSA) in evaluating the safety of Generation-IV reactors. This paper reviews the PSA performed for PRISM using SAPHIRE 7.27 code. This work shows that the core damage frequency (CDF) of PRISM for a single module is estimated by 8.5E-8/year which is lower than the Generation-IV target that is 1E-6 core damage per year. The social risk of PRISM (likelihood of latent cancer fatality) with evacuation is estimated by 9.0E-12/year which is much lower than the basic safety objective (BSO) that is 1E-7/year. The social risk without evacuation is estimated by 1.2E- 11/year which is also much lower than the BSO. For the individual risk (likelihood of prompt fatality), it is concluded that it can be considered negligible with evacuation (1.0E-13/year). Assuming no evacuation, the individual risk is 2.7E-10/year which is again much lower than the BSO. In comparison with other PSAs performed for similar sodium fast reactors (SFRs), it shows that PRISM concept has the lowest CDF.},
	language = {en},
	urldate = {2022-05-14},
	journal = {Nuclear Engineering and Technology},
	author = {Alrammah, Ibrahim},
	month = apr,
	year = {2022},
	keywords = {CDF, PRISM, PSA, SAPHIRE, SFR},
}

@article{wakefield_riskman_nodate,
	title = {{RISKMAN}®, {Celebrating} 20+ {Years} of {Excellence}!},
	abstract = {RISKMAN® is a PC-based, general purpose, integrated tool for quantitative risk analysis. Initiated with software programs first developed for main frames, and with development supported by a user’s group spanning three continents, the PC version of RISKMAN® now celebrates more than 20 years of risk-based applications. While mostly used in the nuclear power industry and related government organizations, RISKMAN® is also used in the offshore oil industry, marine industry, aerospace, and for specialty applications such as for assessing the risks associated with the excavation and destruction of abandoned chemical weapons.},
	language = {en},
	author = {Wakefield, Mr Donald and Epstein, Mr Steven and Xiong, Dr Yongjie and Nouri, Mr Kamyar},
	pages = {10},
}

@article{epstein_validation_nodate,
	title = {Validation {Project} for the {Open}-{PSA} {Model} {Exchange} using {RiskSpectrum}® and {CAFTA}®},
	abstract = {Under the sponsorship of the Institut pour la Maîtrise des Risques (IMdR), and supported financially and technically by more than ten European and US organizations (see section 4), this validation project has been successfully completed with both RiskSpectrum®, from Relcon Scandpower and CAFTA®, from EPRI.},
	language = {en},
	author = {Epstein, Steven and Reinhart, F Mark and Rauzy, Antoine},
	pages = {5},
}

@misc{steven_open-psa_2017,
	title = {Open-{PSA} {Model} {Exchange} {Format}},
	editor = {Steven, Epstein and Antoine, Rauzy},
	year = {2017},
}

@article{rebour_report_nodate,
	title = {Report 2: {Guidance} document on practices to model and implement external {FLOODING} hazards in extended {PSA}},
	abstract = {The goal of this report is to provide guidance on practices to model EXTERNAL FLOODING hazards and its implementation in extended level 1 PSA. This report is a joint deliverable of work package 21 (WP21) and 22 (WP22) of the ASAMPSA\_E project.},
	language = {en},
	author = {Rebour, V and Georgescu, G and Leteinturier, D and Raimond, E and Rovere, S La and Bernadara, P and Vasseur, D and Groudev, P and Ivanov, I and Turschmann, M and Sperbeck, S and Potempski, S and Hirata, K and Kumar, M},
	pages = {111},
}

@inproceedings{prosek_methodology_2017,
	address = {High Tatras Mountains, Tatranské Matliare, Slovak Republic},
	title = {Methodology for selecting initiating events and hazards for consideration in an extended {PSA}},
	isbn = {978-1-138-62937-0 978-1-351-80973-3},
	url = {http://www.crcnetbase.com/doi/10.1201/9781315210469-421},
	doi = {10.1201/9781315210469-421},
	language = {en},
	urldate = {2022-05-10},
	booktitle = {Safety and {Reliability} – {Theory} and {Applications}},
	publisher = {CRC Press},
	author = {Prošek, A and Wielenberg, A and Löffler, H and Raimond, E},
	month = jun,
	year = {2017},
	pages = {490--490},
}

@article{noauthor_planning_nodate,
	title = {{PLANNING} {FOR} {OFF}-{SITE} {RESPONSE} {TO} {RADIATION} {ACCIDENTS} {IN} {NUCLEAR} {FACILITIES}},
	language = {en},
	pages = {125},
}

@article{wu_development_2015,
	title = {Development of reliability and probabilistic safety assessment program {RiskA}},
	volume = {83},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645491500153X},
	doi = {10.1016/j.anucene.2015.03.020},
	abstract = {PSA (probabilistic safety assessment) software, the indispensable tool in nuclear safety assessment, has been widely used. An integrated reliability and PSA program named RiskA has been developed by FDS Team. RiskA supplies several standard PSA modules including fault tree analysis, event tree analysis, uncertainty analysis, failure mode and effect analysis and reliability database, etc. RiskA has several advanced features such as extensible framework, fast fault tree analysis, multiple models formats support and web-based co-modeling. Not only the overview of the architecture and basic functions of RiskA, but also the challenges and solutions in the development procedure of RiskA were introduced. The comparison between RiskA and other popular PSA codes has demonstrated that the calculation and analysis of RiskA is more accurate and efﬁcient. Based on the development of this code package, many applications of safety and reliability analysis of some research reactors and nuclear power plants were performed.},
	language = {en},
	urldate = {2022-05-04},
	journal = {Annals of Nuclear Energy},
	author = {Wu, Yican},
	month = sep,
	year = {2015},
	pages = {316--321},
}

@article{epstein_can_2006,
	title = {Can {We} {Trust} {PRA}: {Take} 3},
	abstract = {ABSTRACT The purpose of this study is to investigate the potential of Binary Decision Diagram (BDD) quantification methods to evaluate the current set of large linked fault trees used in nuclear power plant probabilistic risk assessments. The need for a BDD quantification method stems from desire to eliminate the simplifications that are inherent in the large linked fault tree quantification. These simplifications include the use of the rare event approximation, the use of truncation limits, and the simplified treatment of success terms.},
	language = {en},
	author = {Epstein, Steve and Rauzy, Antoine and Wakefield, Don},
	year = {2006},
	pages = {16},
}

@inproceedings{minato_zero-suppressed_1993,
	title = {Zero-{Suppressed} {BDDs} for {Set} {Manipulation} in {Combinatorial} {Problems}},
	booktitle = {{ACM}/{IEEE}},
	author = {Minato, Shin-ichi},
	year = {1993},
}

@article{minato_zero-suppressed_2001,
	title = {Zero-suppressed {BDDs} and their applications},
	volume = {3},
	issn = {1433-2779},
	url = {http://link.springer.com/10.1007/s100090100038},
	doi = {10.1007/s100090100038},
	abstract = {In many real-life problems, we are often faced with manipulating sets of combinations. In this article, we study a special type of ordered binary decision diagram (OBDD), called zero-suppressed BDDs (ZBDDs). This data structure represents sets of combinations more eﬃciently than using original OBDDs. We discuss the basic data structures and algorithms for manipulating ZBDDs in contrast with the original OBDDs. We also present some practical applications of ZBDDs, such as solving combinatorial problems with unate cube set algebra, logic synthesis methods, Petri net processing, etc. We show that a ZBDD is a useful option in OBDD techniques, suitable for a part of the practical applications.},
	language = {en},
	number = {2},
	urldate = {2022-05-04},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Minato, Shin-ichi},
	month = may,
	year = {2001},
	pages = {156--170},
}

@article{jung_fast_2004,
	title = {A fast {BDD} algorithm for large coherent fault trees analysis},
	volume = {83},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832003002369},
	doi = {10.1016/j.ress.2003.10.009},
	abstract = {Although a binary decision diagram (BDD) algorithm has been tried to solve large fault trees until quite recently, they are not efﬁciently solved in a short time since the size of a BDD structure exponentially increases according to the number of variables. Furthermore, the truncation of If– Then – Else (ITE) connectives by the probability or size limit and the subsuming to delete subsets could not be directly applied to the intermediate BDD structure under construction. This is the motivation for this work.},
	language = {en},
	number = {3},
	urldate = {2022-05-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Jung, Woo Sik and Han, Sang Hoon and Ha, Jaejoo},
	month = mar,
	year = {2004},
	pages = {369--374},
}

@article{jung_zbdd_2009,
	title = {{ZBDD} algorithm features for an efficient {Probabilistic} {Safety} {Assessment}},
	volume = {239},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549309002258},
	doi = {10.1016/j.nucengdes.2009.05.005},
	abstract = {This paper explains a Zero-suppressed Binary Decision Diagram (ZBDD) algorithm and introduces advanced ZBDD algorithm-based features that are implemented into a fault tree solver Fault Tree Reliability Evaluation eXpert (FTREX). The ZBDD algorithm and its advanced features have been developed for solving a fault tree in Probabilistic Safety Assessment (PSA) of a nuclear power plant. The ZBDD can be interpreted as a factorized structure of minimal cut sets (MCSs). A ZBDD algorithm was developed in 2004 for performing a Boolean operation of ZBDDs. The ZBDD algorithm is based on a set of new ZBDD operation formulae. The ZBDD algorithm is known as an efﬁcient replacement of a cutset-based algorithm that is based on traditional Boolean algebra.},
	language = {en},
	number = {10},
	urldate = {2022-05-04},
	journal = {Nuclear Engineering and Design},
	author = {Jung, Woo Sik},
	month = oct,
	year = {2009},
	pages = {2085--2092},
}

@misc{noauthor_open_nodate,
	title = {Open {Reliability}},
	url = {http://www.openreliability.org/},
	urldate = {2022-05-04},
}

@inproceedings{manorma_riskspectrum_2010,
	address = {Amman, Jordan},
	title = {{RiskSpectrum}: {Emerging} software for {Nuclear} {Power} {Industry}},
	isbn = {978-1-4244-5213-2},
	shorttitle = {{RiskSpectrum}},
	url = {http://ieeexplore.ieee.org/document/5462562/},
	doi = {10.1109/INREC.2010.5462562},
	abstract = {RiskSpectrum is advanced software by Relcon Scandpower AB, which is increasingly being used to develop the fault tree and the event tree to find out the reliability of system in various parts of Nuclear Power Plant. In this paper, the feature and scope of RiskSpectrum is demonstrated with a fault tree example of Sodium Cooled Fast Reactor used in Nuclear Power Generation Industry. A self sufficient model with software results has been given with full details, which can work as a basic structure for an advanced and detail studies.},
	language = {en},
	urldate = {2022-05-04},
	booktitle = {2010 1st {International} {Nuclear} \& {Renewable} {Energy} {Conference} ({INREC})},
	publisher = {IEEE},
	author = {{Manorma}},
	month = mar,
	year = {2010},
	pages = {1--6},
}

@misc{noauthor_welcome_nodate,
	title = {Welcome to the {Open} {PSA} {Initiative} website},
	url = {https://open-psa.github.io/joomla1.5/index.php.html},
	urldate = {2022-05-04},
}

@article{valiant_complexity_1979,
	title = {The {Complexity} of {Enumeration} and {Reliability} {Problems}},
	volume = {8},
	issn = {0097-5397, 1095-7111},
	url = {http://epubs.siam.org/doi/10.1137/0208032},
	doi = {10.1137/0208032},
	abstract = {The class of \#P-complete problems is a class of computationally eqivalent counting problems (defined by the author in a previous paper) that are at least as difficult as the NP-complete problems. Here we show, for a large number of natural counting problems for which there was no previous indication of intractability, that they belong to this class. The technique used is that of polynomial time reduction with oracles via translations that are of algebraic or arithmetic nature.},
	language = {en},
	number = {3},
	urldate = {2022-05-04},
	journal = {SIAM Journal on Computing},
	author = {Valiant, Leslie G.},
	month = aug,
	year = {1979},
	pages = {410--421},
}

@article{noauthor_levels_nodate,
	title = {Levels and effects of radiation exposure due to the accident at the {Fukushima} ...},
	language = {en},
	pages = {244},
}

@article{kaplan_methodology_1983,
	title = {A {Methodology} for {Seismic} {Risk} {Analysis} of {Nuclear} {Power} {Plants}},
	volume = {3},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.1983.tb00118.x},
	doi = {10.1111/j.1539-6924.1983.tb00118.x},
	language = {en},
	number = {3},
	urldate = {2022-05-02},
	journal = {Risk Analysis},
	author = {Kaplan, Stan and Perla, Harold F. and Bley, Dennis C.},
	month = sep,
	year = {1983},
	pages = {169--180},
}

@article{nusbaumer_fault_2013,
	title = {Fault tree linking versus event tree linking approaches: a reasoned comparison},
	volume = {227},
	issn = {1748-006X, 1748-0078},
	shorttitle = {Fault tree linking versus event tree linking approaches},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X13490260},
	doi = {10.1177/1748006X13490260},
	abstract = {Two well-known modelling approaches are in use in probabilistic risk assessment: fault tree linking and event tree linking. The question of which modelling approach is most appropriate for specific applications has been extensively, if not emotionally, debated among experts in the past two decades, addressing both modelling and quantification issues. In this article, we determine their degree of equivalence and build ‘methodological bridges’ between the two approaches from a mathematical and algorithmic perspective. We show that, under certain conditions, both modelling approaches are equivalent. Since both fault tree linking and event tree linking approaches are subject to limitations and approximations, established bridges make it possible to formulate important recommendations for probabilistic risk assessment practitioners and quantification engine developers.},
	language = {en},
	number = {3},
	urldate = {2022-05-02},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Nusbaumer, Olivier and Rauzy, Antoine},
	month = jun,
	year = {2013},
	pages = {315--326},
}

@article{world_health_organization_weekly_2013,
	title = {Weekly {Epidemiological} {Record}, 2013, vol. 88, 10 [full issue]},
	volume = {88},
	url = {https://apps.who.int/iris/handle/10665/242041},
	language = {en},
	number = {10},
	urldate = {2022-04-27},
	journal = {Weekly Epidemiological Record = Relevé épidémiologique hebdomadaire},
	author = {{World Health Organization}},
	year = {2013},
	pages = {101--116},
}

@book{world_health_organization_health_2013,
	address = {Geneva},
	title = {Health risk assessment from the nuclear accident after the 2011 {Great} {East} {Japan} earthquake and tsunami, based on a preliminary dose estimation},
	isbn = {978-92-4-150513-0},
	url = {https://apps.who.int/iris/handle/10665/78218},
	language = {en},
	urldate = {2022-04-27},
	publisher = {World Health Organization},
	author = {{World Health Organization}},
	year = {2013},
	note = {Section: Executive summary published as technical document no. WHO/HSE/PHE/2013.1(E)},
	keywords = {Earthquakes, Japan, Nuclear Power Plants, Radiation Dosage, Radiation Injuries, Radiation Monitoring, Radioactive Hazard Release, Risk Assessment, Tsunamis},
}

@techreport{fussell_mocus_1974,
	title = {{MOCUS}: a computer program to obtain minimal sets from fault trees},
	shorttitle = {{MOCUS}},
	url = {http://www.osti.gov/servlets/purl/4267950/},
	language = {en},
	number = {ANCR--1156, 4267950},
	urldate = {2022-04-26},
	author = {Fussell, J.B. and Henry, E.B. and Marshall, N.H.},
	month = aug,
	year = {1974},
	doi = {10.2172/4267950},
	pages = {ANCR--1156, 4267950},
}

@misc{noauthor_benchexec_2022,
	title = {{BenchExec}},
	copyright = {Apache-2.0},
	url = {https://github.com/sosy-lab/benchexec},
	abstract = {BenchExec: A Framework for Reliable Benchmarking and Resource Measurement},
	urldate = {2022-04-26},
	publisher = {SoSy-Lab},
	month = apr,
	year = {2022},
	note = {original-date: 2015-02-13T13:55:15Z},
	keywords = {benchmark, benchmark-framework, benchmarking, cgroups, linux, python, resource-measurement},
}

@misc{rakhimov_scram_2022,
	title = {{SCRAM}},
	copyright = {GPL-3.0},
	url = {https://github.com/rakhimov/scram/blob/b85b78940de38996eeffec54d946824bd4280a1c/scripts/fault_tree_generator.py},
	abstract = {Probabilistic Risk Analysis Tool (fault tree analysis, event tree analysis, etc.)},
	urldate = {2022-04-25},
	author = {Rakhimov, Olzhas},
	month = apr,
	year = {2022},
	note = {original-date: 2014-03-21T01:19:49Z},
}

@book{loeliger_version_2012,
	address = {Beijing},
	edition = {Second edition},
	title = {Version control with {Git}},
	isbn = {978-1-4493-1638-9},
	language = {en},
	publisher = {O'Reilly},
	author = {Loeliger, Jon and McCullough, Matthew},
	year = {2012},
	keywords = {Computer software, Development, Git (Computer file), Open source software},
}

@misc{pandit_development_2022,
	title = {The {Development} of {Supply} {Chain} {Probabilistic} {Risk} {Assessment} {Tool} ({Accepted} for {Publication} in the {ANS} 2022 {Annual} {Meeting})},
	publisher = {ANS Transactions Summary},
	author = {Pandit, Priyanka and Earthperson, Arjun and Nevius, Daniel and A. Diaconeasa, Mihai},
	month = jun,
	year = {2022},
}

@misc{noauthor_nureg-2122_nodate,
	title = {{NUREG}-2122, "{Glossary} of {Risk}-{Related} {Terms} in {Support} of {Risk}-{Informed} {Decision} {Making}."},
	url = {https://www.nrc.gov/docs/ML1331/ML13311A353.pdf},
	language = {en},
	publisher = {Office of Nuclear Regulatory Research},
}

@misc{rakhimov_scram_2022-1,
	title = {{SCRAM}},
	copyright = {GPL-3.0},
	url = {https://github.com/rakhimov/scram},
	abstract = {Probabilistic Risk Analysis Tool (fault tree analysis, event tree analysis, etc.)},
	urldate = {2022-04-20},
	author = {Rakhimov, Olzhas},
	month = mar,
	year = {2022},
	note = {original-date: 2014-03-21T01:19:49Z},
	keywords = {bdd, c-plus-plus, cpp17, event-tree, fault-tree, fta, pra, psa, python, qt5, reliability-engineering, risk-analysis, zbdd},
}

@book{jungnickel_graphs_2013,
	address = {Berlin, Heidelberg},
	series = {Algorithms and {Computation} in {Mathematics}},
	title = {Graphs, {Networks} and {Algorithms}},
	volume = {5},
	isbn = {978-3-642-32277-8 978-3-642-32278-5},
	url = {http://link.springer.com/10.1007/978-3-642-32278-5},
	language = {en},
	urldate = {2022-04-20},
	publisher = {Springer Berlin Heidelberg},
	author = {Jungnickel, Dieter},
	year = {2013},
	doi = {10.1007/978-3-642-32278-5},
}

@misc{we_veselyff_goldbergnh_robertsdf_haasl_nureg-0492_1981,
	title = {{NUREG}-0492, "{Fault} {Tree} {Handbook}".},
	url = {https://drum.lib.umd.edu/handle/1903/7729},
	language = {en},
	author = {W.E. Vesely,F.F. Goldberg,N.H. Roberts,D.F. Haasl},
	month = jan,
	year = {1981},
}

@incollection{cepin_reliability_2011,
	address = {London},
	title = {Reliability {Block} {Diagram}},
	isbn = {978-0-85729-688-7},
	url = {https://doi.org/10.1007/978-0-85729-688-7_9},
	abstract = {The reliability block diagram is a method used to analyze systems and assess their reliability. It includes a graphical representation of the system and equations that can be used to analyze the reliability of the system. The blocks represent the groups of components or the smallest entities of the system, which are not further divided, i.e., components of the system. If the individual components of a system are connected in series, the failure of any component causes the system to fail. If the individual components of a system are connected in parallel, the failures of all components cause the system to fail.},
	language = {en},
	urldate = {2022-04-20},
	booktitle = {Assessment of {Power} {System} {Reliability}: {Methods} and {Applications}},
	publisher = {Springer},
	author = {Čepin, Marko},
	editor = {Čepin, Marko},
	year = {2011},
	doi = {10.1007/978-0-85729-688-7_9},
	keywords = {Component Parallel, Redundant Pumps, Reliability Block Diagram, Smaller Entities, Steps Hand},
	pages = {119--123},
}

@article{bryant_graph-based_1986,
	title = {Graph-{Based} {Algorithms} for {Boolean} {Function} {Manipulation}},
	volume = {C-35},
	issn = {0018-9340},
	url = {http://ieeexplore.ieee.org/document/1676819/},
	doi = {10.1109/TC.1986.1676819},
	abstract = {In this paper we present a new data structure for representing Boolean functions and an associated set of manipulation algorithms. Functions are represented by directed, acyclic graphs in a manner similar to the representations introduced by Lee [1] and Akers [2], but with further restrictions on the ordering of decision variables in the graph. Although a function requires, in the worst case, a graph of size exponential in the number of arguments, many of the functions encountered in typical applications have a more reasonable representation. Our algorithms have time complexity proportional to the sizes of the graphs being operated on, and hence are quite efficient as long as the graphs do not grow too large. We present experimental results from applying these algorithms to problems in logic design verification that demonstrate the practicality of our approach.},
	language = {en},
	number = {8},
	urldate = {2022-04-20},
	journal = {IEEE Transactions on Computers},
	author = {{Bryant}},
	month = aug,
	year = {1986},
	pages = {677--691},
}

@inproceedings{schmitt_quantifying_2009,
	address = {Austin, TX, USA},
	title = {Quantifying supply chain disruption risk using {Monte} {Carlo} and discrete-event simulation},
	isbn = {978-1-4244-5770-0},
	url = {http://ieeexplore.ieee.org/document/5429561/},
	doi = {10.1109/WSC.2009.5429561},
	abstract = {We present a model constructed for a large consumer products company to assess their vulnerability to disruption risk and quantify its impact on customer service. Risk proﬁles for the locations and connections in the supply chain are developed using Monte Carlo simulation, and the ﬂow of material and network interactions are modeled using discrete-event simulation. Capturing both the risk proﬁles and material ﬂow with simulation allows for a clear view of the impact of disruptions on the system. We also model various strategies for coping with the risk in the system in order to maintain product availability to the customer. We discuss the dynamic nature of risk in the network and the importance of proactive planning to mitigate and recover from disruptions.},
	language = {en},
	urldate = {2022-04-20},
	booktitle = {Proceedings of the 2009 {Winter} {Simulation} {Conference} ({WSC})},
	publisher = {IEEE},
	author = {Schmitt, Amanda J. and Singh, Mahender},
	month = dec,
	year = {2009},
	pages = {1237--1248},
}

@article{simchi-levi_identifying_2015,
	title = {Identifying {Risks} and {Mitigating} {Disruptions} in the {Automotive} {Supply} {Chain}},
	volume = {45},
	issn = {0092-2102, 1526-551X},
	url = {http://pubsonline.informs.org/doi/10.1287/inte.2015.0804},
	doi = {10.1287/inte.2015.0804},
	language = {en},
	number = {5},
	urldate = {2022-04-20},
	journal = {Interfaces},
	author = {Simchi-Levi, David and Schmidt, William and Wei, Yehua and Zhang, Peter Yun and Combs, Keith and Ge, Yao and Gusikhin, Oleg and Sanders, Michael and Zhang, Don},
	month = oct,
	year = {2015},
	pages = {375--390},
}

@article{simchi-levi_superstorms_2014,
	title = {From {Superstorms} to {Factory} {Fires}: {Managing} {Unpredictable} {Supply}-{Chain} {Disruptions}},
	issn = {0017-8012},
	shorttitle = {From {Superstorms} to {Factory} {Fires}},
	url = {https://hbr.org/2014/01/from-superstorms-to-factory-fires-managing-unpredictable-supply-chain-disruptions},
	abstract = {Traditional methods for managing supply chain risk rely on knowing the likelihood of occurrence and the magnitude of impact for every potential event that could materially disrupt a firm’s operations. For common supply-chain disruptions—poor supplier performance, forecast errors, transportation breakdowns, and so on—those methods work very well, using historical data to quantify the level of […]},
	urldate = {2022-04-20},
	journal = {Harvard Business Review},
	author = {Simchi-Levi, David and Schmidt, William and Wei, Yehua},
	month = jan,
	year = {2014},
	note = {Section: Risk management},
	keywords = {Decision making and problem solving, Operations strategy, Risk management, Supply chain management},
}

@article{pavlov_hybrid_2018,
	title = {Hybrid fuzzy-probabilistic approach to supply chain resilience assessment},
	volume = {65},
	issn = {1558-0040},
	doi = {10.1109/TEM.2017.2773574},
	abstract = {In this paper, the existing models of supply chain resilience assessment are extended by incorporating ripple effect and structure reconfiguration. Ripple effect mitigation control is vital for supply chain risk management from positions of structural resilience and recoverability. The research approach is based on a hybrid fuzzy-probabilistic approach. The genome method is applied with the objective of including the structural properties of supply chain design into resilience assessment. A supply chain design resilience index is developed, and its computation and application are demonstrated. The results suggest a method of comparing different supply chain designs regarding the resilience both to disruption propagation and with recovery consideration. It also allows the identification of groups of critical suppliers whose failure interrupts supply chain operation.},
	number = {2},
	journal = {IEEE Transactions on Engineering Management},
	author = {Pavlov, Alexander and Ivanov, Dmitry and Dolgui, Alexandre and Sokolov, Boris},
	month = may,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Engineering Management},
	keywords = {Bioinformatics, Flexibility and time-based management, Genomics, Indexes, Reliability, Resilience, Risk management, Supply chains, fuzzy and grey systems, manufacturing supply chain (SC), network theory, supply chain integration, supply chain resilience},
	pages = {303--315},
}

@article{klibi_scenario-based_2012,
	title = {Scenario-based {Supply} {Chain} {Network} risk modeling},
	volume = {223},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221712004821},
	doi = {10.1016/j.ejor.2012.06.027},
	abstract = {This paper provides a risk modeling approach to facilitate the evaluation and the design of Supply Chain Networks (SCNs) operating under uncertainty. The usefulness of the approach is demonstrated with two realistic case studies. Three event types are deﬁned to describe plausible future SCN environments: random, hazardous and deeply uncertain events. A three-phase hazard modeling approach is also proposed. It involves a characterization of SCN hazards in terms of multihazards, vulnerability sources and exposure levels; the estimation of incident arrival, intensity and duration processes; and the assessment of SCN hit consequences in terms of damage and time to recovery. Based on these descriptive models, a Monte Carlo approach is then proposed to generate plausible future scenarios. The two cases studied illustrate the key aspects of the approach, and how it can be used to obtain resilient SCNs under disruptions.},
	language = {en},
	number = {3},
	urldate = {2022-04-20},
	journal = {European Journal of Operational Research},
	author = {Klibi, Walid and Martel, Alain},
	month = dec,
	year = {2012},
	pages = {644--658},
}

@article{yossi_sheffi_supply_2005,
	title = {A {Supply} {Chain} {View} of the {Resilient} {Enterprise}},
	volume = {47},
	copyright = {Copyright Massachusetts Institute of Technology, 2005. All rights reserved.},
	issn = {15329194},
	url = {https://www.proquest.com/docview/224969684/abstract/A7031FB6295A4A7FPQ/1},
	abstract = {Many companies leave risk management and business continuity to security professionals, business continuity planners or insurance professionals. However, the authors argue, building a resilient enterprise should be a strategic initiative that changes the way a company operates and increases its competitiveness. Reducing vulnerability means both reducing the likelihood of a disruption and increasing resilience. Resilience, in turn, can be achieved by either creating redundancy or increasing flexibility. Redundancy is the familiar concept of keeping some resources in reserve to be used in case of a disruption. The most common forms of redundancy are safety stock, the deliberate use of multiple suppliers even when the secondary suppliers have higher costs, and deliberately low capacity utilization rates. Although necessary to some degree, redundancy represents pure cost with no return except in the eventuality of disruption. The authors contend that significantly more leverage, not to mention operational advantages, can be achieved by making supply chains flexible. Flexibility requires building in organic capabilities that can sense threats and respond to them quickly.},
	language = {English},
	number = {1},
	urldate = {2022-04-20},
	journal = {MIT Sloan Management Review},
	author = {Yossi Sheffi, James B. Rice Jr},
	year = {2005},
	note = {Num Pages: 41-48
Place: Cambridge, United States
Publisher: Massachusetts Institute of Technology, Cambridge, MA},
	keywords = {Business And Economics--Management, Competitive advantage, Earthquakes, Flexibility, Insurance industry, Logistics, Manufacturing, Probability, Risk assessment, September 11 terrorist attacks-2001, Strategic planning, Strikes, Suppliers, Supply chains, Terrorism},
	pages = {41--48},
}

@book{barbosa-povoa_pharmaceutical_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Logistics}},
	title = {Pharmaceutical {Supply} {Chains} - {Medicines} {Shortages}},
	isbn = {978-3-030-15397-7 978-3-030-15398-4},
	url = {http://link.springer.com/10.1007/978-3-030-15398-4},
	language = {en},
	urldate = {2022-04-19},
	publisher = {Springer International Publishing},
	editor = {Barbosa-Povoa, Ana Paula and Jenzer, Helena and de Miranda, João Luís},
	year = {2019},
	doi = {10.1007/978-3-030-15398-4},
}

@article{delaney_risk-informed_2005,
	title = {Risk-informed design guidance for future reactor systems},
	volume = {235},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549305000488},
	doi = {10.1016/j.nucengdes.2005.01.004},
	abstract = {Future reactor designs face an uncertain regulatory environment. It is anticipated that there will be some level of probabilistic insights in the regulations and supporting regulatory documents for Generation-IV nuclear reactors. Central to current regulations are design basis accidents (DBAs) and the general design criteria (GDC), which were established before probabilistic risk assessments (PRAs) were developed. These regulations implement a structuralist approach to safety through traditional defense in depth and large safety margins. In a rationalist approach to safety, accident frequencies are quantified and protective measures are introduced to make these frequencies acceptably low. Both approaches have advantages and disadvantages and future reactor design and licensing processes will have to implement a hybrid approach. This paper presents an iterative four-step risk-informed methodology to guide the design of future-reactor systems using a gas-cooled fast reactor emergency core cooling system as an example. This methodology helps designers to analyze alternative designs under potential risk-informed regulations and to anticipate design justifications the regulator may require during the licensing process. The analysis demonstrated the importance of common-cause failures and the need for guidance on how to change the quantitative impact of these potential failures on the frequency of accident sequences as the design changes. Deliberation is an important part of the four-step methodology because it supplements the quantitative results by allowing the inclusion in the design choice of elements such as best design practices and ease of online maintenance, which usually cannot be quantified. The case study showed that, in some instances, the structuralist and the rationalist approaches were inconsistent. In particular, GDC 35 treats the double-ended break of the largest pipe in the reactor coolant system with concurrent loss of offsite power and a single failure in the most critical place as the DBA for the emergency core cooling system. Seventeen out of the 45 variations that we considered violated this DBA, but passed the probabilistic screening criteria. Using PRA techniques, we found that the mean frequency of this accident was very low, thus indicating that deterministic criteria such as GDC 35 must be reassessed in the light of risk insights.},
	language = {en},
	number = {14},
	urldate = {2022-04-10},
	journal = {Nuclear Engineering and Design},
	author = {Delaney, Michael J. and Apostolakis, George E. and Driscoll, Michael J.},
	month = jun,
	year = {2005},
	pages = {1537--1556},
}

@misc{rauzy_open-psa_2011,
	title = {An {Open}-{PSA} {Fault} {Tree} {Engine} ({XFTA}) {Manual} {Version} 1.0},
	author = {Rauzy, Anthony},
	year = {2011},
}

@book{internationale_atomenergie-organisation_fukushima_2015,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@inproceedings{tillman_system_2020,
	title = {A {System} {Reliability} {Approach} for {Assessing} the {Vulnerability} of {United} {States} {Pharmaceutical} {Supply} {Chains}},
	isbn = {9789811485930},
	url = {http://rpsonline.com.sg/proceedings/9789811485930/html/4832.xml},
	doi = {10.3850/978-981-14-8593-0_4832-cd},
	abstract = {We build a system reliability model to evaluate vulnerabilities in United States (US) pharmaceutical supply chains using unique, internal US Food and Drug Administration (USFDA) data on approved manufacturing facilities at different stages of the drug production process. We describe the structure of each supply chain using a reliability block diagram and estimate the probability of an operation disruption for each manufacturing facility using machine learning algorithms. The purpose of this paper is to demonstrate the feasibility of this approach through a case study that highlights the potential for interdependencies across companies and manufacturing roles. This exploratory model could be used by policymakers both to assess latent vulnerabilities in US pharmaceutical supply chains, as well as to understand the impact of an impending shock – such as a hurricane – on US pharmaceutical manufacturing.},
	language = {en},
	urldate = {2022-03-21},
	booktitle = {Proceedings of the 30th {European} {Safety} and {Reliability} {Conference} and 15th {Probabilistic} {Safety} {Assessment} and {Management} {Conference}},
	publisher = {Research Publishing Services},
	author = {Tillman, Zachary and Rosenberg, Matthew and Delhy, Roberto and Ruiz-Barnes, Cesar and Kazemi, Reza},
	year = {2020},
	pages = {1027--1033},
}

@inproceedings{hasselbring_benchmarking_2021,
	address = {Trondheim Norway},
	title = {Benchmarking as {Empirical} {Standard} in {Software} {Engineering} {Research}},
	isbn = {978-1-4503-9053-8},
	url = {https://dl.acm.org/doi/10.1145/3463274.3463361},
	doi = {10.1145/3463274.3463361},
	abstract = {In empirical software engineering, benchmarks can be used for comparing different methods, techniques and tools. However, the recent ACM SIGSOFT Empirical Standards for Software Engineering Research do not include an explicit checklist for benchmarking. In this paper, we discuss benchmarks for software performance and scalability evaluation as example research areas in software engineering, relate benchmarks to some other empirical research methods, and discuss the requirements on benchmarks that may constitute the basis for a checklist of a benchmarking standard for empirical software engineering research.},
	language = {en},
	urldate = {2022-03-17},
	booktitle = {Evaluation and {Assessment} in {Software} {Engineering}},
	publisher = {ACM},
	author = {Hasselbring, Wilhelm},
	month = jun,
	year = {2021},
	pages = {365--372},
}

@inproceedings{wang_verification_2013,
	address = {Chengdu, China},
	title = {Verification of {RiskA} calculation engine based on {Open}-{PSA} platform},
	isbn = {978-1-4799-1016-8 978-1-4799-1014-4},
	url = {http://ieeexplore.ieee.org/document/6625529/},
	doi = {10.1109/QR2MSE.2013.6625529},
	abstract = {Probabilistic Safety Assessment (PSA) has been widely used in nuclear safety and reliability field in recent years. PSA is playing a positive role in these fields and the analysis programs are also in rapid development, but the model created by one program cannot be used in another, so the results are difficult to be cross verified. A universal method is develped based on OpenPSA platform to solve such problem and is also used to check RiskA calculation engine. Results proves that RiskA is valid and reliable.},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {2013 {International} {Conference} on {Quality}, {Reliability}, {Risk}, {Maintenance}, and {Safety} {Engineering} ({QR2MSE})},
	publisher = {IEEE},
	author = {Wang, Jin and Hu, Liqin and Chen, Shanqi and Wang, Fang and Wu, Yican and Li, Yanzhou and Jia, Wei},
	month = jul,
	year = {2013},
	pages = {32--35},
}

@article{sherry_nrcs_nodate,
	title = {The {NRC}’s {SPAR} {Models}: {Current} {Status}, {Future} {Development}, and {Modeling} {Issues}},
	abstract = {Probabilistic risk assessments (PRAs) play an increasingly important role in the regulatory framework of the U.S. nuclear power industry. The Nuclear Regulatory Commission (NRC) relies on a set of plant-specific Standardized Plant Analysis Risk (SPAR) models to provide critical riskbased input to the regulatory process. The Significance Determination Process (SDP), Management Directive 8.3 - NRC Incident Investigation Program, Accident Sequence Precursor (ASP) and Mitigating Systems Performance Index (MSPI) programs are among the regulatory initiatives that receive significant input from the SPAR models. Other uses of the SPAR models include: Screening \& Resolution of Generic Safety Issues, License Amendment reviews and Notice of Enforcement Discretion (NOEDs). This paper presents the current status of SPAR model development activities, future development objectives, and issues related to the development, verification and maintenance of the SPAR models.},
	language = {en},
	author = {Sherry, Richard R and Appignani, Peter L and Buell, Robert F},
	pages = {11},
}

@techreport{branham-haar_models_1992,
	title = {Models and {Results} {Database} ({MAR}-{D}), {Version} 4. 0},
	url = {http://www.osti.gov/servlets/purl/5299087/},
	language = {en},
	number = {NUREG/CR-5301, EGG--2627, 5299087},
	urldate = {2022-03-15},
	author = {Branham-Haar, K.A. and Dinneen, R.A. and Russell, K.D. and Skinner, N.L.},
	month = may,
	year = {1992},
	doi = {10.2172/5299087},
	pages = {NUREG/CR--5301, EGG--2627, 5299087},
}

@article{jones_software_1995,
	title = {Software benchmarking},
	volume = {28},
	issn = {00189162},
	url = {http://ieeexplore.ieee.org/document/467614/},
	doi = {10.1109/2.467614},
	language = {en},
	number = {10},
	urldate = {2022-03-15},
	journal = {Computer},
	author = {Jones, C.},
	month = oct,
	year = {1995},
	pages = {102--103},
}

@incollection{rolstadas_benchmarking_1995,
	address = {Boston, MA},
	title = {Benchmarking in {Software} {Development}},
	isbn = {978-1-4757-4595-5 978-0-387-34847-6},
	url = {http://link.springer.com/10.1007/978-0-387-34847-6_20},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {Benchmarking — {Theory} and {Practice}},
	publisher = {Springer US},
	author = {Maneva, Nelly and Daneva, Maya and Petrova, Valia},
	editor = {Rolstadås, Asbjørn},
	year = {1995},
	doi = {10.1007/978-0-387-34847-6_20},
	note = {Series Title: IFIP Advances in Information and Communication Technology},
	pages = {166--175},
}

@article{beyer_reliable_2019,
	title = {Reliable benchmarking: requirements and solutions},
	volume = {21},
	issn = {1433-2779, 1433-2787},
	shorttitle = {Reliable benchmarking},
	url = {https://link.springer.com/10.1007/s10009-017-0469-y},
	doi = {10.1007/s10009-017-0469-y},
	abstract = {Benchmarking is a widely used method in experimental computer science, in particular, for the comparative evaluation of tools and algorithms. As a consequence, a number of questions need to be answered in order to ensure proper benchmarking, resource measurement, and presentation of results, all of which is essential for researchers, tool developers, and users, as well as for tool competitions. We identify a set of requirements that are indispensable for reliable benchmarking and resource measurement of time and memory usage of automatic solvers, veriﬁers, and similar tools, and discuss limitations of existing methods and benchmarking tools. Fulﬁlling these requirements in a benchmarking framework can (on Linux systems) currently only be done by using the cgroup and namespace features of the kernel. We developed BenchExec, a ready-to-use, tool-independent, and open-source implementation of a benchmarking framework that fulﬁlls all presented requirements, making reliable benchmarking and resource measurement easy. Our framework is able to work with a wide range of different tools, has proven its reliability and usefulness in the International Competition on Software Veriﬁcation, and is used by several research groups worldwide to ensure reliable benchmarking. Finally, we present guidelines on how to present measurement results in a scientiﬁcally valid and comprehensible way.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Beyer, Dirk and Löwe, Stefan and Wendler, Philipp},
	month = feb,
	year = {2019},
	pages = {1--29},
}

@techreport{ma_industry-average_2022,
	title = {Industry-{Average} {Performance} for {Components} and {Initiating} {Events} at {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}: 2020 {Update}},
	shorttitle = {Industry-{Average} {Performance} for {Components} and {Initiating} {Events} at {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}},
	url = {https://www.osti.gov/servlets/purl/1847110/},
	language = {en},
	number = {INL/EXT-21-65055-Rev000, 1847110},
	urldate = {2022-03-15},
	author = {Ma, Zhegang and Kvarfordt, Kellie and Wierman, Thomas},
	month = feb,
	year = {2022},
	doi = {10.2172/1847110},
	pages = {INL/EXT--21--65055--Rev000, 1847110},
}

@inproceedings{pandit_evaluating_2021,
	address = {Virtual, Online},
	title = {Evaluating the {Implementation} of {Distributed} {Ledger} {Technology} for the {Licensing} and {Regulation} of {Nuclear} {Power} {Plants}},
	isbn = {978-0-7918-8564-2},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85642/V08BT08A016/1132953},
	doi = {10.1115/IMECE2021-71730},
	abstract = {The approval process from the U.S. Nuclear Regulatory Commission (NRC) for nuclear power plants is sequential. It involves several government bodies such as the Advisory Committee on Reactor Safeguards (ACRS), public meetings, and hearings. If the submissions made to the NRC do not contain enough information to meet the regulation requirements, the NRC issues a Request for Additional Information (RAI). Thus, the licensee has to go through a paperwork-intensive process that involves multiple regulatory agencies for the various licensing requirements. Moreover, sending applications to the NRC is limited to using an electronic submission generation tool called the Packing Slip Wizard (PSW).},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {Volume {8B}: {Energy}},
	publisher = {American Society of Mechanical Engineers},
	author = {Pandit, Priyanka and Tezbasaran, Alp and Earthperson, Arjun and Diaconeasa, Mihai A.},
	month = nov,
	year = {2021},
	pages = {V08BT08A016},
}

@misc{noauthor_what_nodate,
	title = {What {Went} {Wrong} on the {Westinghouse} {Nuclear} {Projects}},
	url = {https://www.enr.com/articles/41869-what-went-wrong-on-the-westinghouse-nuclear-projects},
	abstract = {Why is no one discussing the real reason these Westinghouse projects are so far over budget and delayed?},
	language = {en},
	urldate = {2022-03-14},
}

@article{chen_uncertainty_2022,
	title = {Uncertainty analysis of {HPR}-1000 {LOCA} with probabilistic and deterministic methods},
	volume = {146},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197022000543},
	doi = {10.1016/j.pnucene.2022.104174},
	abstract = {The HPR-1000 is an advanced Gen III pressurized water reactor (PWR) in China. For the purpose of carrying out uncertainty analysis of the LOCA scenario, two different types of best estimate plus uncertainty (BEPU) method were utilized, namely the DRM of the deterministic method and a typical input-driven probabilistic method. The DRM is carried out by introducing a penalization mode to envelop the input uncertainties, while the probabilistic input-driven method is implemented by performing the uncertainty propagation after the uncertainty sources are identified and quantified. The peak cladding temperature (PCT) was selected to be the figure of merit, and the 95\% confidence limit as well as the tolerance limit of the PCT in the LOCA scenario were obtained. Results show that even though there are some phenomenal differences exist, the uncertainty limit obtained through the two methods are similar and both fall below the acceptance criterion.},
	language = {en},
	urldate = {2022-03-13},
	journal = {Progress in Nuclear Energy},
	author = {Chen, Wei and Xiong, Qingwen and Wu, Dan and Ding, Shuhua and Qian, Libo and Wu, Qing},
	month = apr,
	year = {2022},
	pages = {104174},
}

@article{prescott_fire_nodate,
	title = {Fire {Risk} {Investigation} in {3D} ({FRI3D}) {Software} and {Process} for {Integrated} {Fire} {Modeling}},
	language = {en},
	author = {Prescott, Steven and Christian, Robby and Sampath, Ramprasad and Biersdorf, John},
	pages = {46},
}

@techreport{kinsey_united_2018,
	title = {United {States} {Nuclear} {Manufacturing} {Infrastructure} {Assessment}},
	url = {http://www.osti.gov/servlets/purl/1494317/},
	language = {en},
	number = {DOE-MPRA--NE000638, 1494317},
	urldate = {2022-03-10},
	author = {Kinsey, Stephen and Jessup, William and {MPR Associates, Inc.}},
	month = dec,
	year = {2018},
	doi = {10.2172/1494317},
	pages = {DOE--MPRA--NE000638, 1494317},
}

@techreport{kinsey_united_2018-1,
	title = {United {States} {Nuclear} {Manufacturing} {Infrastructure} {Assessment}},
	url = {http://www.osti.gov/servlets/purl/1494317/},
	language = {en},
	number = {DOE-MPRA--NE000638, 1494317},
	urldate = {2022-02-22},
	author = {Kinsey, Stephen and Jessup, William and {MPR Associates, Inc.}},
	month = dec,
	year = {2018},
	doi = {10.2172/1494317},
	pages = {DOE--MPRA--NE000638, 1494317},
}

@misc{noauthor_photo_nodate,
	title = {Photo - {Google} {Photos}},
	url = {https://photos.google.com/archive/photo/AF1QipNS7Kic976Nhjy77ZCxAGoxpMMkM4fM4I_T55lw},
	urldate = {2022-03-09},
}

@article{hayns_evolution_1999,
	title = {The {Evolution} of {Probabilistic} {Risk} {Assessment} in the {Nuclear} {Industry}},
	volume = {77},
	issn = {09575820},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957582099707913},
	doi = {10.1205/095758299529947},
	language = {en},
	number = {3},
	urldate = {2022-03-09},
	journal = {Process Safety and Environmental Protection},
	author = {Hayns, M.R.},
	month = may,
	year = {1999},
	pages = {117--142},
}

@article{duy_representation_nodate,
	title = {Representation of parameter uncertainty with evidence theory in {Probabilistic} {Risk} {Assessment}},
	abstract = {In the current approach of nuclear power plant Probabilistic Risk Assessment, parameter uncertainty due to a lack of knowledge is generally represented by probability distribution (e.g. log-normal) whose mean or median is considered as point value estimated from operating experience feedback. In this paper, such an approach is shown to lead to potential erroneous and ambiguous results in decision making. To overcome this problem, the Dempster-Shafer Theory of Evidence is considered. In this paper, a so-called unified Dempster- Shafer representation which allows to deal with current issues is proposed to characterize the parameter uncertainty in an appropriate manner. The use of this representation is illustrated through a practical example of Probabilistic Risk Assessment.},
	language = {en},
	author = {Duy, Tu Duong Le and Vasseur, Dominique and Dieulle, Laurence and Bérenguer, Christophe and Couplet, Mathieu},
	pages = {7},
}

@article{garrick_probabilistic_2002,
	title = {Probabilistic risk assessment practices in the {USA} for nuclear power plants},
	volume = {40},
	issn = {09257535},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753501000364},
	doi = {10.1016/S0925-7535(01)00036-4},
	abstract = {It is clear that probabilistic risk assessment or probabilistic safety assessment is embedded in the safety culture of the nuclear power industry, worldwide. Risk assessment applications are in transition in the sense that the regulatory apparatus is not yet in place, at least in the United States of America (USA), to fully support a risk-based licensing process. There is progress on the regulatory front, but it is tedious and not without its frustrations. Currently, the strategy in the USA is a ‘‘risk-informed’’ approach that tends to be ‘‘business as usual’’, but while you’re at it, ‘‘do a risk assessment’’. The result is added burden (and costs) at a time of increased competition in the power ﬁeld as a result of deregulation. There is hope in that some steps are ﬁnally being taken to modify the regulations to allow risk assessment to be more of a part of the licensing process. For example, the regulations having to do with maintenance, plant changes, and technical speciﬁcations have been modiﬁed to allow insights from risk assessment to be part of the basis for licensing amendments. On the matter of standards there is strong support that is scientiﬁcally based and addresses such issues as health eﬀects and environmental impacts. There appears to be less support for standards on such matters as deﬁnition of terms, methodology, and data requirements. \# 2001 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	number = {1-4},
	urldate = {2022-03-09},
	journal = {Safety Science},
	author = {Garrick, B.John and Christie, Robert F},
	month = feb,
	year = {2002},
	pages = {177--201},
}

@article{le_duy_alternative_2013,
	title = {An alternative comprehensive framework using belief functions for parameter and model uncertainty analysis in nuclear probabilistic risk assessment applications},
	volume = {227},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X12474154},
	doi = {10.1177/1748006X12474154},
	abstract = {In nuclear power plants, probabilistic risk assessment insights contribute to achieve a safe design and operation. In this context, the decision-making process must be robust and uncertainties must be taken into account and controlled. In general, the uncertainties in a nuclear probabilistic risk assessment context can be categorized as either aleatory or epistemic. The epistemic uncertainty, which can be subdivided into parameter and model uncertainties, is recognized to have an important impact on actual results of probabilistic risk assessment. Traditionally, the approach of an epistemic uncertainty analysis in nuclear probabilistic risk assessment often relies on the probabilistic approach in which parameter uncertainty is treated by using an assigned probability distribution, e.g. the log-normal one, and model uncertainty can be taken into account through sensitivity studies. Such an approach has been recognized in several recent researchs to present limitations regarding the impacts of assigning probability distribution in case of rare operating feedback data. In order to overcome such a limitation, in this article we propose a comprehensive approach for uncertainty analysis from the parameter and model uncertainties modeling to the final step of the decision-making process using the Dempster-Shafer theory, which is recognized to be more general than the probabilistic approach. We also show that the traditional probabilistic approach, currently used in probabilistic risk assessment practice, can be totally integrated in this framework. Finally, the proposed framework is illustrated and compared with the traditional approach through a practical example from EDF Nuclear Power Plants probabilistic risk assessment application. Some discussions and conclusions for industrial probabilistic risk assessment contexts will be given.},
	language = {en},
	number = {5},
	urldate = {2022-03-09},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Le Duy, Tu Duong and Dieulle, Laurence and Vasseur, Dominique and Bérenguer, Christophe and Couplet, Mathieu},
	month = oct,
	year = {2013},
	pages = {471--490},
}

@article{carlisle_probabilistic_1997,
	title = {Probabilistic {Risk} {Assessment} in {Nuclear} {Reactors}: {Engineering} {Success}, {Public} {Relations} {Failure}},
	volume = {38},
	issn = {0040165X},
	shorttitle = {Probabilistic {Risk} {Assessment} in {Nuclear} {Reactors}},
	url = {https://www.jstor.org/stable/3106954?origin=crossref},
	doi = {10.2307/3106954},
	language = {en},
	number = {4},
	urldate = {2022-03-09},
	journal = {Technology and Culture},
	author = {Carlisle, Rodney P.},
	month = oct,
	year = {1997},
	pages = {920},
}

@article{shah_dynamic_2021,
	title = {Dynamic {Probabilistic} {Risk} {Assessment} {Based} {Response} {Surface} {Approach} for {FLEX} and {Accident} {Tolerant} {Fuels} for {Medium} {Break} {LOCA} {Spectrum}},
	volume = {14},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/14/9/2490},
	doi = {10.3390/en14092490},
	abstract = {After the Fukushima Daiichi Accident, the safety features such as accident tolerant fuel (ATF) and diverse and ﬂexible coping strategies (FLEX) for existing nuclear ﬂeets are being investigated by the US Department of Energy under the Light Water Reactor Sustainability Program. This research is being conducted to quantify the risk-beneﬁt of these safety features. Dynamic probabilistic risk assessment (DPRA)-based response-surface approach has been presented to quantify the FLEX and ATF beneﬁts by estimating the risk associated with each option. ATFs with multilayered silicon carbide (SiC), iron-chromium-aluminum, and chromium-coated zirconium cladding were considered in this study. While these ATF candidates perform better than the current zirconium cladding (Zr), they may introduce additional failure modes in some operating conditions. The fuel failure analysis modules (FAMs) were developed to investigate ATF performance. The dynamic risk assessments were performed using RAVEN, a DPRA tool, coupled with RELAP5 and FAMs. A cumulative distribution function-based index provided a mean of comparing the beneﬁts of safety enhancements. For medium break loss of coolant accidents, FLEX operational timing window for each fuel type was estimated. Among these ATF candidates, SiC-type ATF was the most beneﬁcial candidate for an increased safety margin than Zr-based fuel and was found to complement FLEX strategies in terms of risk and coping time.},
	language = {en},
	number = {9},
	urldate = {2022-03-09},
	journal = {Energies},
	author = {Shah, Asad Ullah Amin and Christian, Robby and Kim, Junyung and Kim, Jaewhan and Park, Jinkyun and Kang, Hyun Gook},
	month = apr,
	year = {2021},
	pages = {2490},
}

@article{baraldi_uncertainty_2014,
	title = {Uncertainty treatment in expert information systems for maintenance policy assessment},
	volume = {22},
	issn = {15684946},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494614002518},
	doi = {10.1016/j.asoc.2014.05.024},
	abstract = {This paper proposes a framework based on the Dempster-Shafer Theory of Evidence (DSTE), Possibility Theory (PT) and Fuzzy Random Variables (FRVs) to represent and propagate the epistemic uncertainty in the parameters of the component degradation-failure models used to evaluate the performance of maintenance policies. An example of application is given with reference to a check valve of a turbo-pump lubricating system in a Nuclear Power Plant, which is affected by fatigue and overtakes condition-based maintenance interventions.},
	language = {en},
	urldate = {2022-03-09},
	journal = {Applied Soft Computing},
	author = {Baraldi, P. and Compare, M. and Zio, E.},
	month = sep,
	year = {2014},
	pages = {297--310},
}

@inproceedings{grabaskas_methodology_2016,
	address = {Charlotte, North Carolina, USA},
	title = {A {Methodology} for the {Development} of a {Reliability} {Database} for an {Advanced} {Reactor} {Probabilistic} {Risk} {Assessment}},
	isbn = {978-0-7918-5002-2},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE24/50022/Charlotte,%20North%20Carolina,%20USA/252086},
	doi = {10.1115/ICONE24-60760},
	abstract = {GE Hitachi Nuclear Energy (GEH) and Argonne National Laboratory are currently engaged in a joint effort to modernize and develop probabilistic risk assessment (PRA) techniques for advanced non-light water reactors. At a high level the primary outcome of this project will be the development of nextgeneration PRA methodologies that will enable risk-informed prioritization of safety- and reliability-focused research and development, while also identifying gaps that may be resolved through additional research. A subset of this effort is the development of a reliability database (RDB) methodology to determine applicable reliability data for inclusion in the quantification of the PRA. The RDB method developed during this project seeks to satisfy the requirements of the Data Analysis element of the ASME/ANS Non-LWR PRA standard. The RDB methodology utilizes a relevancy test to examine reliability data and determine whether it is appropriate to include as part of the reliability database for the PRA. The relevancy test compares three component properties to establish the level of similarity to components examined as part of the PRA. These properties include the component function, the component failure modes, and the environment/boundary conditions of the component. The relevancy test is used to gauge the quality of data found in a variety of sources, such as advanced reactor-specific databases, non-advanced reactor nuclear databases, and non-nuclear databases. The RDB also establishes the integration of expert judgment or separate reliability analysis with past reliability data. This paper provides details on the RDB methodology, and includes an example application of the RDB methodology for determining the reliability of the intermediate heat exchanger of a sodium fast reactor. The example explores a variety of reliability data sources, and assesses their applicability for the PRA of interest through the use of the relevancy test.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Volume 2: {Smart} {Grids}, {Grid} {Stability}, and {Offsite} and {Emergency} {Power}; {Advanced} and {Next} {Generation} {Reactors}, {Fusion} {Technology}; {Safety}, {Security}, and {Cyber} {Security}; {Codes}, {Standards}, {Conformity} {Assessment}, {Licensing}, and {Regulatory} {Issues}},
	publisher = {American Society of Mechanical Engineers},
	author = {Grabaskas, Dave and Brunett, Acacia J. and Bucknor, Matthew},
	month = jun,
	year = {2016},
	pages = {V002T06A031},
}

@book{kamae_earthquakes_2016,
	address = {Tokyo},
	title = {Earthquakes, {Tsunamis} and {Nuclear} {Risks}},
	isbn = {978-4-431-55820-0 978-4-431-55822-4},
	url = {http://link.springer.com/10.1007/978-4-431-55822-4},
	language = {en},
	urldate = {2022-03-09},
	publisher = {Springer Japan},
	editor = {Kamae, Katsuhiro},
	year = {2016},
	doi = {10.1007/978-4-431-55822-4},
}

@inproceedings{mohaghegh_physics-based_2011,
	address = {Denver, Colorado, USA},
	title = {Physics-{Based} {Common} {Cause} {Failure} {Modeling} in {Probabilistic} {Risk} {Analysis}: {A} {Mechanistic} {Perspective}},
	isbn = {978-0-7918-4460-1},
	shorttitle = {Physics-{Based} {Common} {Cause} {Failure} {Modeling} in {Probabilistic} {Risk} {Analysis}},
	url = {https://asmedigitalcollection.asme.org/POWER/proceedings/POWER2011/44601/201/357634},
	doi = {10.1115/POWER2011-55324},
	abstract = {The modeling of dependent failures, specifically Common Cause Failures (CCFs), is one of the most important topics in Probabilistic Risk Analysis (PRA). Currently, CCFs are treated using parametric methods, which are based on historical failure events. Instead of utilizing these existing data-driven approaches, this paper proposes using physics-based CCF modeling which refers to the incorporation of underlying physical failure mechanisms into risk models so that the root causes of dependencies can be “explicitly” included. This requires building a theoretical foundation for the integration of Probabilistic Physics-Of-Failure (PPOF) models into PRA in a way that the interactions of failure mechanisms and, ultimately, the dependencies between the multiple component failures are depicted. To achieve this goal, this paper highlights the following methodological steps (1) modeling the individual failure mechanisms (e.g. fatigue and wear) of two dependent components, (2) applying a mechanistic approach to deterministically model the interactions of their failure mechanisms, (3) utilizing probabilistic sciences (e.g. uncertainty modeling, Bayesian analysis) in order to make the model of interactions probabilistic, and (4) developing appropriate modeling techniques to link the physics-based CCF models to the system-level PRA. The proposed approach is beneficial for (a) reducing CCF occurrence in currently operating plants and (b) modeling CCFs for plants in the design stage.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {{ASME} 2011 {Power} {Conference}, {Volume} 2},
	publisher = {ASMEDC},
	author = {Mohaghegh, Zahra and Modarres, Mohammad and Christou, Aris},
	month = jan,
	year = {2011},
	pages = {201--210},
}

@article{leger_methodological_2009,
	title = {Methodological developments for probabilistic risk analyses of socio-technical systems},
	volume = {223},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR230},
	doi = {10.1243/1748006XJRR230},
	abstract = {Nowadays, the risk analysis of critical systems cannot be focused only on a technical dimension. Indeed last well known accidents in nuclear or aerospace areas underlined initiating causes also related to technical and organisational viewpoints. It led to the development of methods for risk assessment considering three main aspects on the system resources: the technical process, the operator constraining the process, and the organisation constraining human actions on the process. However, only few scientific works tried to federate these methods in a unique and global approach. Thus this paper is focusing on a methodology aiming to achieve the integration of the different methods in order to probabilistically assess the risks. The integration is based on (a) system knowledge structuring and (b) its unified modelling by means of Bayesian Networks supporting also quantification and simulation phases. The methodology is applied to an industrial case to show its feasibility and to conclude on the model relevance for system risk analysis. The results of the methodology can be used by decision makers to prioritise their actions in face with potential or real risks.},
	language = {en},
	number = {4},
	urldate = {2022-03-09},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Léger, A and Weber, P and Levrat, E and Duval, C and Farret, R and Iung, B},
	month = dec,
	year = {2009},
	pages = {313--332},
}

@book{coolen_isipta_2011,
	address = {Innsbruck},
	title = {{ISIPTA} '11: proceedings of the {Seventh} {International} {Symposium} on {Imprecise} {Probability}, {Theories} and {Applications}: {July} 25-28, 2011, {Innsbruck}, {Austria}},
	isbn = {978-3-902652-40-9},
	shorttitle = {{ISIPTA} '11},
	language = {en},
	publisher = {SIPTA, Society for Imprecise Probability, Theories and Applications : Studia Universitätsverlag},
	editor = {Coolen, Franciscus Petrus Antonius and Cooman, Gert de and Fetz, Thomas and Oberguggenberger, Michael},
	year = {2011},
	note = {Meeting Name: International Symposium on Imprecise Probabilities and Their Applications},
	keywords = {Congresses, Probabilities},
}

@book{pham_handbook_2003,
	address = {London ; New York},
	title = {Handbook of reliability engineering},
	isbn = {978-1-85233-453-6},
	language = {en},
	publisher = {Springer},
	editor = {Pham, Hoang},
	year = {2003},
	keywords = {Handbooks, manuals, etc, Reliability (Engineering)},
}

@book{molak_fundamentals_1997,
	address = {Boca Raton},
	title = {Fundamentals of risk analysis and risk management},
	isbn = {978-1-56670-130-3},
	language = {en},
	publisher = {Lewis Publishers},
	editor = {Molak, Vlasta},
	year = {1997},
	keywords = {Risk assessment, Technology},
}

@article{labeau_dynamic_2000,
	title = {Dynamic reliability: towards an integrated platform for probabilistic risk assessment},
	volume = {68},
	issn = {09518320},
	shorttitle = {Dynamic reliability},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095183200000017X},
	doi = {10.1016/S0951-8320(00)00017-X},
	abstract = {Dynamic reliability methods are powerful mathematical frameworks capable of handling interactions among components and process variables explicitly. In principle, they constitute a more realistic modeling of systems for the purposes of reliability, risk and safety analysis. Although there is a growing recognition in the risk community of the potentially greater correctness of these methods, no serious effort has been undertaken to utilize them in industrial applications.},
	language = {en},
	number = {3},
	urldate = {2022-03-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Labeau, P.E. and Smidts, C. and Swaminathan, S.},
	month = jun,
	year = {2000},
	pages = {219--254},
}

@article{kelly_bayesian_2009,
	title = {Bayesian inference in probabilistic risk assessment—{The} current state of the art},
	volume = {94},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832008001919},
	doi = {10.1016/j.ress.2008.07.002},
	abstract = {Markov chain Monte Carlo approaches to sampling directly from the joint posterior distribution of aleatory model parameters have led to tremendous advances in Bayesian inference capability in a wide variety of fields, including probabilistic risk analysis. The advent of freely available software coupled with inexpensive computing power has catalyzed this advance. This paper examines where the risk assessment community is with respect to implementing modern computational-based Bayesian approaches to inference. Through a series of examples in different topical areas, it introduces salient concepts and illustrates the practical application of Bayesian inference via Markov chain Monte Carlo sampling to a variety of important problems.},
	language = {en},
	number = {2},
	urldate = {2022-03-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Kelly, Dana L. and Smith, Curtis L.},
	month = feb,
	year = {2009},
	pages = {628--643},
}

@article{nejad_automatic_nodate,
	title = {Automatic {Generation} of {Generalized} {Event} {Sequence} {Diagrams} for {Guiding} {Simulation} {Based} {Dynamic} {Probabilistic} {Risk} {Assessment} of {Complex} {Systems}},
	language = {en},
	author = {Nejad, Hamed},
	pages = {158},
}

@article{hu_guided_nodate,
	title = {A {GUIDED} {SIMULATION} {METHODOLOGY} {FOR} {DYNAMIC} {PROBABILISTIC} {RISK} {ASSESSMENT} {OF} {COMPLEX} {SYSTEMS}},
	language = {en},
	author = {Hu, Yunwei},
	pages = {239},
}

@article{george-williams_probabilistic_2018,
	title = {Probabilistic {Risk} {Assessment} of {Station} {Blackouts} in {Nuclear} {Power} {Plants}},
	volume = {67},
	issn = {0018-9529, 1558-1721},
	url = {https://ieeexplore.ieee.org/document/8353480/},
	doi = {10.1109/TR.2018.2824620},
	language = {en},
	number = {2},
	urldate = {2022-03-09},
	journal = {IEEE Transactions on Reliability},
	author = {George-Williams, Hindolo and Lee, Min and Patelli, Edoardo},
	month = jun,
	year = {2018},
	pages = {494--512},
}

@article{miller_integrating_nodate,
	title = {{INTEGRATING} {GEOGRAPHIC} {INFORMATION} {SYSTEMS} {WITH} {THE} {LEVEL} 3 {PROBABILISTIC} {RISK} {ASSESSMENT} {OF} {NUCLEAR} {POWER} {PLANTS} {TO} {ADVANCE} {MODELING} {OF} {SOCIO}-{TECHNICAL} {INFRASTRUCTURE} {IN} {EMERGENCY} {RESPONSE} {APPLICATIONS}},
	language = {en},
	author = {Miller, Ian M},
	pages = {200},
}

@article{van_coile_need_2019,
	title = {The {Need} for {Hierarchies} of {Acceptance} {Criteria} for {Probabilistic} {Risk} {Assessments} in {Fire} {Engineering}},
	volume = {55},
	issn = {0015-2684, 1572-8099},
	url = {http://link.springer.com/10.1007/s10694-018-0746-7},
	doi = {10.1007/s10694-018-0746-7},
	abstract = {A Probabilistic Risk Assessment (PRA) is commonly accepted as a tool for Performance Based Design in fire safety engineering, but the position of PRA in the design process, the relationship between different acceptance concepts (absolute, comparative, ALARP), and the responsibilities of the designer remain unclear. Aiming to clarify these aspects, the safety foundation of fire safety solutions is investigated, indicating that PRA is necessary for demonstrating adequate safety when no appeal can be made to the collective experience of the profession. It is suggested that PRA is not a methodology for ‘future fire safety engineering’, but rather a necessary methodology to provide an objective safety foundation for uncommon fire safety designs. Acknowledging that what constitutes ‘acceptable safety’ is subjective and may change over time, an objective proxy of ‘adequate safety’ is defined and proposed as a benchmark against which to assess the adequacy of fire safety designs. In order to clarify the PRA process, a hierarchy of different acceptance concepts is presented. Finally, it is shown how, depending on the applied acceptance concepts, the designer takes responsibility for different implicit assumptions regarding the safety performance of the final design.},
	language = {en},
	number = {4},
	urldate = {2022-03-09},
	journal = {Fire Technology},
	author = {Van Coile, Ruben and Hopkin, Danny and Lange, David and Jomaas, Grunde and Bisby, Luke},
	month = jul,
	year = {2019},
	pages = {1111--1146},
}

@article{bui_spatiotemporal_2020,
	title = {Spatiotemporal {Integration} of an {Agent}-{Based} {First} {Responder} {Performance} {Model} {With} a {Fire} {Hazard} {Propagation} {Model} for {Probabilistic} {Risk} {Assessment} of {Nuclear} {Power} {Plants}},
	volume = {6},
	issn = {2332-9017, 2332-9025},
	url = {https://asmedigitalcollection.asme.org/risk/article/doi/10.1115/1.4044793/975501/Spatiotemporal-Integration-of-an-AgentBased-First},
	doi = {10.1115/1.4044793},
	abstract = {To advance Emergency Response (ER) modeling in Probabilistic Risk Assessment (PRA), this research offers a new methodology that explicitly incorporates the spatiotemporal evolution of underlying physical and social phenomena and their bidirectional interactions. While this methodology is applicable for various ER scenarios on different spatial and temporal scales, this paper focuses on advancing ER modeling for a Nuclear Power Plant (NPP) internal fire. This paper provides a thorough review and categorization of existing studies on internal fire ER modeling for NPPs and highlights the contributions of this research. d This paper then develops a new methodology for fire ER modeling by integrating an agent-based model of e First Responder Performance (FRP) with a Fire Hazard Propagation (FHP) model through a shared it Geographic Information System (GIS)-based spatial simulation environment. This research is the first to d explicitly incorporate space (in addition to time) into the FRP modeling within ER modeling of NPP Fire e PRA. In addition, this research develops a GIS-based interface between FRP and FHP that has the capability y of transferring both spatial and temporal information in a bidirectional way. Although this paper is focused p on a fire ER scenario, the new methodology developed in this paper can contribute to modeling external o control room human performance in other contexts, such as Diverse and Flexible Coping Strategy (FLEX), C maintenance, and offsite first responders in Level 3 PRA.},
	language = {en},
	number = {1},
	urldate = {2022-03-09},
	journal = {ASCE-ASME J Risk and Uncert in Engrg Sys Part B Mech Engrg},
	author = {Bui, Ha and Sakurahara, Tatsuya and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	month = mar,
	year = {2020},
	pages = {011011},
}

@article{sakurahara_modeling_2017,
	title = {{MODELING} {THE} {INTERFACE} {OF} {MANUAL} {FIRE} {PROTECTION} {ACTIONS} {WITH} {FIRE} {PROGRESSION} {IN} {FIRE} {PROBABILISTIC} {RISK} {ASSESSMENT} {OF} {NUCLEAR} {POWER} {PLANTS}},
	language = {en},
	author = {Sakurahara, Tatsuya and Mohaghegh, Zahra and Reihani, Seyed and Kee, Ernie},
	year = {2017},
	pages = {10},
}

@article{sakurahara_methodological_2018,
	title = {Methodological and {Practical} {Comparison} of {Integrated} {Probabilistic} {Risk} {Assessment} ({I}-{PRA}) with the {Existing} {Fire} {PRA} of {Nuclear} {Power} {Plants}},
	volume = {204},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2018.1486159},
	doi = {10.1080/00295450.2018.1486159},
	language = {en},
	number = {3},
	urldate = {2022-03-09},
	journal = {Nuclear Technology},
	author = {Sakurahara, Tatsuya and Mohaghegh, Zahra and Reihani, Seyed and Kee, Ernie},
	month = dec,
	year = {2018},
	pages = {354--377},
}

@article{sakurahara_human_2020,
	title = {Human {Reliability} {Analysis}-{Based} {Method} for {Manual} {Fire} {Suppression} {Analysis} in an {Integrated} {Probabilistic} {Risk} {Assessment}},
	volume = {6},
	issn = {2332-9017, 2332-9025},
	url = {https://asmedigitalcollection.asme.org/risk/article/doi/10.1115/1.4044792/975498/Human-Reliability-AnalysisBased-Method-for-Manual},
	doi = {10.1115/1.4044792},
	abstract = {Abstract
            Fire is one of the most critical initiating events that can lead to core damage in nuclear power plants (NPPs). To evaluate the potential vulnerability of plants to fire hazards, fire probabilistic risk assessment (PRA) is commonly conducted. Manual fire protection features, performed by the first responders (e.g., fire brigade), play a key role in preventing and mitigating fire-induced damage to the plant systems. In the current fire PRA methodology of NPPs, there are two main gaps in the modeling of manual fire protection features: (i) the quantification of the first responder performance is solely based on empirical data (industry-wide historical fire events), and so the plant-specific design and conditions cannot be explicitly considered; and (ii) interactions of first responders with fire propagation are not fully captured. To address these challenges, the authors develop a model-based approach, grounded on human reliability analysis (HRA) and coupled with the fire dynamics simulator (FDS), to model the first responder performance more realistically and consider the interface between the first responder performance and fire propagation more explicitly. In this paper, the HRA-based approach is implemented in an integrated PRA (I-PRA) methodological framework for fire PRA and applied to a switchgear room fire scenario of an NPP. The proposed model-based approach (a) adds more realism to fire PRA and so to risk assessment in NPPs and (b) provides opportunities for sensitivity and importance measure analyses with respect to design conditions; therefore, contributes to risk management in NPPs.},
	language = {en},
	number = {1},
	urldate = {2022-03-09},
	journal = {ASCE-ASME J Risk and Uncert in Engrg Sys Part B Mech Engrg},
	author = {Sakurahara, Tatsuya and Mohaghegh, Zahra and Kee, Ernie},
	month = mar,
	year = {2020},
	pages = {011010},
}

@article{sakurahara_integrated_2018,
	title = {An integrated methodology for spatio-temporal incorporation of underlying failure mechanisms into fire probabilistic risk assessment of nuclear power plants},
	volume = {169},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832017310499},
	doi = {10.1016/j.ress.2017.09.001},
	language = {en},
	urldate = {2022-03-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Sakurahara, Tatsuya and Mohaghegh, Zahra and Reihani, Seyed and Kee, Ernie and Brandyberry, Mark and Rodgers, Shawn},
	month = jan,
	year = {2018},
	pages = {242--257},
}

@article{rasmussen_application_1981,
	title = {The {Application} of {Probabilistic} {Risk} {Assessment} {Techniques} to {Energy} {Technologies}},
	volume = {6},
	issn = {0362-1626},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.eg.06.110181.001011},
	doi = {10.1146/annurev.eg.06.110181.001011},
	language = {en},
	number = {1},
	urldate = {2022-03-09},
	journal = {Annual Review of Energy},
	author = {Rasmussen, N C},
	month = nov,
	year = {1981},
	pages = {123--138},
}

@inproceedings{brissaud_probabilistic_2015,
	address = {Zurich, France},
	title = {Probabilistic {Risk} {Assessment} {Considering} {Parameter} and {Model} {Uncertainties}},
	abstract = {Probabilistic risk assessment (PRA) has become a widely used and accepted tool for managing risk in several industry sectors. The present paper focuses on parameter and model uncertainties within PRA that combine event trees and fault trees. To this end, a PRA is applied to a case study from oil and gas activities. Parameter uncertainties concern frequencies of initiating events, failure rates of safety barriers, factors of common cause failures, test coverages, and conditional probabilities. To perform these uncertainty analyses, a classical approach based on probability density functions and Monte Carlo simulations is used. On the other hand, model uncertainties concern effectiveness and architecture of safety barriers. To perform these uncertainty analyses, an approach based on fictitious events is proposed, which aims at transferring model uncertainties to parameter uncertainties. Resulting frequencies of occurrence of each accidental scenario are then assessed considering both parameter and model uncertainties. The impact of these results on risk management, notably in terms of risk acceptability, are then discussed, considering the selection of testing policy (including proof and partial tests) as example.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {European {Safety} {And} {Reliability}},
	author = {Brissaud, Florent and Rosner, Elsa},
	month = sep,
	year = {2015},
}

@inproceedings{xing_integrated_2017,
	address = {High Tatras Mountains, Tatranské Matliare, Slovak Republic},
	title = {An integrated framework for condition-informed probabilistic risk assessment},
	isbn = {978-1-138-62937-0 978-1-351-80973-3},
	url = {http://www.crcnetbase.com/doi/10.1201/9781315210469-361},
	doi = {10.1201/9781315210469-361},
	abstract = {Traditional Probabilistic Risk Assessment (PRA) is based on techniques like Event Tree Analysis (ETA) and Fault Tree Analysis (FTA), which are considered static, i.e., the failure probabilities of the safety barriers do not take into account the system evolution in time, e.g., due to various degradation mechanisms, like fatigue, wear, corrosion, etc. On the other hand, condition-monitoring data are available in practice and can be used, possibly even for real-time updating. In this paper, we develop an integrated framework for condition-informed risk analysis. A conventional event tree model is used, in which some safety barriers are subject to degradation mechanisms and their failure probabilities are treated as time-dependent. Particle Filtering (PF) is used to update the failure probabilities of the safety barriers in real-time, based on the collected condition-monitoring data. The updated failure probabilities are, then, used in the event tree model. The developed framework also allows predicting the scenario probabilities in the future. To do this, the failure probabilities are updated and predicted by PF and, then integrated in the event tree. The developed framework is applied for condition-informed risk assessment of a high-level alarm equipment from literature.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {Safety and {Reliability} – {Theory} and {Applications}},
	publisher = {CRC Press},
	author = {Xing, Jinduo and Zeng, Zhiguo and Zio, Enrico},
	month = jun,
	year = {2017},
	pages = {412--413},
}

@techreport{wang_probabilistic_1987,
	address = {Maryland},
	title = {Probabilistic {Risk} {Assessment} {A} {Look} at the {Role} of {Artificial} {Intelligence}},
	number = {SRC TR 87-115-r1},
	institution = {Systems Research Center, University of Maryland},
	author = {Wang, J and Moderres, M.},
	month = jun,
	year = {1987},
}

@article{satoh_application_nodate,
	title = {An {Application} of {Probabilistic} {Risk} {Assessment} to {Information} {Security} {Audit}},
	abstract = {After the information security audit, the auditor commonly points out the importance of information assets, the vulnerability of the audited information system, and the need of countermeasures. On such an occasion, the audited often ask the auditor for the quantitative assessment of the risk so that they can take specific measures. Nevertheless, in reality, the auditor can hardly meet this requirement because they do not have any appropriate methods to assess the risk quantitatively and systematically. Therefore, this paper proposes the approach that makes it possible to identify the scenarios of information security accidents systematically, to assess the risk of the occurrence of the scenario quantitatively, and to point out the importance of taking countermeasures by incorporating Probabilistic Risk Assessment in information security audit. For the concrete description and explanation of this approach, this paper takes the case of the audit of password management as an example. By enumerating the possible scenarios that indicate how initiating events, the vulnerability of mitigation systems, and the failures of operations can allow illegal accesses to the information assets, this paper shows that it is possible to assess the security risks by the pair of defenseless time span and its occurrence frequency of each scenario. Finally, since the parameters necessary for risk quantification such as the occurrence frequency of password theft, the probability of theft detection, and the probability of taking countermeasure after the theft have uncertainty, the uncertainty of the occurrence of the scenario itself is assessed by propagating the incompleteness of the knowledge of these parameters with random digits.},
	language = {en},
	author = {Satoh, Naoki and Kumamoto, Hiromitsu},
	pages = {8},
}

@inproceedings{roy_risk_2004,
	address = {Melbourne, Vic., Australia},
	title = {A risk management framework for software engineering practice},
	isbn = {978-0-7695-2089-6},
	url = {http://ieeexplore.ieee.org/document/1290458/},
	doi = {10.1109/ASWEC.2004.1290458},
	abstract = {Formal risk analysis and management in software engineering is still an emerging part of project management. This paper provides a brief introduction to the concepts of risk management for software development projects, and then an overview of a new risk management framework. Risk management for software projects is intended to minimize the chances of unexpected events, or more specifically to keep all possible outcomes under tight management control. Risk management is also concerned with making judgments about how risk events are to be treated, valued, compared and combined.},
	language = {en},
	urldate = {2022-03-09},
	booktitle = {2004 {Australian} {Software} {Engineering} {Conference}. {Proceedings}.},
	publisher = {IEEE},
	author = {Roy, G.G.},
	year = {2004},
	pages = {60--67},
}

@techreport{maheras_plan_2021,
	title = {Plan for {Development} and {Application} of {Risk} {Assessment} {Approach} for {Transportation} {Package} {Approval} of an {MNPP} for {Domestic} {Highway} {Shipment}},
	abstract = {The purpose of this plan is to provide the planning bases for the development and application of a PRA methodology for the highway transport of the Project Pele prototype mobile nuclear power plant (MNPP) that would support a risk-informed pathway for regulatory approval. In addition to a MNPP Transportation PRA, the methodology, technical information, data, and example analyses will be provided to the two Project Pele vendors, BWXT and X-Energy, with the expectation that the PRA methodology, technical information, data, and analysis approaches will be used to support a request for a 10 CFR 71.12 exemption that will be submitted by BWXT or X-Energy to the NRC for approval of the Project Pele transportation package. Additionally, this information will also be provided to the NRC for review, contribution, and endorsement of the process at the same time it is provided to the Project Pele vendors. BWXT or X-Energy will bear the ultimate responsibility for the submittal of the transportation safety analysis report and the request for exemption to the NRC.},
	author = {Maheras, SJ and Short, SM and Coles, GA and Adkins, HE and Phillips, JR and Lowry, PP and Condon, CA and Banerjee, K},
	month = dec,
	year = {2021},
}

@techreport{collin_agr-1_2015,
	title = {{AGR}-1 {Irradiation} {Test} {Final} {As}-{Run} {Report}, {Rev}. 3},
	url = {https://www.osti.gov/biblio/1173081-agr-irradiation-test-final-run-report-rev},
	abstract = {This document presents the as-run analysis of the AGR-1 irradiation experiment. AGR-1 is the first of eight planned irradiations for the Advanced Gas Reactor (AGR) Fuel Development and Qualification Program. Funding for this program is provided by the US Department of Energy (DOE) as part of the Next-Generation Nuclear Plant (NGNP) project. The objectives of the AGR-1 experiment are: 1. To gain experience with multi-capsule test train design, fabrication, and operation with the intent to reduce the probability of capsule or test train failure in subsequent irradiation tests. 2. To irradiate fuel produced in conjunction with the AGR fuel process development effort. 3. To provide data that will support the development of an understanding of the relationship between fuel fabrication processes, fuel product properties, and irradiation performance. In order to achieve the test objectives, the AGR-1 experiment was irradiated in the B-10 position of the Advanced Test Reactor (ATR) at the Idaho National Laboratory (INL) for a total duration of 620 effective full power days of irradiation. Irradiation began on December 24, 2006 and ended on November 6, 2009 spanning 13 ATR cycles and approximately three calendar years. The test contained six independently controlled and monitored capsules. Each capsule contained 12 compacts of a single type, or variant, of the AGR coated fuel. No fuel particles failed during the AGR-1 irradiation. Final burnup values on a per compact basis ranged from 11.5 to 19.6 \%FIMA, while fast fluence values ranged from 2.21 to 4.39 x 1025 n/m2 (E {\textgreater}0.18 MeV). We’ll say something here about temperatures once thermal recalc is done. Thermocouples performed well, failing at a lower rate than expected. At the end of the irradiation, nine of the originally-planned 19 TCs were considered functional. Fission product release-to-birth (R/B) ratios were quite low. In most capsules, R/B values at the end of the irradiation were at or below 10-7 with only one capsule significantly exceeding this value. A maximum R/B of around 2 x 10-7 was reached at the end of the irradiation in Capsule 5. Several shakedown issues were encountered and resolved during the first three cycles. These include the repair of minor gas line leaks; repair of faulty gas line valves; the need to position moisture monitors in regions of low radiation fields for proper functioning; the enforcement of proper on-line data storage and backup, the need to monitor thermocouple performance, correcting for detector spectral gain shift, and a change in the mass flow rate range of the neon flow controllers.},
	language = {English},
	number = {INL/EXT-10-18097},
	urldate = {2022-03-08},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Collin, Blaise P.},
	month = jan,
	year = {2015},
	doi = {10.2172/1173081},
}

@article{collin_agr-1_nodate,
	title = {{AGR}-1 {IRRADIATION} {TEST} {FINAL} {AS}-{RUN} {REPORT}},
	language = {en},
	author = {Collin, Blaise P},
	pages = {115},
}

@book{nichols_pthreads_2002,
	address = {Beijing Köln},
	edition = {Nachdr.},
	title = {Pthreads programming: a {POSIX} standard for better multiprocessing},
	isbn = {978-1-56592-115-3},
	shorttitle = {Pthreads programming},
	language = {eng},
	publisher = {O'Reilly},
	author = {Nichols, Bradford and Buttlar, Dick and Proulx Farrell, Jacqueline},
	year = {2002},
}

@article{grabaskas_development_2022,
	title = {Development of the {Versatile} {Test} {Reactor} {Probabilistic} {Risk} {Assessment}},
	issn = {0029-5639, 1943-748X},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295639.2021.2014741},
	doi = {10.1080/00295639.2021.2014741},
	abstract = {The Versatile Test Reactor (VTR) is a fast spectrum test reactor currently being developed in the United States under the direction of the U.S. Department of Energy (DOE), Office of Nuclear Energy (DOE-NE). The mission of the VTR is to enable accelerated testing of advanced reactor fuels and materials required for advanced reactor technologies. The conceptual design of the 300-MW(thermal), sodiumcooled, metallic-fueled, pool-type fast reactor has been led by U.S. national laboratories in collaboration with General Electric-Hitachi and Bechtel National Inc. To facilitate risk-informed design and authoriza­ tion activities during the conceptual development phase, a conceptual design probabilistic risk assessment (PRA) was performed for the VTR. This paper provides an overview of the development of the VTR conceptual design PRA, including key DOE and industry standards and the PRA analysis approach and structure. In addition, the results of the VTR conceptual design PRA are provided, which include its use within authorization documentation and design decisions, along with important lessons learned during the process. The work reported in the paper is the result of studies supporting a VTR conceptual design, cost, and schedule estimate for DOE-NE to make a decision on procurement. As such, it is preliminary.},
	language = {en},
	urldate = {2022-03-08},
	journal = {Nuclear Science and Engineering},
	author = {Grabaskas, David and Andrus, Jason and Henneke, Dennis and Li, Jonathan and Bucknor, Matthew and Warner, Matthew},
	month = mar,
	year = {2022},
	pages = {1--11},
}

@article{katata_atmospheric_2012,
	title = {Atmospheric discharge and dispersion of radionuclides during the {Fukushima} {Dai}-ichi {Nuclear} {Power} {Plant} accident. {Part} {I}: {Source} term estimation and local-scale atmospheric dispersion in early phase of the accident},
	volume = {109},
	issn = {0265931X},
	shorttitle = {Atmospheric discharge and dispersion of radionuclides during the {Fukushima} {Dai}-ichi {Nuclear} {Power} {Plant} accident. {Part} {I}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X12000525},
	doi = {10.1016/j.jenvrad.2012.02.006},
	abstract = {The atmospheric release of 131I and 137Cs in the early phase of the Fukushima Dai-ichi Nuclear Power Plant (FNPP1) accident from March 12 to 14, 2011 was estimated by combining environmental data with atmospheric dispersion simulations under the assumption of a unit release rate (1 Bq hÀ1). For the simulation, WSPEEDI-II computer-based nuclear emergency response system was used. Major releases of 131I ({\textgreater}1015 Bq hÀ1) were estimated when air dose rates increased in FNPP1 during the afternoon on March 12 after the hydrogen explosion of Unit 1 and late at night on March 14. The high-concentration plumes discharged during these periods ﬂowed to the northwest and southesouthwest directions of FNPP1, respectively. These plumes caused a large amount of dry deposition on the ground surface along their routes. Overall, the spatial pattern of 137Cs and the increases in the air dose rates observed at the monitoring posts around FNPP1 were reproduced by WSPEEDI-II using estimated release rates. The simulation indicated that air dose rates signiﬁcantly increased in the southesouthwest region of FNPP1 by dry deposition of the high-concentration plume discharged from the night of March 14 to the morning of March 15.},
	language = {en},
	urldate = {2022-03-08},
	journal = {Journal of Environmental Radioactivity},
	author = {Katata, Genki and Ota, Masakazu and Terada, Hiroaki and Chino, Masamichi and Nagai, Haruyasu},
	month = jul,
	year = {2012},
	pages = {103--113},
}

@inproceedings{nejad_simulation_2021,
	title = {Simulation {Based} {Probabilistic} {Risk} {Assessment} ({SIMPRA}): {Risk} {Based} {Design}},
	isbn = {978-981-18201-6-8},
	shorttitle = {Fault {Trees}, {Decision} {Trees}, and {Binary} {Decision} {Diagrams}},
	language = {English},
	booktitle = {Proceedings of the 31st {European} {Safety} and {Reliability} {Conference}},
	publisher = {Research Publishing},
	author = {Nejad, Hamed S. and Parhizkar, Tarannom and Mosleh, Ali},
	year = {2021},
}

@techreport{ma_exploring_2022,
	title = {Exploring {Advanced} {Computational} {Tools} and {Techniques} with {Artifical} {Intelligence} and {Machine} {Learning} in {Operating} {Nuclear} {Plants}},
	number = {NUREG/CR-7294 (INL/EXT-21-61117)},
	institution = {Office of Nuclear Regulatory Research},
	author = {Ma, Z. and Bao, H. and Zhang, S. and Xian, M. and Mack, A.},
	month = feb,
	year = {2022},
}

@article{siu_qualitative_nodate,
	title = {{QUALITATIVE} {PRA} {INSIGHTS} {FROM} {SEISMIC} {EVENTS}},
	abstract = {Probabilistic risk assessment (PRA) oriented reviews of historical operational events can help identify potential gaps where improved approaches can increase analysis realism. This report documents the results of an exploratory project reviewing seismic events affecting nuclear power plant (NPP) operations through the full range of induced hazards (e.g., ground motion, displacement, fires, floods). Observations regarding human and organizational factors, seismic/fire interactions, and reactivity effects reinforce the importance of an integrated, multidisciplinary approach to seismic PRA.},
	language = {en},
	author = {Siu, N and Xing, J and Melly, N and Sock, F and Pires, J},
	pages = {88},
}

@article{nejad_automatic_2022,
	title = {Automatic generation of event sequence diagrams for guiding simulation based dynamic probabilistic risk assessment ({SIMPRA}) of complex systems},
	volume = {222},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832022000886},
	doi = {10.1016/j.ress.2022.108416},
	abstract = {Dynamic probabilistic risk assessment (DPRA) is a systematic and comprehensive methodology that has been used and refined over the past decades to evaluate the risks associated with complex systems such as nuclear power plants, space missions, chemical plants, and military systems. A critical step in DPRA is generating risk scenarios which are used to enumerate and assess the probability of different outcomes. The classical approach to generating risk scenarios is not, however, sufficient to deal with the complexity of the above-mentioned systems. The primary contribution of this study is in offering a new method for capturing different types of engineering knowledge and using them to automatically generate risk scenarios, presented in the form of generalized event sequence diagrams, for dynamic systems. In this study, guidelines of this new method are explained in detail. In addition, in order to show the procedure of applying the proposed method on a complex system with industrial application, earth observation satellite systems are studied, and a planner is developed for these satellites. This planner is applied to a lunar reconnaissance orbiter satellite, which is an example of a earth observation satellite system, and risk scenarios are generated.},
	language = {en},
	urldate = {2022-03-01},
	journal = {Reliability Engineering \& System Safety},
	author = {Nejad, Hamed S. and Parhizkar, Tarannom and Mosleh, Ali},
	month = jun,
	year = {2022},
	pages = {108416},
}

@article{veeraraghavan_mastodon_2021,
	title = {{MASTODON}: {An} {Open}-{Source} {Software} for {Seismic} {Analysis} and {Risk} {Assessment} of {Critical} {Infrastructure}},
	volume = {207},
	issn = {0029-5450},
	shorttitle = {{MASTODON}},
	url = {https://doi.org/10.1080/00295450.2020.1807282},
	doi = {10.1080/00295450.2020.1807282},
	abstract = {Seismic analysis and risk assessment of safety-critical infrastructure like hospitals, nuclear power plants, dams, and facilities handling radioactive materials involve computationally intensive numerical models and coupled multiphysics scenarios. They are also performed in a strict regulatory environment that requires high software quality assurance standards, and in the case of safety-related nuclear facilities, a conformance to the American Society of Mechanical Engineers Nuclear Quality Assurance (NQA-1) standard. This paper introduces the open-source finite-element software, MASTODON (Multi-hazard Analysis of Stochastic Time-Domain Phenomena), which implements state-of-the-art seismic analysis and risk assessment tools in a quality-controlled environment. MASTODON is built on MOOSE (Multi-physics Object-Oriented Simulation Environment), which is a highly parallelizable, NQA-1 conforming, coupled multiphysics, finite-element framework developed at Idaho National Laboratory. MASTODON is capable of fault rupture and source-to-site wave propagation using the domain reduction method, nonlinear site response, and soil-structure interaction analysis, implicit and explicit time integration, automated stochastic simulations, and seismic probabilistic risk assessment. When coupled with other MOOSE applications, MASTODON can also solve strongly and weakly coupled multiphysics problems. This paper presents a summary of the capabilities of MASTODON and some demonstrative examples.},
	number = {7},
	urldate = {2022-03-01},
	journal = {Nuclear Technology},
	author = {Veeraraghavan, Swetha and Bolisetti, Chandrakanth and Slaughter, Andrew and Coleman, Justin and Dhulipala, Somayajulu and Hoffman, William and Kim, Kyungtae and Kurt, Efe and Spears, Robert and Munday, Lynn},
	month = jul,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295450.2020.1807282},
	keywords = {Seismic analysis, external hazard, probabilistic risk assessment, site response analysis, soil-structure interaction},
	pages = {1073--1095},
}

@book{woo_atomic_2012,
	address = {London},
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Atomic {Information} {Technology}},
	isbn = {978-1-4471-4029-0 978-1-4471-4030-6},
	url = {http://link.springer.com/10.1007/978-1-4471-4030-6},
	language = {en},
	urldate = {2022-02-25},
	publisher = {Springer London},
	author = {Woo, Taeho},
	year = {2012},
	doi = {10.1007/978-1-4471-4030-6},
}

@book{hofstetter_computational_2014,
	address = {Cham},
	title = {Computational {Engineering}},
	isbn = {978-3-319-05932-7 978-3-319-05933-4},
	url = {http://link.springer.com/10.1007/978-3-319-05933-4},
	language = {en},
	urldate = {2022-02-25},
	publisher = {Springer International Publishing},
	editor = {Hofstetter, Günter},
	year = {2014},
	doi = {10.1007/978-3-319-05933-4},
}

@book{wang_structural_2021,
	address = {Cham},
	series = {Springer {Series} in {Reliability} {Engineering}},
	title = {Structural {Reliability} and {Time}-{Dependent} {Reliability}},
	isbn = {978-3-030-62504-7 978-3-030-62505-4},
	url = {http://link.springer.com/10.1007/978-3-030-62505-4},
	language = {en},
	urldate = {2022-02-25},
	publisher = {Springer International Publishing},
	author = {Wang, Cao},
	year = {2021},
	doi = {10.1007/978-3-030-62505-4},
}

@article{andrews_event-tree_2000,
	title = {Event-tree analysis using binary decision diagrams},
	volume = {49},
	issn = {00189529},
	url = {http://ieeexplore.ieee.org/document/877343/},
	doi = {10.1109/24.877343},
	abstract = {This paper is concerned with ETA (event-tree analysis) where the branch point event causes are defined using fault trees. Attention is on the nontrivial situation where there are dependencies amongst the branch point events. The dependencies are due to component-failures in more than one of the fault trees. In these situations the analysis methods based on traditional FTA (fault-tree analysis) are inaccurate \& inefficient.},
	language = {en},
	number = {2},
	urldate = {2022-02-25},
	journal = {IEEE Transactions on Reliability},
	author = {Andrews, J.D. and Dunnett, S.J.},
	month = jun,
	year = {2000},
	pages = {230--238},
}

@article{ibanez-llano_minimal_2009,
	title = {Minimal cutsets-based reduction approach for the use of binary decision diagrams on probabilistic safety assessment fault tree models},
	volume = {223},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1243/1748006XJRR259},
	doi = {10.1243/1748006XJRR259},
	abstract = {Binary decision diagrams (BDDs) are a well-known alternative to the minimal cutsets (MCS) approach to assess Boolean reliability models. While the application of fault tree analysis can be considered to be consolidated, its application to the event trees involved in the probabilistic safety assessment (PSA) studies of the nuclear industry require extended efforts. For many real PSA models the full conversion procedure remains out of reach in terms of computational resources owing to their size, non-coherency, redundancy, and complexity. A potential solution to improve the quality of assessment methods is to design hybrid algorithms that combine the information derived from the calculation of MCS with the BDD methodology.},
	language = {en},
	number = {4},
	urldate = {2022-02-25},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Ibáñez-Llano, C and Rauzy, A and Meléndez, E and Nieto, F},
	month = dec,
	year = {2009},
	pages = {301--311},
}

@article{banov_new_2020,
	title = {A new heuristics for the event ordering in binary decision diagram applied in fault tree analysis},
	volume = {234},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X19879305},
	doi = {10.1177/1748006X19879305},
	abstract = {Fault tree is a common approach in probabilistic risk assessment of complex engineering systems. Since their introduction, binary decision diagrams proved to be a valuable tool for complete quantification of hard fault tree models. As is known, the size of the binary decision diagram representation is mainly determined by the quality of the selected fault tree event ordering scheme. Finding the optimal event ordering for binary decision diagram representation is a computationally intractable problem, for which reason heuristic approaches are applied to find reasonable good ordering schemes. The existing method for finding optimal ordering schemes related to special types of fan-in 2 read-once formulas is employed in our research to develop a new heuristic for fault tree. Various fault tree simplification methods are used for the sake of reducing fault tree model discrepancy from fan-in 2 read-once formulas. The reduced fault tree is traversed in a depth-first manner, as for every gate, the best ordering scheme is chosen from selected sets of input permutations. The quality of the final event ordering scheme is compared to orderings produced with depth-first left most heuristic on a set of fault tree models addressed in the literature as well as on a set of our hard models. Our method proves to be a useful heuristic for finding good static event ordering, and it compares favourably to the known heuristic based on a depth-first left most assignment approach.},
	language = {en},
	number = {2},
	urldate = {2022-02-25},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Banov, Reni and Šimić, Zdenko and Grgić, Davor},
	month = apr,
	year = {2020},
	pages = {397--406},
}

@article{ghojogh_sampling_nodate,
	title = {Sampling {Algorithms}, from {Survey} {Sampling} to {Monte} {Carlo} {Methods}: {Tutorial} and {Literature} {Review}},
	language = {en},
	journal = {Sampling Algorithms},
	author = {Ghojogh, Benyamin and Nekoei, Hadi and Ghojogh, Aydin and Karray, Fakhri and Crowley, Mark},
	pages = {25},
}

@article{mathieu_fukushima_2018,
	title = {Fukushima {Daiichi}–derived radionuclides in the atmosphere, transport and deposition in {Japan}: {A} review},
	volume = {91},
	issn = {08832927},
	shorttitle = {Fukushima {Daiichi}–derived radionuclides in the atmosphere, transport and deposition in {Japan}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0883292718300039},
	doi = {10.1016/j.apgeochem.2018.01.002},
	abstract = {The Fukushima Daiichi Nuclear Power Plant accident of March 11 2011 led to a signiﬁcant release of radionuclides in the environment. More than 99\% of the release activity in the atmosphere was due to highly volatile radionuclides such as I, Te, Cs, Xe, Kr. Fairly quickly after the accident, the main release events had been identiﬁed and their consequences roughly assessed. Most releases were dispersed over the Paciﬁc Ocean whereas about 20\% was dispersed over the Japan main highland causing areas of signiﬁcant deposit. Since then, the understanding of the diﬀerent episodes has been greatly enhanced. It is appropriate to review what happened in terms of releases into the atmosphere, transport, and deposition of radionuclides on the Japanese territory. We describe here, the current state of understanding of the release phase of the accident and the means used to achieve it. Numerous radiological measurements taken in the Japanese environment enabled the scientists to substantially reconstruct the four main sequences of contamination, to identify the probable trajectories of the radioactive plumes, and to link them with precipitation data to explain the areas of deposition. The measurements were supplemented by modelling techniques. The most signiﬁcant progress come from the quantiﬁcation of the atmospheric releases, the improvement of meteorological data to better take into account the inﬂuence of the complex orography on the plumes trajectories and the modelling of deposition processes. Notwithstanding more realistic simulations, progress is still to be made to accurately estimate people exposure due to the release phase of the FDNPP accident. An important result is that the bulk of the deposition was mostly generated at the beginning of the precipitation, by light rain in less than one hour. The scavenging of plume transported in altitude generates high deposition zones. Therefore, they do not necessarily match the zones within which inhalation exposure to the radioactive plumes was the largest.},
	language = {en},
	urldate = {2022-02-24},
	journal = {Applied Geochemistry},
	author = {Mathieu, Anne and Kajino, Mizuo and Korsakissok, Irène and Périllat, Raphaël and Quélo, Denis and Quérel, Arnaud and Saunier, Olivier and Sekiyama, Tsuyoshi Thomas and Igarashi, Yasuhito and Didier, Damien},
	month = apr,
	year = {2018},
	pages = {122--139},
}

@book{internationale_atomenergie-organisation_fukushima_2015,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident {V} 5/5},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@book{internationale_atomenergie-organisation_fukushima_2015-1,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident {V} 4/5},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@book{internationale_atomenergie-organisation_fukushima_2015-2,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident {V} 3/5},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@book{internationale_atomenergie-organisation_fukushima_2015-3,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident {V} 2/5},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@book{internationale_atomenergie-organisation_fukushima_2015-4,
	address = {Vienna, Austria},
	series = {{STI}/{PUB}},
	title = {The {Fukushima} {Daiichi} accident {V1}/5},
	volume = {1/5},
	isbn = {978-92-0-107015-9},
	abstract = {Report by the Director General -- Technical Volume 1/5: Description and context of the accident -- Technical Volume 2/5: Safety assessment -- Technical Volume 3/5: Emergency preparedness and response -- Technical Volume 4/5: Radiological consequences -- Technical Volume 5/5: Post-accident recovery -- Annexes (5 CD-ROM)},
	language = {en},
	publisher = {International Atomic Energy Agency},
	editor = {Internationale Atomenergie-Organisation},
	year = {2015},
}

@misc{idaho_national_laboratory_gain_program_microreactor_2021,
	title = {Microreactor {Applications} {Research} {Validation} and {Evaluation} {Project} ({MARVEL}) - {Integrating} {Microreactors} with {End}-{User} {Applications}},
	shorttitle = {{MARVEL} - {Integrating} {Microreactors} with {End}-{User} {Applications}},
	url = {https://gain.inl.gov/SiteAssets/MicroreactorProgram/MARVEL_Fact_Sheet_R10.pdf},
	language = {en-us},
	publisher = {US Department of Energy},
	author = {Idaho National Laboratory GAIN Program},
	month = may,
	year = {2021},
}

@misc{westinghouse_global_technology_office_westinghouse_2017,
	title = {Westinghouse {eVinci} {Micro} {Reactor} {Factsheet}},
	shorttitle = {{GTO}-0001},
	url = {https://www.westinghousenuclear.com/Portals/0/new%20plants/evincitm/GTO-0001%20eVinci%20flysheet.pdf},
	language = {en-US},
	publisher = {Westinghouse Electric Company},
	author = {{Westinghouse Global Technology Office}},
	month = oct,
	year = {2017},
}

@techreport{kinsey_united_2018-2,
	title = {United {States} {Nuclear} {Manufacturing} {Infrastructure} {Assessment}},
	url = {http://www.osti.gov/servlets/purl/1494317/},
	language = {en},
	number = {DOE-MPRA--NE000638, 1494317},
	urldate = {2022-02-22},
	author = {Kinsey, Stephen and Jessup, William and {MPR Associates, Inc.}},
	month = dec,
	year = {2018},
	doi = {10.2172/1494317},
	pages = {DOE--MPRA--NE000638, 1494317},
}

@book{noauthor_system_1994,
	edition = {1},
	title = {System {Reliability} {Theory}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9780470316900},
	urldate = {2022-02-21},
	publisher = {John Wiley \& Sons, Ltd},
	year = {1994},
	doi = {10.1002/9780470316900},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470316900},
}

@techreport{drouin_guidance_2017,
	type = {Final {Report}},
	title = {Guidance on the {Treatment} of {Uncertainties} {Associated} with {PRAs} in {Risk} {Informed} {Decisionmaking}},
	language = {English},
	number = {NUREG-1855},
	institution = {NRC},
	author = {Drouin, M. and Gilberston, A. and Parry, G. and Lehner, J. and Martinez-Guridi, G. and LaChance, J. and Wheeler, T.},
	month = mar,
	year = {2017},
}

@article{farrance_uncertainty_nodate,
	title = {Uncertainty of {Measurement}: {A} {Review} of the {Rules} for {Calculating} {Uncertainty} {Components} through {Functional} {Relationships}},
	abstract = {The Evaluation of Measurement Data - Guide to the Expression of Uncertainty in Measurement (usually referred to as the GUM) provides general rules for evaluating and expressing uncertainty in measurement. When a measurand, y, is calculated from other measurements through a functional relationship, uncertainties in the input variables will propagate through the calculation to an uncertainty in the output y. The manner in which such uncertainties are propagated through a functional relationship provides much of the mathematical challenge to fully understanding the GUM.},
	language = {en},
	author = {Farrance, Ian and Frenkel, Robert},
	pages = {27},
}

@article{goebel_lecture_nodate,
	title = {Lecture {Notes} in {Artiﬁcial} {Intelligence}},
	language = {en},
	author = {Goebel, Edited R and Siekmann, J and Wahlster, W},
	pages = {399},
}

@article{hu_uncertainty_2021,
	title = {Uncertainty {Expression} and {Propagation} in the {Risk} {Assessment} of {Uncertain} {Random} {System}},
	volume = {15},
	issn = {1932-8184, 1937-9234, 2373-7816},
	url = {https://ieeexplore.ieee.org/document/9093164/},
	doi = {10.1109/JSYST.2020.2990679},
	abstract = {Expressions and propagations of uncertainties have been the core topics in the development of risk science in last decades, whose purpose is to provide decision-makers with clear information about the uncertainty of system’s risk. Uncertainty theory is an emerging theory that has great advantages in the expression of epistemic uncertainty, compared to the theories such as subjective probability, evidence theory, and possibility theory. A new framework of uncertainty expression is proposed in this article to properly express different uncertainty sources that exist in the system, where the uncertainty theory is used to express epistemic uncertainties and frequentist probability is used to express aleatory uncertainties. A general propagation method is further developed to address the joint calculations of proposed uncertainty expressions, which can be degenerated into pure probabilistic approach and pure uncertainty-based approach. A case study is conducted to show the effectiveness of proposed method, whose results indicate that the application of proposed method will lead to a result which is easier to be understood than results of theories such as evidence theory and possibility theory, and is more robust than results of Bayesian approach.},
	language = {en},
	number = {2},
	urldate = {2022-02-18},
	journal = {IEEE Systems Journal},
	author = {Hu, Lunhu and Kang, Rui and Pan, Xing and Zuo, Dujun},
	month = jun,
	year = {2021},
	pages = {1604--1615},
}

@article{sun_uncertainty_2018,
	title = {Uncertainty {Analysis} of the {Estimated} {Risk} in {Formal} {Safety} {Assessment}},
	volume = {10},
	issn = {2071-1050},
	url = {http://www.mdpi.com/2071-1050/10/2/321},
	doi = {10.3390/su10020321},
	abstract = {An uncertainty analysis is required to be carried out in formal safety assessment (FSA) by the International Maritime Organization. The purpose of this article is to introduce the uncertainty analysis technique into the FSA process. Based on the uncertainty identiﬁcation of input parameters, probability and possibility distributions are used to model the aleatory and epistemic uncertainties, respectively. An approach which combines the Monte Carlo random sampling of probability distribution functions with the a-cuts for fuzzy calculus is proposed to propagate the uncertainties. One output of the FSA process is societal risk (SR), which can be evaluated in the two-dimensional frequency–fatality (FN) diagram. Thus, the conﬁdence-level-based SR is presented to represent the uncertainty of SR in two dimensions. In addition, a method for time window selection is proposed to estimate the magnitude of uncertainties, which is an important aspect of modeling uncertainties. Finally, a case study is carried out on an FSA study on cruise ships. The results show that the uncertainty analysis of SR generates a two-dimensional area for a certain degree of conﬁdence in the FN diagram rather than a single FN curve, which provides more information to authorities to produce effective risk control measures.},
	language = {en},
	number = {2},
	urldate = {2022-02-18},
	journal = {Sustainability},
	author = {Sun, Molin and Zheng, Zhongyi and Gang, Longhui},
	month = jan,
	year = {2018},
	pages = {321},
}

@article{frantzich_risk_1998,
	title = {Risk analysis and fire safety engineering},
	volume = {31},
	issn = {03797112},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0379711298000216},
	doi = {10.1016/S0379-7112(98)00021-6},
	abstract = {The paper demonstrates how two quantitative risk analysis (QRA) methods may be used to evaluate the risk to which the occupants of a building may be subjected if a ﬁre breaks out. The methods (standard QRA and extended QRA) diﬀer in terms of how uncertainties in the variables are considered. The extended QRA explicitly considers uncertainty as it is a part of the methodology. The standard QRA has to be complemented with a sensitivity analysis to fully provide insight into the uncertainty inherent in the scenario. Both methods are applied to a calculation example determining the societal risk for a hospital ward. The analyses are performed as Monte Carlo simulations. 1998 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	number = {4},
	urldate = {2022-02-18},
	journal = {Fire Safety Journal},
	author = {Frantzich, Håkan},
	month = nov,
	year = {1998},
	pages = {313--329},
}

@inproceedings{wilcox_uncertainty_2003,
	address = {College Park, MD},
	title = {Uncertainty modeling of data and uncertainty propagation for risk studies},
	isbn = {978-0-7695-1997-5},
	url = {http://ieeexplore.ieee.org/document/1236160/},
	doi = {10.1109/ISUMA.2003.1236160},
	abstract = {Risk modeling techniques for probabilistic risk assessment are fairly well established, however, data to support risk assessment is still a major problem often leading to questionable risk assessment results. Selecting appropriate data sources and modeling uncertainty helps to improve risk assessment results and can help to make more informed decisions. Risk assessments need to be able to capture existing data with varying uncertainties for risk analysis. Complete databases to quantify event probabilities may not be available relying on the existing state of knowledge for risk assessment. Probabilistic and subjective uncertainty modeling techniques can both be applied to PRA’s based on the varying levels of knowledge to support the quantitative assessment. Probabilistic uncertainty representation using probability distributions require detailed information on the reliability of system components to make risk judgment.},
	language = {en},
	urldate = {2022-02-18},
	booktitle = {Fourth {International} {Symposium} on {Uncertainty} {Modeling} and {Analysis}, 2003. {ISUMA} 2003.},
	publisher = {IEEE},
	author = {Wilcox, R.C. and Ayyub, B.M.},
	year = {2003},
	pages = {184--191},
}

@techreport{vedros_enhancement_2021,
	title = {Enhancement of {Industry} {Legacy} {Probabilistic} {Risk} {Assessment} {Methods} and {Tools}},
	url = {https://www.osti.gov/servlets/purl/1822882/},
	language = {en},
	number = {INL/EXT-21-64448-Rev000, 1822882},
	urldate = {2022-02-17},
	author = {Vedros, Kurt and Boring PhD, Ronald and Knudsen, James and Lawrence, Svetlana and Mandelli, Diego and Park, Jooyoung and Prescott, Steven and Smith, Curtis},
	month = sep,
	year = {2021},
	doi = {10.2172/1822882},
	pages = {INL/EXT--21--64448--Rev000, 1822882},
}

@article{demkowicz_coated_2018,
	title = {Coated particle fuel: {Historical} perspectives and current progress},
	volume = {515},
	issn = {0022-3115},
	shorttitle = {Coated particle fuel},
	url = {https://www.osti.gov/pages/biblio/1494898-coated-particle-fuel-historical-perspectives-current-progress},
	doi = {10.1016/j.jnucmat.2018.09.044},
	abstract = {We report that coated particle fuel concepts date back some 60 years, and have evolved significantly from the relatively primitive pyrocarbon-coated kernels envisioned by the first pioneers. Improvements in particle design, coating layer properties, and kernel composition have produced the modern tristructural isotropic (TRISO) particle, capable of low statistical coating failure fractions and good fission product retention under extremely severe conditions, including temperatures of 1600 °C for hundreds of hours. The fuel constitutes one of the key enabling technologies for high-temperature gas-cooled reactors, allowing coolant outlet temperatures approaching 1000 °C and contributing to enhanced reactor safety due to the hardiness of the particles. TRISO fuel development has taken place in a number of countries worldwide, and several fuel qualification programs are currently in progress. Here, we discuss the unique history of particle fuel development and some key technology advances, concluding with some of the latest progress in UO2 and UCO TRISO fuel qualification.},
	language = {English},
	number = {C},
	urldate = {2022-02-15},
	journal = {Journal of Nuclear Materials},
	author = {Demkowicz, Paul A. and Liu, Bing and Hunn, John D.},
	month = sep,
	year = {2018},
	note = {Institution: Oak Ridge National Lab. (ORNL), Oak Ridge, TN (United States)
Publisher: Elsevier},
}

@book{aho_compilers_2007,
	address = {Boston},
	edition = {2nd ed},
	title = {Compilers: principles, techniques, \& tools},
	isbn = {978-0-321-48681-3},
	shorttitle = {Compilers},
	publisher = {Pearson/Addison Wesley},
	editor = {Aho, Alfred V. and Aho, Alfred V.},
	year = {2007},
	note = {OCLC: ocm70775643},
	keywords = {Compilers (Computer programs)},
}

@article{rabin_finite_1959,
	title = {Finite {Automata} and {Their} {Decision} {Problems}},
	volume = {3},
	issn = {0018-8646, 0018-8646},
	url = {http://ieeexplore.ieee.org/document/5392601/},
	doi = {10.1147/rd.32.0114},
	number = {2},
	urldate = {2022-02-15},
	journal = {IBM Journal of Research and Development},
	author = {Rabin, M. O. and Scott, D.},
	month = apr,
	year = {1959},
	pages = {114--125},
}

@article{harada_dietary_2013,
	title = {Dietary {Intake} of {Radiocesium} in {Adult} {Residents} in {Fukushima} {Prefecture} and {Neighboring} {Regions} after the {Fukushima} {Nuclear} {Power} {Plant} {Accident}: 24-h {Food}-{Duplicate} {Survey} in {December} 2011},
	volume = {47},
	issn = {0013-936X, 1520-5851},
	shorttitle = {Dietary {Intake} of {Radiocesium} in {Adult} {Residents} in {Fukushima} {Prefecture} and {Neighboring} {Regions} after the {Fukushima} {Nuclear} {Power} {Plant} {Accident}},
	url = {https://pubs.acs.org/doi/10.1021/es304128t},
	doi = {10.1021/es304128t},
	abstract = {Since the nuclear power plant accident in Fukushima in March 2011, the Japanese government has conducted screening and removal of contaminated foods from the market that exceed provisional regulation limits for radionuclides. This study aimed to provide an urgent estimate of the dietary exposure of adult residents recruited from three areas in Japan to cesium 134 (134Cs), cesium 137 (137Cs), and, for comparison, natural potassium 40 (40K) on December 4, 2011. Fifty-three sets of 24-h food-duplicate samples were collected in Fukushima Prefecture and neighboring regions. The 134Cs, 137Cs, and 40K levels in the samples were measured using a germanium detector. Items in the food-duplicate samples were recorded and analyzed for radiocesium intake. Radiocesium was detected in 25 of 26 samples from Fukushima. The median dietary intake of radiocesium was 4.0 Bq/day (range {\textless}0.26−17 Bq/day). The estimated annual dose from radiocesium was calculated assuming that the daily intake of radiocesium was constant throughout the year. The median estimated dose level was 23 μSv/ year (range {\textless}2.6−99 μSv/year). The estimated dose level of radiocesium was signiﬁcantly higher in Fukushima than in the Kanto region and western Japan. Stepwise multiple linear regression analyses demonstrated that the intake of fruits and mushrooms produced in Fukushima were signiﬁcant factors for the dietary intake of 137Cs in the 26 participants from Fukushima. The average radioactivity (±SD) of locally produced persimmons and apples (n = 16) were 23 ± 28 and 30 ± 35 Bq/kg for 134Cs and 137Cs, respectively. The preliminary estimated dietary dose levels among Fukushima residents were much lower than the maximum permissible dose 1 mSv/year, based on new Japanese standard limits for radiocesium in foods (100 Bq/kg for general foods). In future studies, the exposure estimates should be reﬁned by probability sampling to eliminate biases.},
	language = {en},
	number = {6},
	urldate = {2022-02-15},
	journal = {Environmental Science \& Technology},
	author = {Harada, Kouji H. and Fujii, Yukiko and Adachi, Ayumu and Tsukidate, Ayako and Asai, Fumikazu and Koizumi, Akio},
	month = mar,
	year = {2013},
	pages = {2520--2526},
}

@article{boring_fifty_nodate,
	title = {Fifty {Years} of {THERP} and {Human} {Reliability} {Analysis}},
	abstract = {In 1962 at a Human Factors Society symposium, Alan Swain presented a paper introducing a Technique for Human Error Rate Prediction (THERP). This was followed in 1963 by a Sandia Laboratories monograph outlining basic human error quantification using THERP and, in 1964, by a special journal edition of Human Factors on quantification of human performance. Throughout the 1960s, Swain and his colleagues focused on collecting human performance data for the Sandia Human Error Rate Bank (SHERB), primarily in connection with supporting the reliability of nuclear weapons assembly in the US. In 1969, Swain met with Jens Rasmussen of Risø National Laboratory and discussed the applicability of THERP to nuclear power applications. By 1975, in WASH-1400, Swain had articulated the use of THERP for nuclear power applications, and the approach was finalized in the watershed publication of the NUREG/CR-1278 in 1983. THERP is now 50 years old, and remains the most well known and most widely used HRA method. In this paper, the author discusses the history of THERP, based on published reports and personal communication and interviews with Swain. The author also outlines the significance of THERP. The foundations of human reliability analysis are found in THERP: human failure events, task analysis, performance shaping factors, human error probabilities, dependence, event trees, recovery, and pre- and post-initiating events were all introduced in THERP. While THERP is not without its detractors, and it is showing signs of its age in the face of newer technological applications, the longevity of THERP is a testament of its tremendous significance. THERP started the field of human reliability analysis. This paper concludes with a discussion of THERP in the context of newer methods, which can be seen as extensions of or departures from Swain’s pioneering work.},
	language = {en},
	author = {Boring, Ronald L},
	pages = {11},
}

@phdthesis{akker_disposition_2012,
	title = {On the {Disposition} of {Graphite} {Containing} {TRISO} {Particles} and the {Aqueous} {Transport} of {Radionuclides} via {Heterogeneous} {Geological} {Formations}},
	url = {https://escholarship.org/uc/item/3678q08m},
	abstract = {Deep Burn Modular High Temperature Rectors (DBMHR) have been proposed as a means to reuse the transuranic (TRU) content of commercial spent nuclear fuel (CSNF). By fissioning greater than 60\% of the initial TRU load DBMHR's transmute much of the fuel inventory into shorter-lived fission products. This use of a DBMHR to recycle CSNF offers remarkable benefits including the extraction of additional electricity without the need for additional raw fuel materials, added proliferation resistance by utilizing up to 99\% of the 239Pu content in the initial load, and a reduction of the radiotoxicity of the subsequent spent fuel. Two central features of the DBMHR design are the TRISO fuel particles and the all graphite core This is important from a repository perspective because pure graphite is reported to be "one of the most chemically inert materials" known, and offers the potential to serve as an ultra-durable matrix for the sequestration of radionuclides (over geologic time periods) generated as a result of the nuclear fuel cycle. In this study we evaluate the performance of DBMHR spent fuel (DBSF) for final geological disposition. The Yucca Mountain geological repository (YMR) is used as the environment for this study because of the completeness of the data sets necessary to conduct this investigation and because the regulations associated with the YMR provide a clear basis for evaluating the performance of the DBSF. A study of DBMHR fuel cycles shows a radiotoxicity benefit from the recycling CSNF in a DBMHR. Additionally, models developed to evaluate the release and transport of radionuclides from TRISO fuel particles and DBSF in a geological repository environment, including a novel model for the transport of an arbitrary length decay chain through an arbitrary combination of fractured and porous transport segments, demonstrate the efficacy of the DBMHR fuel cycle in reducing the environmental impact from the geological disposition of DBSF relative to CSNF. Calculations of the far-field transport of radionuclides released from DBSF are made by the newly developed TTBX computer code (a multi-region extension to the to the existing single region TTB computer code) which implements a numerical inversion of the Laplace-transformed analytical solutions to the radionuclide transport equation. This is done to evaluate the exposure of the target population. Results indicate compliance of the fuel form with regulatory standards related to exposure via groundwater for all cases studied by many orders of magnitude.In our studies of the repository behavior of DBSF we have seen here that graphite is an extremely robust material that has the potential to serve as a highly durable matrix for the sequestration of high level nuclear materials. The long lifetime of the graphite matrix (3 x 10{\textasciicircum}6 years at a minimum) allows many of the short-lived fission products to decay away before they are transported to the biosphere. Additionally, lifetime estimates for the graphite matrix greatly exceed the projected lifetime of many other matrices currently being considered such as UO2 or borosilicate glass. We have seen that in the YMR the long graphite lifetime assures that radionuclides are released congruently with the oxidation of the graphite (which oxidizes extremely slowly). This removes uncertainties associated with the solubilities of the radionuclides and assures that radionuclides will always be present at levels which are at or below their solubility limit. The remarkable performance of graphite in a geological repository highlights its utility to serve as a matrix for the disposition of nuclear material and the need for further detailed material studies of the performance of graphite in repository environments.},
	language = {en},
	urldate = {2022-02-14},
	school = {UC Berkeley},
	author = {Akker, Van Den and Patrick, Bret},
	year = {2012},
}

@incollection{wu_multi-hazard_2019,
	address = {Cham},
	title = {Multi-hazard {Risk} {Assessment}},
	isbn = {978-3-030-14986-4 978-3-030-14987-1},
	url = {http://link.springer.com/10.1007/978-3-030-14987-1_27},
	abstract = {This paper presents a brief summary of multi-hazard risk assessment, focusing on cascading landslide hazards. It starts by presenting the multi-hazard processes an engineering system may face, and possible interactions among the separate hazards and between the vulnerabilities of elements at risk to these hazards. Then a framework for analyzing the ﬂooding, landslide and debris ﬂow processes in a rainstorm is introduced. Multi-hazard risk assessment requires more comprehensive physical analyses than what are needed in conventional geotechnical design. Stability analysis, ﬂow analysis and impact analysis are all required. The outcomes of such physical analyses form the basis for evaluating the risks associated with these multi-hazardous processes. The multi-risk analysis can be performed using a HKUST ﬁve-step procedure, which describes the hazardous processes in an explicit probabilistic framework and identiﬁes key parameters that govern the success of a risk mitigation effort. Rational engineering decisions and emergency management policies can be made based on such physically-based risk analysis.},
	language = {en},
	urldate = {2022-02-14},
	booktitle = {Desiderata {Geotechnica}},
	publisher = {Springer International Publishing},
	author = {Zhang, Limin},
	editor = {Wu, Wei},
	year = {2019},
	doi = {10.1007/978-3-030-14987-1_27},
	note = {Series Title: Springer Series in Geomechanics and Geoengineering},
	pages = {227--236},
}

@article{garrick_roots_nodate,
	title = {{ROOTS} {OF} {QUANTITATIVE} {RISK} {ASSESSMENT}},
	language = {en},
	author = {Garrick, B J},
	pages = {17},
}

@article{garrick_quantitative_2009,
	title = {Quantitative {Risk} {Assessment} of the {State}-{Licensed}  {Radioactive} {Waste} {Disposal} {Area}},
	language = {en},
	journal = {New York},
	author = {Garrick, B John and Stetkar, John W and Dykes, Andrew A and Potter, Thomas E and Wampler, Stephen L},
	year = {2009},
	pages = {699},
}

@incollection{ksibi_probabilistic_2021,
	address = {Cham},
	title = {Probabilistic {Multi}-hazard {Risk} {Assessment}—{Development} of an {Aggregation} {Model} {Based} on the {Algebra} of {Events}},
	isbn = {978-3-030-51209-5 978-3-030-51210-1},
	url = {http://link.springer.com/10.1007/978-3-030-51210-1_312},
	abstract = {It is useful to examine the safety of a strategic facility based on a multihazard approach, considering the extreme events the facility in question could be subjected to during its lifetime. This paper introduces a probabilistic model, based on the algebra of events, for a multi-hazard risk associated with extreme events (e.g., natural, climatological, environmental, and biological, etc.). The probabilistic multi-hazard assessment (PMHA) of the risk is a key issue in structural and environmental safety. A basic characteristic of a probability-based multi-hazard model is that it does not generate a single point estimate, but it rather produces a hazard curve. In the present paper, the annual risk is calculated using a probability-based multi-hazard model totally constructed with the algebra of events and with the aggregation of the multi-hazard curves. The PMHA model is based on the total probability theorem. It grants a more reliable practice by allowing key stakeholders to make risk-informed choices rather than simply relying on traditional deterministic single hazard estimates of risk, with a brief description of uncertainty. Two illustrative applications were performed to demonstrate the feasibility of the PMHA approach: (1) a strategic structure subjected to three independent events: “ﬂooding”, “earthquake”, and “blast”; (2) the earthquake risk of a nuclear site subjected to two dependent events: “long duration” and “high magnitude” earthquake loads. The hazards fragilities are computed for the two examples and implemented in the framework of a multi-hazard approach leading to the estimation of the annual risk of failure.},
	language = {en},
	urldate = {2022-02-14},
	booktitle = {Recent {Advances} in {Environmental} {Science} from the {Euro}-{Mediterranean} and {Surrounding} {Regions} (2nd {Edition})},
	publisher = {Springer International Publishing},
	author = {Hamdi, Yasser and Daoued, Amine Ben and Mouhous-Voyneau, Nassima and Sergent, Philippe},
	editor = {Ksibi, Mohamed and Ghorbal, Achraf and Chakraborty, Sudip and Chaminé, Helder I. and Barbieri, Maurizio and Guerriero, Giulia and Hentati, Olfa and Negm, Abdelazim and Lehmann, Anthony and Römbke, Jörg and Costa Duarte, Armando and Xoplaki, Elena and Khélifi, Nabil and Colinet, Gilles and Miguel Dias, João and Gargouri, Imed and Van Hullebusch, Eric D. and Sánchez Cabrero, Benigno and Ferlisi, Settimio and Tizaoui, Chedly and Kallel, Amjad and Rtimi, Sami and Panda, Sandeep and Michaud, Philippe and Sahu, Jaya Narayana and Seffen, Mongi and Naddeo, Vincenzo},
	year = {2021},
	doi = {10.1007/978-3-030-51210-1_312},
	note = {Series Title: Environmental Science and Engineering},
	pages = {1989--1996},
}

@article{flage_expressing_2009,
	title = {{EXPRESSING} {AND} {COMMUNICATING} {UNCERTAINTY} {IN} {RELATION} {TO} {QUANTITATIVE} {RISK} {ANALYSIS}},
	volume = {2},
	abstract = {A quantitative risk analysis (QRA) should provide a broad, informative and balanced picture of risk, in order to support decisions. To achieve this, a proper treatment of uncertainty is a prerequisite. Most approaches to treatment of uncertainty in QRA seem to be based on the thinking that uncertainty relates to the calculated probabilities and expected values. This causes difficulties when it comes to communicating what the analysis results mean, and could easily lead to weakened conclusions if large uncertainties are involved. An alternative approach is to hold uncertainty, not probability, as a main component of risk, and regard probabilities purely as epistemic-based expressions of uncertainty. In the paper the latter view is taken, and we describe what should be the main components of a risk description when following this approach. We also indicate how this approach relates to decision-making. An important issue addressed is how to communicate the shortcomings and limitations of probabilities and expected values. Sensitivity analysis plays a key role in this regard. Examples are included to illustrate ideas and findings.},
	language = {en},
	author = {Flage, Roger and Aven, Terje},
	year = {2009},
	pages = {11},
}

@book{gardoni_multi-hazard_2016,
	address = {Cham},
	title = {Multi-hazard {Approaches} to {Civil} {Infrastructure} {Engineering}},
	isbn = {978-3-319-29711-8 978-3-319-29713-2},
	url = {http://link.springer.com/10.1007/978-3-319-29713-2},
	language = {en},
	urldate = {2022-02-14},
	publisher = {Springer International Publishing},
	editor = {Gardoni, Paolo and LaFave, James M.},
	year = {2016},
	doi = {10.1007/978-3-319-29713-2},
}

@phdthesis{kappes_multi-hazard_2011,
	address = {Austria},
	type = {Doctorate},
	title = {Multi-{Hazard} {Risk} {Analysis}: a {Concept} and its {Implementation}},
	language = {English},
	school = {University of Vienna},
	author = {Kappes, Melanie S.},
	year = {2011},
}

@article{korswagen_probabilistic_2019,
	title = {Probabilistic assessment of structural damage from coupled multi-hazards},
	volume = {76},
	issn = {01674730},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167473017304058},
	doi = {10.1016/j.strusafe.2018.08.001},
	abstract = {Evaluating and predicting structural damage from multi-hazards is a complex task mainly due to the varying ways in which hazards aﬀect structures. Also, diﬀerent damage scales that employ diﬀerent parameters and criteria are used for evaluating the hazards, making a connection between the damage assessment of two or more hazards diﬃcult. Attempting to compute the cumulated structural damage from various hazards becomes very diﬃcult with these limitations.},
	language = {en},
	urldate = {2022-02-14},
	journal = {Structural Safety},
	author = {Korswagen, P.A. and Jonkman, S.N. and Terwel, K.C.},
	month = jan,
	year = {2019},
	pages = {135--148},
}

@article{kwag_significance_2021,
	title = {Significance of multi-hazard risk in design of buildings under earthquake and wind loads},
	volume = {243},
	issn = {01410296},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0141029621007732},
	doi = {10.1016/j.engstruct.2021.112623},
	abstract = {Traditionally, external hazards are considered in the design of a building through the various combinations of loads prescribed in relevant design codes and standards. It is often the case that the design is governed by a single dominant hazard at a given geographic location. This is particularly true for earthquake and wind hazards, both of which impart time-dependent dynamic loads on the structure. Engineers may nevertheless wonder if a building designed for one of the two dominant hazards will satisfactorily withstand the other. Prior studies have indicated that in some cases, when a building is designed for a single dominant hazard, it does not necessarily provide satisfactory performance against the other hazard. In this paper, we propose a novel framework that builds upon performance-based design requirements and determines whether the design of a building is governed primarily by a single hazard or multiple hazards. It integrates site-dependent hazard characteristics with the performance criteria for a given building type and building geometry. The framework is consistent with the burgeoning area of probabilistic risk assessment, and yet can easily be extended to traditional, deterministically characterized design requirements as illustrated herein.},
	language = {en},
	urldate = {2022-02-14},
	journal = {Engineering Structures},
	author = {Kwag, Shinyoung and Gupta, Abhinav and Baugh, John and Kim, Hyun-Su},
	month = sep,
	year = {2021},
	pages = {112623},
}

@article{ming_quantitative_2022,
	title = {A quantitative multi-hazard risk assessment framework for compound flooding considering hazard inter-dependencies and interactions},
	volume = {607},
	issn = {00221694},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002216942200052X},
	doi = {10.1016/j.jhydrol.2022.127477},
	abstract = {Multi-hazard risk assessment may provide comprehensive analysis of the impact of multiple hazards but still needs to resolve major challenges in three aspects: (1) proper consideration of hazard inter-dependency, (2) physically based modelling of hazard interactions, and (3) fully quantitative risk assessment to show the prob­ ability of loss. Compound flooding is a typical multi-hazard problem that involves the concurrence of multiple hazard drivers, e.g. heavy rainfall, extreme river flow, and storm surge. These hazard drivers may result from the same weather system and are thus statistically inter-dependent, physically overlayed and interacted in the same region. This paper aims to address the mentioned challenges and develop an integrated assessment framework to quantify compound flood risk. The framework is constructed based on the three typical components in disaster risk assessment, i.e. hazard, vulnerability and exposure analysis. In hazard analysis, joint probability and return period distributions of the three hazard drivers of compound flooding are estimated using Copula functions with hazard dependency analysis, which are then used to generate random multi-hazard events to drive a 2D highperformance hydrodynamic model to produce probabilistic inundation maps and frequency-inundation curves. Vulnerability and exposure analysis provides damage functions of the elements at risk, which are used to quantify multi-hazard risk with the frequency-inundation curves. The framework is applied in the Greater London and its downstream Thames estuary to demonstrate its capability to analyse hazard interactions and inter-dependencies to produce fully quantitative risk assessment results such as risk curves quantifying the probability of loss and risk maps illustrating the annual expected loss of residential buildings.},
	language = {en},
	urldate = {2022-02-14},
	journal = {Journal of Hydrology},
	author = {Ming, Xiaodong and Liang, Qiuhua and Dawson, Richard and Xia, Xilin and Hou, Jingming},
	month = apr,
	year = {2022},
	pages = {127477},
}

@techreport{del_cul_triso-coated_2002,
	title = {{TRISO}-{Coated} {Fuel} {Processing} to {Support} {High} {Temperature} {Gas}-{Cooled} {Reactors}},
	url = {http://www.osti.gov/servlets/purl/814326/},
	language = {en},
	number = {ORNL/TM-2002/156, 814326},
	urldate = {2022-02-13},
	author = {Del Cul, G D},
	month = oct,
	year = {2002},
	doi = {10.2172/814326},
	pages = {ORNL/TM--2002/156, 814326},
}

@article{kiryushin_gt-mhr_nodate,
	title = {{GT}-{MHR} {SPENT} {FUEL} {STORAGE} {DISPOSAL} {WITHOUT} {PROCESSING}},
	abstract = {Possibility of GT-MHR spent fuel storage during long time without additional processing is discussed in this paper. Spent fuel elements discharged from this reactor type are ideal waste forms for permanent disposal in a geologic repository. The graphite fuel elements and the ceramic coatings on the fuel particles are as-manufactured engineered barriers that provide excellent near field containment of radionuclides and minimize reliance on the waste package and surrounding geologic media for long-term containment. Because of the high level of plutonium destruction and degradation achieved by GT-MHR, the isotopic composition of residual plutonium in spent fuel elements would not be practical for use in nuclear weapons and for energy production. Dilution of plutonium within the relatively large volume of GT-MHR fuel elements provides excellent resistance to diversion throughout the fuel cycle. This is accomplished without adversely impacting repository land requirements, since repository loading is determined by decay heat load and not by physical volume.},
	language = {en},
	author = {Kiryushin, A I and Kuzavkov, N G and Gushin, Yu L and Sukharev, Yu P and Chudin, A G and Richards, M and Shenoy, A and Diego, San},
	pages = {9},
}

@article{kiryushin_gt-mhr_1998,
	title = {{GT}-{MHR} spent fuel storage disposal without processing},
	url = {https://www.osti.gov/etdeweb/biblio/668244},
	abstract = {Possibility of GT-MHR spent fuel storage during long time without additional processing is discussed in this paper. Spent fuel elements discharged from this reactor type are ideal waste forms for permanent disposal in a geologic repository. The graphite fuel elements and the ceramic coatings on the fuel particles are as-manufactured engineered barriers that provide excellent near field containment of radionuclides and minimize reliance on the waste package and surrounding geologic media for long-term containment. Because of the high level of plutonium destruction and degradation achieved by GT-MHR, the isotopic composition of residual plutonium in spent fuel elements would not be practical for use in nuclear weapons and for energy production. Dilution of plutonium within the relatively large volume of GT-MHR fuel elements provides excellent resistance to diversion throughout the fuel cycle. This is accomplished without adversely impacting repository land requirements, since repository loading is determined by decay heat load and not by physical volume. These conditions of safe fuel storage: criticality conditions, conditions of decay heat removing and radiation doses are discussed as well. (author) 5 refs, 5 figs},
	language = {English},
	urldate = {2022-02-13},
	author = {Kiryushin, A. I. and Kuzavkov, N. G. and Gushin, Yu L. and Sukharev, Yu P. and Chudin, A. G. and Richards, M. and Shenoy, A.},
	month = sep,
	year = {1998},
}

@techreport{united_states_department_of_energy_assessment_2002,
	title = {Assessment of {GT}-{MHR} {Spent} {Fuel} {Characteristics} and {Repository} {Performance}.pdf},
	url = {https://art.inl.gov/NGNP/Subcontractors%20Documents/General%20Atomics/Assessment%20of%20GT-MHR%20Spent%20Fuel%20Characteristics%20and%20Repository%20Performance.pdf},
	language = {English},
	urldate = {2022-02-13},
	author = {United States Department of Energy},
	month = apr,
	year = {2002},
	pages = {72},
}

@article{nalebuff_minimal_1988,
	title = {Minimal {Nuclear} {Deterrence}},
	volume = {32},
	issn = {0022-0027, 1552-8766},
	url = {http://journals.sagepub.com/doi/10.1177/0022002788032003001},
	doi = {10.1177/0022002788032003001},
	abstract = {This article develops a rational theory of minimal nuclear deterrence: What is the minimal amount of weapons needed to maintain a stable balance of power? By searching for the requirements of minimal nuclear deterrence, we hope to gain a better understanding of how to proceed with arms reduction without compromising the value of deterrence.},
	language = {en},
	number = {3},
	urldate = {2022-02-12},
	journal = {Journal of Conflict Resolution},
	author = {Nalebuff, Barry},
	month = sep,
	year = {1988},
	pages = {411--425},
}

@article{rauzy_notes_2018,
	title = {Notes on {Computational} {Uncertainties} in {Probabilistic} {Risk}/{Safety} {Assessment}},
	volume = {20},
	issn = {1099-4300},
	url = {http://www.mdpi.com/1099-4300/20/3/162},
	doi = {10.3390/e20030162},
	language = {en},
	number = {3},
	urldate = {2022-02-11},
	journal = {Entropy},
	author = {Rauzy, Antoine},
	month = mar,
	year = {2018},
	pages = {162},
}

@article{rauzy_finite_2020,
	title = {Finite {Degradation} {Structures}},
	volume = {7},
	number = {2},
	journal = {IFCoLog Journal of Logic ant its Applications},
	author = {Rauzy, Antoine and Yang, Liu},
	year = {2020},
}

@article{rauzy_mathematical_2001,
	title = {Mathematical foundations of minimal cutsets},
	volume = {50},
	issn = {00189529},
	url = {http://ieeexplore.ieee.org/document/983400/},
	doi = {10.1109/24.983400},
	abstract = {Since their introduction in the reliability field, Binary Decision Diagrams have proved to be the most efficient tool to assess Boolean models such as fault trees. Their success increases the need of sound mathematical foundations for the notions that are involved in reliability and dependability studies. This paper clarifies the mathematical status of the notion of minimal cutsets which have a central role in fault-tree assessment. Algorithmic issues are discussed. Minimal cutsets are distinct from prime implicants and they have a great interest from both a computation complexity and practical viewpoint. Implementation of BDD algorithms is explained. All of these algorithms are implemented in the Aralia software, which is widely used. These algorithms and their mathematical foundations were designed to assess efficiently a very large noncoherent fault tree that models the emergency shutdown system of a nuclear reactor.},
	language = {en},
	number = {4},
	urldate = {2022-02-11},
	journal = {IEEE Transactions on Reliability},
	author = {Rauzy, A.},
	month = dec,
	year = {2001},
	pages = {389--396},
}

@inproceedings{knudsen_saphires_2019,
	address = {Charleston, South Carolina, USA},
	title = {{SAPHIRE}'s {Current} "{State} of {Practice}" to {Meet} {PRA} {Demans}},
	volume = {2/2},
	shorttitle = {International {Topical} {Meeting} on {Probabilistic} {Safety} {Assessment} and {Analysis} ({PSA} 2019)},
	language = {eng},
	author = {Knudsen, James and Wood, S. Ted and Smith, Curtis},
	month = may,
	year = {2019},
	note = {Meeting Name: International Topical Meeting on Probabilistic Safety Assessment and Analysis},
}

@inproceedings{rauzy_anatomy_2012,
	title = {Anatomy of an {Efficient} {Fault} {Tree} {Assessment} {Engine}},
	volume = {4},
	author = {Rauzy, Antoine},
	year = {2012},
	pages = {3333--3343},
}

@article{choi_technical_nodate,
	title = {Technical {Maturity} {Assessment} of {Risk}-{Informed} {Safety} {Analysis} {Tools}},
	language = {en},
	author = {Choi, Yong-Joon},
	pages = {7},
}

@article{kwag_development_2019,
	title = {Development of network-based probabilistic safety assessment: {A} tool for risk analyst for nuclear facilities},
	volume = {110},
	issn = {01491970},
	shorttitle = {Development of network-based probabilistic safety assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197018302452},
	doi = {10.1016/j.pnucene.2018.09.017},
	abstract = {The probabilistic safety assessment (PSA) methodology has been developed and utilized to assess the overall risks to a nuclear facility. However, PSAs are challenged when it comes to accurately describing relations among events, or to accommodate newly observed data, or to consider severe accident scenarios within a current framework. To overcome such challenges and take advantage of the merits of recent systems analysis concepts, this paper develops an improved PSA approach, by integrating the current fault tree-based PSA framework with a Bayesian network. The proposed approach enables one to account for event relations beyond logic gates, to incorporate additional ﬁeld observations and to conduct vulnerability assessments in an accident condition. To demonstrate the proposed Bayesian-based method, it is applied to a nuclear research reactor recently constructed in JUST, Irbid, Jordan. Several case studies are conducted to demonstrate how realistic information about events and from ﬁeld inspections changes the core damage risk. In addition, critical scenarios are investigated for an accident, to perform vulnerability assessment beyond a design-basis event. Consequently, it is shown that the proposed approach provides an enhanced framework for risk assessments at nuclear facilities. This framework is ultimately expected to improve decision support for risk-informed designs.},
	language = {en},
	urldate = {2022-02-11},
	journal = {Progress in Nuclear Energy},
	author = {Kwag, Shinyoung and Oh, Jinho},
	month = jan,
	year = {2019},
	pages = {178--190},
}

@article{wiltbank_dynamic_2021,
	title = {Dynamic {PRA} {Prospects} for the {Nuclear} {Industry}},
	volume = {9},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/articles/10.3389/fenrg.2021.750453/full},
	doi = {10.3389/fenrg.2021.750453},
	abstract = {This review paper highlights approaches and tools available to the nuclear industry for dynamic probabilistic risk assessment (DPRA) using dynamic event trees. DPRA is an emerging methodology that has advantages as compared to traditional, static PRA predominantly owing to the addition of time dependent modeling. Traditional PRAs predeﬁne events and outcomes into Event Trees (ET) and Fault Trees (FT), that are coupled with various combinations of Initiating Events (IE), Top Events (TE), branches, end states and sequences. A more complete depiction of the system and accident progression behavior can be quantiﬁed using DPRA to account for dynamic events such as those involving human actions. This paper discusses the strengths and needs of existing DPRA tools to align with the risk informed methodology currently used in the nuclear industry. DPRA is evolving during an exciting time in the nuclear industry with emerging advanced reactor designs also coming on the scene. Advanced nuclear (Gen IV) designs often incorporate passively safe systems that have less readily available data for traditional PRA due to their limited operating history. DPRA is a promising methodology that can address this challenge and demonstrate to the regulatory bodies and public that advanced designs operate within safety margins. In this light, the paper considers the historical role of PRA in the nuclear industry and motivation for considering dynamic PRA models. An introduction to the differences inherent in DPRA and how it complements and enhances existing PRA approaches is discussed. Additionally, a review of research from U.S national laboratories and universities features recent DPRA tool advancements that could be applied in the nuclear industry. These DPRA approaches and tools are summarized and examined to thoughtfully provide a path forward to best leverage existing research and integrate DPRA into advanced reactor design and analysis.},
	language = {en},
	urldate = {2022-02-11},
	journal = {Frontiers in Energy Research},
	author = {Wiltbank, Nathan E. and Palmer, Camille J.},
	month = nov,
	year = {2021},
	pages = {750453},
}

@inproceedings{vaishanav_limitations_2020,
	title = {Limitations of {Traditional} {PRA} {Tools} in {External} {Hazard} {Risk} {Assessment} for {Beyond} {Design} {Basis} {Events}},
	isbn = {9789811485930},
	url = {http://rpsonline.com.sg/proceedings/9789811485930/html/5741.xml},
	doi = {10.3850/978-981-14-8593-0_5741-cd},
	abstract = {Probabilistic risk assessment (PRA) is being used increasingly by the nuclear industry for safety during normal operations as well as for safeguards against external hazards. Computation of total risk in an external hazard PRA is dependent on fragility assessment and risk quantiﬁcation. A systems analysis for propagation of component fragilities is conducted using the fault and event trees. The event and fault trees for an actual power plant can be fairly large in size, which imposes computational challenges. Hence, certain assumptions are employed for computational efﬁciency. Originally, these assumptions were intended for use in design basis accident (DBA) scenarios. In recent years the conventional PRA tools, based on these assumptions and widely used in practice, have also been used for risk assessment in beyond design basis accident (BDBA) scenarios. This paper presents a case study to illustrate the effect of these assumptions when conventional approach is used in BDBA risk assessment. A simple illustrative example is used to show that assumptions are valid for the case of DBA conditions but lead to incorrect risk estimates in the case of BDBA conditions.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Proceedings of the 30th {European} {Safety} and {Reliability} {Conference} and 15th {Probabilistic} {Safety} {Assessment} and {Management} {Conference}},
	publisher = {Research Publishing Services},
	author = {Vaishanav, Pragya and Gupta, Abhinav and Bodda, Saran and Viallet, Emmanuel},
	year = {2020},
	pages = {4156--4161},
}

@inproceedings{gribok_advanced_2019,
	title = {Advanced {Probabilistic} {Risk} {Assessment} through {Continuous} {Fault} {Trees} using {R}-{Functions}},
	isbn = {978-981-11-2724-3},
	url = {http://rpsonline.com.sg/proceedings/9789811127243/html/0368.xml},
	doi = {10.3850/978-981-11-2724-3_0368-cd},
	abstract = {The current state-of-the-art in traditional, Level 1 probabilistic risk assessment (PRA) is the analysis of fault and event trees based on Boolean algebra and cut sets. This approach allows for the delineation of the response of a system to different initiating events and calculating the probability of the failure of a system under different scenarios. Despite its impressive success in the past, classical binary PRA has inherent and fundamental limitations. These limitations include the binary and deterministic nature of the traditional PRA framework, which limits the capability to model risk scenarios with partial (partially open valve), incomplete (wall thinning), and poorly understood (pump loss of power) failures. In addition, discovering the risk scenarios and optimization of the reliability of a system is difficult in the binary PRA framework. Addressing these limitations can significantly improve the quality, reliability, acceptability, and credibility of the PRA. This paper focuses on establishing the proof of principle that mathematically rigorous methodology can be developed that uses continuous fault trees, instead of binary choices. The proposed novel methodology is based on the theory of R-functions. Having converted the Boolean tree into an analytical function, it will now be possible to analyse this function in a continuous domain and apply all available analytical tools, including differentiation and integration, to study the properties of the function and optimize it with respect to the total probability of the system'.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Proceedings of the 29th {European} {Safety} and {Reliability} {Conference} ({ESREL})},
	publisher = {Research Publishing Services},
	author = {Gribok, Andrei and Wood, Ted},
	year = {2019},
	pages = {778--783},
}

@article{sofi_sensitivity-based_2020,
	title = {A {Sensitivity}-{Based} {Approach} for {Reliability} {Analysis} of {Randomly} {Excited} {Structures} {With} {Interval} {Axial} {Stiffness}},
	volume = {6},
	issn = {2332-9017, 2332-9025},
	url = {https://asmedigitalcollection.asme.org/risk/article/doi/10.1115/1.4047574/1084696/A-SensitivityBased-Approach-for-Reliability},
	doi = {10.1115/1.4047574},
	abstract = {Abstract
            Reliability assessment of linear discretized structures with interval parameters subjected to stationary Gaussian multicorrelated random excitation is addressed. The interval reliability function for the extreme value stress process is evaluated under the Poisson assumption of independent up-crossing of a critical threshold. Within the interval framework, the range of stress-related quantities may be significantly overestimated as a consequence of the so-called dependency phenomenon, which arises due to the inability of the classical interval analysis to treat multiple occurrences of the same interval variables as dependent ones. To limit undesirable conservatism in the context of interval reliability analysis, a novel sensitivity-based procedure relying on a combination of the interval rational series expansion and the improved interval analysis via extra unitary interval is proposed. This procedure allows us to detect suitable combinations of the endpoints of the uncertain parameters which yield accurate estimates of the lower bound and upper bound of the interval reliability function for the extreme value stress process. Furthermore, sensitivity analysis enables to identify the most influential parameters on structural reliability. A numerical application is presented to demonstrate the accuracy and efficiency of the proposed method as well as its usefulness in view of decision-making in engineering practice.},
	language = {en},
	number = {4},
	urldate = {2022-02-11},
	journal = {ASCE-ASME J Risk and Uncert in Engrg Sys Part B Mech Engrg},
	author = {Sofi, Alba and Muscolino, Giuseppe and Giunta, Filippo},
	month = dec,
	year = {2020},
	pages = {041008},
}

@article{alfonsi_risk_2022,
	title = {Risk analysis virtual {ENvironment} for dynamic event tree-based analyses},
	volume = {165},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921006307},
	doi = {10.1016/j.anucene.2021.108754},
	abstract = {Conventional Event-Tree (ET) based methodologies are extensively used as tools to perform reliability and safety assessment of complex and critical engineering systems. One of the disadvantages of these methods is that timing/sequencing of events and system dynamics is not explicitly accounted for in the analysis. In order to overcome these limitations several techniques, also known as Dynamic Probabilistic Risk Assessment (DPRA), have been developed. Monte-Carlo (MC) and Dynamic Event Tree (DET) are two of the most widely used DPRA methodologies to perform safety assessment of Nuclear Power Plants (NPP). Since 2012, the Idaho National Laboratory (INL) is developing its own tool to perform Dynamic PRA: RAVEN (Risk Analysis and Virtual ENvironment). RAVEN has been designed in a high modular and pluggable way to enable easy integration of different programming languages (i.e., Python, C++) and coupling with other application including, among the others, several thermal–hydraulic and severe accident codes (e.g., RELAP5-3D, MELCOR, MAAP5, TRACE, etc.). RAVEN is aimed to provide a framework/container of capabilities for engineers and scientists to analyze the response of systems, physics and multi-physics, employing advanced numerical techniques and algorithms. Moreover, RAVEN models stochastic events, such as components failures, and performs uncertainty quantiﬁcation (UQ). Such stochastic modeling is employed by using sampling strategies among which both MC and DET algorithms, which are going to be employed in this paper. In addition, RAVEN processes the large amount of data generated by sampling the physical models using data-mining based algorithms and risk assessment techniques. This paper provides an overview of the DET methodologies that have been deployed within the RAVEN framework, showing the potential of such techniques for the analysis of complex systems. A brief background of classical methodologies and their limitation is also reported and represent the motivation for the deployment of such dynamic technique. In addition, results from a pressurized water reactor loss of coolant accident scenario, using RELAP5-3D as physical model, are reported.},
	language = {en},
	urldate = {2022-02-11},
	journal = {Annals of Nuclear Energy},
	author = {Alfonsi, Andrea and Mandelli, Diego and Parisi, Carlo and Rabiti, Cristian},
	month = jan,
	year = {2022},
	pages = {108754},
}

@inproceedings{zhou_design_2018,
	address = {London, England},
	title = {Design and {Development} of {DeRisk}: {A} {Fault} {Tree} {Analysis} {Program} {Package}},
	isbn = {978-0-7918-5144-9},
	shorttitle = {Design and {Development} of {DeRisk}},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE26/51449/London,%20England/273329},
	doi = {10.1115/ICONE26-81291},
	abstract = {Fault tree analysis (FTA) has been proven to be a very important tool and has been successfully applied to safety/reliability studies in nuclear, chemical, military, space industries/systems. Hitherto, several useful and popular FTA software/program packages have been developed, like CAFTA+, FAUNET, RiskSpectrum, SAPHIRE, RiskA etc. Minimum Cut Set (MCS) method is the most commonly used traditional FTA method. However, it suffers from low efficiency when solving remarkably large fault trees (FTs). To overcome the shortcomings of the traditional method, several new techniques are proposed such as Binary Decision Diagram (BDD), Zero-suppressed Binary Decision Diagram, (ZBDD) Petri Net (PN), Bayesian Network (BN) and Dynamic Uncertain Causality Graph (DUCG). DUCG is a newly presented Probabilistic Graphic Model to deal with systems with dynamics, uncertainties and logic cycles. DUCG is a good choice to analyze large FTs, in our previous papers, we have proved that any FT can be mapped into a DUCG graph and additional modeling and analytical power can be achieved. DeRisk is a DUCG embedded risk analysis program package written in C\# for FTA and is designed as a powerful tool to assist reliability engineers. In this paper, the design schema and the main algorithms of DeRisk are introduced. DeRisk contains five parts: (1) A Graphical User Interface (GUI) Module which interacts with users; (2) A Preprocessing Module which preprocesses FTs (3) An Input Module which allows user to input necessary data by file or by command line; (4) A Calculation Module which offers qualitative/quantitative analysis; (5) An Output Module which outputs the results required by users. Some illustrative examples are used to verify the correctness and effectiveness of DeRisk.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Volume 2: {Plant} {Systems}, {Structures}, {Components}, and {Materials}; {Risk} {Assessments} and {Management}},
	publisher = {American Society of Mechanical Engineers},
	author = {Zhou, Zhenxu and Nie, Hao and Zhang, Qin},
	month = jul,
	year = {2018},
	pages = {V002T14A008},
}

@article{alfonsi_raven_2013,
	title = {{RAVEN} {AS} {A} {TOOL} {FOR} {DYNAMIC} {PROBABILISTIC} {RISK} {ASSESSMENT}: {SOFTWARE} {OVERVIEW}},
	abstract = {RAVEN is a software tool under development at the Idaho National Laboratory (INL) that acts as the control logic driver and post-processing tool for the newly developed Thermal-Hydraulic code RELAP7. The scope of this paper is to show the software structure of RAVEN and its utilization in connection with RELAP-7. A short overview of the mathematical framework behind the code is presented along with its main capabilities such as on-line controlling/monitoring and Monte-Carlo sampling. A demo of a Station Black Out PRA analysis of a simpliﬁed Pressurized Water Reactor (PWR) model is shown in order to demonstrate the Monte-Carlo and clustering capabilities.},
	language = {en},
	author = {Alfonsi, A and Rabiti, C and Mandelli, D and Cogliati, J J and Kinoshita, R A},
	year = {2013},
	pages = {15},
}

@article{alfonsi_dynamic_nodate,
	title = {Dynamic {Event} {Tree} {Analysis} {Through} {RAVEN}},
	abstract = {Conventional Event-Tree (ET) based methodologies are extensively used as tools to perform reliability and safety assessment of complex and critical engineering systems. One of the disadvantages of these methods is that timing/sequencing of events and system dynamics is not explicitly accounted for in the analysis. In order to overcome these limitations several techniques, also know as Dynamic Probabilistic Risk Assessment (DPRA), have been developed. Monte-Carlo (MC) and Dynamic Event Tree (DET) are two of the most widely used D-PRA methodologies to perform safety assessment of Nuclear Power Plants (NPP). In the past two years, the Idaho National Laboratory (INL) has developed its own tool to perform Dynamic PRA: RAVEN (Reactor Analysis and Virtual control ENvironment). RAVEN has been designed in a high modular and pluggable way in order to enable easy integration of different programming languages (i.e., C++, Python) and coupling with other application including the ones based on the MOOSE framework, developed by INL as well. RAVEN performs two main tasks: 1) control logic driver for the new Thermo-Hydraulic code RELAP-7 and 2) post-processing tool. In the ﬁrst task, RAVEN acts as a deterministic controller in which the set of control logic laws (user deﬁned) monitors the RELAP-7 simulation and controls the activation of speciﬁc systems. Moreover, RAVEN models also stochastic events, such as components failures, and performs uncertainty quantiﬁcation. Such stochastic modeling is employed by using both MC and DET algorithms. In the second task, RAVEN processes the large amount of data generated by RELAP-7 using data-mining based algorithms. This paper focuses on the ﬁrst task and shows how it is possible to perform the analysis of dynamic stochastic systems using the newly developed RAVEN DET capability. As an example, the Dynamic PRA analysis, using Dynamic Event Tree, of a simpliﬁed pressurized water reactor for a Station Black-Out scenario is presented.},
	language = {en},
	author = {Alfonsi, A and Rabiti, C and Mandelli, D and Cogliati, J J and Kinoshita, R A and Naviglio, A},
	pages = {13},
}

@article{rochon_conversion_nodate,
	title = {Conversion of {Risk} {Model} from {RiskSpectrum} to {CAFTA}},
	abstract = {There are several software packages available for the development and maintenance of a Probabilistic Safety Assessment (PSA) model. Each of these packages varies in complexity and functionality in different areas of model development. RiskSpectrum® software and CAFTA are two popular software packages with differing capabilities and usability in certain functional areas. One specific example is the application of Boundary Condition (BC) sets. The RiskSpectrum software integrates the ability to change event values dynamically throughout an accident’s progression, whereas basic event values are static through the quantification process until postprocessing, creating results which are more straightforward to understand and troubleshoot, but without the additional functionality provided by the BC sets. These differences mean that complex PRA models cannot easily be converted between the two software platforms. For example, two equivalent fault trees - one in a RiskSpectrum model with BC sets which change event values dynamically and one in CAFTA without BC sets - can yield different results during quantification. Other areas in which differences exist between the RiskSpectrum software and CAFTA are: event trees and their integration with the quantification, common cause calculations, and the handling of mutually-exclusive logic and post-processing rules. For example, the mutually-exclusive logic in CAFTA can be used to control logic in the fault tree in such a way as to mimic the BC sets of the RiskSpectrum software.},
	language = {en},
	author = {Rochon, Chris and Trull, Carroll and Remlinger, Donald and Labarge, N Reed},
	pages = {9},
}

@book{rauzy_probabilistic_2020,
	title = {Probabilistic {Safety} {Analysis} with {XFTA}},
	isbn = {978-82-692273-0-7},
	publisher = {ALTARICA ASSOCIATION},
	author = {Rauzy, Antoine B.},
	year = {2020},
}

@techreport{noauthor_energy_1995,
	title = {Energy, {Electricity} and {Nuclear} {Power} {Estimates} for the {Period} {Up} to 2050.},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/RDS-1-41_web.pdf},
	language = {en},
	urldate = {2022-02-08},
	institution = {International Atomic Energy Agency},
	month = nov,
	year = {1995},
	pages = {430},
}

@inproceedings{grimmeisen_demonstration_2021,
	address = {Virtual, Online},
	title = {Demonstration of a {Limited} {Scope} {Probabilistic} {Risk} {Assessment} for {Autonomous} {Warehouse} {Robots} {With} {OpenPRA}},
	isbn = {978-0-7918-8569-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85697/V013T14A030/1133316},
	doi = {10.1115/IMECE2021-69998},
	abstract = {Abstract
            Probabilistic Risk Assessment (PRA) is an indispensable technology to evaluate the risk, dependability, and resilience characteristics of safety-critical systems. Therefore, PRA uses widely adopted methods, such as classical event trees, fault trees, Markov chains, Bayesian networks, and their numerous combinations. To analyze challenging failure scenarios of modern, intelligent, autonomous, and highly dynamic Cyber-Physical Systems (CPS), the integration of multiple PRA methods is needed. This paper presents a PRA approach based on classical Event Tree Analysis (ETA) and Fault Tree Analysis (FTA) and provides the technical description of a new open-source software platform called OpenPRA. Besides, this paper describes a representative case study from the autonomous system domain, focusing on autonomous warehouse robots.},
	urldate = {2022-02-04},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Grimmeisen, Philipp and Karimov, Artur and Diaconeasa, Mihai A. and Morozov, Andrey},
	month = nov,
	year = {2021},
	pages = {V013T14A030},
}

@inproceedings{polat_use_2021,
	address = {Virtual, Online},
	title = {On the {Use} of {Probabilistic} {Risk} {Assessment} for the {Protection} of {Small} {Modular} {Reactors} {Against} {Terrorist} {Attacks}},
	isbn = {978-0-7918-8569-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85697/V013T14A049/1133303},
	doi = {10.1115/IMECE2021-71504},
	abstract = {Abstract
            Safety and security are two of the most important requirements of the nuclear industry. In the event of a potential problem, the consequences can have serious implications for the public and the environment. Measures should be taken against various hazards and threats by analyzing possible realistic scenarios. Therefore, probabilistic risk assessment is one of the necessary technologies to achieving safe and secure nuclear facilities. In the study, a limited scope probabilistic risk assessment was made for a possible terrorist attack against a generic small modular reactor (SMR). A possible attack threat was selected to develop scenarios by following a probabilistic risk assessment approach.
            In the scenarios created, terrorists have to pass all physical barriers that security guards protect. Thus, the decisions and actions of the security guards directly affect the result of the attack. To analyze these events, a human reliability assessment (HRA) was employed. In the first study, each security guard’s decision-making process was analyzed using the Standardized Plant Analysis Risk Human Reliability Assessment (SPAR-H) method. The purpose of its use in this study is to verify the SPAR-H method’s applicability for security applications.
            In this paper, we give the likelihoods of each security guard making a decision and taking action to prevent terrorists from passing obtained using the SPAR-H method. Besides, event tree and fault tree analyses were performed using the SAPHIRE PRA software.
            Finally, since the current HRA methods were designed for control room operators, we introduce a new model-based HRA methodology applicable for security guards to be used in physical security PRAs.},
	urldate = {2022-02-04},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Polat, Burak and Diaconeasa, Mihai A.},
	month = nov,
	year = {2021},
	pages = {V013T14A049},
}

@inproceedings{polat_modeling_2021,
	address = {Virtual, Online},
	title = {On the {Modeling} of {Wildfires}-{Induced} {Release} and {Atmospheric} {Dispersion} in {Radioactively} {Contaminated} {Regions}},
	isbn = {978-0-7918-8569-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85697/V013T14A037/1133288},
	doi = {10.1115/IMECE2021-71460},
	abstract = {Abstract
            Nuclear energy is one of the most efficient types of electricity production. However, it is one of the biggest fears of people due to the potential radiation effects on human health. Despite the major developments in the nuclear sector, some gaps need to be studied for the higher safety scrutiny of nuclear power plants (NPPs). Besides technical advances for the safer management of an NPP, another important part is having a well-constructed and planned probabilistic risk assessment and management. Realistic probabilistic risk assessment and management provide proper emergency response in case of an accident or hazardous situation to human health. On the other hand, aside from the radiation emitted directly from radioactive sources inside the NPP, there may be indirect radiation emission from dispersions outside the plant’s protected area. For example, we can look at forest fires occurring in radioactively contaminated areas surrounding NPPs that suffered accidents with releases, such as Chernobyl or Fukushima Daiichi. Radioactive particles produced by burning contaminated forests could spread in the air and threaten public health. It has already been observed that fires in forests around Chernobyl can increase the level of radiation in the air. Such events have the possibility to occur in all areas where nuclear facilities are located. The forests contaminated after the Fukushima Daiichi NPP accident, resemble the ones at Chernobyl. This study aims to develop the knowledge for an early sensing and emergency response by doing an atmospheric dispersion modeling and supporting a probabilistic risk assessment for a wildfire scenario in radioactively contaminated areas, such as Chernobyl and Fukushima Daiichi. Also, this study provides a pathway to assessing the risk of nuclear contamination caused by wildfires around nuclear facilities.},
	urldate = {2022-02-04},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Polat, Damla and Diaconeasa, Mihai A.},
	month = nov,
	year = {2021},
	pages = {V013T14A037},
}

@inproceedings{pandit_quantitative_2021,
	address = {Virtual, Online},
	title = {A {Quantitative} {Approach} to {Assess} the {Likelihood} of {Supply} {Chain} {Shortages}},
	isbn = {978-0-7918-8569-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85697/V013T14A023/1133260},
	doi = {10.1115/IMECE2021-73696},
	abstract = {Abstract
            We define supply chains (SCs) as sequences of processes that link the demand and supply of goods or services within a network. SCs are prone to shortages in delivering their output goals due to several factors such as personnel undersupply, inefficient processes, policy failure, equipment malfunction, natural hazards, pandemic outbreaks, power outages, or economic crises. Recent notable supply-chain failures include the 2021 Texas power crisis, personal protection equipment shortages during the COVID-19 pandemic, and regional or global food chain shortages. The consequences of such shortages can range from negligible to devastating. The Texas power crisis resulted in the death of 70 people and left approximately 4.5 billion homes and businesses without power for multiple days.
            In this paper, we presented a methodology to quantify the failure probability of the throughput of a supply chain. We divided the methodology into two major categories of steps. In the first step, we converted the given or assumed supply chain data into fault trees and quantify them. In the second step, we iterated the quantification of the fault tree to build a supply chain shortage risk profile. We introduced the notion of success criteria for the output from a facility, based on which we included or excluded the facility for quantification.
            With the inclusion of relevant field data, we believe that our methodology can enable the stakeholders in the supply-chain decision-making process to detect vulnerable facilities and risk-inform prevention and mitigation actions. Applications for this methodology can include construction, inventory stocking, assessing manufacturing quantities, policy changes, personnel allocation, and financial investment for critical industries such as nuclear, pharmaceutical, aviation, etc.},
	urldate = {2022-02-04},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Pandit, Priyanka and Earthperson, Arjun and Tezbasaran, Alp and Diaconeasa, Mihai A.},
	month = nov,
	year = {2021},
	pages = {V013T14A023},
}

@inproceedings{earthperson_verification_2021,
	address = {Virtual, Online},
	title = {Verification {Study} of the {Nuclear} {PRA} for the {Mars} 2020 {Mission} {Following} {Accidental} {Orbital} {Re}-{Entry}},
	isbn = {978-0-7918-8569-7},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2021/85697/V013T14A019/1133290},
	doi = {10.1115/IMECE2021-71359},
	abstract = {Abstract
            Today, Probabilistic Risk Assessment (PRA) plays a vital role in assuring mission success for robotic and crewed missions alike. Current-day PRA techniques integrate multimodal, often black-box analyses to build comprehensive risk profiles. This paper describes a review and verification study of the “Nuclear Risk Assessment for the Mars 2020 Mission Environmental Impact Statement” (N-PRA)[1]. Sandia National Labs conducted the N-PRA for NASA’s Jet Propulsion Laboratory (JPL). More specifically, we have verified the source term calculations associated with the release of radionuclides from a Multi-Mission Radiothermoelectic Generator (MMRTG) power source for a limited set of accident scenarios in the case of an accidental re-entry into Earth Orbit with an Earth impacting trajectory.
            We achieve this by using analytical methods[2] historically implemented for the Cassini Mission PRA[3] for a failed planetary swingby gravity-assist. Our results are within 28\% to 56\% of the referenced study. Limitations in our methodology are attributed to a lack of modern simulation-based tools and deterministic methods for modeling complex physical phenomena. The results are interpreted and compared with the values presented by the initial authors, along with comments for improving our current methodology.},
	urldate = {2022-02-04},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}; {Research} {Posters}},
	publisher = {American Society of Mechanical Engineers},
	author = {Earthperson, Arjun and Diaconeasa, Mihai A.},
	month = nov,
	year = {2021},
	pages = {V013T14A019},
}

@misc{noauthor_open-psa_nodate,
	title = {The {Open}-{PSA} {Model} {Exchange} {Format} — {The} {Open}-{PSA} {Model} {Exchange} {Format} 2.0},
	url = {https://open-psa.github.io/mef/},
	urldate = {2022-02-02},
}

@techreport{noauthor_building_nodate,
	title = {Building {Resilient} {Supply} {Chains}, {Revitalizing} {American} {Manufacturing}, and {Fostering} {Broad}-{Based} {Growth}.},
	url = {https://www.whitehouse.gov/wp-content/uploads/2021/06/100-day-supply-chain-review-report.pdf},
	institution = {The White House},
}

@article{chen_numerical_2021,
	title = {Numerical simulation of transient overflow characteristics in {CCS} pump building after the main feed water pipe of {SG} ruptures},
	volume = {385},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S002954932100491X},
	doi = {10.1016/j.nucengdes.2021.111539},
	abstract = {The feed water pipes of steam generators (SG) stretch across the pump building of the component cooling water system (CCS), thereby connecting the reactor containment and the steam turbine building in the pressurized water reactor of a nuclear power plant. When main feed water pipes rupture, large quantities of water and steam may discharge into the CCS pump building, which causes the CCS pumps to be submerged and the CCS system to shut down, thereby threatening the safety of nuclear power plants. Therefore, it is necessary to analyze the overflow characteristics after such an accident. However, it is difficult to perform experiments in the CCS pump building, owing to its huge area and complex structure. In this study, numerical simulation was performed via computational fluid dynamics by using the volume of fluid model, in which three phases (water, air, and steam) were considered. Validation \& Verification (V\&V) is performed by comparing the calculated results with experimental verification of the small model, so that the reliability of the calculation method and results are proved. Overflow characteristics in three different accidental conditions were also analyzed: the pump trip accident triggered by double-end fracture (TDEF), pump trip accident triggered by conservative maximum flow rate discharge (TmaxD), and pump trip accident not triggered by a fracture (TnotF) in the pressure compartment. It has been revealed that under TDEF and TmaxD, the maximum water level around the two CCS pumps is lower than the waterproof foundation bed of the CCS pumps. However, under TnotF, the highest water level around the two CCS pumps is much higher than the waterproof foundation bed of the CCS pumps, which may threaten their safety. To address this problem, certain new optimization design schemes have also been proposed.},
	language = {en},
	urldate = {2022-01-31},
	journal = {Nuclear Engineering and Design},
	author = {Chen, Zijia and Lu, Daogang and Zhao, Haiqi and Zhang, Yuhao},
	month = dec,
	year = {2021},
	keywords = {Flood prevention, Large advanced Pressurized Water Reactor, Overflow design optimization, Three-dimensional flow characteristics, VOF model},
	pages = {111539},
}

@book{koren_cafta_1987,
	address = {Germany},
	title = {{CAFTA}: {A} fault tree analysis tool designed for {PSA}},
	isbn = {3-88585-417-1},
	url = {http://inis.iaea.org/search/search.aspx?orig_q=RN:20061750},
	abstract = {The CAFTA workstation to streamline many of the PSA analysis steps and provide the
utility with a maintainable PSA model It supports a PSA methodology commonly in use
today, which includes the use of modularized fault trees, linking and evaluation of
accident sequence level models, and recovery, uncertainty, and importance analyses
on the resulting cut sets In today's environment, utilities are requiring PSA models
to be functional well after the initial study is completed This requires that the
models be in a maintainable form CAFTA can be used to support not only the initial
PSA process, but also the utilities' continuing use of the models for decision-making
(orig)},
	publisher = {Verl TUEV Rheinland},
	author = {Koren, J.M. and Gaertner, J.},
	year = {1987},
}

@techreport{noauthor_analysis_1980,
	address = {Palo Alto, Nuclear Safety Analysis Center, USA},
	title = {Analysis of {Three} {Mile} {Island}-{Unit} 2 accident},
	url = {https://inis.iaea.org/collection/NCLCollectionStore/_Public/13/677/13677904.pdf},
	abstract = {The Nuclear Safety Analysis Center (NSAC) of the Electric Power Research Institute
has analyzed the Three Mile Island-2 accident Early results of this analysis were
a brief narrative summary, issued in mid-May 1979 and an initial version of this report
issued later in 1979 as noted in the Foreword The present report is a revised version
of the 1979 report, containing summaries, a highly detailed sequence of events, a
comparison of that sequence of events with those from other sources, 25 appendices,
references and a list of abbreviations and acronyms A matrix of equipment and system
actions is included as a folded insert},
	number = {EPRI-NSAC--80-1},
	institution = {Electric Power Research Institute},
	month = mar,
	year = {1980},
	pages = {527},
}

@misc{noauthor__nodate,
	title = {§ 52.157 {Contents} of applications; technical information in final safety analysis report.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part052/part052-0157.html},
	urldate = {2022-01-26},
	journal = {NRC Web},
}

@misc{noauthor__nodate-1,
	title = {§ 52.79 {Contents} of applications; technical information in final safety analysis report.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part052/part052-0079.html},
	urldate = {2022-01-26},
	journal = {NRC Web},
}

@article{jang_empirical_2013,
	title = {An empirical study on the basic human error probabilities for {NPP} advanced main control room operation using soft control},
	volume = {257},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549313000186},
	doi = {10.1016/j.nucengdes.2013.01.003},
	abstract = {By adopting new human–system interfaces that are based on computer-based technologies, the operation environment of main control rooms (MCRs) in nuclear power plants (NPPs) has changed. The MCRs that include these digital and computer technologies, such as large display panels, computerized procedures, soft controls, and so on, are called Advanced MCRs. Among the many features in Advanced MCRs, soft controls are an important feature because the operation action in NPP Advanced MCRs is performed by soft control. Using soft controls such as mouse control, touch screens, and so on, operators can select a specific screen, then choose the controller, and finally manipulate the devices. However, because of the different interfaces between soft control and hardwired conventional type control, different basic human error probabilities (BHEPs) should be considered in the Human Reliability Analysis (HRA) for advanced MCRs. Although there are many HRA methods to assess human reliabilities, such as Technique for Human Error Rate Prediction (THERP), Accident Sequence Evaluation Program (ASEP), Human Error Assessment and Reduction Technique (HEART), Human Event Repository and Analysis (HERA), Nuclear Computerized Library for Assessing Reactor Reliability (NUCLARR), Cognitive Reliability and Error Analysis Method (CREAM), and so on, these methods have been applied to conventional MCRs, and they do not consider the new features of advance MCRs such as soft controls. As a result, there is an insufficient database for assessing human reliabilities in advanced MCRs. In this paper, BHEPs in a soft control operation environment are investigated empirically for BHEPs to apply advanced MCRs. A soft control operation environment is constructed by using a compact nuclear simulator (CNS), which is a mockup for advanced MCRs. Before the experiments, all tasks that should be performed by subjects are analyzed using one of the task analysis methods, Systematic Human Error Reduction and Prediction Approach (SHERPA). Human errors are then checked to analyze BHEPs, human error mode, and the cause of human error when using soft control.},
	language = {en},
	urldate = {2022-01-26},
	journal = {Nuclear Engineering and Design},
	author = {Jang, Inseok and Kim, Ar Ryum and Harbi, Mohamed Ali Salem Al and Lee, Seung Jun and Kang, Hyun Gook and Seong, Poong Hyun},
	month = apr,
	year = {2013},
	pages = {79--87},
}

@article{jang_human_2016,
	title = {Human error and the associated recovery probabilities for soft control being used in the advanced {MCRs} of {NPPs}},
	volume = {87},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454915004557},
	doi = {10.1016/j.anucene.2015.09.011},
	abstract = {Since the Three Mile Island (TMI)-2 accident, human error has been recognized as one of the main causes of Nuclear Power Plant (NPP) accidents, and numerous studies related to Human Reliability Analysis (HRA) have been carried out. Most of these studies were focused on considering the conventional Main Control Room (MCR) environment. However, the operating environment of MCRs in NPPs has changed with the adoption of new human-system interfaces (HSI) largely based on up-to-date digital technologies. The MCRs that include these digital and computer technologies, such as large display panels, computerized procedures, and soft controls, are called advanced MCRs. Among the many features of advanced MCRs, soft controls are a particularly important because operating actions in advanced MCRs are performed by soft control. Due to the difference in interfaces between soft control and hardwired conventional controls, different HEP should be used in the HRA for advanced MCRs. Unfortunately, most current HRA databases deal with operations in conventional MCRs and are not explicitly designed to deal with digital Human System Interface (HSI). For this reason, empirical human error and the associated error recovery probabilities were collected from the mockup of an advanced MCR equipped with soft controls. To this end, small-scaled experiments are conducted with 48 graduated students in the department of nuclear engineering in Korea Advanced Institute of Science and Technology (KAIST) are participated, and accident scenarios are designed with respect to the typical Design Basis Accidents (DBAs) in NPPs, such as Steam Generator Tube Rupture (SGTR), Loss of Coolant Accident (LOCA) and Excess Steam Demand Event (ESDE). After that, the Bayesian update is conducted in order to extract the 5\% and 95\% quantiles of empirical human error and the associated recovery failure probabilities.},
	language = {en},
	urldate = {2022-01-26},
	journal = {Annals of Nuclear Energy},
	author = {Jang, Inseok and Jung, Wondea and Seong, Poong Hyun},
	month = jan,
	year = {2016},
	keywords = {Advanced MCR, Human error probability, Recovery failure probabilities, Soft control},
	pages = {290--298},
}

@article{kim_advanced_2016,
	title = {Advanced operation strategy for feed-and-bleed operation in an {OPR1000}},
	volume = {90},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454915005903},
	doi = {10.1016/j.anucene.2015.11.038},
	abstract = {When the secondary side is unavailable in a pressurized water reactor (PWR), heat from the core will accumulate in the primary side causing core damage. In this situation a heat removal mechanism called feed-and-bleed operation (F\&B operation) must be used, which is a process of directly cooling the primary reactor cooling system (RCS). However, conventional operation strategy in emergency operating procedures (EOPs) does not cover all possible conditions to initiate F\&B operation. If the EOP informs on the urgency of F\&B operation, operators will be able to more clearly make decisions regarding F\&B operation initiation. In order to cover all possible scenarios for F\&B operation and systematically inform its urgency, an advanced operating strategy using a decision tree is developed in this study. The plant condition can be classified according to failure of secondary side, RCS pressure condition, injectable inventory to RCS, and remaining core inventory. RCS pressure, core level, and RCS temperature are representative indicators which provide information regarding the initiation of F\&B operation. Indicators can be selected based on their detectability and quantification, and a decision tree is developed according to combinations of indicators. To estimate the effects of the advanced operation strategy, human error probability (HEP) of F\&B operation is re-estimated based on a thermohydraulic analysis. The available time for operators to initiate F\&B operation is also re-estimated to obtain more realistic data. This study is expected to provide a systematic operation strategy to initiate F\&B operation under various plant situations. An OPR1000 is used in this study as an example plant, with the resulting advanced operating strategy able to be applied to most PWRs which have F\&B operation capability.},
	language = {en},
	urldate = {2022-01-26},
	journal = {Annals of Nuclear Energy},
	author = {Kim, Bo Gyung and Yoon, Ho Joon and Kim, Jaewhan and Kang, Hyun Gook},
	month = apr,
	year = {2016},
	keywords = {Emergency operating procedure, Feed-and-bleed operation, OPR1000, Operation strategy},
	pages = {32--43},
}

@article{shin_stpa-based_2021,
	title = {{STPA}-{Based} {Hazard} and {Importance} {Analysis} on {NPP} {Safety} {I}\&{C} {Systems} {Focusing} on {Human}–{System} {Interactions}},
	volume = {213},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832021002349},
	doi = {10.1016/j.ress.2021.107698},
	abstract = {To ensure system safety, conducting required control actions (CAs) in time at the right place is essential. Among the CAs, safety critical ones such as reactor trip signals in a nuclear power plant are preferentially and automatically generated by the instrumentation and control (I\&C) system. If necessary, however, they can also be generated manually by human operators. Even for manual CAs, though, the I\&C system is still needed to convey relevant feedback to the human operators. It is therefore indispensable to analyze the risk associated with the transmission of feedback to the human operators in terms of the condition of the I\&C system. In this context, System-Theoretic Process Analysis (STPA) can provide a framework to link the conditions of the I\&C system with the feedback transmission for manual CA generation. Based on STPA, this study proposes a method to analyze I\&C system hazards and assess the relative importance of system components in terms of human–system interactions, or more specifically, feedback transmission for manual CA generation. As a feasibility study, the method is applied to an example case requiring reactor trip signal generation in the Advanced Power Reactor 1400 (APR-1400).},
	language = {en},
	urldate = {2022-01-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Shin, SUNG-MIN and Lee, SANG HUN and Shin, SEUNG KI and Jang, INSEOK and Park, JINKYUN},
	month = sep,
	year = {2021},
	keywords = {Human-system Interaction, I\&C, NPP, STPA},
	pages = {107698},
}

@article{liu_methodology_2022,
	title = {Methodology for dynamic reliability assessment of team situation awareness of digital nuclear power plants},
	volume = {144},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S014919702100439X},
	doi = {10.1016/j.pnucene.2021.104086},
	abstract = {Team situation awareness (TSA) reliability is an important factor for team reliability. Moreover, situation awareness (SA) is a prominent problem in digital nuclear power plants (NPPs). Currently, since there is no suitable method to dynamically assess TSA reliability, we constructed a dynamical assessment method of TSA reliability based on a dynamic Bayesian network (DBN) to evaluate TSA reliability. First of all, a TSA causal concept model through qualitative analysis, expert group discussion and sample data analysis. On this basis, the quantitative assessment method of TSA reliability was constructed based on DBN and obtained probability distribution of variables. A standardized method was established to obtain the probability distribution of variables. Furthermore, we evaluated TSA dynamic reliability in a steam generator tube rupture (SGTR) accident. The results showed that the error probability of TSA decreased, and the level of TSA reliability continuously increased in SGTR. TSA reliability can be dynamically predicted by causal reasoning, the most important cause of TSA error could be identified by diagnostic reasoning, which provided theoretical support for the targeted prevention of human error. Finally, this established method was proved to be reasonable through sensitivity analysis.},
	language = {en},
	urldate = {2022-01-26},
	journal = {Progress in Nuclear Energy},
	author = {Liu, Yahua and Jin, Xiao and Luo, Zhuhua and Dai, Licao and Liu, Zhen and Li, Pengcheng},
	month = feb,
	year = {2022},
	keywords = {Digital nuclear power plants, Dynamic Bayesian network, Human reliability analysis, Team situation awareness},
	pages = {104086},
}

@article{ramezani_human_2020,
	title = {Human error probability quantification for {NPP} post-accident analysis using {Cognitive}-{Based} {THERP} method},
	volume = {123},
	issn = {0149-1970},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197020300408},
	doi = {10.1016/j.pnucene.2020.103281},
	abstract = {Human Reliability Analysis (HRA) studies human actions from the safety point of view, modeling the most important of them and assessing their probabilities. The Technique for Human Error Rate Prediction (THERP) is a classical HRA approach that models Human Error Probability (HEP) for a specific action regardless of the human cognitive process. Another HRA method is Human Cognitive Reliability (HCR) that expresses the non-response probability as a function of available time regarding the performance type and ignores other affecting factors. In this study, the strengths of the Deterministic Safety Analysis (DSA), THERP and HCR are integrated to form a systematic framework introduced as Cognitive Based THERP (CB-THERP) method to calculate HEP for the Nuclear Power Plant (NPP) post-accident analysis. The calculated values of HEP during the Total Loss of Feedwater (TLFW) accident reveal that a better Human-Machine Interface (HMI) condition reduces HEP. However, operators' higher training level compensates even the worst HMI. In addition, the HMI condition has the greatest impact on an averaged-knowledge Main Control Room (MCR) operator and then an expert and a novice. Dependency almost doesn't influence the worst HMI condition and it much affects highly trained operators when the HMI condition is excellent. Also, the calculated HEP values from the Standardized Plant Analysis Risk-Human Reliability (SPAR-H) and CB-THERP methods for different cases of the scenario have similar trend while THERP calculates a fixed value for them.},
	language = {en},
	urldate = {2022-01-26},
	journal = {Progress in Nuclear Energy},
	author = {Ramezani, Ahmad and Nazari, Tooraj and Rabiee, Ataollah and Hadad, Kamal and Faridafshin, Mohammadjavad},
	month = may,
	year = {2020},
	keywords = {Cognitive-based THERP, DSA, Human reliability analysis, Main control room personnel, SPAR-H, TLFW},
	pages = {103281},
}

@misc{iaea_advances_2020,
	title = {Advances in {Small} {Modular} {Reactor} {Technology} {Developments} {A} {Supplement} to {IAEA} {Advanced} {Reactors} {Information} {System} ({ARIS})},
	publisher = {IAEA},
	author = {IAEA},
	year = {2020},
}

@techreport{kaiser_engineers_div_henry_j_kaiser_co_oakland_calif_study_1960,
	title = {{STUDY} {OF} {REMOTE} {MILITARY} {POWER} {APPLICATIONS} {REPORT} {NO}. 1. {SUMMARY}},
	url = {http://www.osti.gov/servlets/purl/4132375-2RMerr/native/},
	abstract = {Report, a S e l e c t i o n of Applicable lieactor Concepts Report, and t e n s i t e reports. A complete l i s t of a l l reports comprising t h e study i s contained i n t h e Appendix.},
	language = {en},
	number = {NYO-2937, 4132375},
	urldate = {2022-01-25},
	author = {{Kaiser Engineers Div., Henry J. Kaiser Co., Oakland, Calif.}},
	month = jan,
	year = {1960},
	doi = {10.2172/4132375},
	pages = {NYO--2937, 4132375},
}

@book{doyle_nuclear_2008,
	address = {Amsterdam ; Boston},
	title = {Nuclear safeguards, security and nonproliferation: achieving security with technology and policy},
	isbn = {978-0-7506-8673-0},
	shorttitle = {Nuclear safeguards, security and nonproliferation},
	publisher = {Butterworth-Heinemann},
	editor = {Doyle, James E.},
	year = {2008},
	note = {OCLC: ocn226280922},
	keywords = {Case studies, Materials Management, Materials management, Nuclear facilities, Nuclear industry, Nuclear nonproliferation, Nuclear terrorism, Nuclear weapons, Prevention, Security measures},
}

@misc{noauthor_small_nodate,
	title = {Small nuclear power reactors - {World} {Nuclear} {Association}},
	url = {http://www.world-nuclear.org/information-library/nuclear-fuel-cycle/nuclear-power-reactors/small-nuclear-power-reactors.aspx},
	urldate = {2022-01-21},
}

@misc{noauthor_high-temperature_nodate,
	title = {High-{Temperature} {Gas}-{Cooled} {Reactors}},
	url = {https://www.oecd-nea.org/jcms/pl_20497/high-temperature-gas-cooled-reactors},
	abstract = {High-temperature gas-cooled reactors (HTGRs), also known as very-high-temperature reactors (VHTR) are Generation IV reactors that can operate at very high temperatures and use a graphite-moderated gas-cooled nuclear reactor with a once-through uranium fuel cycle.},
	language = {en},
	urldate = {2022-01-21},
	journal = {Nuclear Energy Agency (NEA)},
}

@incollection{iwatsuki_overview_2021,
	title = {Overview of high temperature gas-cooled reactor},
	isbn = {978-0-12-821031-4},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128210314000014},
	language = {en},
	urldate = {2022-01-21},
	booktitle = {High {Temperature} {Gas}-{Cooled} {Reactors}},
	publisher = {Elsevier},
	author = {Iwatsuki, Jin and Kunitomi, Kazuhiko and Mineo, Hideaki and Nishihara, Tetsuo and Sakaba, Nariaki and Shinozaki, Masayuki and Tachibana, Yukio and Yan, Xing},
	year = {2021},
	doi = {10.1016/B978-0-12-821031-4.00001-4},
	pages = {1--16},
}

@book{noauthor_high_nodate,
	title = {High {Temperature} {Gas}-cooled {Reactors}},
	url = {https://web.s.ebscohost.com/ehost/ebookviewer/ebook/bmxlYmtfXzI1MTg5MjRfX0FO0?sid=d438c40f-e9ca-4066-b8f0-d6176c01d5c7@redis&vid=0&format=EB&rid=1},
	number = {978-0-12-821031-4},
	urldate = {2022-01-21},
}

@article{smith_published_nodate,
	title = {Published on behalf of the lnternational {Commission} on {Radiological} {Protection}},
	language = {en},
	author = {Smith, H},
	pages = {108},
}

@article{williams_purdue_1994,
	title = {The {Purdue} enterprise reference architecture},
	volume = {24},
	issn = {01663615},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0166361594900175},
	doi = {10.1016/0166-3615(94)90017-5},
	language = {en},
	number = {2-3},
	urldate = {2022-01-18},
	journal = {Computers in Industry},
	author = {Williams, Theodore J.},
	month = sep,
	year = {1994},
	pages = {141--158},
}

@book{zio_computational_2009,
	series = {Series on {Quality}, {Reliability} and {Engineering} {Statistics}},
	title = {Computational {Methods} for {Reliability} and {Risk} {Analysis}},
	volume = {14},
	isbn = {978-981-283-901-5 978-981-283-902-2},
	url = {https://www.worldscientific.com/worldscibooks/10.1142/7190},
	language = {en},
	urldate = {2022-01-18},
	publisher = {World Scientific Publishing Company},
	author = {Zio, Enrico},
	month = jan,
	year = {2009},
	doi = {10.1142/7190},
}

@article{smith_published_nodate-1,
	title = {Published on behalf of the lnternational {Commission} on {Radiological} {Protection}},
	language = {en},
	author = {Smith, H},
	pages = {108},
}

@article{mandelli_mutual_2021,
	title = {Mutual {Integration} of {Classical} and {Dynamic} {PRA}},
	volume = {207},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2020.1776030},
	doi = {10.1080/00295450.2020.1776030},
	language = {en},
	number = {3},
	urldate = {2022-01-18},
	journal = {Nuclear Technology},
	author = {Mandelli, Diego and Alfonsi, Andrea and Wang, Congjian and Ma, Zhegang and Parisi, Carlo and Aldemir, Tunc and Smith, Curtis and Youngblood, Robert},
	month = mar,
	year = {2021},
	pages = {363--375},
}

@article{noauthor_airborne_nodate,
	title = {"{Airborne} {Particle} {Resuspension} and {Inhalation} {Radiological} {Dose} {Estimation} {Following} {Volcanic} {Events}."},
	language = {en},
	pages = {15},
}

@incollection{romanovsky_efficient_2019,
	address = {Cham},
	title = {Efficient {Model}-{Level} {Reliability} {Analysis} of {Simulink} {Models}},
	volume = {11698},
	isbn = {978-3-030-26600-4 978-3-030-26601-1},
	url = {http://link.springer.com/10.1007/978-3-030-26601-1_10},
	language = {en},
	urldate = {2022-01-18},
	booktitle = {Computer {Safety}, {Reliability}, and {Security}},
	publisher = {Springer International Publishing},
	author = {Ding, Kai and Morozov, Andrey and Janschek, Klaus},
	editor = {Romanovsky, Alexander and Troubitsyna, Elena and Bitsch, Friedemann},
	year = {2019},
	doi = {10.1007/978-3-030-26601-1_10},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {139--154},
}

@book{haugen_safety_2018,
	edition = {1},
	title = {Safety and {Reliability} – {Safe} {Societies} in a {Changing} {World}},
	isbn = {978-1-351-17466-4},
	url = {https://www.taylorfrancis.com/books/9781351174657},
	language = {en},
	urldate = {2022-01-18},
	publisher = {CRC Press},
	editor = {Haugen, Stein and Barros, Anne and van Gulijk, Coen and Kongsvik, Trond and Vinnem, Jan Erik},
	month = jun,
	year = {2018},
	doi = {10.1201/9781351174664},
}

@inproceedings{morozov_aadl-based_2018,
	address = {Reno, NV},
	title = {{AADL}-{Based} {Stochastic} {Error} {Propagation} {Analysis} for {Reliable} {System} {Design} of a {Medical} {Patient} {Table}},
	isbn = {978-1-5386-2870-6},
	url = {https://ieeexplore.ieee.org/document/8463141/},
	doi = {10.1109/RAM.2018.8463141},
	urldate = {2022-01-18},
	booktitle = {2018 {Annual} {Reliability} and {Maintainability} {Symposium} ({RAMS})},
	publisher = {IEEE},
	author = {Morozov, Andrey and Mutzke, Thomas and Ren, Boqi and Janschek, Klaus},
	month = jan,
	year = {2018},
	pages = {1--7},
}

@inproceedings{morozov_stochastic_2016,
	address = {Leipzig, Germany},
	title = {Stochastic {Error} {Propagation} {Analysis} of {Model}-driven {Space} {Robotic} {Software} {Implemented} in {Simulink}},
	isbn = {978-1-4503-4259-9},
	url = {http://dl.acm.org/citation.cfm?doid=3022099.3022103},
	doi = {10.1145/3022099.3022103},
	language = {en},
	urldate = {2022-01-18},
	booktitle = {Proceedings of the 3rd {Workshop} on {Model}-{Driven} {Robot} {Software} {Engineering} - {MORSE} '16},
	publisher = {ACM Press},
	author = {Morozov, Andrey and Janschek, Klaus and Krüger, Thomas and Schiele, André},
	year = {2016},
	pages = {24--31},
}

@misc{openpra_community_openpra_2019,
	title = {{OpenPRA} {Initiative}},
	url = {https://openpra.org/},
	language = {en-US},
	urldate = {2022-01-17},
	author = {{OpenPRA Community}},
	month = apr,
	year = {2019},
}

@book{noauthor_ieee_2018,
	address = {Place of publication not identified},
	title = {{IEEE} {Std} 3006.8-2018: {IEEE} {Recommended} {Practice} for {Analyzing} {Reliability} {Data} for {Equipment} {Used} in {Industrial} and {Commercial} {Power} {Systems}.},
	isbn = {978-1-5044-5029-4},
	shorttitle = {{IEEE} {Std} 3006.8-2018},
	url = {https://ieeexplore.ieee.org/servlet/opac?punumber=8490825},
	language = {English},
	urldate = {2022-01-17},
	publisher = {IEEE},
	year = {2018},
	note = {OCLC: 1066118147},
}

@book{gertman_human_1994,
	address = {New York},
	title = {Human reliability and safety analysis data handbook},
	isbn = {978-0-471-59110-8},
	publisher = {Wiley},
	author = {Gertman, David and Blackman, Harold S.},
	year = {1994},
	keywords = {Human engineering, Reliability (Engineering), Risk assessment, Safety factor in engineering},
}

@techreport{vivek_agarwal_youssef_a_ballout_jess_c_gehin_fission_2021,
	title = {Fission {Battery} {Initiative} - {Research} and {Development} {Plan}},
	url = {https://nuc1.inl.gov/SiteAssets/Fission%20Battery%20Initiative/Fission%20Battery%20R%26D%20Plan%20INL-EXT-21-61275.pdf},
	abstract = {The Fission Battery Initiative has been established by Idaho National Laboratory’s (INL’s) Nuclear Science and Technology Directorate to define, focus, and coordinate research and development of technologies that can fully achieve battery-like functionality for nuclear energy systems. The notion of a “fission battery” conveys a vision focused on realizing very simple “plug-and- play” nuclear systems that can be integrated into a variety of applications requiring affordable, reliable energy in the form of electricity and/or heat and function without operations and maintenance staff. In order to formalize the desired functionality, the initiative has adopted the following key attributes to be achieved: economic, standardized, installed, unattended and reliable.
The initiative will conduct fundamental research and development—i.e., from Technology Readiness Level 1 (basic principles) through 5 (technology demonstration) to innovate and demonstrate enabling technologies to achieve fission battery attributes.
This document introduces the Fission Battery Initiative’s vision, fission- battery attributes, and the initial scope of targeted R\&D planned through 2024.},
	language = {English},
	number = {INL/EXT-21-61275},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {{Vivek Agarwal, Youssef A. Ballout, Jess C. Gehin}},
	month = jan,
	year = {2021},
}

@techreport{rasmussen_reactor_1975,
	title = {Reactor safety study. {An} assessment of accident risks in {U}. {S}. commercial nuclear power plants. {Executive} summary: main report. [{PWR} and {BWR}]},
	shorttitle = {Reactor safety study. {An} assessment of accident risks in {U}. {S}. commercial nuclear power plants. {Executive} summary},
	url = {https://www.osti.gov/biblio/7134131},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WASH-1400-MR; NUREG-75/014-MR},
	urldate = {2021-08-25},
	institution = {Nuclear Regulatory Commission, Washington, D.C. (USA)},
	author = {Rasmussen},
	month = oct,
	year = {1975},
	doi = {10.2172/7134131},
}

@techreport{john_d_belson_military_1964,
	title = {Military {Nuclear} {Power} {Plants}},
	shorttitle = {{WL} {TDR}-64-25},
	url = {https://apps.dtic.mil/sti/pdfs/AD0602678.pdf},
	language = {English},
	author = {{John D. Belson}},
	month = jun,
	year = {1964},
	pages = {208},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors} {Selection} and {Evaluation} of {Licensing} {Basis} {Events}},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-19-55513-Rev1},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = mar,
	year = {2020},
	doi = {10.2172/1560529},
}

@misc{noauthor_prism_nodate,
	title = {{PRISM} - {Probabilistic} {Symbolic} {Model} {Checker}},
	url = {https://www.prismmodelchecker.org/},
	urldate = {2022-01-10},
}

@article{pidd_object-orientation_1995,
	title = {Object-{Orientation}, {Discrete} {Simulation} and the {Three}-{Phase} {Approach}},
	volume = {46},
	issn = {01605682},
	url = {https://www.jstor.org/stable/2584330?origin=crossref},
	doi = {10.2307/2584330},
	number = {3},
	urldate = {2022-01-08},
	journal = {The Journal of the Operational Research Society},
	author = {Pidd, Michael},
	month = mar,
	year = {1995},
	pages = {362},
}

@inproceedings{steven_prescott_curtis_smith_leng_vang_emrald_2018,
	address = {Los Angeles, CA},
	title = {{EMRALD}, {Dynamic} {PRA} for the {Traditional} {Modeler}},
	url = {http://www.iapsam.org/psam14/proceedings/paper/paper_76_1.pdf},
	abstract = {Recently, dynamic probabilistic risk assessment (DPRA) has been used by risk researchers to analyze problems that are either difficult or impossible to solve using traditional fault tree and event tree methods. Several tools have been developed and are helping to advance system safety. However, multiple disciplines use traditional PRA modeling practices and have built advanced and complex models of their systems and DPRA modeling techniques would see faster and more wide-spread adoption if model creation and associated tools corresponded closer to traditional methods.
A new modeling approach was implemented in Event Modeling Risk Assessment using Linked Diagrams (EMRALD) which incorporates the following features:
- An intuitive web-based graphical user interface for modeling.
- Traditional modeling aspects including basic events, fault trees, and event trees, are all captured in a dynamic stat diagram model.
- An Open framework for simple coupling with physics codes.
After running an EMRALD model, the user is able to not only obtain probabilistic results, but can also analyze the timing and ordering of events. Additionally, a coupling framework for physics codes, allows the user to incorporate and then determine when complex phenomena simulation, such as flood or fire analysis, is important to model accuracy.},
	language = {English},
	author = {{Steven Prescott, Curtis Smith, Leng Vang}},
	month = sep,
	year = {2018},
	pages = {12},
}

@misc{analysis_mbsa-tudopenerrorpro_2022,
	title = {mbsa-tud/{OpenErrorPro}},
	copyright = {GPL-3.0},
	url = {https://github.com/mbsa-tud/OpenErrorPro},
	abstract = {Stochastic Error Propagation Analysis},
	urldate = {2022-01-10},
	author = {Analysis, Model-based System},
	month = jan,
	year = {2022},
	note = {original-date: 2018-04-05T16:17:06Z},
}

@misc{nathan_siu_dynamic_nodate,
	title = {Dynamic {PRA} for {Nuclear} {Power} {Plants}: {Not} {If} {But} {When}?},
	url = {https://www.nrc.gov/docs/ML1906/ML19066A390.pdf},
	abstract = {This paper, which is aimed at NRC staff, provides my views on the promise, current status, challenges (technical and otherwise), and near-term path forward for dynamic PRA at the NRC. It also provides some cautions to prospective reviewers of a dynamic PRA, and numerous references for readers interested in more information. The purpose of the paper is to help NRC staff: a) develop an improved understanding of dynamic PRA, and b) formulate potential future activities in the area.},
	language = {English},
	publisher = {US NRC},
	author = {{Nathan Siu}},
}

@article{morozov_dual_2011,
	title = {Dual {Graph} {Error} {Propagation} {Model} for {Mechatronic} {System} {Analysis}},
	volume = {44},
	issn = {14746670},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667016452018},
	doi = {10.3182/20110828-6-IT-1002.03371},
	language = {en},
	number = {1},
	urldate = {2022-01-08},
	journal = {IFAC Proceedings Volumes},
	author = {Morozov, Andrey and Janschek, Klaus},
	month = jan,
	year = {2011},
	pages = {9893--9898},
}

@article{morozov_dual_2011-1,
	title = {Dual {Graph} {Error} {Propagation} {Model} for {Mechatronic} {System} {Analysis}},
	volume = {44},
	issn = {14746670},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667016452018},
	doi = {10.3182/20110828-6-IT-1002.03371},
	language = {en},
	number = {1},
	urldate = {2022-01-07},
	journal = {IFAC Proceedings Volumes},
	author = {Morozov, Andrey and Janschek, Klaus},
	month = jan,
	year = {2011},
	pages = {9893--9898},
}

@misc{ev_oekode_oko-institut_nodate,
	title = {Öko-{Institut} e.{V}. (oeko.de)},
	url = {https://www.oeko.de/publikationen/p-details},
	abstract = {Das Öko-Institut ist eine der europaweit führenden, unabhängigen Forschungs- und Beratungseinrichtungen für eine nachhaltige Zukunft.},
	language = {en},
	urldate = {2022-01-04},
	author = {e.V. (oeko.de), Öko-Institut},
}

@inproceedings{moormann_safety_2009,
	title = {A {Safety} {Re}-{Evaluation} of the {AVR} {Pebble} {Bed} {Reactor} {Operation} and {Its} {Consequences} for {Future} {HTR} {Concepts}},
	url = {https://www.asmedigitalcollection.asme.org/HTR/proceedings/HTR2008/48555/265/335281},
	doi = {10.1115/HTR2008-58336},
	language = {en},
	urldate = {2022-01-04},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Moormann, Rainer},
	month = jul,
	year = {2009},
	pages = {265--274},
}

@inproceedings{noauthor_consequences_1996,
	title = {Consequences of the {Chernobyl} {Accident} for the {Natural} and {Human} {Environments}},
	url = {https://www.osti.gov/servlets/purl/391712},
	author = {, Dreicer et al.},
	year = {1996},
}

@techreport{international_atomic_energy_agency_one_nodate,
	title = {{ONE} {DECADE} {AFTER} {CHERNOBYL} {Summing} up the {Consequences} of the {Accident}},
	author = {{INTERNATIONAL ATOMIC ENERGY AGENCY} and {VIENNA, 1996}},
}

@misc{noauthor_ml18082a044pdf_nodate,
	title = {{ML18082A044}.pdf},
}

@article{papazoglou_master_2003,
	title = {Master {Logic} {Diagram}: method for hazard and initiating event identification in process plants},
	volume = {97},
	issn = {0304-3894},
	shorttitle = {Master {Logic} {Diagram}},
	url = {https://www.sciencedirect.com/science/article/pii/S0304389402002443},
	doi = {10.1016/S0304-3894(02)00244-3},
	abstract = {Master Logic Diagram (MLD), a method for identifying events initiating accidents in chemical installations, is presented. MLD is a logic diagram that resembles a fault tree but without the formal mathematical properties of the latter. MLD starts with a Top Event “Loss of Containment” and decomposes it into simpler contributing events. A generic MLD has been developed which may be applied to all chemical installations storing toxic and/or flammable substances. The method is exemplified through its application to an ammonia storage facility.},
	language = {en},
	number = {1},
	urldate = {2021-12-13},
	journal = {Journal of Hazardous Materials},
	author = {Papazoglou, I. A and Aneziris, O. N},
	month = feb,
	year = {2003},
	keywords = {Ammonia storage, Hazard identification, Initiating events, Master Logic Diagram, Quantified risk assessment},
	pages = {11--30},
}

@article{purba_master_2018,
	title = {Master {Logic} {Diagram}: {An} {Approach} to {Identify} {Initiating} {Events} of {HTGRs}},
	volume = {962},
	issn = {1742-6596},
	shorttitle = {Master {Logic} {Diagram}},
	url = {https://doi.org/10.1088/1742-6596/962/1/012036},
	doi = {10.1088/1742-6596/962/1/012036},
	abstract = {Initiating events of a nuclear power plant being evaluated need to be firstly identified prior to applying probabilistic safety assessment on that plant. Various types of master logic diagrams (MLDs) have been proposedforsearching initiating events of the next generation of nuclear power plants, which have limited data and operating experiences. Those MLDs are different in the number of steps or levels and different in the basis for developing them. This study proposed another type of MLD approach to find high temperature gas cooled reactor (HTGR) initiating events. It consists of five functional steps starting from the top event representing the final objective of the safety functions to the basic event representing the goal of the MLD development, which is an initiating event. The application of the proposed approach to search for two HTGR initiating events, i.e. power turbine generator trip and loss of offsite power, is provided. The results confirmed that the proposed MLD is feasiblefor finding HTGR initiating events.},
	language = {en},
	urldate = {2021-12-13},
	journal = {Journal of Physics: Conference Series},
	author = {Purba, J. H.},
	month = feb,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {012036},
}

@book{noauthor_fukushima_2015,
	address = {Vienna},
	title = {The {Fukushima} {Daiichi} {Accident} {Report} by the {Director} {General} ; {Technical} {Volume} 1/5, {Description} and {Context} of the {Accident} ; {Technical} {Volume} 2/5, {Safety} {Assessment} ; {Technical} {Volume} 3/5, {Emergency} {Preparedness} and {Response} ; {Technical} {Volume} 4/5, {Radiological} {Consequences} ; {Technical} {Volume} 5/5, {Post}-accident {Recovery} ; {Annexes}},
	isbn = {978-92-0-107015-9},
	language = {en},
	publisher = {IAEA},
	year = {2015},
	note = {OCLC: 926729005},
}

@article{higley_environmental_2006,
	title = {Environmental consequences of the chernobyl accident and their remediation: twenty years of experience. {Report} of the chernobyl forum expert group ‘environment’},
	volume = {121},
	issn = {1742-3406, 0144-8420},
	shorttitle = {Environmental consequences of the chernobyl accident and their remediation},
	url = {http://academic.oup.com/rpd/article/121/4/476/1616456/Environmental-consequences-of-the-chernobyl},
	doi = {10.1093/rpd/ncl163},
	language = {en},
	number = {4},
	urldate = {2021-12-13},
	journal = {Radiation Protection Dosimetry},
	author = {Higley, Kathryn A.},
	month = dec,
	year = {2006},
	pages = {476--477},
}

@techreport{muhlheim_identification_2013,
	address = {OAK RIDGE NATIONAL LABORATORY Oak Ridge, Tennessee 37831-6283},
	title = {{IDENTIFICATION} {OF} {INITIATING} {EVENTS} {FOR} {aSMRS}},
	language = {en},
	number = {DE-AC05-00OR22725},
	institution = {OAK RIDGE NATIONAL LABORATORY},
	author = {Muhlheim, M D},
	month = jun,
	year = {2013},
	pages = {51},
}

@book{noauthor_sources_2014,
	title = {Sources, {Effects} and {Risks} of {Ionizing} {Radiation}, {Unscear} 2013 {Report} {Levels} and {Effects} of {Radiation} {Exposure} {Due} to the {Nuclear} {Accident} {After} the 2011 {Great} {East}-japan {Earthquake} ...},
	isbn = {978-92-1-056501-1},
	language = {en},
	publisher = {United Nations Pubns},
	year = {2014},
	note = {OCLC: 922280662},
}

@book{united_nations_sources_2000,
	address = {New York},
	title = {Sources and effects of ionizing radiation: {United} {Nations} {Scientific} {Committee} on the {Effects} of {Atomic} {Radiation}: {UNSCEAR} 2000 report to the {General} {Assembly}, with scientific annexes},
	isbn = {978-92-1-142238-2 978-92-1-142239-9},
	shorttitle = {Sources and effects of ionizing radiation},
	language = {en},
	publisher = {United Nations},
	editor = {United Nations},
	year = {2000},
	note = {OCLC: ocm45228885},
	keywords = {Environmental Exposure, Health aspects, Ionizing radiation, Radiation Injuries},
}

@article{sandhu_external_2019,
	title = {{EXTERNAL} {MULTI}-{HAZARD} {PROBABILISTIC} {RISK} {ASSESSMENT} {METHODOLOGY} {AND} {APPLICATIONS}: {A} {REVIEW} {OF} {THE} {STATE}- {OF}-{THE}-{ART}},
	language = {en},
	author = {Sandhu, Harleen Kaur and Patel, Parth and Gupta, Abhinav and Mihara, Yoshinori},
	year = {2019},
	pages = {10},
}

@article{fleming_use_2018,
	title = {Use of {PRA} to {Select} {Licensing} {Basis} {Events}},
	abstract = {The purpose of this paper is to summarize key elements of the risk-informed and performance-based methods developed within the Industry led Licensing Modernization Project (LMP). The LMP is jointly sponsored by the U.S. Department of Energy and the U.S. nuclear industry to assist the U.S. Nuclear Regulatory Commission (NRC) in the development of regulatory guidance for advanced non-light water reactors currently under development in the U.S. The purpose of this paper is to summarize a risk-informed and performance based approach for the selection and evaluation of LBEs for advanced non-LWRs. This paper summarizes the approach which builds on a PRA model that is introduced early in the design process and provides examples for selected advanced non-LWR technologies.},
	language = {en},
	journal = {Los Angeles},
	author = {Fleming, Karl and Wallace, Edward and Afzali, Amir},
	year = {2018},
	pages = {12},
}

@article{xu_research_2019,
	title = {Research on {Time}-{Dependent} {Failure} {Modeling} {Method} of {Integrating} {Discrete} {Dynamic} {Event} {Tree} {With} {Fault} {Tree}},
	volume = {7},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/article/10.3389/fenrg.2019.00074/full},
	doi = {10.3389/fenrg.2019.00074},
	abstract = {Classical PRA methods such as Fault Tree Analysis (FTA) and Event Tree Analysis (ETA) are characterized as static methods due to predetermined event sequences and success criteria of frontline systems. They are widely accepted for risk analysis of nuclear power plants. Unlike classical PRA, Dynamic PRA (DPRA) couples the stochastic random failures of system with deterministic analysis (by simulation) to determine the risk level of complex systems. It considers the safety signiﬁcance of the timing and order of events on accident progression and consequences. However, it is time-consuming to establish a complicated full-scope system simulation model. Meanwhile, thousands of accident scenarios are generated due to randomness of state transition, uncertainty of model and parameters. An overload of modeling, calculating, and post-processing will arise. So, it is a prospective and challenging idea to integrate the classical PRA method with the dynamic PRA method. The objective of this paper is to address an integrated method of risk quantiﬁcation of accident scenarios. It points out how to treat time-dependent interactions of accident dynamics including random failures, temporal events, conﬁguration changes, and physical process parameters explicitly. Possible dependencies and conﬁguration consistency issues accounting for Discrete Event Tree (DET) branch probabilities are discussed. For DET simulation, some of non-safe-related components to be analyzed could be modeled by FTs for conditional branching probability, instead of a computationally expensive simulation model. A method of integrating FT into DET is introduced which emphasizes on computing the conditional branch probability with FTs online, as well as developing a DET model in case of temporal relations of failure. Finally, a simple case of a Low Pressure Injection System in Large Break Loss-of-Coolant Accident (LBLOCA) scenario is provided as a demonstration.},
	language = {en},
	urldate = {2021-12-06},
	journal = {Frontiers in Energy Research},
	author = {Xu, Anqi and Zhang, Zhijian and Zhang, Min and Wang, He and Zhang, Huazhi and Chen, Sijuan},
	month = aug,
	year = {2019},
	pages = {74},
}

@techreport{noauthor_status_2011,
	title = {Status report 96 - {High} {Temperature} {Gas} {Cooled} {Reactor} - {Pebble}-{Bed} {Module} ({HTR}-{PM})},
	url = {https://aris.iaea.org/PDF/HTR-PM.pdf},
	language = {English},
	urldate = {2021-12-06},
	month = oct,
	year = {2011},
	pages = {18},
}

@inproceedings{boring_human_2016,
	title = {{HUMAN} {UNIMODEL} {FOR} {NUCLEAR} {TECHNOLOGY} {TO} {ENHANCE} {RELIABILITY} ({HUNTER}): {A} {FRAMEWORK} {FOR} {COMPUTATIONAL}-{BASED} {HUMAN} {RELIABILITY} {ANALYSIS}},
	shorttitle = {{HUMAN} {UNIMODEL} {FOR} {NUCLEAR} {TECHNOLOGY} {TO} {ENHANCE} {RELIABILITY} ({HUNTER})},
	abstract = {A computation-based human reliability analysis framework called the Human Unimodel for Nuclear Technology to Enhance Reliability (HUNTER) has been developed as part of the Risk Informed Safety Margin Characterization (RISMC) pathway within the U.S. Department of Energy's Light Water Reactor Sustainability Program that aims to extend the life of the currently operating fleet of U.S. commercial nuclear power plants. HUNTER is a flexible hybrid approach that functions as a framework for dynamic modeling, including a simplified model of human cognition—a virtual operator—that produces relevant outputs such as the human error probability (HEP), time spent on task, or task decisions based on relevant plant evolutions. HUNTER is the human reliability analysis counterpart to the Risk Analysis in a Virtual ENvironment (RAVEN) framework used for dynamic probabilistic risk assessment. Although both RAVEN and HUNTER are under various stages of development, this paper presents a successfully integrated and implemented RAVEN-HUNTER initial demonstration. The demonstration centers on a station blackout scenario, using complexity as the sole virtual operator performance-shaping factor (PSF). The implementation of RAVEN-HUNTER can be readily scaled to other nuclear power plant scenarios of interest and will include additional PSFs in the future.},
	author = {Boring, Ronald and Mandelli, Diego and Skogstad, Martin and Ewing, Sarah and Ulrich, Thomas and Groth, Katrina and Smith, Curtis},
	month = oct,
	year = {2016},
}

@article{chang_sacada_2018,
	title = {{SACADA} {Data} for {HEP} {Estimates}},
	abstract = {The Scenario Authorizing, Characterization, and Debriefing Application (SACADA) software was developed to collect nuclear plants’ operator performance information in simulator training to provide data basis to inform human reliability analysis (HRA), specifically human error probability (HEP) estimates. The software supports HRA as well as operator training to achieve objectives of assessing human reliability and improving human reliability. The U.S. Nuclear Regulatory Commission (NRC) sponsors the SACADA software development aiming the software to be regularly used by nuclear power plants (NPPs) in operator simulator training. To achieve this objective, the software provides functions to facilitate operator simulator training such as authoring simulation scenarios, facilitating post-simulation debriefing, expediting crew performance communication, and exporting information for statistical analysis of crew performance. The intention is that NPPs use the software for operator training and share the collected performance information with the NRC for HRA. Since the first version of the software piloted by an NPP in 2012, the software has been used by a few NPPs inside and outside of the United States. In 2017, the NRC awarded contracts to three contractors to perform an independent analysis of the available SACADA data to propose methods of using SACADA data to inform HEP estimates. The contractors presented their proposed methods in an international HRA data workshop on March 15 and 16, 2018 at the NRC headquarters at Rockville Maryland. This paper discusses the SACADA program, a summary of the methods proposed by the three NRC contractors, and the NRC ongoing and planned HRA data activities.},
	language = {en},
	journal = {Los Angeles},
	author = {Chang, Yung Hsien James and Franklin, Carmen},
	year = {2018},
	pages = {9},
}

@article{mulder_xe-100_nodate,
	title = {Xe-100: {Aspects} of {Design} {Important} to its {Safety} {Considerations}},
	language = {en},
	author = {Mulder, Eben},
	pages = {32},
}

@techreport{kadambi_guidance_2002,
	title = {Guidance for {Performance}-{Based} {Regulation}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/brochures/br0303/br0303.pdf},
	number = {NUREG/BR-0303},
	urldate = {2021-11-24},
	author = {Kadambi, N. P.},
	month = dec,
	year = {2002},
}

@techreport{noauthor_performance-based_2021,
	title = {Performance-{Based} {Licensing} {Methodology}},
	url = {https://www.nrc.gov/docs/ML2118/ML21187A001.pdf},
	urldate = {2021-11-17},
	institution = {Oklo, Inc.},
	month = jul,
	year = {2021},
}

@techreport{noauthor_introduction_nodate,
	type = {Prepared for the {U}.{S}. {Department} of {Energy} {Office} of {Nuclear} {Energy} {Under} {DOE} {Idaho} {Operations} {Office} {Contract} {DE}-{AC07}-{05ID14517}},
	title = {Introduction to {Implementation} and {Assessment} of {Safety} for {Risk}-{Informed} and {Performance}-{Based} {Technical} {Requirements} in {Non}-{Light} {Water} {Reactors}},
	number = {Draft Report Revision 1},
}

@techreport{noauthor_maximum_2021,
	title = {Maximum {Credible} {Accident} {Methodology}},
	url = {https://www.nrc.gov/docs/ML2118/ML21187A001.pdf},
	language = {en},
	institution = {Oklo, Inc.},
	month = jul,
	year = {2021},
	pages = {40},
}

@article{bley_strengths_1992,
	title = {The strengths and limitations of {PSA}: where we stand},
	volume = {38},
	issn = {09518320},
	shorttitle = {The strengths and limitations of {PSA}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209290102Q},
	doi = {10.1016/0951-8320(92)90102-Q},
	language = {en},
	number = {1-2},
	urldate = {2021-11-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Bley, Dennis and Kaplan, Stan and Johnson, David},
	month = jan,
	year = {1992},
	pages = {3--26},
}

@article{kaplan_use_1986,
	title = {On the use of data and judgment in probabilistic risk and safety analysis},
	volume = {93},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549386902116},
	doi = {10.1016/0029-5493(86)90211-6},
	language = {en},
	number = {2-3},
	urldate = {2021-11-17},
	journal = {Nuclear Engineering and Design},
	author = {Kaplan, Stan},
	month = may,
	year = {1986},
	pages = {123--134},
}

@article{choi_development_2021,
	title = {Development of risk assessment framework and the case study for a spent fuel pool of a nuclear power plant},
	volume = {53},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573320308731},
	doi = {10.1016/j.net.2020.09.011},
	abstract = {A Spent Fuel Pool (SFP) is designed to store spent fuel assemblies in the pool. And, a SFP cooling and cleanup system cools the SFP coolant through a heat exchanger which exchanges heat with component cooling water. If the cooling system fails or interfacing pipe (e.g., suction or discharge pipe) breaks, the cooling function may be lost, probably leading to fuel damage. In order to prevent such an incident, it is required to properly cool the spent fuel assemblies in the SFP by either recovering the cooling system or injecting water into the SFP. Probabilistic safety assessment (PSA) is a good tool to assess the SFP risk when an initiating event for the SFP occurs. Since PSA has been focused on reactor-side so far, it is required to study on the framework of PSA approach for SFP and identify the key factors in terms of fuel damage frequency (FDF) through a case study. In this study, therefore, a case study of SFP-PSA on the basis of design information of APR-1400 has been conducted quantitatively, and several sensitivity analyses have been conducted to understand the impact of the key factors on FDF.},
	language = {en},
	number = {4},
	urldate = {2021-11-15},
	journal = {Nuclear Engineering and Technology},
	author = {Choi, Jintae and Seok, Ho},
	month = apr,
	year = {2021},
	keywords = {Probabilistic risk assessment, Probabilistic safety assessment, Spent fuel pool},
	pages = {1127--1133},
}

@article{noauthor_nuregkm-0010_nodate,
	title = {{NUREG}/{KM}-0010, "{WASH}-1400 - {The} {Reactor} {Safety} {Study} - {The} {Introduction} of {Risk} {Assessment} to the {Regulation} of {Nuclear} {Reactors}."},
	language = {en},
	pages = {60},
}

@techreport{collins_planning_1978,
	title = {Planning basis for the development of state and local government {Radiological} {Emergency} {Response} {Plans} in support of light water nuclear power plants},
	url = {http://www.osti.gov/servlets/purl/5765828-1RlU8D/},
	language = {en},
	number = {NUREG-0396, EPA-520/1-78-016, 5765828},
	urldate = {2021-11-15},
	author = {Collins, H.E. and Grimes, B.K. and Galpin, F.},
	month = dec,
	year = {1978},
	doi = {10.2172/5765828},
	pages = {NUREG--0396, EPA--520/1--78--016, 5765828},
}

@article{noauthor_federal_nodate,
	title = {Federal {Guidance} {Report} {No}. 13},
	language = {en},
	pages = {335},
}

@techreport{till_radiological_1983,
	title = {Radiological assessment. {A} textbook on environmental dose analysis},
	url = {http://www.osti.gov/servlets/purl/5407895-XQk6vs/},
	language = {en},
	number = {NUREG/CR-3332, ORNL-5968, 5407895},
	urldate = {2021-11-15},
	author = {Till, J.E. and Meyer, H.R.},
	month = sep,
	year = {1983},
	doi = {10.2172/5407895},
	pages = {NUREG/CR--3332, ORNL--5968, 5407895},
}

@article{prasad_level-1_2011,
	title = {Level-1, -2 and -3 {PSA} for {AHWR}},
	volume = {241},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549311004225},
	doi = {10.1016/j.nucengdes.2011.05.022},
	language = {en},
	number = {8},
	urldate = {2021-11-15},
	journal = {Nuclear Engineering and Design},
	author = {Prasad, M. Hari and Gera, B. and Thangamani, I. and Rastogi, R. and Gopika, V. and Verma, V. and Mukhopadhyay, D. and Bhasin, V. and Chatterjee, B. and Sanyasi Rao, V.V.S. and Lele, H.G. and Ghosh, A.K.},
	month = aug,
	year = {2011},
	pages = {3256--3269},
}

@article{carless_risk_2019,
	title = {Risk and regulatory considerations for small modular reactor emergency planning zones based on passive decontamination potential},
	volume = {167},
	issn = {03605442},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544218321704},
	doi = {10.1016/j.energy.2018.10.173},
	abstract = {It has been argued that risk and performance-based approaches to licensing would be appropriate for Small Modular Reactors (SMRs) because their risk proﬁles differ from large-scale reactors. This is based on several factors including their limited electrical capacity of 300 MW, the below grade reactor vessel, and passive safety features. One design feature that can signiﬁcantly reduce accident severity is the larger lateral surface area-to-volume (A/V) ratio of SMRs. Following a nuclear accident, this larger A/V ratio can increase the removal of radioactive particles due to natural phenomena compared to large light water reactors (LWRs). To quantify the improvements in safety, this work estimates the airborne radioactivity within containment and environmental dose exposure in a post-accident scenario for an advanced Generation IIIþ LWR (AP1000), a representative Generation II LWR (Surry), and an SMR. On average, the AP1000, Surry, and SMR produces 139, 153, and 104 curies/ft3 (182, 200, and 136 terabecquerels/m3) 75 min after a Loss-of-coolant-accident (LOCA). Using Monte Carlo simulations, the SMR produces less radioactivity per volume in containment than the AP1000 and Surry 84\% and 96\% of the time, respectively. On average, the AP1000, Surry, and SMR produces 84, 106, and 7 thousand curies/ MWth (3.1, 3.9, and 2.5 petabecquerels/MWth) 75 min after a LOCA. The larger A/V ratio of the SMR plays a substantial role in reducing the radioactivity. While it is expected that the SMR would have a lower levels of radioactivity compared to the AP1000 and Surry, the SMR produces less radioactivity after normalizing by thermal reactor power and containment volume. With respect to environmental dose exposure, the US Environmental Protection Agency 1e5 rem (0.01e0.05 sieverts) Protective Action Guide (PAG) limits for whole body exposure is not exceeded at the 10-mile (16.1-km) EPZ using the mean estimates for the AP1000 and Surry. The iPWR does not exceed the 1 rem (0.01 sieverts) lower PAG limit for whole body exposure at the 5-mile (8-km) EPZ using the mean value. These ﬁndings can be used in conjunction with the improved analytical methods, found in the SOARCA study, to provide accurate and realistic estimates for exposure. This will help create a pathway to develop a regulatory basis for technology-neutral, risk-based approach to EPZs for iPWRs.},
	language = {en},
	urldate = {2021-11-15},
	journal = {Energy},
	author = {Carless, Travis S. and Talabi, Sola M. and Fischbeck, Paul S.},
	month = jan,
	year = {2019},
	pages = {740--756},
}

@article{programme_purpose_nodate,
	title = {Purpose of {Sponsorship} {Letter} {Name}/{Surname} of {Grantee} {Country} of {Education}},
	language = {en},
	author = {Programme, Master's and Polat, Damla},
	pages = {1},
}

@article{levine_probabilistic_1983,
	title = {Probabilistic risk assessment in the {US}},
	volume = {6},
	issn = {0143-8174},
	url = {https://www.sciencedirect.com/science/article/pii/0143817483900045},
	doi = {10.1016/0143-8174(83)90004-5},
	abstract = {The paper offers an overview of the current state of affairs in the field of probabilistic risk assessment (PRA) in the US as applied to nuclear power. The history of the development of PRA techniques starts essentially with the Reactor Safety Study (RSS) which was sponsored by the Nuclear Regulatory Commission and published in 1975 as report WASH-1400. It was subjected both to extensive technical peer review and, as requested by the US Congress, to oversight review by a scientific panel called the Lewis Committee. Applications of PRA techniques did not spread widely outside the field of advanced reactors such as an HTGR until the Three Mile Island (TMI) accident in March 1979. In the four year since the TMI accident a rapid expansion of the use of PRA has occurred. One of the major strengths of PRA is its broad applicability to problems faced by utilities, designers and regulators. While offering substantial benefits, PRA has also some limitations which need to be understood. The expansion has primarily taken the form of plant-specific studies. Several major studies are now published and many more are in progress. The paper discusses some insights gained from the Big Rock Point and Zion/Indian Point studies, and concludes with a subject closely related to PRA, which is the development of safety goals for nuclear regulation.},
	language = {en},
	number = {4},
	urldate = {2021-11-14},
	journal = {Reliability Engineering},
	author = {Levine, S. and Joksimovich, V. and Stetson, F.},
	month = jan,
	year = {1983},
	pages = {197--209},
}

@article{cohen_probabilistic_1983,
	title = {Probabilistic {Risk} {Assessment} of {Wastes} {Buried} in the {Ground}},
	volume = {3},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.1983.tb01392.x},
	doi = {10.1111/j.1539-6924.1983.tb01392.x},
	abstract = {The differences between probabilistic risk assessment (PRA) and safety analysis (SA) are discussed, and it is shown that PRA is more suitable than SA for determining the acceptability of a technology. Since a PRA by the fault tree-event tree analysis method used for reactor safety studies does not seem to be practical for buried waste, an alternative approach is suggested using geochemical analogs. This method is illustrated for the cases of high-level and low-level radioactive waste and for chemical carcinogens released in coal burning.},
	language = {en},
	number = {4},
	urldate = {2021-11-14},
	journal = {Risk Analysis},
	author = {Cohen, Bernard L.},
	year = {1983},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.1983.tb01392.x},
	keywords = {Probabilistic risk assessment (PRA), geochemical analogs, safety analysis, waste},
	pages = {237--243},
}

@article{koberlein_role_1980,
	title = {The role of probabilistic methods in the development of regulations for nuclear power plant design — assessment and projections — in the {Fed}. {Rep}. {Germany}},
	volume = {60},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/0029549380902502},
	doi = {10.1016/0029-5493(80)90250-2},
	abstract = {Some views on present use and future potential of both reliability and risk analysis in reactor safety assessment and licensing are given. Although the deterministic approach is still dominating, the part of probabilistic methods in the process of regulating nuclear power plants is steadily increasing. Both methods are complementing one another.},
	language = {en},
	number = {1},
	urldate = {2021-11-14},
	journal = {Nuclear Engineering and Design},
	author = {Köberlein, K.},
	month = sep,
	year = {1980},
	pages = {29--31},
}

@article{ravindra_system_1990,
	title = {System reliability considerations in probabilistic risk assesment of nuclear power plants},
	volume = {7},
	issn = {0167-4730},
	url = {https://www.sciencedirect.com/science/article/pii/016747309090075Z},
	doi = {10.1016/0167-4730(90)90075-Z},
	abstract = {The frequencies and consequences of severe accidents at nuclear power plants are examined using a systematic procedure called probabilistic risk assessment (PRA). These accidents may be initiated by equipment malfunctions, operator errors or external initiators such as earthquakes, floods and tornadoes. It is in the case of the external events that the structural system reliability concepts are utilized. Taking the seismic risk analysis as an example, this paper discusses the different elements of the analysis — hazard analysis, fragility evaluation, systems analysis and risk quantification — and examines how the structural system reliability methods are applied. Areas requiring further investigation by the PRA analysts are indicated and the data and research needs are identified.},
	language = {en},
	number = {2},
	urldate = {2021-11-14},
	journal = {Structural Safety},
	author = {Ravindra, M. K.},
	month = mar,
	year = {1990},
	keywords = {core damage, event tree, fault tree, probabilistic risk assessment, public risk, reliability, seismic fragility, seismic hazard, structural system, nuclear power plant},
	pages = {269--280},
}

@article{liu_expert_2020,
	series = {{SI}:{HRA} {FOUNDATIONS} \& {FUTURE}},
	title = {Expert judgments for performance shaping {Factors}’ multiplier design in human reliability analysis},
	volume = {194},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017310293},
	doi = {10.1016/j.ress.2018.12.022},
	abstract = {Human reliability analysis (HRA) still heavily relies on expert judgments to generate reliability data. There exists a widely recognized need to validate and justify the reliability data obtained from expert judgments. For demonstrating such effort, we provide a template of how we base expert elicitations and empirical studies to derive the multipliers of performance shaping factors (PSFs). We applied two expert judgment techniques—absolute probability judgment (APJ) and ratio magnitude estimation (RME)—to update the PSF multiplier design in Standardized Plant Analysis of Risk-Human Reliability Analysis (SPAR-H). Licensed operators (N = 17) from a nuclear power plant were recruited. It is found that APJ and RME have acceptable inter-rater reliability and convergent validity between them. The multipliers estimated by APJ and RME were compared with those from empirical studies in the human performance literature. Certain consistencies between these heterogeneous data sources were found. Combining these heterogeneous data, we suggested the multiplier design of PSFs for SPAR-H. We also bridged the relationship between every PSF and its psychological mechanism to trigger human errors. Our work might suggest the appropriateness of expert elicitations in generating useful data for HRA, and strengthen the empirical and psychological foundations of PSF-based HRA methods.},
	language = {en},
	urldate = {2021-11-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Liu, Peng and Qiu, Yongping and Hu, Juntao and Tong, Jiejuan and Zhao, Jun and Li, Zhizhong},
	month = feb,
	year = {2020},
	keywords = {Absolute probability judgment, Expert judgment, Human reliability analysis, Performance shaping factors, Ratio magnitude estimation},
	pages = {106343},
}

@article{mkrtchyan_bayesian_2015,
	title = {Bayesian belief networks for human reliability analysis: {A} review of applications and gaps},
	volume = {139},
	issn = {0951-8320},
	shorttitle = {Bayesian belief networks for human reliability analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832015000514},
	doi = {10.1016/j.ress.2015.02.006},
	abstract = {The use of Bayesian Belief Networks (BBNs) in risk analysis (and in particular Human Reliability Analysis, HRA) is fostered by a number of features, attractive in fields with shortage of data and consequent reliance on subjective judgments: the intuitive graphical representation, the possibility of combining diverse sources of information, the use the probabilistic framework to characterize uncertainties. In HRA, BBN applications are steadily increasing, each emphasizing a different BBN feature or a different HRA aspect to improve. This paper aims at a critical review of these features as well as at suggesting research needs. Five groups of BBN applications are analysed: modelling of organizational factors, analysis of the relationships among failure influencing factors, BBN-based extensions of existing HRA methods, dependency assessment among human failure events, assessment of situation awareness. Further, the paper analyses the process for building BBNs and in particular how expert judgment is used in the assessment of the BBN conditional probability distributions. The gaps identified in the review suggest the need for establishing more systematic frameworks to integrate the different sources of information relevant for HRA (cognitive models, empirical data, and expert judgment) and to investigate algorithms to avoid elicitation of many relationships via expert judgment.},
	language = {en},
	urldate = {2021-11-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Mkrtchyan, L. and Podofillini, L. and Dang, V. N.},
	month = jul,
	year = {2015},
	keywords = {Bayesian belief networks, Expert judgment, Human error probabilities, Human factors, Human reliability analysis, Organizational factors, Performance shaping factors},
	pages = {1--16},
}

@article{cho_multi-unit_2018,
	title = {Multi-unit {Level} 2 probabilistic safety assessment: {Approaches} and their application to a six-unit nuclear power plant site},
	volume = {50},
	issn = {17385733},
	shorttitle = {Multi-unit {Level} 2 probabilistic safety assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573317305624},
	doi = {10.1016/j.net.2018.04.005},
	abstract = {The risk of multi-unit nuclear power plants (NPPs) at a site has received considerable critical attention recently. However, current probabilistic safety assessment (PSA) procedures and computer code do not support multi-unit PSA because the traditional PSA structure is mostly used for the quantiﬁcation of single-unit NPP risk. In this study, the main purpose is to develop a multi-unit Level 2 PSA method and apply it to full-power operating six-unit OPR1000. Multi-unit Level 2 PSA method consists of three steps: (1) development of single-unit Level 2 PSA; (2) extracting the mapping data from plant damage state to source term category; and (3) combining multi-unit Level 1 PSA results and mapping fractions. By applying developed multi-unit Level 2 PSA method into six-unit OPR1000, site containment failure probabilities in case of loss of ultimate heat sink, loss of off-site power, tsunami, and seismic event were quantiﬁed.},
	language = {en},
	number = {8},
	urldate = {2021-11-13},
	journal = {Nuclear Engineering and Technology},
	author = {Cho, Jaehyun and Han, Sang Hoon and Kim, Dong-San and Lim, Ho-Gon},
	month = dec,
	year = {2018},
	pages = {1234--1245},
}

@article{jin_fragility_2021,
	title = {Fragility analysis and probabilistic performance evaluation of nuclear containment structure subjected to internal pressure},
	volume = {208},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832020308863},
	doi = {10.1016/j.ress.2020.107400},
	abstract = {Based on the detailed three-dimensional finite element model of the nuclear containment structure, this study presents fragility analysis and probabilistic performance evaluation of the nuclear containment structure sub­ jected to internal pressure. To realize automatic running of nonlinear finite element analysis of the nuclear containment structure, Python and Matlab scripts are developed. Confidence intervals of fragility parameters are estimated by the statistical inference method and bootstrap method. An analytical method for constructing the confidence interval of the fragility curve is proposed in this study, and confidence interval of the fragility curve predicted by the proposed method is compared with the bootstrap method. Moreover, statistics of the cumulative failure probability of the nuclear containment structure are estimated by bootstrap method and the proposed Taylor series expansion method . Finally, probabilistic safety margins of the nuclear containment structure are evaluated by the median value method and confidence interval method. Results indicate that statistical uncer­ tainty has almost no effect on the mean value of the fragility parameters. However, statistical uncertainty has some effects on the variability of the fragility parameterβS. In general, the influence of statistical uncertainty on fragility parameterβSis greater than that of fragility parameterPm. Confidence intervals of Pm estimated by the statistical inference method and bootstrap method are almost the same, and statistical inference method over­ estimates the confidence interval of fragility parameterβS. The proposed method for constructing confidence interval provides almost the same prediction of the confidence interval of the fragility curve as the bootstrap method. In general, statistics of the cumulative failure probability of the nuclear containment structure calcu­ lated by the bootstrap method and the proposed Taylor series expansion method are almost the same. The dif­ ference between the safety margin calculated by the median value method and the safety margin with 95\% confidence level calculated by confidence interval method is negligible.},
	language = {en},
	urldate = {2021-11-13},
	journal = {Reliability Engineering \& System Safety},
	author = {Jin, Song and Gong, Jinxin},
	month = apr,
	year = {2021},
	pages = {107400},
}

@article{han_quantitative_2010,
	title = {A quantitative evaluation of reliability of passive systems within probabilistic safety assessment framework for {VHTR}},
	volume = {37},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454909003788},
	doi = {10.1016/j.anucene.2009.12.004},
	abstract = {This article presents a quantitative evaluation of the reliability of passive systems (RoPS) within the probabilistic safety assessment (PSA) framework for very high temperature reactors (VHTR). VHTRs have unfavorable features in regard to deﬁning a robust failure state. From the viewpoint of PSA, the evaluation of the RoPS as a part of VHTR’s PSA should carefully consider the correct status of a passive system in order to resolve these unfavorable features. This article focuses on the application of multiple states criteria to determine the status of a passive system. Two approaches, i.e., the exceedance probability (EP) model and the stress–strength interference (SSI) model were proposed for the multiple states of the system. A feasibility study has examined the basic features of the proposed approaches by using the reactor cavity cooling system (RCCS) for Korean VHTR. The primary condition for the usefulness of the proposed approaches is that sufﬁcient information should be provided in order to determine the system strengths for the multiple states. With regard to the engineering practice, the EP approach for the multiple states can provide a practical solution concerning the evaluation of the RoPS for VHTR’s PSA.},
	language = {en},
	number = {3},
	urldate = {2021-11-13},
	journal = {Annals of Nuclear Energy},
	author = {Han, Seok-Jung and Yang, Joon-Eon},
	month = mar,
	year = {2010},
	pages = {345--358},
}

@inproceedings{tjahyani_pra_nodate,
	title = {{PRA} ({Probabilistic} {Risk} {Assessment}) for {Spent} {Fuel} {Decommissioning} of the {Fugen} {Nuclear} {Power} {Station}},
	abstract = {Fugen Nuclear Power Station will be permanently shutdown in 2003 and immediate fuel unloading and fuel transportation is necessary. The spent fbel pol should be stored safely because the spent fuels are kept in the spent fuel pool. Loss of coling in the spent fuel pool can lead to a srious condition. This paper is to calculate the risk of the spent fuel pool especially probability calculation of consequence during decommissioning. In this case, fel uncovery is as end state. Calculation is based on NUREG-1738. Analysis has been done for 4 initiating events flat are loss of cooling, internal fire, loss of offsite power (LOPA) and loss of inventory. Initiating evern fequency is adopted from Fugen condition and NUREG. More, calculation data is taken from the living PSA of Fugen and NUREG. Results of analysis sowed that the spent fuel pool of Fugen is safe enough because the fuel uncovery probability is 4.438E-08 per year. Moreover, the spent fuel pool cooling system of the Fugen NPS has high reliability because the failure probability is 7.435E-04 per year and will become 2.794E-06 per year if RHR (residual heat removal) system is included. Therefore, RHR system can be considered in the aident management during decommissioning. On the other hand, the maintenance cost increases by keeping the RHR system during decommissioning.},
	language = {en},
	author = {Tjahyani, D T Sony},
	pages = {6},
}

@article{weiner_spent_2013,
	title = {Spent fuel transportation risk assessment: {Transportation} accident analysis},
	volume = {24},
	shorttitle = {Spent fuel transportation risk assessment},
	doi = {10.1179/1746510914Y.0000000046},
	abstract = {The US Nuclear Regulatory Commission (NRC) has recently completed an updated Spent Fuel Transportation Risk Assessment, NUREG-2125. This assessment considered four types of accidents that could interfere with routine transportation of spent nuclear fuel: those in which the spent fuel cask is not affected, those in which there is loss of lead gamma shielding, those in which radioactive material is released and those that could result in a criticality event. The probability of a particular type of accident is the product of the probability that the vehicle carrying the spent fuel cask will be in an accident and the conditional probability that the accident will be of a certain type. An accident in which the spent fuel cask is not damaged or affected at all is the most probable: 99·95\% of vehicle accidents are less severe than the regulatory hypothetical accident, and most accidents that are more severe than this still do not lead to loss of shielding or release, which occur in fewer than one accident in a billion. If a lead shielded cask is involved in one of these impacts, the lead shield can slump, and a small section of the spent fuel in the cask will be shielded only by the steel shells. The resulting external doses are significant but would result in neither acute illness nor death. The collective dose risks are vanishingly small. Consequences and risks of an accidental release of radioactive material are similar, since only very small amounts of material would be released, and only through damaged cask seals. The study also examined the probabilities and risks associated with several possible fire scenarios previously analysed by the NRC, and showed that even such events do not result in significant risks. Inclusion of such events increases the estimated risk by only a small fraction. Another accident type that is of potential concern is one that leads to a criticality event. This study has shown that the combination of factors necessary to produce such an event is so unlikely that the event is not credible.},
	journal = {Packaging, Transport, Storage \& Security of Radioactive Material},
	author = {Weiner, R. and Ammerman, Douglas},
	month = sep,
	year = {2013},
	pages = {147--157},
}

@techreport{garrick_transportation_2020,
	address = {Los Angeles, CA},
	title = {Transportation {Risks} {Associated} with the {Decommissioning} of the {Diablo} {Canyon} {Power} {Plant}},
	number = {GIRS-2020-01},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Garrick, B. John and Chandra, Roy and Diaconeasa, Mihai Aurelian and Wangler, Michael E.},
	month = mar,
	year = {2020},
}

@phdthesis{karell_safety_2018,
	address = {Aalto, Finlandia},
	title = {Safety classification of small and modular nuclear power plants},
	url = {www.aalto.fi},
	abstract = {Safety classes were successfully determined for the safety functions. However, not all initiating events or functions could be taken into account, so the classification could be complemented with these in the future. The classification might change also if the national requirements change as they are based on the design of currently operating plants. The created ADLAS model can be used in future for other licensing aspects of NuScale and additionally for other small and modular nuclear power plants. Related to the second objective of this thesis, some potential challenges were recognized in the NuScale design. These were related to the safety functions mitigating anticipated transients without scram and severe accidents and to the location of containment isolation valves. These might not prevent the licensing in Finland but have to be separately addressed if the actual licensing is started.},
	language = {English},
	school = {Aalto University School of Engineering},
	author = {Karell, Rasmus},
	month = apr,
	year = {2018},
}

@inproceedings{feng_assessing_2021,
	address = {Savannah, Georgia},
	title = {Assessing {Small} {Probabilities} in {Extreme} {Hazard} {Event} {Trees} {When} {Limited} {Information} {Is} {Available}},
	isbn = {978-0-7844-8370-1},
	url = {http://ascelibrary.org/doi/10.1061/9780784483701.030},
	doi = {10.1061/9780784483701.030},
	abstract = {Event trees are often used to assess the risks associated with geoextreme events caused by natural hazards and choose the appropriate risk-management strategy. However, because the frequencies of interest for these extreme events can be as small as once per 1,000–10,000 years, there is limited information available to assess them. This paper proposes a methodology for assessing the probabilities of rare events. The methodology utilizes the possibility of fractional occurrences in a random process to represent estimates of small frequencies in limited lengths of historical record and a decision-based approach to establish noninformative probabilities to be updated with the available information. A case study of a risk-based rehabilitation decision for major rockfill dam demonstrates that realistically representing the uncertainty in assessing small frequencies is important, both in deciding whether or not to rehabilitate the dam and in assessing the value of obtaining additional information about the risk.},
	language = {en},
	urldate = {2021-11-10},
	booktitle = {Geo-{Extreme} 2021},
	publisher = {American Society of Civil Engineers},
	author = {Feng, Kai and Habibi, Mahdi and Gilbert, Robert B. and Nadim, Farrokh},
	month = nov,
	year = {2021},
	pages = {320--331},
}

@misc{noauthor_scalemelcor_2021,
	type = {{ML21200A179}},
	title = {{SCALE}/{MELCOR} {Non}-{LWR} {Source}  {Term} {Demonstration} {Project} – {High}-{Temperature} {Gas}-{Cooled}  {Reactor}},
	url = {https://adamswebsearch2.nrc.gov/webSearch2/main.jsp?AccessionNumber=ML21200A179},
	urldate = {2021-11-10},
	month = jul,
	year = {2021},
}

@article{jung_hurex_2020,
	title = {{HuREX} – {A} framework of {HRA} data collection from simulators in nuclear power plants},
	volume = {194},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832017309857},
	doi = {10.1016/j.ress.2018.07.036},
	abstract = {The fundamental issue in reference to human reliability analysis (HRA) in a nuclear power plant is the lack of empirical data for human error probability (HEP) estimation, and lower level information of human performance that can be used to estimate HEPs. In an effort to resolve this issue, the Korea Atomic Energy Research Institute (KAERI) developed a framework, known as human reliability data extraction (HuREX), for data collection and analyses from a simulator to generate HRA data, such as HEPs, or for correlations between performance shaping factors (PSFs) and the associated HEPs. HuREX provides guidance on the identification of unsafe act (UA) and the processing of collected data. In addition, it allows us to analyze collected data based on the associated forms and taxonomy on generic task types and error modes. An application study was carried out using two sets of fullscope training simulator records to confirm the suitability of HuREX and to generate the HEPs of generic task types with respect to reference plants. As a result, 37 HEPs were successfully quantified for 21 generic task types.},
	language = {en},
	urldate = {2021-11-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Jung, Wondea and Park, Jinkyun and Kim, Yochan and Choi, Sun Yeong and Kim, Seunghwan},
	month = feb,
	year = {2020},
	pages = {106235},
}

@article{fu_htr-pm_2014,
	title = {{HTR}-{PM} {Safety} requirement and {Licensing} experience},
	abstract = {HTR-PM is a 200MWe modular pebble bed high temperature reactor demonstration plant which is being built in Shidao Bay, Weihai, Shandong, China. The main design parameters of HTR-PM were fixed in 2006, the basic design was completed in 2008. The review of Preliminary Safety Analysis Report (PSAR) of HTR-PM was started in April 2008, completed in September 2009. In general, HTRPM design complies with the current safety requirement for nuclear power plant in China, no special standards are developed for modular HTR. Anyway, Chinese Nuclear Safety Authority, together with the designers, developed some dedicated design criteria for key systems and components and published the guideline for the review of safety analysis report of HTR-PM, based on the experiences from licensing of HTR-10 and new development of nuclear safety. The probabilistic safety goal for HTR-PM was also defined by the safety authority. The review of HTR-PM PSAR lasted for one and a half years, with 3 dialogues meetings and 8 topics meetings, with more than 2000 worksheets and answer sheets. The heavily discussed topics during the PSAR review process included: the requirement for the sub-atmospheric ventilation system, the utilization of PSA in design process, the scope of beyond design basis accidents, the requirement for the qualification of TRISO coating particle fuel, and etc. Because of the characteristics of first of a kind for the demonstration plant, the safety authority emphasized the requirement for the experiment and validation, the PSAR was licensed with certain licensing conditions. The whole licensing process was under control, and was re-evaluated again after Fukushima accident to be shown that the design of HTR-PM complies with current safety requirement. This is a good example for how to license a new reactor.},
	language = {en},
	author = {Fu, LI and Zuoyi, ZHANG and Yujie, DONG and Zongxin, WU and Yuliang, SUN},
	year = {2014},
	pages = {7},
}

@article{zuoyi_future_2014,
	title = {Future {Development} of {Modular} {HTGR} in {China} after {HTR}-{PM}},
	abstract = {The modular high temperature gas-cooled reactor (MHTGR) is an inherently safe nuclear energy technology for efficient electricity generation and process heat applications. The MHTGR is promising in China as it may replace fossil fuels in broader energy markets. In line with China’s long-term development plan of nuclear power, the Institute of Nuclear and New Energy Technology (INET) of Tsinghua University developed and designed a MHTGR demonstration plant, named high-temperature gas-cooled reactor-pebble bed module (HTR-PM). The HTR-PM came into the construction phase at the end of 2012.},
	language = {en},
	author = {Zuoyi, Zhang and Haitao, Wang and Yujie, Dong and Fu, Li},
	year = {2014},
	pages = {9},
}

@article{furui_power_2014,
	title = {{ON} {POWER} {REFUELING} {MANAGEMENT} {OF} {HTR}-{PM}},
	abstract = {The refueling management is an important work of nuclear power plant , directly affecting its safety and economy. At present, the ordinary commercial pressurized water reactor (PWR) nuclear power plant has developed more mature in the refueling management, and formed a set of relatively complete system and methods.The High Temperature Gas-cooled Reactor Pebble-modules Demonstration Project(HTR-PM) has significant differences with the ordinary PWR nuclear power plant in the fuel morphology and the refueling mode. It adopts the spherical fuel element and the on-power refueling. Therefore, the HTR-PM refueling management has its own unique characteristics, but currently there is no mature experience to use for reference across the world. This paper gives a brief introduction to the HTR-PM on power refueling management, including the refueling management system construction, the refueling strategy, the fuel element internal transportation,charging and discharging, etc. It aims at finding the befitting HTR-PM refueling management methods in view of its own unique characteristics in order to ensure the orderly development of the refueling management and the refueling safety.},
	language = {en},
	author = {Furui, Sun and Yong, Luo and Qiang, Gao},
	year = {2014},
	pages = {4},
}

@article{tao_plant_2014,
	title = {Plant {Operation} {Station} for {HTR}-{PM} {Low} {Power} and {Shutdown} operation {Probabilistic} safety analysis},
	abstract = {Full range Probabilistic safety analysis (PSA) is one of key conditions for nuclear power plant (NPP) licensing according to the requirement of nuclear safety regulatory authority. High Temperature Gas Cooled Reactor Pebble-bed Module (HTR-PM) has developed construction design and prepared for the charging license application. So after the normal power operation PSA submitted for review, the Low power and Shutdown operation Probabilistic safety analysis (LSPSA) also begin. The results of LSPSA will together with prior normal power PSA results to demonstrate the safety level ofHTR-PM NPP.},
	language = {en},
	author = {Tao, Liu and Jiejuan, Tong},
	year = {2014},
	pages = {7},
}

@article{mandelli_data_nodate,
	title = {Data {Processing} {Methodologies} {Applied} to {Dynamic} {PRA}: an {Overview}},
	abstract = {The use of dynamic event trees (DETs) can serve as a powerful tool for the dynamic probabilistic risk assessment (DPRA) of nuclear power plants. The DETs have the capability to more accurately model the complex interactions and events which may occur during a transient. One of the challenges of DPRA through DETs is the management of the resulting very large data sets. Hence, the need for a methodology able to handle high volumes of data in terms of both cardinality (due to the high number of uncertainties included in the analysis) and dimensionality (due to the complexity of systems) arises. Hierarchical and partitional clustering methodologies are compared and evaluated with regard to their potential to analyze large scenario datasets generated by DETs using several different data sets.},
	language = {en},
	author = {Mandelli, Diego and Yilmaz, Alper and Aldemir, Tunc},
	pages = {12},
}

@article{lee_use_2019,
	title = {Use of {Dynamic} {Event} {Trees} and {Deep} {Learning} for {Real}-{Time} {Emergency} {Planning} in {Power} {Plant} {Operation}},
	volume = {205},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2018.1541394},
	doi = {10.1080/00295450.2018.1541394},
	abstract = {An initiating event that disrupts regular nuclear power plant (NPP) operation can result in a variety of different scenarios as time progresses depending on the response of standby safety systems and operator actions to bring the plant to a safe, stable state, or the uncertainties in accident phenomenology. Depending on the severity of the accident and potential magnitude of release of radioactive material into the environment, off-site emergency response such as evacuation may be warranted. An approach that could be used for real-time emergency guidance to support the declaration of a site emergency and to guide offsite response is presented using observable plant data in the early stages of a severe accident. The approach is based on the simulation of the possible NPP behavior following an initiating event and projects the likelihood of different levels of off-site release of radionuclides from the plant using deep learning (DL) techniques. Training of the DL process is accomplished using results of a large number of scenarios generated with the Analysis of Dynamic Accident Progression Trees/MELCOR/Radiological Assessment System for Consequence Analysis (RASCAL) computer codes to simulate the variety of possible consequences following a station blackout event (similar to the Fukushima accident) for a large pressurized water reactor. The ability of the model to predict the likelihood of different levels of consequences is assessed using a separate test set of MELCOR/RASCAL calculations.},
	language = {en},
	number = {8},
	urldate = {2021-11-08},
	journal = {Nuclear Technology},
	author = {Lee, Ji Hyun and Yilmaz, Alper and Denning, Richard and Aldemir, Tunc},
	month = aug,
	year = {2019},
	pages = {1035--1042},
}

@article{pence_gisbased_2019,
	title = {{GIS}‐{Based} {Integration} of {Social} {Vulnerability} and {Level} 3 {Probabilistic} {Risk} {Assessment} to {Advance} {Emergency} {Preparedness}, {Planning}, and {Response} for {Severe} {Nuclear} {Power} {Plant} {Accidents}},
	volume = {39},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/risa.13241},
	doi = {10.1111/risa.13241},
	language = {en},
	number = {6},
	urldate = {2021-11-08},
	journal = {Risk Analysis},
	author = {Pence, Justin and Miller, Ian and Sakurahara, Tatsuya and Whitacre, James and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	month = jun,
	year = {2019},
	pages = {1262--1280},
}

@article{groth_bayesian_2014,
	title = {A {Bayesian} method for using simulator data to enhance human error probabilities assigned by existing {HRA} methods},
	volume = {128},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832014000581},
	doi = {10.1016/j.ress.2014.03.010},
	abstract = {In the past several years, several international agencies have begun to collect data on human performance in nuclear power plant simulators [1]. This data provides a valuable opportunity to improve human reliability analysis (HRA), but there improvements will not be realized without implementation of Bayesian methods. Bayesian methods are widely used in to incorporate sparse data into models in many parts of probabilistic risk assessment (PRA), but Bayesian methods have not been adopted by the HRA community. In this paper, we provide a Bayesian methodology to formally use simulator data to reﬁne the human error probabilities (HEPs) assigned by existing HRA methods. We demonstrate the methodology with a case study, wherein we use simulator data from the Halden Reactor Project to update the probability assignments from the SPAR-H method. The case study demonstrates the ability to use performance data, even sparse data, to improve existing HRA methods. Furthermore, this paper also serves as a demonstration of the value of Bayesian methods to improve the technical basis of HRA.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina M. and Smith, Curtis L. and Swiler, Laura P.},
	month = aug,
	year = {2014},
	pages = {32--40},
}

@article{yang_adaptive_2019,
	title = {An adaptive probabilistic mapping matrix search algorithm for vulnerability analysis of {PPS}},
	volume = {131},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454919301914},
	doi = {10.1016/j.anucene.2019.04.013},
	abstract = {The paper presents an adaptive probabilistic mapping matrix search algorithm for adversary path planning and vulnerability analysis of physical protection system. The algorithm represents the adversary transition process as stochastic risk-taking path choice behaviors under uncertainties. The interactions among the protective elements are characterized by a full probabilistic mapping scheme of discretized Cell-to-Cell transitions across the area of physical protection for path planning analysis. Practice of the proposed algorithm is demonstrated with a hypothetical case of nuclear facility for risk-signiﬁcant adversary path identiﬁcation. The analysis results show that the method is capable of path search analysis for determining the system effectiveness measures.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Annals of Nuclear Energy},
	author = {Yang, Jun and Wang, Jun and Wei, Guanxiang and Yang, Ming and Lu, Hongxing},
	month = sep,
	year = {2019},
	pages = {433--442},
}

@article{yoo_methodology_2015,
	title = {Methodology for analyzing risk at nuclear facilities},
	volume = {81},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454915001188},
	doi = {10.1016/j.anucene.2015.02.041},
	abstract = {A methodology for evaluating risks at nuclear facilities is developed in this work. A series of measures is drawn from the analysis of factors that determine risks. Five measures are created to evaluate risks at nuclear facilities. These include the legal and institutional framework, material control, physical protection system effectiveness, human resources, and consequences. Evaluation attributes are developed for each measure and speciﬁc values are given in order to calculate the risk value quantitatively. Questionnaires are drawn up on whether or not a state has properly established a legal and regulatory framework (based on international standards). These questionnaires can be a useful measure for comparing the status of the physical protection regime between two countries. Analyzing an insider threat is not an easy task and no methodology has been developed for this purpose. In this study, attributes that could quantitatively evaluate an insider threat, in the case of an unauthorized removal of nuclear materials, are developed by adopting the Nuclear Material Accounting \& Control (NMAC) system. The effectiveness of a physical protection system, P(E), could be analyzed by calculating the probability of interruption, P(I), and the probability of neutralization, P(N). In this study, the Tool for Evaluating Security System (TESS) code developed by KINAC is used to calculate P(I) and P(N). Consequence is an important measure used to analyze risks at nuclear facilities. This measure comprises radiological, economic, and social damage. Social and economic damages are difﬁcult to evaluate. Therefore, radiation levels and theft of nuclear materials that could be quantiﬁed are adopted as attributes for analyzing the consequences. Awareness of the nuclear security culture and physical protection resources such as stafﬁng, capabilities, and cost required to provide PP should be considered when evaluating risks. In this study, these attributes are included in the measure of human resources. Human resources include such factors as trustworthiness, degree of nuclear security culture awareness, and frequency of psychiatric testing of employees. A case study performed on hypothetical facilities demonstrates that the developed methodology could be used to analyze innovative nuclear systems as well as existing facilities.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Annals of Nuclear Energy},
	author = {Yoo, Hosik and Lee, Nayoung and Ham, Taekyu and Seo, Janghoon},
	month = jul,
	year = {2015},
	pages = {213--218},
}

@article{lee_development_2011,
	title = {Development of a qualitative evaluation framework for performance shaping factors ({PSFs}) in advanced {MCR} {HRA}},
	volume = {38},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454911001319},
	doi = {10.1016/j.anucene.2011.04.006},
	abstract = {Human reliability analysis (HRA) is performed as part of the probabilistic risk assessment to identify and quantify human actions and the associated impacts on structures, systems, and components of complex facilities. In performing HRA, conditions that inﬂuence human performance have been analyzed in terms of several context factors. These context factors, which are called performance shaping factors (PSFs) are used to adjust the basic human error probability (BHEP), and PSFs have been derived in various ways depending on the HRA methods used.},
	language = {en},
	number = {8},
	urldate = {2021-11-08},
	journal = {Annals of Nuclear Energy},
	author = {Lee, Seung Woo and Kim, Ar Ryum and Ha, Jun Su and Seong, Poong Hyun},
	month = aug,
	year = {2011},
	pages = {1751--1759},
}

@misc{mulder_overview_2021,
	address = {X-energy},
	title = {Overview of {X}-{Energy}’s 200 {MWth} {Xe}-100 {Reactor}},
	language = {English},
	author = {Mulder, Eben J},
	month = jun,
	year = {2021},
}

@article{romanato_advantages_2011,
	title = {{ADVANTAGES} {OF} {DRY} {HARDENED} {CASK} {STORAGE} {OVER} {WET} {STORAGE} {FOR} {SPENT} {NUCLEAR} {FUEL}},
	abstract = {Pools are generally used to store and maintain spent nuclear fuel assemblies for cooling, after removed from reactors. After three to five years stored in the pools, spent fuel can be reprocessed or sent to a final disposition in a geological repository and handled as radioactive waste or sent to another site waiting for future solution. Spent fuel can be stored in dry or wet installations, depending on the method adopted by the nuclear plant. If this storage were exclusively wet, at the installation decommissioning in the future, another solution for storage will need to be found. Today, after a preliminary cooling, the spent fuel assemblies can be removed from the pool and sent to dry hardened storage installations. This kind of storage does not need complex radiation monitoring and it is safer than wet storage. Brazil has two nuclear reactors in operation, a third reactor is under construction and they use wet spent fuel storage . Dry hardened casks use metal or both metal and concrete for radiation shielding and they are safe, especially during an earthquake. An earthquake struck Japan on March 11, 2011 damaging Fukushima Daiichi nuclear power plant. The occurrence of earthquakes in Brazil is very small but dry casks can resist to other events, including terrorist acts, better than pools. This paper shows the advantages of dry hardened cask storage in comparison with the wet storage (water pools) for spent nuclear fuel.},
	language = {en},
	author = {Romanato, Luiz Sergio},
	year = {2011},
	pages = {9},
}

@article{jung_hurex_2020-1,
	series = {{SI}:{HRA} {FOUNDATIONS} \& {FUTURE}},
	title = {{HuREX} – {A} framework of {HRA} data collection from simulators in nuclear power plants},
	volume = {194},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017309857},
	doi = {10.1016/j.ress.2018.07.036},
	abstract = {The fundamental issue in reference to human reliability analysis (HRA) in a nuclear power plant is the lack of empirical data for human error probability (HEP) estimation, and lower level information of human performance that can be used to estimate HEPs. In an effort to resolve this issue, the Korea Atomic Energy Research Institute (KAERI) developed a framework, known as human reliability data extraction (HuREX), for data collection and analyses from a simulator to generate HRA data, such as HEPs, or for correlations between performance shaping factors (PSFs) and the associated HEPs. HuREX provides guidance on the identification of unsafe act (UA) and the processing of collected data. In addition, it allows us to analyze collected data based on the associated forms and taxonomy on generic task types and error modes. An application study was carried out using two sets of full-scope training simulator records to confirm the suitability of HuREX and to generate the HEPs of generic task types with respect to reference plants. As a result, 37 HEPs were successfully quantified for 21 generic task types.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Reliability Engineering \& System Safety},
	author = {Jung, Wondea and Park, Jinkyun and Kim, Yochan and Choi, Sun Yeong and Kim, Seunghwan},
	month = feb,
	year = {2020},
	keywords = {HRA data, Human error probability, Human performance data, Human reliability analysis (HRA), Simulator data},
	pages = {106235},
}

@article{cepin_depend-hramethod_2008,
	title = {{DEPEND}-{HRA}—{A} method for consideration of dependency in human reliability analysis},
	volume = {93},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832007002505},
	doi = {10.1016/j.ress.2007.10.004},
	abstract = {A consideration of dependencies between human actions is an important issue within the human reliability analysis. A method was developed, which integrates the features of existing methods and the experience from a full scope plant simulator. The method is used on real plant-specific human reliability analysis as a part of the probabilistic safety assessment of a nuclear power plant. The method distinguishes dependency for pre-initiator events from dependency for initiator and post-initiator events. The method identifies dependencies based on scenarios, where consecutive human actions are modeled, and based on a list of minimal cut sets, which is obtained by running the minimal cut set analysis considering high values of human error probabilities in the evaluation. A large example study, which consisted of a large number of human failure events, demonstrated the applicability of the method. Comparative analyses that were performed show that both selection of dependency method and selection of dependency levels within the method largely impact the results of probabilistic safety assessment. If the core damage frequency is not impacted much, the listings of important basic events in terms of risk increase and risk decrease factors may change considerably. More efforts are needed on the subject, which will prepare the background for more detailed guidelines, which will remove the subjectivity from the evaluations as much as it is possible.},
	language = {en},
	number = {10},
	urldate = {2021-11-08},
	journal = {Reliability Engineering \& System Safety},
	author = {Čepin, Marko},
	month = oct,
	year = {2008},
	keywords = {Dependent events, Human reliability analysis, Post-initiators, Pre-initiators},
	pages = {1452--1460},
}

@article{groth_bridging_2013,
	title = {Bridging the gap between {HRA} research and {HRA} practice: {A} {Bayesian} network version of {SPAR}-{H}},
	volume = {115},
	issn = {0951-8320},
	shorttitle = {Bridging the gap between {HRA} research and {HRA} practice},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832013000501},
	doi = {10.1016/j.ress.2013.02.015},
	abstract = {The shortcomings of Human Reliability Analysis (HRA) have been a topic of discussion for over two decades. Repeated attempts to address these limitations have resulted in over 50 HRA methods, and the HRA research community continues to develop new methods. However, there remains a gap between the methods developed by HRA researchers and those actually used by HRA practitioners. Bayesian Networks (BNs) have become an increasingly popular part of the risk and reliability analysis framework over the past decade. BNs provide a framework for addressing many of the shortcomings of HRA from a researcher perspective and from a practitioner perspective. Several research groups have developed advanced HRA methods based on BNs, but none of these methods has been adopted by HRA practitioners in the U.S. nuclear power industry or at the U.S. Nuclear Regulatory Commission. In this paper we bridge the gap between HRA research and HRA practice by building a BN version of the widely used SPAR-H method. We demonstrate how the SPAR-H BN can be used by HRA practitioners, and we also demonstrate how it can be modified to incorporate data and information from research to advance HRA practice. The SPAR-H BN can be used as a starting point for translating HRA research efforts and advances in scientific understanding into real, timely benefits for HRA practitioners.},
	language = {en},
	urldate = {2021-11-08},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina M. and Swiler, Laura P.},
	month = jul,
	year = {2013},
	keywords = {Bayesian network (BN), Causality, Context uncertainty, Human reliability analysis (HRA), SPAR-H},
	pages = {33--42},
}

@misc{venter_module_2010,
	title = {Module 6d - {Pebble} {Bed} {HTGR} {Refueling} {Design}},
	url = {https://art.inl.gov/NGNP/Training%20Modules%20%20HTGR%20Fundamentals/Module%206d%20-%20Pebble%20Bed%20HTGR%20Refueling%20Design.pdf},
	language = {English},
	urldate = {2021-11-07},
	author = {Venter, Pieter},
	month = may,
	year = {2010},
}

@misc{kadak_politically_2002,
	address = {Washington, D.C},
	title = {The {Politically} {Correct} {Nuclear} {Energy} {Plant} - {Modular} {Pebble} {Bed} {Reactor} {High} {Temperature} {Gas} {Reactor}},
	url = {https://web.mit.edu/pebble-bed/Presentation/MPBRHTGR.pdf},
	language = {English},
	urldate = {2021-11-07},
	author = {Kadak, Andrew C},
	month = nov,
	year = {2002},
}

@misc{noauthor_nuclear_2010,
	title = {Nuclear {Engineering} {International}},
	url = {https://web.archive.org/web/20100626054414/http://www.neimagazine.com/story.asp?sectioncode=76&storyCode=2053102},
	urldate = {2021-11-07},
	month = jun,
	year = {2010},
}

@article{silva_reconsideration_2018,
	title = {Reconsideration of {PRA} {Framework} – {Addressing} {Level} 3 {PRA} {Coverage} and {Multi}-unit {Issues}},
	abstract = {The accident at the Fukushima Daiichi Nuclear Power Station (1FNPS) stimulated the consideration of the total risk of accident among PRA analysts. Several solutions have been proposed, including the enlargement of the scope of traditional level 3 PRA framework and the consideration of multi-unit effects. This study aims to identify foreseen issues arising from these solutions, and to propose an alternative approach to evaluate the total risk of accident. Enlargement of PRA coverage can create (1) difficulty attributed to multidisciplinary approach, (2) difficulty in acquisition and management of excessive amount of data, (3) difficulty in decision-making, and (4) difficulty in communicating with stakeholders. An alternative approach is proposed to address these issues. It is better to stick with the traditional PRA scope, and cover multi-unit evaluation and consideration of various accident consequences by the qualitative or semi-quantitative assessment. All results are put on the table and go through deliberation process where all parties gather and discuss the results before making decisions. The alternative approach enables the assessment of the total risk of accident without facing all aforementioned issues.},
	language = {en},
	journal = {Los Angeles},
	author = {Silva, Kampanart and Sugawara, Shin-etsu},
	year = {2018},
	pages = {8},
}

@misc{silva_reconsideration_2018-1,
	title = {Reconsideration of {PRA} {Framework} – {Addressing} {Level} 3 {PRA} {Coverage} and {Multi}-unit {Issues}},
	url = {https://www.semanticscholar.org/paper/Reconsideration-of-PRA-Framework-%E2%80%93-Addressing-Level-Silva-Sugawara/b65fd3172ee33631ea0efc5b82a2dc7f7ee9f1c2},
	abstract = {The accident at the Fukushima Daiichi Nuclear Power Station (1FNPS) stimulated the consideration of the total risk of accident among PRA analysts. Several solutions have been proposed, including the enlargement of the scope of traditional level 3 PRA framework and the consideration of multi-unit effects. This study aims to identify foreseen issues arising from these solutions, and to propose an alternative approach to evaluate the total risk of accident. Enlargement of PRA coverage can create (1) difficulty attributed to multidisciplinary approach, (2) difficulty in acquisition and management of excessive amount of data, (3) difficulty in decision-making, and (4) difficulty in communicating with stakeholders. An alternative approach is proposed to address these issues. It is better to stick with the traditional PRA scope, and cover multi-unit evaluation and consideration of various accident consequences by the qualitative or semi-quantitative assessment. All results are put on the table and go through deliberation process where all parties gather and discuss the results before making decisions. The alternative approach enables the assessment of the total risk of accident without facing all aforementioned issues.},
	language = {en},
	urldate = {2021-11-06},
	author = {Silva, K. and Sugawara, Shin-etsu},
	year = {2018},
}

@techreport{moe_modernization_2019,
	title = {Modernization of {Technical} {Requirements} or {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} or {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1560527-modernization-technical-requirements-licensing-advanced-non-light-water-reactors-probabilistic-risk-assessment-approach},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Probabilistic Risk Assessment Approach,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs).},
	language = {English},
	number = {INL/EXT-19-55514-Rev000; SC-29980-101.Rev0},
	urldate = {2021-11-06},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company Services, Birmingham, AL (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = aug,
	year = {2019},
	doi = {10.2172/1560527},
}

@misc{noauthor_appendix_nodate,
	title = {{APPENDIX} {A}: {GAS} {AND} {PEBBLE} {BED} {REACTORS} {AND} {THEIR} {FUELS}},
	url = {https://www.nrc.gov/docs/ML1204/ML12045A014.pdf},
	abstract = {3/10 Rev 4 Fuel Cycle Processes Directed Self-Study Course},
	language = {English},
	urldate = {2021-11-05},
	publisher = {USNRC Technical Training Center},
}

@article{kadak_future_2005,
	title = {A future for nuclear energy: pebble bed reactors},
	volume = {1},
	issn = {1475-3219, 1741-8038},
	shorttitle = {A future for nuclear energy},
	url = {http://www.inderscience.com/link.php?id=6679},
	doi = {10.1504/IJCIS.2005.006679},
	abstract = {Pebble Bed Reactors could allow nuclear plants to support the goal of reducing global climate change in an energy hungry world. They are small, modular, inherently safe, use a demonstrated nuclear technology and can be competitive with fossil fuels. Pebble bed reactors are helium cooled reactors that use small tennis ball size fuel balls consisting of only 9 grams of uranium per pebble to provide a low power density reactor. The low power density and large graphite core provide inherent safety features such that the peak temperature reached even under the complete loss of coolant accident without any active emergency core cooling system is significantly below the temperature that the fuel melts. This feature should enhance public confidence in this nuclear technology. With advanced modularity principles, it is expected that this type of design and assembly could lower the cost of new nuclear plants removing a major impediment to deployment.},
	language = {en},
	number = {4},
	urldate = {2021-11-05},
	journal = {International Journal of Critical Infrastructures},
	author = {Kadak, Andrew C.},
	year = {2005},
	pages = {330},
}

@techreport{noauthor_nrc_2020,
	type = {{DRAFT}},
	title = {{NRC} {Non}-{Light} {Water} {Reactor} ({Non}-{LWR}) {Vision} and {Strategy}, {Volume} 5 {Radionuclide} {Characterization}, {Criticality}, {Shielding}, and {Transport} in the {Nuclear} {Fuel} {Cycle}, {Draft}},
	url = {https://www.nrc.gov/docs/ML2030/ML20308A744.pdf},
	language = {en},
	institution = {United states Nuclear Regulatory Commission},
	month = nov,
	year = {2020},
	pages = {72},
}

@misc{reitsma_introduction_2019,
	title = {Introduction to the {CRP} on modular {HTGR} {Safety} {Design}: {Background} and {Overview}; {Definition} of modular {HTGR}; {Status}},
	url = {https://nucleus-new.iaea.org/sites/htgr-kb/gif-iaea/Shared%20Documents/1st%20GIF-IAEA-mHTGR/A7_Reitsma_IAEA_GIF_Safety_mHTGR-Dec2019.pdf},
	language = {en},
	author = {Reitsma, Frederik},
	month = dec,
	year = {2019},
	note = {Frederik Reitsma
Team Leader, SMR Technology Development
Nuclear Power Technology Development Section
Division of Nuclear Power, Department of Nuclear Energy},
}

@article{fang_safety_2017,
	title = {Safety {Features} of {High} {Temperature} {Gas} {Cooled} {Reactor}},
	volume = {2017},
	issn = {1687-6075},
	url = {https://www.hindawi.com/journals/stni/2017/9160971/},
	doi = {10.1155/2017/9160971},
	language = {en},
	urldate = {2021-11-05},
	journal = {Science and Technology of Nuclear Installations},
	author = {Fang, Chao and Morris, Robert and Li, Fu},
	month = nov,
	year = {2017},
	note = {Publisher: Hindawi},
	pages = {e9160971},
}

@misc{noauthor_nuclear_2020,
	title = {Nuclear power and the environment},
	url = {https://www.nupic.com/NUPIC/Home/HotTopics.aspx},
	urldate = {2021-09-24},
	journal = {U.S. Energy Information Administration},
	month = jan,
	year = {2020},
}

@misc{noauthor_nukleer_nodate,
	title = {Nükleer enerji ve çevre - {ABD} {Enerji} {Bilgi} İdaresi ({EIA})},
	url = {https://www.eia.gov/energyexplained/nuclear/nuclear-power-and-the-environment.php},
	urldate = {2021-11-04},
}

@misc{noauthor_x-energy_nodate,
	title = {X-energy is {Developing} a {Pebble} {Bed} {Reactor} {That} {They} {Say} {Can}'t {Melt} {Down}},
	url = {https://www.energy.gov/ne/articles/x-energy-developing-pebble-bed-reactor-they-say-cant-melt-down},
	abstract = {This pebble bed, high-temperature gas-cooled reactor can't melt down, according to X-energy.},
	language = {en},
	urldate = {2021-11-04},
	journal = {Energy.gov},
}

@article{boring_atomistic_2005,
	title = {Atomistic and holistic approaches to human reliability analysis in the {US} nuclear power industry:},
	volume = {25},
	shorttitle = {Atomistic and holistic approaches to human reliability analysis in the {US} nuclear power industry},
	doi = {10.1080/09617353.2005.11690802},
	abstract = {A variety of methods have been developed to generate human error probabilities in the US nuclear power industry. When actual operations data are not available, it is necessary for an analyst to estimate these probabilities. Most approaches, including THERP, ASEP, SLIM-MAUD, and SPAR-H, feature an atomistic approach to characterizing and estimating error. The atomistic approach is based on the notion that events and their causes can be decomposed and individually quantified. In contrast, in the holistic approach, such as found in ATHEANA, the analysis centers on the entire event, which is quantified as an indivisible whole. The distinction between atomistic and holistic approaches is important in understanding the nature of human reliability analysis quantification and the utility and shortcomings associated with each approach.},
	journal = {Safety and Reliability},
	author = {Boring, Ronald and Gertman, David},
	month = jun,
	year = {2005},
	pages = {21--37},
}

@article{zhou_analysis_2020,
	title = {Analysis of {Measuring} {Characteristics} of the {Differential} {Pressure} {Water}-{Level} {Measurement} {System} {Under} {Depressurization} {Condition}},
	volume = {8},
	issn = {2296-598X},
	url = {https://www.frontiersin.org/article/10.3389/fenrg.2020.00145},
	doi = {10.3389/fenrg.2020.00145},
	abstract = {In this paper, RELAP5 code was selected to study the measuring characteristics of the double reference tube level gauge, which is commonly used in high temperature and high pressure vessels on marine nuclear power platforms, under steady and transient depressurization conditions. The response characteristics of water-level gauge, influenced by the reference cup supply water flow rate under the condition of rapid depressurization, is discussed. Measurement error and accuracy of the water-level measuring device are analyzed under both steady and transient conditions. The simulation results indicate that the relative error of the double reference tube level gauge is about 0.79\% in steady state, while the measurement error is too large to accurately obtain the level in the vessel under the transient depressurization condition. However, the relative measurement error can reach about 10\% under the condition of a small depressurization rate.},
	urldate = {2021-11-02},
	journal = {Frontiers in Energy Research},
	author = {Zhou, Xuwei and Cheng, Jie and She, Luchao and Fan, Guangming},
	year = {2020},
	pages = {145},
}

@article{zvoncek_development_2017,
	title = {Development of a {Fully}-{Coupled}, {All} {States}, {All} {Hazards} {Level} 2 {PSA} at {Leibstadt} {Nuclear} {Power} {Plant}},
	volume = {49},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573316303278},
	doi = {10.1016/j.net.2017.01.016},
	abstract = {This paper describes the development process, the innovative techniques used and insights gained from the latest integrated, full scope, multistate Level 2 PSA analysis conducted at the Leibstadt Nuclear Power Plant (KKL), Switzerland. KKL is a modern single-unit General Electric Boiling Water Reactor (BWR/6) with Mark III Containment, and a power output of 3600MWth/1200MWe, the highest among the ﬁve operating reactors in Switzerland.},
	language = {en},
	number = {2},
	urldate = {2021-10-29},
	journal = {Nuclear Engineering and Technology},
	author = {Zvoncek, Pavol and Nusbaumer, Olivier and Torri, Alfred},
	month = mar,
	year = {2017},
	pages = {426--433},
}

@article{chang_cognitive_2007,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents: {Part} 5: {Dynamic} probabilistic simulation of the {IDAC} model},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832006001256},
	doi = {10.1016/j.ress.2006.05.012},
	abstract = {This is the last in a series of five papers that discuss the Information Decision and Action in Crew (IDAC) context for human reliability analysis (HRA) and example application. The model is developed to probabilistically predict the responses of the control room operating crew in nuclear power plants during an accident, for use in probabilistic risk assessments (PRA). The operator response spectrum includes cognitive, emotional, and physical activities during the course of an accident. This paper describes a dynamic PRA computer simulation program, accident dynamics simulator (ADS), developed in part to implement the IDAC model. This paper also provides a detailed example of implementing a simpler version of IDAC, compared with the IDAC model discussed in the first four papers of this series, to demonstrate the practicality of integrating a detailed cognitive HRA model within a dynamic PRA framework.},
	number = {8},
	urldate = {2019-01-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive simulation, Dynamic probabilistic risk assessment, Human reliability analysis},
	pages = {1076--1101},
}

@article{chang_cognitive_2007-1,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents: {Part} 3: {IDAC} operator response model},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832006001268},
	doi = {10.1016/j.ress.2006.05.013},
	abstract = {This is the third in a series of five papers describing the IDAC (Information, Decision, and Action in Crew context) model for human reliability analysis. An example application of this modeling technique is also discussed in this series. The model is developed to probabilistically predict the responses of the nuclear power plant control room operating crew in accident conditions. The operator response spectrum includes cognitive, emotional, and physical activities during the course of an accident. This paper discusses the modeling components and their process rules. An operator's problem-solving process is divided into three types: information pre-processing (I), diagnosis and decision-making (D), and action execution (A). Explicit and context-dependent behavior rules for each type of operator are developed in the form of tables, and logical or mathematical relations. These regulate the process and activities of each of the three types of response. The behavior rules are developed for three generic types of operator: Decision Maker, Action Taker, and Consultant. This paper also provides a simple approach to calculating normalized probabilities of alternative behaviors given a context.},
	number = {8},
	urldate = {2019-01-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive, Dynamic probabilistic risk assessment, Human reliability analysis, Performance influencing factors, Performance shaping factors},
	pages = {1041--1060},
}

@article{chang_cognitive_2007-2,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents. {Part} 4: {IDAC} causal model of operator problem-solving response},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents. {Part} 4},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832006001244},
	doi = {10.1016/j.ress.2006.05.011},
	abstract = {This is the fourth in a series of five papers describing the Information, Decision, and Action in Crew context (IDAC) operator response model for human reliability analysis. An example application of this modeling technique is also discussed in this series. The model has been developed to probabilistically predicts the responses of a nuclear power plant control room operating crew in accident conditions. The operator response spectrum includes cognitive, emotional, and physical activities during the course of an accident. This paper assesses the effects of the performance-influencing factors (PIFs) affecting the operators’ problem-solving responses including information pre-processing (I), diagnosis and decision making (D), and action execution (A). Literature support and justifications are provided for the assessment on the influences of PIFs.},
	number = {8},
	urldate = {2019-01-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive and dynamic probabilistic risk assessment, Human reliability analysis, Performance shaping factors, Performance-influencing factors},
	pages = {1061--1075},
}

@article{chang_cognitive_2007-3,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents: {Part} 1: {Overview} of the {IDAC} {Model}},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832006001232},
	doi = {10.1016/j.ress.2006.05.014},
	abstract = {This is the first in a series of five papers that discuss the information, decision, and action in crew context (IDAC) model for human reliability analysis (HRA). An example application of this modeling technique is also discussed in this series. The model is developed to probabilistically predict the responses of the nuclear power plant control room-operating crew during an accident for use in probabilistic risk assessments. The operator response spectrum includes cognitive, emotional, and physical activities during the course of the accident. This paper provides an overview of the IDAC architecture and principles of implementation as a HRA model. IDAC includes a crew model of three types of operators: decision maker, action taker, and consultant. Within the crew context, each individual operator's behaviors are simulated through a cognitive model under the influence of a number of explicitly modeled performance-influencing factors.},
	number = {8},
	urldate = {2019-01-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive response, Dynamic probabilistic risk assessment, Human reliability analysis, Simulation},
	pages = {997--1013},
}

@article{chang_cognitive_2007-4,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents. {Part} 2: {IDAC} performance influencing factors model},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents. {Part} 2},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832006001220},
	doi = {10.1016/j.ress.2006.05.010},
	abstract = {This is the second in a series of five papers describing the information, decision, and action in crew context (IDAC) model for human reliability analysis. An example application of this modeling technique is also discussed in this series. The model is developed to probabilistically predict the responses of the nuclear power plant control room operating crew in accident conditions. The operator response spectrum includes cognitive, psychological, and physical activities during the course of an accident. This paper identifies the IDAC set of performance influencing factors (PIFs), providing their definitions and causal organization in the form of a modular influence diagram. Fifty PIFs are identified to support the IDAC model to be implemented in a computer simulation environment. They are classified into eleven hierarchically structured groups. The PIFs within each group are independent to each other; however, dependencies may exist between PIFs within different groups. The supporting evidence for the selection and organization of the influence paths based on psychological literature, observations, and various human reliability analysis methodologies is also indicated.},
	number = {8},
	urldate = {2019-01-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive, Dynamic probabilistic risk assessment, Human reliability analysis, Performance influencing factors, Performance shaping factors},
	pages = {1014--1040},
}

@phdthesis{diaconeasa_integration_2017,
	type = {{PhD}},
	title = {Integration of {Qualitative} and {Quantitative} {Hybrid} {Causal} {Logic} into a {Simulation}-based {Platform} for {Probabilistic} {Risk} {Assessment} of {Nuclear} {Power} {Plants}},
	url = {https://escholarship.org/uc/item/9wc84881},
	abstract = {Dynamic Probabilistic Risk Assessment (PRA) refers to an emerging class of PRA methods that generate risk scenarios through the model-based simulation of systems such as nuclear power plants (NPPs) and their crew response to accident initiators. The dynamic PRA approach offers several advantages over the conventional approaches currently used by the nuclear industry worldwide. These advantages include: (1) time-dependent prediction of the operator error-forcing contexts, (2) better representation of the thermal-hydraulic success criteria, and (3) considerable reduction in analyst-to-analyst variability of the results. An example of such a simulation platform is the Accident Dynamics Simulator coupled with the Information, Decision and Action in a Crew context cognitive model (ADS-IDAC), and a realistic NPP thermal-hydraulic model. The aim of this research is to integrate qualitative and quantitative hybrid causal logic into the ADS-IDAC dynamic PRA platform. This makes ADS-IDAC a more practical and realistic analysis tool for specific applications. These applications are primarily event assessments, but also include the ability to analyze highly dynamic and complex accident scenarios in support of conventional PRAs. This work offers major modeling enhancements of ADS-IDAC, including dynamically linked fault trees (FTs) for support and frontline systems modeling, more advanced system and operating crew modeling capabilities, comprehensive quantification features modeling human failure evens (HFEs), and uncertainty propagation through the generated discrete dynamic event tree (DDET). The new risk assessment process was streamlined with the help of a newly developed user-friendly graphical interface, which provides efficient and convenient access to all the capabilities of the ADS-IDAC simulation engine.},
	language = {en\_US},
	urldate = {2019-01-20},
	school = {University of California, Los Angeles},
	author = {Diaconeasa, Mihai Aurelian},
	year = {2017},
}

@phdthesis{li_modeling_2013,
	type = {{PhD}},
	title = {Modeling and {Simulation} of {Operator} {Knowledge}-based {Behavior}},
	url = {http://drum.lib.umd.edu/handle/1903/14288},
	abstract = {Many accidents are attributed to human errors. Abundant evidences could be found in major accidents in petro-chemical, nuclear, aviation, and other industries. In the nuclear power industry, safe operation heavily relies on the operators' interaction with plant systems. For example, Three Mile Island accident was exacerbated by the operators' misdiagnosis of the situation, which led to the termination of the plant's automatic protection system that could have prevented meltdown of the reactor core. Hence, human Reliability Analysis (HRA) is an important ingredient of Probabilistic Risk Assessment (PRA), particularly in the nuclear industry. HRA aims to predict possible human errors, identify "error forcing contexts", and assess error probabilities. Despite advances in HRA discipline over the past two decades, virtually all existing methods lack a causal model and few leverage the theoretical and empirical insights for error prediction in a systematic and formal way. One approach that has attempted to address this major shortcoming is IDAC crew simulation model of ADS-IDAC dynamic PRA platform. Through the interactions between an IDAC crew model and a pressurizer water reactor plant model, ADS-IDAC dynamically simulates the operators' cognitive activities and actions in an accident condition. The goal of proposed research is to introduce an advanced reasoning capability and structured knowledge representation to enhance the realism and predictive power of in the IDAC model for situations where crew behaviors are governed by both the Emergency Operating Procedure (EOP) and their knowledge of the plant. This is achieved by: 1) Developing and implementing a cognitive architecture to simulate operators' understanding of accident conditions and plant response, their reasoning processes and knowledge utilization to make a diagnosis. A reasoning module has been added to the individual operator model within IDAC model to mimic operators knowledge-based reasoning processes; 2) Developing and applying a comprehensive set of Performance Shaping Factors (PSF) to model the impacts of situational and cognitive factors on operators' behaviors. The effects and interdependencies of PSFs are incorporated the reasoning module; and 3) Performing a calibration and validation of the model predictions by comparing the simulation results with results of a number of plant-crew simulator exercises.},
	language = {en},
	urldate = {2019-02-01},
	school = {University of Maryland},
	author = {Li, Yuandan},
	year = {2013},
}

@phdthesis{coyne_predictive_2009,
	type = {{PhD}},
	title = {A {Predictive} {Model} of {Nuclear} {Power} {Plant} {Crew} {Decision}-{Making} and {Performance} in a {Dynamic} {Simulation} {Environment}},
	url = {http://drum.lib.umd.edu/handle/1903/9888},
	abstract = {The safe operation of complex systems such as nuclear power plants requires close coordination between the human operators and plant systems.  In order to maintain an adequate level of safety following an accident or other off-normal event, the operators often are called upon to perform complex tasks during dynamic situations with incomplete information.  The safety of such complex systems can be greatly improved if the conditions that could lead operators to make poor decisions and commit erroneous actions during these situations can be predicted and mitigated.  The primary goal of this research project was the development and validation of a cognitive model capable of simulating nuclear plant operator decision-making during accident conditions.  

Dynamic probabilistic risk assessment methods can improve the prediction of human error events by providing rich contextual information and an explicit consideration of feedback arising from man-machine interactions.  The Accident Dynamics Simulator paired with the Information, Decision, and Action in a Crew context cognitive model (ADS-IDAC) shows promise for predicting situational contexts that might lead to human error events, particularly knowledge driven errors of commission.  ADS-IDAC generates a discrete dynamic event tree (DDET) by applying simple branching rules that reflect variations in crew responses to plant events and system status changes.  Branches can be generated to simulate slow or fast procedure execution speed, skipping of procedure steps, reliance on memorized information, activation of mental beliefs, variations in control inputs, and equipment failures.  Complex operator mental models of plant behavior that guide crew actions can be represented within the ADS-IDAC mental belief framework and used to identify situational contexts that may lead to human error events.  

This research increased the capabilities of ADS-IDAC in several key areas.  The ADS-IDAC computer code was improved to support additional branching events and provide a better representation of the IDAC cognitive model.  An operator decision-making engine capable of responding to dynamic changes in situational context was implemented.  The IDAC human performance model was fully integrated with a detailed nuclear plant model in order to realistically simulate plant accident scenarios.  Finally, the improved ADS-IDAC model was calibrated, validated, and updated using actual nuclear plant crew performance data.  This research led to the following general conclusions:

(1) A relatively small number of branching rules are capable of efficiently capturing a wide spectrum of crew-to-crew variabilities.

(2) Compared to traditional static risk assessment methods, ADS-IDAC can provide a more realistic and integrated assessment of human error events by directly determining the effect of operator behaviors on plant thermal hydraulic parameters.  

(3) The ADS-IDAC approach provides an efficient framework for capturing actual operator performance data such as timing of operator actions, mental models, and decision-making activities.},
	language = {en},
	urldate = {2019-02-01},
	school = {University of Maryland},
	author = {Coyne, Kevin},
	year = {2009},
}

@techreport{acosta_dynamic_1991,
	address = {Cambridge, MA},
	type = {Technical {Report}},
	title = {Dynamic event tree analysis method ({DETAM}) for accident sequence analysis},
	url = {http://dspace.mit.edu/handle/1721.1/89676},
	abstract = {Includes bibliographical references (pages 133-138)},
	urldate = {2019-02-01},
	institution = {Dept. of Nuclear Engineering, Massachusetts Institute of Technology},
	author = {Acosta, Crispiniano and Siu, Nathan O.},
	year = {1991},
}

@article{izquierdo_relationship_1996,
	title = {Relationship between probabilistic dynamics and event trees},
	volume = {52},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832095001344},
	doi = {10.1016/0951-8320(95)00134-4},
	language = {en},
	number = {3},
	urldate = {2021-10-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Izquierdo, J.M. and Melendez, E. and Devooght, J.},
	month = jun,
	year = {1996},
	pages = {197--209},
}

@article{acosta_dynamic_1993,
	title = {Dynamic event trees in accident sequence analysis: application to steam generator tube rupture},
	volume = {41},
	issn = {09518320},
	shorttitle = {Dynamic event trees in accident sequence analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209390027V},
	doi = {10.1016/0951-8320(93)90027-V},
	language = {en},
	number = {2},
	urldate = {2021-10-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Acosta, C. and Siu, N.},
	month = jan,
	year = {1993},
	pages = {135--154},
}

@article{karanki_quantification_2016,
	title = {Quantification of {Dynamic} {Event} {Trees} – {A} comparison with event trees for {MLOCA} scenario},
	volume = {147},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832015003105},
	doi = {10.1016/j.ress.2015.10.017},
	abstract = {Dynamic event trees (DETs) provide the means to simulate physical system evolutions, the evolution of system states due to stochastic events, and the dynamic interactions between these evolutions. For risk assessment, the framework avoids the need to specify a priori the sequence of stochastic events prior to the plant response simulation and to iterate between the deﬁnition of the sequences and simulation of the responses. For nuclear power plants, DETs have been applied to treat scenarios up to core damage as well as post-core damage accident scenarios. The quantiﬁcation of the frequencies of the sequences leading to the undesired system outcomes, while conceptually straightforward, faces several implementation issues. These include, for instance, the treatment of support system dependencies and of events characterized by a continuous aleatory variable. Some solutions to these issues are proposed and applied in a case study dealing with Medium Break Loss of Coolant Accident (MLOCA) scenarios. Additionally, the results obtained from DET quantiﬁcation are compared with those estimated with a “classical” event tree model for these scenarios. This comparison provides some case-speciﬁc results on the impact of the improved modeling of dynamics on risk estimates.},
	language = {en},
	urldate = {2021-10-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Karanki, Durga Rao and Dang, Vinh N.},
	month = mar,
	year = {2016},
	pages = {19--31},
}

@misc{waksman_project_2020,
	title = {Project {Pele} {Overview}: {Mobile} {Nuclear} {Power} for {Future} {DoD} {Needs}},
	copyright = {Approved for Public Release},
	shorttitle = {Project {Pele} {Overview}},
	url = {https://hdiac.org/wp-content/uploads/2020/08/2020-08-12-HDIAC-Webinar-Pele-Program-Overview-Public.pdf},
	language = {English},
	author = {Waksman, Jeff},
	month = mar,
	year = {2020},
}

@article{saito_detailed_2015,
	title = {Detailed deposition density maps constructed by large-scale soil sampling for gamma-ray emitting radioactive nuclides from the {Fukushima} {Dai}-ichi {Nuclear} {Power} {Plant} accident},
	volume = {139},
	issn = {0265931X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X14000642},
	doi = {10.1016/j.jenvrad.2014.02.014},
	abstract = {Soil deposition density maps of gamma-ray emitting radioactive nuclides from the Fukushima Dai-ichi Nuclear Power Plant (NPP) accident were constructed on the basis of results from large-scale soil sampling. In total 10,915 soil samples were collected at 2168 locations. Gamma rays emitted from the samples were measured by Ge detectors and analyzed using a reliable uniﬁed method. The determined radioactivity was corrected to that of June 14, 2011 by considering the intrinsic decay constant of each nuclide. Finally the deposition maps were created for 134Cs, 137Cs, 131I, 129mTe and 110mAg. The radioactivity ratio of 134Cse137Cs was almost constant at 0.91 regardless of the locations of soil sampling. The radioactivity ratios of 131I and 129mTee137Cs were relatively high in the regions south of the Fukushima NPP site. Effective doses for 50 y after the accident were evaluated for external and inhalation exposures due to the observed radioactive nuclides. The radiation doses from radioactive cesium were found to be much higher than those from the other radioactive nuclides.},
	language = {en},
	urldate = {2021-10-27},
	journal = {Journal of Environmental Radioactivity},
	author = {Saito, Kimiaki and Tanihata, Isao and Fujiwara, Mamoru and Saito, Takashi and Shimoura, Susumu and Otsuka, Takaharu and Onda, Yuichi and Hoshi, Masaharu and Ikeuchi, Yoshihiro and Takahashi, Fumiaki and Kinouchi, Nobuyuki and Saegusa, Jun and Seki, Akiyuki and Takemiya, Hiroshi and Shibata, Tokushi},
	month = jan,
	year = {2015},
	pages = {308--319},
}

@article{tofani_ranking_2008,
	title = {Ranking {Nuclear} and {Radiological} {Terrorism} {Scenarios}: {The} {Italian} {Case}},
	volume = {28},
	issn = {02724332, 15396924},
	shorttitle = {Ranking {Nuclear} and {Radiological} {Terrorism} {Scenarios}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.2008.01100.x},
	doi = {10.1111/j.1539-6924.2008.01100.x},
	language = {en},
	number = {5},
	urldate = {2021-10-25},
	journal = {Risk Analysis},
	author = {Tofani, Alessandro and Bartolozzi, Massimiliano},
	month = oct,
	year = {2008},
	pages = {1431--1444},
}

@article{schleimer_day_1974,
	title = {The {Day} {They} {Blew} {Up} {San} {Onofre}: {A} scenario for sabotage at a nuclear power plant},
	volume = {30},
	issn = {0096-3402, 1938-3282},
	shorttitle = {The {Day} {They} {Blew} {Up} {San} {Onofre}},
	url = {http://www.tandfonline.com/doi/full/10.1080/00963402.1974.11458151},
	doi = {10.1080/00963402.1974.11458151},
	language = {en},
	number = {8},
	urldate = {2021-10-25},
	journal = {Bulletin of the Atomic Scientists},
	author = {Schleimer, Joseph D.},
	month = oct,
	year = {1974},
	pages = {24--27},
}

@article{ustinova_methods_2014,
	title = {Methods for {Analyzing} the {Risk} of {Nuclear} {Sabotage}},
	volume = {116},
	issn = {1063-4258, 1573-8205},
	url = {http://link.springer.com/10.1007/s10512-014-9875-3},
	doi = {10.1007/s10512-014-9875-3},
	language = {en},
	number = {6},
	urldate = {2021-10-25},
	journal = {Atomic Energy},
	author = {Ustinova, E. V.},
	month = oct,
	year = {2014},
	pages = {433--436},
}

@article{pence_gisbased_2019-1,
	title = {{GIS}‐{Based} {Integration} of {Social} {Vulnerability} and {Level} 3 {Probabilistic} {Risk} {Assessment} to {Advance} {Emergency} {Preparedness}, {Planning}, and {Response} for {Severe} {Nuclear} {Power} {Plant} {Accidents}},
	volume = {39},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/risa.13241},
	doi = {10.1111/risa.13241},
	language = {en},
	number = {6},
	urldate = {2021-10-25},
	journal = {Risk Analysis},
	author = {Pence, Justin and Miller, Ian and Sakurahara, Tatsuya and Whitacre, James and Reihani, Seyed and Kee, Ernie and Mohaghegh, Zahra},
	month = jun,
	year = {2019},
	pages = {1262--1280},
}

@article{fairlie_no_1997,
	title = {No dose too low},
	volume = {53},
	issn = {0096-3402, 1938-3282},
	url = {https://www.tandfonline.com/doi/full/10.1080/00963402.1997.11456790},
	doi = {10.1080/00963402.1997.11456790},
	language = {en},
	number = {6},
	urldate = {2021-10-25},
	journal = {Bulletin of the Atomic Scientists},
	author = {Fairlie, Ian and Resnikoff, Marvin},
	month = nov,
	year = {1997},
	pages = {52--56},
}

@article{fabrikant_chernobyl_1987,
	title = {The {Chernobyl} {Disaster}: {An} {International} {Perspective}},
	volume = {1},
	issn = {0921-8106},
	shorttitle = {The {Chernobyl} {Disaster}},
	url = {http://journals.sagepub.com/doi/10.1177/108602668700100401},
	doi = {10.1177/108602668700100401},
	abstract = {The most important human issue in industrial crisis management remains the health and safety of people, both as individuals and of large populations at risk. The events of Three Mile Island, Bhopal, and Tylenol evolved\&mdash;in large measure\&mdash;as local or national crises, and responses to cope with these events were primarily local and national. In contrast, the catastrophic accident at the Chernobyl nuclear power plant in the Soviet Ukraine elicited major international responses, particularly from Western European and American authorities, for a critical period before the Soviet Union admitted openly that an accident had occurred. While the event of Chernobyl significantly affected a sizeable worker population and residents in the immediate vicinity, it had an adverse but lesser impact on the rest of the Soviet Union, Europe, Asia, and North America. This paper provides some background on the accident, examines how large amounts of radioactive materials were released into the environment, how they may have found their way into humans, how nations responded to the accident, and what some of the international implications for decision and policy making may be.},
	language = {en},
	number = {4},
	urldate = {2021-10-25},
	journal = {Industrial Crisis Quarterly},
	author = {Fabrikant, Jacob I.},
	month = dec,
	year = {1987},
	pages = {2--12},
}

@article{anspaugh_global_1988,
	title = {The {Global} {Impact} of the {Chernobyl} {Reactor} {Accident}},
	volume = {242},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.3201240},
	doi = {10.1126/science.3201240},
	language = {en},
	number = {4885},
	urldate = {2021-10-25},
	journal = {Science},
	author = {Anspaugh, Lynn R. and Catlin, Robert J. and Goldman, Marvin},
	month = dec,
	year = {1988},
	pages = {1513--1519},
}

@article{henneke_use_2017,
	title = {The use of comprehensive in-process peer reviews in support of the {UK} {ABWR} {PSA} generic design assessment process},
	issn = {9781510851801},
	shorttitle = {International {Topical} {Meeting} on {Probabilistic} {Safety} {Assessment} and {Analysis} ({PSA} 2017)},
	language = {eng},
	author = {Henneke, Dennis},
	collaborator = {American Nuclear Society},
	year = {2017},
	pages = {857--860},
}

@misc{noauthor_ncsu_nodate,
	title = {{NCSU} {Libraries} - {Tripsaver} - {Transaction} {Details}},
	url = {https://tripsaver.lib.ncsu.edu/illiad.dll?action=10&form=72},
	urldate = {2021-10-24},
}

@article{noauthor_research_2016,
	title = {Research and {Experiment} on the {Key} {Technologies} of the {Spent} {Fuel} {Storage} in {HTR}-{PM}},
	abstract = {High Temperature Reactor demonstration project of China (HTR-PM) is one of the major national science and technology projects, some key technologies for the design and operation of the demonstration project are formed to research according to the main technology. The spent fuel storage system is one of the main systems of the HTR-PM. In order to solve the technical problems related to the operation of spent fuel, several experiments have been conducted, including: spent fuel loading, getting back, spent fuel canister hoisting, storage well cover hoisting, storage canister drop and so on. In the study process, the test facility has been set up to carry on the operation and the experiment verification to ensure the reliability and safety of the spent fuel storage system.},
	language = {en},
	year = {2016},
	pages = {5},
}

@book{wang_research_2016,
	address = {United States},
	title = {Research and {Experiment} on the {Key} {Technologies} of the {Spent} {Fuel} {Storage} in {HTR}-{PM} - 18486},
	abstract = {High Temperature Reactor demonstration project of China (HTR-PM) is one of the major
national science and technology projects, some key technologies for the design and
operation of the demonstration project are formed to research according to the main
technology The spent fuel storage system is one of the main systems of the HTR-PM
In order to solve the technical problems related to the operation of spent fuel, several
experiments have been conducted, including: spent fuel loading, getting back, spent
fuel canister hoisting, storage well cover hoisting, storage canister drop and so
on In the study process, the test facility has been set up to carry on the operation
and the experiment verification to ensure the reliability and safety of the spent
fuel storage system Spent fuel storage system undertakes spent fuel receiving, spent
fuel canister transfer, storage, lifting and other functions in HTR-PM, the project
research need to solve several major technical problems related to the spent fuel
operation, which mainly include: Develop the transportable spent fuel canister for
HTR-PM, the canister is corrosion resistance, impact resistance, and is in subcritical
condition when loaded with fuel Develop the spent fuel canister hoister, which could
hoist the spent fuel canister safely and reliably Develop the spent fuel storage well
cover hoister, which could hoist the well cover safely and reliably Study the small
probability of the spent fuel canister in extreme condition of canister hoist falling
accidents, to ensure the radiation protect safety and residual heat removal safety
of the canister in case of the canister drop when lifting Develop the spent fuel charging
device and return device, which could load the spent fuel elements into the spent
fuel canister, and could take out the fuel elements from the canister The key technology
and equipment of the spent fuel storage system in HTR-PM would be solved through the
research of the project Project research is very important for the implementation
and safe operation of the HTR-PM project (authors)},
	publisher = {American Nuclear Society - ANS},
	author = {WANG, Jinhua and LI, Yue and WU, Bin},
	year = {2016},
	note = {INIS Reference Number: 52073021},
}

@article{so_level_2021,
	title = {Level 1 probabilistic safety assessment of supercritical–{CO2}–cooled micro modular reactor in conceptual design phase},
	volume = {53},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573320301935},
	doi = {10.1016/j.net.2020.07.029},
	abstract = {Micro reactors are increasingly being considered for utilization as distributed power sources. Hence, the probabilistic safety assessment (PSA) of a direct supercriticaleCO2ecooled fast reactor, called micro modular reactor (MMR), was performed in this study; this reactor was developed using innovative design concepts. It adopted a modular design and passive safety systems to minimize site constraints. As the MMR is in its conceptual design phase, design weaknesses and valuable safety insights could be identiﬁed during PSA. Level 1 internal event PSA was carried out involving literature survey, system characterization, identiﬁcation of initiating events, transient analyses, development of event trees and fault trees, and quantiﬁcation. The initiating events and scenarios signiﬁcantly contributing to core damage frequency (CDF) were determined to identify design weaknesses in MMR. The most signiﬁcant initiating event category contributing to CDF was the transients with the power conversion system initially available category, owing to its relatively high occurrence frequency. Further, an importance analysis revealed that the safety of MMR can be signiﬁcantly improved by improving the reliability of reactor trip and passive decay heat removal system operation. The ﬁndings presented in this paper are expected to contribute toward future applications of PSA for assessing unconventional nuclear reactors in their conceptual design phases.},
	language = {en},
	number = {2},
	urldate = {2021-10-24},
	journal = {Nuclear Engineering and Technology},
	author = {So, Eunseo and Kim, Man Cheol},
	month = feb,
	year = {2021},
	pages = {498--508},
}

@article{martins_application_2013,
	title = {Application of {Bayesian} {Belief} networks to the human reliability analysis of an oil tanker operation focusing on collision accidents},
	volume = {110},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832012001883},
	doi = {10.1016/j.ress.2012.09.008},
	abstract = {During the last three decades, several techniques have been developed for the quantitative study of human reliability. In the 1980s, techniques were developed to model systems by means of binary trees, which did not allow for the representation of the context in which human actions occur. Thus, these techniques cannot model the representation of individuals, their interrelationships, and the dynamics of a system. These issues make the improvement of methods for Human Reliability Analysis (HRA) a pressing need. To eliminate or at least attenuate these limitations, some authors have proposed modeling systems using Bayesian Belief Networks (BBNs). The application of these tools is expected to address many of the deficiencies in current approaches to modeling human actions with binary trees. This paper presents a methodology based on BBN for analyzing human reliability and applies this method to the operation of an oil tanker, focusing on the risk of collision accidents. The obtained model was used to determine the most likely sequence of hazardous events and thus isolate critical activities in the operation of the ship to study Internal Factors (IFs), Skills, and Management and Organizational Factors (MOFs) that should receive more attention for risk reduction.},
	language = {en},
	urldate = {2021-10-22},
	journal = {Reliability Engineering \& System Safety},
	author = {Martins, Marcelo Ramos and Maturana, Marcos Coelho},
	month = feb,
	year = {2013},
	keywords = {Bayesian belief networks (BBNs), Collision, Human reliability analysis (HRA), Oil tanker, Probabilistic risk assessment (PRA)},
	pages = {89--109},
}

@article{zheng_development_2020,
	title = {The development of a next-generation human reliability analysis: {Systems} analysis for formal pharmaceutical human reliability ({SAFPH})},
	volume = {202},
	issn = {0951-8320},
	shorttitle = {The development of a next-generation human reliability analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S095183201931066X},
	doi = {10.1016/j.ress.2020.106927},
	abstract = {Medication errors originating in community pharmacies are a serious patient safety hazard. However, due to the complexity of the community pharmacy environment, current experimental and observational studies are insufficient to address these problems. Furthermore, the static nature of traditional, model-based human reliability analyses (HRAs) are not able to handle the dynamic environmental elements that can impact human performance. To address this issue and allow analysts to accurately predict medication error rates, we develop a new HRA called the Systems Analysis for Formal Pharmaceutical Human Reliability (SAFPH). This method addresses the limits of previous HRAs by combining concepts from the Cognitive Reliability and Error Analysis Method (CREAM) HRA with probabilistic model checking, a computational tool for automatically proving properties about complex, stochastic systems. In this paper, we use SAFPH to analyze a common community pharmacy dispensing procedure, compare our results to published error rates, and use our results to explore interventions that could reduce error rates. We ultimately discuss our results and explore how our method could be developed in future research.},
	language = {en},
	urldate = {2021-10-22},
	journal = {Reliability Engineering \& System Safety},
	author = {Zheng, Xi and Bolton, Matthew L. and Daly, Christopher and Biltekoff, Elliot},
	month = oct,
	year = {2020},
	keywords = {Cognitive reliability and error analysis method (CREAM), Formal methods, Human reliability analysis (HRA), Medication errors, Probabilistic model checking},
	pages = {106927},
}

@article{tao_probabilistic_2020,
	title = {Probabilistic safety assessment method for spent nuclear fuel road transportation},
	abstract = {Spent Nuclear Fuel (SNF) transportation has the potential possibility of releasing radioactivity, thus it is signiﬁcant to assess the transportation risks and take effective measures to improve its safety. Current researches were mainly focused on the assessment of the transportation consequences, which lacked detailed and systematic analysis of the transportation process. In this paper, Probabilistic Safety Assessment (PSA) method for SNF Road Transportation (SNFRT) is proposed. The PVCRES (personnel, vehicle, cask, road, environment, supervision and management) risk indicators are proposed and quantiﬁed to characterize the risks that exist during the transportation process, which is in line with the actual situation. Then an ET/FT integrated model is established in order to assess the risk of SNFRT process from a certain Nuclear Power Plant (NPP) to the reprocessing plant. The risk level is quantiﬁed and targeted improvement approaches are proposed to demonstrate the feasibility and effectiveness of this method. Ó 2019 Elsevier Ltd. All rights reserved.},
	language = {en},
	journal = {Annals of Nuclear Energy},
	author = {Tao, Longlong},
	year = {2020},
	pages = {8},
}

@article{liu_design_2002,
	title = {Design and full scale test of the fuel handling system},
	abstract = {In the 10 MW High Temperature Gas-cooled Reactor-Test Module (HTR-10) fuel elements move through the core driven by gravity. To reach their design burn-up the fuel elements are re-shuttled five times. This transportation outside the core is mainly achieved pneumatically. Although, adopting the international experience at design and operation of similar systems some key components were improved so that the fuel handling system (FHS) becomes simpler and more reliable. The improved components were tested in full-scale testing facilities. The debugging test and the first loading operation for the FHS indicate that the FHS meets the demands of the HTR-10. In this paper, the functions, design parameters, technological processes, main components and design characteristics of the FHS are described in detail. The flow schemes, design parameters of the full-scale testing facilities and the experimental results are briefly introduced. \# 2002 Elsevier Science B.V. All rights reserved.},
	language = {en},
	journal = {Nuclear Engineering and Design},
	author = {Liu, J G and Xiao, H L and Li, C P},
	year = {2002},
	pages = {10},
}

@misc{noauthor_design_nodate,
	title = {Design and full scale test of the fuel handling system - {PDF} {Free} {Download}},
	url = {https://coek.info/pdf-design-and-full-scale-test-of-the-fuel-handling-system-.html},
	abstract = {In the 10 MW High Temperature Gas-cooled Reactor-Test Module (HTR-10) fuel elements move through the core driven by grav...},
	language = {en},
	urldate = {2021-10-20},
	journal = {coek.info},
}

@techreport{jason_pottorf_acrs_2017,
	title = {{ACRS} {Presentation}: {Design} of the {Highly} {Integrated} {Protection} {System} {Platform} {Topical} {Report}},
	number = {PM-0217-52652},
	institution = {NuScale Power},
	author = {{Jason Pottorf}},
	month = feb,
	year = {2017},
}

@article{webb_alara_1984,
	title = {{ALARA} in practice: how is it working?},
	volume = {4},
	issn = {0260-2814},
	shorttitle = {{ALARA} in practice},
	url = {https://iopscience.iop.org/article/10.1088/0260-2814/4/2/002},
	doi = {10.1088/0260-2814/4/2/002},
	abstract = {A workshop on the optimisation of radiation protection (ALARA) was organised b y the CEC in November 1983. This rapporteurs paper reviews the development of techniques for carrying out A L A M studies, and how they have been applied inpractice. In the course of thepaper the contributions made by the other twentypapers are identified andplaced in context. Therole of techniques such as costbenefit analysis is clarified and the outstanding difficulties in practical application discussed.},
	language = {en},
	number = {2},
	urldate = {2021-10-18},
	journal = {Journal of the Society for Radiological Protection},
	author = {Webb, G A M and Lochard, J},
	month = jun,
	year = {1984},
	pages = {58--65},
}

@article{silva_discussion_2018,
	title = {Discussion on probability of cesium-137 release exceeding 100 {TBq} as a part of the consideration of nuclear power plant probabilistic risk criteria for environmental protection},
	volume = {180},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832017313121},
	doi = {10.1016/j.ress.2018.07.013},
	abstract = {Though the fundamental safety objective of the IAEA is to protect both people and the environment from harmful radiation eﬀects, probabilistic risk criteria for environmental protection has only been discussed recently after the occurrence of the Fukushima Accident. Preceding studies conﬁrmed the appropriateness of using 100 TBq cesium-137 release as a part of the probabilistic risk criterion since it has limited consequences to the environment. This study aims to propose the way to derive the probability of this release when used as a probabilistic risk criterion. Literature survey revealed issues of existing criteria. As most criteria are not systematically derived, it is diﬃcult to justify the contribution to the fundamental safety objective and the appropriateness of the probability used in the criteria. Accident consequence mitigative features or actions were not also taken into account in the derivation process. The way to address these issues is to simply follow the same process as the derivation of the probabilistic risk criteria for human protection. This will ensure the required level of safety without posing unnecessary burden onto the operator, and will enable the operator to concentrate its eﬀorts on safety actions that contribute to nuclear safety.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Reliability Engineering \& System Safety},
	author = {Silva, Kampanart and Okamoto, Koji},
	month = dec,
	year = {2018},
	pages = {88--93},
}

@article{podofillini_bayesian_2013,
	title = {A {Bayesian} approach to treat expert-elicited probabilities in human reliability analysis model construction},
	volume = {117},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832013000914},
	doi = {10.1016/j.ress.2013.03.015},
	abstract = {In human reliability analysis (HRA), models are often used for the prediction of human error probabilities (HEPs), given a set of performance conditions, typically represented by ratings on a set of influencing factors. The relationships underlying these models (yielding HEPs for specific sets of factor ratings) should ideally be built on empirical data. However the derivation of these relationships in practice has to cope with limited availability of data, so that a strong component of expert judgment is always present. Nevertheless, the incorporation of expert judgment in HRA models is typically not done in a formal way, so that that it is often impossible to distinguish source data and judgments. In this context, this paper presents a Bayesian approach to aggregate expert estimates on human error probabilities to determine the relationships of an HRA model. The idea is to build a computable model using information from experts, provided as estimates. A numerical example demonstrates that the approach formally and transparently represents (and distinguishes) the inherent variability of the HEP quantity as well as that of the experts providing their estimates.},
	language = {en},
	urldate = {2021-10-15},
	journal = {Reliability Engineering \& System Safety},
	author = {Podofillini, L. and Dang, V. N.},
	month = sep,
	year = {2013},
	keywords = {Bayesian methods, Expert judgment, Human reliability analysis, Probabilistic safety assessment, Subjective probabilities},
	pages = {52--64},
}

@book{pioro_handbook_2016,
	title = {Handbook of generation {IV} nuclear reactors},
	isbn = {978-0-08-100162-2},
	url = {https://www.sciencedirect.com/book/9780081001493/handbook-of-generation-iv-nuclear-reactors},
	abstract = {Handbook of Generation IV Nuclear Reactors presents information on the current fleet of Nuclear Power Plants (NPPs) with water-cooled reactors (Generation III and III+) (96\% of 430 power reactors in the world) that have relatively low thermal efficiencies (within the range of 32 36\%) compared to those of modern advanced thermal power plants (combined cycle gas-fired power plants - up to 62\% and supercritical pressure coal-fired power plants - up to 55\%). Moreover, thermal efficiency of the current fleet of NPPs with water-cooled reactors cannot be increased significantly without completely different innovative designs, which are Generation IV reactors. Nuclear power is vital for generating electrical energy without carbon emissions. Complete with the latest research, development, and design, and written by an international team of experts, this handbook is completely dedicated to Generation IV reactors.},
	language = {English},
	urldate = {2021-10-13},
	author = {Pioro, I. L},
	year = {2016},
	note = {OCLC: 952045966},
}

@article{aras_critical_2021,
	title = {A {Critical} {Look} at the {Need} for {Performing} {Multi}-{Hazard} {Probabilistic} {Risk} {Assessment} for {Nuclear} {Power} {Plants}},
	volume = {2},
	abstract = {Probabilistic Risk Assessment (PRA) is one of the technologies that is used to inform the design, licensing, operation, and maintenance activities of nuclear power plants (NPPs). A PRA can be performed by considering the single hazard (e.g., earthquake, ﬂood, high wind, landslide) or by considering multi-hazards (e.g., earthquake and tsunami, high wind and internal ﬁre). Single hazard PRA was thought sufﬁcient to cover the analysis of a severe accident until the Fukushima Daiichi NPP accident in 2011. Since then, efforts were made to consider multi-hazards as well; thus, multi-hazard PRAs are starting to be seen as being indispensable for NPPs. In addition to the changing frequency of global and local natural hazards, other reasons to be highlighted are that the number and diversity of NPPs will probably increase. Moreover, advanced reactors are close to becoming a reality by designing them with passive safety systems, smaller, standardized, and even transportable to make them cheaper across the design, licensing construction, and operation stages. Thus, multi-hazards should be addressed in any future full-scope PRA. Although we found a few studies discussing multi-hazards, a general framework for multi-hazard PRA is still missing. In this paper, we argue that the starting point for any multi-hazard PRA general framework should be the Advanced Non-LWR Licensing Basis Event Selection (LBE) Approach and Probabilistic Risk Assessment Standard for Non-Light Water Reactor (non-LWR) Nuclear Power Plants. For Probabilistic Risk Assessment (PRA), history has shown us the path forward before, with Three Mile Accident being seen as one milestone to understand the necessity of PRA. The Fukushima Daiichi NPP Accident is another milestone in the development of PRA, showing the need for performing multi-hazard PRA for the current and future NPPs.},
	language = {en},
	journal = {Eng},
	author = {Aras, Egemen M and Diaconeasa, Mihai A},
	year = {2021},
	pages = {454--467},
}

@article{fuls_interim_2005,
	title = {The interim fuel storage facility of the {PBMR}},
	volume = {32},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454905001568},
	doi = {10.1016/j.anucene.2005.05.006},
	abstract = {The PBMRÕs spent fuel and partially burnt fuel are stored in the sphere storage system (SSS), which acts as the interim fuel storage facility of the plant. It is unique in the world since the fuel is stored in bulk containers (called storage tanks), each capable of holding more than 500,000 spheres for a period of about 80 years. The SSS has the ability to transfer the contents of one tank to another tank, and to return partially burnt fuel back to the reactor core for refuelling.},
	language = {en},
	number = {17},
	urldate = {2021-10-10},
	journal = {Annals of Nuclear Energy},
	author = {Fuls, W.F. and Viljoen, C. and Stoker, C. and Koch, C. and Kleingeld, M.},
	month = nov,
	year = {2005},
	pages = {1854--1866},
}

@article{fuls_interim_2005-1,
	title = {The interim fuel storage facility of the {PBMR}},
	volume = {32},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454905001568},
	doi = {10.1016/j.anucene.2005.05.006},
	abstract = {The PBMR’s spent fuel and partially burnt fuel are stored in the sphere storage system (SSS), which acts as the interim fuel storage facility of the plant. It is unique in the world since the fuel is stored in bulk containers (called storage tanks), each capable of holding more than 500,000 spheres for a period of about 80 years. The SSS has the ability to transfer the contents of one tank to another tank, and to return partially burnt fuel back to the reactor core for re-fuelling. The storage tanks are individually sealed carbon steel pressure vessels. They form the final barrier of any fission products that have diffused from the fuel spheres. Sub-criticality is achieved through the geometric cross-section of the tank, and by taking credit for fuel burn-up. Protection from the corrosive environment where the PBMR Demonstration plant will be built is achieved by actively cooling the tank with clean dry air. In the event of an active cooling failure, louvres open automatically and cooling is done passively via natural convection making use of the chimney-effect. Sufficient radiation protection is provided around each tank to facilitate maintenance and inspection operations where needed. The design of the SSS is nearing the end of its basic design phase, and for some components, detail design work has already commenced. The design complies with all spent fuel storage requirements and is seen as a cost-effective solution for the interim storage of PBMR spent fuel.},
	language = {en},
	number = {17},
	urldate = {2021-10-10},
	journal = {Annals of Nuclear Energy},
	author = {Fuls, W. F. and Viljoen, C. and Stoker, C. and Koch, C. and Kleingeld, M.},
	month = nov,
	year = {2005},
	pages = {1854--1866},
}

@article{godovykh_analysis_2015,
	title = {Analysis of {Interaction} {Peculiarities} in the {System} “{OUTSIDER} – {PHYSICAL} {PROTECTION} {SYSTEM}” for {Nuclear} {Facility}},
	volume = {1084},
	issn = {1662-8985},
	url = {https://www.scientific.net/AMR.1084.609},
	doi = {10.4028/www.scientific.net/AMR.1084.609},
	abstract = {The paper presents an approach to evaluating the effectiveness of physical protection systems (PPS). Considering the fact that different processes are subject to universal physical laws and principles of development, a parallel was drawn between the concepts of conflict resolution field to description of interaction in the system “outsider – PPS”. The description of mathematical model in the form of dependence with respect to the real conflict in the system “outsider – PPS” is given. The result of the model analysis is determination of the parameter, allowing estimating the rate of threat increase in conflict situation. Also competence of PPS operator is considered in the framework of the work. Furthermore, actions of operator were taken as a key factor affecting the efficiency of the whole security system. To resolve identified issues ways to develop special qualities required for the operator and their professional skills through training were suggested. Also the issues of control of psychophysiological characteristics of PPS staff were addressed.},
	language = {en},
	urldate = {2021-10-10},
	journal = {Advanced Materials Research},
	author = {Godovykh, Alexey and Parepko, Margarita and Stepanov, Boris},
	month = jan,
	year = {2015},
	pages = {609--612},
}

@article{andiwijayakusuma_comparative_2019,
	title = {A {Comparative} {Study} of the {Algorithms} for {Path} finding to {Determine} the {Adversary} {Path} in {Physical} {Protection} {System} of {Nuclear} {Facilities}},
	volume = {1198},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/1198/9/092002},
	doi = {10.1088/1742-6596/1198/9/092002},
	abstract = {The shortest path algorithm is the process of finding a path on a weighted graph that minimizes the number of the weights of the path-forming side. Thus, the resulting path is the distance that has the least weight or distance. In physical protection systems (PPS), the implementation of the shortest path algorithm is determining the most vulnerable adversary path to penetrate the physical protection system of a nuclear facility. The paths between points at a facility passed by the adversary will form a directed and weighted graph. The weights on the graph represent the ability of a protective device (e.g. CCTV, sensor, alarm etc.). The formed graph will be processed using algorithms to determine the most vulnerable path. In this paper, we study and examine the performance of two types of algorithms namely Dijkstra and A*. The purpose of this study is to compare the two algorithms which we will use it to determine the most vulnerable path related to the physical protection system of nuclear facilities. Our results show that the A* algorithm provides more efficient path results than the Dijkstra algorithm.},
	language = {en},
	number = {9},
	urldate = {2021-10-10},
	journal = {Journal of Physics: Conference Series},
	author = {Andiwijayakusuma, D. and Mardhi, A. and Savitri, I. and Asmoro, T.},
	month = apr,
	year = {2019},
	pages = {092002},
}

@article{yoo_new_2009,
	title = {A new physical protection measure for evaluating risks at nuclear facilities},
	volume = {36},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030645490900190X},
	doi = {10.1016/j.anucene.2009.06.014},
	abstract = {The Physical Protection (PP) measures for evaluating risks at nuclear facilities have been developed. The developed measures can be used to not only evaluate the physical protection status of operational nuclear facilities, but also for the next generation of nuclear systems such as the SFR (Sodium Fast Reactor) and the VHTR (Very High Temperature Reactor). These measures can substitute those existing methodologies developed by the Gen-IV PR\&PP group and the INPRO. These measures have been adapted to hypothetical nuclear facilities, and scenarios have been created to analyze PP risk quantitatively. The PP measures developed in this study contain Probability of Interruption (PI), Probability of Neutralization (PN), Consequences (C), Fissile Material Type (MT) and Effectiveness of Physical Protection Resources (EPR). In this paper, tools and tables for calculating each PP measure are suggested and illustrated in detail. The PI and PN measures can be calculated quantitatively using these tools. A new computer code for calculating PI has also been developed. The EPR, MT and C measures were obtained from tables developed by collecting and analyzing related information. Computational results of the PP measures in ﬁve different scenarios, and at three different facilities demonstrate the effectiveness of the methodology developed. The results obtained are represented in a spider diagram (after normalizing the measure calculated). The value of PI and C changed because of the scenario; but the other three measures, EPR, MT and PN (determined by the characteristics of the facility) did not vary. It is expected that by using a larger number of reﬁned scenarios more reliable information will be provided. It is also anticipated that the PP measures developed in this study can be applied to operational nuclear facilities, as well as a future nuclear systems under development.},
	language = {en},
	number = {9},
	urldate = {2021-10-10},
	journal = {Annals of Nuclear Energy},
	author = {Yoo, Hosik},
	month = sep,
	year = {2009},
	pages = {1463--1468},
}

@article{rentai_atmospheric_2011,
	title = {Atmospheric {Dispersion} of {Radioactive} {Material} in {Radiological} {Risk} {Assessment} and {Emergency} {Response}},
	volume = {1},
	issn = {2185-4823},
	url = {https://www.aesj.net/document/pnst001/7.pdf},
	doi = {10.15669/pnst.1.7},
	abstract = {The purpose of a consequence assessment system is to assess the consequences of specific hazards on people and the environment. In this paper, the studies on technique and method of atmospheric dispersion modeling of radioactive material in radiological risk assessment and emergency response are reviewed in brief. Some current statuses of nuclear accident consequences assessment in China were introduced. In the future, extending the dispersion modeling scales such as urban building scale, establishing high quality experiment dataset and method of model evaluation, improved methods of real-time modeling using limited inputs, and so on, should be promoted with high priority of doing much more work.},
	language = {en},
	number = {0},
	urldate = {2021-10-10},
	journal = {Progress in Nuclear Science and Technology},
	author = {Rentai, Yao},
	month = feb,
	year = {2011},
	pages = {7--13},
}

@article{specter_application_1989,
	title = {Application of {PRA} to emergency planning},
	volume = {24},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832089900902},
	doi = {10.1016/0951-8320(89)90090-2},
	abstract = {PRA methodology has been used to analyze the effectiveness {\textasciitilde}/ different emergency response strategies in reducing the health consequences {\textasciitilde}] hypothetical large releases af radioactivityJ{\textasciitilde}'om a nuclear power plant. A.IOw years ago the gra{\textasciitilde}h'd response, i.e. et'acuate the innermost two miles or so zone near the plant attd shelter.['rom two to ten miles, was found to he a particularly e\{/ectire emergency response, ht the gra{\textasciitilde}h'd response, typically 93\% to 99"./,, {\textasciitilde}?/"the emergency phmn\#tg zone population, would take shelter. With such emphasLs on sheltering atul with a sign([leant improvement in public protection relati{\textasciitilde}'e to tt massi['e ct,acuatiott respoctse, the public real' accept this emergency response as hoth.[{\textasciitilde},asihle atut {\textasciitilde}\}[[{\textasciitilde},ctive. Very recent analyses m{\textasciitilde}l.v jttSli/{\textasciitilde}v even smalh'r i/l/l{\textasciitilde}q".70/I('A', approaching an 'all .shelterin{\textasciitilde}'re.{\textasciitilde}ponse.},
	language = {en},
	number = {2},
	urldate = {2021-10-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Specter, Herschel},
	month = jan,
	year = {1989},
	pages = {151--166},
}

@article{dvorzhak_probabilistic_2016,
	title = {Probabilistic risk assessment from potential exposures to the public applied for innovative nuclear installations},
	volume = {152},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832016000740},
	doi = {10.1016/j.ress.2016.03.008},
	abstract = {Potential exposures are those that may occur as a result of unanticipated operational performance or accidents. Potential exposure situations are probabilistic in nature because they depend on uncertain events such as equipment failure, operator errors or external initiators beyond the control of the operator. Consequently, there may exist a range of possible radiological impacts that need to be considered. In this paper a Level 3 Probabilistic Safety Assessment (PSA) for a hypothetical scenario relevant to Innovative Nuclear Energy Systems (INS) was conducted using computer code MACCS (MELCOR Accident Consequence Code Systems). The acceptability of an INS was analyzed taking into account the general requirement that relocation or evacuation measures must not be necessary beyond the site boundary. In addition, deterministic modeling of the accident consequences for the critical meteorological conditions was carried out using the JRODOS decision support system (Real-time On-line Decision Support system for off-site emergency management in Europe). The approach used for dose and risk assessment from potential exposure of accidental releases and their comparison with acceptance criteria are presented. The methodology described can be used as input to the licensing procedure and engineering design considerations to help satisfy relevant health and environmental impact criteria for ﬁssion or fusion nuclear installations.},
	language = {en},
	urldate = {2021-10-10},
	journal = {Reliability Engineering \& System Safety},
	author = {Dvorzhak, Alla and Mora, Juan C. and Robles, Beatriz},
	month = aug,
	year = {2016},
	pages = {176--186},
}

@misc{lyman_pebble-bed_nodate,
	title = {The {Pebble}-{Bed} {Modular} {Reactor} ({PBMR}): {Safety} {Issues}},
	shorttitle = {The {Pebble}-{Bed} {Modular} {Reactor} ({PBMR})},
	abstract = {The Bush Administration has made the expansion of nuclear power generation a centerpiece of its domestic energy policy. However, the White House has not addressed the practical issue of how to overcome the nearly three-decade-long aversion among U.S. electric utilities to investing in new nuclear plants. In today's deregulating market, utilities will not build new nuclear power plants unless they are clearly competitive with fossil fuel plants (or receive substantial government subsidies).},
	author = {Lyman, Edwin S.},
}

@techreport{niephaus_experience_1998,
	address = {International Atomic Energy Agency (IAEA)},
	title = {Experience with the interim storage of spent {HTR} fuel elements and a view to necessary measures for final disposal},
	abstract = {In the Federal Republic of Germany the AVR pilot high-temperature reactor was operated
successfully for more than 20 years and the THTR prototype high-temperature reactor
for more than three years The reactors were shut down for decommissioning at the end
of 1988 and the discharge of core inventories and packaging of the fuel, together
with the temporarily stored fuel, for long-term interim storage in appropriate casks
and facilities was started in 1992 and finished in 1995 for the THTR and began in
1994 for AVR and will be completed at the beginning of 1998 With a view to the long-term
interim storage and final disposal of spent HTR fuel from both reactors many experiments
have been carried out to characterize the spent fuel and to learn about its behaviour
and during the operating period of the AVR reactor much experience has been gathered
by remote handling, shipping and temporarily storing fuel packages at different appropriate
facilities of the Forschungszentrum Juelich GmbH (FZJ) Furthermore, after starting
the discharge of the AVR core more than 200 so-called AVR dry storage canisters (AVR-TLK),
each containing 950 spent fuel elements have been reloaded from an AVR single shipping
cask into CASTOR THTR / AVR shipping and storage casks in the hot cell facility, which
is one part of the waste treatment and storage building of FZJ, and currently about
100 CASTOR casks, each containing in all 1900 fuel elements, have been prepared and
stored in the AVR interim storage facility (AVR-BL), as another part of this building
(author)},
	number = {1011-4289},
	author = {Niephaus, D. and Storch, S. and Halaszovich, S.},
	year = {1998},
	note = {IAEA-TECDOC--1043
INIS Reference Number: 29059911},
	pages = {163--169},
}

@article{lin_analysis_2020,
	title = {Analysis of the interactions between spent fuel pebble bed and storage canister under impact loading},
	volume = {361},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549320300431},
	doi = {10.1016/j.nucengdes.2020.110548},
	abstract = {The high temperature gas-cooled reactor pebble-bed modular (HTR-PM) stores spent fuel on-site by a dry storage system based on canisters. To ensure the safety containment of the radioactive contents, it is necessary to assess the interactions between spent fuel pebble bed and storage canister under impact loading, such as the event of accidental drop. In this paper, the thin walled canister and the pebble bed inside are modelled by finite element method (FEM) and discrete element method (DEM), respectively. With coupling the two types of model, the dynamic structural interactions inside the pebble bed and between the spent fuel elements and the wall of canisters under impact loading are analyzed numerically. The results show that this method can effectively evaluate the safety and structural design rationality of the fuel storage canister and provide a reference for the subsequent design of fuel canisters.},
	language = {en},
	urldate = {2021-10-10},
	journal = {Nuclear Engineering and Design},
	author = {Lin, Musen and Li, Yue},
	month = may,
	year = {2020},
	keywords = {HTR-PM, Impact, Safety analysis, Spent fuel},
	pages = {110548},
}

@article{evangeliou_fire_2015,
	title = {Fire evolution in the radioactive forests of {Ukraine} and {Belarus}: future risks for the population and the environment},
	volume = {85},
	issn = {0012-9615},
	shorttitle = {Fire evolution in the radioactive forests of {Ukraine} and {Belarus}},
	url = {http://doi.wiley.com/10.1890/14-1227.1},
	doi = {10.1890/14-1227.1},
	abstract = {In this paper, we analyze the current and future status of forests in Ukraine and Belarus that were contaminated after the nuclear disaster in 1986. Using several models, together with remote-sensing data and observations, we studied how climate change in these forests may affect ﬁre regimes. We investigated the possibility of 137Cs displacement over Europe by studying previous ﬁre events, and examined three ﬁre scenarios that depended on different emission altitudes of 137Cs, assuming that 10\% of the forests were affected by ﬁres. Field measurements and modeling simulations conﬁrmed that numerous radioactive contaminants are still present at these sites in extremely large quantities.},
	language = {en},
	number = {1},
	urldate = {2021-10-08},
	journal = {Ecological Monographs},
	author = {Evangeliou, N. and Balkanski, Y. and Cozic, A. and Hao, W. M. and Mouillot, F. and Thonicke, K. and Paugam, R. and Zibtsev, S. and Mousseau, T. A. and Wang, R. and Poulter, B. and Petkov, A. and Yue, C. and Cadule, P. and Koffi, B. and Kaiser, J. W. and Møller, A. P.},
	month = feb,
	year = {2015},
	pages = {49--72},
}

@article{amiro_burning_1996,
	title = {Burning radionuclide question: {What} happens to iodine, cesium and chlorine in biomass fires?},
	volume = {187},
	issn = {00489697},
	shorttitle = {Burning radionuclide question},
	url = {https://linkinghub.elsevier.com/retrieve/pii/004896979605125X},
	doi = {10.1016/0048-9697(96)05125-X},
	abstract = {Fires can mobilize radionuclides from contaminated biomass through suspension of gasesand particles in the atmosphere or solubilization and enrichment of the ash. Field and laboratory burns were conducted to determine the fate of I, Cs and Cl in biomass tires. Straw, wood, peat, dulse (seaweed)and radish plants were combusted with temperatures varying from 160 to lOOO’C,representing the normal range of field fire temperatures. Loss to the atmosphere increasedwith fire temperature and during a typical field fire, 80-90\% of the I and Cl, and 40-70\% of the Cs was lost to the atmosphere. The remainder was left behind in the ash and was soluble. Typically, the ash was enriched in I by a factor of two to three, with higher enrichments of Cs and lower enrichments of Cl, when compared to the initial fuel concentration during field burns. Most of the I was lost to the atmosphere as a gas. If the elements were radioactive isotopes, such as ?, 13?Csand “Cl, fires could cause an increased radiological dose to people through inhalation, exposure to ash, or ingestion of plants becauseof increased uptake of ash leachate.},
	language = {en},
	number = {2},
	urldate = {2021-10-08},
	journal = {Science of The Total Environment},
	author = {Amiro, B.D. and Sheppard, S.C. and Johnston, F.L. and Evenden, W.G. and Harris, D.R.},
	month = aug,
	year = {1996},
	pages = {93--103},
}

@article{horrill_effect_1995,
	title = {The effect of heather burning on the transfer of radiocaesium to smoke and the solubility of radiocaesium associated with different types of heather ash},
	volume = {29},
	issn = {0265931X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0265931X9500012Y},
	doi = {10.1016/0265-931X(95)00012-Y},
	abstract = {Heather (Calluna vulgaris) dominates large tracts of the United Kingdom and fire is used as a management tool to encourage new growth. Heather contaminated with radiocaesium from the Chernobyl accident was burnt under controlled conditions giving a ‘hot’ (660°C) and ‘cool’ (55O”C)fire. Losses of up to 40\% of the radiocaesium activity were recorded in the smoke and subsequent leaching experiments, using artificial rainwater, demonstrated that a further 20\% of the activity could be mobilised in a short period. The implications of using heather burning as a management tool are considered.},
	language = {en},
	number = {1},
	urldate = {2021-10-08},
	journal = {Journal of Environmental Radioactivity},
	author = {Horrill, A.D. and Kennedy, V.H. and Paterson, I.S. and McGowan, G.M.},
	month = jan,
	year = {1995},
	pages = {1--10},
}

@inproceedings{oh_comparison_2007,
	address = {PyeongChang, Korea},
	title = {Comparison of {Frequency}-{Consequence} ({F}-{C}) {Curves} or {Criteria} in {Foreign} {Countries}},
	author = {OH, Kju-Myeng and AHN, Sany-Kyu and Jo, Nam-Chol and Yoon, Won-Hyo and Chung, Dae-Wook and Lee, Hoon-Joo},
	month = oct,
	year = {2007},
	pages = {593--594},
}

@techreport{epri_seismic_2013,
	address = {Palo Alto, CA},
	title = {Seismic {Probabilistic} {Risk} {Assessment} {Implementation} {Guide}},
	language = {en},
	number = {30020000709},
	institution = {EPRI},
	author = {EPRI, J.},
	year = {2013},
	pages = {448},
}

@book{noauthor_treatment_nodate,
	address = {Vienna},
	series = {Safety {Series}},
	title = {Treatment of {External} {Hazards} in {Probabilistic} {Safety} {Assessment} for {Nuclear} {Power} {Plants}: {A} {Safety} {Practice}},
	isbn = {92-0-104794-0},
	url = {https://www.iaea.org/publications/5178/treatment-of-external-hazards-in-probabilistic-safety-assessment-for-nuclear-power-plants-a-safety-practice},
	number = {50-P-7},
	urldate = {2021-07-22},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
}

@misc{electric_power_research_institute_basics_2011,
	address = {San Diego, CA, United States and Jacksonville, FL, United States},
	title = {Basics of {Nuclear} {Power} {Plant} {Probabilistic} {Risk} {Assessment}},
	author = {Electric Power Research Institute},
	year = {2011},
}

@article{ribeiro_human_2016,
	title = {Human reliability analysis of the {Tokai}-{Mura} accident through a {THERP}–{CREAM} and expert opinion auditing approach},
	volume = {87},
	issn = {0925-7535},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753516300510},
	doi = {10.1016/j.ssci.2016.04.009},
	abstract = {This paper presents a human reliability analysis (HRA) model that allows the incorporation of features related to facility conditions to determine human error probabilities (HEP) used in probabilistic safety analyses of process plants. We present an approach to show the predominance of human factors as an accident cause, as well as existing methodologies for HEP determination and their deficiencies in incorporating socio-technical elements that influence them. Such elements are: inappropriate design, training, procedures, communication, safety culture, management in the production process changes, emergency planning, accident investigation, environmental factors, maintenance workload and human–system interface. A mathematical model is proposed to incorporate these elements taking into account their contribution weights as well as measuring their degree of implementation in the plant. This creates a factor that can modify existing HEPs, giving values that better reflect plant reality. The model was applied to the accident that occurred in 1999 in Tokai-Mura, Japan. The modified HEP was 2 times greater than the nominal HEP. This shows that considering organizational factors thoroughly allows for a more realistic plant behavior modeling in face of abnormal events.},
	language = {en},
	urldate = {2021-10-01},
	journal = {Safety Science},
	author = {Ribeiro, A. C. and Sousa, A. L. and Duarte, J. P. and Frutuoso e Melo, P. F.},
	month = aug,
	year = {2016},
	keywords = {CREAM, Expert opinion elicitation, Human reliability analysis, THERP, Tokai-Mura accident},
	pages = {269--279},
}

@article{forester_expert_2004,
	series = {Human {Reliability} {Analysis}: {Data} {Issues} and {Errors} of {Commission}},
	title = {Expert elicitation approach for performing {ATHEANA} quantification},
	volume = {83},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832003002072},
	doi = {10.1016/j.ress.2003.09.011},
	abstract = {An expert elicitation approach has been developed to estimate probabilities for unsafe human actions (UAs) based on error-forcing contexts (EFCs) identified through the ATHEANA (A Technique for Human Event Analysis) search process. The expert elicitation approach integrates the knowledge of informed analysts to quantify UAs and treat uncertainty (‘quantification-including-uncertainty’). The analysis focuses on (a) the probabilistic risk assessment (PRA) sequence EFCs for which the UAs are being assessed, (b) the knowledge and experience of analysts (who should include trainers, operations staff, and PRA/human reliability analysis experts), and (c) facilitated translation of information into probabilities useful for PRA purposes. Rather than simply asking the analysts their opinion about failure probabilities, the approach emphasizes asking the analysts what experience and information they have that is relevant to the probability of failure. The facilitator then leads the group in combining the different kinds of information into a consensus probability distribution. This paper describes the expert elicitation process, presents its technical basis, and discusses the controls that are exercised to use it appropriately. The paper also points out the strengths and weaknesses of the approach and how it can be improved. Specifically, it describes how generalized contextually anchored probabilities (GCAPs) can be developed to serve as reference points for estimates of the likelihood of UAs and their distributions.},
	language = {en},
	number = {2},
	urldate = {2021-10-01},
	journal = {Reliability Engineering \& System Safety},
	author = {Forester, John and Bley, Dennis and Cooper, Susan and Lois, Erasmia and Siu, Nathan and Kolaczkowski, Alan and Wreathall, John},
	month = feb,
	year = {2004},
	keywords = {ATHEANA, Expert elicitation, HRA, Human performance, Human reliability analysis, PRA, Probabilistic risk assessment, Uncertainty},
	pages = {207--220},
}

@misc{noauthor_researchgate_nodate,
	title = {{ResearchGate}},
	url = {https://www.researchgate.net/requests/r93051777},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2021-10-01},
	journal = {ResearchGate},
}

@misc{noauthor_appendix_nodate,
	title = {Appendix {A} {To} {Part} 50—{General} {Design} {Criteria} {For} {Nuclear} {Power} {Plants} {\textbar} {NRC}.gov},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/part050-appa.html},
	urldate = {2021-09-30},
}

@misc{us_nuclear_regulatory_commission_guidance_nodate,
	title = {{GUIDANCE} {FOR} {DEVELOPING} {PRINCIPAL} {DESIGN} {CRITERIA} {FOR} {NON}-{LIGHT}-{WATER} {REACTORS}},
	author = {{U.S. Nuclear Regulatory Commission}},
}

@article{dvorzhak_probabilistic_2016-1,
	title = {Probabilistic risk assessment from potential exposures to the public applied for innovative nuclear installations},
	volume = {152},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832016000740},
	doi = {10.1016/j.ress.2016.03.008},
	abstract = {Potential exposures are those that may occur as a result of unanticipated operational performance or accidents. Potential exposure situations are probabilistic in nature because they depend on uncertain events such as equipment failure, operator errors or external initiators beyond the control of the operator. Consequently, there may exist a range of possible radiological impacts that need to be considered. In this paper a Level 3 Probabilistic Safety Assessment (PSA) for a hypothetical scenario relevant to Innovative Nuclear Energy Systems (INS) was conducted using computer code MACCS (MELCOR Accident Consequence Code Systems). The acceptability of an INS was analyzed taking into account the general requirement that relocation or evacuation measures must not be necessary beyond the site boundary. In addition, deterministic modeling of the accident consequences for the critical meteorological conditions was carried out using the JRODOS decision support system (Real-time On-line Decision Support system for off-site emergency management in Europe). The approach used for dose and risk assessment from potential exposure of accidental releases and their comparison with acceptance criteria are presented. The methodology described can be used as input to the licensing procedure and engineering design considerations to help satisfy relevant health and environmental impact criteria for ﬁssion or fusion nuclear installations.},
	language = {en},
	urldate = {2021-09-30},
	journal = {Reliability Engineering \& System Safety},
	author = {Dvorzhak, Alla and Mora, Juan C. and Robles, Beatriz},
	month = aug,
	year = {2016},
	pages = {176--186},
}

@article{park_quantitative_2020,
	title = {A quantitative assessment framework for cyber-attack scenarios on nuclear power plants using relative difficulty and consequence},
	volume = {142},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454920301304},
	doi = {10.1016/j.anucene.2020.107432},
	abstract = {Digital instrumentation and control (I\&C) systems have been replacing analog I\&C systems in nuclear power plants (NPPs) on account of the beneﬁcial functions digital systems provide. As a result, NPP risks have been centralized into the digital I\&C systems, with the issue of cyber-attack thus emerging as one of the new threats. To achieve more effective cyber security, it is necessary to evaluate the risk of cyberattack quantitatively. This work proposes a quantitative assessment framework to evaluate NPP risk due to cyber-attack scenarios. This framework evaluates the risk by deﬁning the difﬁculty and consequence of a cyber-attack, for which the assessment methods are based on Bayesian belief network and probabilistic safety assessment methods, respectively. Application of the framework to several possible cyber-attack scenarios quantitatively assessed the difﬁculty and consequence of the scenarios, thereby providing risk information. It is expected that application of the proposed framework can enhance cyber security.},
	language = {en},
	urldate = {2021-09-30},
	journal = {Annals of Nuclear Energy},
	author = {Park, Jong Woo and Lee, Seung Jun},
	month = jul,
	year = {2020},
	pages = {107432},
}

@article{peterson_overview_2019,
	title = {An overview of methodologies for cybersecurity vulnerability assessments conducted in nuclear power plants},
	volume = {346},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549319300330},
	doi = {10.1016/j.nucengdes.2019.02.025},
	abstract = {Cyber-attacks against critical energy infrastructure have gone from possible to eventual to actual. With electrical generation sources in the United States changing under a wide range of pressures, the current ﬂeet of nuclear power plants in the United States provides a reliable and sustainable source of electrical generation capacity. However, in order to extend the lifetime of the ﬂeet, modernization upgrades to digital instrumentation and control systems are required. While this produces many opportunities for increased eﬃciency, it introduces a new level of complexity for securing and reliably operating reactors in the presence cyberthreats. The United States Nuclear Regulatory Commission recently began urging stronger cybersecurity eﬀorts at nuclear power plants. As upgrades at nuclear power plants begin, the implementation of digital instrumentation and control systems to monitor and run the power plant introduces new vulnerabilities that must be addressed. This necessitates a more modern discussion of risk. Within this context, we critically review past cyber-vulnerability incidents at nuclear installations and other critical facilities. We then analyze challenges to vulnerabilities within the context of modernization of the current nuclear ﬂeet and propose future research directions needed to resolve these issues.},
	language = {en},
	urldate = {2021-09-30},
	journal = {Nuclear Engineering and Design},
	author = {Peterson, John and Haney, Michael and Borrelli, R.A.},
	month = may,
	year = {2019},
	pages = {75--84},
}

@article{zhao_rapid_2021,
	title = {Rapid source term prediction in nuclear power plant accidents based on dynamic {Bayesian} networks and probabilistic risk assessment},
	volume = {158},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921000931},
	doi = {10.1016/j.anucene.2021.108217},
	abstract = {Source term prediction plays an essential role in mitigating the consequences of nuclear accidents and therefore is of practical importance. In this research, we propose a method for rapid source term prediction in nuclear accidents. The proposed method ﬁrst performs fault diagnosis based on real-time plant information to diagnose plant status. Then it uses the results in fault diagnosis and pre-deﬁned source terms in probabilistic risk assessment to obtain real-time source term prediction. Fault diagnosis is based on dynamic Bayesian networks, which exhibit advantages in modeling complex systems and probabilistic reasoning with available evidence. The use of pre-deﬁned source terms for various accident scenarios in probabilistic risk assessment enables us to cover a broad range of accident scenarios. This is in contrast to the limited number of basis accident scenarios used in the current practice for source term prediction. The proposed method is demonstrated using a high temperature gas cooled reactor.},
	language = {en},
	urldate = {2021-09-30},
	journal = {Annals of Nuclear Energy},
	author = {Zhao, Yunfei and Tong, Jiejuan and Zhang, Liguo},
	month = aug,
	year = {2021},
	pages = {108217},
}

@misc{noauthor_proposed_nodate,
	title = {Proposed {PBMR}, {Safety} {Analysis} {Report} ({September} 2002) {\textbar} {ELAW}},
	url = {https://www.elaw.org/content/south-africa-proposed-pbmr-safety-analysis-report-september-2002},
	urldate = {2021-09-29},
}

@techreport{noauthor_safety_2001,
	title = {Safety {Aspects} of {HTR} {Technology}},
	url = {https://www.nrc.gov/docs/ML0922/ML092250104.pdf},
	abstract = {NRC visit in Germany},
	urldate = {2021-09-29},
	month = jul,
	year = {2001},
}

@phdthesis{savkina_probabilistic_2004,
	title = {Probabilistic {Accident} analysis of the {Pebble} {Bed} {Modular} {Reactor} for {Use} with {Risk} {Informed} {Regulation}},
	url = {https://dspace.mit.edu/bitstream/handle/1721.1/17748/56504086-MIT.pdf?sequence=2&isAllowed=y},
	urldate = {2021-09-29},
	school = {MIT},
	author = {Savkina, Marina D.},
	month = feb,
	year = {2004},
}

@article{kadambi_pbmr_2006,
	title = {{PBMR} {White} {Paper}: {PRA} {Approach}.},
	language = {en},
	author = {Kadambi, Mr N Prasad},
	year = {2006},
	pages = {75},
}

@misc{us_nuclear_regulatory_commissioncaras_introduction_2001,
	title = {{INTRODUCTION} {TO} {THE} {PEBBLE} {BED} {MODULAR} {REACTOR}},
	url = {https://www.nrc.gov/docs/ML0125/ML012530326.pdf},
	language = {eng},
	author = {U.S. Nuclear Regulatory CommissionCaras},
	month = aug,
	year = {2001},
	note = {Doc. No. 009949-185},
	keywords = {Animals, Calcium, Deoxycholic Acid, Diglycerides, Hydrogen-Ion Concentration, Kinetics, Magnesium, Manganese, Microsomes, Liver, Osmolar Concentration, Phospholipids, Phosphoric Monoester Hydrolases, Rats, Sodium Chloride, Structure-Activity Relationship, Temperature},
}

@techreport{phillip_casey_durst_nuclear_2009,
	title = {Nuclear {Safeguards} {Considerations} {For} {The} {Pebble} {Bed} {Modular} {Reactor} ({PBMR})},
	url = {http://www.osti.gov/servlets/purl/968683-viUrGs/},
	language = {en},
	number = {INL/EXT-09-16782, 968683},
	urldate = {2021-09-29},
	author = {{Phillip Casey Durst} and {David Beddingfield} and {Brian Boyer} and {Robert Bean} and {Michael Collins} and {Michael Ehinger} and {David Hanks} and {David L. Moses} and {Lee Refalo}},
	month = oct,
	year = {2009},
	doi = {10.2172/968683},
	pages = {INL/EXT--09--16782, 968683},
}

@article{hao_cesium_2018,
	title = {Cesium emissions from laboratory fires},
	volume = {68},
	issn = {1096-2247, 2162-2906},
	url = {https://www.tandfonline.com/doi/full/10.1080/10962247.2018.1493001},
	doi = {10.1080/10962247.2018.1493001},
	abstract = {If a radiological incident such as a nuclear power plant accident, a radiological dispersal device, or detonation of an improvised nuclear device occurs, significant areas may be contaminated. Initial cleanup priorities would likely focus on populated areas, leaving the forested areas to pass several seasons where the overhead canopy materials would fall to the forest floor. In the event of a wildfire in a radionuclide-contaminated forest, some radionuclides would be emitted in the air while the rest would remain in the ash. This paper reports on a laboratory simulation study that examines the partitioning of cesium-133 (a nonradioactive isotope of cesium) between airborne particulate matter and residual nonentrained ash when pine needles and peat are doped with cesium. Only 1–2.5\% of the doped cesium in pine needles was emitted as particulate matter, and most of the cesium was concentrated in the particulate fraction greater than 10 µm in aerodynamic diameter. For peat fires, virtually all of the cesium remained in the ash. The results from this study will be used for modeling efforts to assess potential exposure risks to firefighters and the surrounding public.},
	language = {en},
	number = {11},
	urldate = {2021-09-29},
	journal = {Journal of the Air \& Waste Management Association},
	author = {Hao, Wei Min and Baker, Stephen and Lincoln, Emily and Hudson, Scott and Lee, Sang Don and Lemieux, Paul},
	month = nov,
	year = {2018},
	pages = {1211--1223},
}

@techreport{cogliati_pebble-bed_2011,
	title = {Pebble-bed pebble motion: {Simulation} and {Applications}},
	shorttitle = {Pebble-bed pebble motion},
	url = {https://www.osti.gov/biblio/1031696-pebble-bed-pebble-motion-simulation-applications},
	abstract = {Pebble bed reactors (PBR) have moving graphite fuel pebbles. This unique feature provides advantages, but also means that simulation of the reactor requires understanding the typical motion and location of the granular flow of pebbles. This report presents a method for simulation of motion of the pebbles in a PBR. A new mechanical motion simulator, PEBBLES, efficiently simulates the key elements of motion of the pebbles in a PBR. This model simulates gravitational force and contact forces including kinetic and true static friction. It's used for a variety of tasks including simulation of the effect of earthquakes on a PBR, calculation of packing fractions, Dancoff factors, pebble wear and the pebble force on the walls. The simulator includes a new differential static friction model for the varied geometries of PBRs. A new static friction benchmark was devised via analytically solving the mechanics equations to determine the minimum pebble-to-pebble friction and pebble-to-surface friction for a five pebble pyramid. This pyramid check as well as a comparison to the Janssen formula was used to test the new static friction equations. Because larger pebble bed simulations involve hundreds of thousands of pebbles and long periods of time, the PEBBLES code has been parallelized. PEBBLES runs on shared memory architectures and distributed memory architectures. For the shared memory architecture, the code uses a new O(n) lock-less parallel collision detection algorithm to determine which pebbles are likely to be in contact. The new collision detection algorithm improves on the traditional non-parallel O(n log(n)) collision detection algorithm. These features combine to form a fast parallel pebble motion simulation. The PEBBLES code provides new capabilities for understanding and optimizing PBRs. The PEBBLES code has provided the pebble motion data required to calculate the motion of pebbles during a simulated earthquake. The PEBBLES code provides the ability to determine the contact forces and the lengths of motion in contact. This information combined with the proper wear coefficients can be used to determine the dust production from mechanical wear. These new capabilities enhance the understanding of PBRs, and the capabilities of the code will allow future improvements in understanding.},
	language = {English},
	number = {INL/EXT-11-23047},
	urldate = {2021-09-29},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Cogliati, Joshua J. and Ougouag, Abderrafi M.},
	month = nov,
	year = {2011},
	doi = {10.2172/1031696},
}

@book{buck_gentlemens_2020,
	address = {Montclair},
	edition = {1st},
	title = {Gentlemen's club: partners of exotic dancers},
	isbn = {978-0-578-66340-1},
	shorttitle = {Gentlemen's club},
	abstract = {"For six years, Chris Buck has been photographing and interviewing the partners of exotic dancers. The result is Buck's most surprising and compelling work: forty interviews and portrait sittings with people in committed relationships with women who dance in strip clubs. These couples have confronted the challenging questions of human connection and intimacy we all face, with a mix of courage, humor, and vulnerability"--},
	publisher = {Norman Stuart Publishing},
	author = {Buck, Christopher William and Burana, Lily},
	year = {2020},
	keywords = {Arjun's Library - Physical Copy},
}

@book{baker_blue_2008,
	address = {New York},
	title = {A blue hand: the {Beats} in {India}},
	isbn = {978-1-59420-158-5},
	shorttitle = {A blue hand},
	publisher = {Penguin Press},
	author = {Baker, Deborah},
	year = {2008},
	note = {OCLC: ocn156975405},
	keywords = {Arjun's Library - Physical Copy, Ginsberg, Allen, India, Travel},
}

@book{brautigan_trout_2010,
	address = {Boston},
	edition = {1st Mariner Books ed},
	title = {Trout fishing in {America}},
	isbn = {978-0-547-25527-9},
	publisher = {Mariner Books},
	author = {Brautigan, Richard},
	year = {2010},
	note = {OCLC: ocn299712304},
	keywords = {Arjun's Library - Physical Copy},
}

@book{berrigan_times_2010,
	address = {Eugene, OR},
	title = {The time's discipline: the {Beatitudes} and nuclear resistance},
	isbn = {978-1-60899-057-3},
	shorttitle = {The time's discipline},
	language = {English},
	publisher = {Wipf \& Stock Publishers},
	author = {Berrigan, Philip and McAlister, Elizabeth},
	year = {2010},
	note = {OCLC: 774486833},
	keywords = {Arjun's Library - Physical Copy},
}

@misc{noauthor_bayesian_nodate,
	title = {A {Bayesian} network for reliability assessment of man-machine phased-mission system considering the phase dependencies of human cognitive error {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832020308735?token=8F23909B4AF110E0A41F228CC38CAC792EA11484B0F2609CC2DF3F042B8B3471947CD88A9A9910B103086286CC52E8D3&originRegion=us-east-1&originCreation=20210929150712},
	language = {en},
	urldate = {2021-09-29},
	doi = {10.1016/j.ress.2020.107385},
}

@misc{noauthor_bayesian_nodate-1,
	title = {A {Bayesian} network for reliability assessment of man-machine phased-mission system considering the phase dependencies of human cognitive error - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020308735},
	urldate = {2021-09-29},
}

@misc{noauthor_engineering_nodate,
	title = {Engineering {Village} - {Multi}-{Hazard}},
	url = {https://www.engineeringvillage.com/search/quick.url?usageZone=evlogo&usageOrigin=header},
	urldate = {2021-07-23},
}

@article{rubin_next_nodate,
	title = {Next {Generation} {Nuclear} {Plant} {Technical} {Issues} and {Safety} {Research} {Needs}—{NRC} {Staff} {Views}},
	language = {en},
	author = {Rubin, Stuart},
	pages = {1},
}

@article{noauthor_mechanistic_2016,
	title = {{MECHANISTIC} {SOURCE} {TERMS} {FOR} {THE} {XE}-100 {REACTOR} {XSTERM} {Code} {Development} {Approach}},
	language = {en},
	year = {2016},
	pages = {14},
}

@article{ba_multi-hazard_2021,
	title = {Multi-hazard disaster scenario method and emergency management for urban resilience by integrating experiment–simulation–field data},
	volume = {2},
	issn = {26664496},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666449621000141},
	doi = {10.1016/j.jnlssr.2021.05.002},
	language = {en},
	number = {2},
	urldate = {2021-09-28},
	journal = {Journal of Safety Science and Resilience},
	author = {Ba, Rui and Deng, Qing and Liu, Yi and Yang, Rui and Zhang, Hui},
	month = jun,
	year = {2021},
	pages = {77--89},
}

@article{su_inclusion_2014,
	title = {Inclusion of task dependence in human reliability analysis},
	volume = {128},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832014000696},
	doi = {10.1016/j.ress.2014.04.007},
	abstract = {Dependence assessment among human errors in human reliability analysis (HRA) is an important issue, which includes the evaluation of the dependence among human tasks and the effect of the dependence on the final human error probability (HEP). This paper represents a computational model to handle dependence in human reliability analysis. The aim of the study is to automatically provide conclusions on the overall degree of dependence and calculate the conditional human error probability (CHEP) once the judgments of the input factors are given. The dependence influencing factors are first identified by the experts and the priorities of these factors are also taken into consideration. Anchors and qualitative labels are provided as guidance for the HRA analyst׳s judgment of the input factors. The overall degree of dependence between human failure events is calculated based on the input values and the weights of the input factors. Finally, the CHEP is obtained according to a computing formula derived from the technique for human error rate prediction (THERP) method. The proposed method is able to quantify the subjective judgment from the experts and improve the transparency in the HEP evaluation process. Two examples are illustrated to show the effectiveness and the flexibility of the proposed method.},
	language = {en},
	urldate = {2021-09-27},
	journal = {Reliability Engineering \& System Safety},
	author = {Su, Xiaoyan and Mahadevan, Sankaran and Xu, Peida and Deng, Yong},
	month = aug,
	year = {2014},
	keywords = {Dependence, Expert elicitation, Human error probability, Human reliability analysis},
	pages = {41--55},
}

@inproceedings{renze_psa_2017,
	address = {Shanghai, China},
	title = {{PSA} {Research} of {Transport} of {New} {Fuel} of {HTR}-{PM}},
	isbn = {978-0-7918-5782-3},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE25/57823/Shanghai,%20China/252528},
	doi = {10.1115/ICONE25-66012},
	abstract = {Probabilistic safety assessment (PSA) method was explored to be introduced in radiation risk assessment of radioactive material transport (RMT), and then radiation risk of road transport (RT) of new fuel element (FE) of commercial High Temperature Reactor-Pebblebed Modules (HTR-PM) was analyzed. By accident scenario analysis, mechanical analysis and criticality analysis, both accident conditions of package radiation level hoist and criticality were chosen for accident frequency analysis. Since the results show that accident frequency of package radiation level hoist is low and accident frequency of criticality is extremely low, criticality accident can be neglected in the sequential risk assessment. The consequence of typical accident scenarios was estimated, and the results show that the maximum external exposure dose arising from the accident for emergency workers is 0.55mSv, and 4.55×10-3mSv for public people around, which is acceptable. The global radiation risk is 1.24×10-10person•Sv/(vehicle•each transport), for which impact accident contributes the maximum percent.},
	language = {en},
	urldate = {2021-09-26},
	booktitle = {Volume 4: {Nuclear} {Safety}, {Security}, {Non}-{Proliferation} and {Cyber} {Security}; {Risk} {Management}},
	publisher = {American Society of Mechanical Engineers},
	author = {Renze, Wang and Jiangang, Zhang and Guoqiang, Li and Dajie, Zhuang and Dongyuan, Meng and Xuexin, Wang and Hongchao, Sun and Shutang, Sun},
	month = jul,
	year = {2017},
	pages = {V004T14A002},
}

@article{wang_research_2016-1,
	title = {Research on radiation risk of new fuel transportation for {HTR}-{PM}},
	volume = {50},
	issn = {10006931},
	doi = {10.7538/yzk.2016.50.12.2299},
	abstract = {The systemic application of probabilistic safety assessment (PSA) method to radiation risk assessment of radioactive material transportation was explored, and then the radiation risk of road transportation of new fuel elements of HTR-PM was analyzed. Based on actual route data and potential accident scenarios, both accident conditions of package radiation level hoist and criticality were chosen for accident frequency analysis. The results show that the frequency of package radiation level hoist accident is 4.2110-7 (vehicleeach transportation)-1, while the consequence of criticality accident could not be considered because its frequency is less than 110-13 (vehicleeach transportation)-1. The results of accident consequence show that in the package radiation level hoist accident, the maximum external exposure dose arising from the accident for emergency worker is 0.55 mSv, and 4.5510-3 mSv for public people around, which are acceptable. The global radiation risk is 1.2410-10 personSv/(vehicleeach transportation), for which impact accident contributes the maximum percent.  2016, Editorial Board of Atomic Energy Science and Technology. All right reserved.},
	number = {12},
	journal = {Yuanzineng Kexue Jishu/Atomic Energy Science and Technology},
	author = {Wang, Ren-Ze and Meng, Dong-Yuan and Zhuang, Da-Jie and Cao, Fang-Fang and Li, Guo-Qiang and Wang, Xue-Xin and Zhang, Jian-Gang and Sun, Hong-Chao and Sun, Shu-Tang},
	year = {2016},
	note = {Publisher: Atomic Energy Press},
	keywords = {Accidents, Atmospheric radiation, Criticality (nuclear fission), Fueling, Fuels, Hoists, Materials handling, Motor transportation, Radiation, Radioactive elements, Radioactive waste transportation, Risk assessment, Roads and streets, Vehicles},
	pages = {2299--2304},
}

@article{wei_jinfeng_characteristics_2012,
	series = {J. {Tsinghua} {Univ}., {Sci}. {Technol}. ({China})},
	title = {Characteristics of closed fuel cycles in the pebble bed high temperature gas cooled reactor},
	volume = {52},
	issn = {1000-0054},
	abstract = {The reuse of uranium and plutonium from high temperature gas-cooled reactor (HTGR) spent fuel will improve resource usage and minimize waste. The characteristics of different closed fuel cycles were studied here for uranium and plutonium recycled from 250 MWth high-temperature gas-cooled reactor pebble-bed-module (HTR-PM) spent fuel from a U-Pu fueled core. PuO2 and MOX fuel elements using recycled plutonium and uranium were then used in new PuO2 or MOX fueled cores with the same geometry as the original reactor. PuO2 from LWR spent fuel was also evaluated. The characteristics of the fuel utilization and transuranic incineration in these closed fuel cycles were studied with the VSOP program. The natural uranium utilization closed fuel for these closed fuel cycle is increased by 6\%, 8\% and 20\%, while the plutonium burn rates are 40\%, 41\% and 63\%, respectively. Thus, these HTGR closed fuel cycles can effectively burn plutonium isotopes and increase natural uranium utilization.},
	number = {2},
	journal = {Journal of Tsinghua University (Science and Technology)},
	author = {{Wei Jinfeng} and {Sun Yuliang} and {Li Fu}},
	month = feb,
	year = {2012},
	note = {Place: China
Publisher: Tsinghua University Press},
	keywords = {fission reactor core control, gas cooled reactors, geometry, plutonium, radioactive waste processing, uranium},
	pages = {249--52},
}

@article{fuks_management_2020,
	title = {Management of radioactive waste containing graphite: {Overview} of methods},
	volume = {13},
	issn = {19961073},
	shorttitle = {Management of radioactive waste containing graphite},
	doi = {10.3390/en13184638},
	abstract = {Since the beginning of the nuclear industry, graphite has been widely used as a moderator and reflector of neutrons in nuclear power reactors. Some reactors are relatively old and have already been shut down. As a result, a large amount of irradiated graphite has been generated. Although several thousand papers in the International Nuclear Information Service (INIS) database have discussed the management of radioactive waste containing graphite, knowledge of this problem is not common. The aim of the paper is to present the current status of the methods used in different countries to manage graphite-containing radioactive waste. Attention has been paid to the methods of handling spent TRISO fuel after its discharge from high-temperature gas-cooled reactors (HTGR) reactors.  2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).},
	number = {18},
	journal = {Energies},
	author = {Fuks, Leon and Herdzik-Koniecko, Irena and Kiegiel, Katarzyna and Zakrzewska-Koltuniewicz, Grazyna},
	year = {2020},
	note = {Publisher: MDPI AG},
	keywords = {Gas cooled reactors, Graphite, High temperature gas reactors, Information services, Nuclear fuels, Nuclear industry, Radioactive waste storage, Radioactive wastes, Radioactivity, Waste management},
}

@inproceedings{atmoko_design_2019,
	address = {Palembang, South Sumatra, India},
	series = {Journal of {Physics}: {Conference} {Series}},
	title = {Design {Criteria} of {Instrumentation} and {Control} in {Fuel} {Handling} {System} of {RDE}},
	volume = {1198},
	doi = {10.1088/1742-6596/1198/2/022029},
	abstract = {The Experimental Power Reactor (RDE) is built based on HTGR technology with pebble fuel. The fuel handling system in the RDE is one of the major installations for the RDE to maintain in continuous operation without being shutdown. There are several stages in RDE fuel supply in its fuel handling system, first fresh fuel input stage, second fuel fuel field selection, and third used fuel selection which can still be used provided that it still meets degree burn / burn-up below 80\% and become waste (spent fuel). These three processes need to be monitored and controlled with an integrated instrumentation system. The system is generally called the instrumentation and control system (I\&C) fuel handling system To meet these needs it is necessary to design and construction the system required criteria with reference to several standards. 2019 Published under licence by IOP Publishing Ltd.},
	booktitle = {1st {Symposium} of {Emerging} {Nuclear} {Technology} and {Engineering} {Novelty}, {SENTEN} 2018, {July} 4, 2018  -  {July} 5, 2018},
	publisher = {IOP Publishing Ltd},
	author = {Atmoko, Dian Fitri and Suntoro, Achmad and {Deswandri}},
	year = {2019},
	note = {Issue: 2},
	keywords = {Fuel systems, Fuels, Materials handling, Materials handling equipment},
}

@article{lin_dynamic_2021,
	title = {Dynamic analysis of dry storage canister and the spent fuels inside under vertical drop in {HTR}-{PM}},
	volume = {154},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S030645492030726X},
	doi = {10.1016/j.anucene.2020.108030},
	abstract = {High-temperature gas cooled reactor pebble-bed modular (HTR-PM) uses a dry storage system based on steel storage canisters to store and transport spent fuels on-site. For the canister, one of the key equipment, it is necessary to verify the reliability of the structural design in extreme events, especially under the accidental drop. Since there are 40,000 fuel elements in a canister, interfacial coupling effect between thin-walled storage canister and pebble bed cannot be ignored under the impact. Here, pebble bed and storage canister are modelled by discrete element model and finite element model, respectively. Using this interfacial coupling model, dynamic interactions between the inner surface of canister and spent fuel elements and inside the pebble bed self were analysed numerically. Interactive forces calculated during impact is well applied to diagnose the failure behaviour of fuel elements. The computation results are validated by the full-scale drop test of HTR-PM spent fuel canister.},
	language = {en},
	urldate = {2021-09-26},
	journal = {Annals of Nuclear Energy},
	author = {Lin, Musen and Wang, Jinhua and Wu, Bin and Li, Yue},
	month = may,
	year = {2021},
	keywords = {Contact force, DEM-FEM, Drop test, Impact, Spent fuel storage canister},
	pages = {108030},
}

@techreport{joksimovic_htgr_1977,
	type = {Conference},
	title = {{HTGR} risk assessment study},
	url = {https://www.osti.gov/biblio/5450842-htgr-risk-assessment-study},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {GA-A-14336; CONF-770625-4},
	urldate = {2021-09-26},
	institution = {General Atomics, San Diego, CA (United States)},
	author = {Joksimovic, V. and Houghton, W. J. and Emon, D. E.},
	month = jul,
	year = {1977},
}

@article{fleming_probabilistic_1981,
	title = {Probabilistic risk assessment of {HTGRs}},
	volume = {2},
	issn = {0143-8174},
	url = {https://www.sciencedirect.com/science/article/pii/0143817481900251},
	doi = {10.1016/0143-8174(81)90025-1},
	abstract = {Probabilistic risk assessment (PRA) methods have been applied to gas-cooled reactors for more than a decade and to HTGRs for more than six years in the programmes sponsored by the US Department of Energy. Significant advancements to the development of PRA methodology in these programmes are summarized as are the specific applications of the methods to HTGRs. Emphasis here is on PRA as a tool for evaluating HTGR design options. Current work and future directions are also discussed.},
	language = {en},
	number = {1},
	urldate = {2021-09-26},
	journal = {Reliability Engineering},
	author = {Fleming, K. N. and Houghton, W. J. and Hannaman, G. W. and Joksimovic, V.},
	month = jan,
	year = {1981},
	pages = {17--25},
}

@article{noauthor_nureg-2199_nodate,
	title = {{NUREG}-2199, {Vol}. 1, "{An} {Integrated} {Human} {Event} {Analysis} {System} ({IDHEAS}) for {Nuclear} {Power} {Plant} {Internal} {Events} {At}-{Power} {Application} - {Volume} 1."},
	language = {en},
	pages = {317},
}

@article{hall_experimental_1979,
	title = {Experimental oral infections of pregnant heifers with {Salmonella} dublin},
	volume = {135},
	issn = {0007-1935},
	doi = {10.1016/s0007-1935(17)32991-3},
	language = {eng},
	number = {1},
	journal = {The British Veterinary Journal},
	author = {Hall, G. A. and Jones, P. W.},
	month = feb,
	year = {1979},
	pmid = {761062},
	keywords = {Animals, Cattle, Cattle Diseases, Female, Pregnancy, Pregnancy Complications, Infectious, Salmonella Infections, Animal},
	pages = {75--82},
}

@misc{noauthor_technical_nodate,
	title = {Technical {Basis} and {Implementation} {Guidelines} for {A} {Technique} for {Human} {Event} {Analysis} ({ATHEANA}) ({NU}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1624/index.html},
	urldate = {2021-09-25},
	journal = {NRC Web},
}

@techreport{swain_handbook_1983,
	title = {Handbook of human-reliability analysis with emphasis on nuclear power plant applications. {Final} report},
	url = {http://www.osti.gov/servlets/purl/5752058/},
	language = {en},
	number = {NUREG/CR-1278, SAND-80-0200, 5752058},
	urldate = {2021-09-25},
	author = {Swain, A D and Guttmann, H E},
	month = aug,
	year = {1983},
	doi = {10.2172/5752058},
	pages = {NUREG/CR--1278, SAND--80--0200, 5752058},
}

@techreport{bley_philosophy_1999,
	title = {Philosophy of {ATHEANA}},
	url = {https://www.osti.gov/biblio/5044},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {SAND99-0702C},
	urldate = {2021-09-25},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States); Sandia National Lab. (SNL-CA), Livermore, CA (United States)},
	author = {Bley, D. C. and Cooper, S. E. and Forester, J. A. and Kolaczkowski, A. M. and Ramey-Smith, A. and Thompson, C. M. and Whitehead, D. W. and Wreathall, J.},
	month = mar,
	year = {1999},
}

@article{saji_new_2003,
	title = {A new approach to reactor safety goals in the framework of {INES}},
	volume = {80},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832003000255},
	doi = {10.1016/S0951-8320(03)00025-5},
	abstract = {By extending a framework of the International Nuclear Event Scales (INES) widely used throughout the world, the author proposes a new concept of reactor safety goals that facilitates engineering applications, while removing some of the uncertainties often encountered in implementing safety goals. The INES criteria speciﬁed in releases are translated into doses by performing dispersion calculations for a typical site to estimate radiological consequences to the public. Quantitative health objectives that incorporate lessons learned from radiological consequences of the Chernobyl accident are deployed into master risk curves. More attention is paid to immediate noble gas releases occurring in the early phase of severe accidents, as well as the delayed release of iodine and cesium that can cause wide spread land contamination. The land contaminated with radioactive iodine around Chernobyl and the subsequent ingestion of iodine through pasturecow-milk pathways is said to have induced many of the thyroid cancer cases. By monitoring more frequent incidents with/without release, a set of master risk curves can be used to assess the operating performance of plants in a safety space delineated by three regions (acceptable, tolerable, unacceptable). It is concluded that another Level 5 or beyond radiological consequence, especially the potential land contamination by 137Cs would be a disaster and is totally unacceptable.},
	language = {en},
	number = {2},
	urldate = {2021-09-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Saji, Genn},
	month = may,
	year = {2003},
	pages = {143--161},
}

@article{aleta_regulatory_2009,
	title = {Regulatory implications of a linear non-threshold ({LNT}) dose-based risks},
	volume = {67},
	issn = {09698043},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0969804309001390},
	doi = {10.1016/j.apradiso.2009.02.032},
	abstract = {Current radiation protection regulatory limits are based on the linear non-threshold (LNT) theory using health data from atomic bombing survivors. Studies in recent years sparked debate on the validity of the theory, especially at low doses.},
	language = {en},
	number = {7-8},
	urldate = {2021-09-25},
	journal = {Applied Radiation and Isotopes},
	author = {Aleta, C.R.},
	month = jul,
	year = {2009},
	pages = {1290--1298},
}

@article{sankaranarayanan_reflections_2008,
	title = {Reflections on the impact of advances in the assessment of genetic risks of exposure to ionizing radiation on international radiation protection recommendations between the mid-1950s and the present},
	volume = {658},
	issn = {13835742},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S138357420700066X},
	doi = {10.1016/j.mrrev.2007.10.004},
	abstract = {Efforts at protecting people against the harmful effects of radiation had their beginnings in the early 1900s with the intent of protecting individuals in medicine and associated professions. Such efforts remain vital for all of us more than 100 years later as part of our ‘learning to live with ionizing radiation.’ The ﬁeld of radiation protection has evolved slowly over time with advances in knowledge on hereditary (i.e., genetic) and carcinogenic effects of radiation continually improving our ability to make informed judgments about how best to balance risks against beneﬁts of radiation exposure. This paper examines just one aspect of these efforts, namely, how advances in knowledge of genetic effects of radiation have impacted on the recommendations of the International Commission on Radiological Protection (ICRP). The focus is on the period from the mid1950s (when genetic risk estimates were ﬁrst made) to 2007. This article offers a detailed historical analysis and personal perspective, and concludes with a synopsis of key developments in radiation protection.},
	language = {en},
	number = {1-2},
	urldate = {2021-09-25},
	journal = {Mutation Research/Reviews in Mutation Research},
	author = {Sankaranarayanan, K. and Wassom, J.S.},
	month = jan,
	year = {2008},
	pages = {1--27},
}

@article{yoshikawa_experimental_1999,
	title = {An experimental study on estimating human error probability ({HEP}) parameters for {PSA}/{HRA} by using human model simulation},
	volume = {42},
	issn = {0014-0139, 1366-5847},
	url = {https://www.tandfonline.com/doi/full/10.1080/001401399184910},
	doi = {10.1080/001401399184910},
	language = {en},
	number = {11},
	urldate = {2021-09-25},
	journal = {Ergonomics},
	author = {Yoshikawa, Hidekazu and Wu, Wei},
	month = nov,
	year = {1999},
	pages = {1588--1595},
}

@article{conway_physical_2019,
	title = {Physical security analysis and simulation of the multi-layer security system for the {Offshore} {Nuclear} {Plant} ({ONP})},
	volume = {352},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549319301712},
	doi = {10.1016/j.nucengdes.2019.110160},
	abstract = {This research has investigated the effectiveness of the proposed security plan for the ONP-300 through the use of a simulation software developed by ARES Security Corporation which evaluates the plant design and security plan. This paper updates the security strategy in the earlier 2016 paper (ICONE24-61029, Charlotte, NC, Kindfuller et. al.) with the following significant additions: a modification of the plant design for security optimization, changes in the guard force based on simulations, placement of the protective barrier to prevent damage from ship explosions, and establishment of the shore station guard force, response team and key facilities. Different attack scenarios were investigated, and four design-basis threats were formulated based on guidance from industry professionals. Through the use of ARES software, results indicated that the initial platform design for the ONP 300 had line-of-sight issues for security officers on the top deck of the plant resulting in an unacceptable performance. This realization led to changes in the ONP 300′s security configuration and structural layout. Additional sensitivity analysis resulted in reduction of guard force size and emphasized the importance of redundant radar systems.},
	language = {en},
	urldate = {2021-09-25},
	journal = {Nuclear Engineering and Design},
	author = {Conway, Jared and Todreas, Neil and Halsema, John and Guryan, Chris and Birch, Arthur and Isdanavich, Tom and Florek, Jason and Buongiorno, Jacopo and Golay, Michael},
	month = oct,
	year = {2019},
	pages = {110160},
}

@article{woo_analytic_2013,
	title = {Analytic study for physical protection system ({PPS}) in nuclear power plants ({NPPs})},
	volume = {265},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549313005323},
	doi = {10.1016/j.nucengdes.2013.09.025},
	language = {en},
	urldate = {2021-09-25},
	journal = {Nuclear Engineering and Design},
	author = {Woo, Tae Ho},
	month = dec,
	year = {2013},
	pages = {932--937},
}

@techreport{odendaal_quality_2020,
	type = {Topical {Report}},
	title = {Quality {Assurance} {Program} {Description}},
	language = {en},
	institution = {X-energy, LLC},
	author = {Odendaal, T},
	year = {2020},
	pages = {47},
}

@unpublished{noauthor_qt53n4f34mpdf_nodate,
	title = {qt53n4f34m.pdf},
	url = {https://escholarship.org/content/qt53n4f34m/qt53n4f34m.pdf},
	urldate = {2021-09-17},
}

@article{noauthor_us_nodate,
	title = {U.{S}. {Nuclear} {Regulatory} {Commission} {Final} {Safety} {Evaluation} {For} {X}-{Energy}'s {Topical} {Report} {Xeqapd}-{Np}, "{Quality} {Assurance} {Program} {Description}," {Revision} 3 ({EPID} {No}. {L}-2019-{Top}-0020)},
	language = {en},
	pages = {22},
}

@misc{noauthor_xe-100_nodate,
	title = {Xe-100 {Project} {Overview} and {Pre}-{Application} {Activities}},
	url = {https://www.nrc.gov/reactors/new-reactors/advanced/ongoing-licensing-activities/pre-application-activities/xe-100.html},
	urldate = {2021-09-24},
	journal = {NRC Web},
}

@misc{noauthor_xe-100_nodate-1,
	title = {Xe-100 reactor pre-application documents ({NRC} {Docket} 99902071).},
	url = {https://adams.nrc.gov/wba/?data=(mode:sections,sections:(filters:(public-library:!t),options:(within-folder:(enable:!f,insubfolder:!f,path:%27%27)),properties_search_all:!(!(DocketNumber,starts,%2799902071%27,%27%27))))&qn=New&tab=advanced-search-pars&z=0},
	urldate = {2021-09-24},
}

@misc{noauthor_xe-100_nodate-2,
	title = {Xe-100},
	url = {https://www.nrc.gov/reactors/new-reactors/advanced/ongoing-licensing-activities/pre-application-activities/xe-100.html},
	urldate = {2021-09-24},
	journal = {NRC Web},
}

@article{park_probabilistic_nodate,
	title = {Probabilistic safety assessment-based importance analysis of cyber-attacks on nuclear power plants},
	author = {Park, JongWoo},
	pages = {8},
}

@article{hagood_small_nodate,
	title = {Small {Modular} {Reactor} and {Advanced} {Reactor} {RD}\&{D}:},
	language = {en},
	author = {Hagood, Michael},
	pages = {23},
}

@misc{noauthor_high_2019,
	type = {Text},
	title = {High {Temperature} {Gas} {Cooled} {Reactor} {Fuels} and {Materials}},
	url = {https://www.iaea.org/publications/8270/high-temperature-gas-cooled-reactor-fuels-and-materials},
	language = {en},
	urldate = {2021-09-24},
	month = feb,
	year = {2019},
	note = {Publisher: IAEA},
}

@techreport{humrickhouse_htgr_2011,
	title = {{HTGR} {Dust} {Safety} {Issues} and {Needs} for {Research} and {Development}},
	url = {https://www.osti.gov/biblio/1023483},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-11-21097},
	urldate = {2021-09-23},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Humrickhouse, Paul W.},
	month = jun,
	year = {2011},
	doi = {10.2172/1023483},
}

@inproceedings{humrickhouse_htgr_2011-1,
	title = {{HTGR} {Dust} {Safety} {Issues} and {Needs} for {Research} and {Development}},
	doi = {10.2172/1023483},
	abstract = {This report presents a summary of high temperature gas-cooled reactor dust safety issues. It draws upon a literature review and the proceedings of the Very High Temperature Reactor Dust Assessment Meeting held in Rockville, MD in March 2011 to identify and prioritize the phenomena and issues that characterize the effect of carbonaceous dust on high temperature reactor safety. It reflects the work and input of approximately 40 participants from the U.S. Department of Energy and its National Labs, the U.S. Nuclear Regulatory Commission, industry, academia, and international nuclear research organizations on the topics of dust generation and characterization, transport, fission product interactions, and chemical reactions. The meeting was organized by the Idaho National Laboratory under the auspices of the Next Generation Nuclear Plant Project, with support from the U.S. Nuclear Regulatory Commission. Information gleaned from the report and related meetings will be used to enhance the fuel, graphite, and methods technical program plans that guide research and development under the Next Generation Nuclear Plant Project. Based on meeting discussions and presentations, major research and development needs include: generating adsorption isotherms for fission products that display an affinity for dust, investigating the formation and properties of carbonaceous crust on the insidemore » of high temperature reactor coolant pipes, and confirming the predominant source of dust as abrasion between fuel spheres and the fuel handling system.« less},
	author = {Humrickhouse, P.},
	year = {2011},
}

@techreport{noauthor_mil-std_nodate,
	title = {{MIL}-{STD} {756B} {Reliability} {Modeling} {Prediction}.pdf},
	url = {http://everyspec.com/MIL-STD/MIL-STD-0700-0799/MIL_STD_756B_1072/},
}

@misc{noauthor_earthquake_nodate,
	title = {Earthquake {Glossary}},
	url = {https://earthquake.usgs.gov/learn/glossary/?term=acceleration},
	urldate = {2021-09-20},
}

@article{beyea_response_2016,
	title = {Response to, “{On} the origins of the linear no-threshold ({LNT}) dogma by means of untruths, artful dodges and blind faith.”},
	volume = {148},
	issn = {00139351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S001393511630038X},
	doi = {10.1016/j.envres.2016.01.039},
	abstract = {It is not true that successive groups of researchers from academia and research institutions—scientists who served on panels of the US National Academy of Sciences (NAS)—were duped into supporting a linear no-threshold model (LNT) by the opinions expressed in the genetic panel section of the 1956 “BEAR I” report. Successor reports had their own views of the LNT model, relying on mouse and human data, not fruit ﬂy data. Nor was the 1956 report biased and corrupted, as has been charged in an article by Edward J. Calabrese in this journal. With or without BEAR I, the LNT model would likely have been accepted in the US for radiation protection purposes in the 1950's.},
	language = {en},
	urldate = {2021-09-20},
	journal = {Environmental Research},
	author = {Beyea, Jan},
	month = jul,
	year = {2016},
	pages = {527--534},
}

@article{embrey_use_1981,
	title = {The use of {Quantified} {Expert} {Judgement} in the {Assessment} of {Human} {Reliability} in {Nuclear} {Power} {Plant} {Operation}},
	volume = {25},
	issn = {0163-5182},
	url = {http://journals.sagepub.com/doi/10.1177/107118138102500124},
	doi = {10.1177/107118138102500124},
	abstract = {The procedures of system r e l i a b i l i t y assessment i n n u c l e a r power a r e described, with particular reference t o t h e need f o r e v a l u a t i n g human r e l i a b i l i t y . The shortcomings of e x i s t i n g approaches a r e discussed, and an a l t e r n a t i v e methodology described, which u t i l i s e s quantified subjective judgement.},
	language = {en},
	number = {1},
	urldate = {2021-09-18},
	journal = {Proceedings of the Human Factors Society Annual Meeting},
	author = {Embrey, David E.},
	month = oct,
	year = {1981},
	pages = {96--99},
}

@article{zou_heuristic_2017,
	title = {A heuristic approach for the evaluation of {Physical} {Protection} {System} effectiveness},
	volume = {105},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454916309112},
	doi = {10.1016/j.anucene.2017.03.029},
	abstract = {Physical Protection System (PPS) is essential for each nuclear power plant to safeguard its nuclear materials and nuclear facilities from theft, robbery, illegal transport and sabotage. This paper presents a novel method (HAPPS) combined with Estimate of Adversary Sequence Interruption (EASI) method and heuristic approach (Ant Colony Optimization, ACO) for analyzing and evaluating the PPS effectiveness of NPPs. Import 2-D engineering drawings into the analysis application, identify the information contained in the model, and use the HAPPS method as search algorithm to seek the vulnerable adversary intrusion and escape path under certain conditions. The results of PPS effectiveness analysis will provide a detailed technical feedback for redesigning PPS.},
	language = {en},
	urldate = {2021-09-18},
	journal = {Annals of Nuclear Energy},
	author = {Zou, Bowen and Yang, Ming and Guo, Jia and Benjamin, Emi-Reybold and Wu, Wenfei},
	month = jul,
	year = {2017},
	pages = {302--310},
}

@article{tao_bibliometric_2020,
	title = {A bibliometric analysis of human reliability research},
	volume = {260},
	issn = {09596526},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095965262031088X},
	doi = {10.1016/j.jclepro.2020.121041},
	abstract = {Due to the rapid development of scientiﬁc technology, human inﬂuence is considered as a dominant factor that affects the occurrence of various accidents, while the promotion of human reliability is useful for the reduction of human errors. In order to uncover the research characteristics and development trends in the human reliability research domain, a bibliometric analysis of scientiﬁc documents was carried out via the Web of Science Core Collection database. In general, a total of 1463 documents on human reliability were indexed between 1984 and 2018, covering 3287 authors, 533 journals, 71 countries, and 1364 institutions. The studies related to human reliability have a signiﬁcant increase from the earliest 4 in 1984 to 137 articles in 2018. The USA, UK, and China made the three most contributions to the literature associated with human reliability research. In terms of the major sources of human reliability publications, Reliability Engineering \& System Safety, Safety Science, Microelectronics and Reliability, Applied Ergonomics, and Ergonomics were the ﬁve most active journals in this domain. Park, Jung, Kirwan, Seong, and Zhang greatly devoted to human reliability publications. According to the frequency of keywords, the hottest topics in human reliability domain focus on human reliability analysis, human error, model, ergonomics, human reliability assessment, patient safety, and nuclear power plant, etc. The primary themes in human reliability research concentrate on the human reliability analysis methods, system reliability analysis, human error identiﬁcation, and human performance in human-machine system, etc. Future research should emphasize human factor experimentation, cognitive model, the development of human reliability analysis methods, and human reliability analysis in information technology.},
	language = {en},
	urldate = {2021-09-18},
	journal = {Journal of Cleaner Production},
	author = {Tao, Jing and Qiu, Dongyang and Yang, Fuqiang and Duan, Zaipeng},
	month = jul,
	year = {2020},
	pages = {121041},
}

@misc{noauthor_log-normal_2021,
	title = {Log-normal distribution},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Log-normal_distribution&oldid=1040369783},
	abstract = {In probability theory, a log-normal (or lognormal) distribution is a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable X is log-normally distributed, then Y = ln(X) has a normal distribution. Equivalently, if Y has a normal distribution, then the exponential function of Y, X = exp(Y), has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values. It is a convenient and useful model for measurements in exact and engineering sciences, as well as medicine, economics and other topics (e.g., energies, concentrations, lengths, financial returns and other metrics).
The distribution is occasionally referred to as the Galton distribution or Galton's distribution, after Francis Galton. The log-normal distribution has also been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.A log-normal process is the statistical realization of the multiplicative product of many independent random variables, each of which is positive. This is justified by considering the central limit theorem in the log domain (sometimes call Gibrat's law). The log-normal distribution is the maximum entropy probability distribution for a random variate X—for which the mean and variance of ln(X) are specified.},
	language = {en},
	urldate = {2021-09-17},
	journal = {Wikimedia commons},
	month = aug,
	year = {2021},
	note = {Page Version ID: 1040369783},
}

@techreport{stamm_american_2019,
	title = {American {Nuclear} {Society} {Standards} {Committee} {Glossary} of {Definitions} and {Terminology}},
	url = {https://www.ans.org/file/731/1/ANS%20SC%20Glossary%20of%20Definitions%20and%20Terminology%20(April%202019).pdf},
	language = {en},
	author = {Stamm, Steven},
	year = {2019},
	pages = {201},
}

@article{shu_team_2002,
	title = {Team performance modeling for {HRA} in dynamic situations},
	volume = {78},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832002001114},
	doi = {10.1016/S0951-8320(02)00111-4},
	abstract = {This paper proposes a team behavior network model that can simulate and analyze response of an operator team to an incident in a dynamic and context-sensitive situation. The model is composed of four sub-models, which describe the context of team performance. They are task model, event model, team model and human–machine interface model. Each operator demonstrates aspects of his/her specific cognitive behavior and interacts with other operators and the environment in order to deal with an incident. Individual human factors, which determine the basis of communication and interaction between individuals, and cognitive process of an operator, such as information acquisition, state-recognition, decision-making and action execution during development of an event scenario are modeled. A case of feed and bleed operation in pressurized water reactor under an emergency situation was studied and the result was compared with an experiment to check the validity of the proposed model.},
	language = {en},
	number = {2},
	urldate = {2021-09-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Shu, Yufei and Furuta, Kazuo and Kondo, Shunsuke},
	month = nov,
	year = {2002},
	keywords = {Cognitive model, Communication, Human factors, Human reliability analysis, Team performance},
	pages = {111--121},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: {S0951}-8320(02)00111-4 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0951832002001114?token=8AB2AE70D5C5015AC45DE0E37EF24C4BE670490C366223C89B7975F05BAF3390CF803EA2DEEF8463031463CC70B10050&originRegion=us-east-1&originCreation=20210917145619},
	language = {en},
	urldate = {2021-09-17},
	doi = {10.1016/S0951-8320(02)00111-4},
}

@article{shu_team_2002-1,
	title = {Team performance modeling for {HRA} in dynamic situations},
	volume = {78},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832002001114},
	doi = {10.1016/S0951-8320(02)00111-4},
	abstract = {This paper proposes a team behavior network model that can simulate and analyze response of an operator team to an incident in a dynamic and context-sensitive situation. The model is composed of four sub-models, which describe the context of team performance. They are task model, event model, team model and human–machine interface model. Each operator demonstrates aspects of his/her specific cognitive behavior and interacts with other operators and the environment in order to deal with an incident. Individual human factors, which determine the basis of communication and interaction between individuals, and cognitive process of an operator, such as information acquisition, state-recognition, decision-making and action execution during development of an event scenario are modeled. A case of feed and bleed operation in pressurized water reactor under an emergency situation was studied and the result was compared with an experiment to check the validity of the proposed model.},
	language = {en},
	number = {2},
	urldate = {2021-09-17},
	journal = {Reliability Engineering \& System Safety},
	author = {Shu, Yufei and Furuta, Kazuo and Kondo, Shunsuke},
	month = nov,
	year = {2002},
	keywords = {Cognitive model, Communication, Human factors, Human reliability analysis, Team performance},
	pages = {111--121},
}

@article{wang_risk_2018,
	title = {Risk {Analysis} of {Spent} {Fuel} {Pool} {Caused} by {Seismic} {Events}},
	volume = {4},
	issn = {2332-8983},
	url = {https://doi.org/10.1115/1.4040367},
	doi = {10.1115/1.4040367},
	abstract = {Spent fuel pool (SFP) stores fuel assemblies removed from the reactor over the years. SFP and its accident mitigation measures may fail simultaneously at the time of the earthquake, which may cause serious accident consequences. This paper uses probabilistic safety assessment (PSA) method to quantitatively evaluate the risk of SFP for a CPR1000 unit caused by seismic events. Quantitative analysis results show that seismic events' risk is the highest in all internal events and external events for SFP. In order to reduce the risk of SFP, more attention should be paid to improve seismic capacity or reduce the common failure for systems and components associated with SFP under the earthquake situation.},
	number = {4},
	urldate = {2021-09-17},
	journal = {Journal of Nuclear Engineering and Radiation Science},
	author = {Wang, Ming and Lin, Modi and Wang, Jinkai},
	month = sep,
	year = {2018},
}

@article{arjun_dsp_2017,
	title = {{DSP} optimization techniques for {LCDK} with focus on {IoT} applications},
	url = {http://rgdoi.net/10.13140/RG.2.2.20822.40008},
	doi = {10.13140/RG.2.2.20822.40008},
	language = {en},
	urldate = {2021-09-17},
	author = {Arjun},
	year = {2017},
	note = {Publisher: Unpublished},
}

@misc{noauthor_small_nodate,
	title = {Small {Nuclear} {Reactors} for {Military} {Installations}- {Capabilities}, {C}.pdf},
}

@techreport{us_department_of_energy_restoring_2020,
	title = {Restoring {America}'s {Competitive} {Nuclear} {Advantage}},
	language = {English},
	institution = {U.S Deparment of Energy},
	author = {U.S Department of Energy},
	year = {2020},
	pages = {32},
}

@article{philippe_feasibility_2016,
	title = {The {Feasibility} of {Ending} {HEU} {Fuel} {Use} in the {U}.{S} {Navy}},
	volume = {46},
	url = {https://www.armscontrol.org/act/2016-10/features/feasibility-ending-heu-fuel-use-us-navy},
	language = {English},
	number = {6},
	journal = {Arms Control Today},
	author = {Philippe, Sebastian and von Hippel, Frank},
	month = nov,
	year = {2016},
	pages = {12},
}

@techreport{vitali_study_2018,
	title = {Study on the use of {Mobile} {Nuclear} {Power} {Plants} for {Ground} {Operations}},
	shorttitle = {Mobile {Nuclear} {Power} {Plants} for {Ground} {Operations}},
	abstract = {This study was commissioned by the Army Deputy Chief of Staff (DCS), G-4 to analyze the potential benefits and challenges of mobile nuclear power plants (MNPPs) with very small modular reactor (vSMR) technology and to address the broader operational and strategic implications of energy delivery and management.},
	language = {English},
	institution = {Deputy Chief of Staff, G-4},
	author = {Vitali, Juan A and Lamothe, Joseph G and Toomey, Charles J. Jr and Peoples, Virgil O and Mccabe, Kerry A},
	month = oct,
	year = {2018},
	pages = {148},
}

@techreport{trump_executive_2021,
	title = {Executive {Order} on {Promoting} {Small} {Modular} {Reactors} for {National} {Defense} and {Space} {Exploration}},
	abstract = {The purpose of this order is to take an important additional step to revitalize the United States nuclear engery sector, reinvigorate America's space exploration program, and develop diverse energy options for national defense needs. Under this action, the United States Government will coordinate its nuclear activities to apply the benefits of nuclear energy most effectively toward American technology supremacy, including the use of small modular reactors for national defense and space exploration.},
	language = {English},
	author = {Trump, Donald J.},
	month = jan,
	year = {2021},
	pages = {6},
}

@techreport{national_science_and_technology_council_common_2021,
	title = {Common {Technology} {Development} {Roadmap} of {Small} {Modular} {Reactors} for {Space} {Exploration} and {National} {Defense}},
	abstract = {This document provides a common technology roadmap, as directed through Executive Order 13972, to coordinate terrestrial- and space-based advanced nuclear reactor (ANR) efforts. This roadmap is intended to serve as a resource to assist Federal departments and agencies and private sector partners in planning ANR development activities that are coordinated, cost-effective, and well-designed to enable potential future mission needs.},
	language = {English},
	institution = {Executive Office of the President of the United States},
	collaborator = {National Science {and} Technology Council},
	month = sep,
	year = {2021},
	pages = {35},
}

@misc{matthews_blue_2012,
	title = {Blue {Ribbon} {Commission} on {America}'s {Nuclear} {Future}: {Report} to the {Secretary} of {Energy}},
	publisher = {Blue Ribbon Commission},
	editor = {Matthews, Carol},
	month = jan,
	year = {2012},
}

@article{lee_design-phase_2019,
	title = {A design-phase probabilistic safety assessment of a research reactor to enhance its safety},
	author = {Lee, YoonHwan},
	month = apr,
	year = {2019},
	pages = {11},
}

@article{taotao_improved_2017,
	title = {An improved multi-unit nuclear plant seismic probabilistic risk assessment},
	author = {Taotao, Zhou and Mohammad, Modarres},
	month = nov,
	year = {2017},
	pages = {14},
}

@techreport{noauthor_proceedings_2012,
	title = {Proceedings of the 2012 {International} {Congress} on {Advances} in {National} {Power} {Plants} - {ICAPP} '12},
	url = {https://www.osti.gov/biblio/22105915-proceedings-international-congress-advances-national-power-plants-icapp},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	urldate = {2021-09-11},
	institution = {American Nuclear Society - ANS; La Grange Park (United States)},
	month = jul,
	year = {2012},
}

@misc{noauthor_2012_nodate,
	title = {2012 {International} {Congress} on {Advances} in {Nuclear} {Power} {Plants} ({ICAPP} '12) -- {ANS} / {ANS} {Store} / {Proceedings}},
	url = {https://www.ans.org/store/item-700368/},
	urldate = {2021-09-11},
}

@misc{noauthor_ncsu_nodate,
	title = {{NCSU} {Libraries} - {Tripsaver} - {Transaction} {Details}},
	url = {https://tripsaver.lib.ncsu.edu/illiad.dll?action=10&form=72},
	urldate = {2021-09-11},
}

@article{arigi_dependency_2020,
	title = {Dependency analysis method for human failure events in multi-unit probabilistic safety assessments},
	volume = {203},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183202030613X},
	doi = {10.1016/j.ress.2020.107112},
	abstract = {Dependency between human failure events (HFEs) is often analyzed as a part of the conventional human reliability analysis (HRA) process for nuclear power plants (NPPs). None of the existing methods have considered an application to multi-unit (MU) scenarios. In this study, we introduce a novel approach to evaluate the dependencies between HFEs in cases of MU event scenarios. We focus on developing a set of MU HFE dependency evaluation elements and their evaluation criteria based on the framework of the single-unit evaluation elements that have been utilized in the HRA practice for NPPs. The unique MU HFE dependency evaluation elements are defined, and we present a new dependency evaluation tree for qualitative analysis. In addition, important cases are provided to demonstrate the application of the proposed method, including four MU initiating events: MU loss of offsite power, MU loss of condenser vacuum, MU general transient, and MU loss of ultimate heat sink. Quantitative analysis with several illustrative HFEs in MU probabilistic safety assessment (PSA) cutsets are also presented. This method fills the gap of a HFE dependency analysis method in the case of MU PSA.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Arigi, Awwal Mohammed and Park, Gayoung and Kim, Jonghyun},
	month = nov,
	year = {2020},
	keywords = {Dependency analysis, Human error dependency, Human factors, Human reliability analysis, Multi-unit HRA, Multi-unit PSA, Organizational factors},
	pages = {107112},
}

@article{ekanem_phoenix_2016,
	title = {Phoenix – {A} model-based {Human} {Reliability} {Analysis} methodology: {Qualitative} {Analysis} {Procedure}},
	volume = {145},
	issn = {0951-8320},
	shorttitle = {Phoenix – {A} model-based {Human} {Reliability} {Analysis} methodology},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832015001994},
	doi = {10.1016/j.ress.2015.07.009},
	abstract = {Phoenix method is an attempt to address various issues in the field of Human Reliability Analysis (HRA). Built on a cognitive human response model, Phoenix incorporates strong elements of current HRA good practices, leverages lessons learned from empirical studies, and takes advantage of the best features of existing and emerging HRA methods. Its original framework was introduced in previous publications. This paper reports on the completed methodology, summarizing the steps and techniques of its qualitative analysis phase. The methodology introduces the “Crew Response Tree” which provides a structure for capturing the context associated with Human Failure Events (HFEs), including errors of omission and commission. It also uses a team-centered version of the Information, Decision and Action cognitive model and “macro-cognitive” abstractions of crew behavior, as well as relevant findings from cognitive psychology literature and operating experience, to identify potential causes of failures and influencing factors during procedure-driven and knowledge-supported crew-plant interactions. The result is the set of identified HFEs and likely scenarios leading to each. The methodology itself is generic in the sense that it is compatible with various quantification methods, and can be adapted for use across different environments including nuclear, oil and gas, aerospace, aviation, and healthcare.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Ekanem, Nsimah J. and Mosleh, Ali and Shen, Song-Hua},
	month = jan,
	year = {2016},
	keywords = {Crew Failure Mode (CFM), Crew Response Tree (CRT), Human Failure Event (HFE), Human Reliability Analysis (HRA), Performance Influencing Factor (PIF), Probabilistic Risk Assessment (PRA)},
	pages = {301--315},
}

@article{ekanem_phoenix_2016-1,
	title = {Phoenix – {A} model-based {Human} {Reliability} {Analysis} methodology: {Qualitative} {Analysis} {Procedure}},
	volume = {145},
	issn = {0951-8320},
	shorttitle = {Phoenix – {A} model-based {Human} {Reliability} {Analysis} methodology},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832015001994},
	doi = {10.1016/j.ress.2015.07.009},
	abstract = {Phoenix method is an attempt to address various issues in the field of Human Reliability Analysis (HRA). Built on a cognitive human response model, Phoenix incorporates strong elements of current HRA good practices, leverages lessons learned from empirical studies, and takes advantage of the best features of existing and emerging HRA methods. Its original framework was introduced in previous publications. This paper reports on the completed methodology, summarizing the steps and techniques of its qualitative analysis phase. The methodology introduces the “Crew Response Tree” which provides a structure for capturing the context associated with Human Failure Events (HFEs), including errors of omission and commission. It also uses a team-centered version of the Information, Decision and Action cognitive model and “macro-cognitive” abstractions of crew behavior, as well as relevant findings from cognitive psychology literature and operating experience, to identify potential causes of failures and influencing factors during procedure-driven and knowledge-supported crew-plant interactions. The result is the set of identified HFEs and likely scenarios leading to each. The methodology itself is generic in the sense that it is compatible with various quantification methods, and can be adapted for use across different environments including nuclear, oil and gas, aerospace, aviation, and healthcare.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Ekanem, Nsimah J. and Mosleh, Ali and Shen, Song-Hua},
	month = jan,
	year = {2016},
	keywords = {Crew Failure Mode (CFM), Crew Response Tree (CRT), Human Failure Event (HFE), Human Reliability Analysis (HRA), Performance Influencing Factor (PIF), Probabilistic Risk Assessment (PRA)},
	pages = {301--315},
}

@article{arigi_dependency_2020-1,
	title = {Dependency analysis method for human failure events in multi-unit probabilistic safety assessments},
	volume = {203},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S095183202030613X},
	doi = {10.1016/j.ress.2020.107112},
	abstract = {Dependency between human failure events (HFEs) is often analyzed as a part of the conventional human reliability analysis (HRA) process for nuclear power plants (NPPs). None of the existing methods have considered an application to multi-unit (MU) scenarios. In this study, we introduce a novel approach to evaluate the dependencies between HFEs in cases of MU event scenarios. We focus on developing a set of MU HFE dependency evaluation elements and their evaluation criteria based on the framework of the single-unit evaluation elements that have been utilized in the HRA practice for NPPs. The unique MU HFE dependency evaluation elements are defined, and we present a new dependency evaluation tree for qualitative analysis. In addition, important cases are provided to demonstrate the application of the proposed method, including four MU initiating events: MU loss of offsite power, MU loss of condenser vacuum, MU general transient, and MU loss of ultimate heat sink. Quantitative analysis with several illustrative HFEs in MU probabilistic safety assessment (PSA) cutsets are also presented. This method fills the gap of a HFE dependency analysis method in the case of MU PSA.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Reliability Engineering \& System Safety},
	author = {Arigi, Awwal Mohammed and Park, Gayoung and Kim, Jonghyun},
	month = nov,
	year = {2020},
	keywords = {Dependency analysis, Human error dependency, Human factors, Human reliability analysis, Multi-unit HRA, Multi-unit PSA, Organizational factors},
	pages = {107112},
}

@article{calabrese_linear_2019,
	title = {The linear {No}-{Threshold} ({LNT}) dose response model: {A} comprehensive assessment of its historical and scientific foundations},
	volume = {301},
	issn = {00092797},
	shorttitle = {The linear {No}-{Threshold} ({LNT}) dose response model},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0009279718311177},
	doi = {10.1016/j.cbi.2018.11.020},
	abstract = {The linear no-threshold (LNT) single-hit (SH) dose response model for cancer risk assessment is comprehensively assessed with respect to its historical foundations. This paper also examines how mistakes, ideological biases, and scientific misconduct by key scientists affected the acceptance, validity, and applications of the LNT model for cancer risk assessment. In addition, the analysis demonstrates that the LNT single-hit model was inappropriately adopted for governmental risk assessment, regulatory policy, practices, and for risk communication.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Chemico-Biological Interactions},
	author = {Calabrese, Edward J.},
	month = mar,
	year = {2019},
	pages = {6--25},
}

@article{calabrese_muller-neel_2020,
	title = {The {Muller}-{Neel} dispute and the fate of cancer risk assessment},
	volume = {190},
	issn = {00139351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0013935120308562},
	doi = {10.1016/j.envres.2020.109961},
	abstract = {The National Academy of Sciences (NAS) Atomic Bomb Casualty Commission (ABCC) human genetic study (i.e., The Neel and Schull, 1956a report) showed an absence of genetic damage in offspring of atomic bomb survivors in support of a threshold model, but was not considered for evaluation by the NAS Biological Effects of Atomic Radiation (BEAR) I Genetics Panel. The study therefore could not impact the Panel’s decision to recommend the linear non-threshold (LNT) dose-response model for risk assessment. Summaries and transcripts of the Panel meetings failed to reveal an evaluation of this study, despite its human relevance and ready availability, relying instead on data from Drosophila and mice. This paper explores correspondence among and between BEAR Ge­ netics Panel members, including James N´eel, the study director, and other contemporaries to assess why the Panel failed to use these data and how the decision to recommend the LNT model affected future cancer risk assessment policies and practices. This failure of the Genetics Panel was due to: (1) a strongly unified belief in the LNT model among panel members and their refusal to acknowledge that a low dose of radiation could exhibit a threshold, a conclusion that the N´eel/Schull atomicbomb study could support, and (2) an excessive degree of selfinterest among panel members who experimented with animal models, such as Hermann J. Muller, and feared that human genetic studies would expose the limitations of extrapolating from animal (especially Drosophila) to human responses and would strongly shift research investments/academic grants from animal to human studies. Thus, the failure to consider the N´eel/Schull atomic bomb study served both the purposes of preserving the LNT policy goal and ensuring the continued dominance of Muller and his similarly research-oriented colleagues.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Environmental Research},
	author = {Calabrese, Edward J.},
	month = nov,
	year = {2020},
	pages = {109961},
}

@article{calabrese_origins_2015,
	title = {On the origins of the linear no-threshold ({LNT}) dogma by means of untruths, artful dodges and blind faith},
	volume = {142},
	issn = {00139351},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0013935115300311},
	doi = {10.1016/j.envres.2015.07.011},
	abstract = {This paper is an historical assessment of how prominent radiation geneticists in the United States during the 1940s and 1950s successfully worked to build acceptance for the linear no-threshold (LNT) dose–response model in risk assessment, signiﬁcantly impacting environmental, occupational and medical exposure standards and practices to the present time. Detailed documentation indicates that actions taken in support of this policy revolution were ideologically driven and deliberately and deceptively misleading; that scientiﬁc records were artfully misrepresented; and that people and organizations in positions of public trust failed to perform the duties expected of them. Key activities are described and the roles of speciﬁc individuals are documented. These actions culminated in a 1956 report by a Genetics Panel of the U.S. National Academy of Sciences (NAS) on Biological Effects of Atomic Radiation (BEAR). In this report the Genetics Panel recommended that a linear dose response model be adopted for the purpose of risk assessment, a recommendation that was rapidly and widely promulgated. The paper argues that current international cancer risk assessment policies are based on fraudulent actions of the U. S. NAS BEAR I Committee, Genetics Panel and on the uncritical, unquestioning and blind-faith acceptance by regulatory agencies and the scientiﬁc community.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Environmental Research},
	author = {Calabrese, Edward J.},
	month = oct,
	year = {2015},
	pages = {432--442},
}

@article{scott_its_2008,
	title = {It's {Time} for a {New} {Low}-{Dose}-{Radiation} {Risk} {Assessment} {Paradigm}—{One} that {Acknowledges} {Hormesis}},
	volume = {6},
	issn = {1559-3258, 1559-3258},
	url = {http://journals.sagepub.com/doi/10.2203/dose-response.07-005.Scott},
	doi = {10.2203/dose-response.07-005.Scott},
	abstract = {The current system of radiation protection for humans is based on the linear-no-threshold (LNT) risk-assessment paradigm. Perceived harm to irradiated nuclear workers and the public is mainly reflected through calculated hypothetical increased cancers. The LNT-based system of protection employs easy-to-implement measures of radiation exposure. Such measures include the equivalent dose (a biological-damage-potential-weighted measure) and the effective dose (equivalent dose multiplied by a tissue-specific relative sensitivity factor for stochastic effects). These weighted doses have special units such as the sievert (Sv) and millisievert (mSv, one thousandth of a sievert). Radiation-induced harm is controlled via enforcing exposure limits expressed as effective dose. Expected cancer cases can be easily computed based on the summed effective dose (person-sievert) for an irradiated group or population. Yet the current system of radiation protection needs revision because radiation-induced natural protection (hormesis) has been neglected. A novel, nonlinear, hormetic relative risk model for radiation-induced cancers is discussed in the context of establishing new radiation exposure limits for nuclear workers and the public.},
	language = {en},
	number = {4},
	urldate = {2021-09-11},
	journal = {Dose-Response},
	author = {Scott, Bobby R.},
	month = oct,
	year = {2008},
	pages = {dose--response.0},
}

@article{calabrese_ethical_2021,
	title = {Ethical failings: {The} problematic history of cancer risk assessment},
	volume = {193},
	issn = {00139351},
	shorttitle = {Ethical failings},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0013935120314791},
	doi = {10.1016/j.envres.2020.110582},
	abstract = {This paper demonstrates that unethical conduct by the US National Academy of Sciences (NAS) Biological Effects of Atomic Radiation (BEAR) I Genetics Panel led to their recommendation of the Linear Non-Threshold (LNT) Model for radiation risk assessment and its subsequent adoption by the US and the world community. The analysis, which is based largely on preserved communications of the US NAS Genetics Panel members, reveals that Panel members and their administrative leadership at the NAS displayed an integrated series of unethical actions designed to ensure, (1) the acceptance of the LNT and (2) funding to radiation geneticist panel members and professional colleagues. These findings are significant because major public policies in open democracies, such as cancer risk assessment and other issues impacted by public fears of radiation or chemical exposures, require ethical foundations. Recognition of these ethical failures of the BEAR I Genetics Panel should require a high level administrative, legislative and scientific reassessment of the scientific foundations of cancer risk assessment, with the likely result necessitating revision of current policies and practices. The BEAR I Genetics Panel, 1956 Science journal publication should immediately be retracted because it contains deliberate mis­ representations of the scientific record that were designed to manipulate scientific and public opinion on radi­ ation risk assessment in a dishonest manner.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Environmental Research},
	author = {Calabrese, Edward J.},
	month = feb,
	year = {2021},
	pages = {110582},
}

@article{harbron_cancer_2012,
	title = {Cancer risks from low dose exposure to ionising radiation – {Is} the linear no-threshold model still relevant?},
	volume = {18},
	issn = {10788174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1078817411000691},
	doi = {10.1016/j.radi.2011.07.003},
	abstract = {A review of current knowledge of the biological consequences of diagnostic radiography is well overdue. Despite the monumental investment of time and effort by epidemiologists and biologists over the last 60 years, the ability of low doses of ionising radiation to cause cancer has not been proven. While there is little doubt that serious stochastic and deterministic consequences exist for moderate to large doses, the appropriateness of extrapolating cancer risks to low doses using the linear no-threshold (LNT) model is debatable. Current epidemiological evidence only has sufﬁcient statistical power to detect excess malignancies above around 100 millisieverts (mSv). The lack of detectable excesses below this level could be due to either insufﬁcient statistical power, or genuine lack of carcinogenic potential. The matter has been further complicated by the discovery of various cellular processes including bystander effects, hypersensitivity and adaptive responses, none of which are well understood. A substantial weight of evidence is required to produce a paradigm shift in radiation protection. At present there is insufﬁcient evidence to allow complete rejection of the LNT model, although it must now be acknowledged that the concept has serious limitations.},
	language = {en},
	number = {1},
	urldate = {2021-09-11},
	journal = {Radiography},
	author = {Harbron, Richard William},
	month = feb,
	year = {2012},
	pages = {28--33},
}

@article{cheikh_el_wely_analysis_2021,
	title = {Analysis of physical protection system effectiveness of nuclear power plants based on performance approach},
	volume = {152},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454920306769},
	doi = {10.1016/j.anucene.2020.107980},
	abstract = {The physical protection system is a set of essential components for the protection of nuclear power plants against all types of threats. There are two methods for analyzing the protection systems effectiveness such as the performance method and the compliance method. In this study, the performance method is used to analyze and evaluate the physical protection system based on the Estimate of Adversary Sequence Interruption (EASI) model. The performance approach makes it possible to evaluate the functioning of the physical protection system elements to verify the overall of the protection system effectiveness. The performance method is easy to apply and gives effective results. The physical protection system effectiveness depends on the nature of the threat, either internal or external.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Annals of Nuclear Energy},
	author = {Cheikh El Wely, I. and Chetaine, A.},
	month = mar,
	year = {2021},
	pages = {107980},
}

@article{woo_analytic_2013,
	title = {Analytic study for physical protection system ({PPS}) in nuclear power plants ({NPPs})},
	volume = {265},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549313005323},
	doi = {10.1016/j.nucengdes.2013.09.025},
	language = {en},
	urldate = {2021-09-11},
	journal = {Nuclear Engineering and Design},
	author = {Woo, Tae Ho},
	month = dec,
	year = {2013},
	pages = {932--937},
}

@article{woo_systems_2013,
	title = {Systems {Thinking} {Safety} {Analysis}: {Nuclear} {Security} {Assessment} of {Physical} {Protection} {System} in {Nuclear} {Power} {Plants}},
	volume = {2013},
	issn = {1687-6075, 1687-6083},
	shorttitle = {Systems {Thinking} {Safety} {Analysis}},
	url = {http://www.hindawi.com/journals/stni/2013/473687/},
	doi = {10.1155/2013/473687},
	abstract = {The dynamical assessment has been performed in the aspect of the nuclear power plants (NPPs) security. The physical protection system (PPS) is constructed by the cyber security evaluation tool (CSET) for the nuclear security assessment. The systems thinking algorithm is used for the quantifications by the Vensim software package. There is a period of 60 years which is the life time of NPPs' operation. The maximum possibility happens as 3.59 in the 30th year. The minimum value is done as 1.26 in the 55th year. The difference is about 2.85 times. The results of the case with time delay have shown that the maximum possibility of terror or sabotage incident happens as 447.42 in the 58th year and the minimum value happens as 89.77 in the 51st year. The difference is about 4.98 times. Hence, if the sabotage happens, the worst case is that the intruder can attack the target of the nuclear material in about one and a half hours. The general NPPs are modeled in the study and controlled by the systematic procedures.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Science and Technology of Nuclear Installations},
	author = {Woo, Tae Ho},
	year = {2013},
	pages = {1--5},
}

@article{wadoud_physical_2018,
	title = {Physical protection evaluation process for nuclear facility via sabotage scenarios},
	volume = {57},
	issn = {11100168},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016817300625},
	doi = {10.1016/j.aej.2017.01.045},
	abstract = {The function of Physical Protection System (PPS) should meet three basic elements (detection, delay, and response) and it is required to protect the nuclear facility against possibility of bombing, sabotage, and theft. The system must be fast in performance to achieve sufﬁcient time for the arrival of response forces and complete the defense about the property in time, thwarting the adversary and neutralizing the implementation of its mission. The performance of the physical protection system should be designed to oppose and limit the capabilities and tactics of the attacker toward the nuclear facility. And in this ways it works as a barrier to obstruct the attacker against penetration. In this work an evaluation of the physical protection system effectiveness for a hypothetical facility against sabotage is presented. Proposed sabotage scenarios will be used as an input for this evaluation. The evaluation process was carried out using the single path computer model (EASI), for the determination of the probability of interruption (PI) as a ﬁrst metric factor of the PPS effectiveness. The Probability of Neutralization (PN) is computed by the neutralization analysis module as a second metric factor of the PPS effectiveness. The probability of detection and delay time values of detection, delay, communication and response forces action was measured along a speciﬁc sabotage path of the adversary. If the evaluation reveals any vulnerability, the initial system design must be redesigned to correct the vulnerabilities and another analysis of the redesigned system is performed.},
	language = {en},
	number = {2},
	urldate = {2021-09-08},
	journal = {Alexandria Engineering Journal},
	author = {Wadoud, A.A. and Adail, A.S. and Saleh, A.A.},
	month = jun,
	year = {2018},
	pages = {831--839},
}

@article{landucci_assessment_2017,
	title = {Assessment of attack likelihood to support security risk assessment studies for chemical facilities},
	volume = {110},
	issn = {09575820},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957582017302100},
	doi = {10.1016/j.psep.2017.06.019},
	language = {en},
	urldate = {2021-09-08},
	journal = {Process Safety and Environmental Protection},
	author = {Landucci, Gabriele and Argenti, Francesca and Cozzani, Valerio and Reniers, Genserik},
	month = aug,
	year = {2017},
	pages = {102--114},
}

@article{zou_insider_2018,
	title = {Insider threats of {Physical} {Protection} {Systems} in nuclear power plants: {Prevention} and evaluation},
	volume = {104},
	issn = {01491970},
	shorttitle = {Insider threats of {Physical} {Protection} {Systems} in nuclear power plants},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197017302020},
	doi = {10.1016/j.pnucene.2017.08.006},
	abstract = {Physical Protection Systems (PPS) are used to protect critical facilities and prevent against adversarial intrusion. The insider threats of PPS must be considered when analyzing the effectiveness of PPS. On the basis of the normal approach termed “Estimate of Adversary Sequence Interruption, EASI”, a novel method named “Estimate and Prevention of the Insider Threats, EPIT” was proposed for the speciﬁc estimation of insider behaviors. According to failure mode and effects analysis (FMEA) method, the EPIT method adequately considers the common failure causes of protective devices to analyze the insider threat to the effectiveness of PPS. By the EPIT method results, a reasonable management and rights allocation of staffs can be ﬁgured out to mitigate insider threats.},
	language = {en},
	urldate = {2021-09-08},
	journal = {Progress in Nuclear Energy},
	author = {Zou, Bowen and Yang, Ming and Guo, Jia and Wang, Junbo and Benjamin, Emi-Reynolds and Liu, Hang and Li, Wei},
	month = apr,
	year = {2018},
	pages = {8--15},
}

@article{turati_adaptive_2018,
	title = {Adaptive simulation for failure identification in the {Advanced} {Lead} {Fast} {Reactor} {European} {Demonstrator}},
	volume = {103},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197017302925},
	doi = {10.1016/j.pnucene.2017.11.013},
	abstract = {The identiﬁcation undesired or abnormal states of a nuclear power plant is of primary importance for deﬁning accident prevention and mitigation actions. To this aim, computational models and simulators are frequently employed, as they allow to study the system response to diﬀerent operational conditions. For complex systems like the nuclear power plants, this is in general challenging because the simulation tools are i) high-dimensional; ii) black-box; iii) dynamic and iv) computationally demanding.},
	language = {en},
	urldate = {2021-09-08},
	journal = {Progress in Nuclear Energy},
	author = {Turati, Pietro and Cammi, Antonio and Lorenzi, Stefano and Pedroni, Nicola and Zio, Enrico},
	month = mar,
	year = {2018},
	pages = {176--190},
}

@article{el-genk_dynamic_2010,
	title = {Dynamic {Simulation} of a {Space} {Reactor} {System} with {Closed} {Brayton} {Cycle} {Loops}},
	volume = {26},
	issn = {0748-4658, 1533-3876},
	url = {https://arc.aiaa.org/doi/10.2514/1.46262},
	doi = {10.2514/1.46262},
	language = {en},
	number = {3},
	urldate = {2021-09-07},
	journal = {Journal of Propulsion and Power},
	author = {El-Genk, Mohamed S. and Tournier, Jean-Michael P. and Gallo, Bruno M.},
	month = may,
	year = {2010},
	pages = {394--406},
}

@article{denning_impact_2017,
	title = {Impact of {PRA} and severe accident research in reducing reactor risk},
	author = {Denning, R.S. and Budnitz, R.J.},
	month = may,
	year = {2017},
	pages = {13},
}

@article{groth_building_2020,
	title = {Building and using dynamic risk-informed diagnosis procedures for complex system accidents},
	volume = {234},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X18803836},
	doi = {10.1177/1748006X18803836},
	abstract = {Accidents pose unique challenges for operating crews in complex systems such as nuclear power plants, presenting limitations in plant status information and lack of detailed monitoring, diagnosis, and response planning support. Advances in severe accident simulation and dynamic probabilistic risk assessment provide an opportunity to garner detailed insight into accident scenarios. In this article, we demonstrate how to build and use a framework which leverages dynamic probabilistic risk assessment, simulation, and dynamic Bayesian networks to provide real-time monitoring and diagnostic support for severe accidents in a nuclear power plant. We use general purpose modeling technology, the dynamic Bayesian network, and adapt it for risk management of complex engineering systems. This article presents a prototype model for monitoring and diagnosing system states associated with loss of flow and transient overpower accidents in a generic sodium fast reactor. We discuss using this framework to create a risk-informed accident management framework called Safely Managing Accidental Reactor Transients procedures. This represents a new application of risk assessment, expanding probabilistic risk assessment techniques beyond static decision support into dynamic, real-time models which support accident diagnosis and management.},
	language = {en},
	number = {1},
	urldate = {2021-09-07},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Groth, Katrina M and Denman, Matthew R and Darling, Michael C and Jones, Thomas B and Luger, George F},
	month = feb,
	year = {2020},
	pages = {193--207},
}

@book{takeda_high-temperature_2021,
	series = {{JSME} {Series}},
	title = {High-{Temperature} {Gas} {Reactors}},
	volume = {5},
	isbn = {978-0-12-821031-4},
	author = {Takeda, Tetsuaki and Inagaki, Yoshiyuki},
	year = {2021},
}

@book{kugeler_modular_2019,
	edition = {1},
	title = {Modular {High}-temperature {Gas}-cooled {Reactor} {Power} {Plant}},
	isbn = {978-3-662-57710-3},
	publisher = {Springer-Verlag Berlin Heidelberg},
	author = {Kugeler, Kurt and Zhang, Zuoyi},
	year = {2019},
}

@inproceedings{metzroth_dynamic_2010,
	address = {Red Hook, NY},
	title = {Dynamic {Event} {Tree} {Analysis} as a {Risk} {Management} {Tool}},
	isbn = {978-1-61738-643-5},
	shorttitle = {International {Congress} on {Advances} in {Nuclear} {Power} {Plants} 2010 ({ICAPP} 2010)},
	language = {eng},
	publisher = {Curran},
	author = {Metzroth, Kyle and Aldemir, Tunc},
	year = {2010},
}

@article{smith_bayesian_1993,
	title = {Bayesian {Computation} {Via} the {Gibbs} {Sampler} and {Related} {Markov} {Chain} {Monte} {Carlo} {Methods}},
	volume = {55},
	issn = {00359246},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1993.tb01466.x},
	doi = {10.1111/j.2517-6161.1993.tb01466.x},
	abstract = {The use of the Gibbs sampler for Bayesian computation is reviewed and illustrated in the context of some canonical examples. Other Markov chain Monte Carlo simulation methods are also briefly described, and comments are made on the advantages of sample-based approaches for Bayesian inference summaries.},
	language = {en},
	number = {1},
	urldate = {2021-09-06},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Smith, A. F. M. and Roberts, G. O.},
	month = sep,
	year = {1993},
	pages = {3--23},
}

@article{lewis_dynamic_2020,
	title = {A {Dynamic} {Bayesian} {Network} {Structure} for {Joint} {Diagnostics} and {Prognostics} of {Complex} {Engineering} {Systems}},
	volume = {13},
	issn = {1999-4893},
	url = {https://www.mdpi.com/1999-4893/13/3/64},
	doi = {10.3390/a13030064},
	abstract = {Dynamic Bayesian networks (DBNs) represent complex time-dependent causal relationships through the use of conditional probabilities and directed acyclic graph models. DBNs enable the forward and backward inference of system states, diagnosing current system health, and forecasting future system prognosis within the same modeling framework. As a result, there has been growing interest in using DBNs for reliability engineering problems and applications in risk assessment. However, there are open questions about how they can be used to support diagnostics and prognostic health monitoring of a complex engineering system (CES), e.g., power plants, processing facilities and maritime vessels. These systems’ tightly integrated human, hardware, and software components and dynamic operational environments have previously been difﬁcult to model. As part of the growing literature advancing the understanding of how DBNs can be used to improve the risk assessments and health monitoring of CESs, this paper shows the prognostic and diagnostic inference capabilities that are possible to encapsulate within a single DBN model. Using simulated accident sequence data from a model sodium fast nuclear reactor as a case study, a DBN is designed, quantiﬁed, and veriﬁed based on evidence associated with a transient overpower. The results indicate that a joint prognostic and diagnostic model that is responsive to new system evidence can be generated from operating data to represent CES health. Such a model can therefore serve as another training tool for CES operators to better prepare for accident scenarios.},
	language = {en},
	number = {3},
	urldate = {2021-09-06},
	journal = {Algorithms},
	author = {Lewis, Austin D. and Groth, Katrina M.},
	month = mar,
	year = {2020},
	pages = {64},
}

@article{tripathi_dynamic_2020,
	title = {Dynamic reliability framework for a {Nuclear} {Power} {Plant} using dynamic flowgraph methodology},
	volume = {143},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454920301651},
	doi = {10.1016/j.anucene.2020.107467},
	abstract = {Passive safety systems are being considered in advanced reactor designs to provide inherent stability for the operation of the nuclear reactor. Passive shutdown is provided for guaranteed removal of decay heat under emergency conditions. The reliability of such systems should be very high. The static reliability assessment of such systems has been considered using various techniques such as fault tree analysis, failure mode effect analysis, and reliability block diagrams. Dynamic reliability methods are powerful mathematical frameworks capable of handling interactions among components and process variables explicitly. In principle, they constitute a more realistic modelling of systems for the purposes of reliability, risk and safety analysis. Although there is a growing recognition in the risk community of the potentially greater correctness of these methods, no serious effort has been undertaken to utilize them in industrial applications. The dynamic ﬂowgraph methodology is an integrated methodological approach to modelling and analyzing the behavior of software-driven embedded systems for the purpose of reliability/safety assessment and veriﬁcation. In the present work, dynamic ﬂowgraph methodology has been used to analyze the Station Blackout Scenario for a Nuclear Power Plant. The beneﬁts of the proposed method are brought out with respect to the traditional methods like fault tree analysis, which deteriorates in applicability with increasing system size and complexity and fails to accommodate the dynamics of the system. The proposed method has been validated on the passive residual heat removal system of pressurized heavy water reactor.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Annals of Nuclear Energy},
	author = {Tripathi, Manish and Singh, Lalit Kumar and Singh, Suneet},
	month = aug,
	year = {2020},
	pages = {107467},
}

@article{chen_research_2020,
	title = {Research on living {PSA} method based on time-dependent {MFT} for real-time online risk monitoring},
	volume = {143},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454920301043},
	doi = {10.1016/j.anucene.2020.107406},
	abstract = {This paper presents a living PSA modeling and updating method based on a time-dependent modular fault tree (MFT), which takes into account all the failure modes involved in the whole life cycle of a component for continuous state transition and time-dependent problem analysis. And a Stage 4-Living PSA, characterized by real-time online automatic updating model, is achieved using a combination of the time-dependent MFT method and the state monitoring technology. This method has a remarkable effect in enhancing the updating ability, ﬂexibility of the model and reducing the scale of the model. And using this method cannot only capture the risk ﬂuctuations caused by any conﬁguration change more accurately and timely, but also reﬂect the effect of the component cumulative running time on the realtime risk of the plant, and provide more valuable data for making operation and maintenance decision. Moreover, A real-time online risk monitoring (RORM) system with a hierarchical modular modeling strategy and computational data structure is also developed to automatically update the living PSA model after receiving conﬁguration change information of the plant, and this system displays graphical risk information that helps users to carry out daily operation risk management more effectively at nuclear power plants (NPPs). Finally, the function and interface of this system applied to RORM are demonstrated by using the living PSA model for the Middle Break Loss of Coolant Accident (MLOCA) in the Fuqing NPP. The achievement of RORM can reduce the burden on the plant personnel, and avoided the fact that the lagged and unreasonable risk information that misleads plant personnel into making decisions, resulting in greater risk or economic loss.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Annals of Nuclear Energy},
	author = {Chen, Sijuan and Zhang, Zhijian and Zhang, Huazhi and Zhang, Min and Wang, He and Ma, Yingfei and Xu, Anqi and Wang, Yan and Zheng, Gangyang},
	month = aug,
	year = {2020},
	pages = {107406},
}

@article{kim_deterministic_2010,
	title = {Deterministic and risk-informed approaches for safety analysis of advanced reactors: {Part} {II}, {Risk}-informed approaches},
	volume = {95},
	issn = {09518320},
	shorttitle = {Deterministic and risk-informed approaches for safety analysis of advanced reactors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010000153},
	doi = {10.1016/j.ress.2009.12.004},
	abstract = {Technical insights and ﬁndings from a critical review of deterministic approaches typically applied to ensure design safety of nuclear power plants were presented in the companion paper of Part I included in this issue. In this paper we discuss the risk-informed approaches that have been proposed to make a safety case for advanced reactors including Generation-IV reactors such as Modular High-Temperature Gas-cooled Reactor (MHTGR), Pebble Bed Modular Reactor (PBMR), or Sodium-cooled Fast Reactor (SFR). Also considered herein are a risk-informed safety analysis approach suggested by Westinghouse as a means to improve the conventional accident analysis, together with the Technology Neutral Framework recently developed by the US Nuclear Regulatory Commission as a high-level regulatory infrastructure for safety evaluation of any type of reactor design. The insights from a comparative review of various deterministic and risk-informed approaches could be usefully used in developing a new licensing architecture for enhanced safety of evolutionary or advanced plants.},
	language = {en},
	number = {5},
	urldate = {2021-09-06},
	journal = {Reliability Engineering \& System Safety},
	author = {Kim, Inn Seock and Ahn, Sang Kyu and Oh, Kyu Myung},
	month = may,
	year = {2010},
	pages = {459--468},
}

@article{kyu_ahn_deterministic_2010,
	title = {Deterministic and risk-informed approaches for safety analysis of advanced reactors: {Part} {I}, deterministic approaches},
	volume = {95},
	issn = {09518320},
	shorttitle = {Deterministic and risk-informed approaches for safety analysis of advanced reactors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010000165},
	doi = {10.1016/j.ress.2009.12.005},
	abstract = {The objective of this paper and a companion paper in this issue (part II, risk-informed approaches) is to derive technical insights from a critical review of deterministic and risk-informed safety analysis approaches that have been applied to develop licensing requirements for water-cooled reactors, or proposed for safety veriﬁcation of the advanced reactor design. To this end, a review was made of a number of safety analysis approaches including those speciﬁed in regulatory guides and industry standards, as well as novel methodologies proposed for licensing of advanced reactors. This paper and the companion paper present the review insights on the deterministic and risk-informed safety analysis approaches, respectively. These insights could be used in making a safety case or developing a new licensing review infrastructure for advanced reactors including Generation IV reactors.},
	language = {en},
	number = {5},
	urldate = {2021-09-06},
	journal = {Reliability Engineering \& System Safety},
	author = {Kyu Ahn, Sang and Kim, Inn Seock and Myung Oh, Kyu},
	month = may,
	year = {2010},
	pages = {451--458},
}

@article{weber_severe_2020,
	title = {Severe {Accident} {Phenomena}: {A} {Comparison} {Among} the {NuScale} {SMR}, {Other} {Advanced} {LWR} {Designs}, and {Operating} {LWRs}},
	volume = {206},
	issn = {0029-5450, 1943-7471},
	shorttitle = {Severe {Accident} {Phenomena}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2020.1756160},
	doi = {10.1080/00295450.2020.1756160},
	abstract = {During a severe accident in a nuclear reactor, there are a number of phenomenological events that can present a challenge to containment integrity. These include the generation and combustion of hydrogen, energetic fuel-coolant interactions, thermal attack of fission product barriers, core-concrete interactions, direct containment heating, and gradual overpressurization. The advanced design of the NuScale small modular reactor (SMR) has resulted in the reduced likelihood and severity of severe accident challenges to containment. This paper discusses the features of the NuScale design that reduce the likelihood of occurrence of these severe accident phenomena and also discusses the ability of containment to survive in the unlikely event that they do occur. The impact of severe accident phenomena for the NuScale design is compared and contrasted against other advanced light water reactors (ALWRs), such as the AP1000 reactor and the Economic Simplified Boiling Water Reactor (ESBWR), as well as the existing fleet, using information from publicly available documents.},
	language = {en},
	number = {9},
	urldate = {2021-09-06},
	journal = {Nuclear Technology},
	author = {Weber, Scott J. and Mullin, Etienne M.},
	month = sep,
	year = {2020},
	pages = {1351--1360},
}

@article{bodda_risk_2020,
	title = {Risk informed validation framework for external flooding scenario},
	volume = {356},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002954931930408X},
	doi = {10.1016/j.nucengdes.2019.110377},
	abstract = {Safety of nuclear plants against external ﬂooding has gained signiﬁcant attention following the accident at Fukushima Daiichi nuclear power station. In United States, Oyster Creek nuclear plant was safely shutdown when high storm surge during hurricane Sandy caused a potential ﬂooding threat. Subsequently, the nuclear energy industry experienced a signiﬁcant activity in Probabilistic Risk Assessment (PRA) for external ﬂooding. Increasingly, methods of computational ﬂuid dynamics including advanced simulation codes are being considered to evaluate the sequence of events during diﬀerent scenarios of ﬂooding at a plant. One of the key limitations in the use of advanced codes for external ﬂooding is related to a lack of credibility of such simulations. The motivation of this study is to develop a formal validation approach that provides a basis to quantify credibility of risk assessments that are based on advanced simulation codes. In this study, we illustrate the application of existing performance based risk-informed validation framework to an external ﬂooding event. However, it is determined that a direct application of this approach to ﬂooding is restricted due to a lack of relevant data to evaluate experimental fragilities for ﬂooding failures. Therefore, we take a simple synthetic example to evaluate the applicability of the proposed framework to validation of ﬂooding PRA scenario and update the proposed framework as needed.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Bodda, Saran Srikanth and Gupta, Abhinav and Dinh, Nam},
	month = jan,
	year = {2020},
	pages = {110377},
}

@article{wang_reliability_2019,
	title = {Reliability assessment of passive residual heat removal system of {IPWR} using {Kriging} regression model},
	volume = {127},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454918307047},
	doi = {10.1016/j.anucene.2018.12.040},
	abstract = {Passive safety systems have been incorporated into new design nuclear power plants to enhance the power plants’ inherent safety. However, due to the lack of the experimental data and operational experience, evaluating the reliability of passive systems is a challenging task. Many uncertainties are involved in the thermal hydraulic process during startup and operation. This may make the system unable to accomplish its expected function even though the hardware is available, known as functional failure. The evaluation of system functional failure probabilities based on the direct Monte Carlo method may be computationally impractical. In order to reduce the computational load, the Kriging regression model was constructed to avoid a large number of thermal hydraulics simulations. Compared with other metamodels, the Kriging regression model obtained better accuracy. The proposed method was applied to evaluate the reliability of a passive residual heat removal system of IPWR200 during a station blackout accident. The Kriging regression model not only ensures the accuracy of the reliability assessment, but also greatly reduces the runs of T-H codes. Furthermore, global sensitivity analysis aimed at determining the contributions of input parameters was carried out. Results indicate that the probability of passive residual heat removal system failing functionally is estimated to be 1.94e-4 and that insufﬁcient decay heat removal is the most likely failure mode. Sensitivity analysis results identiﬁed ﬁve key uncertain parameters, which is signiﬁcant for system performance. The sensitivity information can provide guidance for enhancing passive safety systems design and operation, which is of great importance to the safety and reliability of passive safety systems.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Annals of Nuclear Energy},
	author = {Wang, Chenyang and Peng, Minjun and Xia, Genglei and Cong, Tenglong},
	month = may,
	year = {2019},
	pages = {479--489},
}

@article{ding_approach_2019,
	title = {An approach for radiological consequence assessment under unified temporal and spatial coordinates considering multi-reactor accidents},
	volume = {127},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454918306856},
	doi = {10.1016/j.anucene.2018.12.024},
	abstract = {The current approaches and computer code systems for radiological consequence assessment of nuclear accidents have still gaps in assessing consequences of nuclear accidents involving multiple reactors, since multi-reactor accidents should be treated in one unique temporal and spatial system. This paper presents an approach to unify and generalize temporal and spatial coordinates for the consequence assessment of multi-reactor accidents. A code system named Advanced Radiological Consequence Assessment Toolkit (ARCAT) was developed accordingly. ARCAT is intended to support in particular emergency preparedness studies at the nuclear power plant level.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Annals of Nuclear Energy},
	author = {Ding, Hongchun and Tong, Jiejuan and Raskob, Wolfgang and Zhang, Liguo},
	month = may,
	year = {2019},
	pages = {450--458},
}

@article{wang_application_2018,
	title = {Application of {NUREG}/{CR}-6850 to the fire risk quantification of a {High} {Temperature} {Gas}-{Cooled} {Reactor}},
	volume = {330},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549318300712},
	doi = {10.1016/j.nucengdes.2018.02.001},
	abstract = {NUREG/CR-6850 provides a universal process to conduct ﬁre Probabilistic Risk Analyses (PRAs) of Nuclear Power Plants (NPPs). A three-step procedure among the report’s ﬁndings is proposed for quantifying ﬁre-induced risks of potentially risk-signiﬁcant ﬁre scenarios: i) Estimation of the compartment ﬁre ignition frequencies associated with the ﬁre ignition sources; ii) Estimation of the frequency of occurrence of the compartment ﬁre scenario; and iii) Quantiﬁcation of the ﬁre PRA model induced by the ﬁre scenario, to generate the ﬁre risk results. The procedure supported by operational records of traditional Light-Water Reactors (LWRs) also can be applied to the new-type reactors, provided that the challenges of the new imbedded features and equipment can be legitimately tackled. In this study, three key issues manifested in the applications of the three-step ﬁre risk quantiﬁcation procedure to new-type reactors are discussed, namely, ignition frequency estimating approaches of the new-reactor-speciﬁc ﬁre compartments in i), applicability analysis of the ﬁre modeling tools and uncertainty treatment in ii), and updating ﬁre PRA models in iii). The feasibility of the analysis is illustrated to a switchgear room ﬁre scenario of the ﬁrst demonstration NPP of High Temperature Gas-Cooled Reactor (HTRPM) in China.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Wang, Wei and Tong, Jiejuan and Zhao, Jun},
	month = apr,
	year = {2018},
	pages = {332--343},
}

@article{zhao_rapid_2021,
	title = {Rapid source term prediction in nuclear power plant accidents based on dynamic {Bayesian} networks and probabilistic risk assessment},
	volume = {158},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454921000931},
	doi = {10.1016/j.anucene.2021.108217},
	abstract = {Source term prediction plays an essential role in mitigating the consequences of nuclear accidents and therefore is of practical importance. In this research, we propose a method for rapid source term prediction in nuclear accidents. The proposed method ﬁrst performs fault diagnosis based on real-time plant information to diagnose plant status. Then it uses the results in fault diagnosis and pre-deﬁned source terms in probabilistic risk assessment to obtain real-time source term prediction. Fault diagnosis is based on dynamic Bayesian networks, which exhibit advantages in modeling complex systems and probabilistic reasoning with available evidence. The use of pre-deﬁned source terms for various accident scenarios in probabilistic risk assessment enables us to cover a broad range of accident scenarios. This is in contrast to the limited number of basis accident scenarios used in the current practice for source term prediction. The proposed method is demonstrated using a high temperature gas cooled reactor.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Annals of Nuclear Energy},
	author = {Zhao, Yunfei and Tong, Jiejuan and Zhang, Liguo},
	month = aug,
	year = {2021},
	pages = {108217},
}

@article{zubair_advancement_2013,
	title = {Advancement in living probabilistic safety assessment to increase safety of nuclear power plants},
	volume = {227},
	issn = {1748-006X, 1748-0078},
	url = {http://journals.sagepub.com/doi/10.1177/1748006X13485192},
	doi = {10.1177/1748006X13485192},
	abstract = {Among the energy resources, the energy obtained from nuclear power plants is very important for the prosperity of any country. Living probabilistic safety assessment is a growing field that provides a high level of safety for nuclear power plants. Living probabilistic safety assessment consists of different techniques, among them this article presents a method to update reliability data. This method is based on Binomial likelihood function and its conjugate beta distribution for demand failure probability, and Poisson likelihood function and its conjugate gamma distribution for operational failure rate. The method uses generic data for beta and gamma prior distribution, which is updated by using the reliability data update method. Reliability data update is a computer-based program used to update nuclear power plant data according to changing conditions. By updating the living probabilistic safety assessment it is possible to get an online risk monitor system that can be helpful in severe accident conditions, as in Fukushima accident, to make the man–machine system friendly.},
	language = {en},
	number = {5},
	urldate = {2021-09-06},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
	author = {Zubair, Muhammad and Heo, Gyunyoung},
	month = oct,
	year = {2013},
	pages = {534--539},
}

@article{hussein_emerging_2020,
	title = {Emerging small modular nuclear power reactors: {A} critical review},
	volume = {5},
	issn = {26660326},
	shorttitle = {Emerging small modular nuclear power reactors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666032620300259},
	doi = {10.1016/j.physo.2020.100038},
	abstract = {This paper reviews the smallness, modularity and reactor-design aspects of emerging small modular reactors (SMRs). It is shown that small (whether in physical size or power level) reactors are not new, but offer economic and ﬂexibility advantages that allow their use in a variety of applications. The different deﬁnitions of modularity are reviewed, including modularity in design, process intensiﬁcation, manufacturing and construction. It is shown that these forms of modularity when applied to SMRs have some advantages, but also have some challenges that need to be addressed if their full potential is to be realized. Even if these forms of modularity are not fully utilized, the lower power ( 300 MW electrical) of SMRs allows the formation of larger power plants by incremental addition of reactor units, in the so-called scale modularity. The paper reviews the unique features of emerging SMR designs, and compares them to those of the early era of nuclear power. It is shown that while many modern SMR designs incorporate well-proven features that were tested and proven in early reactors. others introduce aspects of Generation IV reactors, in terms of inherent and/or passive safety. Given the promise of SMRs as means to reduce greenhouse gas emissions and their ability to supply reliable and base-load power, the licensing of such reactors by national regulators will provide a boost to their acceptability and adaptability as a player in combating climate change.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Physics Open},
	author = {Hussein, Esam M.A.},
	month = dec,
	year = {2020},
	pages = {100038},
}

@article{wu_nuclear_2021,
	title = {Nuclear non‐proliferation review and improving proliferation resistance assessment in the future},
	volume = {45},
	issn = {0363-907X, 1099-114X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/er.5486},
	doi = {10.1002/er.5486},
	abstract = {An increasing number of countries have taken nuclear energy as a preferred approach in response to the environment deterioration and energy supply deficit. The rapid expansion of nuclear technologies, however, would pose a great challenge to nuclear non-proliferation, especially for the Generation IV nuclear reactor systems, which significantly differ from current nuclear fuel systems. This paper gives an overview of non-proliferation research activities worldwide and outlines the existing problems, especially in non-proliferation assessment. Because of numerous processes and various types of variables involved in nuclear fuel cycles (NFC), it is difficult to obtain a quantitative and objective assessment on non-proliferation. In addition, the influences imposed by national nuclear policy on non-proliferation have been rarely studied because of their large uncertainties, which may not precisely reflect the real non-proliferation status in a specific country. In view of the above issues, we put forward an assessment framework by considering impact factors of national nuclear policy and by employing multi-mathematical models to address some of the issues including subjectivity and uncertainties in the current assessment methodologies.},
	language = {en},
	number = {8},
	urldate = {2021-09-06},
	journal = {International Journal of Energy Research},
	author = {Wu, Jianhui and Ma, Yuwen and Yu, Chenggang and Zou, Chunyan and Cai, Xiangzhou and Chen, Jingen},
	month = jun,
	year = {2021},
	pages = {11399--11422},
}

@article{zaghi_establishing_2016,
	title = {Establishing {Common} {Nomenclature}, {Characterizing} the {Problem}, and {Identifying} {Future} {Opportunities} in {Multihazard} {Design}},
	volume = {142},
	issn = {0733-9445, 1943-541X},
	url = {http://ascelibrary.org/doi/10.1061/%28ASCE%29ST.1943-541X.0001586},
	doi = {10.1061/(ASCE)ST.1943-541X.0001586},
	language = {en},
	number = {12},
	urldate = {2021-09-06},
	journal = {Journal of Structural Engineering},
	author = {Zaghi, Arash E. and Padgett, Jamie E. and Bruneau, Michel and Barbato, Michele and Li, Yue and Mitrani-Reiser, Judith and McBride, Amanda},
	month = dec,
	year = {2016},
}

@article{john_garrick_principles_1970,
	title = {Principles of unified systems safety analysis},
	volume = {13},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549370901652},
	doi = {10.1016/0029-5493(70)90165-2},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {John Garrick, B.},
	month = aug,
	year = {1970},
	pages = {245--321},
}

@article{kaplan_use_1979,
	title = {On the {Use} of a {Bayesian} {Reasoning} in {Safety} and {Reliability} {Decisions}—{Three} {Examples}},
	volume = {44},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT79-A32258},
	doi = {10.13182/NT79-A32258},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Nuclear Technology},
	author = {Kaplan, Stan and Garrick, B. John},
	month = jul,
	year = {1979},
	pages = {231--245},
}

@article{apostolakis_data_1980,
	title = {Data specialization for plant specific risk studies},
	volume = {56},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549380901338},
	doi = {10.1016/0029-5493(80)90133-8},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Apostolakis, G. and Kaplan, S. and Garrick, B.J. and Duphily, R.J.},
	month = feb,
	year = {1980},
	pages = {321--329},
}

@article{garrick_lessons_1989,
	title = {Lessons {Learned} from 21 {Nuclear} {Plant} {Probabilistic} {Risk} {Assessments}},
	volume = {84},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT89-A34216},
	doi = {10.13182/NT89-A34216},
	language = {en},
	number = {3},
	urldate = {2021-09-06},
	journal = {Nuclear Technology},
	author = {Garrick, B. John},
	month = mar,
	year = {1989},
	pages = {319--330},
}

@article{garrick_quantitative_2009,
	title = {Quantitative {Risk} {Assessment} of the {State}-{Licensed}  {Radioactive} {Waste} {Disposal} {Area}},
	language = {en},
	journal = {New York},
	author = {Garrick, B John and Stetkar, John W and Dykes, Andrew A and Potter, Thomas E and Wampler, Stephen L},
	year = {2009},
	pages = {699},
}

@article{kennedy_probabilistic_1980,
	title = {Probabilistic seismic safety study of an existing nuclear power plant},
	volume = {59},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549380902034},
	doi = {10.1016/0029-5493(80)90203-4},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Kennedy, R.P. and Cornell, C.A. and Campbell, R.D. and Kaplan, S. and Perla, H.F.},
	month = aug,
	year = {1980},
	pages = {315--338},
}

@article{kaplan_use_1986,
	title = {On the use of data and judgment in probabilistic risk and safety analysis},
	volume = {93},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549386902116},
	doi = {10.1016/0029-5493(86)90211-6},
	language = {en},
	number = {2-3},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Kaplan, Stan},
	month = may,
	year = {1986},
	pages = {123--134},
}

@inproceedings{prosek_methodology_2017,
	address = {High Tatras Mountains, Tatranské Matliare, Slovak Republic},
	title = {Methodology for selecting initiating events and hazards for consideration in an extended {PSA}},
	isbn = {978-1-138-62937-0 978-1-351-80973-3},
	url = {http://www.crcnetbase.com/doi/10.1201/9781315210469-421},
	doi = {10.1201/9781315210469-421},
	language = {en},
	urldate = {2021-09-06},
	booktitle = {Safety and {Reliability} – {Theory} and {Applications}},
	publisher = {CRC Press},
	author = {Prošek, A and Wielenberg, A and Löffler, H and Raimond, E},
	month = jun,
	year = {2017},
	pages = {490--490},
}

@article{dejesus_segarra_bayesian_2021,
	title = {A {Bayesian} {Network} {Approach} for {Modeling} {Dependent} {Seismic} {Failures} in a {Nuclear} {Power} {Plant} {Probabilistic} {Risk} {Assessment}},
	volume = {213},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832021002167},
	doi = {10.1016/j.ress.2021.107678},
	abstract = {The importance of modeling dependency between seismic failures of multiple components in a nuclear power plant (NPP) probabilistic risk assessment (PRA) has been discussed since the 1980s. In NUREG/CR-7237, Budnitz et al. found the Reed-McCann method to be the most promising method for modeling dependent seismic failures in NPP PRA. However, there are issues with the Reed-McCann method’s quantification of the seismic fragility of a system of multiple components. To address this issue and to facilitate an overall realism increase in modeling dependencies in seismic PRA, this paper proposes a Bayesian network (BN) approach to model dependent seismic failures. To illustrate the proposed approach, we calculate the fragility of a parallel system and a series system using the Reed-McCann method, the BN approach, the First-Order Reliability Method (FORM) and Monte Carlo simulation (MCS). Then, we compare the system fragility results from these four approaches/methods to the lower and upper bounds of the system fragility. We found that the BN approach performed better than the ReedMcCann method with respect to providing results that stay within the lower and upper bounds of the system fragility. Further, the BN approach gives similar results to FORM and MCS. This paper proposes a BN approach because, in combination with our previous work about extending a probabilistic seismic hazard analysis to ac­ count for the spatial variability of ground motion at an NPP hard-rock site, it can be used to simultaneously and realistically account for dependent seismic failures and spatial variability of ground motion in both single-unit and multi-unit seismic PRAs.},
	language = {en},
	urldate = {2021-09-06},
	journal = {Reliability Engineering \& System Safety},
	author = {DeJesus Segarra, Jonathan and Bensi, Michelle and Modarres, Mohammad},
	month = sep,
	year = {2021},
	pages = {107678},
}

@article{dezert_multi-criteria_2010,
	title = {Multi-criteria decision making based on {DSmT}-{AHP}},
	abstract = {In this paper, we present an extension of the multicriteria decision making based on the Analytic Hierarchy Process (AHP) which incorporates uncertain knowledge matrices for generating basic belief assignments (bba’s). The combination of priority vectors corresponding to bba’s related to each (sub)criterion is performed using the Proportional Conﬂict Redistribution rule no. 5 proposed in Dezert-Smarandache Theory (DSmT) of plausible and paradoxical reasoning. The method presented here, called DSmT-AHP, is illustrated on very simple examples.},
	language = {en},
	author = {Dezert, J and Tacnet, J M and Batton-Hubert, Mireille and Smarandache, F},
	year = {2010},
	pages = {9},
}

@article{flage_expressing_2009,
	title = {{EXPRESSING} {AND} {COMMUNICATING} {UNCERTAINTY} {IN} {RELATION} {TO} {QUANTITATIVE} {RISK} {ANALYSIS}},
	volume = {2},
	abstract = {A quantitative risk analysis (QRA) should provide a broad, informative and balanced picture of risk, in order to support decisions. To achieve this, a proper treatment of uncertainty is a prerequisite. Most approaches to treatment of uncertainty in QRA seem to be based on the thinking that uncertainty relates to the calculated probabilities and expected values. This causes difficulties when it comes to communicating what the analysis results mean, and could easily lead to weakened conclusions if large uncertainties are involved. An alternative approach is to hold uncertainty, not probability, as a main component of risk, and regard probabilities purely as epistemic-based expressions of uncertainty. In the paper the latter view is taken, and we describe what should be the main components of a risk description when following this approach. We also indicate how this approach relates to decision-making. An important issue addressed is how to communicate the shortcomings and limitations of probabilities and expected values. Sensitivity analysis plays a key role in this regard. Examples are included to illustrate ideas and findings.},
	language = {en},
	author = {Flage, Roger and Aven, Terje},
	year = {2009},
	pages = {11},
}

@article{ebisawa_evaluation_1994,
	title = {Evaluation of response factors for seismic probabilistic safety assessment of nuclear power plants},
	volume = {147},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549394902062},
	doi = {10.1016/0029-5493(94)90206-2},
	abstract = {This paper presents a method for evaluating "response factors" of components in nuclear power plants for use in a seismic probabilistic safety assessment (PSA).The response factor here is a measure of conservatism included in response calculations in seismic design analysis of components and is defined as a ratio of conservative design response to actual response. This method has the following characteristic features: (1) the components are classified into several groups based on the differences in their location and in the vibration models used in design response analyses; (2) the response factors are decomposed into subfactors corresponding to the stages of the seismic response analyses in the design practices; (3) the response factors for components are calculated as products of subfactors; (4) the subfactors are expressed either as a single value or as a function of parameters that influence the response of components.},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Nuclear Engineering and Design},
	author = {Ebisawa, K. and Abe, K. and Muramatsu, K. and Itoh, M. and Kohno, K. and Tanaka, T.},
	month = mar,
	year = {1994},
	pages = {197--210},
}

@techreport{doene_usdoe_office_of_nuclear_energy_science_and_technology_ne_technology_2002,
	title = {A {Technology} {Roadmap} for {Generation} {IV} {Nuclear} {Energy} {Systems}},
	url = {http://www.osti.gov/servlets/purl/859029-304XRr/},
	language = {en},
	number = {GIF-002-00, 859029},
	urldate = {2021-09-06},
	author = {{DOENE (USDOE Office of Nuclear Energy, Science and Technology (NE))}},
	month = dec,
	year = {2002},
	doi = {10.2172/859029},
	pages = {GIF--002--00, 859029},
}

@article{haas_criteria_1982,
	title = {Criteria for safety related nuclear plant operator actions: {A} preliminary assessment of available data},
	volume = {3},
	issn = {0143-8174},
	shorttitle = {Criteria for safety related nuclear plant operator actions},
	url = {https://www.sciencedirect.com/science/article/pii/0143817482900221},
	doi = {10.1016/0143-8174(82)90022-1},
	abstract = {The need for a quantitative data base on the reliability of nuclear power plant operators has long been recognised by human factors and reliability analysts, and the great need for further assessment of operator performance under accident conditions has been dramatically emphasised by the incident at Three Mile Island-2. In the US, an effort has been under way for a number of years to develop a design standard to define when required manual operator action can be accepted as part of a nuclear plant design basis. Insufficient data are available to provide quantitative guidelines for the standard. To provide the necessary data base to support such standards and the necessary quantitative assessment of operator reliability, the US Nuclear Regulatory Commission is sponsoring a study at Oak Ridge National Laboratory to develop the data base. A preliminary assessment, completed in April 1979, concluded that sufficient data from US operating experience did not exist to provide an adequate data base. A programme of research using full-scope nuclear plant simulators and results that are correlated to field data was suggested. That programme was recently initiated. This paper reviews the approach, results and conclusions of the preliminary assessment and summarises the planned research programme of simulator studies.},
	language = {en},
	number = {1},
	urldate = {2021-09-05},
	journal = {Reliability Engineering},
	author = {Haas, P. M. and Bott, T. F.},
	month = jan,
	year = {1982},
	pages = {59--72},
}

@techreport{fleming_treatment_1979,
	title = {Treatment of operator actions in the {HTGR} risk assessment study},
	url = {https://www.osti.gov/biblio/5474843},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {GA-A-15499; CONF-791103-71},
	urldate = {2021-09-05},
	institution = {General Atomic Co., San Diego, CA (USA)},
	author = {Fleming, K. N. and Silady, F. A. and Hannaman, G. W.},
	month = dec,
	year = {1979},
}

@techreport{morgan_multi-disciplinary_1992,
	title = {A multi-disciplinary assessment of operator action time for mitigating a postulated accident},
	url = {https://www.osti.gov/biblio/7243977},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {WSRC-MS-92-198-Del.Ver.; CONF-9208117-13},
	urldate = {2021-09-05},
	institution = {Westinghouse Savannah River Co., Aiken, SC (United States)},
	author = {Morgan, C. D. and Fields, C. C. and Hightower, I. I. I. and Buczek, J. A. and Jenkins, T. B. and Swanson, P. J.},
	month = jan,
	year = {1992},
}

@article{exposito_development_2008,
	title = {Development of a software tool for the analysis and verification of emergency operating procedures through the integrated simulation of plant and operators actions},
	volume = {35},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454907003180},
	doi = {10.1016/j.anucene.2007.10.009},
	abstract = {Probabilistic safety assessment (PSA) includes operator actions as elements in the set of the considered protection performances during accident sequences. Nevertheless, its impact throughout a sequence is not usually analyzed dynamically. In this sense, it is convenient to make a more detailed analysis about its importance in the dynamics of the sequences, allowing for sensitivity studies with respect to human reliability and response times. For this reason, new developments in simulation software must be able to incorporate operator actions in conventional thermalhydraulic simulations. In this paper, we present one of these new tools, the TRETA/TIZONA–COPMA III coupled codes, which can be used for evaluating the impact in the final plant state of the execution by operators of procedures and the evaluation of the available times for the manual actions of the operators. This software tool consists of a closed-loop plant/operator simulator: a thermalhydraulic code for simulating the plant transient (TRETA for PWR NPPs and TIZONA for BWR NPPs) and the procedures processor (COPMA III) to simulate the operator actions requested by the procedures, both coupled by a data communication system which allows the information exchange (SWBus). The first pilot cases have been performed in order to analyze sequences initiated by secondary side breaks leading to loss of heat sink sequences in a PWR plant. These tests have been carried out using the real plant EOPs for COPMA-III and a PWR plant model for TRETA code. The results of these simulations are presented in this paper.},
	language = {en},
	number = {7},
	urldate = {2021-09-05},
	journal = {Annals of Nuclear Energy},
	author = {Expósito, A. and Queral, C. and Hortal, J. and Quiroga, A. and Ibarra, A. and Hulsund, J. E. and González, I. and Jiménez, G.},
	month = jul,
	year = {2008},
	pages = {1340--1359},
}

@techreport{noauthor_nuscale_nodate,
	title = {{NuScale} {Power}, {LLC} {Submittal} of "{NuScale} {Control} {Room} {Staffing} {Plan}," {TR}-0420-69456, {Revision} 0},
	language = {en},
	pages = {33},
}

@article{wadoud_physical_2018-1,
	title = {Physical protection evaluation process for nuclear facility via sabotage scenarios},
	volume = {57},
	issn = {11100168},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016817300625},
	doi = {10.1016/j.aej.2017.01.045},
	abstract = {The function of Physical Protection System (PPS) should meet three basic elements (detection, delay, and response) and it is required to protect the nuclear facility against possibility of bombing, sabotage, and theft. The system must be fast in performance to achieve sufﬁcient time for the arrival of response forces and complete the defense about the property in time, thwarting the adversary and neutralizing the implementation of its mission. The performance of the physical protection system should be designed to oppose and limit the capabilities and tactics of the attacker toward the nuclear facility. And in this ways it works as a barrier to obstruct the attacker against penetration. In this work an evaluation of the physical protection system effectiveness for a hypothetical facility against sabotage is presented. Proposed sabotage scenarios will be used as an input for this evaluation. The evaluation process was carried out using the single path computer model (EASI), for the determination of the probability of interruption (PI) as a ﬁrst metric factor of the PPS effectiveness. The Probability of Neutralization (PN) is computed by the neutralization analysis module as a second metric factor of the PPS effectiveness. The probability of detection and delay time values of detection, delay, communication and response forces action was measured along a speciﬁc sabotage path of the adversary. If the evaluation reveals any vulnerability, the initial system design must be redesigned to correct the vulnerabilities and another analysis of the redesigned system is performed.},
	language = {en},
	number = {2},
	urldate = {2021-09-04},
	journal = {Alexandria Engineering Journal},
	author = {Wadoud, A.A. and Adail, A.S. and Saleh, A.A.},
	month = jun,
	year = {2018},
	pages = {831--839},
}

@inproceedings{spurgin_hra_2007,
	address = {Monterey, CA, USA},
	title = {{HRA} requirements for {PRAs}},
	isbn = {978-1-4244-0305-9 978-1-4244-0306-6},
	url = {http://ieeexplore.ieee.org/document/4413230/},
	doi = {10.1109/HFPP.2007.4413230},
	abstract = {The purpose of this paper is to produce some discussion about the current trends in the nuclear power industry as far as human reliability assessment methods and approaches are concerned including the skills and knowledge of industry HRA specialists. The paper addresses topics covered in the withdrawn IEEE standard P.1547, “Recommended Practice for Conducting Human Reliability Analysis for Nuclear Power Generating Stations.” The choice of HRA methods is discussed along with the skills needed for utility HRA specialists and the various sources of HRA data. The IEEE standard introduced three categories similar to the premier PRA standard generated by the ASME. The paper discusses these and calls for a critical discussion into the relationship of HRA models, data, experts and HRA practitioners to categories in PRA/HRAs.},
	language = {en},
	urldate = {2021-09-04},
	booktitle = {2007 {IEEE} 8th {Human} {Factors} and {Power} {Plants} and {HPRCT} 13th {Annual} {Meeting}},
	publisher = {IEEE},
	author = {Spurgin, Anthony J.},
	month = aug,
	year = {2007},
	pages = {341--346},
}

@article{zou_insider_2018-1,
	title = {Insider threats of {Physical} {Protection} {Systems} in nuclear power plants: {Prevention} and evaluation},
	volume = {104},
	issn = {01491970},
	shorttitle = {Insider threats of {Physical} {Protection} {Systems} in nuclear power plants},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197017302020},
	doi = {10.1016/j.pnucene.2017.08.006},
	abstract = {Physical Protection Systems (PPS) are used to protect critical facilities and prevent against adversarial intrusion. The insider threats of PPS must be considered when analyzing the effectiveness of PPS. On the basis of the normal approach termed “Estimate of Adversary Sequence Interruption, EASI”, a novel method named “Estimate and Prevention of the Insider Threats, EPIT” was proposed for the speciﬁc estimation of insider behaviors. According to failure mode and effects analysis (FMEA) method, the EPIT method adequately considers the common failure causes of protective devices to analyze the insider threat to the effectiveness of PPS. By the EPIT method results, a reasonable management and rights allocation of staffs can be ﬁgured out to mitigate insider threats.},
	language = {en},
	urldate = {2021-09-04},
	journal = {Progress in Nuclear Energy},
	author = {Zou, Bowen and Yang, Ming and Guo, Jia and Wang, Junbo and Benjamin, Emi-Reynolds and Liu, Hang and Li, Wei},
	month = apr,
	year = {2018},
	pages = {8--15},
}

@article{landucci_assessment_2017-1,
	title = {Assessment of attack likelihood to support security risk assessment studies for chemical facilities},
	volume = {110},
	issn = {09575820},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957582017302100},
	doi = {10.1016/j.psep.2017.06.019},
	language = {en},
	urldate = {2021-09-04},
	journal = {Process Safety and Environmental Protection},
	author = {Landucci, Gabriele and Argenti, Francesca and Cozzani, Valerio and Reniers, Genserik},
	month = aug,
	year = {2017},
	pages = {102--114},
}

@incollection{iwatsuki_1_2021,
	title = {1 - {Overview} of high temperature gas-cooled reactor},
	volume = {5},
	isbn = {978-0-12-821031-4},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128210314000014},
	booktitle = {High {Temperature} {Gas}-{Cooled} {Reactors}},
	publisher = {Academic Press},
	author = {Iwatsuki, Jin and Kunitomi, Kazuhiko and Mineo, Hideaki and Nishihara, Tetsuo and Sakaba, Nariaki and Shinozaki, Masayuki and Tachibana, Yukio and Yan, Xing},
	editor = {Takeda, Tetsuaki and Inagaki, Yoshiyuki},
	month = jan,
	year = {2021},
	doi = {10.1016/B978-0-12-821031-4.00001-4},
	keywords = {HTGR, graphite, helium gas, inherent safety, nuclear heat, power generation, spherical fuel},
	pages = {1--16},
}

@techreport{ferrante_consideration_2021,
	type = {Practical {Guidance}},
	title = {Consideration of {Defense}-in-{Depth} and {Safety} {Margins} in {Risk} {Informed} {Decision} {Making}},
	language = {en},
	number = {3002020763},
	institution = {EPRI},
	author = {Ferrante, Fernando},
	month = aug,
	year = {2021},
	pages = {208},
}

@article{whitworth_application_1987,
	title = {Application of operator error analysis in the design of {Sizewell} ‘{B}’},
	volume = {19},
	issn = {01438174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0143817487900631},
	doi = {10.1016/0143-8174(87)90063-1},
	abstract = {A programme of operatOr error analysis is bbing carried outfor the Sizewell 'B' P WR design. This"paper describes the methods used, the analysis" which has been carried out, preliminao' results and design changes which have been incorporated to reduce the risk. At this"stage, systematic ident!fication and reduction of risk from operator error has been achieved. Further analysis" and quant(/ication of error is required to substantiate that the risk arising from operator error does not dominate the risk due to mechanical plantfailures.},
	language = {en},
	number = {4},
	urldate = {2021-09-02},
	journal = {Reliability Engineering},
	author = {Whitworth, D.P.D.},
	month = jan,
	year = {1987},
	pages = {299--316},
}

@article{jutla_probabilistic_1987,
	title = {Probabilistic fracture mechanics: {A} report of a meeting on ‘probabilistic fatigue’},
	volume = {19},
	issn = {01438174},
	shorttitle = {Probabilistic fracture mechanics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0143817487900606},
	doi = {10.1016/0143-8174(87)90060-6},
	language = {en},
	number = {4},
	urldate = {2021-09-02},
	journal = {Reliability Engineering},
	author = {Jutla, T.},
	month = jan,
	year = {1987},
	pages = {287--292},
}

@article{apostolakis_pitfalls_1981,
	title = {Pitfalls in risk calculations},
	volume = {2},
	issn = {01438174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0143817481900196},
	doi = {10.1016/0143-8174(81)90019-6},
	abstract = {Two pitJctlls in risk and reliability calculations are Mentified. Thefirst is the treatment qf the failure rates of nominally identical items as independent variables, when the states of knowledge that determine their distributions are identical. Such analyses result in underestimation o f the uncertainties. The second is due to the use o f the linear approximation to the exponential distribution or the use of lognormal distributions JbrJ)'equeneies offailure per demand, which results in erroneous means and varianees.},
	language = {en},
	number = {2},
	urldate = {2021-09-02},
	journal = {Reliability Engineering},
	author = {Apostolakis, G. and Kaplan, S.},
	month = apr,
	year = {1981},
	pages = {135--145},
}

@article{crosetti_fault_1971,
	title = {Fault {Tree} {Analysis} with {Probability} {Evaluaticn}},
	volume = {18},
	issn = {0018-9499},
	url = {http://ieeexplore.ieee.org/document/4325911/},
	doi = {10.1109/TNS.1971.4325911},
	language = {en},
	number = {1},
	urldate = {2021-09-02},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Crosetti, Paul A.},
	year = {1971},
	pages = {465--471},
}

@techreport{noauthor_international_nodate,
	title = {International {HRA} {Empirical} {Study} – {Phase} 1 {Report} ({NUREG}/{IA}-0216, {Volume} 1)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/agreement/ia0216/v1/index.html},
	urldate = {2021-09-01},
}

@techreport{liao_nureg-2156_nodate,
	title = {{NUREG}-2156, "{The} {U}.{S}. {HRA} {Empirical} {Study}. {Assessment} of {HRA} {Method} {Predictions} against {Operating} {Crew} {Performance} on a {U}.{S}. {Nuclear} {Power} {Plant} {Simulator}."},
	language = {en},
	author = {Liao, Harry},
	pages = {461},
}

@misc{noauthor_international_nodate-1,
	title = {International {HRA} {Empirical} {Study} – {Phase} 1 {Report} ({NUREG}/{IA}-0216, {Volume} 1)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/agreement/ia0216/v1/index.html},
	urldate = {2021-09-01},
	journal = {NRC Web},
}

@misc{noauthor_us_nodate,
	title = {The {U}.{S}. {HRA} {Empirical} {Study} – {Assessment} of {HRA} {Method} {Predictions} against {Operating} {Crew} {Performan}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr2156/index.html},
	urldate = {2021-09-01},
	journal = {NRC Web},
}

@article{koo_radioactivity_2014,
	title = {Radioactivity release from the {Fukushima} accident and its consequences: {A} review},
	volume = {74},
	issn = {01491970},
	shorttitle = {Radioactivity release from the {Fukushima} accident and its consequences},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197014000444},
	doi = {10.1016/j.pnucene.2014.02.013},
	abstract = {The Fukushima accident in March 2011 caused by the massive earthquake and tsunami led to hydrogen explosion, core meltdown, and the subsequent release of huge radioactivity both into the atmosphere and the Paciﬁc Ocean. In the case of volatile ﬁssion products such as 137Cs and 131I, the release fraction of the core inventory of the units 1e3 into the atmosphere is estimated to be 1.2e6.6\% and 1.1e7.9\%, respectively. As for gaseous ﬁssion product 133Xe, it is estimated that nearly 100\% of the core inventory might have been released into the atmosphere. In addition, about 16\% of the 137Cs inventory ﬂowed into the sea when the contaminated water used for cooling the decay heat of the units 1e3 overﬂowed the reactors. Therefore, even though almost three years have passed since the accident, it is still having a tremendous impact not only on Japan but all over the world as well.},
	language = {en},
	urldate = {2021-09-01},
	journal = {Progress in Nuclear Energy},
	author = {Koo, Yang-Hyun and Yang, Yong-Sik and Song, Kun-Woo},
	month = jul,
	year = {2014},
	pages = {61--70},
}

@article{winiarek_estimation_2014,
	title = {Estimation of the caesium-137 source term from the {Fukushima} {Daiichi} nuclear power plant using a consistent joint assimilation of air concentration and deposition observations},
	volume = {82},
	issn = {13522310},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S135223101300770X},
	doi = {10.1016/j.atmosenv.2013.10.017},
	abstract = {Inverse modelling techniques can be used to estimate the amount of radionuclides and the temporal proﬁle of the source term released in the atmosphere during the accident of the Fukushima Daiichi nuclear power plant in March 2011. In Winiarek et al. (2012b), the lower bounds of the caesium-137 and iodine-131 source terms were estimated with such techniques, using activity concentration measurements. The importance of an objective assessment of prior errors (the observation errors and the background errors) was emphasised for a reliable inversion. In such critical context where the meteorological conditions can make the source term partly unobservable and where only a few observations are available, such prior estimation techniques are mandatory, the retrieved source term being very sensitive to this estimation.},
	language = {en},
	urldate = {2021-09-01},
	journal = {Atmospheric Environment},
	author = {Winiarek, Victor and Bocquet, Marc and Duhanyan, Nora and Roustan, Yelva and Saunier, Olivier and Mathieu, Anne},
	month = jan,
	year = {2014},
	pages = {268--279},
}

@article{stohl_xenon-133_2012,
	title = {Xenon-133 and caesium-137 releases into the atmosphere from the {Fukushima} {Dai}-ichi nuclear power plant: determination of the source term, atmospheric dispersion, and deposition},
	volume = {12},
	issn = {1680-7324},
	shorttitle = {Xenon-133 and caesium-137 releases into the atmosphere from the {Fukushima} {Dai}-ichi nuclear power plant},
	url = {https://acp.copernicus.org/articles/12/2313/2012/},
	doi = {10.5194/acp-12-2313-2012},
	abstract = {Abstract. On 11 March 2011, an earthquake occurred about 130 km off the Pacific coast of Japan's main island Honshu, followed by a large tsunami. The resulting loss of electric power at the Fukushima Dai-ichi nuclear power plant developed into a disaster causing massive release of radioactivity into the atmosphere. In this study, we determine the emissions into the atmosphere of two isotopes, the noble gas xenon-133 (133Xe) and the aerosol-bound caesium-137 (137Cs), which have very different release characteristics as well as behavior in the atmosphere. To determine radionuclide emissions as a function of height and time until 20 April, we made a first guess of release rates based on fuel inventories and documented accident events at the site. This first guess was subsequently improved by inverse modeling, which combined it with the results of an atmospheric transport model, FLEXPART, and measurement data from several dozen stations in Japan, North America and other regions. We used both atmospheric activity concentration measurements as well as, for 137Cs, measurements of bulk deposition. Regarding 133Xe, we find a total release of 15.3 (uncertainty range 12.2–18.3) EBq, which is more than twice as high as the total release from Chernobyl and likely the largest radioactive noble gas release in history. The entire noble gas inventory of reactor units 1–3 was set free into the atmosphere between 11 and 15 March 2011. In fact, our release estimate is higher than the entire estimated 133Xe inventory of the Fukushima Dai-ichi nuclear power plant, which we explain with the decay of iodine-133 (half-life of 20.8 h) into 133Xe. There is strong evidence that the 133Xe release started before the first active venting was made, possibly indicating structural damage to reactor components and/or leaks due to overpressure which would have allowed early release of noble gases. For 137Cs, the inversion results give a total emission of 36.6 (20.1–53.1) PBq, or about 43\% of the estimated Chernobyl emission. Our results indicate that 137Cs emissions peaked on 14–15 March but were generally high from 12 until 19 March, when they suddenly dropped by orders of magnitude at the time when spraying of water on the spent-fuel pool of unit 4 started. This indicates that emissions may not have originated only from the damaged reactor cores, but also from the spent-fuel pool of unit 4. This would also confirm that the spraying was an effective countermeasure. We explore the main dispersion and deposition patterns of the radioactive cloud, both regionally for Japan as well as for the entire Northern Hemisphere. While at first sight it seemed fortunate that westerly winds prevailed most of the time during the accident, a different picture emerges from our detailed analysis. Exactly during and following the period of the strongest 137Cs emissions on 14 and 15 March as well as after another period with strong emissions on 19 March, the radioactive plume was advected over Eastern Honshu Island, where precipitation deposited a large fraction of 137Cs on land surfaces. Radioactive clouds reached North America on 15 March and Europe on 22 March. By middle of April, 133Xe was fairly uniformly distributed in the middle latitudes of the entire Northern Hemisphere and was for the first time also measured in the Southern Hemisphere (Darwin station, Australia). In general, simulated and observed concentrations of 133Xe and 137Cs both at Japanese as well as at remote sites were in good quantitative agreement. Altogether, we estimate that 6.4 PBq of 137Cs, or 18\% of the total fallout until 20 April, were deposited over Japanese land areas, while most of the rest fell over the North Pacific Ocean. Only 0.7 PBq, or 1.9\% of the total fallout were deposited on land areas other than Japan.},
	language = {en},
	number = {5},
	urldate = {2021-09-01},
	journal = {Atmospheric Chemistry and Physics},
	author = {Stohl, A. and Seibert, P. and Wotawa, G. and Arnold, D. and Burkhart, J. F. and Eckhardt, S. and Tapia, C. and Vargas, A. and Yasunari, T. J.},
	month = mar,
	year = {2012},
	pages = {2313--2343},
}

@article{marzo_atmospheric_2014,
	title = {Atmospheric transport and deposition of radionuclides released after the {Fukushima} {Dai}-chi accident and resulting effective dose},
	volume = {94},
	issn = {13522310},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1352231014004555},
	doi = {10.1016/j.atmosenv.2014.06.009},
	abstract = {On 11 March 2011 an earthquake off the Paciﬁc coast of the Fukushima prefecture generated a tsunami that hit Fukushima Dai-ichi and Fukushima Da-ini Nuclear Power Plants. From 12 March a signiﬁcant amount of radioactive material was released into the atmosphere and dispersed worldwide. Among the most abundant radioactive species released were iodine and cesium isotopes. By means of an atmospheric dispersion Lagrangian code and publicly available meteorological data, the atmospheric dispersion of 131I, 134Cs, and 137Cs have been simulated for three months after the event with a spatial resolution of 0.5  Â 0.5  globally. The simulation has been validated by comparison to publicly available measurements collected in 206 locations worldwide. Sensitivity analysis shows that release height of the radionuclides, wet deposition velocity, and source term are the parameters with the most impact on the simulation results.},
	language = {en},
	urldate = {2021-09-01},
	journal = {Atmospheric Environment},
	author = {Marzo, Giuseppe A.},
	month = sep,
	year = {2014},
	pages = {709--722},
}

@inproceedings{almomani_probabilistic_2016,
	title = {Probabilistic {Risk} {Assessment} {Procedure} of an {Interim} {Dry} {Storage} {Facility} for {Spent} {Nuclear} {Fuel} under {Aircraft} {Strike}},
	abstract = {In order to investigate the interim dry storage facility for nuclear spent fuel is safe and reliable under credible external accidents caused by human induced, it is important to use a probabilistic safety assessment approach for evaluating the severity of an aircraft strike scenario. This paper gives an evaluation method of aircraft risk model by defining a reference case study that includes a given cask model with carefully selected impact conditions from literature based on a quantified manner. The analysis procedure is divided into three major consecutive parts: structural assessment of facility's wall, structural assessment of storage cask, and radiological consequence analysis. This paper presents an overview of the analysis procedure with a sample of calculations to provide an insight of probable risk level with brief technical explanations. This risk frame model would provide an efficient way to investigate the storage facility capacity against the aircraft crash and to protect the physical health of individuals and the environment.},
	author = {Almomani, Belal and Lee, Sanghoon and Kang, Hyun},
	month = aug,
	year = {2016},
}

@incollection{sarkisov_nuclear_2006,
	address = {Dordrecht},
	title = {{NUCLEAR} {AND} {RADIATION} {SAFETY} {DURING} {LONG}-{TERM} {STORAGE} {OF} {SPENT} {NUCLEAR} {FUEL} {OF} {LAND}-{BASED} {REACTOR} {FACILITY} {STANDS}-{PROTOTYPES} 27/{VT} {AND} {KM}-1},
	volume = {215},
	isbn = {978-1-4020-4171-6},
	url = {http://link.springer.com/10.1007/1-4020-4173-X_17},
	abstract = {Within the framework of the ISTC Project \#2710р between the Russian Research Center “Institute for Physics and Power Engineering” (RRC IPPE, below IPPE) and the Brookhaven National Laboratory of the US Department of Energy an investigation has been performed addressing the issues of nuclear and radiation safety when storing Spent Nuclear Fuel (SNF) of land-based stands-prototypes 27/VT and KM-1 constructed during the period of developing lead-bismuth coolant reactor installations for Alphaclass Nuclear Submarines (NS). The detailed results of the investigation can be found in the Final Report under this Project [1].},
	language = {en},
	urldate = {2021-09-01},
	booktitle = {Scientific and {Technical} {Issues} in the {Management} of {Spent} {Fuel} of {Decommissioned} {Nuclear} {Submarines}},
	publisher = {Kluwer Academic Publishers},
	author = {Pankratov, D.V. and Ignatiev, C.V. and Toshinskiy, G.I. and Zabud’Ko, A.N. and Andreyanov, V.S. and Riabaya, L. D. and Suvorov, G.P. and Khvostov, P.V. and Khudiakov, E.M. and Filatov, B.V. and Vishniakov, B.S. and Il’In, V.G. and Kozhevnikov, Yu. M. and Moscowitz, P. D.},
	editor = {Sarkisov, Ashot and Tournyol du Clos, Alain},
	year = {2006},
	doi = {10.1007/1-4020-4173-X_17},
	note = {Series Title: NATO Science Series II: Mathematics, Physics and Chemistry},
	pages = {179--194},
}

@article{kang_development_nodate,
	title = {Development of {Methodology} for {Spent} {Fuel} {Pool} {Risk} {Assessment}},
	author = {KANG, Kyung Min and Kim, Hyowon and Kim, Bo Gyung and Lee, Seung Woo and JUNG, Kuyoung},
}

@misc{noauthor_nc_2012,
	title = {{NC} {State} {University} {Libraries} - {My} {Account}},
	copyright = {North Carolina State University},
	url = {https://myaccount.lib.ncsu.edu/checkouts},
	language = {en},
	urldate = {2021-09-01},
	month = feb,
	year = {2012},
	note = {Publisher: North Carolina State University Libraries.},
}

@inproceedings{taniguchi_development_2018,
	title = {Development of {Fuel} {Route}/{Dropped} {Load} {PSA} for {UK} {ABWR}},
	url = {http://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE26/51449/V002T14A016/273293},
	doi = {10.1115/ICONE26-82022},
	language = {en},
	urldate = {2021-09-01},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Taniguchi, Daisuke and Hirokawa, Naoki and Ishiwatari, Yuki},
	month = oct,
	year = {2018},
}

@inproceedings{wang_filtration_2018,
	title = {Filtration {Technology} {Research} of {Graphite} {Dust} {Produced} in {Spent} {Fuel} {Transportation} {Process} in {HTR}-{PM}},
	url = {http://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE26/51449/V002T03A001/273307},
	doi = {10.1115/ICONE26-81022},
	language = {en},
	urldate = {2021-09-01},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Wang, Jinhua and Wang, Bing and Wu, Bin and Li, Yue and Wang, Haitao},
	month = oct,
	year = {2018},
}

@inproceedings{zhang_recommendations_2017,
	title = {Recommendations for {Conducting} {Probabilistic} {Risk} {Assessment} of {Spent} {Fuel} {Storage} {Facilities}},
	url = {http://mechanicaldesign.asmedigitalcollection.asme.org/ICONE/proceedings/ICONE25/57823/V004T14A003/252537},
	doi = {10.1115/ICONE25-66023},
	language = {en},
	urldate = {2021-09-01},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Zhang, Sai and Zhao, Jun and Tong, Jiejuan and Xu, Zhixin},
	month = oct,
	year = {2017},
}

@inproceedings{mitman_probabilistic_2008,
	title = {Probabilistic {Risk} {Assessment} of {Bolted} {Dry} {Spent} {Fuel} {Storage} {Cask}},
	url = {http://manufacturingscience.asmedigitalcollection.asme.org/ICONE/proceedings/ICONE12/4689X/273/304100},
	doi = {10.1115/ICONE12-49607},
	language = {en},
	urldate = {2021-09-01},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Mitman, Jeffrey T. and Canavan, Ken},
	month = nov,
	year = {2008},
	pages = {273--281},
}

@article{vaurio_human_2009,
	title = {Human factors, human reliability and risk assessment in license renewal of nuclear power plant},
	volume = {9},
	author = {Vaurio, Jussi},
	month = may,
	year = {2009},
}

@article{noauthor_use_2010,
	title = {Use of risk measures in design and licensing of future reactors},
	month = apr,
	year = {2010},
	pages = {9},
}

@article{torabi_canadian_2020,
	title = {Canadian licensing framework of {CANDU} reactors and safety analysis challenges in the allocation of emergency mitigating equipment},
	author = {Torabi, Keivan},
	year = {2020},
	pages = {10},
}

@misc{noauthor_wash-1400_nodate,
	title = {{WASH}-1400 – {The} {Reactor} {Safety} {Study} – {The} {Introduction} of {Risk} {Assessment} to the {Regulation} of {Nucl}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/knowledge/km0010/index.html},
	urldate = {2021-08-31},
	journal = {NRC Web},
}

@article{douple_long-term_2011,
	title = {Long-term {Radiation}-{Related} {Health} {Effects} in a {Unique} {Human} {Population}: {Lessons} {Learned} from the {Atomic} {Bomb} {Survivors} of {Hiroshima} and {Nagasaki}},
	volume = {5},
	issn = {1935-7893, 1938-744X},
	shorttitle = {Long-term {Radiation}-{Related} {Health} {Effects} in a {Unique} {Human} {Population}},
	url = {https://www.cambridge.org/core/product/identifier/S1935789300003839/type/journal_article},
	doi = {10.1001/dmp.2011.21},
	abstract = {For 63 years scientists in the Atomic Bomb Casualty Commission and its successor, the Radiation Effects Research Foundation, have been assessing the long-term health effects in the survivors of the atomic bombings of Hiroshima and Nagasaki and in their children. The identification and follow-up of a large population (approximately a total of 200 000, of whom more than 40\% are alive today) that includes a broad range of ages and radiation exposure doses, and healthy representatives of both sexes; establishment of well-defined cohorts whose members have been studied longitudinally, including some with biennial health examinations and a high survivorparticipation rate; and careful reconstructions of individual radiation doses have resulted in reliable excess relative risk estimates for radiation-related health effects, including cancer and noncancer effects in humans, for the benefit of the survivors and for all humankind. This article reviews those risk estimates and summarizes what has been learned from this historic and unique study.},
	language = {en},
	number = {S1},
	urldate = {2021-08-30},
	journal = {Disaster Medicine and Public Health Preparedness},
	author = {Douple, Evan B. and Mabuchi, Kiyohiko and Cullings, Harry M. and Preston, Dale L. and Kodama, Kazunori and Shimizu, Yukiko and Fujiwara, Saeko and Shore, Roy E.},
	month = mar,
	year = {2011},
	pages = {S122--S133},
}

@article{kellerer_conversion_2001,
	title = {On the conversion of solid cancer excess relative risk into lifetime attributable risk},
	volume = {40},
	issn = {0301-634X, 1432-2099},
	url = {http://link.springer.com/10.1007/s004110100106},
	doi = {10.1007/s004110100106},
	abstract = {Risk coefficients representing the lifetime radiation-induced cancer mortality (or incidence) attributable to an exposure to ionizing radiation, have been published by major international scientific committees. The calculations involve observations in an exposed population and choices of a standard population (for risk transportation), of suitable numerical models, and of computational techniques. The present lack of a firm convention for these choices makes it difficult to inter-compare risk estimates presented by different scientific bodies. Some issues that relate to a necessary harmonization and standardization of risk estimates are explored here. Computational methods are discussed and, in line with the approach utilized by ICRP, conversion factors from excess relative risk (ERR) to lifetime attributable risk (LAR) are exemplified for exposures at all ages and for occupational exposures. A standard population is specified to illustrate the possibility of a simplified standard for risk transportation computations. It is suggested that a more realistic perception of lifetime risk could be gained by the use of coefficients scaled to the lifetime spontaneous cancer rates in the standard population. The resulting quantity lifetime fractional risk (LFR) is advantageous also because it depends much less on the choice of the reference population than the lifetime attributable risk (LAR).},
	language = {en},
	number = {4},
	urldate = {2021-08-30},
	journal = {Radiation and Environmental Biophysics},
	author = {Kellerer, A. M. and Nekolla, Elke A. and Walsh, Linda},
	month = dec,
	year = {2001},
	pages = {249--257},
}

@article{vaeth_calculating_nodate,
	title = {Calculating excess lifetime risk in relative risk models.},
	language = {en},
	author = {Vaeth, Michael and Piercet, Donald A},
	pages = {12},
}

@article{evangeliou_global_2014,
	title = {Global and local cancer risks after the {Fukushima} {Nuclear} {Power} {Plant} accident as seen from {Chernobyl}: {A} modeling study for radiocaesium ({134Cs} \& {137Cs})},
	volume = {64},
	issn = {01604120},
	shorttitle = {Global and local cancer risks after the {Fukushima} {Nuclear} {Power} {Plant} accident as seen from {Chernobyl}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0160412013002808},
	doi = {10.1016/j.envint.2013.11.020},
	abstract = {The accident at the Fukushima Daiichi Nuclear Power Plant (NPP) in Japan resulted in the release of a large number of ﬁssion products that were transported worldwide. We study the effects of two of the most dangerous radionuclides emitted, 137Cs (half-life: 30.2 years) and 134Cs (half-life: 2.06 years), which were transported across the world constituting the global fallout (together with iodine isotopes and noble gasses) after nuclear releases. The main purpose is to provide preliminary cancer risk estimates after the Fukushima NPP accident, in terms of excess lifetime incident and death risks, prior to epidemiology, and compare them with those occurred after the Chernobyl accident. Moreover, cancer risks are presented for the local population in the form of high-resolution risk maps for 3 population classes and for both sexes. The atmospheric transport model LMDZORINCA was used to simulate the global dispersion of radiocaesium after the accident. Air and ground activity concentrations have been incorporated with monitoring data as input to the LNT-model (Linear Non-Threshold) frequently used in risk assessments of all solid cancers. Cancer risks were estimated to be small for the global population in regions outside Japan. Women are more sensitive to radiation than men, although the largest risks were recorded for infants; the risk is not depended on the sex at the age-at-exposure. Radiation risks from Fukushima were more enhanced near the plant, while the evacuation measures were crucial for its reduction. According to our estimations, 730–1700 excess cancer incidents are expected of which around 65\% may be fatal, which are very close to what has been already published (see references therein). Finally, we applied the same calculations using the DDREF (Dose and Dose Rate Effectiveness Factor), which is recommended by the ICRP, UNSCEAR and EPA as an alternative reduction factor instead of using a threshold value (which is still unknown). Excess lifetime cancer incidents were estimated to be between 360 and 850, whereas 220–520 of them will be fatal. Nevertheless, these numbers are expected to be even smaller, as the response of the Japanese ofﬁcial authorities to the accident was rapid. The projected cancer incidents are much lower than the casualties occurred from the earthquake itself (N20,000) and also smaller than the accident of Chernobyl.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Environment International},
	author = {Evangeliou, Nikolaos and Balkanski, Yves and Cozic, Anne and Møller, Anders Pape},
	month = mar,
	year = {2014},
	pages = {17--27},
}

@article{evangeliou_wildfires_2014,
	title = {Wildfires in {Chernobyl}-contaminated forests and risks to the population and the environment: {A} new nuclear disaster about to happen?},
	volume = {73},
	issn = {01604120},
	shorttitle = {Wildfires in {Chernobyl}-contaminated forests and risks to the population and the environment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0160412014002608},
	doi = {10.1016/j.envint.2014.08.012},
	abstract = {Radioactive contamination in Ukraine, Belarus and Russia after the Chernobyl accident left large rural and forest areas to their own fate. Forest succession in conjunction with lack of forest management started gradually transforming the landscape. During the last 28 years dead wood and litter have dramatically accumulated in these areas, whereas climate change has increased temperature and favored drought. The present situation in these forests suggests an increased risk of wildﬁres, especially after the pronounced forest ﬁres of 2010, which remobilized Chernobyl-deposited radioactive materials transporting them thousand kilometers far. For the aforementioned reasons, we study the consequences of different forest ﬁres on the redistribution of 137Cs. Using the time frequency of the ﬁres that occurred in the area during 2010, we study three scenarios assuming that 10\%, 50\% and 100\% of the area are burnt. We aim to sensitize the scientiﬁc community and the European authorities for the foreseen risks from radioactivity redistribution over Europe. The global model LMDZORINCA that reads deposition density of radionuclides and burnt area from satellites was used, whereas risks for the human and animal population were calculated using the Linear No-Threshold (LNT) model and the computerized software ERICA Tool, respectively. Depending on the scenario, whereas between 20 and 240 humans may suffer from solid cancers, of which 10–170 may be fatal. ERICA predicts insigniﬁcant changes in animal populations from the ﬁres, whereas the already extreme radioactivity background plays a major role in their living quality. The resulting releases of 137Cs after hypothetical wildﬁres in Chernobyl's forests are classiﬁed as high in the International Nuclear Events Scale (INES). The estimated cancer incidents and fatalities are expected to be comparable to those predicted for Fukushima. This is attributed to the fact that the distribution of radioactive fallout after the wildﬁres occurred to the intensely populated Western Europe, whereas after Fukushima it occurred towards the Paciﬁc Ocean. The situation will be exacerbated near the forests not only due to the expected redistribution of refractory radionuclides (also trapped there), but also due to the nutritional habits of the local human and animal population.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Environment International},
	author = {Evangeliou, Nikolaos and Balkanski, Yves and Cozic, Anne and Hao, Wei Min and Møller, Anders Pape},
	month = dec,
	year = {2014},
	pages = {346--358},
}

@article{little_risks_2009,
	title = {Risks {Associated} with {Low} {Doses} and {Low} {Dose} {Rates} of {Ionizing} {Radiation}: {Why} {Linearity} {May} {Be} ({Almost}) the {Best} {We} {Can} {Do}},
	volume = {251},
	issn = {0033-8419, 1527-1315},
	shorttitle = {Risks {Associated} with {Low} {Doses} and {Low} {Dose} {Rates} of {Ionizing} {Radiation}},
	url = {http://pubs.rsna.org/doi/10.1148/radiol.2511081686},
	doi = {10.1148/radiol.2511081686},
	language = {en},
	number = {1},
	urldate = {2021-08-30},
	journal = {Radiology},
	author = {Little, Mark P. and Wakeford, Richard and Tawn, E. Janet and Bouffler, Simon D. and Berrington de Gonzalez, Amy},
	month = apr,
	year = {2009},
	pages = {6--12},
}

@article{santos_probabilistic_nodate,
	title = {A {Probabilistic} {Failure} {Assessment} of a {Dry} {Cask} {Storage} {System}},
	abstract = {The Office of Nuclear Regulatory Research (RES) of the U.S. Nuclear Regulatory Commission (NRC) has applied probabilistic methods to failure assessments of a dry cask storage system. Analyses were performed to examine the behavior of a fully loaded cask subjected to loads from accidental drops or inhibited normal cooling. This study focuses on a specific cask system (Holtec International HI-STORM 100) storing boiling-water reactor (BWR) spent fuel. The analyses described below are part of a probabilistic risk assessment (PRA) performed by the NRC for dry cask storage. The objectives of this paper are to describe the analyses used to (1) calculate the probability of cask failure and (2) estimate the fraction of fuel failure for various initiating events. No results will be presented in this paper because the analyses are still ongoing.},
	language = {en},
	author = {Santos, Cayetano and Kalinousky, Douglas and Ryder, Christopher and Abramson, Lee and Shaukat, Syed and Schaperow, Jason and Rubin, Alan},
	pages = {8},
}

@article{tjahyani_327_nodate,
	title = {3.27 {PRA} ({Probabilistic} {Risk} {Assessment}) for {Spent} {Fuel} {Decommissioning} of the {Fugen} {Nuclear} {Power} {Station}},
	abstract = {Fugen Nuclear Power Station will be permanently shutdown in 2003 and immediate fuel unloading and fuel transportation is necessary. The spent fbel pol should be stored safely because the spent fuels are kept in the spent fuel pool. Loss of coling in the spent fuel pool can lead to a srious condition. This paper is to calculate the risk of the spent fuel pool especially probability calculation of consequence during decommissioning. In this case, fel uncovery is as end state. Calculation is based on NUREG-1738. Analysis has been done for 4 initiating events flat are loss of cooling, internal fire, loss of offsite power (LOPA) and loss of inventory. Initiating evern fequency is adopted from Fugen condition and NUREG. More, calculation data is taken from the living PSA of Fugen and NUREG. Results of analysis sowed that the spent fuel pool of Fugen is safe enough because the fuel uncovery probability is 4.438E-08 per year. Moreover, the spent fuel pool cooling system of the Fugen NPS has high reliability because the failure probability is 7.435E-04 per year and will become 2.794E-06 per year if RHR (residual heat removal) system is included. Therefore, RHR system can be considered in the aident management during decommissioning. On the other hand, the maintenance cost increases by keeping the RHR system during decommissioning.},
	language = {en},
	author = {Tjahyani, D T Sony},
	pages = {6},
}

@techreport{sony_tjahyani_pra_2003,
	address = {Japan},
	title = {{PRA} ({Probabilistic} {Risk} {Assessment}) for spent fuel decommissioning of the {Fugen} {Nuclear} {Power} {Station}},
	abstract = {Fugen Nuclear Power Station will be permanently shutdown in 2003 and immediate fuel
unloading and fuel transportation is necessary The spent fuel pool should be stored
safely because the spent fuels are kept in the spent fuel pool Loss of cooling in
the spent fuel pool can lead to a serious condition This paper is to calculate the
risk of the spent fuel pool especially probability calculation of consequence during
decommissioning In this case, fuel uncovery is as end state Calculation is based on
NUREG-1738 Analysis has been done for 4 initiating events that are loss of cooling,
internal fire, loss of offsite power (LOPA) and loss of inventory Initiating even
frequency is adopted from Fugen condition and NUREG More, calculation data is taken
from the living PSA of Fugen and NUREG Results of analysis showed that the spent fuel
pool of Fugen is safe enough because the fuel uncovery probability is 4438E-08 per
year Moreover, the spent fuel pool cooling system of the Fugen NPS has high reliability
because the failure probability is 7435E-04 per year and will become 2794E-06 per
year if RHR (residual heat removal) system is included Therefore, RHR system can be
considered in the accident management during decommissioning On the other hand, the
maintenance cost increases by keeping the RHR system during decommissioning (author)},
	author = {Sony Tjahyani, D.T. and Iguchi, Y. and Kiyota, S.},
	year = {2003},
	note = {JAERI-Conf--2003-006
INIS Reference Number: 36116113},
	pages = {277--282},
}

@misc{noauthor_safety_nodate,
	title = {Safety of {Spent} {Fuel} {Storage} ({NUREG}/{BR}-0528)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/brochures/br0528/index.html},
	urldate = {2021-03-28},
	journal = {NRC Web},
}

@misc{noauthor_probabilistic_nodate,
	title = {Probabilistic {Risk} {Assessment} ({PRA}) {Study} {\textbar} {Bureau} of {Safety} and {Environmental} {Enforcement}},
	url = {https://www.bsee.gov/what-we-do/offshore-regulatory-programs/risk-assessment-analysis/probabilistic-risk-assessment-analysis},
	urldate = {2021-08-27},
}

@misc{noauthor_technical_nodate,
	title = {Technical {Study} of {Spent} {Fuel} {Pool} {Accident} {Risk} at {Decommissioning} {Nuclear} {Power} {Plants} ({NUREG}-1738},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1738/index.html},
	urldate = {2021-08-27},
	journal = {NRC Web},
}

@article{duman_kantarcioglu_nukleer_2018,
	title = {Nükleer {Güç} {Santrallerinde} {Ağır} {Kazalar} İçin 3+ {Seviye} {Olasılıklı} {Güvenlik} {Analizi} {Yönteminin} {Geliştirilmesi} {Ve} {Akkuyu} {Nükleer} {Güç} {Santrali} İçin {Uygulanması}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {http://openaccess.hacettepe.edu.tr:8080/xmlui/handle/11655/5569},
	abstract = {The purpose of this thesis is to develop 3+ level probabilistic safety analysis (PSA) method 
for severe accidents in nuclear power plants and to apply the developed method to Akkuyu 
Nuclear Power Plant. For this purpose, first of all, safety principles in nuclear power plants 
were investigated. Off-site emergency management is defined as the ultimate safety barrier 
for severe accidents. For this reason, off-site emergency management approaches in Turkey 
and around the world have been examined. International standards for emergency and early 
protective measures have been explored. Mass evacuation practices were also investigated 
to detail the evacuation procedures which is one of the protective measures applied during 
general emergencies. 
In this study, 2nd and 3rd Level PSA applications were carried out in order to comprehend 
PSA methods in an integrated manner. For this purpose, AES 2006 reactor design and 
containment safety systems of Mersin Akkuyu NPP were examined. In order to study the 
behavior of containment safety systems in a selected severe accident scenario, a simplified 
Level 2 PSA application was performed. In this application, containment event tree (CAT) 
and fault trees for passive safety systems of containment were developed. Analysis were 
performed using SAPHIRE code. 
Moreover, calculations were performed to understand the logic behind atmospheric 
dispersion of radioactive materials in case of severe accidents. The calculation of the air 
concentrations at different distances were performed using the PAVAN code as a 
fundamental application. In addition, as an application related to Level 3 PSA, radiation 
exposures that may arise from atmospheric dispersion were calculated for emergency 
planning zones. For the severe accident case, RASCAL code was used to estimate the dose 
distribution. Also, with NRC DOSE code, dose distributions were estimated using the 
expected releases during normal operation. All data obtained were used to verify the data 
presented by Akkuyu Project Company in the Environmental Impact Assessment (EIA) 
Report. 
According to the relevant regulations, size of Urgent Protective Action Zone (UPZ) is a 
circle with 20 km diameter. Today, approximately 15,000 people live within UPZ. It is 
assumed that Akkuyu NPP will be online in 2025 and the population estimated for the year 
2025 is 26,000 within UPZ. In the light of obtained data, the area subject to the evacuation 
plan was examined in detail and a probabilistic approach to the delay of evacuation, due to 
the failures in the off-site emergency management process, was developed. Based on this 
approach the evacuation model was generated. In the analysis, fault tree method was used. 
The uncertainties in the results were analyzed and the confidence intervals were determined. 
In addition, different combinations of failures that may arise independently from each other 
were studied and their possible consequences were predicted. A risk matrix was constructed 
to illustrate the probability-consequence analysis. Combinations with high probability and 
large negative impacts on evacuation and with low probability but large negative impacts 
were stated as having high risk profile because they may cause a serious break down in 
evacuation procedures. 
The results show that the probability of accidents during mass evacuation practices is 
extremely high. The confidence intervals of the calculations are wide. The generated risk 
matrix shows that disruptions can significantly affect the evacuation processes and in some 
combinations the process can be seriously interrupted. As a result, it is concluded that the 
developed method is a method that can be used to base plans on numerical data and analysis, 
to make the necessary arrangements in the plans by anticipating possible problems and to 
develop realistic emergency management approaches in this way.},
	language = {tur},
	urldate = {2021-08-27},
	author = {Duman Kantarcıoğlu, Veda},
	year = {2018},
	note = {Accepted: 2018-12-26T10:47:42Z
Publisher: Fen Bilimleri Enstitüsü},
}

@article{treichel_how_nodate,
	title = {How to {Achieve} {Public} {Participation} in {Nuclear} {Waste} {Decisions}: {Public} {Relations} or {Transparent} {Adversary} {Science}},
	abstract = {The current U.S. nuclear waste disposal program began with passage of the Nuclear Waste Policy Act of 1982 and was modified by the Nuclear Waste Policy Amendments Act of 1987. The Amendments Act made many major changes to the original Act, the most significant of which was the singling out of Yucca Mountain as the only site to be studied for a deep geologic high-level nuclear waste repository. While that decision appeared to simplify and streamline the program, it vastly increased the levels of public resistance and protest, particularly in Nevada.},
	language = {en},
	author = {Treichel, Judy},
	pages = {10},
}

@article{treichel_how_2000,
	title = {How to {Achieve} {Public} {Participation} in {Nuclear} {Waste} {Decisions}: {Public} {Relations} or {Transparent} {Adversary} {Science}},
	volume = {11},
	issn = {1073-8673},
	shorttitle = {How to {Achieve} {Public} {Participation} in {Nuclear} {Waste} {Decisions}},
	url = {https://scholars.unh.edu/risk/vol11/iss3/5},
	number = {3},
	journal = {RISK: Health, Safety \& Environment (1990-2002)},
	author = {Treichel, Judy},
	month = jun,
	year = {2000},
}

@misc{noauthor_environmental_nodate,
	title = {Environmental assessment overview: {Yucca} {Mountain} {Site}, {Nevada} {Research} and {Development} {Area}, {Nevada} - {ScienceBase}-{Catalog}},
	url = {https://www.sciencebase.gov/catalog/item/5140ac78e4b089809dbf54cd},
	urldate = {2021-08-27},
}

@inproceedings{karlsson_nuclear_2006,
	title = {Nuclear {Waste}, {Risks} and {Sustainable} {Development}},
	author = {Karlsson, Mikael and Swahn, Johan},
	month = jan,
	year = {2006},
}

@article{sjoberg_physical_nodate,
	title = {Physical and {Managed} {Risk} of {Nuclear} {Waste}},
	language = {en},
	author = {Sjöberg, Lennart and Drottz-Sjöberg, Britt-Marie},
	pages = {9},
}

@article{sjoberg_physical_1997,
	title = {Physical and {Managed} {Risk} of {Nuclear} {Waste}},
	volume = {8},
	issn = {1073-8673},
	url = {https://scholars.unh.edu/risk/vol8/iss2/4},
	number = {2},
	journal = {RISK: Health, Safety \& Environment (1990-2002)},
	author = {Sjöberg, Lennart and Drottz-Sjöberg, Britt-Marie},
	month = mar,
	year = {1997},
}

@article{datta_risks_2009,
	title = {Risks characterisation in nuclear waste management - avoiding catastrophe},
	volume = {n° 27},
	issn = {1768-5958},
	url = {https://www.cairn.info/revue-management-et-avenir-2009-7-page-198.htm},
	abstract = {{\textless}titre{\textgreater}Résumé{\textless}/titre{\textgreater}L’évaluation des risques dans le management des déchets nucléaires est essentiellement basée sur des hypothèses et des modèles probabilistes qui visent à établir les risques d’occurence d’événements accidentels sur des sites nucléaires, de défaillances dans des dépôts de carburant nucléaire et d’émission de radioactivité correspondante. Les niveaux de radiation auxquelles on estime que les populations environnantes pourraient être exposées sont liés de manière inappropriée aux risques de cancer et de malformations congénitales. Les sites de production d’énergie nucléaire et les dépôts de carburant nucléaire sont très sûrs en comparaison des risques sanitaires liés à d’autres modes de production énergétique, ou même des risques que tout un chacun accepte volontiers dans sa vie quotidienne. Les populations ne sont pas favorables aux sites et aux activités nucléaires du fait, d’une part, des images négatives et effrayantes, issues d’extrapolations non-scientifiques quant aux effets nocifs de fortes expositions, et, d’autre part, des inquiétudes exagérément amplifiées quant à la sécurité et aux risques médicaux qui leur sont liés. Des tests nucléaires à grande échelle et l’expérience tirée d’accidents démontrent que même des accidents très graves n’exposent les populations qu’à des doses de radiations qui ne sont pas nocives pour la santé. Pour satisfaire les futurs besoins énergétiques de l’Inde, l’énergie nucléaire est une solution incontournable ; ses nombreux avantages et son usage à des fins pacifiques doivent être expliqués aux populations à travers des programmes de sensibilisation.},
	language = {fr},
	number = {7},
	urldate = {2021-08-27},
	journal = {Management Avenir},
	author = {Datta, Dr},
	month = nov,
	year = {2009},
	note = {Bibliographie\_available: 1
Cairndomain: www.cairn.info
Cite Par\_available: 0
Publisher: Management Prospective Ed.},
	pages = {198--207},
}

@book{sadia_risk_2018,
	title = {Risk analysis for long term disposal of radioactive nuclear waste},
	abstract = {In this study the technical risk analysis that was conducted using fault trees.With respect to the scenarios in Bangladesh, there is still no concrete proposal about a permanent disposal method, so this analysis is based on the propositions and other historical data. When actual data is produced, this risk analysis technique can then be employed to calculate risks.},
	author = {Sadia, Sabikun and Hosan, Md and Dewan, Md Jafor and Ahmed, Saikat},
	month = oct,
	year = {2018},
}

@article{almomani_probabilistic_2017,
	title = {Probabilistic risk assessment of aircraft impact on a spent nuclear fuel dry storage},
	volume = {311},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549316304459},
	doi = {10.1016/j.nucengdes.2016.11.012},
	abstract = {This paper proposes a systematic risk evaluation framework for one of the most significant impact events on an interim dry storage facility, an aircraft crash, by using a probabilistic approach. A realistic case study that includes a specific cask model and selected impact conditions is performed to demonstrate the practical applicability of the proposed framework. An event tree analysis of an occurred aircraft crash that defines a set of impact conditions and storage cask response is constructed. The Monte-Carlo simulation is employed for the probabilistic approach in consideration of sources of uncertainty associated with the impact loads onto the internal storage casks. The parameters for representing uncertainties that are managed probabilistically include the aircraft impact velocity, the compressive strength of the reinforced concrete wall, the missile shape factor, and the facility wall thickness. Failure probabilities of the impacted wall and a single storage cask under direct mechanical impact load caused by the aircraft crash are estimated. A finite element analysis is applied to simulate the postulated direct engine impact load onto the cask body, and a source term analysis for associated releases of radioactive materials as well as an off-site consequence analysis are performed. Finally, conditional risk contribution calculations are represented by an event tree model. Case study results indicate that no severe risk is presented, as the radiological consequences do not exceed regulatory exposure limits to the public. This risk model can be used with any other representative detailed parameters and reference design concepts for other comparable direct or indirect impact conditions onto the cask body, which may provide an efficient way to investigate storage facility capacity to withstand an aircraft crash and thereby protect public health.},
	language = {en},
	urldate = {2021-08-27},
	journal = {Nuclear Engineering and Design},
	author = {Almomani, Belal and Lee, Sanghoon and Jang, Dongchan and Kang, Hyun Gook},
	month = jan,
	year = {2017},
	pages = {104--119},
}

@article{hsueh_development_1996,
	title = {The development and application of the accident dynamic simulator for dynamic probabilistic risk assessment of nuclear power plants},
	volume = {52},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832095001409},
	doi = {10.1016/0951-8320(95)00140-9},
	language = {en},
	number = {3},
	urldate = {2021-08-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Hsueh, Kae-Sheng and Mosleh, Ali},
	month = jun,
	year = {1996},
	pages = {297--314},
}

@article{zhang_improved_2018,
	title = {An improved probabilistic method for screening safety-related human actions in nuclear power plants},
	volume = {340},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549318311361},
	doi = {10.1016/j.nucengdes.2018.10.011},
	abstract = {For the reliability and safety of nuclear power plants (NPPs), their design and operation must follow the relevant principles of human factors engineering (HFE). As various human actions are involved in the operation of NPPs, there is a need to screen human actions first and, then, focus the analysis on the critical ones. In the past, different NPPs have adopted different standards in screening human actions and many of these standards lack theoretical support. In this study, the concept of human action risk achievement worth (HRAW) is introduced to support probabilistic screening. A new probabilistic method for screening safety-related human actions in NPPs is proposed. The results of a case study indicate that the proposed method performs well and better than the previous probabilistic screening method typically used, it also implies that this method can provides methodological support to the probabilistic screening method of human actions. On the one hand, utilizing this method to screen human actions can help identifying those actions that are critical for the safety of NPPs. On the other hand, it can reduce the workload and improve work efficiency. The method is traceable and easy to use. It not only can be used in the design of NPPs, but also can provide guidelines for reviewers to evaluate the NPPs safety.},
	language = {en},
	urldate = {2021-08-25},
	journal = {Nuclear Engineering and Design},
	author = {Zhang, Li and Wang, Chunbo and Zio, Enrico and Zou, Yanhua and Jiang, Jianjun and Liu, Yanzi and Liu, Zhaopeng},
	month = dec,
	year = {2018},
	keywords = {Human action risk achievement worth (HRAW), Human actions, Human factors engineering (HFE), Nuclear power plant (NPP), Probabilistic screening method},
	pages = {415--420},
}

@article{kim_framework_2018,
	title = {A framework to estimate probability of diagnosis error in {NPP} advanced {MCR}},
	volume = {111},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454916311331},
	doi = {10.1016/j.anucene.2017.08.026},
	abstract = {Recently, a new type of main control room (MCR) has been adopted in nuclear power plants (NPPs). The new MCR, known as the advanced MCR, consists of digitalized human-system interfaces (HSIs), computer-based procedures (CPS), and soft controls while the conventional MCR includes many alarm tiles, analog indicators, hard-wired control devices, and paper-based procedures. These changes significantly affect the generic activities of the MCR operators, in relation to diagnostic activities. The aim of this paper is to suggest a framework to estimate the probabilities of diagnosis errors in the advanced MCR by updating a time reliability correlation (TRC) model. Using Bayesian inference, the TRC model was updated with the probabilities of diagnosis errors. Here, the diagnosis error data were collected from a full-scope simulator of the advanced MCR. To do this, diagnosis errors were determined based on an information processing model and their probabilities were calculated. However, these calculated probabilities of diagnosis errors were largely affected by context factors such as procedures, HSI, training, and others, known as PSFs (Performance Shaping Factors). In order to obtain the nominal diagnosis error probabilities, the weightings of PSFs were also evaluated. Then, with the nominal diagnosis error probabilities, the TRC model was updated. This led to the proposal of a framework to estimate the nominal probabilities of diagnosis errors in the advanced MCR.},
	language = {en},
	urldate = {2021-08-25},
	journal = {Annals of Nuclear Energy},
	author = {Kim, Ar Ryum and Kim, Jong Hyun and Jang, Inseok and Seong, Poong Hyun},
	month = jan,
	year = {2018},
	keywords = {Advanced MCR, Bayesian inference, Diagnosis error probability, Human reliability analysis (HRA), Profiling technique, Time reliability correlation (TRC) model},
	pages = {31--40},
}

@article{chang_development_2003,
	title = {Development of {Dynamic} {PRA}: {The} accident dynamic simulator({ADS}) tool},
	author = {Chang, Y.H. and Mosleh, A and Dang, V.N.},
	year = {2003},
	pages = {9},
}

@article{mandelli_mutual_2020,
	title = {Mutual {Integration} of classical and dynamic {PRA}},
	author = {Mandelli, Diego and Alfonsi, Anderea and Wang, Congjian},
	month = may,
	year = {2020},
	pages = {14},
}

@article{mandelli_measuring_2017,
	title = {Measuring {Risk} {Importance} in a {Dynamic} {PRA} framework},
	author = {Mandelli, Diego and Ma, Zhegang and Parisi, Carlo},
	month = oct,
	year = {2017},
	pages = {9},
}

@book{tosoni_novel_2021,
	title = {Novel methods of scenario analysis for the probabilistic risk assessment of nuclear waste storage and disposal facilities},
	isbn = {978-952-64-0466-0},
	url = {https://aaltodoc.aalto.fi:443/handle/123456789/109085},
	abstract = {The safety of nuclear waste management facilities is typically assessed by considering accident scenarios in which the containment function may be compromised. In some scenario analysis approaches, relatively few scenarios are built based on the available knowledge. Then, the containment performance of the facility and the resulting radiological impact is analyzed separately for each scenario. Alternatively, other approaches consider scenarios within a structured probabilistic safety assessment.   
 
Probabilistic safety assessment systematically accounts for the aleatory uncertainty about the evolution of the nuclear waste management facility under a set of accident scenarios. Thus, the probabilities and impacts of these scenarios are aggregated into an estimate of the overall risk. The scarcity and imprecision of the data utilized in the safety assessment also involves epistemic uncertainty, as it is hard to assign precise values to event probabilities and other model parameters.   
 
This dissertation addresses the modeling of uncertainties in estimating the risk of nuclear waste management facilities, and what this implies for the comprehensiveness of scenario analysis as a support to risk-informed decision making. Specifically, it is suggested that comprehensiveness is achieved when the uncertainty about risk is sufficiently small to assess conclusively whether the facility is safe or not.   
 
The main challenges in the attainment of comprehensiveness are also identified, and novel methodologies for probabilistic scenario analysis are presented. In particular, Bayesian networks and probabilistic cross-impact analysis are developed to describe systemic dependencies. Epistemic uncertainties are characterized through probability distributions or regions of feasible values. The uncertainties are propagated to the risk estimate by using Monte Carlo simulation or solving optimization problems. Risk importance measures are introduced and calculated to identify which scenarios contribute most to the overall risk level. This offers relevant information for risk management decisions.},
	language = {en},
	urldate = {2021-08-24},
	publisher = {Aalto University},
	author = {Tosoni, Edoardo},
	year = {2021},
	note = {Accepted: 2021-08-19T09:00:11Z
ISSN: 1799-4942 (electronic)},
}

@misc{noauthor_final_nodate,
	title = {Final {Safety} {Evaluation} {Report} {Related} {To} {Certification} {Of} {The} {AP1000} {Standard} {Design} ({NUREG}-1793, {Initial} {Report}) {\textbar} {NRC}.gov},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1793/initial/index.html#pub-info},
	urldate = {2021-08-24},
}

@article{mercurio_integrated_2018,
	title = {Integrated {Level} 1–{Level} 2 decommissioning probabilistic risk assessment for boiling water reactors},
	volume = {50},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573317307143},
	doi = {10.1016/j.net.2018.03.001},
	language = {en},
	number = {5},
	urldate = {2021-08-21},
	journal = {Nuclear Engineering and Technology},
	author = {Mercurio, Davide and Andersen, Vincent M. and Wagner, Kenneth C.},
	month = jun,
	year = {2018},
	pages = {627--638},
}

@article{kukielka_impact_1999,
	title = {The impact of assessing lower head integrity on boiling water reactor probabilistic risk assessments},
	volume = {63},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832098000428},
	doi = {10.1016/S0951-8320(98)00042-8},
	language = {en},
	number = {3},
	urldate = {2021-08-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Kukielka, Casimir A.},
	month = mar,
	year = {1999},
	pages = {267--273},
}

@article{you_probabilistic_2002,
	title = {Probabilistic failure analysis of nuclear piping with empirical study of {Taiwan}'s {BWR} plants},
	volume = {79},
	issn = {03080161},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0308016102000613},
	doi = {10.1016/S0308-0161(02)00061-3},
	language = {en},
	number = {7},
	urldate = {2021-08-21},
	journal = {International Journal of Pressure Vessels and Piping},
	author = {You, Jang-Shyong and Wu, Wen-Fang},
	month = jul,
	year = {2002},
	pages = {483--492},
}

@article{mandelli_dynamic_2005,
	title = {Dynamic and {Classical} {PRA} : a {BWR} {SBO} {Case} {Comparison}},
	volume = {12},
	journal = {INL},
	author = {Mandelli, Diego and Ma, Zhegang and Smith, Curtis},
	month = may,
	year = {2005},
	pages = {12},
}

@article{liao_assessment_2019,
	title = {Assessment of {HRA} method predictions against operating crew performance: {Part} {I}: {Study} background, design and methodology},
	volume = {191},
	issn = {0951-8320},
	shorttitle = {Assessment of {HRA} method predictions against operating crew performance},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832018303661},
	doi = {10.1016/j.ress.2019.106509},
	abstract = {This is the first in a series of three papers documenting two large-scale human reliability analysis (HRA) empirical studies – the International HRA Empirical Study and the US HRA Empirical Study. The two studies are the first major efforts in recent years to benchmark HRA methods by comparing HRA method predictions against actual operator performance in responding to accidents simulated on nuclear power plant (NPP) full-scale simulators. The studies aimed to gain knowledge and insights concerning the strengths and weaknesses of the studied HRA methods and the factors contributing to inter-analyst (or intra-method) variability. In addition, the studies also compared the results of the same HRA method applied by different analysis teams. This paper provides the background and motivation of the studies, the overall study design, the simulation scenarios and human failure events to be analyzed, and concluding remarks concerning lessons learned on benchmarking HRA methods with crew performance of scenarios on NPP simulators.},
	language = {en},
	urldate = {2021-08-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Liao, Huafei and Forester, John and Dang, Vinh N. and Bye, Andreas and Chang, Yung Hsien J. and Lois, Erasmia},
	month = nov,
	year = {2019},
	keywords = {Human error probability, Human failure event, Human reliability analysis, Nuclear power plant, Probabilistic risk assessment, Simulation},
	pages = {106509},
}

@article{moieni_advances_1994,
	title = {Advances in human reliability analysis methodology. {Part} {I}: frameworks, models and data},
	volume = {44},
	issn = {0951-8320},
	shorttitle = {Advances in human reliability analysis methodology. {Part} {I}},
	url = {https://www.sciencedirect.com/science/article/pii/0951832094901058},
	doi = {10.1016/0951-8320(94)90105-8},
	abstract = {This paper, in two parts, summarizes some of the advancements made in the area of human reliability analysis (HRA) in the past decade. The paper focuses on the HRA program sponsored by the Electric Power Research Institute (EPRI) since 1982 as part of an effort to better understand the role of operators in safe operation of nuclear power plants (NPPs) and advance the state-of-the-art in HRA. Many technical reports have been published and numerous papers have been presented in national and international conferences on the various EPRI HRA projects. This paper is an attempt to summarize a decade of research in this area with an emphasis on recent advancements made towards development of a simulator-based HRA methodology using data from NPP simulators. HRA frameworks, models, data and computer codes are discussed, and areas for further research are pointed out. Part I herein covers the frameworks, models and data. Part II of the paper (see this issue, pp. 57–66) discusses the PC-based software developed to facilitate the process of simulator data collection and analysis as well as the assessment of human reliability.},
	language = {en},
	number = {1},
	urldate = {2021-08-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Moieni, P. and Spurgin, A. J. and Singh, A.},
	month = jan,
	year = {1994},
	pages = {27--55},
}

@article{patriarca_human_2020,
	title = {Human reliability analysis: {Exploring} the intellectual structure of a research field},
	volume = {203},
	issn = {0951-8320},
	shorttitle = {Human reliability analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020306037},
	doi = {10.1016/j.ress.2020.107102},
	abstract = {Humans play a crucial role in modern socio-technical systems. Rooted in reliability engineering, the discipline of Human Reliability Analysis (HRA) has been broadly applied in a variety of domains in order to understand, manage and prevent the potential for human errors. This paper investigates the existing literature pertaining to HRA and aims to provide clarity in the research field by synthesizing the literature in a systematic way through systematic bibliometric analyses. The multi-method approach followed in this research combines factor analysis, multi-dimensional scaling, and bibliometric mapping to identify main HRA research areas. This document reviews over 1200 contributions, with the ultimate goal of identifying current research streams and outlining the potential for future research via a large-scale analysis of contributions indexed in Scopus database.},
	language = {en},
	urldate = {2021-08-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Patriarca, Riccardo and Ramos, Marilia and Paltrinieri, Nicola and Massaiu, Salvatore and Costantino, Francesco and Di Gravio, Giulio and Boring, Ronald Laurids},
	month = nov,
	year = {2020},
	keywords = {Bibliometrics, Human factor, Human reliability assessment, Literature review, Scientometrics},
	pages = {107102},
}

@article{chang_cognitive_2007,
	title = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents: {Part} 5: {Dynamic} probabilistic simulation of the {IDAC} model},
	volume = {92},
	issn = {0951-8320},
	shorttitle = {Cognitive modeling and dynamic probabilistic simulation of operating crew response to complex system accidents},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832006001256},
	doi = {10.1016/j.ress.2006.05.012},
	abstract = {This is the last in a series of five papers that discuss the Information Decision and Action in Crew (IDAC) context for human reliability analysis (HRA) and example application. The model is developed to probabilistically predict the responses of the control room operating crew in nuclear power plants during an accident, for use in probabilistic risk assessments (PRA). The operator response spectrum includes cognitive, emotional, and physical activities during the course of an accident. This paper describes a dynamic PRA computer simulation program, accident dynamics simulator (ADS), developed in part to implement the IDAC model. This paper also provides a detailed example of implementing a simpler version of IDAC, compared with the IDAC model discussed in the first four papers of this series, to demonstrate the practicality of integrating a detailed cognitive HRA model within a dynamic PRA framework.},
	language = {en},
	number = {8},
	urldate = {2021-08-20},
	journal = {Reliability Engineering \& System Safety},
	author = {Chang, Y. H. J. and Mosleh, A.},
	month = aug,
	year = {2007},
	keywords = {Cognitive simulation, Dynamic probabilistic risk assessment, Human reliability analysis},
	pages = {1076--1101},
}

@misc{noauthor_esa_nodate,
	title = {{ESA} reviews {COVID} impacts on supply and demand : {Uranium} \& {Fuel} - {World} {Nuclear} {News}},
	url = {https://world-nuclear-news.org/Articles/ESA-reviews-COVID-impacts-on-supply-and-demand},
	urldate = {2021-08-20},
}

@misc{noauthor_development_nodate,
	title = {Development of risk assessment framework and the case study for a spent fuel pool of a nuclear power plant {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S1738573320308731?token=E3A1BD627F2AB920183D361360E7AD22162BCA56BEED41058F855689C951C2600B2A8F127F5778B0E84421F2EE66638D&originRegion=us-east-1&originCreation=20210819024631},
	language = {en},
	urldate = {2021-08-19},
	doi = {10.1016/j.net.2020.09.011},
}

@book{jaehyun_probabilistic_2016,
	title = {Probabilistic {Risk} {Assessment} of {Cask} {Drop} {Accident} considering {Human} {Errors} during on-site {Spent} {Nuclear} {Fuel} {Transportation}},
	abstract = {PRA (Probabilistic Risk Assessment) of cask drop accident during on-site SNF (Spent Nuclear Fuel) transportation between SFP (Spent Fuel Pool) and wharf in NPP site was done in this research. Modified process of cask storage system was used. Based on modified process with height and state of cask, drop accident scenarios were invented. Bolted metal cask is selected as a target cask, which is composed of four parts: 21 fuel assemblies, cask body, 2 cask lids, and 2 impact limiters. Based on the results of FDR (Fuel Damage Ratio) and Release Fraction from cask to environment (RFc-e) from the simulation of ABAQUS, source term from cask drop accident was calculated. For all stages, side drop was applied. With the source term, risk to each person in LPZ (Low Population Zone) was calculated by Hotspot code. The total risk in LPZ with 45,000 MWD/MTU burn-up SNFs was calculated as 1.906E-06 man-person/transport for rubber o-ring case, and 8.413E-06 for metal o-ring case.},
	author = {Jaehyun, Ham and Almomani, Belal and Christian, Robby and Kang, Hyun},
	month = oct,
	year = {2016},
}

@misc{noauthor_reliability_nodate,
	title = {The {Reliability} {Research} and {Risk} {Analysis} of {Spent} {Fuel} {Pool} under {Internal} {Fire} - {ProQuest}},
	url = {https://www.proquest.com/openview/8441c8cb4c5495164db9884947a96e50/1?pq-origsite=gscholar&cbl=4998669},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	urldate = {2021-08-19},
}

@book{national_research_council_lessons_2014,
	address = {Washington, DC},
	title = {Lessons {Learned} from the {Fukushima} {Nuclear} {Accident} for {Improving} {Safety} of {U}.{S}. {Nuclear} {Plants}},
	isbn = {978-0-309-27253-7},
	url = {https://www.nap.edu/catalog/18294/lessons-learned-from-the-fukushima-nuclear-accident-for-improving-safety-of-us-nuclear-plants},
	abstract = {The March 11, 2011, Great East Japan Earthquake and tsunami sparked a humanitarian disaster in northeastern Japan. They were responsible for more than 15,900 deaths and 2,600 missing persons as well as physical infrastructure damages exceeding \$200 billion. The earthquake and tsunami also initiated a severe nuclear accident at the Fukushima Daiichi Nuclear Power Station. Three of the six reactors at the plant sustained severe core damage and released hydrogen and radioactive materials. Explosion of the released hydrogen damaged three reactor buildings and impeded onsite emergency response efforts. The accident prompted widespread evacuations of local populations, large economic losses, and the eventual shutdown of all nuclear power plants in Japan.
Lessons Learned from the Fukushima Nuclear Accident for Improving Safety and Security of U.S. Nuclear Plants is a study of the Fukushima Daiichi accident. This report examines the causes of the crisis, the performance of safety systems at the plant, and the responses of its operators following the earthquake and tsunami. The report then considers the lessons that can be learned and their implications for U.S. safety and storage of spent nuclear fuel and high-level waste, commercial nuclear reactor safety and security regulations, and design improvements. Lessons Learned makes recommendations to improve plant systems, resources, and operator training to enable effective ad hoc responses to severe accidents. This report's recommendations to incorporate modern risk concepts into safety regulations and improve the nuclear safety culture will help the industry prepare for events that could challenge the design of plant structures and lead to a loss of critical safety functions.
In providing a broad-scope, high-level examination of the accident, Lessons Learned is meant to complement earlier evaluations by industry and regulators. This in-depth review will be an essential resource for the nuclear power industry, policy makers, and anyone interested in the state of U.S. preparedness and response in the face of crisis situations.},
	language = {English},
	publisher = {The National Academies Press},
	author = {{National Research Council}},
	year = {2014},
	doi = {10.17226/18294},
	keywords = {Conflict and Security Issues, Energy and Energy Conservation, Environment and Environmental Studies},
}

@techreport{mcdowell_advanced_nodate,
	title = {Advanced {Nuclear} {Reactor} {Plant} {Parameter} {Envelope} and {Guidance}},
	abstract = {Pacific Northwest National Laboratory (PNNL) is supporting the National Reactor Innovation Center (NRIC) at Idaho National Laboratory (INL) by developing advanced nuclear reactor plant parameter envelopes (PPEs) to facilitate environmental reviews of potential future advanced reactor demonstration projects at INL and elsewhere in the United States. Two PPEs are developed in this report for two size ranges: (1) microreactors, which are defined for this PPE as single units with outputs of 60 MWt or less, and (2) small- to medium-sized advanced reactors with outputs above 60 MWt up to 1,000 MWt.},
	language = {en},
	author = {McDowell, BK and Goodman, D},
	pages = {150},
}

@book{till_radiological_2008,
	address = {Oxford ; New York},
	title = {Radiological risk assessment and environmental analysis},
	isbn = {978-0-19-512727-0},
	language = {en},
	publisher = {Oxford University Press},
	editor = {Till, John E. and Grogan, Helen A.},
	year = {2008},
	keywords = {Accidents, Radiation, Environmental Exposure, Environmental Monitoring, Health risk assessment, Radiation, Radiation Injuries, Radiation dosimetry, Radioactive Pollutants, Risk Assessment, Safety measures, adverse effects, methods, prevention \& control},
}

@article{allison_development_2020,
	title = {Development and {Preliminary} {Assessment} of the new {ASYST} - {ISA} {Integral} {Analysis} {BEPU} {Code} using the {PBF} {SFD}-{ST} {Bundle} {Heating} and {Melting} {Experiment}, a {Typical} {BWR} {Under} {Fukushima}-{Daiichi}-{Accident}-{Like} {Thermal} {Hydraulic} {Conditions} and {PWR} for a {Steam} {Line} {Break} in the {Containment}},
	abstract = {ASYST (Adaptive SYStem Thermal-hydraulics) - ISA (Integral Simulation and Analysis) is a new code being developed jointly under the direction of the organizations noted above that combines the capabilities of SCDAPSIM and SAMPSON. The thermal hydraulic module, ASYST-THA, replaces the original US NRC-developed RELAP5 code used in RELAP/SCDAPSIM/MOD3.x and THA used in SAMPSON with new system level hydrodynamic options that include multidimensional, multi fluid models originally developed by ISS and IAE. The ASYST reactor-specific modeling options include modules describing the behavior of (a) the core/fuel assembly structures, (b) late phase debris/melt relocation, (c) the containment including melt spreading and molten core-concrete interactions, and (d) fission product release and transport. The core/fuel assembly behavior module uses derivatives of the SCDAPSIM/MOD3.x models and correlations while the late phase debris/melt relocation module uses a combination of SCDAPSIM/MOD3.x (2D based) models and SAMPSON MCRA, DCA, DSA (3D-based) models. The fission product release and transport module uses combinations of models from SCDAPSIM/MOD3.x and SAMPSON. The core-concrete interaction module uses a SCDAPSIM-based porous media model in combination with SAMPSON’s Debris-Concrete Interaction (DCRA) models and correlations. The reactor vessel, reactor coolant system and containment thermal hydraulic behavior is described by ASYST-THA in combination with the SAMPSON hydrogen combustion, hydrogen detonation and steam explosion modules, HYNA, DDOC and VESUVIUS, respectively. Funding and additional technical contributions for the development of ASYST comes from the contributors to the international SCDAP Development and Training Program (SDTP).},
	language = {en},
	author = {Allison, C M and Hohorst, J K and Ezzidi, A and Naitoh, M and Pericas, Raimon},
	year = {2020},
	pages = {12},
}

@article{noauthor_review_nodate,
	title = {A {Review} of {Uncertainty} {Quantification} in {Deep} {Learning}: {Techniques}, {Applications} and {Challenges}},
	url = {https://arxiv.org/pdf/2011.06225.pdf},
	urldate = {2021-08-06},
}

@misc{noauthor_physics-informed_nodate,
	title = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Physics-informed neural networks},
	url = {https://reader.elsevier.com/reader/sd/pii/S0021999118307125?token=6823840954B40A03B02C2E80B6134CC4211860C4CC2B7A84B510EE88AF220FE58F5140678A5CCDB19852DFA79DE06658&originRegion=us-east-1&originCreation=20210812153552},
	language = {en},
	urldate = {2021-08-12},
	doi = {10.1016/j.jcp.2018.10.045},
}

@techreport{sandia_national_laboratories_handbook_2003,
	address = {Washington, D.C},
	title = {Handbook of {Parameter} {Estimation} for {Probabilistic} {Risk} {Assessment}},
	number = {NUREG/CR-6823},
	author = {{Sandia National Laboratories} and U.S. Nuclear Regulatory Commission},
	month = sep,
	year = {2003},
}

@techreport{idaho_national_engineering_and_environmental_laboratory_rates_1999,
	title = {Rates of {Initiating} {Events} at {U}.{S}. {Nuclear} {Power} {Plants}: 1987 - 1995},
	url = {https://www.nrc.gov/docs/ML0705/ML070580080.pdf},
	number = {NUREG/CR-5750},
	urldate = {2021-02-24},
	author = {Idaho National Engineering {and} Environmental Laboratory},
	year = {1999},
}

@book{noauthor_technical_2019,
	address = {Vienna},
	series = {Safety {Reports} {Series}},
	title = {Technical {Approach} to {Probabilistic} {Safety} {Assessment} for {Multiple} {Reactor} {Units}},
	isbn = {978-92-0-102618-7},
	url = {https://www.iaea.org/publications/12228/technical-approach-to-probabilistic-safety-assessment-for-multiple-reactor-units},
	number = {96},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2019},
}

@techreport{noauthor_guidelines_nodate,
	title = {Guidelines for {Preparing} and {Reviewing} {Applications} for the  {Licensing} of {Non}-{Power} {Reactors} {Standard} {Review} {Plan} and  {Acceptance} {Criteria}},
	number = {NUREG-1537, Part 2},
	institution = {Office of Nuclear Reactor Regulation, U.S. Nuclear Regulatory Commission},
}

@techreport{carolina_pulstar_nodate,
	title = {{PULSTAR} {REACTOR} {UPDATED} {SAFETY} {ANALYSIS} {REPORT}},
	language = {en},
	number = {ML17201Q129},
	author = {Carolina, North},
	pages = {424},
}

@techreport{noauthor_estimating_nodate,
	title = {Estimating {Loss}-of-{Coolant} {Accident} ({LOCA}) {Frequencies} {Through} the {Elicitation} {Process}},
	language = {en},
	number = {NUREG-1829 Vol 1},
	pages = {232},
}

@techreport{noauthor_pipe_nodate,
	title = {Pipe {Failures} in {U}.{S}. {Commercial} {Nuclear} {Power} {Plants}},
	url = {https://www.epri.com/research/products/TR-100380},
	urldate = {2021-08-10},
}

@misc{noauthor_protective_nodate,
	title = {Protective {Action} {Guides} ({PAGs}) {\textbar} {US} {EPA}},
	url = {https://www.epa.gov/radiation/protective-action-guides-pags},
	urldate = {2021-08-05},
}

@misc{noauthor_part_nodate,
	title = {{PART} 20—{STANDARDS} {FOR} {PROTECTION} {AGAINST} {RADIATION}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part020/index.html},
	urldate = {2021-08-05},
}

@incollection{noauthor_loadstrength_2015,
	title = {Load–{Strength} ({Demand}-{Capacity}) {Models}},
	isbn = {978-1-118-87319-9},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118873199.ch6},
	abstract = {Reliability is often derived from the probability of violating a limit (failure) state. The load-strength interference model is a special case of the general reliability model, where only two controlling random variables are present: strength and load. If a load-strength interference is present, the reliability on demand equals the probability that strength will be greater than load. The load-strength interference integral can be derived if the integration is performed between the lower and the upper bound of the load. The load-strength integral can be solved numerically using the Simpson's method. This approach is illustrated in this chapter by a numerical example related to calculating the risk of failure of a critical component. Load and strength are assumed to be statistically independent, normally distributed random variables. The chapter also presents a discussion on reliability and risk analysis based on the load-strength interference approach.},
	language = {en},
	urldate = {2021-08-03},
	booktitle = {Reliability and {Risk} {Models}},
	publisher = {John Wiley \& Sons, Ltd},
	year = {2015},
	doi = {10.1002/9781118873199.ch6},
	note = {Section: 6
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118873199.ch6},
	keywords = {Simpson method, demand-capacity models, general reliability model, load-strength integrals, load-strength interference model, reliability model, risk analysis},
	pages = {119--137},
}

@article{russell_computer_nodate,
	title = {Computer {Science} {Department} {University} of {California}, {Los} {Angeles}, {CA} 90095},
	language = {en},
	author = {Russell, Stuart},
	pages = {7},
}

@inproceedings{li_nrc_2015,
	address = {Sun Valley, Idaho},
	title = {{NRC} {Research} on {Digital} {Modeling} for {Use} in {PRA}},
	volume = {1 of 2},
	author = {Li, Ming and Coyne, Kevin},
	month = apr,
	year = {2015},
	pages = {393--398},
}

@inproceedings{siu_knowledge_2015,
	address = {Sun Valley, Idaho},
	title = {Knowledge {Engineering} {Tools}-{Ready} to {Support} {Risk}-{Informed} {Decision} {Making}?},
	volume = {1 of 2},
	author = {Siu, Nathan and Margaret, Tobin and Appignani, Peter and Coyne, Kevin},
	month = apr,
	year = {2015},
	pages = {84--90},
}

@inproceedings{diaconeasa_ads-idac_2017,
	address = {Philadelphia, PA},
	title = {The {ADS}-{IDAC} {Dynamic} {Platform} with {Dynamically} {Linked} {System} {Fault} {Trees}},
	isbn = {978-1-5108-5180-1},
	shorttitle = {International {Topical} {Meeting} on {Probabilistic} {Safety} {Assessment} and {Analysis} ({PSA} 2017)},
	language = {eng},
	author = {Diaconeasa, Mihai A. and Mosleh, Ali},
	year = {2017},
}

@article{seong_analysis_2018,
	title = {Analysis of the technical status of multiunit risk assessment in nuclear power plants},
	volume = {50},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573317301870},
	doi = {10.1016/j.net.2017.12.015},
	abstract = {Since the Fukushima Daiichi nuclear disaster, concern and worry about multiunit accidents have been increasing. Korea has a higher urgency to evaluate its site risk because its number of nuclear power plants (NPPs) and population density are higher than those in other countries. Since the 1980s, technical documents have been published on multiunit probabilistic safety assessment (PSA), but the Fukushima accident accelerated research on multiunit PSA. It is therefore necessary to summarize the present situation and draw implications for further research. This article reviews journal and conference papers on multiunit or site risk evaluation published between 2011 and 2016. The contents of the reviewed literature are classified as research status, initiators, and methodologies representing dependencies, and the insights and conclusions are consolidated. As of 2017, the regulatory authority and nuclear power utility have launched a full-scale project to assess multiunit risk in Korea. This article provides comprehensive reference materials on the necessary enabling technology for subsequent studies of multiunit or site risk assessment.},
	language = {en},
	number = {3},
	urldate = {2021-08-02},
	journal = {Nuclear Engineering and Technology},
	author = {Seong, Changkyung and Heo, Gyunyoung and Baek, Sejin and Yoon, Ji Woong and Kim, Man Cheol},
	month = apr,
	year = {2018},
	keywords = {Multiunit, Nuclear Power Plant, Probabilistic Safety Assessment, Site Risk Assessment},
	pages = {319--326},
}

@book{tester_sustainable_2005,
	title = {Sustainable {Energy}: {Choosing} {Among} {Options}},
	isbn = {978-0-262-20153-7},
	shorttitle = {Sustainable {Energy}},
	abstract = {Human survival depends on a continuing energy supply, but the need for ever-increasing amounts of energy poses a dilemma: How can we provide the benefits of energy to the population of the globe without damaging the environment, negatively affecting social stability, or threatening the well-being of future generations? The solution will lie in finding sustainable energy sources and more efficient means of converting and utilizing energy. This textbook is designed for advanced undergraduate and graduate students as well as others who have an interest in exploring energy resource options and technologies with a view toward achieving sustainability. It clearly presents the trade-offs and uncertainties inherent in evaluating and choosing different energy options and provides a framework for assessing policy solutions.Sustainable Energy includes illustrative examples, problems, references for further reading, and links to relevant Web sites. Outside the classroom, the book is a resource for government, industry, and nonprofit organizations. The first six chapters provide the tools for making informed energy choices. They examine the broader aspects of energy use, including resource estimation, environmental effects, and economic evaluations. Chapters 7-15 review the main energy sources of today and tomorrow, including fossil fuels, nuclear power, biomass, geothermal energy, hydropower, wind energy, and solar energy, examining their technologies, environmental impacts, and economics. The remaining chapters treat energy storage, transmission, and distribution; the electric power sector; transportation; industrial energy usage; commercial and residential buildings; and synergistic complex systems. Sustainable Energy addresses the challenges of integrating diverse factors and the importance for future generations of the energy choices we make today.},
	language = {en},
	publisher = {MIT Press},
	author = {Tester, Jefferson W. and Drake, Elisabeth M. and Driscoll, Michael J. and Golay, Michael W. and Peters, William A.},
	year = {2005},
	keywords = {Nature / Environmental Conservation \& Protection, Science / Energy},
}

@inproceedings{lo_frano_external_2014,
	address = {Prague, Czech Republic},
	title = {External {Event} {Risk} {Assessment}: {Methodology} and {Application}},
	isbn = {978-0-7918-4596-7},
	shorttitle = {External {Event} {Risk} {Assessment}},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE22/45967/Prague,%20Czech%20Republic/250826},
	doi = {10.1115/ICONE22-31222},
	abstract = {The 2011 Fukushima accident revealed various gaps related to probabilistic approach, used for the plant risk assessment against external events. In consideration of that and analysing the evolution of the accident scenario, some issues need to be re-considered and/or improved for a reliable NPP risk evaluation in Fukushima conditions.},
	language = {en},
	urldate = {2021-08-01},
	booktitle = {Volume 6: {Nuclear} {Education}, {Public} {Acceptance} and {Related} {Issues}; {Instrumentation} and {Controls} ({I}\&{C}); {Fusion} {Engineering}; {Beyond} {Design} {Basis} {Events}},
	publisher = {American Society of Mechanical Engineers},
	author = {Lo Frano, Rosa and Burgazzi, Luciano},
	month = jul,
	year = {2014},
	pages = {V006T15A032},
}

@article{hudson_approach_2019,
	title = {{AN} {APPROACH} {TO} {DEVELOPING} {AN} {INTEGRATED} {SITE} {PROBABILISTIC} {RISK} {ASSESSMENT} ({PRA})},
	language = {en},
	author = {Hudson, D W},
	year = {2019},
	pages = {10},
}

@article{youngblood_quantitative_2019,
	title = {{QUANTITATIVE} {RISK} {ANALYSIS} {SUPPORT} {TO} {DECISION}-{MAKING} {FOR} {NEW} {SYSTEMS}},
	language = {en},
	author = {Youngblood, R and Dezfuli, H},
	year = {2019},
	pages = {8},
}

@article{kantarcioglu_development_2019,
	title = {{DEVELOPMENT} {OF} 3+ {LEVEL} {PROBABILISTIC} {SAFETY} {ASSESSMENT} {METHODOLOGY} {AND} {APPLICATION} {FOR} {AKKUYU} {NUCLEAR} {POWER} {PLANT}},
	language = {en},
	author = {Kantarcioglu, Veda Duman and Ergun, Sule},
	year = {2019},
	pages = {10},
}

@article{lovelace_jensen_2019,
	title = {{JENSEN} {HUGHES} 2011 {Pine} {Lake} {Road} {Suite} 1300, {Lincoln}, {NE}, 68512 {NLovelace}@jensenhughes.com and mjohnson@jensenhughes.com},
	language = {en},
	author = {Lovelace, Nicholas and Johnson, Matt},
	year = {2019},
	pages = {4},
}

@article{gordon_office_2019,
	title = {{OFFICE} {FOR} {NUCLEAR} {REGULATION} – {RISK} {INFORMED} {REGULATORY} {DECISION} {MAKING}},
	language = {en},
	author = {Gordon, Joshua and Turner, Shane},
	year = {2019},
	pages = {9},
}

@article{christian_code_2019,
	title = {{CODE} {SURROGATE} {DEVELOPMENT} {FOR} {DYNAMIC} {PRA}},
	abstract = {Layer 1 as the closest layer to fuel pellets underwent tension while Layer 3 which interfaces with coolant experienced a compression.},
	language = {en},
	author = {Christian, Robby and Kang, Hyun Gook},
	year = {2019},
	pages = {8},
}

@article{smith_india-united_2019,
	title = {{INDIA}-{UNITED} {STATES} {COLLABORATION} {ON} {ADVANCED} {DYNAMIC} {RELIABILITY} {MODELING}},
	language = {en},
	author = {Smith, Curtis L and Arul, John and Vinod, Gopika and Shukla, Darpan Krishnakumar},
	year = {2019},
	pages = {5},
}

@article{picoco_integration_2019,
	title = {{INTEGRATION} {OF} {RECOVERIES} {INTO} {DYNAMIC} {EVENT} {TREES}: {A} {CASE} {STUDY}},
	language = {en},
	author = {Picoco, Claudia and Rychkov, Valentin and Aldemir, Tunc},
	year = {2019},
	pages = {10},
}

@article{labarge_pra_2019,
	title = {{PRA} {MAINTENANCE} {AND} {PRA} {UPGRADE}},
	language = {en},
	author = {Labarge, N Reed and Maioli, Andrea and Christian, Rachel and Linthicum, Roy},
	year = {2019},
	pages = {6},
}

@inproceedings{prasad_simulation_nodate,
	address = {Charleston, SC},
	title = {Simulation {Based} {Dynamic} {Event} {Tree} {Analysis}},
	language = {en},
	urldate = {2021-08-01},
	author = {Prasad, Mahendra and Kumar, Mithilesh and Vinod, Gopika and Chattopadhyay, J. and Smith, Curtis},
	month = may,
	pages = {602--605},
}

@book{iaea_assessment_2018,
	address = {Vienna},
	title = {Assessment of {Vulnerabilities} of {Operating} {Nuclear} {Power} {Plants} to {Extreme} {External} {Events}.},
	isbn = {978-92-0-108817-8},
	url = {https://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=5233908},
	language = {en},
	urldate = {2021-08-01},
	publisher = {IAEA},
	author = {{IAEA}},
	year = {2018},
	note = {OCLC: 1021810697},
}

@book{iaea_probabilistic_2021,
	address = {S.l.},
	title = {{PROBABILISTIC} {SAFETY} {ASSESSMENT} {FOR} {SEISMIC} {EVENTS}},
	isbn = {978-92-0-131520-5},
	language = {English},
	publisher = {INTL ATOMIC ENERGY AGENCY},
	author = {{IAEA}},
	year = {2021},
	note = {OCLC: 1239650367},
}

@book{werdine_trending_2005,
	address = {Vienna},
	title = {Trending of low level events and near misses to enhance safety performance in nuclear power plants},
	url = {http://www-pub.iaea.org/MTCD/publications/PDF/te_1477_web.pdf},
	language = {en},
	urldate = {2021-08-01},
	publisher = {International Atomic Energy Agency},
	author = {Werdine, H and {Agence internationale de l'énergie atomique}},
	year = {2005},
	note = {OCLC: 1132060244},
}

@book{agence_internationale_de_lenergie_atomique_determining_2006,
	address = {Vienna},
	title = {Determining the quality of probabilistic safety assessment ({PSA}) for applications in nuclear power plants},
	isbn = {978-92-0-108706-5},
	url = {http://www-pub.iaea.org/MTCD/publications/PDF/te_1511_web.pdf},
	abstract = {This publication provides an approach for achieving the technical consistency of probabilistic safety assessments (PSAs) needed to support reliably various PSA applications. The approach involves the consideration of a set of technical features, called attributes, of the major PSA elements relevant for various applications. This document covers a Level 1 internal events at-power PSA. Nine PSA elements characterizing the major PSA tasks were defined. For each PSA element, a set of general attributes needed for all PSA applications and special attributes needed for specific PSA applications were elaborated. A comprehensive list of PSA applications was compiled. For each PSA application, a brief description of the purpose of the application and the way the PSA can be used to support it were provided along with the information on what PSA results and metrics can be used in the decision making process. The document provides a mapping of the special attributes to the considered PSA applications.},
	language = {en},
	urldate = {2021-08-01},
	publisher = {International Atomic Energy Agency},
	author = {{Agence internationale de l'énergie atomique}},
	year = {2006},
	note = {OCLC: 1132033013},
}

@misc{noauthor_us_nodate,
	title = {{US} {NRC}: 10 {CFR} {Part} 52- {Licenses}, {Certifications}, and {Approvals} for {Nuclear} {Power} {Pants}.},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part052/},
	urldate = {2020-09-05},
}

@book{noauthor_post-challenger_1988,
	address = {Washington, D.C.},
	title = {Post-{Challenger} {Evaluation} of {Space} {Shuttle} {Risk} {Assessment} and {Management}},
	isbn = {978-0-309-54234-0},
	url = {http://www.nap.edu/catalog/10616},
	urldate = {2021-07-30},
	publisher = {National Academies Press},
	month = jan,
	year = {1988},
	doi = {10.17226/10616},
	note = {Pages: 10616},
}

@misc{marsnasagov_historical_nodate,
	title = {Historical {Log} {\textbar} {Missions}},
	url = {https://mars.nasa.gov/mars-exploration/missions/historical-log},
	abstract = {NASA’s real-time portal for Mars exploration, featuring the latest news, images, and discoveries from the Red Planet.},
	language = {en},
	urldate = {2021-07-30},
	journal = {NASA’s Mars Exploration Program},
	author = {mars.nasa.gov},
}

@inproceedings{boyer_multi-hazard_2017,
	address = {Pittsburgh, PA},
	title = {Multi-hazard risk aggregation in support of risk-informed decision making},
	volume = {1 of 2},
	author = {Boyer, Robert and Thornsbury, Eric and Levinson, Stanley and Maioli, Andrea},
	month = sep,
	year = {2017},
	pages = {442--451},
}

@inproceedings{coyne_dynamic_2008,
	address = {Honh Kong, China},
	title = {Dynamic {PRA} approach for the prediction of operator errors},
	booktitle = {{IAPSAM}},
	author = {Coyne, Kevin and Mosleh, Ali},
	month = may,
	year = {2008},
	pages = {3105--3113},
}

@inproceedings{dennis_development_2017,
	address = {Pittsburgh, PA},
	title = {Development of integrated site risk using the multi-unit dynamic probabilistic risk asessment ({MU}-{DPRA}) methodology},
	volume = {1 of 2},
	author = {Dennis, Matthew and Modarres, Mohammed and Mosleh, Ali},
	month = sep,
	year = {2017},
	pages = {492--501},
}

@article{hakata_improvement_nodate,
	title = {{IMPROVEMENT} {OF} {EXTERNAL} {EVENT} ( {TSUNAMI} {SEISMIC}) {PSA} {APROACH} {FOR} {SEVERE} {ACCIDENTS} {OF} {NUCLEAR} {POWER} {PLANTS}},
	abstract = {Fukushima Daiichi nuclear power plant was subjected to and experienced significant damages from a large tsunami induced by the East Great Japan Earthquake. The cores at three units of the plant were severely damaged. The main challenges at the plant were preventing tsunami inundation to the site, preventing flooding of the vital safety systems and components and implementing effective accident management to mitigate the station blackout (SBO) and loss of ultimate heat sink.},
	language = {en},
	author = {Hakata, Tadakuni and Johnson, David H},
	pages = {12},
}

@inproceedings{nasif_dynamic_2019,
	address = {Ibaraki, Japan},
	title = {Dynamic event tree tool for the safety assessment of a nuclear power plant},
	booktitle = {{ICONE}-27},
	author = {Nasif, Hesham and Kawai, Katsunori},
	month = may,
	year = {2019},
}

@inproceedings{mandelli_dynamic_2017,
	address = {Pittsburgh, PA},
	title = {Dynamic {PRA} of a {Multi}-{Unit} {Plant}},
	volume = {2 of 2},
	author = {Mandelli, D. and Parisi, C. and Alfonsi, A. and Maljovec, D. and Germain, S. St},
	month = sep,
	year = {2017},
	pages = {1061--1068},
}

@article{valentin_published_nodate,
	title = {Published on behalf of the lnternational {Commission} on {Radiological} {Protection}},
	abstract = {I. INTRODUCTION 1.1. Purpose ofthis docum 1.2. Biokinetic models ....... 1.2.1. Respiratory tra 1.2.2. Gastro-intestinr 1.2.3. Entry through i 1.2.4. Systemic circul: 1.3. The Human Respirato 1.3.1. Main changes f 1.3.2. Outline of the I 1.4. Choice between referel 1.4.1. Use of the HR! 1.4.2. Use of specific ' 1.5. Outline of the docume 1.5.1. Main text, Chal 1.5.2. Annexes...........},
	language = {en},
	author = {Valentin, J},
	pages = {326},
}

@article{noauthor_chapter_nodate,
	title = {Chapter {I} introduction},
	language = {en},
	pages = {65},
}

@book{noauthor_age-dependent_1996,
	address = {Oxford},
	series = {{ICRP} publication {Radiation} protection},
	title = {Age-dependent doses to members of the public from intake of radionuclides. 4: {Inhalation} dose coefficients},
	isbn = {978-0-08-042736-2},
	shorttitle = {Age-dependent doses to members of the public from intake of radionuclides. 4},
	language = {en},
	number = {71},
	publisher = {Pergamon Press},
	year = {1996},
}

@article{suman_artificial_2021,
	title = {Artificial intelligence in nuclear industry: {Chimera} or solution?},
	volume = {278},
	issn = {0959-6526},
	shorttitle = {Artificial intelligence in nuclear industry},
	url = {https://www.sciencedirect.com/science/article/pii/S0959652620340671},
	doi = {10.1016/j.jclepro.2020.124022},
	abstract = {Nuclear industry is in crisis and innovation is the central theme of its survival in future. Artificial intelligence has made a quantum leap in last few years. This paper comprehensively analyses recent advancement in artificial intelligence for its applications in nuclear power industry. A brief background of machine learning techniques researched and proposed in this domain is outlined. A critical assessment of various nuances of artificial intelligence for nuclear industry is provided. Lack of operational data from real power plant especially for transients and accident scenario is a major concern regarding the accuracy of intelligent systems. There is no universally agreed opinion among researchers for selecting the best artificial intelligence techniques for a specific purpose as intelligent systems developed by various researchers are based on different data set. Interlaboratory work frame or round-robin programme to develop the artificial intelligent tool for any specific purpose, based on the same data base, can be crucial in claiming the accuracy and thus the best technique. The black box nature of artificial techniques also poses a serious challenge for its implementation in nuclear industry, as it makes them prone to fooling.},
	language = {en},
	urldate = {2021-07-26},
	journal = {Journal of Cleaner Production},
	author = {Suman, Siddharth},
	month = jan,
	year = {2021},
	keywords = {ANN, Artificial intelligence, Clean energy, Machine learning, Sustainability},
	pages = {124022},
}

@article{hussein_emerging_2020,
	title = {Emerging small modular nuclear power reactors: {A} critical review},
	volume = {5},
	issn = {26660326},
	shorttitle = {Emerging small modular nuclear power reactors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666032620300259},
	doi = {10.1016/j.physo.2020.100038},
	abstract = {This paper reviews the smallness, modularity and reactor-design aspects of emerging small modular reactors (SMRs). It is shown that small (whether in physical size or power level) reactors are not new, but offer economic and ﬂexibility advantages that allow their use in a variety of applications. The different deﬁnitions of modularity are reviewed, including modularity in design, process intensiﬁcation, manufacturing and construction. It is shown that these forms of modularity when applied to SMRs have some advantages, but also have some challenges that need to be addressed if their full potential is to be realized. Even if these forms of modularity are not fully utilized, the lower power ( 300 MW electrical) of SMRs allows the formation of larger power plants by incremental addition of reactor units, in the so-called scale modularity. The paper reviews the unique features of emerging SMR designs, and compares them to those of the early era of nuclear power. It is shown that while many modern SMR designs incorporate well-proven features that were tested and proven in early reactors. others introduce aspects of Generation IV reactors, in terms of inherent and/or passive safety. Given the promise of SMRs as means to reduce greenhouse gas emissions and their ability to supply reliable and base-load power, the licensing of such reactors by national regulators will provide a boost to their acceptability and adaptability as a player in combating climate change.},
	language = {en},
	urldate = {2021-07-26},
	journal = {Physics Open},
	author = {Hussein, Esam M.A.},
	month = dec,
	year = {2020},
	pages = {100038},
}

@article{wu_nuclear_2021,
	title = {Nuclear non‐proliferation review and improving proliferation resistance assessment in the future},
	volume = {45},
	issn = {0363-907X, 1099-114X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/er.5486},
	doi = {10.1002/er.5486},
	abstract = {An increasing number of countries have taken nuclear energy as a preferred approach in response to the environment deterioration and energy supply deficit. The rapid expansion of nuclear technologies, however, would pose a great challenge to nuclear non-proliferation, especially for the Generation IV nuclear reactor systems, which significantly differ from current nuclear fuel systems. This paper gives an overview of non-proliferation research activities worldwide and outlines the existing problems, especially in non-proliferation assessment. Because of numerous processes and various types of variables involved in nuclear fuel cycles (NFC), it is difficult to obtain a quantitative and objective assessment on non-proliferation. In addition, the influences imposed by national nuclear policy on non-proliferation have been rarely studied because of their large uncertainties, which may not precisely reflect the real non-proliferation status in a specific country. In view of the above issues, we put forward an assessment framework by considering impact factors of national nuclear policy and by employing multi-mathematical models to address some of the issues including subjectivity and uncertainties in the current assessment methodologies.},
	language = {en},
	number = {8},
	urldate = {2021-07-26},
	journal = {International Journal of Energy Research},
	author = {Wu, Jianhui and Ma, Yuwen and Yu, Chenggang and Zou, Chunyan and Cai, Xiangzhou and Chen, Jingen},
	month = jun,
	year = {2021},
	pages = {11399--11422},
}

@incollection{khan_10_2020,
	series = {Woodhead {Publishing} {Series} in {Energy}},
	title = {10 - {Nonpower} applications of nuclear technology},
	isbn = {978-0-12-818483-7},
	url = {https://www.sciencedirect.com/science/article/pii/B978012818483700010X},
	abstract = {With nuclear engineering development, nonelectric as well as nonpower applications of nuclear and radiation technologies become more important, and their utilization is expected to increase dramatically in the near future. The modern state of this field and its main achievements are discussed in this chapter. First, a short review of nonelectrical usage of nuclear energy is given, such as district heating, industrial process heat applications, and water desalination to distinguish between nonelectric and nonpower types of applications. The main part of the chapter deals with the current state of radiation applications in agrosciences including radiation stimulation and inhibition of growth and development in plants and animals, pest control, and food irradiation for microbiological decontamination. The basics of radiation biology are given, which helps in improving the understanding of radiation effects in a living organism. Also, issues of the safety of irradiated food are covered in this chapter. Furthermore, the main approaches of nuclear medicine are explained both for diagnostic and therapeutic purposes, as well as other nuclear technologies used in healthcare-related fields like radiation sterilization, sterile insect technique (SIT), and environment contamination control. Also, other spheres of nuclear nonenergetic applications are mentioned in examples of material sciences and nondestructive control systems, instrumental analysis, and radioisotope dating.},
	booktitle = {Nuclear {Reactor} {Technology} {Development} and {Utilization}},
	publisher = {Woodhead Publishing},
	author = {Udalova, Alla A.},
	editor = {Khan, Salah Ud-Din and Nakhabov, Alexander},
	year = {2020},
	doi = {https://doi.org/10.1016/B978-0-12-818483-7.00010-X},
	keywords = {Food irradiation, Nonenergetic applications, Nuclear medicine, Radiation in pest control, Radiation sterilization, Radiation stimulation, Radiation therapy, Radioisotopes},
	pages = {319--341},
}

@article{smidts_probabilistic_1994,
	title = {Probabilistic dynamics: {A} comparison between continuous event trees and a discrete event tree model},
	volume = {44},
	issn = {0951-8320},
	shorttitle = {Probabilistic dynamics},
	url = {https://www.sciencedirect.com/science/article/pii/0951832094900116},
	doi = {10.1016/0951-8320(94)90011-6},
	abstract = {The feeling that dynamics and their interaction with the random evolution of parameters was ill-treated in classical probabilistic safety assessment methodologies led to the development of probabilistic dynamics methodologies. These methods explicitly model the mutual influence between physical variables, operators and components, using different basic assumptions. This paper is a first attempt at a systematic comparison between two such methodologies, namely, DYLAM and the continuous event tree (CET) theory on a simple problem. The problem involves one bistate component and one physical variable whose evolution depends on the component current state and that should not, in any case, cross a prespecified threshold. The methods are briefly discussed. In particular, we show how DYLAM can be derived as a special case of the CET theory. The numerical implementation of each method is also reviewed. Each method is then applied to the specific problem. The probability of system failure over time is compared to its real, analytically derived, value. We focus on key issues such as exactness, stability and efficiency. We point out the main differences between the methods and draw a first set of conclusions as to their respective fields of application, recognizing, however, that the analysis should be carried further on more complex problems to reach definitive conclusions.},
	language = {en},
	number = {2},
	urldate = {2021-07-23},
	journal = {Reliability Engineering \& System Safety},
	author = {Smidts, C.},
	month = jan,
	year = {1994},
	pages = {189--206},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: 0951-8320(94)90011-6 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/0951832094900116?token=773EF3FA26A6E983B0D4613769FD1C15469EF29683AC1DA1C65BB9F833F63AAADCFFE58A6C1FCC4C1FF3E1E28403FC28&originRegion=us-east-1&originCreation=20210723192422},
	language = {en},
	urldate = {2021-07-23},
	doi = {10.1016/0951-8320(94)90011-6},
	note = {ISSN: 0951-8320},
}

@misc{noauthor_home_nodate,
	title = {Home {\textbar} {NARSIS}},
	url = {http://www.narsis.eu/},
	urldate = {2021-07-23},
}

@misc{noauthor_coronavirus_nodate,
	title = {Coronavirus disease ({COVID}-19)},
	url = {https://www.who.int/emergencies/diseases/novel-coronavirus-2019},
	urldate = {2021-07-23},
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {Reactor} {Demonstration} {Program} {\textbar} {Department} of {Energy}},
	url = {https://www.energy.gov/ne/advanced-reactor-demonstration-program},
	urldate = {2021-07-23},
}

@misc{noauthor_evidence_nodate,
	title = {Evidence {\textbar} {Facts} – {Climate} {Change}: {Vital} {Signs} of the {Planet}},
	url = {https://climate.nasa.gov/evidence/},
	urldate = {2021-07-23},
}

@misc{marsnasagov_mars_nodate,
	title = {Mars 2020 {Expanded} {Spacecraft} {Illustration}},
	url = {https://mars.nasa.gov/resources/25326/mars-2020-expanded-spacecraft-illustration},
	abstract = {This illustration depicts five major components of the Mars 2020 spacecraft. Top to bottom: cruise stage, backshell, descent stage, Perseverance rover and heat shield.},
	language = {en},
	urldate = {2021-07-23},
	journal = {NASA’s Mars Exploration Program},
	author = {mars.nasa.gov},
}

@misc{noauthor_engineering_nodate,
	title = {Engineering {Village} - {Multi}-{Hazard} without {Nuclear}},
	url = {https://www-engineeringvillage-com.prox.lib.ncsu.edu/search/quick.url?SEARCHID=6f14ae80568f41d980ad3b90393fd997&COUNT=1&usageOrigin=&usageZone=},
	urldate = {2021-07-23},
}

@article{noauthor_nureg-1407_nodate,
	title = {{NUREG}-1407, "{Procedural} and {Submittal} {Guidance} for the {Individual} {Plant} {Examination} of {External} {Events} ({IPEEE}) for {Severe} {Accident} {Vulnerabilities}," {Final} {Report}.},
	language = {en},
	pages = {98},
}

@book{international_atomic_energy_agency_extreme_1981,
	address = {International Atomic Energy Agency (IAEA)},
	title = {Extreme meteorological events in nuclear power plant siting, excluding tropical cyclones},
	isbn = {92-0-123981-5},
	url = {http://inis.iaea.org/search/search.aspx?orig_q=RN:13645265},
	abstract = {This Safety Guide deals with the extremes of meteorological variables and the extreme
meteorological phenomena in accordance with the general criteria of the Code The Guide
outlines a procedure based on the following steps: (1) The meteorological phenomena
and variables are described and classified, according to their effects on safety (2)
Data sources are identified, and data are collected (3) Meteorological variables such
as air temperature are analysed to determine their design bases; and the design basis
event in case of phenomena such as the design basis tornado is identified (4) As appropriate,
the design basis value for the variable, or the design basis for the phenomena (such
as pressure drop and maximum wind speed of the design basis tornado), is defined In
the following sections, the general procedure for evaluating the design bases of extreme
meteorological variables and phenomena is outlined The procedure is then presented
in detail for each variable or phenomenon considered The variables characterizing
the meteorological environment dealt with in this Guide are wind speed, atmospheric
precipitation, and temperature The extreme meteorological phenomena discussed here
are the tornado and, briefly, the tropical cyclone, which is discussed more extensively
in the Safety Guide on Design Basis Tropical Cyclone for Nuclear Power Plants (IAEA
Safety Series No 50-SG-S11B)},
	publisher = {IAEA},
	author = {International Atomic Energy Agency, Vienna (Austria)},
	year = {1981},
}

@book{noauthor_external_nodate,
	address = {Vienna},
	series = {Safety {Series}},
	title = {External {Man}-{Induced} {Events} in {Relation} to {Nuclear} {Power} {Plant} {Design}: {A} {Safety} {Guide}},
	isbn = {92-0-103295-1},
	url = {https://www.iaea.org/publications/5184/external-man-induced-events-in-relation-to-nuclear-power-plant-design-a-safety-guide},
	number = {50-SG-D5 (Rev. 1)},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
}

@techreport{kimura_evaluation_1989,
	address = {United States},
	title = {Evaluation of external hazards to nuclear power plants in the {United} {States}: {Other} external events},
	url = {http://inis.iaea.org/search/search.aspx?orig_q=RN:20045139},
	abstract = {In support of implementation of the Nuclear Regulatory Commission's Severe Accident
Policy, the Lawrence Livermore National Laboratory (LLNL) has performed a study of
the risk of core damage to nuclear power plants in the United States due to ''other
external events'' The broad objective has been to gain an understanding of whether
''other external events'' (the hazards not covered by previous reports) are among
the major potential accident initiators that may pose a threat of severe reactor core
damage or of large radioactive release to the environment from the reactor The ''other
external events'' covered in this report are nearby industrial/military facility accidents,
on site hazardous material storage accidents, severe temperature transients, severe
weather storms, lightning strikes, external fires, extraterrestrial activity, volcanic
activity, earth movement, and abrasive windstorms The analysis was based on two figures-of-merit,
one based on core damage frequency and the other based on the frequency of large radioactive
releases 37 refs, 8 tabs},
	author = {Kimura, C.Y. and Prassinos, P.G.},
	year = {1989},
	note = {NUREG/CR--5042-Suppl2},
	pages = {54},
}

@techreport{noauthor_approach_2009,
	type = {Regulatory {Guide}},
	title = {An {Approach} for {Determining} {The} {Technical} {Adequacy} of {Probabilistic} {Risk} {Assessment} {Results} for {Risk}-{Informed} {Activities}},
	number = {1.200, Revision 2},
	institution = {U.S. Nuclear Regulatory Commission},
	month = mar,
	year = {2009},
}

@techreport{gilbertson_approach_2018,
	type = {Regulatory {Guide}},
	title = {An {Approach} for {Using} {Probabilistic} {Risk} {Assessment} in {Risk}-{Informed} {Decisions} on {Plant}-{Specific} {Changes} to the {Licensing} {Basis}},
	number = {1.174, Revision 3},
	institution = {U.S. Nuclear Regulatory Commission},
	author = {Gilbertson, Anders},
	month = jan,
	year = {2018},
}

@inproceedings{coyne_nuclear_2012,
	address = {Helsinki,Finland},
	title = {Nuclear {Power} {Plant} {Precursor} {Risk} {Assessment} {Using} a {Dynamic} {Probabilistic} {Risk} {Method}},
	volume = {Vol.3},
	isbn = {978-1-62276-436-5},
	author = {Coyne, Kevin and Hunter, Christopher and DeMoss, Gary and Siu, Nathan and Li, Yuandan and Mosleh, Ali},
	month = jun,
	year = {2012},
	pages = {2451--2460},
}

@article{hofer_dynamic_nodate,
	title = {Dynamic {Event} {Trees} for {Probabilistic} {Safety} {Analysis}},
	abstract = {Abstract: In technical systems like nuclear power plants, an accident sequence starts with an initiating event and evolves over time through the interaction of dynamics and stochastics. This interaction is capable of producing infinitely many different sequences. Along the time line they define a continuous dynamic event tree with infinitely many branch points. At each point of time, the stochastic variability of the accident consequences is summarized by a multivariate probability distribution. A probabilistic safety analysis (PSA) requires an approximation to this distribution for selected consequence variables. It is felt that the conventional event tree analysis of Level 1 and of Level 2 PSA does often not permit a satisfactory probabilistic representation for PSA purposes. For this reason various methods of probabilistic dynamics have been suggested over the past decade. This paper presents a recent development that combines dynamic event tree analysis with Monte Carlo simulation. The advantages of this combination are explained and illustrated by a practical application involving MELCOR as the dynamics code.},
	author = {Hofer, E. and Kloos, M. and Krzykacz-hausmann, B. and Peschke, J. and Sonnenkalb, M.},
}

@article{moradi_modernizing_2020,
	title = {Modernizing risk assessment: {A} systematic integration of {PRA} and {PHM} techniques},
	volume = {204},
	issn = {0951-8320},
	shorttitle = {Modernizing risk assessment},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020306955},
	doi = {10.1016/j.ress.2020.107194},
	abstract = {Recent advances in sensing and computing technologies have resulted in an abundance of data in various formats and more processing power for using this data. Consequently, there has been an interest in using these advances to enhance modeling and assessment techniques for safety and reliability of a variety of systems. To date, this has occurred under two distinct aspects of reliability engineering. Prognostics and Health Management (PHM) has developed powerful new algorithms for understanding and predicting the mechanical and electrical devices’ health. For complex systems, the techniques of Probabilistic Risk Assessment (PRA), which provide a system-level perspective, have become increasingly dynamic. Both PHM and PRA bring unique advantages and limitations. PHM excels at data handling and supports prediction, but the methods applicable at the component level are not suitable for modeling complex engineering systems (CES). PRA provides a comprehensive approach suitable for drawing together many types of data and assessing complex systems, but is limited in the ability to exploit advanced ML methods or enable prediction. In this paper, we explore how to systematically draw together the advances in PHM and PRA to provide a more forward-looking, model- and data-driven approach for assessing and predicting the risk and health of CES.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Moradi, Ramin and Groth, Katrina M.},
	month = dec,
	year = {2020},
	keywords = {Complex systems, Deep learning, Logic modeling, Probabilistic risk assessment, Prognostics and health management (PHM)},
	pages = {107194},
}

@article{lydell_oecd-nea_nodate,
	title = {{OECD}-{NEA} {CODAP} {EVENT} {DATA} {PROJECT} {ON} {PASSIVE} {COMPONENT} {DEGRADATION} \& {FAILURES} {IN} {COMMERCIAL} {NUCLEAR} {POWER} {PLANTS}},
	abstract = {Since May 2002, the OECD/NEA has operated an event database on passive component degradation and failure. During 2002-2011 the project, referred to as OPDE, focused on piping component failure events. In May 2011, the Project Review Group approved the transition of OPDE to a new, expanded “OECD-NEA Component Operational Experience, Degradation and Aging Program (CODAP).” The objective of CODAP is to collect information on passive metallic component degradation and failures of the primary system, reactor pressure vessel internals, main process and safety systems, and support systems (i.e., ASME Code Class 1, 2 and 3 systems). It also covers non-safety related components with significant operational impact.},
	language = {en},
	author = {Lydell, Bengt and Huerta, Alejandro},
	pages = {10},
}

@article{li_simulating_nodate,
	title = {{SIMULATING} {NUCLEAR} {POWER} {PLANT} {OPERATORS}’ {USE} {OF} {KNOWLEDGE} {IN} {SITUATION} {AWARENESS}},
	abstract = {This paper introduces a model for simulating control room crew use of knowledge in accident situation assessment. Coupled with a dynamic PRA software platform (ADS) the proposed operator simulation model can be used to support detailed human reliability studies. The model is an extension of the IDAC cognitive model and is designed to mimic operator behavior in the following areas: selectively gathering information from control panel; updating the perceived information in operator’s mental model of the plant; using of knowledge and experience to explain the observed plant states and transients; making diagnosis of accidents; and taking actions in response to the dynamically changing plant condition. Some key psychological ingredients (e.g. selective attention focus, limited cognitive resources) have been incorporated in the model to enhance the realism. An overview of this model is provided with emphasis on cognitive activities associated with accident diagnosis. Detailed simulation results of an accident scenario are presented to demonstrate the model capabilities.},
	language = {en},
	author = {Li, Yuandan and Mosleh, Ali},
	pages = {12},
}

@article{kloos_mcdet_2006,
	title = {{MCDET}: {A} {Probabilistic} {Dynamics} {Method} {Combining} {Monte} {Carlo} {Simulation} with the {Discrete} {Dynamic} {Event} {Tree} {Approach}},
	volume = {153},
	issn = {0029-5639},
	shorttitle = {{MCDET}},
	url = {https://doi.org/10.13182/NSE06-A2601},
	doi = {10.13182/NSE06-A2601},
	abstract = {The MCDET method for probabilistic dynamics is a combination of Monte Carlo (MC) simulation and the Discrete Dynamic Event Tree (DDET) approach. The implementation of MCDET works in tandem with any appropriate deterministic dynamics code.MCDET was developed to achieve a more realistic modeling and analysis of complex system dynamics in the framework of probabilistic safety analyses. It is capable of accounting for aleatory (stochastic) uncertainties, which are the reason why the safety assessment is probabilistic, and for epistemic (state-of-knowledge) uncertainties, which determine the precision of the probabilistic assessment. In MCDET, discrete aleatory variables are generally treated by the DDET approach, whereas continuous aleatory variables are handled by MC simulation. For each set of values provided by the MC simulation, MCDET generates a new DDET.The paper gives a description of the MCDET method and an overview of the results that may be obtained from its application. The results presented were derived from an application of MCDET in combination with the deterministic dynamics code MELCOR for integrated severe accident simulation. For illustration purposes, the consequences in a German nuclear power plant after a station blackout were analyzed.},
	number = {2},
	urldate = {2021-07-16},
	journal = {Nuclear Science and Engineering},
	author = {Kloos, Martina and Peschke, Jörg},
	month = jun,
	year = {2006},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.13182/NSE06-A2601},
	pages = {137--156},
}

@article{johst_extension_2021,
	title = {Extension of a {Level} 2 {PSA} {Event} {Tree} {Based} on {Results} of a {Probabilistic} {Dynamic} {Safety} {Analysis} of {Induced} {Steam} {Generator} {Tube} {Rupture}},
	volume = {207},
	issn = {0029-5450},
	url = {https://doi.org/10.1080/00295450.2020.1766347},
	doi = {10.1080/00295450.2020.1766347},
	abstract = {This paper presents the approach of extending a classical generic event tree (ET) of a Level 2 Probabilistic Safety Analysis to the results of a probabilistic dynamic safety analysis. The example of creep-induced steam generator tube rupture has been chosen. The results of an Analysis of Thermal Hydraulics of Leaks and Transients with Core Degradation (ATHLET-CD)/Monte Carlo Dynamic Event Tree (MCDET) simulation analyzing the failure of reactor coolant system components by creeping in a scenario of a high-pressure core melt accident in a generic pressurized water reactor (PWR) have been implemented in the ET. From the results of these simulations, a set of parameters has been extracted and integrated into the ET along with their probability distributions. The effect of these parameters on both the progression of the severe accident sequence under consideration and the release categories of a generic German PWR plant, respectively, is discussed in this paper.},
	number = {3},
	urldate = {2021-07-16},
	journal = {Nuclear Technology},
	author = {Johst, Sören and Hage, Michael and Peschke, Jörg},
	month = mar,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295450.2020.1766347},
	keywords = {Level 2 PSA, dynamic PSA, event tree, induced steam generator rupture},
	pages = {352--362},
}

@article{parhizkar_supervised_2021,
	title = {Supervised dynamic probabilistic risk assessment of complex systems, part 2: {Application} to risk-informed decision making, practice and results},
	volume = {208},
	issn = {0951-8320},
	shorttitle = {Supervised dynamic probabilistic risk assessment of complex systems, part 2},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020308796},
	doi = {10.1016/j.ress.2020.107392},
	abstract = {One challenge that has received attention in maritime industry is assessing the risk level of dynamic positioning (DP) systems in emergency situations. Statistics from recent years have shown that the risk level of some DP operations is above the industry's risk criteria. Operators have a significant impact on incidents’ consequences by making responsive decisions. In emergencies, one is afforded little time to make a decision. Available risk models are not efficient enough to provide systems’ risk level in a short period of time. In this study, the application of a new supervised methodology to assist decision making in emergencies is proposed. This method significantly reduces the processing and execution time of a system's probabilistic risk assessment models. In this methodology, the most probable failure scenarios are generated using an optimization model. The objective of the optimization model in this study is to find scenarios with the highest occurrence probabilities. The constraints are a system's dynamic simulation and its risk model. The proposed method is applied to three incidents that occurred in the Norwegian offshore sector in previous years. The results show that the model can predict the most probable scenarios with an acceptable accuracy in a very short time.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Parhizkar, Tarannom and Utne, Ingrid Bouwer and Vinnem, Jan Erik and Mosleh, Ali},
	month = apr,
	year = {2021},
	keywords = {Cognitive models, Dynamic positioning system, Dynamic probabilistic risk assessment, Emergency situations, Risk-based decision making, Supervised algorithms},
	pages = {107392},
}

@article{parhizkar_supervised_2021-1,
	title = {Supervised {Dynamic} {Probabilistic} {Risk} {Assessment} of {Complex} {Systems}, {Part} 1: {General} {Overview}},
	volume = {208},
	issn = {0951-8320},
	shorttitle = {Supervised {Dynamic} {Probabilistic} {Risk} {Assessment} of {Complex} {Systems}, {Part} 1},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832020308929},
	doi = {10.1016/j.ress.2020.107406},
	abstract = {Dynamic probabilistic risk assessment (DPRA) is a systematic and comprehensive methodology that has been used and refined over the past decades to evaluate risks associated with complex systems. However, current approaches to construct and execute DPRA models are challenged by high execution time owing to numerous possible scenarios. This issue will affect the execution time of the model, which is in contrast with the aim of modeling. DPRA models must be sufficiently fast to assist decision-making processes in the required time. In this study, a new method is proposed to enhance the execution times of DPRA models. This method uses optimization algorithms to determine failure scenarios and sort scenarios based on their occurrence probabilities. The most efficient optimization algorithms, considering the nature of the DPRA models, are mixed-integer sequential quadratic programming, modified branch-and-bound algorithm, and modified particle swarm optimization, which are then compared and discussed. To validate the effectiveness of this method, a simple case study is presented. The results show the effectiveness of the method, which has high accuracy and reduces the execution time significantly (e.g. execution time of risk assessment of 16,464 possible behavior scenarios after an incident in a dynamic positioning system is one fifth of the conventional methods). A detailed supervised DPRA model of dynamic positioning systems and its application on three incidents that occurred in the Norwegian offshore sector in previous years is presented in a subsequent article (Part 2 of 1) (Parhizkar et. al.). Case study results confirm that the supervised DPRA method can be applied to other complex systems so that the dynamic probabilistic risk values can be evaluated quickly and accurately.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Parhizkar, Tarannom and Vinnem, Jan Erik and Utne, Ingrid Bouwer and Mosleh, Ali},
	month = apr,
	year = {2021},
	keywords = {Decision-making process, Dynamic positioning system, Dynamic probabilistic risk assessment, Emergency situations, Optimization model, Supervised algorithms},
	pages = {107406},
}

@article{waghen_multi-level_2021,
	title = {Multi-level interpretable logic tree analysis: {A} data-driven approach for hierarchical causality analysis},
	volume = {178},
	issn = {0957-4174},
	shorttitle = {Multi-level interpretable logic tree analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417421004760},
	doi = {10.1016/j.eswa.2021.115035},
	abstract = {This paper presents a data-driven approach for a hierarchical causality analysis of faults in a complex system, named a multi-level interpretable logic tree (MILTA). From a representative faults dataset, this approach constructs dependent trees that explain the relation structure between the root-causes, intermediate causes and faults with the minimum expert involvement. The MILTA model combines the discovered knowledge in dataset (KDD) in the form of feasible solutions and the fault tree analysis (FTA), level after level, as long as the root-causes are not completely uncovered. A burn-and-build algorithm is developed to maximize the representability of the feasible solutions with a minimum number of patterns. Using Bayes’ theorem, the hierarchical causality between the root-causes and the fault is captured through different causality rules that quantify the effects of the root-causes on the fault occurrence. An actuator system dataset that consists of complex fault and normal operation states is used as an illustrative example. The MILTA model finds the same documented root-cause and uncovers other root-causes with higher accuracy.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Expert Systems with Applications},
	author = {Waghen, Kerelous and Ouali, Mohamed-Salah},
	month = sep,
	year = {2021},
	keywords = {Causality analysis, Complex system, Fault diagnosis, Fault tree, Knowledge discovery in dataset},
	pages = {115035},
}

@article{heo_recent_2021,
	title = {Recent research towards integrated deterministic-probabilistic safety assessment in {Korea}},
	issn = {1738-5733},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573321002667},
	doi = {10.1016/j.net.2021.05.015},
	abstract = {For a long time, research into integrated deterministic-probabilistic safety assessment has been continuously conducted to point out and overcome the limitations of classical ET (event tree)/FT (fault tree) based PSA (probabilistic safety assessment). The current paper also attempts to assert the reason why a technical transformation from classical PSA is necessary with a re-interpretation of the categories of risk. In this study, residual risk was classified into interpolating- and extrapolating-censored categories, which represent risks that are difficult to identify through an interpolation or extrapolation of representative scenarios due to potential nonlinearity between hardware and human behaviors intertwined in time and space. The authors hypothesize that such risk can be dealt with only if the classical ETs/FTs are freely relocated, entailing large-scale computation associated with physical models. The functional elements that are favorable to find residual risk were inferred from previous studies. The authors then introduce their under-development enabling techniques, namely DICE (Dynamic Integrated Consequence Evaluation) and DeBATE (Deep learning–Based Accident Trend Estimation). This work can be considered as a preliminary initiative to find the bridging points between deterministic and probabilistic assessments on the pillars of big data technology.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Nuclear Engineering and Technology},
	author = {Heo, Gyunyoung and Baek, Sejin and Kwon, Dohun and Kim, Hyeonmin and Park, Jinkyun},
	month = may,
	year = {2021},
	keywords = {DICE (Dynamic Integrated Consequence Evaluation), DeBATE (Deep learning–Based Accident Trend Estimation), Integrated deterministic-probabilistic safety assessment, Residual risk},
}

@article{hakobyan_dynamic_2008,
	title = {Dynamic generation of accident progression event trees},
	volume = {238},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549308004470},
	doi = {10.1016/j.nucengdes.2008.08.005},
	abstract = {Currently, the development and analysis of accident progression event trees (APETs) are performed in a manner that is computationally time consuming, difficult to reproduce and also can be phenomenologically inconsistent. A software tool is presented for automated APET generation using the concept of dynamic event trees. The tool determines the branching times from a severe accident analysis code based on user specified criteria for branching. It assigns user specified probabilities to every branch, tracks the total branch probability, and truncates branches based on the given pruning/truncation rules to avoid an unmanageable number of scenarios. While the software tool could be applied to any systems analysis code, the MELCOR code is used for this illustration. A case study is presented involving station blackout with the loss of auxiliary feedwater system for a pressurized water reactor.},
	language = {en},
	number = {12},
	urldate = {2021-07-16},
	journal = {Nuclear Engineering and Design},
	author = {Hakobyan, Aram and Aldemir, Tunc and Denning, Richard and Dunagan, Sean and Kunsman, David and Rutt, Benjamin and Catalyurek, Umit},
	month = dec,
	year = {2008},
	pages = {3457--3467},
}

@inproceedings{tian_novel_2008,
	address = {Washington, DC, USA},
	title = {A {Novel} {Concept} of the {Modular} {HTGR} and {Its} {New} {Application}},
	isbn = {978-0-7918-4854-8 978-0-7918-3834-1},
	url = {https://asmedigitalcollection.asme.org/HTR/proceedings/HTR2008/48548/7/334926},
	doi = {10.1115/HTR2008-58042},
	abstract = {The Ordered Bed Modular HTGR (OBMR) core is filled with an ordered bed of fuel spheres, which has great structural stability. It is able to adapt its configuration to ship space, create stability in ships at large and work in vibrating and possibly bumping environment, which are suitable for ship applications. The modular HTGR has features of inherent safety, high-cycle efficiency, and coupling with gas turbine power conversion system, would make a great advantage for marine use. The OBMR design for ship applications allows the option for a shorter refueling period and lower fuel cost, and reaches deep burn-up of this fuel element. It uses significantly less fuel costs than that of the PWR powered and oil powered ships. In addition, this technology also displays promising aspects in the distributed energy applications, particularly in combined heating and power applications. Therefore, development of the OBMR should still be taken into account to expand its use for purposes other than electricity generation, and can make a significant contribution to the reduction of global carbon-dioxide emissions.},
	language = {en},
	urldate = {2021-07-16},
	booktitle = {Fourth {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology}, {Volume} 1},
	publisher = {ASMEDC},
	author = {Tian, Jiafu},
	month = jan,
	year = {2008},
	pages = {7--14},
}

@article{kato_advanced_2008,
	title = {Advanced {High} {Temperature} {Gas}-{Cooled} {Reactor} {Systems}},
	abstract = {Three systems have been proposed for advanced high temperature gas-cooled reactors (HTGRs): a supercritical carbon dioxide (S-CO2) gas turbine power conversion system; a new MicroChannel Heat Exchanger (MCHE); and a once-through-then-out (OTTO) refueling scheme with burnable poison (BP) loading.},
	language = {en},
	author = {Kato, Yasuyoshi},
	year = {2008},
	pages = {8},
}

@article{li_dynamic_2019,
	title = {Dynamic simulation of knowledge based reasoning of nuclear power plant operator in accident conditions: {Modeling} and simulation foundations},
	volume = {119},
	issn = {09257535},
	shorttitle = {Dynamic simulation of knowledge based reasoning of nuclear power plant operator in accident conditions},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753518303540},
	doi = {10.1016/j.ssci.2018.02.031},
	abstract = {This paper describes major additions to the modeling and simulation capabilities of the Accident Dynamic Simulator paired with the Information, Decision, and Action in a Crew context (ADS-IDAC), a platform for conducting dynamic probabilistic risk assessment (DPRA) of nuclear power plants. The new advancements are mostly in modeling of operator knowledge-based behavior in accident conditions, enhancing realism of the IDAC model, and simulation approach to Human Reliability Analysis (HRA). The focus is situation assessment and diagnosis of the accident cause. Knowledge-based reasoning plays an important role in this phase. A reasoning module has been developed and implemented in ADS-IDAC to simulate operators’ knowledge-based reasoning. This paper describes the cognitive architecture of the reasoning module, including knowledge representation (model of operator’s understanding of the plant systems and functions), a memory representation, information processing ﬂow, reasoning sequence generation, and rules for accident diagnosis. Some theoretical and empirical insights for human error prediction are embedded in this causal model as simulation rules. Human cognitive limitations and heuristics that potentially contribute to human errors are explicitly modeled. Together with the model description, several example simulations are provided to demonstrate diﬀerent features of the reasoning module. Examples of the simulation show that the reasoning module in ADS-IDAC produces realistic knowledgebased responses by capturing cognitive limitations, deliberative reasoning, and dynamic of accident progression.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Safety Science},
	author = {Li, Yuandan and Mosleh, Ali},
	month = nov,
	year = {2019},
	pages = {315--329},
}

@article{li_simulation-based_2011,
	title = {Simulation-based automatic generation of risk scenarios},
	volume = {22},
	abstract = {A methodology for automatically generating risk scenarios is presented. Its main idea is to let the system model “express itself” through simulation. This is achieved by having the simulation model driven by an elaborated simulation engine, which: (i) manipulates the generation of branch points, i.e. event occurrence times; (ii) employs a depth-ﬁrst systematic exploration strategy to cover all possible branch paths at each branch point. In addition, a backtracking technique, as an extension, is implemented to recover some missed risk scenarios. A widely discussed dynamic reliability example (a holdup tank) is used to aid in the explanation of and to demonstrate the effectiveness of the proposed methodology.},
	language = {en},
	number = {3},
	author = {Li, Jinghui and Kang, Rui and Mosleh, Ali and Pan, Xing},
	year = {2011},
	pages = {8},
}

@inproceedings{diaconeasa_model-based_2019,
	address = {Salt Lake City, Utah, USA},
	title = {Model-{Based} {Resilience} {Assessment} {Framework} for {Autonomous} {Systems}},
	isbn = {978-0-7918-8350-1},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2019/83501/Salt%20Lake%20City,%20Utah,%20USA/1073568},
	doi = {10.1115/IMECE2019-12288},
	abstract = {While automation technologies advance faster than ever, gaps of resilience capabilities between autonomous and humanoperated systems have not yet been identified and addressed appropriately. To date, there exists no generic framework for resilience assessment that is applicable to a broad spectrum of domains or able to take into account the impacts on missionscenario-level resilience from system-speciﬁc attributes. In the proposed framework, resilience is meant to describe the ability of a system, in an open range of adverse scenarios, to maintain normal operating conditions or to recover from degraded or failed states in order to provide anticipated functions or services to achieve mission success. The term resilience is introduced in relation with classical terms such as fault, error, failure, faulttolerance, reliability, and risk. The proposed model-based resilience assessment framework is based on a resilience ontology that enables the use of system models into reliability and risk models for transparent, persistent, and up-to-date modeling and quantification. A SysML profile and associated OWL ontology are defined to enable the use of a range of resilience mechanisms into the design and operation of a system.},
	language = {en},
	urldate = {2021-07-16},
	booktitle = {Volume 13: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}},
	publisher = {American Society of Mechanical Engineers},
	author = {Diaconeasa, Mihai A. and Mosleh, Ali and Morozov, Andrey and Tai, Ann T.},
	month = nov,
	year = {2019},
	pages = {V013T13A027},
}

@article{picoco_framework_2020,
	title = {A framework for verifying {Dynamic} {Probabilistic} {Risk} {Assessment} models},
	volume = {203},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832020306001},
	doi = {10.1016/j.ress.2020.107099},
	abstract = {Recent development of more powerful computational and technological resources has led to significant improvements in the utilization of dynamic methodologies for the Probabilistic Risk Assessment (PRA) of nuclear power plants. These methodologies integrate deterministic and probabilistic analyses and are generally referred to as Dynamic PRA (DPRA) methods. DPRA is performed through the generation and simulation of possibly thousands of different accident scenarios. To ensure the quality and the correctness of the results, DPRA models should be verified. Since DPRA generates large amount of data, a visual inspection of results to verify the correctness of the model used is neither practical nor reliable. As one of the steps for DPRA analysis, a framework is proposed to systematically explore the DPRA model prior to its simulation using statecharts which provide a graphical notation for describing dynamic aspects of system behavior. The application of the framework is illustrated using two case studies: (i) performance assessment of a heated room using the PyCATSHOO DPRA tool, and, (ii) DPRA performed with RAVEN-MAAP5-EDF codes for loss of off-site power as the initiating event in a pressurized water reactor.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Picoco, Claudia and Rychkov, Valentin and Aldemir, Tunc},
	month = nov,
	year = {2020},
	pages = {107099},
}

@article{lee_online_2020,
	title = {An online operator support tool for severe accident management in nuclear power plants using dynamic event trees and deep learning},
	volume = {146},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454920303248},
	doi = {10.1016/j.anucene.2020.107626},
	abstract = {Operating staffs of a nuclear power plant (NPP) are responsible for returning the NPP to a stable state and alert authorities if there is the potential for offsite radiological consequences following an accident. An operator support tool (OST) using deep learning techniques and trained by data from dynamic probabilistic safety/risk assessment (DPSA/DPRA) is proposed to assist the NPP personnel in decision-making. The DPSA/DPRA methodology employs time-dependent branching conditions based on the evolving state of the NPP and accounts for complex hardware/process/software/human interactions to predict possible outcomes of the initiating event. A large number of scenarios generated from the DPSA/DPRA performed for a pressurized water reactor station blackout as a function of time were used to train the OST to predict possible offsite dose outcomes at 2-mile and 10-mile site boundaries for emergency response planning. The results show that the OST can predict offsite dose levels with greater than 90\% accuracy.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Annals of Nuclear Energy},
	author = {Lee, Ji Hyun and Yilmaz, Alper and Denning, Richard and Aldemir, Tunc},
	month = oct,
	year = {2020},
	pages = {107626},
}

@article{lee_use_2019,
	title = {Use of {Dynamic} {Event} {Trees} and {Deep} {Learning} for {Real}-{Time} {Emergency} {Planning} in {Power} {Plant} {Operation}},
	volume = {205},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2018.1541394},
	doi = {10.1080/00295450.2018.1541394},
	abstract = {An initiating event that disrupts regular nuclear power plant (NPP) operation can result in a variety of different scenarios as time progresses depending on the response of standby safety systems and operator actions to bring the plant to a safe, stable state, or the uncertainties in accident phenomenology. Depending on the severity of the accident and potential magnitude of release of radioactive material into the environment, off-site emergency response such as evacuation may be warranted. An approach that could be used for real-time emergency guidance to support the declaration of a site emergency and to guide offsite response is presented using observable plant data in the early stages of a severe accident. The approach is based on the simulation of the possible NPP behavior following an initiating event and projects the likelihood of different levels of off-site release of radionuclides from the plant using deep learning (DL) techniques. Training of the DL process is accomplished using results of a large number of scenarios generated with the Analysis of Dynamic Accident Progression Trees/MELCOR/Radiological Assessment System for Consequence Analysis (RASCAL) computer codes to simulate the variety of possible consequences following a station blackout event (similar to the Fukushima accident) for a large pressurized water reactor. The ability of the model to predict the likelihood of different levels of consequences is assessed using a separate test set of MELCOR/RASCAL calculations.},
	language = {en},
	number = {8},
	urldate = {2021-07-16},
	journal = {Nuclear Technology},
	author = {Lee, Ji Hyun and Yilmaz, Alper and Denning, Richard and Aldemir, Tunc},
	month = aug,
	year = {2019},
	pages = {1035--1042},
}

@article{sezen_computational_2019,
	title = {A computational risk assessment approach to the integration of seismic and flooding hazards with internal hazards},
	volume = {355},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549319303760},
	doi = {10.1016/j.nucengdes.2019.110341},
	abstract = {Probabilistic risk assessment (PRA) of nuclear power plants historically focuses on internal events at the plant, rather than external hazards. Although the importance of external hazards risk analysis is now well recognized, the methods for assessing the risk associated with low probability external hazards rely heavily on subjective judgment of specialists, often using conservative elements in the analysis, as is the case with the Conservative Deterministic Failure Margin approach commonly used for seismic PRA. The U.S. Department of Energy Light Water Reactor Sustainability program has been investigating the use of first principles analyses to provide a more realistic assessment of the risk of external hazards, in a process called computational risk assessment (CRA). Efforts undertaken are described in the development of CRA methods to integrate the risk associated with seismic and flooding events into traditional PRA. The results of four case studies are presented.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Nuclear Engineering and Design},
	author = {Sezen, Halil and Hur, J. and Smith, C. and Aldemir, T. and Denning, R.},
	month = dec,
	year = {2019},
	pages = {110341},
}

@article{vierow_application_2014,
	title = {Application of dynamic probabilistic risk assessment techniques for uncertainty quantification in generation {IV} reactors},
	volume = {77},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197014001012},
	doi = {10.1016/j.pnucene.2014.04.012},
	abstract = {Demonstration of a practical approach is presented by which dynamic probabilistic risk/safety assessment (PRA/PSA) techniques are used to augment the uncertainty quantiﬁcation process for Generation IV reactors. While the traditional PRA approach using event- and fault-trees is mostly concerned with aleatory uncertainties, dynamic PRA/PSA techniques allow simultaneous consideration of both epistemic and aleatory uncertainties in a phenomenologically and stochastically consistent manner. Epistemic uncertainties are expected to be particularly important in the PRA/PSA of Generation IV reactors. A dynamic PRA/PSA methodology is coupled with a reactor safety code to enable a more efﬁcient and yet accurate evaluation of epistemic uncertainties which appear in the analysis of Generation IV reactors. Key uncertainties are identiﬁed for a postulated Loss of Forced Circulation event in a Pebble Bed Modular Reactor. The effects of these uncertainties on a selected key Figure of Merit, the stored energy in the core materials, are quantiﬁed. As a key result, the analyses show that the shape of the cumulative distribution function for each event tree is inﬂuenced by the aleatory uncertainties while the variations in the magnitudes of the cumulative distribution functions are determined by the epistemic uncertainties.},
	language = {en},
	urldate = {2021-07-16},
	journal = {Progress in Nuclear Energy},
	author = {Vierow, K. and Hogan, K. and Metzroth, K. and Aldemir, T.},
	month = nov,
	year = {2014},
	pages = {320--328},
}

@article{aldemir_probabilistic_2010,
	title = {Probabilistic risk assessment modeling of digital instrumentation and control systems using two dynamic methodologies},
	volume = {95},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832010000967},
	doi = {10.1016/j.ress.2010.04.011},
	abstract = {The Markov/cell-to-cell mapping technique (CCMT) and the dynamic ﬂowgraph methodology (DFM) are two system logic modeling methodologies that have been proposed to address the dynamic characteristics of digital instrumentation and control (I\&C) systems and provide risk-analytical capabilities that supplement those provided by traditional probabilistic risk assessment (PRA) techniques for nuclear power plants. Both methodologies utilize a discrete state, multi-valued logic representation of the digital I\&C system. For probabilistic quantiﬁcation purposes, both techniques require the estimation of the probabilities of basic system failure modes, including digital I\&C software failure modes, that appear in the prime implicants identiﬁed as contributors to a given system event of interest. As in any other system modeling process, the accuracy and predictive value of the models produced by the two techniques, depend not only on the intrinsic features of the modeling paradigm, but also and to a considerable extent on information and knowledge available to the analyst, concerning the system behavior and operation rules under normal and off-nominal conditions, and the associated controlled/monitored process dynamics. The application of the two methodologies is illustrated using a digital feedwater control system (DFWCS) similar to that of an operating pressurized water reactor. This application was carried out to demonstrate how the use of either technique, or both, can facilitate the updating of an existing nuclear power plant PRA model following an upgrade of the instrumentation and control system from analog to digital. Because of scope limitations, the focus of the demonstration of the methodologies was intentionally limited to aspects of digital I\&C system behavior for which probabilistic data was on hand or could be generated within the existing project bounds of time and resources. The data used in the probabilistic quantiﬁcation portion of the process were gathered partially from fault injection experiments with the DFWCS, separately conducted under conservative assumptions, partially from operating experience, and partially from generic data bases. The purpose of the quantiﬁcation portion of the process was, purely to demonstrate the PRA-updating use and application of the methodologies, without making any particular claim regarding the speciﬁc validity and predictive value of the data utilized to illustrate the quantitative risk calculations produced from the qualitative information analytically generated by the models. A comparison of the results obtained from the Markov/CCMT and DFM regarding the event sequences leading to DFWCS failure modes show qualitative and quantitative consistency for the risk scenarios and sequences under consideration. The study also shows that: (a) the risk signiﬁcance of the timing of system component failures may depend on factors that include the actual variability of initiating conditions of a dynamic transient, even within the nominal control range and (b) the range of dynamic outcomes may also be dependent on the choice of the assumed basic system-component failure modes included in the models, regardless of whether some of these would or would not be considered to have direct safety implications according to the traditional safety/non-safety equipment classiﬁcations.},
	language = {en},
	number = {10},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Aldemir, T. and Guarro, S. and Mandelli, D. and Kirschenbaum, J. and Mangan, L.A. and Bucci, P. and Yau, M. and Ekici, E. and Miller, D.W. and Sun, X. and Arndt, S.A.},
	month = oct,
	year = {2010},
	pages = {1011--1039},
}

@article{aldemir_measure_2007,
	title = {Some {Measure} {Theoretic} {Issues} in {Probabilistic} {Dynamics}},
	volume = {155},
	issn = {0029-5639, 1943-748X},
	url = {https://www.tandfonline.com/doi/full/10.13182/NSE07-A2680},
	doi = {10.13182/NSE07-A2680},
	abstract = {Probabilistic dynamics (or continuous event tree approach) is a methodology used for the probabilistic risk assessment of systems where statistical dependence between failure events may arise because of indirect coupling through the controlled/monitored physical process and/or direct coupling through software/hardware/human intervention. Both the continuous and discrete time/space forms of the probabilistic dynamics frameworks assume that the set of possible trajectories describing the evolution of the system as a function of time in its state-space consists of measurable (and hence compact) subsets. Using a reduced-order boiling water reactor model, it is shown that this assumption may not be valid for systems of practical interest to nuclear engineering. The consequences of violating the measurability assumption on the probabilistic model accuracy are illustrated for the discrete time/state-space approach. Some guidelines for the choice of time/state discretization are also proposed.},
	language = {en},
	number = {3},
	urldate = {2021-07-16},
	journal = {Nuclear Science and Engineering},
	author = {Aldemir, Tunc},
	month = mar,
	year = {2007},
	pages = {497--507},
}

@article{aldemir_methodologies_2007,
	title = {Methodologies for the {Probabilistic} {Risk} {Assessment} of {Digital} {Reactor} {Protection} and {Control} {Systems}},
	volume = {159},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT07-A3863},
	doi = {10.13182/NT07-A3863},
	language = {en},
	number = {2},
	urldate = {2021-07-16},
	journal = {Nuclear Technology},
	author = {Aldemir, Tunc and Miller, Don W. and Stovsky, Michael and Kirschenbaum, Jason and Bucci, Paolo and Mangan, L. Anthony and Fentiman, Audeen and Arndt, Steven A.},
	month = aug,
	year = {2007},
	pages = {167--191},
}

@article{belhadj_need_1992,
	title = {On the need for dynamic methodologies in risk and reliability studies},
	volume = {38},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0951832092901358},
	doi = {10.1016/0951-8320(92)90135-8},
	language = {en},
	number = {3},
	urldate = {2021-07-16},
	journal = {Reliability Engineering \& System Safety},
	author = {Belhadj, Mohamed and Hassan, Mahbubul and Aldemir, Tunc},
	month = jan,
	year = {1992},
	pages = {219--236},
}

@article{choi_development_2021,
	title = {Development of a {Two}-{Stage} {DQFM} to {Improve} {Efficiency} of {Single}- and {Multi}-{Hazard} {Risk} {Quantification} for {Nuclear} {Facilities}},
	volume = {14},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/14/4/1017},
	doi = {10.3390/en14041017},
	abstract = {The probabilistic safety assessment (PSA) of a nuclear power plant (NPP) under single and multiple hazards is one of the most important tasks for disaster risk management of nuclear facilities. To date, various approaches—including the direct quantiﬁcation of the fault tree using the Monte Carlo simulation (DQFM) method—have been employed to quantify single- and multihazard risks to nuclear facilities. The major advantage of the DQFM method is its applicability to a partially correlated system. Other methods can represent only an independent or a fully correlated system, but DQFM can quantify the risk of partially correlated system components by the sampling process. However, as a sampling-based approach, DQFM involves computational costs which increase as the size of the system and the number of hazards increase. Therefore, to improve the computational efﬁciency of the conventional DQFM, a two-stage DQFM method is proposed in this paper. By assigning enough samples to each hazard point according to its contribution to the ﬁnal risk, the proposed two-stage DQFM can effectively reduce computational costs for both single- and multihazard risk quantiﬁcation. Using examples of single- and multi-hazard threats to nuclear facilities, the effectiveness of the proposed two-stage DQFM is successfully demonstrated. Especially, two-stage DQFM saves computation time of conventional DQFM up to 72\% for multi-hazard example.},
	language = {en},
	number = {4},
	urldate = {2021-07-16},
	journal = {Energies},
	author = {Choi, Eujeong and Kwag, Shinyoung and Ha, Jeong-Gon and Hahm, Daegi},
	month = feb,
	year = {2021},
	pages = {1017},
}

@article{picoco_integration_2019,
	title = {{INTEGRATION} {OF} {RECOVERIES} {INTO} {DYNAMIC} {EVENT} {TREES}: {A} {CASE} {STUDY}},
	language = {en},
	author = {Picoco, Claudia and Rychkov, Valentin and Aldemir, Tunc},
	year = {2019},
	pages = {10},
}

@article{diaconeasa_discrete_2018,
	title = {Discrete {Dynamic} {Event} {Tree} {Uncertainty} {Quantification} in the {ADS}-{IDAC}},
	abstract = {ADS-IDAC stands for the Accident Dynamics Simulator coupled with the Information, Decision and Action in a Crew context. It contains both a cognitive crew model and a nuclear power plant thermal-hydraulic model to simulate their response behavior and interactions given abnormal conditions and generate a discrete dynamic event tree (DDET). When the probabilities of the initiating events and branching or non-branching events in a DDET are subject to uncertainty, the probabilities can be considered to be random variables described by some probability distribution. The form of their probability distribution depends on the type of events (e.g., hardware failure, human activity, etc.) Therefore, the probability of the end state events in such a DDET will also be a random variable, and the form of its probability distribution will depend both on the DDET structure and the probability distributions of the events. In this paper, the various sampling techniques (i.e., Monte Carlo, Latin Hypercube, quasi-Monte Carlo) that are implemented in an updated version of ADS-IDAC are summarized. They are used for the propagation of uncertainties in the DDET generated by ADSIDAC. These Monte Carlo methods are used to obtain a probability distribution of the end state events in a DDET using available information on the tree structure and the assumed probability distributions of its top events. The same methods can be applied to simulate the fault trees (FTs) used to represent frontline and support systems. For these accident sequences, the propagation of uncertainties is performed on the combined structure of DDET and FTs.},
	language = {en},
	journal = {Los Angeles},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {9},
}

@article{diaconeasa_performing_2018,
	title = {Performing an {Accident} {Sequence} {Precursor} {Analysis} with the {ADS}-{IDAC}},
	abstract = {An accident sequence precursor is defined as an observed event that combined with one or several postulated events could lead to core damage, while an accident sequence precursor analysis is a probabilistic safety assessment performed to obtain the conditional probability of a core damage accident given an initiating event and identify the dominant event sequences. The current discrete dynamic probabilistic safety assessment techniques are generally used to simulate accident scenarios and their probability of occurrence. They are an appropriate tool for performing an accident sequence precursor analysis that can capture realistic scenarios in a transparent manner. One such platform is ADS-IDAC – the accident Dynamics Simulator coupled with the Information, Decision, and Action in a Crew context cognitive model, and a mature nuclear power plant thermal-hydraulic model. Rich contextual scenarios are algorithmically generated using a relatively small set of branching rules that cover both stochastic and deterministic interactions between the system and the crew evolutions. Moreover, thermal-hydraulic success criteria are explicitly represented in the simulation. This paper provides details about how to perform an accident sequence precursor analysis with ADS-IDAC. Additional information is included regarding the recommended analysis team, the necessary information for performing the analysis, when to use ADS-IDAC, and the advantages and limitations of using it.},
	language = {en},
	journal = {Los Angeles},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {7},
}

@book{podofillini_safety_2015,
	title = {Safety and {Reliability} of {Complex} {Engineered} {Systems}: {ESREL} 2015},
	isbn = {978-1-138-02879-1 978-1-315-64841-5},
	shorttitle = {Safety and {Reliability} of {Complex} {Engineered} {Systems}},
	url = {http://www.crcnetbase.com/doi/book/10.1201/b19094},
	language = {en},
	urldate = {2021-07-16},
	publisher = {CRC Press},
	editor = {Podofillini, Luca and Sudret, Bruno and Stojadinovic, Bozidar and Zio, Enrico and Kröger, Wolfgang},
	month = sep,
	year = {2015},
	doi = {10.1201/b19094},
}

@article{lewandowski_development_2014,
	title = {Development of a {Dynamic}, {Plant} {Condition}-{Dependent} {Probabilistic} {Safety} {Assessment}},
	abstract = {Although each nuclear power plant has a plant-specific probabilistic risk assessment (PRA) that reflects design differences from other plants, the condition of each plant changes uniquely with time. A great deal of surveillance data are collected for the plant that reflect the changing condition of the plant. In some instances, plant staff use these data to guide the plant’s preventative maintenance and surveillance programs. In general, however, these data are not used to characterize the evolving risk of the plant. Our understanding of the underlying mechanisms for the degradation of systems, although far from perfect, is improving with time. The possibility of developing a condition-dependent PRA is explored that would take a first principles approach to modeling the progression of degradation mechanisms, periodically adapting the model to account for surveillance results, and using the model as a basis for a time-dependent characterization of plant specific risk. Because surveillance data would be used to periodically assess the consistency of the observed behavior with model predictions, it might be possible to provide early identification of unanticipated degradation mechanisms. A case study is described involving a potential bypass accident sequence involving the progression of flowaccelerated corrosion in secondary system piping and stress corrosion cracking of steam generator tubes.},
	language = {en},
	author = {Lewandowski, Radoslaw and Denning, Richard and Aldemir, Tunc and Zhang, Jinsuo},
	year = {2014},
	pages = {14},
}

@article{lee_multi-hazard_2019,
	title = {Multi-{Hazard} {Risk} {Assessment} {Using} {Bayesian} {Network} and {Fault} {Tree} {Analysis} {Considering} {Effects} of {Structural} {Damage}},
	abstract = {Recently, South Korea experienced two strongest earthquake events in its modern history, i.e. 2016 Gyeongju (Mw 5.4) and 2017 Pohang Earthquakes (Mw 5.5). In the region generally considered as a low or moderate seismic zone, the occurrences of such earthquakes and their socio-economic consequences alarmed the general public. Moreover, those earthquake events featured a number of mainand after-shocks, which raised a significant concern about potential major catastrophes caused by multihazard effects. This paper presents a probabilistic framework being developed to assess such multihazard risk of nuclear power plants (NPPs). First, a ground motion prediction equation is represented by a Bayesian Network (BN). The relationship between main- and after-shocks, e.g. the modified Omori law is incorporated into the BN. Second, to overcome limitations in existing Probabilistic Risk Assessment (PRA) of NPPs, which often employs event tree and fault tree analysis, the BN representing the multi-hazard is connected with the fault trees constructed for the NPP. Finally, to address the impact of structural damage caused by earlier shocks on later events, the fragilities of NPP components are updated. These updated fragilities are incorporated into the fault trees connected with the BN for accurate after-shock risk assessment. The proposed methodology integrates our knowledge on the multi-hazard (BN), reliability of NPP (fault tree) and inter-hazard effect (system identification). The proposed framework is demonstrated by an NPP under main- and after-shock scenarios. Potential applications to other types of multi-hazards and future research needs are also discussed.},
	language = {en},
	journal = {South Korea},
	author = {Lee, Se-Hyeok and Mun, ChangUk and Song, Junho and Kwag, Shinyoung and Hahm, Daegi},
	year = {2019},
	pages = {8},
}

@inproceedings{morozov_hybrid_2020,
	address = {Virtual, Online},
	title = {A {Hybrid} {Methodology} for {Model}-{Based} {Probabilistic} {Resilience} {Evaluation} of {Dynamic} {Systems}},
	isbn = {978-0-7918-8466-9},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2020/84669/Virtual,%20Online/1099611},
	doi = {10.1115/IMECE2020-23789},
	abstract = {Advanced classical Probabilistic Risk Assessment (PRA) effectively combines various methods for quantitative risk evaluation, such as event trees, fault trees, and Bayesian networks. PRA methods and tools provide the means for the qualitative reliability evaluation (e.g., cut sets) and the computation of quantitative reliability metrics (e.g., end states probabilities). Modern safety-critical systems from various industrial domains tend toward a high level of autonomy and demand not only reliability but also resilience, the ability to recover from degraded or failed states. The numerical resilience analysis of such dynamic systems requires more flexible methods. These methods shall enable the analysis of the systems with sophisticated software parts and dynamic feedback loops. A suitable candidate is the Dual-graph Error Propagation Model (DEPM) that can capture nontrivial failure scenarios and dynamic fault-tolerance mechanisms. The DEPM exploits the method for the automatic generation of Markov chain models and the application of probabilistic model checking techniques. Moreover, the DEPM enables the analysis of highlycustomizable system resilience metrics, e.g., “the probability of system recovery to a particular state after a specified system failure during a defined time interval.” In this paper, we show how DEPM-based resilience analysis can be integrated with the general PRA methodology for resilience evaluations. The proposed methodology is demonstrated on a safety-critical autonomous UAV system.},
	language = {en},
	urldate = {2021-07-16},
	booktitle = {Volume 14: {Safety} {Engineering}, {Risk}, and {Reliability} {Analysis}},
	publisher = {American Society of Mechanical Engineers},
	author = {Morozov, Andrey and Diaconeasa, Mihai A. and Steurer, Mikael},
	month = nov,
	year = {2020},
	pages = {V014T14A024},
}

@article{norio_2011_2011,
	title = {The 2011 eastern {Japan} great earthquake disaster: {Overview} and comments},
	volume = {2},
	issn = {2095-0055, 2192-6395},
	shorttitle = {The 2011 eastern {Japan} great earthquake disaster},
	url = {http://link.springer.com/10.1007/s13753-011-0004-9},
	doi = {10.1007/s13753-011-0004-9},
	abstract = {This article briefly reviews the causes and impacts of the massive eastern Japan earthquake and tsunami of 11 March 2011, and comments on the response measures taken by Japan to cope with this devastating disaster. Mass losses occurred mostly because the intensity of the quake and the induced tsunami exceeded local coping capacity. Particularly, the nuclear power plant crisis triggered by the tsunami significantly increased the short- and long-term impacts of the disaster. While the coping capacity Japanese society built after the 1995 Hanshin-Awaji great earthquake tremendously mitigated the damages, there is room for improvement despite Japan’s great efforts in this disaster. Investigating the tsunami preparedness of the coastal nuclear power plants is an issue of paramount importance. In response to future large-scale disasters, there is an urgent need for a highly collaborative framework based on which all available resources could be mobilized; a mutual assistance and rescue system against catastrophes among regions and countries on the basis of international humanitarian aid; and further in-depth research on the multi-hazard and disaster-chain phenomenon in large-scale disasters and corresponding governance approaches.},
	language = {en},
	number = {1},
	urldate = {2021-07-16},
	journal = {International Journal of Disaster Risk Science},
	author = {Norio, Okada and Ye, Tao and Kajitani, Yoshio and Shi, Peijun and Tatano, Hirokazu},
	month = mar,
	year = {2011},
	pages = {34--42},
}

@article{aldemir_dynamic_2009,
	title = {Dynamic {Reliability} {Modeling} of {Digital} {Instrumentation} and {Control} {Systems} in {Nuclear} {Power} {Plants}},
	abstract = {This paper shows how it is possible construct PRA models of digital instrumentation and control system using the DFM and Markov/CCMT as two example dynamic methodologies. The digital feedwater control system of a PWR has been used as an example system to illustrate the process. The prime implicants and their probabilities generated by these two methodologies have been compared. The comparison shows a very close consistency between the DFM and Markov/CCMT results. The power of these dynamic methodologies is their ability to identify combinations of component failure modes, even across time boundaries, that can result in system failure modes that otherwise would be very difficult to identify with a standard ET/FT approach. Applications of either methodology require complete and thorough supporting analyses (e.g. FMEA) and data (e.g. transition and failure data for components), as well as a system model describing the system behavior under normal and upset conditions (e.g. simulator).},
	language = {en},
	author = {Aldemir, T and Guarro, S and Kirschenbaum, J and Mandelli, D and Mangan, L A and Bucci, P and Yau, M and Johnson, B and Elks, C and Ekici, E and Stovsky, M P and Miller, D W and Sun, X and Arndt, S A},
	year = {2009},
	pages = {3},
}

@article{mandelli_scenario_nodate,
	title = {Scenario {Aggregation} in {Dynamic} {PRA} {Uncertainty} {Quantification}},
	language = {en},
	author = {Mandelli, Diego and Aldemir, Tunc and Yilmaz, Alper},
	pages = {4},
}

@article{coyne_nuclear_nodate,
	title = {Nuclear {Plant} {Control} {Room} {Operator} {Modeling} {Within} the {ADS}-{IDAC}, {Version} 2, {Dynamic} {PRA} {Environment}: {Part} 2 - {Modeling} {Capabilities} and {Application} {Examples}},
	abstract = {Dynamic simulation-based approaches for probabilistic risk assessment (PRA) offer several key advantages over traditional “static” techniques such as traditional event tree-fault tree based methods. For example, dynamic simulation approaches can more realistically represent event sequence and timing, provide a better representation of thermal hydraulic success criteria, and permit more detailed modeling of operator response. Version 2.0 of the Accident Dynamics Simulator paired with the Information, Decision, and Action cognitive model in a Crew context (ADS-IDAC) is one such dynamic method that shows promise for supporting nuclear power plant PRAs and other risk-informed applications. By linking a realistic nuclear plant thermal-hydraulic model with a crew behavior model, ADS-IDAC creates a rich simulation environment. The crew behavior model describes the operators’ preferences and tendencies, knowledge, and situation-response rules. ADS-IDAC generates a discrete dynamic event tree (DDET) by applying simple branching rules that reflect variations in crew responses to plant events and system status changes. Branches can be generated to simulate a variety of operator behaviors, including procedure execution speed and adherence, evolving situational assessments, and variations in plant control preferences. This is the second of two papers in this volume and describes the dynamic modeling capabilities supported by the ADSIDAC Version 2.0 simulation platform and provides examples of their application.},
	language = {en},
	author = {Coyne, Kevin and Mosleh, Ali},
	pages = {12},
}

@article{coyne_nuclear_nodate-1,
	title = {Nuclear {Plant} {Control} {Room} {Operator} {Modeling} {Within} the {ADS}-{IDAC}, {Version} 2, {Dynamic} {PRA} {Environment}: {Part} 1 - {General} {Description} and {Cognitive} {Foundations}},
	abstract = {Dynamic simulation-based approaches for probabilistic risk assessment (PRA) offer several key advantages over traditional “static” techniques such as traditional event tree-fault tree based methods. For example, dynamic simulation approaches can more realistically represent event sequence and timing, provide a better representation of thermal hydraulic success criteria, and permit more detailed modeling of operator response. Version 2.0 of the Accident Dynamics Simulator paired with the Information, Decision, and Action cognitive model in a Crew context (ADS-IDAC) is one such dynamic method that shows promise for supporting nuclear power plant PRAs and other risk-informed applications. By linking a realistic nuclear plant thermal-hydraulic model with a crew behavior model, ADS-IDAC creates a rich simulation environment. The crew behavior model describes the operators’ preferences and tendencies, knowledge, and situation-response rules.},
	language = {en},
	author = {Coyne, Kevin and Mosleh, Ali},
	pages = {14},
}

@article{somwanshi_comparison_2019,
	series = {International {Conference} on {Pervasive} {Computing} {Advances} and {Applications}- {PerCAA} 2019},
	title = {Comparison of {Fuzzy}-{PID} and {PID} {Controller} for {Speed} {Control} of {DC} {Motor} using {LabVIEW}},
	volume = {152},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050919306702},
	doi = {10.1016/j.procs.2019.05.019},
	abstract = {DC Motors are widely used in industries because they provide better quality with high torque and low volume. A individual PID Controller and A Fuzzy Based PID Controller is proposed to design in this paper. By a comparison between both the Controllers an overview of performance of both the Controllers is provided. By the literature review it is found that many of the researchers used fuzzy controller with some algorithms to tune the parameters of the PID Controller so here for the tuning of the PID parameters Fuzzy Controller itself used. In Conventional PID Controller there is a difficulty to control the value of the parameters and get good suitable characteristic. In the Fuzzy-Controller to satisfy the control characteristics of the parameters there is special ability and that is to provide an easy computing, to control for Motor. By comparing the responses for both the controllers, Fuzzy based PID Controller presents better performance than PID Controller. To Model the DC Motor and for the simulation purpose LabVIEW software has been used.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Procedia Computer Science},
	author = {Somwanshi, Devendra and Bundele, Mahesh and Kumar, Gaurav and Parashar, Gajal},
	month = jan,
	year = {2019},
	keywords = {DC Motor, Fuzzy Logic, LabVIEW, PID Controller},
	pages = {252--260},
}

@book{hetrick_dynamics_1971,
	address = {Chicago},
	title = {Dynamics of nuclear reactors},
	isbn = {978-0-226-33166-9},
	publisher = {University of Chicago Press},
	author = {Hetrick, David L.},
	year = {1971},
	keywords = {Mathematical models, Nuclear reactor kinetics, Nuclear reactors},
}

@inproceedings{guohua_review_2020,
	address = {Virtual, Online},
	title = {Review of {Application} on {Dynamic} {Fault} {Tree} {Method} in {Nuclear} {Power} {Plants}},
	isbn = {978-0-7918-8377-8},
	url = {https://asmedigitalcollection.asme.org/ICONE/proceedings/ICONE2020/83778/Virtual,%20Online/1088623},
	doi = {10.1115/ICONE2020-16191},
	abstract = {Fault tree analysis (FTA) is one of the most important methods of probabilistic risk assessment (PRA). The fault state of the system is taken. While traditional FTA is based on static failure model. FTA is not applicable for systems that include redundant, sequence-related systems. At the same time, nuclear power plants (NPPs) contains a large number of redundant equipment, and FTA is difficult to solve these dynamic problems. Therefore, it is necessary to use dynamic fault tree analysis (DFTA) for PRA. In DFTA research, the modular analysis method was first proposed. The modular method divides the dynamic fault tree into a dynamic fault tree and a static fault tree. Among them, the dynamic fault tree is analyzed using a Markov chain, and the static fault tree is studied using a binary decision diagrams method. However, the shortcomings are that when the system is complicated, the information explosion in the Markov chain is appeared. To solve this problem, a dynamic fault tree is transformed into a Bayesian network. At the same time, to verify the feasibility of the method, Monte Carlo random sampling was used to evaluate the method. Other methods are relatively infrequently studied.},
	language = {en},
	urldate = {2021-07-07},
	booktitle = {Volume 2: {Nuclear} {Policy}; {Nuclear} {Safety}, {Security}, and {Cyber} {Security}; {Operating} {Plant} {Experience}; {Probabilistic} {Risk} {Assessments}; {SMR} and {Advanced} {Reactors}},
	publisher = {American Society of Mechanical Engineers},
	author = {Guohua, Wu and Diping, Yuan and Yiqing, Xiao and Jiaxin, Wang},
	month = aug,
	year = {2020},
	pages = {V002T08A023},
}

@article{lachance_discrete_nodate,
	title = {Discrete {Dynamic} {Probabilistic} {Risk} {Assessment} {Model} {Development} and {Application}.},
	abstract = {As part of an exploratory long-term research project, Sandia National Laboratories and the University of Maryland, under the support and guidance of the US Nuclear Regulatory Commission, developed a tool for conducting dynamic probabilistic risk analysis (PRA) for postulated severe accident scenarios by coupling and extending existing capabilities in hardware/phenomena and operator response simulation. The effort encompasses aspects of both Level 1 and Level 2 PRA. The dynamic PRA tool utilizes MELCOR as the code for simulating severe nuclear reactor accidents in a discrete dynamic event tree (DDET) framework. The Accident Dynamics Simulator (ADS) developed at the University of Maryland is used to generate the DDETs for an accident simulation that reflect variations in important parameters including: phenomenological events, the behavior of active and passive components, and operators’ cognitive activities and actions. Specific focus was placed on inclusion of an operator cognitive model in the dynamic PRA tool that addresses both pre-core damage human actions and post-core damage human actions. To that purpose, the Information, Decision, and Actions in a Crew (IDAC) context cognitive model developed at the University of Maryland was utilized. An existing ADS-IDAC model developed for a pressurized water reactor was expanded to address operator actions directed in both emergency operating procedures and severe accident management guidelines. The developed tool was applied to a demonstration problem; a station blackout (SBO) scenario at the Surry Nuclear Station. Both short-term and long-term SBO sequences were included in the demonstration evaluation. This report describes the developed tool and corresponding models and the results of the SBO demonstration problem. Insights from the demonstration evaluation, including potential further development of the dynamic PRA tool, are provided.},
	language = {en},
	author = {LaChance, J and Cardoni, J and Li, Y and Mosleh, A and Aird, D and Helton, D and Coyne, K},
	pages = {148},
}

@article{mandelli_mining_2018,
	title = {Mining data in a dynamic {PRA} framework},
	volume = {108},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S014919701830129X},
	doi = {10.1016/j.pnucene.2018.05.004},
	abstract = {Computational, also known as Dynamic, Probabilistic Risk Assessment (PRA) methods employ system simulation codes coupled with stochastic analysis tools in order to determine probabilities of certain outcomes such as system failure. In contrast to Classical PRA methods (i.e., Event-Tree and Fault-Tree) in which timing and sequencing of events is set by the analyst, accident progression is dictated by the system control logic and its interaction with the system temporal evolution. Due to the nature of the problem, Dynamic PRA methods can be expensive form a computational point of view since a large number of accident scenarios is simulated. Consequently, they also generate a large amount of data (database storage may be on the order of gigabytes or higher). We investigate and apply several methods and algorithms to analyze these large time-dependent data sets. The objective is to present a broad overview of methods and algorithms that can be used to improve data quality and to analyze and extract information from large data sets containing time dependent data. In this context, “extracting information” means constructing input-output correlations, ﬁnding commonalities, and identifying outliers.},
	language = {en},
	urldate = {2021-07-07},
	journal = {Progress in Nuclear Energy},
	author = {Mandelli, D. and Maljovec, D. and Alfonsi, A. and Parisi, C. and Talbot, P. and Cogliati, J. and Smith, C. and Rabiti, C.},
	month = sep,
	year = {2018},
	pages = {99--110},
}

@article{mandelli_scenario_nodate-1,
	title = {Scenario {Aggregation} in {Dynamic} {PRA} {Uncertainty} {Quantification}},
	language = {en},
	author = {Mandelli, Diego and Aldemir, Tunc and Yilmaz, Alper},
	pages = {4},
}

@article{mandelli_measuring_2019,
	title = {Measuring risk-importance in a {Dynamic} {PRA} framework},
	volume = {128},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454918306996},
	doi = {10.1016/j.anucene.2018.12.035},
	abstract = {Risk Importance Measures (RIMs) are indexes that are used to rank Structures, Systems, and Components (SSCs). The most used measures are: Risk Reduction Worth, Risk Achievement Worth, Birnbaum and Fussell-Vesely. Once obtained from Classical Probabilistic Risk Assessment (PRA), these risk measures can be effectively employed to identify the most risk-important SSCs. The objective of this paper is to present a series of methods that can be employed to measure risk importance of SSCs from Dynamic PRA. In contrast to Classical PRA methods, Dynamic PRA methods couple stochastic models with system simulators to determine risk associated to complex systems such as nuclear plants. Compared to Classical PRA methods, Dynamic PRA approaches can evaluate with higher resolution the safety impact of timing and sequencing of events on the accident progression. The developed set of RIMs are directly derived from Classical RIMs and adapted to deal with simulation-based data. We present a series of analytical tests to show how RIMs can be obtained from a Dynamic PRA data and a comparison of the RIMs obtained from Classical and Dynamic PRA for a Large Break Loss Of Coolant Accident (LB-LOCA) initiating event of a Pressurized Water Reactor (PWR). The obtained results have highlighted differences among the two PRA approaches in the predicted ﬁnal outcome of few accident sequences. This have consequently affected the risk importance of a subset of basic events.},
	language = {en},
	urldate = {2021-07-07},
	journal = {Annals of Nuclear Energy},
	author = {Mandelli, D. and Ma, Z. and Parisi, C. and Alfonsi, A. and Smith, C.},
	month = jun,
	year = {2019},
	pages = {160--170},
}

@article{mandelli_mutual_2021,
	title = {Mutual {Integration} of {Classical} and {Dynamic} {PRA}},
	volume = {207},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.1080/00295450.2020.1776030},
	doi = {10.1080/00295450.2020.1776030},
	abstract = {A new generation of dynamic methods has started receiving attention for nuclear reactor probabilistic risk assessment (PRA). These methods, which are commonly referred to as dynamic PRA (DPRA) methodologies, directly employ system simulators to evaluate the impact of timing and sequencing of events (e.g., failure of components) on accident progression. Compared to classical PRA (CPRA) methods, which are based on static Boolean logic structures such as fault trees and event trees (ETs), DPRA methods can provide valuable insights from an accident management perspective. However, as of today this class of methods has received limited attention in practical applications. One factor is DPRA research and development has progressed mostly as an alternative to state-of-practice CPRA methods (i.e., disconnected from currently employed PRA methods). This disconnect is addressed in this paper by presenting several algorithms that can be employed to bridge the gap between CPRA and DPRA. First, algorithms designed to identify differences between CPRA and DPRA results are presented. The identifica­ tion process compares the CPRA ET sequence or the minimal cut sets (MCSs) obtained by CPRA with the set of transients simulated by the DPRA. If inconsistencies are observed, solutions are provided to incorporate these differences back into the CPRA by employing DPRA to inform existing CPRA. We performed this incorporation either probabilistically (e.g., by updating MCS probability) or topologically (by adding new branching conditions or sequences in the ET).},
	language = {en},
	number = {3},
	urldate = {2021-07-07},
	journal = {Nuclear Technology},
	author = {Mandelli, Diego and Alfonsi, Andrea and Wang, Congjian and Ma, Zhegang and Parisi, Carlo and Aldemir, Tunc and Smith, Curtis and Youngblood, Robert},
	month = mar,
	year = {2021},
	pages = {363--375},
}

@article{mandelli_dynamic_2013,
	title = {Dynamic {PRA}: an {Overview} of {New} {Algorithms} to {Generate}, {Analyze} and {Visualize} {Data}},
	volume = {109},
	language = {en},
	journal = {Modeling and Simulation},
	author = {Mandelli, D and Smith, C and Rabiti, C and Alfonsi, A and Youngblood, R and Pascucci, V and Wang, B and Maljovec, D and Bremer, P T and Aldemir, T and Yilmaz, A and Zamalieva, D},
	year = {2013},
	pages = {5},
}

@article{mandelli_multi-unit_2019,
	title = {Multi-unit dynamic {PRA}},
	volume = {185},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832017308530},
	doi = {10.1016/j.ress.2018.12.029},
	abstract = {Dynamic Probabilistic Risk Analysis (PRA) methods couple stochastic methods (e.g., RAVEN) with safety analysis codes (e.g., RELAP5-3D) to determine risk associated to complex systems such as nuclear plants. Compared to classical PRA methods, which are based on static logic structures (e.g., Event-Trees, Fault-Trees), they can evaluate with higher resolution the safety impact of timing and sequencing of events on the accident progression. Recently, special attention has been given to nuclear plant sites which consist of multiple units and, in particular, on the safety impact of system dependencies, shared systems and common resources on core damage frequencies. In the literature, classical PRA methods have been employed to model multi-unit sites in a limited number of cases while Dynamic PRA methods have never been applied to analyze a full multi-unit model. This paper presents a PRA analysis of a multi-unit plant using Dynamic PRA methods. We employ RAVEN as stochastic tool coupled with RELAP5-3D. The site under consideration consists of three units (each unit is composed by a reactor and its associated spent fuel pool) while the considered initiating event is a seismic induced station blackout event. This paper describes in detail how the multi-unit site has been constructed and, in particular, how unit dependencies and shared resources are modeled from both a deterministic and stochastic point of view.},
	language = {en},
	urldate = {2021-07-07},
	journal = {Reliability Engineering \& System Safety},
	author = {Mandelli, D. and Parisi, C. and Alfonsi, A. and Maljovec, D. and Boring, R. and Ewing, S. and St Germain, S. and Smith, C. and Rabiti, C. and Rasmussen, M.},
	month = may,
	year = {2019},
	pages = {303--317},
}

@book{cormen_introduction_2009,
	address = {Cambridge, Mass},
	edition = {3rd ed},
	title = {Introduction to algorithms},
	isbn = {978-0-262-03384-8 978-0-262-53305-8},
	language = {en},
	publisher = {MIT Press},
	editor = {Cormen, Thomas H.},
	year = {2009},
	note = {OCLC: ocn311310321},
	keywords = {Computer algorithms, Computer programming},
}

@article{busby_cascading_2021,
	title = {Cascading risks: {Understanding} the 2021 winter blackout in {Texas}},
	volume = {77},
	issn = {2214-6296},
	shorttitle = {Cascading risks},
	url = {https://www.sciencedirect.com/science/article/pii/S2214629621001997},
	doi = {10.1016/j.erss.2021.102106},
	abstract = {The Texas freeze of February 2021 left more than 4.5 million customers (more than 10 million people) without electricity at its peak, some for several days. The freeze had cascading effects on other services reliant upon electricity including drinking water treatment and medical services. Economic losses from lost output and damage are estimated to be \$130 billion in Texas alone. In the wake of the freeze, there has been major fallout among regulators and utilities as actors sought to apportion blame and utilities and generators began to settle up accounts. This piece offers a retrospective on what caused the blackouts and the knock-on effects on other services, the subsequent financial and political effects of the freeze, and the implications for Texas and the country going forward. Texas failed to sufficiently winterize its electricity and gas systems after 2011. Feedback between failures in the two systems made the situation worse. Overall, the state faced outages of 30 GW of electricity as demand reached unprecedented highs. The gap between production and demand forced the non-profit grid manager, the Electric Reliability Council of Texas (ERCOT), to cut off supply to millions of customers or face a systems collapse that by some accounts was minutes away. The 2021 freeze suggests a need to rethink the state’s regulatory approach to energy to avoid future such outcomes. Weatherization, demand response, and expanded interstate interconnections are potential solutions Texas should consider to avoid generation losses, reduce demand, and tap neighboring states’ capacity.},
	language = {en},
	urldate = {2021-07-02},
	journal = {Energy Research \& Social Science},
	author = {Busby, Joshua W. and Baker, Kyri and Bazilian, Morgan D. and Gilbert, Alex Q. and Grubert, Emily and Rai, Varun and Rhodes, Joshua D. and Shidore, Sarang and Smith, Caitlin A. and Webber, Michael E.},
	month = jul,
	year = {2021},
	keywords = {Electricity, Energy systems, Resilience, Texas},
	pages = {102106},
}

@article{mosleh_pra_2014,
	title = {{PRA}: {A} {PERSPECTIVE} {ON} {STRENGTHS}, {CURRENT} {LIMITATIONS}, {AND} {POSSIBLE} {IMPROVEMENTS}},
	volume = {46},
	issn = {1738-5733},
	shorttitle = {{PRA}},
	url = {https://www.sciencedirect.com/science/article/pii/S1738573315300851},
	doi = {10.5516/NET.03.2014.700},
	abstract = {Probabilistic risk assessment (PRA) has been used in various technological fields to assist regulatory agencies, managerial decision makers, and systems designers in assessing and mitigating the risks inherent in these complex arrangements. Has PRA delivered on its promise? How do we gage PRA performance? Are our expectations about value of PRA realistic? Are there disparities between what we get and what we think we are getting form PRA and its various derivatives? Do current PRAs reflect the knowledge gained from actual events? How do we address potential gaps? These are some of the questions that have been raised over the years since the inception of the field more than forty years ago. This paper offers a brief assessment of PRA as a technical discipline in theory and practice, its key strengths and weaknesses, and suggestions on ways to address real and perceived shortcomings.},
	language = {en},
	number = {1},
	urldate = {2021-06-30},
	journal = {Nuclear Engineering and Technology},
	author = {Mosleh, ALI},
	month = feb,
	year = {2014},
	keywords = {Advanced PRA Methods, PRA Applications and Lesson Leaned, Probabilistic Risk Assessment},
	pages = {1--10},
}

@article{mandelli_multi-unit_2019-1,
	title = {Multi-unit dynamic {PRA}},
	volume = {185},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832017308530},
	doi = {10.1016/j.ress.2018.12.029},
	abstract = {Dynamic Probabilistic Risk Analysis (PRA) methods couple stochastic methods (e.g., RAVEN) with safety analysis codes (e.g., RELAP5-3D) to determine risk associated to complex systems such as nuclear plants. Compared to classical PRA methods, which are based on static logic structures (e.g., Event-Trees, Fault-Trees), they can evaluate with higher resolution the safety impact of timing and sequencing of events on the accident progression. Recently, special attention has been given to nuclear plant sites which consist of multiple units and, in particular, on the safety impact of system dependencies, shared systems and common resources on core damage frequencies. In the literature, classical PRA methods have been employed to model multi-unit sites in a limited number of cases while Dynamic PRA methods have never been applied to analyze a full multi-unit model. This paper presents a PRA analysis of a multi-unit plant using Dynamic PRA methods. We employ RAVEN as stochastic tool coupled with RELAP5-3D. The site under consideration consists of three units (each unit is composed by a reactor and its associated spent fuel pool) while the considered initiating event is a seismic induced station blackout event. This paper describes in detail how the multi-unit site has been constructed and, in particular, how unit dependencies and shared resources are modeled from both a deterministic and stochastic point of view.},
	language = {en},
	urldate = {2021-06-30},
	journal = {Reliability Engineering \& System Safety},
	author = {Mandelli, D. and Parisi, C. and Alfonsi, A. and Maljovec, D. and Boring, R. and Ewing, S. and St Germain, S. and Smith, C. and Rabiti, C. and Rasmussen, M.},
	month = may,
	year = {2019},
	keywords = {Dynamic PRA, Multi-unit, PRA, Reduced order modeling},
	pages = {303--317},
}

@misc{noauthor_inl_nodate,
	title = {{INL} {National} {University} {Consortium} - {Fission} {Battery} {Initiative}},
	url = {https://nuc1.inl.gov:443/SitePages/Fission%20Battery%20Initiative.aspx},
	language = {en-US},
	urldate = {2021-06-29},
}

@misc{noauthor_global_nodate,
	title = {Global {Report} on {Food} {Crises} - 2021 {\textbar} {World} {Food} {Programme}},
	url = {https://www.wfp.org/publications/global-report-food-crises-2021},
	urldate = {2021-06-28},
}

@article{cohen_contributing_2020,
	title = {Contributing factors to personal protective equipment shortages during the {COVID}-19 pandemic},
	volume = {141},
	issn = {0091-7435},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7531934/},
	doi = {10.1016/j.ypmed.2020.106263},
	abstract = {This study investigates the forces that contributed to severe shortages in personal protective equipment in the US during the COVID-19 crisis. Problems from a dysfunctional costing model in hospital operating systems were magnified by a very large demand shock triggered by acute need in healthcare and panicked marketplace behavior that depleted domestic PPE inventories. The lack of effective action on the part of the federal government to maintain and distribute domestic inventories, as well as severe disruptions to the PPE global supply chain, amplified the problem. Analysis of trade data shows that the US is the world's largest importer of face masks, eye protection, and medical gloves, making it highly vulnerable to disruptions in exports of medical supplies. We conclude that market prices are not appropriate mechanisms for rationing inputs to health because health is a public good. Removing the profit motive for purchasing PPE in hospital costing models, strengthening government capacity to maintain and distribute stockpiles, developing and enforcing regulations, and pursuing strategic industrial policy to reduce US dependence on imported PPE will help to better protect healthcare workers with adequate supplies of PPE., 
          
            
              •
              Market failure and government failure contributed to PPE shortage during COVID-19
            
          
          
            
              •
              Dysfunctional hospital budgeting models disincentivize adequate inventories of PPE
            
          
          
            
              •
              Federal government failed to maintain and distribute domestic inventories of PPE
            
          
          
            
              •
              Pursue strategic industrial policy to reduce US dependence on PPE supply chain
            
          
          
            
              •
              Market prices are inappropriate mechanisms for rationing inputs to health, like PPE},
	urldate = {2021-06-28},
	journal = {Preventive Medicine},
	author = {Cohen, Jennifer and Rodgers, Yana van der Meulen},
	month = dec,
	year = {2020},
	pmid = {33017601},
	pmcid = {PMC7531934},
	pages = {106263},
}

@misc{noauthor_great_nodate,
	title = {The {Great} {State} of {Texas}: explaining the power crisis and what happens next},
	shorttitle = {The {Great} {State} of {Texas}},
	url = {https://www.power-technology.com/features/the-great-state-of-texas-explaining-the-power-crisis-and-what-happens-next/},
	abstract = {The devastating winter storm that hit Texas sent energy prices skyrocketing but made the Bank of America millions of dollars.},
	language = {en-GB},
	urldate = {2021-06-28},
}

@article{padilha_da_silva_analysis_nodate,
	title = {Analysis of criteria applicable to the screening approach used in {PSA} for external events},
	abstract = {Since the Fukushima Daiichi accident, external events analysis has become a priority issue within regulatory bodies, operators, and designers, raising concerns about the capabilities of nuclear power plants to withstand severe conditions. Generally, the methodology applied to the Probabilistic Safety Assessment (PSA) of external events consists of the identification of potential single and combined external hazards, screening of external hazards, analysis of site and plant response, analysis of initiating events and quantification of accident sequences probabilities.},
	language = {en},
	author = {Padilha da Silva, Thiago and Maturana, Marcos Coelho},
	pages = {10},
}

@article{kiam_heong_ang_pid_2005,
	title = {{PID} control system analysis, design, and technology},
	volume = {13},
	issn = {1063-6536},
	url = {http://ieeexplore.ieee.org/document/1453566/},
	doi = {10.1109/TCST.2005.847331},
	number = {4},
	urldate = {2021-06-27},
	journal = {IEEE Transactions on Control Systems Technology},
	author = {{Kiam Heong Ang} and Chong, G. and {Yun Li}},
	month = jul,
	year = {2005},
	keywords = {Autonomous Control Systems, PID Control, PID Tuning},
	pages = {559--576},
}

@article{pj_antsaklis_introduction_1991,
	title = {An introduction to autonomous control systems},
	volume = {11},
	issn = {1066-033X, 1941-000X},
	url = {https://ieeexplore.ieee.org/document/88585/},
	doi = {10.1109/37.88585},
	number = {4},
	urldate = {2021-06-27},
	journal = {IEEE Control Systems},
	author = {{P.J. Antsaklis} and {K.M. Passino} and {S.J. Wang}},
	month = jun,
	year = {1991},
	keywords = {Autonomous Control Systems},
	pages = {5--13},
}

@article{mandelli_linking_2020,
	title = {Linking classical {PRA} models to a dynamic {PRA}},
	volume = {149},
	issn = {0306-4549},
	url = {https://www.sciencedirect.com/science/article/pii/S0306454920304448},
	doi = {10.1016/j.anucene.2020.107746},
	abstract = {This paper presents a series of methods designed to incorporate classical Probabilistic Risk Assessment (PRA) models such as Event Trees (ETs) and Fault Trees (FTs) into dynamic PRA. In contrast to classical PRA, dynamic PRA couples stochastic methods with system simulators to determine the risks associated with complex systems such as nuclear power plants. Compared with classical PRA methods, they can evaluate with higher resolution the safety impact of timing and sequencing of events on the progression of the accident. As part of a dynamic PRA analysis, it is not uncommon that parts of the system to be analyzed might not require a computationally expensive simulation model. These parts could be in fact modeled by employing classical PRA models (e.g., a FT). Here, we present a set of methods and tools that can be used to link the most common classical PRA models (ETs, FTs, reliability block diagrams and Markov models) to simulation codes such as RELAP5-3D: creating a “hybrid PRA.” In order to show the potential of such an hybrid PRA we employ this method to verify ET modeling assumptions (e.g., success criteria) using a large break loss of coolant accident initiating event as a test case. In this respect, we link a set of FTs from the original PRA to the RELAP5-3D code and perform a hybrid PRA. The FTs are employed to model the control logic of several safety systems and to propagate component failures throughout the system. Provided the generated dynamic PRA data, we show how conservative assumptions in the original PRA can be identified and how such original PRA can be modified by updating success criteria captured by the set of RELAP5-3D simulation runs.},
	language = {en},
	urldate = {2021-06-23},
	journal = {Annals of Nuclear Energy},
	author = {Mandelli, D. and Wang, C. and Parisi, C. and Maljovec, D. and Alfonsi, A. and Ma, Z. and Smith, C.},
	month = dec,
	year = {2020},
	keywords = {Dynamic PRA, Event-tree, Fault-tree, Markov model, Probabilistic risk assessment, Reliability block diagram},
	pages = {107746},
}

@inproceedings{poston_nuclear_2002,
	address = {Albuquerque, New Mexico (USA)},
	title = {Nuclear safety calculations for heatpipe power system reactors},
	volume = {608},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1449798},
	doi = {10.1063/1.1449798},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Poston, David I.},
	year = {2002},
	note = {ISSN: 0094243X},
	pages = {748--758},
}

@inproceedings{dyke_phase_2002,
	address = {Albuquerque, New Mexico (USA)},
	title = {Phase 1 space fission propulsion system testing and development progress},
	volume = {608},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1449790},
	doi = {10.1063/1.1449790},
	language = {en},
	urldate = {2021-06-18},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Dyke, Melissa Van and Houts, Mike and Godfroy, Tom and Dickens, Ricky and Poston, David and Kapernick, Rick and Reid, Bob and Salvail, Pat and Ring, Peter and El-Genk, Mohamed S. and Bragg, Mary J.},
	year = {2002},
	note = {ISSN: 0094243X},
	pages = {692--697},
}

@inproceedings{prosek_methodology_2017,
	address = {High Tatras Mountains, Tatranské Matliare, Slovak Republic},
	title = {Methodology for selecting initiating events and hazards for consideration in an extended {PSA}},
	isbn = {978-1-138-62937-0 978-1-351-80973-3},
	url = {http://www.crcnetbase.com/doi/10.1201/9781315210469-421},
	doi = {10.1201/9781315210469-421},
	language = {en},
	urldate = {2021-06-15},
	booktitle = {Safety and {Reliability} – {Theory} and {Applications}},
	publisher = {CRC Press},
	author = {Prošek, A and Wielenberg, A and Löffler, H and Raimond, E},
	month = jun,
	year = {2017},
	pages = {490--490},
}

@techreport{daniell_review_2019,
	title = {Review of state-of-the art for hazard and multi-hazard characterisation},
	language = {English},
	number = {2810899},
	author = {Daniell, James and Schaefer, Andreas and Wenzel, Friedemann and Hacker, Eric},
	month = apr,
	year = {2019},
	pages = {252},
}

@techreport{noauthor_nei_nodate,
	title = {{NEI} 20-09 {Performance} of {PRA} {Peer} {Reviews} {Using} the {ASME}/{ANS} {Advanced} {Non}-{LWR} {PRA} {Standard}},
	url = {https://www.nrc.gov/docs/ML2030/ML20302A115.pdf},
	number = {ML20302A115},
	urldate = {2021-06-14},
}

@misc{noauthor_international_nodate,
	title = {International {Nuclear} and {Radiological} {Event} {Scale} ({INES}) {\textbar} {IAEA}},
	url = {https://www.iaea.org/resources/databases/international-nuclear-and-radiological-event-scale},
	urldate = {2021-06-11},
}

@inproceedings{cooper_what_2013,
	address = {Columbia, SC},
	title = {What {HRA} needs to support site-wide, multi-hazard {Level} 2-{PRA}},
	publisher = {American Nuclear Society},
	author = {Cooper, Susan E. and Xing, Jing and Chang, Y. James},
	month = sep,
	year = {2013},
}

@misc{noauthor_stress-strength_nodate,
	title = {Stress-{Strength} {Analysis} - {ReliaWiki}},
	url = {http://reliawiki.org/index.php/Stress-Strength_Analysis},
	urldate = {2021-06-08},
}

@misc{noauthor_generating_nodate,
	title = {Generating {Normal} {Random} {Variables} - {Part} 1: {Inverse} {Transform} {Sampling}},
	shorttitle = {Generating {Normal} {Random} {Variables} - {Part} 1},
	url = {https://www.ttested.com/generating-normal-random-variables-part-1/index.html},
	abstract = {The normal distribution is one of the most important developments in the history of statistics. As well as its useful statistical properties, it is so well-loved for its omnipresence in the natural wo},
	language = {en},
	urldate = {2021-06-07},
	journal = {T-Tested {\textbar} Blogging about all things data},
}

@misc{noauthor_system_nodate,
	title = {System {Reliability} {Theory}: {Models}, {Statistical} {Methods}, and {Applications}, 2nd {Edition} {\textbar} {Wiley}},
	shorttitle = {System {Reliability} {Theory}},
	url = {https://www.wiley.com/en-us/System+Reliability+Theory%3A+Models%2C+Statistical+Methods%2C+and+Applications%2C+2nd+Edition-p-9780471471332},
	abstract = {A thoroughly updated and revised look at system reliability theory Since the first edition of this popular text was published nearly a decade ago, new standards have changed the focus of reliability engineering and introduced new concepts and terminology not previously addressed in the engineering literature. Consequently, the Second Edition of System Reliability Theory: Models, Statistical Methods, and Applications has been thoroughly rewritten and updated to meet current standards. To maximize its value as a pedagogical tool, the Second Edition features: Additional chapters on reliability of maintained systems and reliability assessment of safety-critical systems Discussion of basic assessment methods for operational availability and production regularity New concepts and terminology not covered in the first edition Revised sequencing of chapters for better pedagogical structure New problems, examples, and cases for a more applied focus An accompanying Web site with solutions, overheads, and supplementary information With its updated practical focus, incorporation of industry feedback, and many new examples based on real industry problems and data, the Second Edition of this important text should prove to be more useful than ever for students, instructors, and researchers alike.},
	language = {en-us},
	urldate = {2021-06-07},
	journal = {Wiley.com},
}

@book{rausand_system_2020,
	title = {System {Reliability} {Theory}: {Models}, {Statistical} {Methods}, and {Applications}},
	isbn = {978-1-119-37395-7},
	shorttitle = {System {Reliability} {Theory}},
	abstract = {Handbook and reference for industrial statisticians and system reliability engineers  System Reliability Theory: Models, Statistical Methods, and Applications, Third Edition presents an updated and revised look at system reliability theory, modeling, and analytical methods. The new edition is based on feedback to the second edition from numerous students, professors, researchers, and industries around the world. New sections and chapters are added together with new real-world industry examples, and standards and problems are revised and updated.  System Reliability Theory covers a broad and deep array of system reliability topics, including:  · In depth discussion of failures and failure modes  · The main system reliability assessment methods  · Common-cause failure modeling  · Deterioration modeling  · Maintenance modeling and assessment using Python code  · Bayesian probability and methods  · Life data analysis using R  Perfect for undergraduate and graduate students taking courses in reliability engineering, this book also serves as a reference and resource for practicing statisticians and engineers.  Throughout, the book has a practical focus, incorporating industry feedback and real-world industry problems and examples.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Rausand, Marvin and Barros, Anne and Hoyland, Arnljot},
	month = oct,
	year = {2020},
	note = {Google-Books-ID: JloEEAAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / Stochastic Processes, Technology \& Engineering / Quality Control},
}

@misc{noauthor_great_nodate,
	title = {Great {East} {Japan} {Earthquake}},
	url = {https://www.who.int/westernpacific/emergencies/great-east-japan-earthquake},
	urldate = {2021-06-07},
}

@article{noauthor_advances_2020,
	title = {Advances in {Small} {Modular} {Reactor} {Technology} {Developments} [{A} supplement to : {IAEA} {Advanced} {Reactors} {Information} {System} ({ARIS}]},
	journal = {International Atomic Energy Agency},
	year = {2020},
}

@misc{noauthor_nuclear_nodate,
	title = {Nuclear {Regulatory} {Commission}},
	url = {https://www.nrc.gov/},
	urldate = {2021-06-06},
}

@book{noauthor_assessment_2017,
	address = {Vienna},
	series = {{TECDOC} {Series}},
	title = {Assessment of {Vulnerabilities} of {Operating} {Nuclear} {Power} {Plants} to {Extreme} {External} {Events}},
	isbn = {978-92-0-108817-8},
	url = {https://www.iaea.org/publications/12270/assessment-of-vulnerabilities-of-operating-nuclear-power-plants-to-extreme-external-events},
	number = {1834},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2017},
}

@book{noauthor_probabilistic_2020,
	address = {Vienna},
	series = {{TECDOC} {Series}},
	title = {Probabilistic {Safety} {Assessment} for {Seismic} {Events}},
	isbn = {978-92-0-131420-8},
	url = {https://www.iaea.org/publications/14744/probabilistic-safety-assessment-for-seismic-events},
	number = {1937},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2020},
}

@article{gonze_assessment_2014,
	title = {Assessment of {Dry} and {Wet} {Atmospheric} {Deposits} of {Radioactive} {Aerosols}: {Application} to {Fukushima} {Radiocaesium} {Fallout}},
	volume = {48},
	issn = {0013-936X, 1520-5851},
	shorttitle = {Assessment of {Dry} and {Wet} {Atmospheric} {Deposits} of {Radioactive} {Aerosols}},
	url = {https://pubs.acs.org/doi/10.1021/es502590s},
	doi = {10.1021/es502590s},
	abstract = {The Fukushima Dai-ichi nuclear accident led to massive atmospheric deposition of radioactive substances onto the land surfaces. The spatial distribution of deposits has been estimated by Japanese authorities for gamma-emitting radionuclides through either airborne monitoring surveys (since April 2011) or in situ gamma-ray spectrometry of bare soil areas (since summer 2011). We demonstrate that signiﬁcant diﬀerences exist between the two surveys for radiocaesium isotopes and that these diﬀerences can be related to dry deposits through the use of physically based relationships involving aerosol deposition velocities. The methodology, which has been applied to cesium-134 and cesium-137 deposits within 80-km of the nuclear site, provides reasonable spatial estimations of dry and wet deposits that are discussed and compared to atmospheric numerical simulations from the Japanese Atomic Energy Agency and the French Institute of Radioprotection and Nuclear Safety. As a complementary approach to numerical simulations, this ﬁeld-based analysis has the possibility to contribute information that can be applied to the understanding and assessment of dose impacts to human populations and the environment around Fukushima.},
	language = {en},
	number = {19},
	urldate = {2021-05-26},
	journal = {Environmental Science \& Technology},
	author = {Gonze, Marc-André and Renaud, Philippe and Korsakissok, Irène and Kato, Hiroaki and Hinton, Thomas G. and Mourlon, Christophe and Simon-Cornu, Marie},
	month = oct,
	year = {2014},
	pages = {11268--11276},
}

@techreport{von_schoenberg_aerosol_2020,
	type = {preprint},
	title = {Aerosol dynamics and dispersion of radioactive particles},
	url = {https://acp.copernicus.org/preprints/acp-2020-669/acp-2020-669.pdf},
	abstract = {Abstract. In an event of a nuclear power plant failure with release of radioactive material into the atmosphere, dispersion modelling is used to understand, how the released radioactivity is spread. For the dispersion of particles, Lagrangian Particle Dispersion Models, LPDMs are commonly used in which model particles, representing the released material, are transported through the atmosphere. These model particles are usually inert and undergo only first order processes such as dry deposition and simplified wet deposition along the path through the atmosphere. Aerosol dynamic processes including coagulation, condensational growth, chemical interactions, formation of new particles and interaction with new aerosol sources are usually neglected in such models. The objective for this study is to analyse the importance of including more advanced aerosol dynamic processes in LPDM simulations for the use in radioactive preparedness. In this investigation, a fictitious NPP failure, commencing with hourly separation for a full year, is studied for three geographically and atmospherically different sites. We conclude that: a) modelling of wet deposition by incorporating an advanced cloud parameterisation is advisable since, it significantly influence simulated levels of airborne activity as well as the formation of hotspots, and b) with advanced cloud parametrisation in the model, the inclusion of full aerosol dynamics can make a difference in single events, especially for formation of hot spots e.g. in 5 \% of the simulated cases the decrease of airborne radioactivity concentration differed with more than 60 \%-points compared to a simplified version of the model.},
	language = {en},
	urldate = {2021-05-26},
	institution = {Aerosols/Atmospheric Modelling/Troposphere/Physics (physical properties and processes)},
	author = {von Schoenberg, Pontus and Tunved, Peter and Grahn, Håkan and Wiedensohler, Alfred and Krejci, Radovan and Brännström, Niklas},
	month = sep,
	year = {2020},
	doi = {10.5194/acp-2020-669},
}

@article{morino_atmospheric_2011,
	title = {Atmospheric behavior, deposition, and budget of radioactive materials from the {Fukushima} {Daiichi} nuclear power plant in {March} 2011: {RADIOACTIVE} {MATERIALS} {FROM} {FUKUSHIMA}},
	volume = {38},
	issn = {00948276},
	shorttitle = {Atmospheric behavior, deposition, and budget of radioactive materials from the {Fukushima} {Daiichi} nuclear power plant in {March} 2011},
	url = {http://doi.wiley.com/10.1029/2011GL048689},
	doi = {10.1029/2011GL048689},
	language = {en},
	number = {7},
	urldate = {2021-05-26},
	journal = {Geophysical Research Letters},
	author = {Morino, Yu and Ohara, Toshimasa and Nishizawa, Masato},
	month = apr,
	year = {2011},
	pages = {n/a--n/a},
}

@article{garrick_response_2012,
	title = {Response},
	volume = {32},
	copyright = {© 2012 Society for Risk Analysis},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.2011.01763.x},
	doi = {https://doi.org/10.1111/j.1539-6924.2011.01763.x},
	language = {en},
	number = {3},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John},
	year = {2012},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2011.01763.x},
	pages = {373--373},
}

@article{garrick_quantitative_2010,
	title = {Quantitative {Risk} {Assessment} of the {New} {York} {State} {Operated} {West} {Valley} {Radioactive} {Waste} {Disposal} {Area}},
	volume = {30},
	copyright = {© 2010 Society for Risk Analysis},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.2010.01418.x},
	doi = {https://doi.org/10.1111/j.1539-6924.2010.01418.x},
	abstract = {This article is based on a quantitative risk assessment (QRA) that was performed on a radioactive waste disposal area within the Western New York Nuclear Service Center in western New York State. The QRA results were instrumental in the decision by the New York State Energy Research and Development Authority to support a strategy of in-place management of the disposal area for another decade. The QRA methodology adopted for this first of a kind application was a scenario-based approach in the framework of the triplet definition of risk (scenarios, likelihoods, consequences). The measure of risk is the frequency of occurrence of different levels of radiation dose to humans at prescribed locations. The risk from each scenario is determined by (1) the frequency of disruptive events or natural processes that cause a release of radioactive materials from the disposal area; (2) the physical form, quantity, and radionuclide content of the material that is released during each scenario; (3) distribution, dilution, and deposition of the released materials throughout the environment surrounding the disposal area; and (4) public exposure to the distributed material and the accumulated radiation dose from that exposure. The risks of the individual scenarios are assembled into a representation of the risk from the disposal area. In addition to quantifying the total risk to the public, the analysis ranks the importance of each contributing scenario, which facilitates taking corrective actions and implementing effective risk management. Perhaps most importantly, quantification of the uncertainties is an intrinsic part of the risk results. This approach to safety analysis has demonstrated many advantages of applying QRA principles to assessing the risk of facilities involving hazardous materials.},
	language = {en},
	number = {8},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John and Stetkar, John W. and Bembia, Paul J.},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2010.01418.x},
	keywords = {Quantitative risk assessment (QRA), West Valley, radioactive waste, risk triplet, scenarios},
	pages = {1219--1230},
}

@article{garrick_interval_2010,
	title = {Interval {Analysis} {Versus} {Probabilistic} {Analysis}},
	volume = {30},
	copyright = {© 2010 Society for Risk Analysis},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.2010.01360.x},
	doi = {https://doi.org/10.1111/j.1539-6924.2010.01360.x},
	language = {en},
	number = {3},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. J.},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.2010.01360.x},
	pages = {369--370},
}

@article{garrick_comments_2004,
	title = {Comments on “{CAPPS} {II}: {The} {Foundation} of {Aviation} {Security}?”},
	volume = {24},
	issn = {1539-6924},
	shorttitle = {Comments on “{CAPPS} {II}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0272-4332.2004.00492.x},
	doi = {https://doi.org/10.1111/j.0272-4332.2004.00492.x},
	language = {en},
	number = {4},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0272-4332.2004.00492.x},
	pages = {925--927},
}

@article{kaplan_fitting_2001,
	title = {Fitting {Hierarchical} {Holographic} {Modeling} into the {Theory} of {Scenario} {Structuring} and a {Resulting} {Refinement} to the {Quantitative} {Definition} of {Risk}},
	volume = {21},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/0272-4332.215153},
	doi = {https://doi.org/10.1111/0272-4332.215153},
	abstract = {A point of view is suggested from which the Hierarchical Holographic Modeling (HHM) method can be seen as one more method within the Theory of Scenario Structuring (TSS), which is that part of Quantitative Risk Assessment having to do with the task of identifying the set of risk scenarios. Seen in this way, HHM brings strongly to our attention the fact that different methods within TSS can result in different sets of risk scenarios for the same underlying problem. Although this is not a problem practically, it is a bit awkward conceptually from the standpoint of the “set of triplets” definition of risk, in which the scenario set is part of the definition. Accordingly, the present article suggests a refinement to the set of triplets definition, which removes the specific set of scenarios, found by any of the TSS methods, from the definition of risk and casts it, instead, as an approximation to the “true” set of scenarios that is native to the problem at hand and not affected by the TSS method used.},
	language = {en},
	number = {5},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Kaplan, Stan and Haimes, Yacov Y. and Garrick, B. John},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/0272-4332.215153},
	keywords = {Theory of scenario structuring, hierarchical holographic modeling, quantitative risk assessment},
	pages = {807--807},
}

@article{garrick_perspectives_2002,
	title = {Perspectives on the {Use} of {Risk} {Assessment} to {Address} {Terrorism}},
	volume = {22},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/0272-4332.00052},
	doi = {https://doi.org/10.1111/0272-4332.00052},
	language = {en},
	number = {3},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John},
	year = {2002},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/0272-4332.00052},
	pages = {421--423},
}

@article{garrick_risk_1989,
	title = {Risk {Assessment} {Practices} in the {Space} {Industry}: {The} {Move} {Toward} {Quantification}},
	volume = {9},
	issn = {1539-6924},
	shorttitle = {Risk {Assessment} {Practices} in the {Space} {Industry}},
	url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.1989.tb01209.x},
	doi = {https://doi.org/10.1111/j.1539-6924.1989.tb01209.x},
	language = {en},
	number = {1},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John},
	year = {1989},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.1989.tb01209.x},
	pages = {1--7},
}

@article{garrick_recent_1984,
	title = {Recent {Case} {Studies} and {Advancements} in {Probabilistic} {Risk} {Assessment}},
	volume = {4},
	issn = {1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.1984.tb00946.x},
	doi = {https://doi.org/10.1111/j.1539-6924.1984.tb00946.x},
	abstract = {During the period from 1977 to 1984, Pickard, Lowe and Garrick, Inc., had the lead in preparing several full scope probabilistic risk assessments for electric utilities. Five of those studies are discussed from the point of view of advancements and lessons learned. The objective and trend of these studies is toward utilization of the risk models by the plant owners as risk management tools. Advancements that have been made are in presentation and documentation of the PRAs, generation of more understandable plant level information, and improvements in methodology to facilitate technology transfer. Specific areas of advancement are in the treatment of such issues as dependent failures, human interaction, and the uncertainty in the source term. Lessons learned cover a wide spectrum and include the importance of plant specific models for meaningful risk management, the role of external events in risk, the sensitivity of contributors to choice of risk index, and the very important finding that the public risk is extremely small. The future direction of PRA is to establish less dependence on experts for in-plant application. Computerizing the PRAs such that they can be accessed on line and interactively is the key.},
	language = {en},
	number = {4},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Garrick, B. John},
	year = {1984},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.1984.tb00946.x},
	keywords = {management, reliability, risk, safety},
	pages = {267--279},
}

@article{kaplan_misconceptions_1981,
	title = {Some {Misconceptions} {About} {Misconceptions}: {A} {Response} to {Abramson}},
	volume = {1},
	issn = {1539-6924},
	shorttitle = {Some {Misconceptions} {About} {Misconceptions}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1539-6924.1981.tb01421.x},
	doi = {https://doi.org/10.1111/j.1539-6924.1981.tb01421.x},
	language = {en},
	number = {4},
	urldate = {2021-05-25},
	journal = {Risk Analysis},
	author = {Kaplan, Stanley and Garrick, B. John},
	year = {1981},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1539-6924.1981.tb01421.x},
	pages = {231--233},
}

@techreport{noauthor_probabilistic_nodate,
	title = {{PROBABILISTIC} {SAFETY} {ASSESSMENT} {FOR} {RESEARCH} {REACTORS}},
	language = {en},
	number = {IAEA-TECDOC-400},
	institution = {IAEA},
	pages = {118},
}

@article{wang_review_2020,
	title = {A review of the research into the relations between hazards in multi-hazard risk analysis},
	volume = {104},
	issn = {0921-030X, 1573-0840},
	url = {http://link.springer.com/10.1007/s11069-020-04259-3},
	doi = {10.1007/s11069-020-04259-3},
	abstract = {With the development of disaster-risk research, it has been found that many areas are prone to the simultaneous occurrence of natural disasters and technological accidents. Such events are known as “multi-hazard.” Increasing attention has been paid to multi-hazard risk, and the theory and methods of multi-hazard risk analysis have been put forward and applied in some areas. Compared with single-hazard risk analysis, multi-hazard risk analysis is more complex and challenging. Researchers typically focus on the characteristics of specific multi-hazard scenarios. However, when multiple hazards occur simultaneously, the relationship between them may be complex. At present, there are still many confusing descriptions of the relationship between hazards, and there are also differences in the research methods for different multi-hazard scenarios. This paper clarifies the relationship between hazards in multi-hazard scenarios by dividing them into three categories: mutually amplified hazards, mutually exclusive hazards, and non-influential hazards. A series of risk analysis methods have been reviewed for different hazard relationships (e.g., Natech events, human-induced hazards, disaster chains, the domino effect, and concurrent hazards), and possible challenges and solutions have been put forward.},
	language = {en},
	number = {3},
	urldate = {2021-05-23},
	journal = {Natural Hazards},
	author = {Wang, Jiajun and He, Zhichao and Weng, Wenguo},
	month = dec,
	year = {2020},
	pages = {2003--2026},
}

@article{he_risk_2020,
	title = {A {Risk} {Assessment} {Method} for {Multi}‐{Hazard} {Coupling} {Disasters}},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/risa.13628},
	doi = {10.1111/risa.13628},
	language = {en},
	urldate = {2021-05-23},
	journal = {Risk Analysis},
	author = {He, Zhichao and Weng, Wenguo},
	month = nov,
	year = {2020},
	pages = {risa.13628},
}

@article{ming_quantitative_2015,
	title = {Quantitative multi-hazard risk assessment with vulnerability surface and hazard joint return period},
	volume = {29},
	issn = {1436-3240, 1436-3259},
	url = {http://link.springer.com/10.1007/s00477-014-0935-y},
	doi = {10.1007/s00477-014-0935-y},
	abstract = {Risk assessment plays an important role in disaster risk management. Existing multi-hazard risk assessment models are often qualitative or semi-quantitative in nature and used for comparative study of regional risk levels. They cannot estimate directly probability of disaster losses from the joint impact of several hazards. In this paper, a quantitative approach of multi-hazard risk assessment based on vulnerability surface and joint return period of hazards is put forward to assess the risk of crop losses in the Yangtze River Delta region of China. The impact of strong wind and ﬂood, the two most prominent agricultural hazards in the area, is analyzed. The multihazard risk assessment process consists of three steps. First, a vulnerability surface, which denotes the functional relationship between the intensity of the hazards and disaster losses, was built using the crop losses data for losses caused by strong wind and ﬂood in the recent 30 years. Second, the joint probability distribution of strong wind and ﬂood was established using the copula functions.},
	language = {en},
	number = {1},
	urldate = {2021-05-23},
	journal = {Stochastic Environmental Research and Risk Assessment},
	author = {Ming, Xiaodong and Xu, Wei and Li, Ying and Du, Juan and Liu, Baoyin and Shi, Peijun},
	month = jan,
	year = {2015},
	pages = {35--44},
}

@article{kappes_challenges_2012,
	title = {Challenges of analyzing multi-hazard risk: a review},
	volume = {64},
	issn = {0921-030X, 1573-0840},
	shorttitle = {Challenges of analyzing multi-hazard risk},
	url = {http://link.springer.com/10.1007/s11069-012-0294-2},
	doi = {10.1007/s11069-012-0294-2},
	abstract = {Many areas of the world are prone to several natural hazards, and effective risk reduction is only possible if all relevant threats are considered and analyzed. However, in contrast to single-hazard analyses, the examination of multiple hazards poses a range of additional challenges due to the differing characteristics of processes. This refers to the assessment of the hazard level, as well as to the vulnerability toward distinct processes, and to the arising risk level. As comparability of the single-hazard results is strongly needed, an equivalent approach has to be chosen that allows to estimate the overall hazard and consequent risk level as well as to rank threats. In addition, the visualization of a range of natural hazards or risks is a challenging task since the high quantity of information has to be depicted in a way that allows for easy and clear interpretation. The aim of this contribution is to give an outline of the challenges each step of a multi-hazard (risk) analysis poses and to present current studies and approaches that face these difﬁculties.},
	language = {en},
	number = {2},
	urldate = {2021-05-23},
	journal = {Natural Hazards},
	author = {Kappes, Melanie S. and Keiler, Margreth and von Elverfeldt, Kirsten and Glade, Thomas},
	month = nov,
	year = {2012},
	pages = {1925--1958},
}

@article{choine_multi_2015,
	title = {A {Multi} {Hazard} {Risk} {Assessment} {Methodology} {Accounting} for {Cascading} {Hazard} {Events}},
	abstract = {The INFRARISK project is developing reliable stress tests on European Critical Infrastructure using integrated tools for decision-support. This aims to achieve higher infrastructure network resilience to rare and low probability extreme events. As part of the project, a hazard assessment methodology is developed to account for extreme natural hazards with cascading effects. Often hazard scenarios arising from cascading effects lead to disastrous consequences because such hazards are not prepared for. In particular, this paper focuses on the cascading hazard scenario involving earthquake triggered landslides. Traditional risk analysis considers each risk source as independent from the others. As a consequence, values for risk are usually defined regardless of interactions among the multiple risks present in a region. The current approach accounts for interaction between the two hazards in such a way that the probabilities of occurrence can be aggregated as part of an overall risk assessment methodology. The methodology is then demonstrated on a virtual road network case study as a proof of concept.},
	language = {en},
	author = {Choine, Mairéad Ní},
	year = {2015},
	pages = {8},
}

@inproceedings{poston_design_2002,
	address = {Albuquerque, New Mexico (USA)},
	title = {Design and analysis of the {SAFE}-400 space fission reactor},
	volume = {608},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1449775},
	doi = {10.1063/1.1449775},
	language = {en},
	urldate = {2021-05-22},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Poston, David I. and Kapernick, Richard J. and Guffee, Ray M.},
	year = {2002},
	note = {ISSN: 0094243X},
	pages = {578--588},
}

@inproceedings{bragg-sitton_reactor_2004,
	address = {Albuquerque, New Mexico (USA)},
	title = {Reactor {Start}-up and {Control} {Methodologies}: {Consideration} of the {Space} {Radiation} {Environment}},
	volume = {699},
	shorttitle = {Reactor {Start}-up and {Control} {Methodologies}},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1649623},
	doi = {10.1063/1.1649623},
	language = {en},
	urldate = {2021-05-22},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Bragg-Sitton, Shannon M.},
	year = {2004},
	note = {ISSN: 0094243X},
	pages = {614--622},
}

@article{noauthor_epa_nodate,
	title = {{EPA} {Radiogenic} {Cancer} {Risk} {Models} and {Projections} for the {U}.{S}. {Population}},
	language = {en},
	pages = {175},
}

@book{noauthor_health_2006,
	address = {Washington, D.C.},
	title = {Health {Risks} from {Exposure} to {Low} {Levels} of {Ionizing} {Radiation}: {BEIR} {VII} {Phase} 2},
	isbn = {978-0-309-09156-5},
	shorttitle = {Health {Risks} from {Exposure} to {Low} {Levels} of {Ionizing} {Radiation}},
	url = {http://www.nap.edu/catalog/11340},
	language = {en},
	urldate = {2021-05-21},
	publisher = {National Academies Press},
	month = mar,
	year = {2006},
	doi = {10.17226/11340},
	note = {Pages: 11340},
}

@article{shimizu_operation_2014,
	title = {Operation and maintenance experience from the {HTTR} database},
	volume = {51},
	issn = {0022-3131},
	url = {https://doi.org/10.1080/00223131.2014.946568},
	doi = {10.1080/00223131.2014.946568},
	abstract = {The Japan Atomic Energy Agency has been establishing a database of operation and maintenance experience for the High Temperature Engineering Test Reactor. The objective of this database is to share information from operation and maintenance experience and make use of the knowledge gained in the design, construction, and operation of future High Temperature Gas-cooled Reactors (HTGRs). Between 1997 and 2012, more than 1000 events have been registered in this database system.This paper describes trends in operation and maintenance events recorded in this database, including experience gained from the Great East Japan Earthquake. The paper also identifies the following significant items that are expected to be useful in the design of future HTGRs: (1) performance degradation of helium gas compressors, (2) malfunction of the reserved shutdown system in the reactivity control system, (3) problems with emergency gas turbine generators, and (4) consequences of the Great East Japan Earthquake.},
	number = {11-12},
	urldate = {2021-05-18},
	journal = {Journal of Nuclear Science and Technology},
	author = {Shimizu, Atsushi and Furusawa, Takayuki and Homma, Fumitaka and Inoi, Hiroyuki and Umeda, Masayuki and Kondo, Masaaki and Isozaki, Minoru and Fujimoto, Nozomu and Iyoku, Tatsuo},
	month = dec,
	year = {2014},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00223131.2014.946568},
	keywords = {Great East Japan Earthquake, HTGR, HTTR, database, events, experience, lessons learned, maintenance, operation},
	pages = {1444--1451},
}

@article{zhang_shandong_2016,
	title = {The {Shandong} {Shidao} {Bay} 200 {MWe} {High}-{Temperature} {Gas}-{Cooled} {Reactor} {Pebble}-{Bed} {Module} ({HTR}-{PM}) {Demonstration} {Power} {Plant}: {An} {Engineering} and {Technological} {Innovation}},
	volume = {2},
	issn = {2095-8099},
	shorttitle = {The {Shandong} {Shidao} {Bay} 200 {MWe} {High}-{Temperature} {Gas}-{Cooled} {Reactor} {Pebble}-{Bed} {Module} ({HTR}-{PM}) {Demonstration} {Power} {Plant}},
	url = {https://www.sciencedirect.com/science/article/pii/S2095809916301552},
	doi = {10.1016/J.ENG.2016.01.020},
	abstract = {After the first concrete was poured on December 9, 2012 at the Shidao Bay site in Rongcheng, Shandong Province, China, the construction of the reactor building for the world's first high-temperature gas-cooled reactor pebble-bed module (HTR-PM) demonstration power plant was completed in June, 2015. Installation of the main equipment then began, and the power plant is currently progressing well toward connecting to the grid at the end of 2017. The thermal power of a single HTR-PM reactor module is 250 MWth, the helium temperatures at the reactor core inlet/outlet are 250/750 °C, and a steam of 13.25 MPa/567 °C is produced at the steam generator outlet. Two HTR-PM reactor modules are connected to a steam turbine to form a 210 MWe nuclear power plant. Due to China's industrial capability, we were able to overcome great difficulties, manufacture first-of-a-kind equipment, and realize series major technological innovations. We have achieved successful results in many aspects, including planning and implementing R\&D, establishing an industrial partnership, manufacturing equipment, fuel production, licensing, site preparation, and balancing safety and economics; these obtained experiences may also be referenced by the global nuclear community.},
	language = {en},
	number = {1},
	urldate = {2021-05-18},
	journal = {Engineering},
	author = {Zhang, Zuoyi and Dong, Yujie and Li, Fu and Zhang, Zhengming and Wang, Haitao and Huang, Xiaojin and Li, Hong and Liu, Bing and Wu, Xinxin and Wang, Hong and Diao, Xingzhong and Zhang, Haiquan and Wang, Jinhua},
	month = mar,
	year = {2016},
	keywords = {High-temperature gas-cooled reactor, High-temperature gas-cooled reactor pebble-bed module, Modular high-temperature gas-cooled reactor, Nuclear energy, Pebble bed},
	pages = {112--118},
}

@techreport{copinger_fort_2004,
	title = {Fort {Saint} {Vrain} {Gas} {Cooled} {Reactor} {Operational} {Experience}},
	url = {http://www.osti.gov/servlets/purl/1495207/},
	language = {en},
	number = {NUREG/CR--6839, ORNL/TM--2003/223, 1495207},
	urldate = {2021-05-17},
	author = {Copinger, D. A. and Moses, D. L. and Cupidon, L. R.},
	month = jan,
	year = {2004},
	doi = {10.2172/1495207},
	pages = {NUREG/CR--6839, ORNL/TM--2003/223, 1495207},
}

@article{maraba_pid_2011,
	title = {{PID} {Neural} {Network} {Based} {Speed} {Control} of {Asynchronous} {Motor} using {Programmable} {Logic} {Controller}},
	volume = {11},
	issn = {1582-7445, 1844-7600},
	url = {http://www.aece.ro/abstractplus.php?year=2011&number=4&article=4},
	doi = {10.4316/AECE.2011.04004},
	language = {en},
	number = {4},
	urldate = {2021-05-14},
	journal = {Advances in Electrical and Computer Engineering},
	author = {Maraba, V. A. and Kuzucuoglu, A. E.},
	year = {2011},
	pages = {23--28},
}

@techreport{noauthor_high_2010,
	title = {High {Temperature} {Gas} {Cooled} {Reactor} {Fuels} and {Materials}},
	language = {English},
	institution = {International Atomic Energy Agency},
	year = {2010},
}

@article{chisholm_systematic_2020,
	title = {A systematic approach to identify initiating events and its relationship to {Probabilistic} {Risk} {Assessment}: {Demonstrated} on the {Molten} {Salt} {Reactor} {Experiment}},
	volume = {129},
	issn = {0149-1970},
	shorttitle = {A systematic approach to identify initiating events and its relationship to {Probabilistic} {Risk} {Assessment}},
	url = {https://www.sciencedirect.com/science/article/pii/S0149197020302559},
	doi = {10.1016/j.pnucene.2020.103507},
	abstract = {One of the first steps in developing a risk assessment model is an exhaustive search for initiating events, which is a systematic and comprehensive starting point to answer the question “what can go wrong?” for a given system design. Identifying Postulated Initiating Events (PIEs) for a reactor design that is at a conceptual or preliminary stage facilitates the incorporation of risk insights into the next iteration of the design process and allows for the early establishment of more quantifiable risk assessment models, such as event sequence diagrams and event tree analysis. Liquid-Fueled Molten Salt Reactors (LF-MSRs) are an example of an advanced reactor technology that does not benefit from having a wealth of operating experience or prior risk-informed safety assessment efforts. Furthermore, design details, such as normal operating conditions and the composition of radioactive material inventories, can deviate substantially from those in other reactors, such that a systematic and comprehensive approach to identifying PIEs for an LF-MSR may highlight accident initiators that have not previously been identified. In the present work, the Master Logic Diagram (MLD) and Hazards and Operability (HAZOP) study approaches were used, together, to identify and consider PIEs for multiple inventories of radioactive material across various Plant Operating States (POSs) in a specific LF-MSR design -- the Molten Salt Reactor Experiment (MSRE). Potentially risk-significant PIEs identified during the analyses of the MSRE design are presented. Furthermore, considerations for exhaustively identifying PIEs for advanced reactor designs are discussed; for example, the combination of inductive and deductive methods was found to provide a robust identification of PIEs in a way that is conducive to the analysis of a nuclear reactor design at an early design stage.},
	language = {en},
	urldate = {2021-05-12},
	journal = {Progress in Nuclear Energy},
	author = {Chisholm, Brandon M. and Krahn, Steven L. and Fleming, Karl N.},
	month = nov,
	year = {2020},
	keywords = {Initiating events, Master logic diagram, Molten salt reactor, Process hazards analysis, Risk assessment, Safety},
	pages = {103507},
}

@article{sandhu_external_2019,
	title = {{EXTERNAL} {MULTI}-{HAZARD} {PROBABILISTIC} {RISK} {ASSESSMENT} {METHODOLOGY} {AND} {APPLICATIONS}: {A} {REVIEW} {OF} {THE} {STATE}- {OF}-{THE}-{ART}},
	language = {en},
	author = {Sandhu, Harleen Kaur and Patel, Parth and Gupta, Abhinav and Mihara, Yoshinori},
	year = {2019},
	pages = {10},
}

@article{ebisawa_evaluation_1994,
	title = {Evaluation of response factors for seismic probabilistic safety assessment of nuclear power plants},
	volume = {147},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/0029549394902062},
	doi = {https://doi.org/10.1016/0029-5493(94)90206-2},
	abstract = {This paper presents a method for evaluating “response factors” of components in nuclear power plants for use in a seismic probabilistic safety assessment (PSA). The response factor here is a measure of conservatism included in response calculations in seismic design analysis of components and is defined as a ratio of conservative design response to actual response. This method has the following characteristic features: (1) the components are classified into several groups based on the differences in their location and in the vibration models used in design response analyses; (2) the response factors are decomposed into subfactors corresponding to the stages of the seismic response analyses in the design practices; (3) the response factors for components are calculated as products of subfactors; (4) the subfactors are expressed either as a single value or as a function of parameters that influence the response of components. This paper describes the outline of this method and results from an application to a sample problem in which response factors were quantified for examples of components selected from the groups.},
	number = {2},
	journal = {Nuclear Engineering and Design},
	author = {Ebisawa, K. and Abe, K. and Muramatsu, K. and Itoh, M. and Kohno, K. and Tanaka, T.},
	year = {1994},
	pages = {197--210},
}

@article{ebisawa_evaluation_1994-1,
	title = {Evaluation of response factors for seismic probabilistic safety assessment of nuclear power plants},
	volume = {147},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549394902062},
	doi = {10.1016/0029-5493(94)90206-2},
	abstract = {This paper presents a method for evaluating "response factors" of components in nuclear power plants for use in a seismic probabilistic safety assessment (PSA).The response factor here is a measure of conservatism included in response calculations in seismic design analysis of components and is defined as a ratio of conservative design response to actual response. This method has the following characteristic features: (1) the components are classified into several groups based on the differences in their location and in the vibration models used in design response analyses; (2) the response factors are decomposed into subfactors corresponding to the stages of the seismic response analyses in the design practices; (3) the response factors for components are calculated as products of subfactors; (4) the subfactors are expressed either as a single value or as a function of parameters that influence the response of components.},
	language = {en},
	number = {2},
	urldate = {2021-05-02},
	journal = {Nuclear Engineering and Design},
	author = {Ebisawa, K. and Abe, K. and Muramatsu, K. and Itoh, M. and Kohno, K. and Tanaka, T.},
	month = mar,
	year = {1994},
	pages = {197--210},
}

@article{dezert_multi-criteria_2010,
	title = {Multi-criteria decision making based on {DSmT}-{AHP}},
	abstract = {In this paper, we present an extension of the multicriteria decision making based on the Analytic Hierarchy Process (AHP) which incorporates uncertain knowledge matrices for generating basic belief assignments (bba’s). The combination of priority vectors corresponding to bba’s related to each (sub)criterion is performed using the Proportional Conﬂict Redistribution rule no. 5 proposed in Dezert-Smarandache Theory (DSmT) of plausible and paradoxical reasoning. The method presented here, called DSmT-AHP, is illustrated on very simple examples.},
	language = {en},
	author = {Dezert, J and Tacnet, J M and Batton-Hubert, Mireille and Smarandache, F},
	year = {2010},
	pages = {9},
}

@article{noauthor_implementation_nodate,
	title = {Implementation of {Risk}-{Informed} {Categorization} and {Alternative} {Treatment} of {Structures}, {Systems}, and {Components} {For} {Nuclear} {Plants}},
	language = {en},
	pages = {2},
}

@article{noauthor_psa_nodate,
	title = {{PSA} {Applications} {Guide}},
	pages = {94},
}

@article{noauthor_framework_nodate,
	title = {A {Framework} for {Using} {Risk} {Insights} in {Integrated} {Risk}-{Informed} {Decision}-{Making}},
	language = {en},
	pages = {160},
}

@article{noauthor_insights_2018,
	title = {Insights on {Risk} {Margins} at {Nuclear} {Power} {Plants}: {A} {Technical} {Evaluation} of {Margins} in {Relation} to {Quantitative} {Health} {Objectives} and {Subsidiary} {Risk} {Goals} in the {United} {States}},
	language = {en},
	year = {2018},
	pages = {20},
}

@article{noauthor_approach_nodate,
	title = {An {Approach} to {Risk} {Aggregation} for {Risk}-{Informed} {Decision}-{Making}},
	language = {en},
	pages = {102},
}

@article{presley_practical_nodate,
	title = {Practical {Guidance} on the {Use} of {Probabilistic} {Risk} {Assessment} in {Risk}-{Informed} {Applications} with a {Focus} on the {Treatment} of {Uncertainty}},
	language = {en},
	author = {Presley, M},
	pages = {178},
}

@article{noauthor_treatment_nodate,
	title = {Treatment of {Parameter} and {Modeling} {Uncertainty} for {Probabilistic} {Risk} {Assessments}},
	language = {en},
	pages = {176},
}

@incollection{spitzer_guidance_2004,
	address = {London},
	title = {Guidance for {External} {Events} {Analysis}},
	isbn = {978-1-4471-1057-6 978-0-85729-410-4},
	url = {http://link.springer.com/10.1007/978-0-85729-410-4_241},
	language = {en},
	urldate = {2021-05-01},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer London},
	author = {Knochenhauer, Michael and Louko, Pekka},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	doi = {10.1007/978-0-85729-410-4_241},
	pages = {1498--1503},
}

@article{caillat_international_nodate,
	title = {International {Conference} on {Thermoelectrics} {June} 2005 {Clemson}, {South} {Carolina}},
	language = {en},
	author = {Caillat, T and Sakamoto, J and Jewell, A and Cheng, J and Paik, J and Gascoin, F and Snyder, J and Blair, R},
	pages = {38},
}

@article{swaminathan_event_1999,
	title = {The {Event} {Sequence} {Diagram} framework for dynamic {Probabilistic} {Risk} {Assessment}},
	volume = {63},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832098000271},
	doi = {10.1016/S0951-8320(98)00027-1},
	language = {en},
	number = {1},
	urldate = {2021-04-30},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Smidts, C.},
	month = jan,
	year = {1999},
	pages = {73--90},
}

@misc{noauthor_openpra_nodate,
	title = {{OpenPRA}: {Open}-{Source} {Framework} for {Probabilistic} {Risk} {Assessment} {\textbar} {Probabilistic} {Risk} {Assessment} {Group}},
	url = {https://openpra.org},
	urldate = {2021-04-30},
}

@article{breeding_nureg-1150_1992,
	title = {The {NUREG}-1150 probabilistic risk assessment for the {Surry} {Nuclear} {Power} {Station}},
	volume = {135},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/002954939290301B},
	doi = {10.1016/0029-5493(92)90301-B},
	language = {en},
	number = {1},
	urldate = {2021-04-29},
	journal = {Nuclear Engineering and Design},
	author = {Breeding, R.J. and Helton, J.C. and Murfin, W.B. and Smith, L.N. and Johnson, J.D. and Jow, H.-N. and Shiver, A.W.},
	month = jun,
	year = {1992},
	pages = {29--59},
}

@article{avila_methodology_nodate,
	title = {Methodology for calculation of doses to man and implementation in {Pandora}},
	language = {en},
	author = {Avila, Rodolfo and Bergström, Ulla},
	pages = {23},
}

@article{gupta_blockchain_2020,
	title = {Blockchain {For} {Dummies}®, 3rd {IBM} {Limited} {Edition}},
	language = {en},
	author = {Gupta, Manav},
	year = {2020},
	pages = {50},
}

@article{ellingwood_validation_1990,
	title = {Validation studies of seismic {PRAs}},
	volume = {123},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/002954939090237R},
	doi = {10.1016/0029-5493(90)90237-R},
	language = {en},
	number = {2-3},
	urldate = {2021-04-12},
	journal = {Nuclear Engineering and Design},
	author = {Ellingwood, Bruce},
	month = oct,
	year = {1990},
	pages = {189--196},
}

@article{swiler_epistemic_nodate,
	title = {Epistemic {Uncertainty} {Quantification} {Tutorial}},
	language = {en},
	author = {Swiler, Laura P and Paez, Thomas L and Mayes, Randall L},
	pages = {26},
}

@article{lele_how_2020,
	title = {How {Should} {We} {Quantify} {Uncertainty} in {Statistical} {Inference}?},
	volume = {8},
	issn = {2296-701X},
	url = {https://www.frontiersin.org/article/10.3389/fevo.2020.00035/full},
	doi = {10.3389/fevo.2020.00035},
	abstract = {An inferential statement is any statement about the parameters, form of the underlying process or future outcomes. An inferential statement, that provides an approximation to the truth, becomes “statistical” only when there is a measure of uncertainty associated with it. The uncertainty of an inferential statement is generally quantiﬁed in terms of probability of the strength of approximation to the truth. This is what we term “inferential uncertainty.” Answer to this question has signiﬁcant implications in statistical decision making where inferential uncertainty is combined with loss functions for predicted outcomes to compute the risk associated with the decision. The Classical and the Evidential paradigms use aleatory (frequency based) probability for quantifying uncertainty whereas the Bayesian approach utilizes epistemic (belief based) probability. To compute aleatory uncertainty, one needs to answer the question: which experiment is being repeated, hypothetically or otherwise? whereas computing epistemic uncertainty requires: What is the prior belief? Deciding which type of uncertainty is appropriate for scientiﬁc inference has been a contentious issue and without proper resolution because it has been commonly formulated in terms of statements about parameters, that are statistical constructs, not observables. Common to these approaches is the desire to understand the data generating mechanism. Whether one follows the Frequentist or the Bayesian approach inferential statements concerning prediction are aleatory in nature and are practically ascertainable. We consider the desirable characteristics for quantiﬁcation of uncertainty as: (1) Parameterization and data transformation invariance, (2) correct predictive coverage, (3) uncertainty that depends only on the data at hand and the hypothesized data generating mechanism, and (4) diagnostics for model misspeciﬁcation and guidance for correction. We examine the Classical, Bayesian and Evidential approaches in the light of these characteristics. Unfortunately, none of these inferential approaches possesses all of our desiderata although the Evidential approach seems to come closest. Choosing an inferential approach, thus, involves choosing between either specifying the hypothetical experiment that will be repeated or equivalently a sampling distribution of the estimator or a prior distribution on the model space or an evidence function.},
	language = {en},
	urldate = {2021-04-08},
	journal = {Frontiers in Ecology and Evolution},
	author = {Lele, Subhash R.},
	month = mar,
	year = {2020},
	pages = {35},
}

@misc{noauthor_redundant_nodate,
	title = {Redundant {System} {Basic} {Concepts}},
	url = {https://www.ni.com/en-us/innovations/white-papers/08/redundant-system-basic-concepts.html},
	abstract = {This paper provides a basic background into the types of redundancy that can be built into a system and explains how to calculate the effect of redundancy on system reliability.},
	language = {en},
	urldate = {2021-04-07},
}

@misc{leon_time_2020,
	title = {Time and {Space} {Complexity}},
	url = {https://levelup.gitconnected.com/time-and-space-complexity-725dcba31902},
	abstract = {Basics and the big O notation.},
	language = {en},
	urldate = {2021-04-07},
	journal = {Medium},
	author = {Leon, Keno},
	month = mar,
	year = {2020},
}

@misc{leon_time_2020-1,
	title = {Time and {Space} {Complexity}},
	url = {https://levelup.gitconnected.com/time-and-space-complexity-725dcba31902},
	abstract = {Basics and the big O notation.},
	language = {en},
	urldate = {2021-04-07},
	journal = {Medium},
	author = {Leon, Keno},
	month = mar,
	year = {2020},
}

@misc{noauthor_boost_nodate,
	title = {The {Boost} {Graph} {Library} - 1.75.0},
	url = {https://www.boost.org/doc/libs/1_75_0/libs/graph/doc/index.html},
	urldate = {2021-04-05},
}

@incollection{ionescu_exact_1999,
	address = {Boston, MA},
	title = {Exact {Methods} to {Compute} {Network} {Reliability}},
	isbn = {978-1-4612-7280-9 978-1-4612-1782-4},
	url = {http://link.springer.com/10.1007/978-1-4612-1782-4_20},
	abstract = {In this paper, we present and compare some exact methods to resolve the network reliability problems. These problems concern all kinds of networks, such as computer, communication or power networks. When components of the network are subject to random failures, the network may or may not continue functioning after the failures of some components. The probability that the network will function is its reliability. Networks are modeled by a graph G = (V,E) composed of elements that fail independently of each other with known probabilities. The K-terminal reliability problem has been studied extensively. It consists in evaluating the probability that a given subset of vertices, denoted K, is connected. This problem is NP-hard. We propose here to expose the main methods, developed since the 1970s. We first consider the enumeration methods using elementary states, paths or cuts. Then we explain the factoring method performed by the reductions. These allow to treat series-parallel graph in linear time. At last, we present the decomposition method implemented as a table-based reduction algorithm and that allows us to resolve the reliability problem in linear time for graphs with bounded treewidth.},
	language = {en},
	urldate = {2021-04-05},
	booktitle = {Statistical and {Probabilistic} {Models} in {Reliability}},
	publisher = {Birkhäuser Boston},
	author = {Lucet, Corinne and Manouvrier, Jean-François},
	editor = {Ionescu, D. C. and Limnios, N.},
	year = {1999},
	doi = {10.1007/978-1-4612-1782-4_20},
	pages = {279--294},
}

@article{chaturvedi_network_nodate,
	title = {Network {Reliability}},
	language = {en},
	author = {Chaturvedi, Sanjay K},
	pages = {260},
}

@article{noauthor_ieee_2017,
	title = {{IEEE} {Guide} for {General} {Principles} of {Reliability} {Analysis} of {Nuclear} {Power} {Generating} {Station} {Systems} and {Other} {Nuclear} {Facilities}},
	doi = {10.1109/IEEESTD.2017.7891100},
	abstract = {General reliability and availability analysis methods that can be applied to structures, systems, and components (SSCs) in nuclear power generating stations and other nuclear facilities are contained in this guide.},
	journal = {IEEE Std 352-2016 (Revision of IEEE Std 352-1987)},
	month = apr,
	year = {2017},
	note = {Conference Name: IEEE Std 352-2016 (Revision of IEEE Std 352-1987)},
	keywords = {Class 1E, Failure analysis, IEEE 352™, IEEE Standards, MTBF, MTTF, MTTR, Nuclear power generation, Power system reliability, Safety, availability, failure rate, nuclear power generating station, reliability},
	pages = {1--155},
}

@misc{noauthor_data_dictionary_simulated_datadocx_nodate,
	title = {data\_dictionary\_simulated\_data.docx},
	url = {https://docs.google.com/document/d/1sId1zVxi8kj_WFLUFjydGSxrkiKUm0Ym/edit?usp=drive_web&ouid=100220442048567187901&rtpof=true&usp=embed_facebook},
	abstract = {Supply Chain Simulated Data  This dataset contains simulated data for 7,567 drug supply chains. Each drug supply chain can have multiple applications (e.g. NDAs); each application can have multiple API facilities (upstream), and each API facility can be associated with multiple FDF facilities (...},
	language = {en},
	urldate = {2021-04-04},
	journal = {Google Docs},
}

@misc{noauthor_flow_2021,
	title = {Flow network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Flow_network&oldid=1007783330},
	abstract = {In graph theory, a flow network (also known as a transportation network) is a directed graph where each edge has a capacity and each edge receives a flow. The amount of flow on an edge cannot exceed the capacity of the edge. Often in operations research, a directed graph is called a network, the vertices are called nodes and the edges are called arcs.  A flow must satisfy the restriction that the amount of flow into a node equals the amount of flow out of it, unless it is a source, which has only outgoing flow, or sink, which has only incoming flow.  A network can be used to model traffic in a computer network, circulation with demands, fluids in pipes, currents in an electrical circuit, or anything similar in which something travels through a network of nodes.},
	language = {en},
	urldate = {2021-04-04},
	journal = {Wikipedia},
	month = feb,
	year = {2021},
	note = {Page Version ID: 1007783330},
}

@article{kennedy_probabilistic_1980,
	title = {Probabilistic seismic safety study of an existing nuclear power plant},
	volume = {59},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549380902034},
	doi = {10.1016/0029-5493(80)90203-4},
	language = {en},
	number = {2},
	urldate = {2021-04-01},
	journal = {Nuclear Engineering and Design},
	author = {Kennedy, R.P. and Cornell, C.A. and Campbell, R.D. and Kaplan, S. and Perla, H.F.},
	month = aug,
	year = {1980},
	pages = {315--338},
}

@article{swaminathan_cassini_1997,
	title = {The {Cassini} {Mission} probabilistic risk analysis: {Comparison} of two probabilistic dynamic methodologies},
	volume = {58},
	issn = {09518320},
	shorttitle = {The {Cassini} {Mission} probabilistic risk analysis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832097000525},
	doi = {10.1016/S0951-8320(97)00052-5},
	language = {en},
	number = {1},
	urldate = {2021-03-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Swaminathan, S. and Van-Halle, J.-Y. and Smidts, Carol and Mosleh, Ali and Bell, Steve and Rudolph, Kevin and Mulvihill, Robert J. and Bream, Bruce},
	month = oct,
	year = {1997},
	pages = {1--14},
}

@misc{noauthor_prism_nodate,
	title = {{PRISM} - {Case} {Studies} - {Embedded} {Control} {System}},
	url = {https://www.prismmodelchecker.org/casestudies/embedded.php},
	urldate = {2021-03-19},
}

@article{muppala_stochastic_1994,
	title = {Stochastic reward nets for reliability prediction},
	volume = {1},
	number = {2},
	journal = {Communications in Reliability, Maintainability and Serviceability},
	author = {Muppala, J. and Ciardo, G. and Trivedi, K.},
	month = jul,
	year = {1994},
	note = {Publisher: SAE International},
	pages = {9--20},
}

@misc{noauthor_error_nodate,
	title = {Error {Propagation} in {Embedded} {Control} {Systems}},
	url = {https://docs.google.com/document/d/1Fu_HowN3F94GtheLF1r6TCAObhzUzGmMycqrytvuV4E/edit?usp=embed_facebook},
	abstract = {Probabilistic Risk Assessment Group      Error Propagation in Embedded Control Systems   Documented History Log REV DESCRIPTION DATE v0.1 First Edition March 2021  Acronyms and Abbreviations  AA Acronyms and Abbreviations     Contents Documented History Log	2 Acronyms and Ab...},
	language = {en},
	urldate = {2021-03-19},
	journal = {Google Docs},
}

@incollection{noauthor_appendix_2010,
	title = {Appendix {D}: {Minimal} {Cut} {Set} {Analysis}},
	isbn = {978-0-470-93542-2},
	shorttitle = {Appendix {D}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470935422.app4},
	abstract = {This chapter contains sections titled: Introduction Minimal Cut Set Analysis Boolean Algebra Sample Problem 2},
	language = {en},
	urldate = {2021-03-17},
	booktitle = {Guidelines for {Chemical} {Process} {Quantitative} {Risk} {Analysis}},
	publisher = {John Wiley \& Sons, Ltd},
	year = {2010},
	doi = {10.1002/9780470935422.app4},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470935422.app4},
	pages = {661--670},
}

@article{kim_preliminary_2019,
	title = {{PRELIMINARY} {STUDY} {ON} {THE} {QUANTIFICATION} {OF} {COMPONENT} {LEVEL} {FAILURE} {FREQUENCY} {BY} {MULTI}-{HAZARD}},
	abstract = {After the Fukushima accident occurred, the risk assessment of a natural hazard is more emphasized. There has been many researches to clarify residual risks those were not considered before. The multi-hazard risk is one of them. For the risk assessment of multi-hazard external events, the combination of multi-event and multi-hazard were categorized by its characteristics. In this research, the multi-event was classified into three types as the independent, simultaneous, and sequential events. A mathematical expression for the multi-hazard curve and the multi-fragility curve was developed and a convolution equation composed of these two curves was derived. An example case for the multi-hazard risk assessment was performed with regard to tsunami and earthquake induced multi-hazard. The failure frequency considering only a single hazard were compared with that of a multi-hazard quantitatively. As a result, the failure frequency increased by multi-hazard, therefore, the multi-hazard effect needs to be considered.},
	language = {en},
	author = {Kim, Jung Han and Kim, Min Kyu and Choi, In-Kil},
	year = {2019},
	pages = {6},
}

@book{noauthor_health_1990,
	address = {Washington, D.C.},
	title = {Health {Effects} of {Exposure} to {Low} {Levels} of {Ionizing} {Radiation}: {BEIR} {V}},
	isbn = {978-0-309-03995-6},
	shorttitle = {Health {Effects} of {Exposure} to {Low} {Levels} of {Ionizing} {Radiation}},
	url = {http://www.nap.edu/catalog/1224},
	language = {en},
	urldate = {2021-03-12},
	publisher = {National Academies Press},
	month = jan,
	year = {1990},
	doi = {10.17226/1224},
	note = {Pages: 1224},
}

@book{noauthor_nasa_2004,
	address = {Office of Safety and Mission Assurance},
	series = {8000 - {Safety}, {Quality}, {Reliability}, {Maintainability}},
	title = {{NASA} {Software} {Safety} {Guidebook}},
	url = {https://standards.nasa.gov/standard/nasa/nasa-gb-871913},
	abstract = {The focus of this document is on analysis, development, and assurance of safety-critical software, including firmware (e.g. software residing in non-volatile memory, such as ROM, EPROM, EEPROM, or flash memory) and programmable logic. This document also discusses issues with contractor-developed software. It provides guidance on how to address creation and assurance of safety-critical software within the overall software development, management, risk management, and assurance activities.},
	language = {en-US},
	number = {NASA-GB-8719.13},
	publisher = {NASA},
	month = mar,
	year = {2004},
}

@phdthesis{wang_hybrid_2007,
	type = {{PhD}},
	title = {Hybrid {Causal} {Logic} {Methodology} for {Risk} {Assessment}},
	url = {http://drum.lib.umd.edu/handle/1903/7729},
	abstract = {Probabilistic Risk Assessment is being increasingly used in a number of industries such as nuclear, aerospace, chemical process, to name a few.  Probabilistic Risk Assessment (PRA) characterizes risk in terms of three questions:  (1) What can go wrong? (2) How likely is it? (3) What are the consequences?  Probabilistic Risk Assessment studies answer these questions by systematically postulating and quantifying undesired scenarios in a highly integrated, top down fashion. The PRA process for technological systems typically includes the following steps: objective and scope definition, system familiarization, identification of initiating events, scenario modeling, quantification, uncertainty analysis, sensitivity analysis, importance ranking, and data analysis. 

Fault trees and event trees are widely used tools for risk scenario analysis in PRAs of technological systems. This methodology is most suitable for systems made of hardware components.  A more comprehensive treatment of risks of technical systems needs to consider the entire environment within which such systems are designed and operated.  This environment includes the physical environment, the socio-economic environment, and in some cases the regulatory and oversight environment.  The technical system, supported by an organization of people in charge of its operation, is at the cross-section of these environments. 

In order to develop a more comprehensive risk model for these systems, an important step is to extend the modeling capabilities of the conventional Probabilistic Risk Assessment methodology to also include risks associated with human activities and organizational factors in addition to hardware and software failures and adverse conditions of the physical environment.  The causal modeling should also extend to the influence of regulatory and oversight functions.  This research offers such a methodology. It proposes a multi-layered modeling approach so that most the appropriate techniques are applied to different individual domains of the system.  The approach is called the Hybrid Causal Logic (HCL) methodology.  The main layers include:  (a) A model to define safety/risk context.  This is done using a technique known as event sequence diagram (ESD) method that helps define the kinds of accidents and incidents that can occur in relation to the system being considered;  (b) A model that captures the behaviors of the physical system (hardware, software, and environmental factors) as possible causes or contributing factors to accidents and incidents delineated by the event sequence diagrams.  This is done by common system modeling techniques such as fault tress (FT); and (c) A model to extend the causal chain of events to their potential human and organizational roots.  This is done using Bayesian belief networks (BBN).  Bayesian belief networks are particularly useful as they do not require complete knowledge of the relation between causes and effects.  The integrated model is therefore a hybrid causal model with the corresponding sets of taxonomies and analytical and computational procedures.  

In this research, a methodology to combine fault trees, event trees or event sequence diagrams, and Bayesian belief networks has been introduced. Since such hybrid models involve significant interdependencies, the nature of such dependencies are first determined to pave the way for developing proper algorithmic solutions of the logic model. Major achievements of this work are: (1) development of the Hybrid Causal Logic model concept and quantification algorithms; (2) development and testing of computer implementation of algorithms (collaborative work); (3) development and implementation of algorithms for HCL-based importance measures, an uncertainty propagation method the BBN models, and algorithms for qualitative-quantitative Bayesian belief networks; and (4) development and testing of the Integrated Risk Information System (IRIS) software based on HCL methodology.},
	language = {en\_US},
	urldate = {2019-01-20},
	school = {University of Maryland},
	author = {Wang, Chengdong},
	month = nov,
	year = {2007},
}

@article{research_drugs_2018,
	title = {Drugs: {FDA} {Glossary} of {Terms}},
	url = {https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-glossary-terms},
	abstract = {What’s the meaning of this? Welcome to the Drugs@FDA glossary of terms. From abbreviated new drug application to therapeutic equivalence codes, FDA defines it.},
	language = {en},
	urldate = {2021-03-09},
	journal = {FDA},
	author = {Research, Center for Drug Evaluation and},
	month = nov,
	year = {2018},
	note = {Publisher: FDA},
}

@incollection{ojovan_chapter_2019,
	title = {Chapter 9 - {Principles} of {Nuclear} {Waste} {Management}},
	isbn = {978-0-08-102702-8},
	url = {https://www.sciencedirect.com/science/article/pii/B9780081027028000091},
	abstract = {The acceptance by society of risks associated with radiation and radioactive materials is conditional on the benefits to be gained from their use. A key issue, if radiation and radionuclides are to continue to be used and accepted by the public, is the safe management of nuclear waste. There is justifiable public concern about nuclear waste management, in particular that planned for high level waste (HLW), which may include spent nuclear fuel and spent sealed radioactive sources. Lack of public acceptance often leads to the so-called “not in my backyard” (NIMBY) syndrome. Although this lack of acceptance has a number of roots, the central issue is that of safety and it is not only a question of achieving safety but also of convincing people that safety is achievable. Despite the technical difficulties associated with HLW disposal it cannot be postponed and remains the responsibility of the current generation. The essence of this requirement is expressed in the two internationally approved documents, ‘Safety Series No. 111-F. The Principles of Radioactive Waste Management’ and ‘Safety Standard SF-1. Fundamental Safety Principles’. Although not legally binding these two publications have involved input from many countries with experience in the nuclear industry with the latter document recommended as the reference basis of radioactive waste management safety standards. Moreover the International Atomic Energy Agency has approved procedures for the safety of unreprocessed spent fuel as well as HLW management through the legally binding Joint Convention, which establishes commonly shared safety objectives and sets out specific obligations for states generating such materials. The Radioactive Waste Management Committee of the Organisation for Economic Co-operation and Development Nuclear Energy Agency approved the Environmental and Ethical Basis of the Geological Disposal of Long-lived Radioactive Waste. All of these efforts and publications are geared towards ensuring both safety and public acceptance of nuclear energy worldwide.},
	language = {en},
	urldate = {2021-03-08},
	booktitle = {An {Introduction} to {Nuclear} {Waste} {Immobilisation} ({Third} {Edition})},
	publisher = {Elsevier},
	author = {Ojovan, Michael I. and Lee, William E. and Kalmykov, Stepan N.},
	editor = {Ojovan, Michael I. and Lee, William E. and Kalmykov, Stepan N.},
	month = jan,
	year = {2019},
	doi = {10.1016/B978-0-08-102702-8.00009-1},
	keywords = {High level waste, IAEA, International Atomic Energy Agency, fundamental principles, radioactive waste management},
	pages = {107--118},
}

@article{groth_data-informed_2012,
	title = {A data-informed {PIF} hierarchy for model-based {Human} {Reliability} {Analysis}},
	volume = {108},
	issn = {0951-8320},
	url = {https://www.sciencedirect.com/science/article/pii/S0951832012001561},
	doi = {10.1016/j.ress.2012.08.006},
	abstract = {This paper addresses three problems associated with the use of Performance Shaping Factors in Human Reliability Analysis. (1) There are more than a dozen Human Reliability Analysis (HRA) methods that use Performance Influencing Factors (PIFs) or Performance Shaping Factors (PSFs) to model human performance, but there is not a standard set of PIFs used among the methods, nor is there a framework available to compare the PIFs used in various methods. (2) The PIFs currently in use are not defined specifically enough to ensure consistent interpretation of similar PIFs across methods. (3) There are few rules governing the creation, definition, and usage of PIF sets. This paper introduces a hierarchical set of PIFs that can be used for both qualitative and quantitative HRA. The proposed PIF set is arranged in a hierarchy that can be collapsed or expanded to meet multiple objectives. The PIF hierarchy has been developed with respect to a set fundamental principles necessary for PIF sets, which are also introduced in this paper. This paper includes definitions of the PIFs to allow analysts to map the proposed PIFs onto current and future HRA methods. The standardized PIF hierarchy will allow analysts to combine different types of data and will therefore make the best use of the limited data in HRA. The collapsible hierarchy provides the structure necessary to combine multiple types of information without reducing the quality of the information.},
	language = {en},
	urldate = {2021-03-05},
	journal = {Reliability Engineering \& System Safety},
	author = {Groth, Katrina M. and Mosleh, Ali},
	month = dec,
	year = {2012},
	keywords = {Human Reliability Analysis, Human error, Performance Influencing Factors, Performance Shaping Factors, Taxonomy},
	pages = {154--174},
}

@article{hunicke_ai_nodate,
	title = {{AI} for {Dynamic} {Difficulty} {Adjustment} in {Games}},
	abstract = {Video Games are boring when they are too easy and frustrating when they are too hard. While most singleplayer games allow players to adjust basic difficulty (easy, medium, hard, insane), their overall level of challenge is often static in the face of individual player input. This lack of flexibility can lead to mismatches between player ability and overall game difficulty.},
	language = {en},
	author = {Hunicke, Robin and Chapman, Vernell},
	pages = {7},
}

@misc{noauthor_finding_nodate,
	title = {Finding {Max} {Flow} using the {Ford}-{Fulkerson} {Algorithm} and {Matthew} {McConaughey}: a step-by-step explanation{\textbar}downey.io},
	url = {https://downey.io/blog/max-flow-ford-fulkerson-algorithm-explanation/},
	urldate = {2021-03-03},
}

@misc{weisstein_network_nodate,
	type = {Text},
	title = {Network {Flow}},
	copyright = {Copyright 1999-2020 Wolfram Research, Inc.  See https://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {https://mathworld.wolfram.com/NetworkFlow.html},
	abstract = {The network flow problem considers a graph G with a set of sources S and sinks T and for which each edge has an assigned capacity (weight), and then asks to find the maximum flow that can be routed from S to T while respecting the given edge capacities. The network flow problem can be solved in time O(n{\textasciicircum}3) (Edmonds and Karp 1972; Skiena 1990, p. 237). It is implemented in the Wolfram Language as FindMaximumFlow[g, source, sink].},
	language = {en},
	urldate = {2021-03-03},
	author = {Weisstein, Eric W.},
	note = {Publisher: Wolfram Research, Inc.},
}

@article{noauthor_nureg-1855_nodate,
	title = {{NUREG}-1855, {Vol}. 1, "{Guidance} on the {Treatment} of {Uncertainties} {Associated} with {PRAs} in {Risk}-{Informed} {Decision} {Making}."},
	language = {en},
	pages = {144},
}

@article{choi_review_2021,
	title = {A review of multihazard risk assessment: {Progress}, potential, and challenges in the application to nuclear power plants},
	volume = {53},
	issn = {22124209},
	shorttitle = {A review of multihazard risk assessment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2212420920314357},
	doi = {10.1016/j.ijdrr.2020.101933},
	abstract = {The risk of natural hazards is continuously increasing because of climate change and the ever-increasing pop­ ulation density. Therefore, understanding and mitigating the risks of natural hazards have become an essential task for critical infrastructure systems (CISs). Particularly, nuclear power plants (NPPs) exposed to multihazards, which are combinations of more than two natural hazards, can lead to severe outcomes. For example, the Fukushima NPP was damaged because of the Great East Japan earthquake and tsunami (2011) and is still at its recovery stage. Therefore, considering the significant consequences of these multihazards, it is essential to un­ derstand the phenomena and their effects on structure systems in a quantitative and probabilistic manner. However, compared with single hazard phenomena, concurrent and successive multihazards have not been relatively extensively studied because of their inherent complexity and limited availability of data. In this paper, we review multihazards in terms of the types of disaster combinations based on analysis level such as hazard, fragility, and risk assessment. Furthermore, state-of-the-art models have been reviewed and the progress, po­ tential, and challenges in the application of multihazard risk research to NPPs are discussed.},
	language = {en},
	urldate = {2021-03-01},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Choi, Eujeong and Ha, Jeong-Gon and Hahm, Deagi and Kim, Min Kyu},
	month = feb,
	year = {2021},
	pages = {101933},
}

@article{dib_consortium_2018,
	title = {Consortium {Blockchains}: {Overview}, {Applications} and {Challenges}},
	shorttitle = {Consortium {Blockchains}},
	abstract = {The Blockchain technology has recently attracted increasing interests worldwide because of its potential to disrupt
existing businesses and to revolutionize the way applications will be built, operated, consumed and marketed in the near future.
While this technology was initially designed as an immutable
and distributed ledger for preventing the double spending of
cryptocurrencies, it is now foreseen as the core backbone of enterprises by enabling the interoperability and collaboration between
organizations. In this context, consortium blockchains emerged
as an interesting architecture concept that benefits from the
transactions’ efficiency and privacy of private blockchains, while leveraging the decentralized governance of public blockchains.
Although many studies have been made on the blockchain
technology in general, the concept of consortium blockchains has
been very little addressed in the literature. To bridge this gap, this article provides a detailed analysis of consortium blockchains,
in terms of architectures, technological components and applications. In particular, the underlying consensus algorithms are
analyzed in details, and a general taxonomy is discussed. Then,
a practical case study that focuses on the consortium blockchain
technology Ethermint is performed in order to highlight its main
advantages and limitations. Finally, various research challenges
and opportunities are discussed.},
	author = {Dib, Omar and Brousmiche, Kei-Léo and Durand, Antoine and Thea, Eric and Hamida, Elyes},
	month = sep,
	year = {2018},
}

@misc{noauthor_scm_nodate,
	title = {{SCM} {Definitions} and {Glossary} of {Terms}},
	url = {https://cscmp.org/CSCMP/Educate/SCM_Definitions_and_Glossary_of_Terms.aspx},
	urldate = {2021-02-26},
}

@misc{noauthor_glossary_nodate,
	title = {Glossary of {Transportation}, {Logistics}, {Supply} {Chain}, and {International} {Trade} {Terms} - {Inbound} {Logistics}},
	url = {https://www.inboundlogistics.com/cms/logistics-glossary/},
	urldate = {2021-02-26},
}

@article{kwag_development_2019,
	title = {Development of {Efficient} {External} {Multi}-{Hazard} {Risk} {Quantification} {Methodology} for {Nuclear} {Facilities}},
	volume = {12},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/12/20/3925},
	doi = {10.3390/en12203925},
	abstract = {Probabilistic safety assessment (PSA) of nuclear facilities on external multi-hazards has become a major issue after the Fukushima accident in 2011. However, the existing external hazard PSA methodology is for single hazard events and cannot cover the impact of multi-hazards. Therefore, this study proposes a methodology for quantifying multi-hazard risks for nuclear energy plants. Speciﬁcally, we developed an eﬃcient multi-hazard PSA methodology based on the probability distribution-based Boolean algebraic approach and sampling-based method, which are currently single-hazard PSA methodologies. The limitations of the probability distribution-based Boolean algebraic approach not being able to handle partial dependencies between the components are solved through this sampling-based method. In addition, we devised an algorithm that was more eﬃcient than the existing algorithm for improving the limits of the current sampling-based method, as it required a signiﬁcant computational time. The proposed methodology was applied from simple examples to single- and multi-hazard PSA examples of actual nuclear power plants. The results showed that the proposed methodology was veriﬁed in terms of accuracy and eﬃciency perspectives. Regarding the sampling-based method, it was conﬁrmed that the proposed algorithm yielded fragility and risk results that have similar degrees of accuracy, even though it extracted a smaller number of samples than the existing algorithm.},
	language = {en},
	number = {20},
	urldate = {2021-02-25},
	journal = {Energies},
	author = {Kwag, Shinyoung and Ha, Jeong Gon and Kim, Min Kyu and Kim, Jung Han},
	month = oct,
	year = {2019},
	pages = {3925},
}

@article{bodda_enhancement_2020,
	title = {Enhancement of risk informed validation framework for external hazard scenario},
	volume = {204},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832020306414},
	doi = {10.1016/j.ress.2020.107140},
	abstract = {In recent years, the U.S. Nuclear Regulatory Commission (USNRC) and the International Atomic Energy Agency (IAEA) have developed methodologies to assess the vulnerabilities of nuclear plants against site speciﬁc extreme hazards. In many cases, advanced simulation tools are being considered to simulate multi-physics, multi-scale phenomena and to evaluate vulnerability of nuclear facilities. The credibility of advanced simulation tools is assessed based on a formal veriﬁcation, validation, and uncertainty quantiﬁcation procedure. One of the key limitations in validation is the lack of relevant experimental data at system-level. This limitation leads to a decrease in the conﬁdence of system-level risk predictions. Therefore, a robust validation framework is needed to formalize the conﬁdence in predictive capability of advanced simulation results. This study enhances the existing risk informed validation methodology, originally proposed by Kwag et al. [1] and Bodda et al. [2], by developing additional attributes and a new set of validation indicies for a complete and wider applicability of the framework. In this manuscript, the methodology to identify the critical path that leads to the system-level failure is illustrated. The overall validation is checked for completeness and consistency by comparing the critical path for both the system-level simulation and experimental models. The applicability of the code for an intended application is represented in terms of various maturity levels and helps in the process of decision making.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Reliability Engineering \& System Safety},
	author = {Bodda, Saran Srikanth and Gupta, Abhinav and Dinh, Nam},
	month = dec,
	year = {2020},
	pages = {107140},
}

@article{bani-mustafa_new_2020,
	title = {A new framework for multi-hazards risk aggregation},
	volume = {121},
	issn = {09257535},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753519308227},
	doi = {10.1016/j.ssci.2019.08.043},
	abstract = {In this paper, we develop a new method for Multi-Hazards Risk Aggregation (MHRA). A hierarchical framework is first developed for evaluating the trustworthiness of the risk assessment. The evaluation is based on two main attributes (criteria), i.e., the strength of knowledge supporting the assessment and the fidelity of the risk assessment model. These two attributes are further broken down into sub-attributes and, finally, leaf attributes. The trustworthiness is calculated using a weighted average of the leaf attributes, in which the weights are calculated using the Dempster Shafer Theory-Analytical Hierarchy Process (DST-AHP). Risk aggregation is, then, performed by a “weighted posterior” method, considering the level of trustworthiness. An application to the risk aggregation of two hazard groups in Nuclear Power Plants (NPP) is illustrated.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Safety Science},
	author = {Bani-Mustafa, Tasneem and Zeng, Zhiguo and Zio, Enrico and Vasseur, Dominique},
	month = jan,
	year = {2020},
	pages = {283--302},
}

@article{kwag_development_2018,
	title = {Development of an earthquake-induced landslide risk assessment approach for nuclear power plants},
	volume = {50},
	issn = {17385733},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1738573318302602},
	doi = {10.1016/j.net.2018.07.016},
	abstract = {Despite recent advances in multi-hazard analysis, the complexity and inherent nature of such problems make quantiﬁcation of the landslide effect in a probabilistic safety assessment (PSA) of NPPs challenging. Therefore, in this paper, a practical approach was presented for performing an earthquake-induced landslide PSA for NPPs subject to seismic hazard. To demonstrate the effectiveness of the proposed approach, it was applied to Korean typical NPP in Korea as a numerical example. The assessment result revealed the quantitative probabilistic effects of peripheral slope failure and subsequent run-out effect on the risk of core damage frequency (CDF) of a NPP during the earthquake event. Parametric studies were conducted to demonstrate how parameters for slope, and physical relation between the slope and NPP, changed the CDF risk of the NPP. Finally, based on these results, the effective strategies were suggested to mitigate the CDF risk to the NPP resulting from the vulnerabilities inherent in adjacent slopes. The proposed approach can be expected to provide an effective framework for performing the earthquake-induced landslide PSA and decision support to increase NPP safety.},
	language = {en},
	number = {8},
	urldate = {2021-02-25},
	journal = {Nuclear Engineering and Technology},
	author = {Kwag, Shinyoung and Hahm, Daegi},
	month = dec,
	year = {2018},
	pages = {1372--1386},
}

@article{kumar_integrated_2015,
	title = {Integrated risk assessment for multi-unit {NPP} sites—{A} comparison},
	volume = {293},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549315003416},
	doi = {10.1016/j.nucengdes.2015.06.025},
	language = {en},
	urldate = {2021-02-25},
	journal = {Nuclear Engineering and Design},
	author = {Kumar, C. Senthil and Hassija, Varun and Velusamy, K. and Balasubramaniyan, V.},
	month = nov,
	year = {2015},
	pages = {53--62},
}

@article{kwag_probabilistic_2017,
	title = {Probabilistic risk assessment framework for structural systems under multiple hazards using {Bayesian} statistics},
	volume = {315},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549317300584},
	doi = {10.1016/j.nucengdes.2017.02.009},
	abstract = {Conventional probabilistic risk assessment (PRA) methodologies (USNRC, 1983; IAEA, 1992; EPRI, 1994; Ellingwood, 2001) conduct risk assessment for different external hazards by considering each hazard separately and independent of each other. The risk metric for a speciﬁc hazard is evaluated by a convolution of the fragility and the hazard curves. The fragility curve for basic event is obtained by using empirical, experimental, and/or numerical simulation data for a particular hazard. Treating each hazard as an independently can be inappropriate in some cases as certain hazards are statistically correlated or dependent. Examples of such correlated events include but are not limited to ﬂooding induced ﬁre, seismically induced internal or external ﬂooding, or even seismically induced ﬁre. In the current practice, system level risk and consequence sequences are typically calculated using logic trees to express the causative relationship between events. In this paper, we present the results from a study on multi-hazard risk assessment that is conducted using a Bayesian network (BN) with Bayesian inference. The framework can consider statistical dependencies among risks from multiple hazards, allows updating by considering the newly available data/information at any level, and provide a novel way to explore alternative failure scenarios that may exist due to vulnerabilities.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Nuclear Engineering and Design},
	author = {Kwag, Shinyoung and Gupta, Abhinav},
	month = apr,
	year = {2017},
	pages = {20--34},
}

@article{hassija_probabilistic_2014,
	title = {Probabilistic safety assessment of multi-unit nuclear power plant sites – {An} integrated approach},
	volume = {32},
	issn = {09504230},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950423014001223},
	doi = {10.1016/j.jlp.2014.07.013},
	abstract = {Multi-unit safety assessment has gained global importance after the Fukushima disaster in 2011. Most of the nuclear sites in the world have more than one reactor and hence it is important to evolve a methodology to systematically assess the safety of the multi-unit site. In this paper, unique features to be addressed in multi-unit safety assessment are discussed and an integrated approach is developed to assess the risk contribution of multiple nuclear plants at the site. The paper highlights the importance of risks for multi-unit sites arising from shared system, common cause failures, failure correlations, cliffedge effects, etc. from different hazards. Though the main emphasis on multi-unit safety is on external hazards, the proposed approach also includes risk from random internal events. The approach developed not only quantiﬁes the frequency of multiple core damage for a multi-unit site but also evaluates site core damage frequency which is the frequency of at least single core damage per site per year.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Journal of Loss Prevention in the Process Industries},
	author = {Hassija, Varun and Senthil Kumar, C. and Velusamy, K.},
	month = nov,
	year = {2014},
	pages = {52--62},
}

@article{yu_large_2015,
	title = {Large {LOCA} accident analysis for {AP1000} under earthquake},
	volume = {77},
	issn = {03064549},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454914005933},
	doi = {10.1016/j.anucene.2014.11.013},
	abstract = {Seismic probabilistic safety assessment (PSA) is developed to give the insight of nuclear power plant risk under earthquake and the main contributors to the risk. However, component failure probability including the initial event frequency is the function of peak ground acceleration (PGA), and all the components especially the different kinds of components at same place will share the common ground shaking, which is one of the important factors to inﬂuence the result. In this paper, we propose an analysis method based on Monte Carlo (MC) simulation in which the effect of all components sharing the same PGA level can be expressed by explicit pattern. The Large LOCA accident in AP1000 is analyzed as an example, based on the seismic hazard curve used in this paper, the core damage frequency is almost equal to the initial event frequency, moreover the frequency of each accident sequence is close to and even equal to the initial event frequency, while the main contributors are seismic events since multi components and systems failures will happen simultaneously when a high value of PGA is sampled. The component failure probability is determined by uncertainties in PGA and in component seismic capacity, and the former is the crucial element to inﬂuence the result.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Annals of Nuclear Energy},
	author = {Yu, Yu and Lv, Xuefeng and Niu, Fenglei},
	month = mar,
	year = {2015},
	pages = {142--147},
}

@article{li_ranking_2009,
	title = {Ranking the {Risks} from {Multiple} {Hazards} in a {Small} {Community}},
	volume = {29},
	issn = {02724332, 15396924},
	url = {http://doi.wiley.com/10.1111/j.1539-6924.2008.01164.x},
	doi = {10.1111/j.1539-6924.2008.01164.x},
	language = {en},
	number = {3},
	urldate = {2021-02-25},
	journal = {Risk Analysis},
	author = {Li, Hua and Apostolakis, George E. and Gifun, Joseph and VanSchalkwyk, William and Leite, Susan and Barber, David},
	month = mar,
	year = {2009},
	pages = {438--456},
}

@techreport{noauthor_elicitation_1990,
	title = {Elicitation and {Use} of {Expert} {Judgment} in {Performance} {Assessment} for {High}-{Level} {Radioactive} {Waste} {Repositories}},
	url = {https://www.nrc.gov/docs/ML0401/ML040150792.pdf},
	number = {NUREG/CR-5411},
	urldate = {2021-02-24},
	year = {1990},
}

@article{cadwallader_preliminary_nodate,
	title = {Preliminary {Failure} {Modes} and {Effects} {Analysis} of the {US} {DCLL} {Test} {Blanket} {Module}},
	language = {en},
	author = {Cadwallader, Lee C},
	pages = {158},
}

@article{sehgal_light_2006,
	title = {{LIGHT} {WATER} {REACTOR} ({LWR}) {SAFETY}},
	abstract = {In this paper, a historical review of the developments in the safety of LWR power plants is presented. The paper reviews the developments prior to the TMI-2 accident, i.e. the concept of the defense in depth, the design basis, the large LOCA technical controversies and the LWR safety research programs. The TMI-2 accident, which became a turning point in the history of the development of nuclear power is described briefly. The Chernobyl accident, which terrified the world and almost completely curtailed the development of nuclear power is also described briefly. The great international effort of research in the LWR design-base and severe accidents, which was, respectively, conducted prior to and following the TMI-2 and Chernobyl accidents is described next. We conclude that with the knowledge gained and the improvements in plant organisation/management and in the training of the staff at the presently-installed nuclear power stations, the LWR plants have achieved very high standards of safety and performance. The Generation 3 + LWR power plants, next to be installed, may claim to have reached the goal of assuring the safety of the public to a very large extent. This review is based on the historical developments in LWR safety that occurred primarily in USA, however, they are valid for the rest of the Western World. This review can not do justice to the many many fine contributions that have been made over the last fifty years to the cause of LWR safety. We apologize if we have not mentioned them. We also apologize for not providing references to many of the fine investigations, which have contributed towards LWR safety earning the conclusions that we describe just above.},
	language = {en},
	journal = {NUCLEAR ENGINEERING AND TECHNOLOGY},
	author = {Sehgal, Bal Raj},
	year = {2006},
	pages = {36},
}

@techreport{noauthor_proposed_2002,
	title = {Proposed {PBMR}, {Safety} {Analysis} {Report}},
	url = {https://elaw.org/system/files/PBMR%20SAR.pdf},
	urldate = {2021-02-17},
	year = {2002},
}

@article{tong_development_2012,
	series = {5th {International} {Topical} {Meeting} on {High} {Temperature} {Reactor} {Technology} ({HTR} 2010)},
	title = {Development of {Probabilistic} {Safety} {Assessment} with respect to the first demonstration nuclear power plant of high temperature gas cooled reactor in {China}},
	volume = {251},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S0029549311008491},
	doi = {10.1016/j.nucengdes.2011.09.055},
	abstract = {Due to the unique concept of HTR-PM (High Temperature Gas Cooled Reactor-Pebble Bed Module) design, Chinese nuclear authority has anticipated that HTR-PM will bring challenge to the present regulation. The pilot use of PSA (Probabilistic Safety Assessment) during HTR-PM design and safety review is deemed to be the necessary and efficient tool to tackle the problem, and is actively encouraged as indicated in the authority's specific policy statement on HTR-PM project. The paper summarizes the policy statement to set up the base of PSA development and application activities. The up-to-date status of HTR-PM PSA development and the risk-informed application activities are introduced in this paper as the follow-up response to the policy statement. For open discussion, the paper hereafter puts forward several technical issues which have been encountered during HTR-PM PSA development. Since HTR-PM PSA development experience has the general conclusion that many of the PSA elements can be and have been implemented successfully by the traditional PSA techniques, only the issues which extra innovative efforts may be needed are highlighted in this paper. They are safety goal and risk metrics, PSA modeling framework for the non-water reactors, passive system reliability evaluation, initiating events frequencies and component reliability data estimation techniques for the new reactors and so on. The paper presents the way in which the encountered technical issues were or will be solved, although the proposed way may not be the ultimate best solution. The paper intends to express the standpoint that although the PSA of new reactor has the inherent weakness due to the insufficient information and larger data uncertainty, the problem of component reliability data is much less severe than people have conceived. The unique design conception and functional features of the reactors can influence the results more significantly than the component reliability data. What we are benefited from PSA is indeed the systematic way which PSA follows. This is more important especially for the new reactors.},
	language = {en},
	urldate = {2021-02-17},
	journal = {Nuclear Engineering and Design},
	author = {Tong, Jiejuan and Zhao, Jun and Liu, Tao and Xue, Dazhi},
	month = oct,
	year = {2012},
	pages = {385--390},
}

@techreport{han_overview_2012,
	title = {Overview of {VHTR}'s {PSA} approach in {Korea}},
	url = {http://inis.iaea.org/Search/search.aspx?orig_q=RN:48018732},
	language = {English},
	urldate = {2021-02-17},
	author = {Han, Seok-Jung},
	year = {2012},
	note = {Number: NEA-CSNI-R--2012-2},
}

@article{bassi_level_2010,
	title = {Level 1 probabilistic safety assessment to support the design of the {CEA} {2400MWth} gas-cooled fast reactor},
	volume = {240},
	issn = {0029-5493},
	url = {https://www.sciencedirect.com/science/article/pii/S002954931000539X},
	doi = {10.1016/j.nucengdes.2010.09.003},
	abstract = {As part of the design of a 4th generation reactor, the integration of safety in the early phase of the concepts is expected. To date, probabilistic insights are increasingly employed in the safety demonstration in combination with the deterministic approach (e.g. to identify the sequences of complex failures, to justify the categorization of situations) and used, even at an early stage of design, to identify the reliability of systems and equipment to handle the safety objectives (expressed in terms of core damage frequency targets). Within this frame, the CEA has undertaken to assess the benefit of developing a probabilistic model to support the design of the 2400MWth gas-cooled fast reactor. In the building process of this level 1 probabilistic safety assessment, a first phase consisted in making a preliminary model that took only into account families of initiating events that were defined for the design of the decay heat removal dedicated loops, namely the loss of coolant accidents (representative of medium pressure situations) and loss of off-site power/station black-out transients (representative of high pressure situations). Owing to the results obtained with this preliminary L1PSA model, it emerged that an increased reliability of the DHR function in high pressure conditions (i.e. characterized by IEs not associated to the loss of integrity of the helium pressure boundary) is suitable to reduce the overall core damage frequency. The track was therefore chosen to require the use of normal loops as first line of provision of the DHR function, possibly including components or particular operating modes related to the secondary and tertiary circuits. In addition, this final L1PSA model is characterized by success criteria based on transient calculations performed with the CATHARE2 code and to a perimeter extended to all representative internal IEs at full operating power. This paper presents the building process and the main results related to these two successive L1PSA models. Finally, useful insights are translated into GFR design improvements that are leading to an overall CDF at full operating power that satisfies nowadays with the probabilistic target defined for 3rd generation reactors, being at least the objective for 4th generation reactors.},
	language = {en},
	number = {11},
	urldate = {2021-02-17},
	journal = {Nuclear Engineering and Design},
	author = {Bassi, C. and Azria, Ph. and Balmain, M.},
	month = nov,
	year = {2010},
	pages = {3758--3780},
}

@techreport{kadambi_probabilistic_2006,
	title = {Probabilistic {Risk} {Assessment} {Approach} for the {Pebble} {Bed} {Modular} {Reactor}},
	language = {en},
	author = {Kadambi, Mr N Prasad},
	year = {2006},
	pages = {75},
}

@techreport{borchardt_proposed_nodate,
	title = {Proposed {Licensing} {Approach} for the {Pebble} {Bed} {Modular} {Reactor} in the {United} {States}},
	language = {en},
	author = {Borchardt, William and Lyons, James and Cubbage, Amy and Jackson, Diane and Rubin, Stuart and Wilson, Jerry and Moore, Janice},
	pages = {94},
}

@techreport{noauthor_preliminary_1986,
	title = {Preliminary safety information document for the standard {MHTGR}. {Volume} 4},
	url = {https://www.osti.gov/biblio/712655-preliminary-safety-information-document-standard-mhtgr-volume},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {DOE/HTGR-86-024-Vol.4},
	urldate = {2021-02-17},
	institution = {Stone and Webster Engineering Corp., Boston, MA (United States); Gas-Cooled Reactor Associates, La Jolla, CA (United States)},
	month = jan,
	year = {1986},
	doi = {https://doi.org/10.2172/712655},
	doi = {https://doi.org/10.2172/712655},
}

@inproceedings{pantano_thermal_2005,
	address = {Albuquerque, New Mexico (USA)},
	title = {Thermal {Analysis} of {Step} 2 {GPHS} for {Next} {Generation} {Radioisotope} {Power} {Source} {Missions}},
	volume = {746},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.1867204},
	doi = {10.1063/1.1867204},
	language = {en},
	urldate = {2021-02-15},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Pantano, David R.},
	year = {2005},
	note = {ISSN: 0094243X},
	pages = {827--834},
}

@inproceedings{von_arx_mmrtg_2006,
	address = {Albuquerque, New Mexico (USA)},
	title = {{MMRTG} {Heat} {Rejection} {Summary}},
	volume = {813},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.2169255},
	doi = {10.1063/1.2169255},
	language = {en},
	urldate = {2021-02-15},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {von Arx, Alan V.},
	year = {2006},
	note = {ISSN: 0094243X},
	pages = {743--750},
}

@misc{noauthor_51_nodate,
	title = {5.1 - {Introduction} to {Functions}},
	url = {https://mathonweb.com/help_ebook/html/functions_6.htm},
	urldate = {2021-02-12},
}

@phdthesis{kai_ding_dependability-oriented_nodate,
	title = {Dependability-oriented {Design} and {Analysis} of {Control} {Systems} at the {Model} {Level} under {Random} {Hardware} {Fault}},
	author = {{Kai Ding}},
}

@techreport{coleman_multi-hazard_2016,
	title = {Multi-{Hazard} {Advanced} {Seismic} {Probabilistic} {Risk} {Assessment} {Tools} and {Applications}},
	url = {http://www.osti.gov/servlets/purl/1369534/},
	language = {en},
	number = {INL/EXT--16-40055, 1369534},
	urldate = {2021-02-11},
	author = {Coleman, Justin L. and Bolisetti, Chandu and Veeraraghavan, Swetha and Parisi, Carlo and Prescott, Steven R. and Gupta, Abhinav},
	month = sep,
	year = {2016},
	doi = {10.2172/1369534},
	pages = {INL/EXT--16--40055, 1369534},
}

@article{vaishanav_limitations_2020,
	title = {Limitations of traditional tools for beyond design basis external hazard {PRA}},
	volume = {370},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029549320303939},
	doi = {10.1016/j.nucengdes.2020.110899},
	language = {en},
	urldate = {2021-02-11},
	journal = {Nuclear Engineering and Design},
	author = {Vaishanav, Pragya and Gupta, Abhinav and Bodda, Saran Srikanth},
	month = dec,
	year = {2020},
	pages = {110899},
}

@inproceedings{jung_development_2004,
	address = {London},
	title = {Development of an {Efficient} {BDD} {Algorithm} to {Solve} {Large} {Fault} {Trees}},
	isbn = {978-0-85729-410-4},
	abstract = {This paper presents an efficient BDD (Binary Decision Diagram) algorithm for large fault trees by which subsuming and truncation could be performed in the process of the construction of the BDD structure. That results in a fast computation of the minimal cut sets (MCSs) and a smaller memory usage.},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	publisher = {Springer London},
	author = {Jung, Woo Sik and Han, Sang Hoon and Ha, Jaejoo},
	editor = {Spitzer, Cornelia and Schmocker, Ulrich and Dang, Vinh N.},
	year = {2004},
	pages = {3373--3378},
}

@inproceedings{munshi_opencl_2009,
	address = {Stanford, CA},
	title = {The {OpenCL} specification},
	isbn = {978-1-4673-8873-3},
	url = {http://ieeexplore.ieee.org/document/7478342/},
	doi = {10.1109/HOTCHIPS.2009.7478342},
	urldate = {2021-02-11},
	booktitle = {2009 {IEEE} {Hot} {Chips} 21 {Symposium} ({HCS})},
	publisher = {IEEE},
	author = {Munshi, Aaftab},
	month = aug,
	year = {2009},
	pages = {1--314},
}

@article{karonis_mpich-g2_2003,
	title = {{MPICH}-{G2}: {A} {Grid}-enabled implementation of the {Message} {Passing} {Interface}},
	volume = {63},
	issn = {07437315},
	shorttitle = {{MPICH}-{G2}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0743731503000029},
	doi = {10.1016/S0743-7315(03)00002-9},
	language = {en},
	number = {5},
	urldate = {2021-02-11},
	journal = {Journal of Parallel and Distributed Computing},
	author = {Karonis, Nicholas T. and Toonen, Brian and Foster, Ian},
	month = may,
	year = {2003},
	pages = {551--563},
}

@misc{noauthor_open-psa_nodate,
	title = {The {Open}-{PSA} {Initiative} — {The} {Open}-{PSA} {Model} {Exchange} {Format} 2.0},
	url = {https://open-psa.github.io/mef/mef/open_psa_initiative.html},
	urldate = {2021-02-11},
}

@misc{noauthor_open-psa_nodate-1,
	title = {The {Open}-{PSA} {Model} {Exchange} {Format} — {The} {Open}-{PSA} {Model} {Exchange} {Format} 2.0},
	url = {https://open-psa.github.io/mef/},
	urldate = {2021-02-11},
}

@techreport{noauthor_ieee_nodate,
	title = {{IEEE} {Standard} for {Floating}-{Point} {Arithmetic}},
	url = {http://ieeexplore.ieee.org/document/4610935/},
	urldate = {2021-02-11},
	institution = {IEEE},
	doi = {10.1109/IEEESTD.2008.4610935},
	note = {ISBN: 9780738157528},
}

@inproceedings{hartig_semantics_2018,
	address = {Lyon, France},
	title = {Semantics and {Complexity} of {GraphQL}},
	isbn = {978-1-4503-5639-8},
	url = {http://dl.acm.org/citation.cfm?doid=3178876.3186014},
	doi = {10.1145/3178876.3186014},
	language = {en},
	urldate = {2021-02-11},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference} on {World} {Wide} {Web}  - {WWW} '18},
	publisher = {ACM Press},
	author = {Hartig, Olaf and Pérez, Jorge},
	year = {2018},
	pages = {1155--1164},
}

@techreport{moe_modernization_2020,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/servlets/purl/1700670/},
	abstract = {This report, “Modernization of Technical Requirements for Licensing of Advanced Non-Light Water Reactors: Probabilistic Risk Assessment Approach,” represents a key element in the development of a methodology for the efficient licensing of advanced non-light water reactors (non-LWRs). It is the result of a Licensing Modernization Project (LMP) led by Southern Company and cost-shared by the U.S. Department of Energy (DOE). The LMP has developed detailed proposals for establishing licensing technical requirements to facilitate risk-informed and performance-based design and licensing of advanced non-LWRs. Such a methodology acknowledges enhancements in safety achievable with advanced designs and reflects more recent states of knowledge regarding safety and design innovation, creating an opportunity for reduced regulatory complexity with increased levels of safety. The project builds on best practices, as well as previous activities through DOE and industry-sponsored advanced reactor licensing initiatives.},
	language = {en},
	number = {INL/EXT-20-60395-Rev000, 1700670},
	urldate = {2021-02-10},
	author = {Moe, Wayne},
	month = mar,
	year = {2020},
	doi = {10.2172/1700670},
	pages = {INL/EXT--20--60395--Rev000, 1700670},
}

@incollection{stamatelatos_development_2006,
	title = {Development of the {Mars} {Exploration} {Rover} {PRA} ({PSAM}-0027)},
	isbn = {978-0-7918-0244-1},
	url = {https://asmedigitalcollection.asme.org/ebooks/book/137/chapter/25749/development-of-the-mars-exploration-rover-pra-psam},
	language = {en},
	urldate = {2021-02-06},
	booktitle = {Proceedings of the {Eighth} {International} {Conference} on {Probabilistic} {Safety} {Assessment} \& {Management} ({PSAM})},
	publisher = {ASME Press},
	editor = {Stamatelatos, Michael G. and Blackman, Harold S.},
	year = {2006},
	doi = {10.1115/1.802442.paper218},
	pages = {1759--1764},
}

@article{kashparov_forest_2000,
	title = {Forest fires in the territory contaminated as a result of the {Chernobyl} accident: radioactive aerosol resuspension and exposure of fire-fighters},
	abstract = {Studies were carried out to investigate the processes of resuspension and redistribution of radionuclides by "re in the territories contaminated as a result of the Chernobyl accident. In this set of experiments, the dispersed radioactive aerosol composition, the values of airborne radioactive aerosol concentrations, the resuspension factor, the resuspension rate, the deposition \#ux and the deposition velocity have been obtained for the di!erent phases of a "re and at various distances from the "re. In the active phase of a "re, the airborne concentrations of radionuclides increase by several orders of magnitude relative to the background value. The resuspension factor for the active phase of a "re was assessed as 10{\textbackslash} \vphantom{\{}\}10{\textbackslash}  m{\textbackslash} , while the value of the resuspension rate had a 10{\textbackslash}   s{\textbackslash}  order of magnitude at a deposition velocity of 1\vphantom{\{}\}2 cm s{\textbackslash} . The additional terrestrial contamination due to a forest "re can be estimated as a value in the range 10{\textbackslash} \vphantom{\{}\}10{\textbackslash}  of its background value. As recommended by ICRP, the human respiratory tract model was applied for calculation of the E!ective Equivalent Dose (EED) to "remen. The dose coe\$cient for radioactive aerosol inhalation was estimated at 1.5;10{\textbackslash}  Sv (Bq m{\textbackslash}  h){\textbackslash} . 2000 Elsevier Science Ltd. All rights reserved.},
	language = {en},
	author = {Kashparov, V A and Lundin, S M and Kadygrib, A M and Protsak, V P and Levtchuk, S E and Yoschenko, V I and Kashpur, V A and Talerko, N M},
	year = {2000},
	pages = {18},
}

@misc{noauthor_modified-wildfires-research_nodate,
	title = {Modified-wildfires-research paper draft},
	url = {https://docs.google.com/document/d/16QhUwRPnea-pMmxR55Oc46H9EmgffiLF0VIpYMxSzYs/edit?usp=drive_web&ouid=109069197482038217465&usp=embed_facebook},
	abstract = {On the Modeling of Wildfires-Induced Release and Atmospheric Dispersion in Radioactively Contaminated Regions  Damla Polat *, Mihai A. Diaconeasa †  *NC State University, Department of Nuclear Engineering, Raleigh, NC 27695, dpolat2@ncsu.edu †NC State University, Department of Nuclear Engineering...},
	language = {en},
	urldate = {2021-02-05},
	journal = {Google Docs},
}

@article{ahn_establishment_2008,
	title = {Establishment of risk-based accident scenarios using the master logic diagram related to {LILW} management in the temporary storage facility},
	volume = {35},
	doi = {10.1016/j.anucene.2008.08.003},
	abstract = {The initiating event, which is the first step in the establishment of risk-based accident scenarios, was derived by master logic diagram (MLD) method based on the fault tree analysis (FTA), and then the risk-based accident scenarios were developed by the event tree analysis (ETA) through the derived initiating events. The main initiating events led to the arbitrary operational accident: the dropping of a drum and fire were derived from the MLD method. Consequently, based on two main initiating events, four heading events were derived, and then the 12 risk-based accident scenarios concerning the LILW management in the temporary storage facility were finally established by the ETA method.},
	journal = {Annals of Nuclear Energy - ANN NUCL ENERG},
	author = {Ahn, Min and Lee, Kun and Choi, Kyung},
	month = dec,
	year = {2008},
	pages = {2420--2425},
}

@article{papazoglou_master_2003,
	title = {Master {Logic} {Diagram}: {Method} for hazard and initiating event identification in process plants},
	volume = {97},
	shorttitle = {Master {Logic} {Diagram}},
	doi = {10.1016/S0304-3894(02)00244-3},
	abstract = {Master Logic Diagram (MLD), a method for identifying events initiating accidents in chemical installations, is presented. MLD is a logic diagram that resembles a fault tree but without the formal mathematical properties of the latter. MLD starts with a Top Event "Loss of Containment" and decomposes it into simpler contributing events. A generic MLD has been developed which may be applied to all chemical installations storing toxic and/or flammable substances. The method is exemplified through its application to an ammonia storage facility.},
	journal = {Journal of hazardous materials},
	author = {Papazoglou, I.A. and Aneziris, Oiga},
	month = mar,
	year = {2003},
	pages = {11--30},
}

@article{purba_master_2018,
	title = {Master {Logic} {Diagram}: {An} {Approach} to {Identify} {Initiating} {Events} of {HTGRs}},
	volume = {962},
	shorttitle = {Master {Logic} {Diagram}},
	doi = {10.1088/1742-6596/962/1/012036},
	abstract = {Initiating events of a nuclear power plant being evaluated need to be firstly identified prior to applying probabilistic safety assessment on that plant. Various types of master logic diagrams (MLDs) have been proposedforsearching initiating events of the next generation of nuclear power plants, which have limited data and operating experiences. Those MLDs are different in the number of steps or levels and different in the basis for developing them. This study proposed another type of MLD approach to find high temperature gas cooled reactor (HTGR) initiating events. It consists of five functional steps starting from the top event representing the final objective of the safety functions to the basic event representing the goal of the MLD development, which is an initiating event. The application of the proposed approach to search for two HTGR initiating events, i.e. power turbine generator trip and loss of offsite power, is provided. The results confirmed that the proposed MLD is feasiblefor finding HTGR initiating events.},
	journal = {Journal of Physics: Conference Series},
	author = {Purba, Julwan},
	month = feb,
	year = {2018},
	pages = {012036},
}

@article{verfondern_methods_1993,
	title = {Methods and data for {HTGR} fuel performance and radionuclide release modeling during normal operation and accidents for safety analysis},
	url = {https://www.osti.gov/etdeweb/biblio/10135256},
	abstract = {The previous status report released in 1987 on reference data and calculation models for fission product transport in High-Temperature, Gas-Cooled Reactor (HTGR) safety analyses has been updated to reflect the current state of knowledge in the German HTGR program. The content of the status report has been expanded to include information from other national programs in HTGRs to provide comparative information on methods of analysis and the underlying database for fuel performance and fission product transport. The release and transport of fission products during normal operating conditions and during the accident scenarios of core heatup, water and air ingress, and depressurization are discussed. (orig.) [Deutsch] Der im Jahre 1987 erschienene Statusbericht mit der Beschreibung einer Referenz-Datenbasis und Rechenmodellen ist auf den neuesten Stand gebracht worden und beschreibt den gegenwaertigen state-of-the-art im deutschen HTR-Programm. Der Inhalt des Statusberichts ist erweitert worden um Informationen aus den HTR-Programmen anderer Nationen, um einen Vergleich der Analysemethoden sowie der zugrunde liegenden Datenbasis zur Beschreibung des Brennstoffverhaltens und des Spaltprodukttransports zu ermoeglichen. Der Bericht umfasst die Bereiche Freisetzung und Transport von Spaltprodukten waehrend des Normalbetriebs sowie im Verlaufe von Unfallszenarien von Kernaufheizung, Wasser- und Lufteinbruch und Druckentlastung. (orig.)},
	language = {English},
	urldate = {2021-02-03},
	author = {Verfondern, K. and Martin, R. C. and Moormann, R.},
	month = jan,
	year = {1993},
}

@misc{noauthor_inis_nodate,
	title = {{INIS} {Repository} {Search} - {Single} {Result}},
	url = {https://inis.iaea.org/search/searchsinglerecord.aspx?recordsFor=SingleRecord&RN=11500274},
	urldate = {2021-02-03},
}

@article{li_safety_2011,
	title = {Safety analysis for hot gas duct vessel in {HTR}-{PM}},
	volume = {174},
	doi = {10.13182/NT11-A11677},
	abstract = {The hot gas duct vessel (HGDV) is an important part of the high-temperature reactor-pebble-bed module (HTR-PM) primary loop pressure boundary system. It connects the reactor pressure vessel (RPV) and steam generator pressure vessel. Because the dimensions of the HGDV are smaller than those of the other two vessels, it is often considered the weakest of the three vessels. Therefore, the safety of the HGDV has become one of the most important issues in the design of the HTRPM. In the present paper, a comprehensive safety analysis of the HGDV in the HTR-PM was performed with an emphasis on the structural features. The designs of the HGDV and the support system of the primary loop pressure boundary are first described. A preliminary safety analysis of the HGDV, including the stress calculations and leak-before-break (LBB) analysis, is then presented. The results show that the stress levels of the HGDV under various accidents have a safety margin of at least 55.3\% compared with the stress limits specified in American Society of Mechanical Engineers code, and the stress intensity factor at the postulated flaw is less than the critical stress intensity factor. The LBB analysis indicated that the leak detection system is capable of detecting leaks caused by a postulated throughthickness crack in the HGDV before it reaches the critical size. Although the preliminary analysis has proved the safety of the HGDV, the consequences of a hypothetical HGDV double-ended break accident were also studied to further investigate the safety features of the HTR-PM. Several mitigation measures were employed based on the original design. The structural integrity of the support system, the reactor internals, and the containment under double-ended break accident were evaluated. The results show that these main structures could maintain integrity under the HGDV double-ended break accident.},
	journal = {Nuclear Technology},
	author = {Li, Xiaotian and Li, Xiaowei and Shi, Li and Zhang, Zhengming and He, Shuyan},
	month = apr,
	year = {2011},
	pages = {29--40},
}

@article{oconnor_inlext-_nodate,
	title = {{INL}/{EXT}- 11-22708, "{ModularHTGR} {Safety} {Basis} {andApproach}."},
	language = {en},
	author = {O'Connor, T J and Sink, C J and Zamore, J},
	pages = {45},
}

@techreport{martin_compilation_1993,
	title = {Compilation of {Fuel} {Performance} and {Fission} {Product} {Transport} {Models} and {Database} for {MHTGR} {Design}},
	url = {https://www.osti.gov/biblio/10199713-compilation-fuel-performance-fission-product-transport-models-database-mhtgr-design},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {ORNL/NPR-91/6},
	urldate = {2021-02-02},
	institution = {Oak Ridge National Lab., TN (United States)},
	author = {Martin, R. C.},
	month = oct,
	year = {1993},
	doi = {https://doi.org/10.2172/10199713},
	doi = {https://doi.org/10.2172/10199713},
}

@article{gottaut_results_1990,
	title = {Results of experiments at the {AVR} reactor},
	volume = {121},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/002954939090099J},
	doi = {10.1016/0029-5493(90)90099-J},
	abstract = {The most important experiments at the AVR reactor and their results will be discussed. This choice illustrates the significance of the “AVR experiment” for high-temperature reactor development in Germany and for the construction and operation of future HTR projects.},
	language = {en},
	number = {2},
	urldate = {2021-02-02},
	journal = {Nuclear Engineering and Design},
	author = {Gottaut, H. and Krüger, K.},
	month = jul,
	year = {1990},
	pages = {143--153},
}

@article{reutler_advantages_1984,
	title = {Advantages of going modular in {HTRs}},
	volume = {78},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/002954938490298X},
	doi = {10.1016/0029-5493(84)90298-X},
	abstract = {A multitude of problems that are encountered in large HTR power plans, constructively as well as concerning plant safety, can be related to the mere physical size of a large reactor core. In limiting the thermal power of an HTR-module to approximately 200 MW an inherent limitation of the fuel element temperature below critical values can be guaranteed for all possible core heat up accidents. Consequently, a significant failure rate of coated particles can be excluded and, hence, out of physical reasons, no intolerable fission product release from the core will ever have to be considered. The HTR-module is so qualified and very well suited for all possible plant sides which have to be taken into consideration for medium sized plants for the production of process steam and electricity. The cost investigations show considerable cost advantages for modular HTRs. For German conditions it was found that even a four-modular plant (800 MW/thermal) is competitive with a fossile-fueled plant of the same size, the specific plant costs were evaluated to be DM 4700/kW (electric). Moreover the investigations show that the increase of the power of the modular unit yields only small cost advantages, therefore in a modularized power plant it even would be possible to reduce the power of a modular unit below 200 MW without having to cope with severe economic penalties, if the distance from technological or safety limits is felt to be too small.},
	language = {en},
	number = {2},
	urldate = {2021-02-02},
	journal = {Nuclear Engineering and Design},
	author = {Reutler, H. and Lohnert, G. H.},
	month = apr,
	year = {1984},
	pages = {129--136},
}

@article{baumer_construction_1990,
	title = {Construction and operating experience with the 300-{MW} {THTR} nuclear power plant},
	volume = {121},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/002954939090100C},
	doi = {10.1016/0029-5493(90)90100-C},
	abstract = {After a long construction period which was mainly induced by changing safety and licence requirements, the THTR 300 nuclear power plant was successfully commissioned after starting electricity generation in November 1985. Evalution of the operating experience reveals absolutely positive results: the principal design data have been achieved; the principal design of the large pebble bed reactor was confirmed. Shut down of the plant after the generation of 2.9 million MWh and 423 full power days is due to financial risk of the prototype plant.},
	language = {en},
	number = {2},
	urldate = {2021-02-02},
	journal = {Nuclear Engineering and Design},
	author = {Bäumer, R. and Kalinowski, I. and Röhler, E. and Schöning, J. and Wachholz, W.},
	month = jul,
	year = {1990},
	pages = {155--166},
}

@article{zhang_current_2009,
	title = {Current status and technical description of {Chinese} 2×{250MWth} {HTR}-{PM} demonstration plant},
	volume = {239},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/S0029549309001332},
	doi = {10.1016/j.nucengdes.2009.02.023},
	abstract = {After the nuclear accidents of Three Mile Island and Chernobyl the world nuclear community made great efforts to increase research on nuclear reactors and to develop advanced nuclear power plants with much improved safety features. Following the successful construction and a most gratifying operation of the 10MWth high-temperature gas-cooled test reactor (HTR-10), the Institute of Nuclear and New Energy Technology (INET) of Tsinghua University has developed and designed an HTR demonstration plant, called the HTR-PM (high-temperature-reactor pebble-bed module). The design, having jointly been carried out with industry partners from China and in collaboration of experts worldwide, closely follows the design principles of the HTR-10. Due to intensive engineering and R\&D efforts since 2001, the basic design of the HTR-PM has been finished while all main technical features have been fixed. A Preliminary Safety Analysis Report (PSAR) has been compiled. The HTR-PM plant will consist of two nuclear steam supply system (NSSS), so called modules, each one comprising of a single zone 250MWth pebble-bed modular reactor and a steam generator. The two NSSS modules feed one steam turbine and generate an electric power of 210MW. A pilot fuel production line will be built to fabricate 300,000 pebble fuel elements per year. This line is closely based on the technology of the HTR-10 fuel production line. The main goals of the project are two-fold. Firstly, the economic competitiveness of commercial HTR-PM plants shall be demonstrated. Secondly, it shall be shown that HTR-PM plants do not need accident management procedures and will not require any need for offsite emergency measures. According to the current schedule of the project the completion date of the demonstration plant will be around 2013. The reactor site has been evaluated and approved; the procurement of long-lead components has already been started. After the successful operation of the demonstration plant, commercial HTR-PM plants are expected to be built at the same site. These plants will comprise many NSSS modules and, correspondingly, a larger turbine.},
	language = {en},
	number = {7},
	urldate = {2021-02-02},
	journal = {Nuclear Engineering and Design},
	author = {Zhang, Zuoyi and Wu, Zongxin and Wang, Dazhong and Xu, Yuanhui and Sun, Yuliang and Li, Fu and Dong, Yujie},
	month = jul,
	year = {2009},
	pages = {1212--1219},
}

@article{baumer_thtr_1991,
	series = {High-temperature {Helium} {Gas}-cooled {Nuclear} reactors: {Past} {Experience} {Current} {Status} and {Future} {Prospects}},
	title = {{THTR} commissioning and operating experience},
	volume = {16},
	issn = {0360-5442},
	url = {http://www.sciencedirect.com/science/article/pii/0360544291900873},
	doi = {10.1016/0360-5442(91)90087-3},
	abstract = {This account of the commissioning and performance of the THTR includes descriptions of the design data and power operation, core dynamics, control behavior, power and temperature distribution in the core, refueling and damage of the spherical fuel elements, coolant gas activity and impurity content in the primary circuit and thermodynamic parameters of the primary system. The problems of the risk participation contacts and the covering of financial risks are discussed.},
	language = {en},
	number = {1},
	urldate = {2021-02-02},
	journal = {Energy},
	author = {Baumer, R. and Kalinowski, I.},
	month = jan,
	year = {1991},
	pages = {59--70},
}

@article{jones_criteria_nodate,
	title = {Criteria for {Development} of {Evacuation} {Time} {Estimate} {Studies}},
	language = {en},
	author = {Jones, J and Walton, F and Wolshon, B},
	pages = {70},
}

@article{noauthor_nuregkm-0010_nodate,
	title = {{NUREG}/{KM}-0010, "{WASH}-1400 - {The} {Reactor} {Safety} {Study} - {The} {Introduction} of {Risk} {Assessment} to the {Regulation} of {Nuclear} {Reactors}."},
	language = {en},
	pages = {60},
}

@article{theofanous_proper_1996,
	title = {On the proper formulation of safety goals and assessment of safety margins for rare and high-consequence hazards},
	volume = {54},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832096000798},
	doi = {10.1016/S0951-8320(96)00079-8},
	language = {en},
	number = {2-3},
	urldate = {2021-01-26},
	journal = {Reliability Engineering \& System Safety},
	author = {Theofanous, T.G.},
	month = nov,
	year = {1996},
	pages = {243--257},
}

@book{ahn_resilience_2017,
	address = {Cham},
	title = {Resilience: {A} {New} {Paradigm} of {Nuclear} {Safety}},
	isbn = {978-3-319-58767-7 978-3-319-58768-4},
	shorttitle = {Resilience},
	url = {http://link.springer.com/10.1007/978-3-319-58768-4},
	language = {en},
	urldate = {2021-01-26},
	publisher = {Springer International Publishing},
	editor = {Ahn, Joonhong and Guarnieri, Franck and Furuta, Kazuo},
	year = {2017},
	doi = {10.1007/978-3-319-58768-4},
}

@article{starr_ultimate_2000,
	title = {The {Ultimate} {Uncertainty} - {Intergenerational} {Planning}},
	volume = {20},
	issn = {0272-4332, 1539-6924},
	url = {http://doi.wiley.com/10.1111/0272-4332.206073},
	doi = {10.1111/0272-4332.206073},
	language = {en},
	number = {6},
	urldate = {2021-01-19},
	journal = {Risk Analysis},
	author = {Starr, Chauncey},
	month = dec,
	year = {2000},
	pages = {793--800},
}

@article{starr_separation_1979,
	title = {The separation of nuclear power from nuclear proliferation},
	volume = {51},
	issn = {00295493},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0029549379900827},
	doi = {10.1016/0029-5493(79)90082-7},
	language = {en},
	number = {2},
	urldate = {2021-01-20},
	journal = {Nuclear Engineering and Design},
	author = {Starr, Chauncey},
	month = jan,
	year = {1979},
	pages = {105--111},
}

@article{starr_precautionary_2003,
	title = {The {Precautionary} {Principle} {Versus} {Risk} {Analysis}},
	volume = {23},
	issn = {0272-4332, 1539-6924},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1539-6924.00285},
	doi = {10.1111/1539-6924.00285},
	language = {en},
	number = {1},
	urldate = {2021-01-19},
	journal = {Risk Analysis},
	author = {Starr, Chauncey},
	month = feb,
	year = {2003},
	pages = {1--3},
}

@article{starr_social_1969,
	title = {Social {Benefit} versus {Technological} {Risk}},
	volume = {165},
	url = {http://www.jstor.org/stable/1727970},
	language = {en},
	number = {3899},
	journal = {Science, New Series},
	author = {Starr, Chauncey},
	year = {1969},
	pages = {1232--1238},
}

@book{lee_risk_2012,
	title = {Risk and {Safety} {Analysis} of {Nuclear} {Systems}},
	isbn = {978-1-118-04345-5},
	abstract = {The book has been developed in conjunction with NERS 462, a course offered every year to seniors and graduate students in the University of Michigan NERS program. The first half of the book covers the principles of risk analysis, the techniques used to develop and update a reliability data base, the reliability of multi-component systems, Markov methods used to analyze the unavailability of systems with repairs, fault trees and event trees used in probabilistic risk assessments (PRAs), and failure modes of systems. All of this material is general enough that it could be used in non-nuclear applications, although there is an emphasis placed on the analysis of nuclear systems. The second half of the book covers the safety analysis of nuclear energy systems, an analysis of major accidents and incidents that occurred in commercial nuclear plants, applications of PRA techniques to the safety analysis of nuclear power plants (focusing on a major PRA study for five nuclear power plants), practical PRA examples, and emerging techniques in the structure of dynamic event trees and fault trees that can provide a more realistic representation of complex sequences of events. The book concludes with a discussion on passive safety features of advanced nuclear energy systems under development and approaches taken for risk-informed regulations for nuclear plants.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Lee, John C. and McCormick, Norman J.},
	month = jan,
	year = {2012},
	note = {Google-Books-ID: mB5rLNJH534C},
	keywords = {Arjun's Library - Physical Copy, Science / Chemistry / General, Technology \& Engineering / Chemical \& Biochemical},
}

@book{smith_probabilistic_2012,
	title = {Probabilistic {Risk} {Assessment} {Procedures} {Guide} for {NASA} {Managers} and {Practitioners}: {NASA}/{SP}-2011-3421 {Probabilistic} {Risk} {Assessment} {Procedures} {Guide} for {NASA} {Managers} and {Practitioners}},
	isbn = {978-1-4700-8054-9},
	shorttitle = {Probabilistic {Risk} {Assessment} {Procedures} {Guide} for {NASA} {Managers} and {Practitioners}},
	url = {https://ntrs.nasa.gov/api/citations/20120001369/downloads/20120001369.pdf},
	abstract = {During the past several decades, much has been written on PRA methods and applications. Several university and practitioner textbooks and sourcebooks currently exist, but they focus on applications of PRA to industries other than aerospace. Although some of the techniques used in PRA originated in work for aerospace and military applications, no comprehensive reference currently exists for PRA applications to aerospace systems. This PRA Procedures Guide, in the present second edition, is neither a textbook nor an exhaustive sourcebook of PRA methods and techniques. It provides a set of recommended procedures, based on the experience of the authors, that are applicable to different levels and types of PRA that are performed for aerospace applications. It therefore serves two purposes, to: 1. Complement the training material taught in the NASA PRA course for practitioners, and together with the Fault Tree Handbook, the Risk-Informed Decision Making Handbook, the Bayesian Inference handbook, the Risk Management Handbook, and the System Safety Handbook to provide quantitative risk methodology documentation, and to 2. Provide aerospace PRA practitioners in selecting an analysis approach that is best suited for their applications.},
	language = {English},
	publisher = {CreateSpace Independent Publishing Platform},
	author = {Smith, Curtis Lee},
	month = feb,
	year = {2012},
	keywords = {Arjun's Library - Physical Copy},
}

@book{warren_jacob_luzadder_basic_1962,
	edition = {5th},
	title = {Basic {Graphics} for {Engineers} and {Technical} {Students}},
	shorttitle = {Basic {Graphics}},
	url = {https://books.google.com/books/about/Basic_Graphics_for_Engineers_and_Technic.html?id=kjZNAAAAYAAJ},
	language = {English},
	publisher = {Prentice-Hall},
	author = {{Warren Jacob Luzadder}},
	year = {1962},
	keywords = {Arjun's Library - Physical Copy},
}

@book{g_david_shilling_process_1963,
	title = {Process dynamics and control},
	volume = {9},
	url = {http://doi.wiley.com/10.1002/aic.690090602},
	language = {en},
	urldate = {2021-01-22},
	author = {{G. David Shilling}},
	month = nov,
	year = {1963},
	keywords = {Arjun's Library - Physical Copy},
}

@book{zill_first_2005,
	address = {Belmont, CA},
	edition = {8th ed},
	title = {First course in differential equations with modeling applications},
	isbn = {978-0-534-41878-6 978-0-534-42038-3 978-0-534-49489-6 978-0-534-41894-6},
	publisher = {Brooks/Cole},
	author = {Zill, Dennis G.},
	year = {2005},
	keywords = {Arjun's Library - Physical Copy, Differential equations, Textbooks},
}

@book{joseph_h_yuen_deep_2014,
	series = {Applications of {Communications} {Theory}},
	title = {Deep {Space} {Telecommunications} {Systems} {Engineering}},
	isbn = {978-1-4952-5076-7},
	url = {https://www.amazon.com/Deep-Space-Telecommunications-Systems-Engineering/dp/1495250768},
	abstract = {A vital, often predominant function in every space mission is that of communications. From the moment of launch, the only connection between spacecraft and earth is the communications system. This system is responsible for sending scientific data back to earth in the specified quality and quantity together with engineering data reporting the condition of the spacecraft. The communications system also provides the capability of tracking the spacecraft and commanding it to take certain actions. Without an effective communications system a successful mission would not be possible. To appreciate the challenge that one faces in designing such systems for planetary exploration, one must consider the enormous distances that are involved. Voyager spacecraft, for example, are now more than one billion miles from earth, tens of thousands of times farther than the most distant communications satellite, and continue to transmit data and respond to commands. The necessity of minimizing spacecraft weight presents a major problem to communications systems designers. The far-reaching implications of spacecraft weight become apparent as the designer considers the problems of providing power supply, antennas, and other necessary devices and supporting elements. Another important challenge is the extreme reliability required of the communications system on the spacecraft. Once the spacecraft is launched, on-board failures can no longer be repaired except by use of redundant systems. System degradation due to aging, imperfect antenna pointing, or imperfect trajectories can be expected; and the designer must know how much degradation to expect from each case and must design the equipment, the operations, and the procedures of data analysis accordingly. The telecommunications engineer works with the most precise and advanced techniques of the engineering world. Since the launch in 1958 of Explorer I, the first free-world satellite, there has been substantial progress in improving communications capability. Even though substantial progress has been made in the last 25 years, space exploration is still in its infancy. There has been no exploration beyond the solar system. There are numerous galaxies and billions of stars to investigate. Bigger and tougher challenges are still ahead; more exciting times are yet to come. These challenges will undoubtedly call for more advanced telecommunications systems to transmit information to and from deep space. Telecommunications technology is still in its infancy. Through the years, a number of telecommunications design techniques, procedures, and analyses contributing to the success of deep space exploration missions have been developed and applied. The purpose of this book is to provide descriptive and analytical information useful for the optimum design, specification, and performance evaluation of deep space telecommunications systems. The book emphasizes system performance information. Long, tedious derivations are not included. The book should serve to acquaint new telecommunications engineers with the techniques available to them and should summarize for the experienced engineers the analyses and information necessary for their work. It also provides a background for understanding the interface between the Deep Space Network and the spacecraft and is intended to facilitate the conceptual designs and analyses for the enhancement of telecommunications performance and assurance of compatibility between spacecraft and ground system capabilities.},
	language = {English},
	publisher = {NASA},
	author = {{Joseph H. Yuen}},
	month = jan,
	year = {2014},
	keywords = {Arjun's Library - Physical Copy},
}

@book{babcock__wilcox_steam_2007,
	address = {New York, N.Y},
	edition = {38},
	title = {Steam its generation and use},
	language = {English},
	publisher = {Babcock \& Wilcox Company},
	author = {{Babcock \& Wilcox}},
	year = {2007},
	note = {OCLC: 1113000228},
	keywords = {Arjun's Library - Physical Copy},
}

@book{sagan_pale_2011,
	address = {Place of publication not identified},
	title = {Pale {Blue} {Dot}},
	language = {English},
	publisher = {Ballantine Books : Sold by Random House Digital},
	author = {Sagan, Carl and Druyan, Ann},
	year = {2011},
	note = {OCLC: 754644052},
	keywords = {Arjun's Library - Physical Copy},
}

@book{cacuci_theory_2003,
	address = {Boca Raton, Fla.},
	series = {Sensitivity and uncertainty analysis},
	title = {Theory},
	isbn = {978-1-58488-115-5},
	language = {eng},
	number = {Dan G. Cacuci ; Vol. 1},
	publisher = {Chapman \& Hall/CRC},
	author = {Cacuci, Dan G. and Cacuci, Dan G.},
	year = {2003},
	note = {OCLC: 249673410},
	keywords = {Arjun's Library - Physical Copy},
}

@book{rogawski_singlevariable_2012,
	address = {New York},
	title = {Singlevariable {Calculus}},
	isbn = {978-1-4292-3190-9 978-1-4292-3189-3 978-1-4292-3182-4},
	language = {English},
	publisher = {W.H. Freeman},
	author = {Rogawski, Jon},
	year = {2012},
	note = {OCLC: 760294078},
	keywords = {Arjun's Library - Physical Copy},
}

@book{sanborn_yosemite_1989,
	address = {Yosemite National Park, Calif.},
	title = {Yosemite: its discovery, its wonders and its people},
	shorttitle = {Yosemite},
	url = {https://archive.org/details/yosemiteitsdisco0000sanb},
	language = {English},
	urldate = {2021-01-22},
	publisher = {Yosemite Association},
	author = {Sanborn, Margaret},
	year = {1989},
	note = {OCLC: 1195476394},
	keywords = {Arjun's Library - Physical Copy},
}

@book{streetman_solid_2015,
	title = {Solid state electronic devices},
	isbn = {978-81-203-5000-7},
	language = {English},
	author = {Streetman, Ben G and Banerjee, Sanjay K},
	year = {2015},
	note = {OCLC: 1120432877},
	keywords = {Arjun's Library - Physical Copy},
}

@book{munshi_premchand_premchand_nodate,
	title = {Premchand {Ki} {Amar} {Kahaniyan}},
	volume = {1},
	isbn = {1-5233-4281-1 978-1-5233-4281-5},
	url = {https://www.abebooks.com/9781523342815/Premchand-Amar-Kahaniyan-Hindi-Edition-1523342811/plp},
	abstract = {Early 20th century famous Indian Hindi novel writer Munshi Premchand was born in the year 1880 at 31st of July in the Lamhi village district of Varanasi. The birth name of him is Dhanpat Rai. Finally his name becomes changed to the Munshi Premchand. His first name Munshi is an honorary given by his wishers in the society because of his quality and effective writings. As a Hindi writer he wrote approximately dozens...},
	language = {Hindi},
	author = {{Munshi Premchand}},
	keywords = {Arjun's Library - Physical Copy},
}

@book{cacuci_applications_2005,
	address = {Boca Raton, Fla.},
	series = {Sensitivity and uncertainty analysis},
	title = {Applications to large-scale systems},
	isbn = {978-1-58488-116-2},
	language = {eng},
	number = {Dan G. Cacuci ; Vol. 2},
	publisher = {Chapman \& Hall/CRC},
	author = {Cacuci, Dan G. and Ionescu-Bujor, Mihaela and Navon, Ionel Michael and Cacuci, Dan G.},
	year = {2005},
	note = {OCLC: 254649890},
	keywords = {Arjun's Library - Physical Copy},
}

@book{krane_introductory_1987,
	address = {New York},
	title = {Introductory nuclear physics},
	isbn = {978-0-471-80553-3},
	publisher = {Wiley},
	author = {Krane, Kenneth S. and Halliday, David},
	year = {1987},
	keywords = {Arjun's Library - Physical Copy, Nuclear physics},
}

@book{modi_parallel_1990,
	address = {Oxford},
	edition = {Reprinted},
	series = {Oxford applied mathematics and computing science series},
	title = {Parallel algorithms and matrix computation},
	isbn = {978-0-19-859670-7 978-0-19-859655-4},
	publisher = {Clarendon Pr},
	author = {Modi, Jagdish J.},
	year = {1990},
	note = {OCLC: 246843041},
	keywords = {Arjun's Library - Physical Copy},
}

@book{rodrigue_parallel_1989,
	address = {Philadelphia, Pa},
	title = {Parallel processing for scientific computing: proceedings of the {Third} {SIAM} {Conference} on {Parallel} {Processing} for {Scientific} {Computing}, {Los} {Angeles}, {California}, {December} 1 - 4, 1987},
	isbn = {978-0-89871-228-5},
	shorttitle = {Parallel processing for scientific computing},
	language = {eng},
	publisher = {SIAM},
	editor = {Rodrigue, Garry and Conference on Parallel Processing for Scientific Computing},
	year = {1989},
	note = {Meeting Name: SIAM Conference on Parallel Processing for Scientific Computing
OCLC: 258418402},
	keywords = {Arjun's Library - Physical Copy},
}

@book{hord_parallel_1990,
	address = {Boca Raton, Fla.},
	title = {Parallel supercomputing in {SIMD} architectures},
	isbn = {978-0-8493-4271-4},
	language = {eng},
	publisher = {CRC Press},
	author = {Hord, R. Michael},
	year = {1990},
	note = {OCLC: 20827205},
	keywords = {Arjun's Library - Physical Copy},
}

@book{pausch_last_2008,
	address = {London},
	title = {The last lecture},
	isbn = {978-0-340-97773-6},
	language = {eng},
	publisher = {Hodder \& Stoughton},
	author = {Pausch, Randy and Zaslow, Jeffrey},
	year = {2008},
	note = {OCLC: 611048249},
	keywords = {Arjun's Library - Physical Copy},
}

@book{e_principles_2011,
	address = {Cambridge},
	title = {Principles of multiscale modeling},
	isbn = {978-1-107-09654-7},
	language = {eng},
	publisher = {Cambridge Univ. Press},
	author = {E, Weinan},
	year = {2011},
	note = {OCLC: 755057227},
	keywords = {Arjun's Library - Physical Copy},
}

@book{tong_principles_1988,
	address = {New York u.a},
	title = {Principles of design improvement for light water reactors},
	isbn = {978-0-89116-416-6 978-3-540-18881-0},
	language = {eng},
	publisher = {Hemisphere Publ. Corp},
	author = {Tong, Long-Sun},
	year = {1988},
	note = {OCLC: 16833730},
	keywords = {Arjun's Library - Physical Copy},
}

@book{dongarra_proceedings_1990,
	address = {Philadelphia},
	series = {{SIAM} {Proceedings} {Series}},
	title = {Proceedings of the 4th {SIAM} {Conference} on {Parallel} {Processing} for {Scientific} {Computing}},
	isbn = {978-0-89871-262-9},
	publisher = {SIAM},
	author = {Dongarra, Jack and Messina, Paul and Sorensen, Danny C.},
	year = {1990},
	note = {Meeting Name: held at the SIAM Conference, Chicago, 1989
OCLC: 833631124},
	keywords = {Arjun's Library - Physical Copy},
}

@book{fleming_future_1989,
	address = {Philadelphia, Pa},
	series = {{SIAM} reports on issues in the mathematical sciences},
	title = {Future directions in control theory: a mathematical perspective ; report of the {Panel} on {Future} {Directions} in {Control} {Theory}},
	isbn = {978-0-89871-234-6},
	shorttitle = {Future directions in control theory},
	language = {eng},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Fleming, Wendell H. and National Science Foundation and Society for Industrial {and} Applied Mathematics},
	year = {1989},
	note = {OCLC: 257337209},
	keywords = {Arjun's Library - Physical Copy},
}

@book{liu_principles_2016,
	address = {New York, NY},
	title = {Principles of photonics},
	isbn = {978-1-107-16428-4},
	language = {eng},
	publisher = {Cambridge University Press},
	author = {Liu, Jia-Ming},
	year = {2016},
	keywords = {Arjun's Library - Physical Copy},
}

@book{oecd_nuclear_energy_agency_-core_1992,
	address = {Paris : [Washington, D.C},
	title = {In-core instrumentation and reactor core assessment: proceedings of a specialists' meeting, {Pittsburg}[h], {USA}, 1-4 {October} 1991 = {Instrumentation} et évaluation de l'état du coeur des réacteurs: compte rendu d'une réunion de spécialistes, {Pittsburg}[h], États-{Unis}, 1-4 {Octobre} 1991},
	isbn = {978-92-64-03682-6},
	shorttitle = {In-core instrumentation and reactor core assessment},
	publisher = {Nuclear Energy Agency, Organisation for Economic Co-operation and Development ; OECD Publications and Information Centre, distributor]},
	editor = {OECD Nuclear Energy Agency},
	year = {1992},
	keywords = {Arjun's Library - Physical Copy, Instruments Congresses, Measurement Congresses, Nuclear power plants, Nuclear reactors},
}

@book{christensen_optimal_1990,
	address = {New York},
	series = {Mathematical concepts and methods in science and engineering},
	title = {Optimal control of distributed nuclear reactors},
	isbn = {978-0-306-43305-4},
	number = {41},
	publisher = {Plenum Pr},
	author = {Christensen, Gustav S. and Soliman, S. A. and Nieva, R.},
	year = {1990},
	note = {OCLC: 246836036},
	keywords = {Arjun's Library - Physical Copy},
}

@book{van_valkenburg_network_1974,
	address = {Englewood Cliffs/N.J},
	edition = {3. ed},
	title = {Network analysis},
	isbn = {978-0-13-611095-8},
	language = {eng},
	publisher = {Prentice-Hall},
	author = {Van Valkenburg, Mac E.},
	year = {1974},
	note = {OCLC: 693952},
	keywords = {Arjun's Library - Physical Copy},
}

@book{maccormick_multilevel_1989,
	address = {Philadelphia},
	series = {Frontiers in applied mathematics},
	title = {Multilevel adaptive methods for partial differential equations},
	isbn = {978-0-89871-247-6},
	number = {6},
	publisher = {Soc. for Industrial and Applied Mathematics},
	author = {MacCormick, Stephen F.},
	year = {1989},
	note = {OCLC: 231058163},
	keywords = {Arjun's Library - Physical Copy},
}

@book{clarke_optimization_1990,
	address = {Philadelphia},
	edition = {Unabridged, corr. republ},
	series = {Classics in applied mathematics},
	title = {Optimization and nonsmooth analysis},
	isbn = {978-0-89871-256-8},
	language = {eng},
	number = {5},
	publisher = {SIAM},
	author = {Clarke, Frank H.},
	year = {1990},
	note = {OCLC: 830697311},
	keywords = {Arjun's Library - Physical Copy},
}

@book{glasko_inverse_1988,
	address = {New York},
	title = {Inverse problems of mathematical physics},
	isbn = {978-0-88318-584-1},
	language = {English},
	publisher = {American Institute of physics},
	author = {Glasko, Vladlen Borisovič and Bincer, Adam},
	year = {1988},
	note = {OCLC: 468245846},
	keywords = {Arjun's Library - Physical Copy},
}

@book{peterson_operating_1986,
	address = {Reading, Mass.},
	edition = {2. ed., reprint. with corr},
	title = {Operating system concepts},
	isbn = {978-0-201-06198-7},
	language = {eng},
	publisher = {Addison-Wesley},
	author = {Peterson, James Lyle and Silberschatz, Abraham},
	year = {1986},
	note = {OCLC: 15212250},
	keywords = {Arjun's Library - Physical Copy},
}

@book{rogawski_multivariable_2011,
	address = {New York},
	title = {Multivariable calculus},
	isbn = {978-1-4292-3193-0},
	language = {English},
	publisher = {W.H. Freeman and Company},
	author = {Rogawski, Jon},
	year = {2011},
	note = {OCLC: 641501327},
	keywords = {Arjun's Library - Physical Copy},
}

@book{gallivan_parallel_1994,
	address = {Philadelphia, Pa},
	edition = {3. printing},
	title = {Parallel algorithms for matrix computations},
	isbn = {978-0-89871-260-5},
	language = {eng},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Gallivan, Kyle A.},
	year = {1994},
	note = {OCLC: 258114059},
	keywords = {Arjun's Library - Physical Copy},
}

@book{hsu_modern_1976,
	address = {New York},
	title = {Modern control principles and applications},
	isbn = {978-0-07-030635-6},
	language = {English},
	publisher = {McGraw-Hill},
	author = {Hsu, Jay C and Meyer, Andrew U},
	year = {1976},
	note = {OCLC: 634904297},
	keywords = {Arjun's Library - Physical Copy},
}

@book{lewins_research_1993,
	address = {Taunton, Somerset, England},
	series = {Research studies in nuclear technology},
	title = {Research and development in the nuclear industry: based on the proceedings of a conference held at the {University} of {Cambridge}, {England}, {April} 1992},
	isbn = {978-0-471-93594-0 978-0-86380-134-1},
	shorttitle = {Research and development in the nuclear industry},
	language = {eng},
	number = {5},
	publisher = {Research Studies Press [u.a.]},
	editor = {Lewins, Jeffery D. and Gittus, John H. and British Nuclear Forum and Institution of Nuclear Engineers},
	year = {1993},
	note = {Meeting Name: Conference
OCLC: 636629244},
	keywords = {Arjun's Library - Physical Copy},
}

@book{van_huffel_total_1991,
	address = {Philadelphia, Pa},
	series = {Frontiers in applied mathematics},
	title = {The total least squares problem: computational aspects and analysis},
	isbn = {978-0-89871-275-9},
	shorttitle = {The total least squares problem},
	language = {eng},
	number = {9},
	publisher = {Soc. for Industrial and Applied Mathematics},
	author = {Van Huffel, Sabine and Vandewalle, Joos},
	year = {1991},
	note = {OCLC: 231320119},
	keywords = {Arjun's Library - Physical Copy},
}

@book{diacu_introduction_2000,
	address = {New York},
	title = {An introduction to differential equations: order and chaos},
	isbn = {978-0-7167-3296-9},
	shorttitle = {An introduction to differential equations},
	publisher = {W.H. Freeman},
	author = {Diacu, Florin},
	year = {2000},
	keywords = {Arjun's Library - Physical Copy, Differential equations},
}

@book{elden_matrix_2007,
	address = {Philadelphia, PA},
	series = {Fundamentals of algorithms},
	title = {Matrix methods in data mining and pattern recognition},
	isbn = {978-0-89871-626-9},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Eldén, Lars},
	year = {2007},
	note = {OCLC: ocm77572489},
	keywords = {Algebras, Linear, Arjun's Library - Physical Copy, Data mining, Mathematical models, Pattern recognition systems},
}

@book{van_loan_introduction_1996,
	address = {Sudbury, Mass},
	series = {The {Jones} and {Bartlett} series in computational science and applied mathematics},
	title = {Introduction to computational science and mathematics},
	isbn = {978-0-86720-473-5},
	publisher = {Jones and Bartlett},
	author = {Van Loan, Charles F.},
	year = {1996},
	keywords = {Arjun's Library - Physical Copy, Computer programming, Computer science, Mathematics},
}

@book{bretscher_linear_2009,
	address = {Upper Saddle River, NJ},
	edition = {4th ed},
	title = {Linear algebra with applications},
	isbn = {978-0-13-600926-9},
	publisher = {Pearson Prentice Hall},
	author = {Bretscher, Otto},
	year = {2009},
	note = {OCLC: ocn232922076},
	keywords = {Algebras, Linear, Arjun's Library - Physical Copy, Textbooks},
}

@book{dongarra_solving_1993,
	address = {Philadelphia, Pa},
	edition = {2. printing},
	title = {Solving linear systems on vector and shared memory computers},
	isbn = {978-0-89871-270-4},
	language = {eng},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Dongarra, Jack},
	year = {1993},
	note = {OCLC: 258077808},
	keywords = {Arjun's Library - Physical Copy},
}

@book{geever_foundation_2012,
	address = {New York},
	title = {The {Foundation} {Center}'s guide to proposal writing},
	isbn = {978-1-59542-404-4},
	language = {English},
	publisher = {The Foundation Center},
	author = {Geever, Jane C and {Foundation Center}},
	year = {2012},
	note = {OCLC: 1089592722},
	keywords = {Arjun's Library - Physical Copy},
}

@book{myler_pocket_1993,
	address = {Englewood Cliffs, NJ},
	title = {The pocket handbook of image processing algorithms in {C}},
	isbn = {978-0-13-642240-2},
	language = {eng},
	publisher = {Prentice Hall PTR},
	author = {Myler, Harley R. and Weeks, Arthur R.},
	year = {1993},
	note = {OCLC: 636785230},
	keywords = {Arjun's Library - Physical Copy},
}

@book{clarke_methods_1989,
	address = {Philadelphia, Pa},
	series = {{CBMS}-{NSF} regional conference series in applied mathematics},
	title = {Methods of dynamic and nonsmooth optimization},
	isbn = {978-0-89871-241-4},
	language = {eng},
	number = {57},
	publisher = {Soc. for Industrial and Applied Mathematics},
	author = {Clarke, Frank H.},
	year = {1989},
	note = {OCLC: 20217161},
	keywords = {Arjun's Library - Physical Copy},
}

@book{churchland_neurocomputational_1993,
	address = {Cambridge, Mass.},
	edition = {3rd pr},
	series = {A {Bradford} book},
	title = {A neurocomputational perspective: the nature of mind and the structure of science},
	isbn = {978-0-262-53106-1 978-0-262-03151-6},
	shorttitle = {A neurocomputational perspective},
	language = {eng},
	publisher = {MIT Press},
	author = {Churchland, Paul M.},
	year = {1993},
	note = {OCLC: 258172282},
	keywords = {Arjun's Library - Physical Copy},
}

@book{cox_object-oriented_1987,
	address = {Reading, Mass.},
	edition = {Repr., with corr},
	title = {Object-oriented programming: an evolutionary approach},
	isbn = {978-0-201-10393-9},
	shorttitle = {Object-oriented programming},
	language = {eng},
	publisher = {Addison-Wesley},
	author = {Cox, Brad J.},
	year = {1987},
	note = {OCLC: 17246026},
	keywords = {Arjun's Library - Physical Copy},
}

@book{ortega_introduction_1988,
	address = {New York},
	series = {Frontiers of computer science},
	title = {Introduction to parallel and vector solution of linear systems},
	isbn = {978-0-306-42862-3},
	publisher = {Plenum Press},
	author = {Ortega, James M.},
	year = {1988},
	keywords = {Arjun's Library - Physical Copy, Equations, Numerical solutions Data processing, Parallel processing (Electronic computers), Supercomputers},
}

@book{friedhoff_visualization_1989,
	address = {New York},
	title = {Visualization: the second computer revolution},
	isbn = {978-0-8109-1709-5},
	shorttitle = {Visualization},
	language = {eng},
	publisher = {Abrams},
	author = {Friedhoff, Richard Mark and Benzon, William},
	year = {1989},
	note = {OCLC: 19395957},
	keywords = {Arjun's Library - Physical Copy},
}

@book{mann_methods_1974,
	address = {New York},
	series = {Wiley series in probability and mathematical statistics {Applied} probability and statistics},
	title = {Methods for statistical analysis of reliability and life data},
	isbn = {978-0-471-56737-0},
	language = {eng},
	publisher = {Wiley},
	author = {Mann, Nancy R. and Schafer, Ray E. and Singpurwalla, Nozer D.},
	year = {1974},
	note = {OCLC: 762637},
	keywords = {Arjun's Library - Physical Copy},
}

@book{ortega_numerical_1990,
	address = {Philadelphia},
	series = {Classics in applied mathematics},
	title = {Numerical analysis: a second course},
	isbn = {978-0-89871-250-6},
	shorttitle = {Numerical analysis},
	language = {eng},
	number = {3},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Ortega, James M.},
	year = {1990},
	note = {OCLC: 20723194},
	keywords = {Arjun's Library - Physical Copy},
}

@book{wouk_new_1986,
	address = {Philadelphia, Pa},
	title = {New computing environments: parallel, vector and systolic ; [proceedings of a workshop held at {Stanford} {University}, {Stanford}, {California}, {November} 7 - 9, 1984]},
	isbn = {978-0-89871-201-8},
	shorttitle = {New computing environments},
	language = {eng},
	publisher = {SIAM},
	editor = {Wouk, Arthur and USA},
	year = {1986},
	note = {Meeting Name: Research Workshop on New Computing Environments: Parallel, Vector and Systolic
OCLC: 14193142},
	keywords = {Arjun's Library - Physical Copy},
}

@book{barrett_templates_1994,
	address = {Philadelphia},
	title = {Templates for the solution of linear systems: building blocks for iterative methods},
	isbn = {978-0-89871-328-2},
	shorttitle = {Templates for the solution of linear systems},
	language = {eng},
	publisher = {SIAM},
	editor = {Barrett, Richard},
	year = {1994},
	note = {OCLC: 612116664},
	keywords = {Arjun's Library - Physical Copy},
}

@book{greenbaum_iterative_1997,
	address = {Philadelphia, PA},
	series = {Frontiers in applied mathematics},
	title = {Iterative methods for solving linear systems},
	isbn = {978-0-89871-396-1},
	number = {17},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Greenbaum, Anne},
	year = {1997},
	keywords = {Arjun's Library - Physical Copy, Equations, Simultaneous, Iterative methods (Mathematics), Numerical solutions},
}

@book{thomas_credit_2002,
	address = {Philadelphia, PA},
	series = {{SIAM} monographs on mathematical modeling and computation},
	title = {Credit scoring and its applications},
	isbn = {978-0-89871-483-8},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Thomas, L. C. and Edelman, David B. and Crook, Jonathan N.},
	year = {2002},
	keywords = {Arjun's Library - Physical Copy, Credit scoring systems},
}

@book{national_research_council_us_evaluation_2009,
	address = {Washington, D.C},
	title = {Evaluation of quantification of margins and uncertainties methodology for assessing and certifying the reliability of the nuclear stockpile},
	isbn = {978-0-309-12853-7},
	publisher = {National Academies Press},
	editor = {National Research Council (U.S.) and National Research Council (U.S.)},
	year = {2009},
	note = {OCLC: ocn294935745},
	keywords = {Arjun's Library - Physical Copy, Nuclear weapons, Testing, Uncertainty (Information theory), United States},
}

@book{bishop_pattern_2009,
	address = {New York, NY},
	edition = {Corrected at 8th printing 2009},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2 978-1-4939-3843-8},
	language = {eng},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2009},
	note = {OCLC: 845772798},
	keywords = {Arjun's Library - Physical Copy},
}

@book{steinbeck_east_2016,
	address = {New York, New York},
	series = {Penguin classics},
	title = {East of {Eden}},
	isbn = {978-0-14-312948-6},
	publisher = {Penguin Books},
	author = {Steinbeck, John},
	year = {2016},
	keywords = {Arjun's Library - Physical Copy, Brothers, Children of prostitutes, Domestic fiction, Fathers and sons, Fiction, Salinas River Valley (Calif.), Sibling rivalry},
}

@book{gallimore_alien_2019,
	title = {Alien information theory},
	isbn = {978-1-5272-3476-5},
	language = {English},
	author = {Gallimore, Andrew R},
	year = {2019},
	note = {OCLC: 1137217904},
	keywords = {Arjun's Library - Physical Copy},
}

@book{glowinski_fourth_1991,
	address = {Philadelphia},
	title = {Fourth {International} {Symposium} on {Domain} {Decomposition} {Methods} for {Partial} {Differential} {Equations}},
	isbn = {978-0-89871-278-0},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Glowinski, R. and Akademii︠a︡ nauk SSSR and Society for Industrial {and} Applied Mathematics and Société de mathématiques appliquées et industrielles},
	year = {1991},
	note = {Meeting Name: International Symposium on Domain Decomposition Methods for Partial Differential Equations},
	keywords = {Arjun's Library - Physical Copy, Congresses, Decomposition method, Differential equations, Partial},
}

@book{franklin_feedback_2008,
	address = {New Delhi, India},
	title = {Feedback control of dynamic systems},
	isbn = {978-81-317-2142-1},
	language = {English},
	publisher = {Dorling Kindersley (India)},
	author = {Franklin, Gene F and Powell, J. David and Emami-Naeini, Abbas},
	year = {2008},
	note = {OCLC: 774981197},
	keywords = {Arjun's Library - Physical Copy},
}

@book{lochbaum_fukushima_2014,
	address = {New York},
	title = {Fukushima: the story of a nuclear disaster},
	isbn = {978-1-59558-908-8},
	shorttitle = {Fukushima},
	publisher = {The New Press},
	author = {Lochbaum, David A.},
	collaborator = {Union of Concerned Scientists},
	year = {2014},
	keywords = {Accidents, Arjun's Library - Physical Copy, Fukushima Nuclear Disaster, Japan, 2011, Japan Fukushima-ken, Nuclear power plants},
}

@book{coleman_experimentation_2009,
	address = {Hoboken, N.J},
	edition = {3rd ed},
	title = {Experimentation, validation, and uncertainty analysis for engineers},
	isbn = {978-0-470-16888-2},
	publisher = {John Wiley \& Sons},
	author = {Coleman, Hugh W. and Steele, W. Glenn and Coleman, Hugh W.},
	year = {2009},
	note = {OCLC: ocn310400087},
	keywords = {Arjun's Library - Physical Copy, Engineering, Experiments, Uncertainty},
}

@book{ercegovac_introduction_1999,
	address = {New York},
	title = {Introduction to digital systems},
	isbn = {978-0-471-52799-2},
	publisher = {John Wiley Sons},
	author = {Ercegovac, Miloš D. and Lang, Tomás and Moreno, Jaime H.},
	year = {1999},
	keywords = {Arjun's Library - Physical Copy, Digital integrated circuits, Electronic digital computers},
}

@book{kleinberg_algorithm_2006,
	address = {Boston},
	title = {Algorithm design},
	isbn = {978-0-321-29535-4},
	publisher = {Pearson/Addison-Wesley},
	author = {Kleinberg, Jon and Tardos, Éva},
	year = {2006},
	keywords = {Arjun's Library - Physical Copy, Computer algorithms, Data structures (Computer science)},
}

@book{asch_data_2016,
	address = {Philadelphia},
	series = {Fundamentals of algorithms},
	title = {Data assimilation: methods, algorithms, and applications},
	isbn = {978-1-61197-453-9},
	shorttitle = {Data assimilation},
	number = {11},
	publisher = {SIAM, Society for Industrial and Applied Mathematics},
	author = {Asch, Mark and Bocquet, Marc and Nodet, Maëlle},
	year = {2016},
	keywords = {Algorithms, Arjun's Library - Physical Copy, Inverse problems (Differential equations), Numerical analysis},
}

@book{lewis_foundations_1993,
	address = {Los Alamitos, Calif},
	title = {Foundations of parallel programming: a machine-independent approach},
	isbn = {978-0-8186-5692-7 978-0-8186-5691-0},
	shorttitle = {Foundations of parallel programming},
	publisher = {IEEE Computer Society Press},
	author = {Lewis, T. G.},
	year = {1993},
	keywords = {Arjun's Library - Physical Copy, Parallel programming (Computer science)},
}

@book{lindsay_debt_2013,
	address = {Port Townsend, Washington},
	series = {Lannan literary selections},
	title = {Debt to the bone-eating snotflower},
	isbn = {978-1-55659-446-5},
	publisher = {Copper Canyon Press},
	author = {Lindsay, Sarah},
	year = {2013},
	keywords = {Arjun's Library - Physical Copy},
}

@book{taylor_introduction_1982,
	address = {Mill Valley, Calif},
	series = {A series of books in physics},
	title = {An introduction to error analysis: the study of uncertainties in physical measurements},
	isbn = {978-0-935702-07-1 978-0-935702-10-1},
	shorttitle = {An introduction to error analysis},
	publisher = {University Science Books},
	author = {Taylor, John R.},
	year = {1982},
	keywords = {Arjun's Library - Physical Copy, Error analysis (Mathematics), Mathematical physics, Physical measurements},
}

@book{delves_computational_1988,
	address = {Cambridge},
	edition = {1. paperback ed},
	title = {Computational methods for integral equations},
	isbn = {978-0-521-35796-8 978-0-521-26629-1},
	publisher = {Cambridge Univ. Press},
	author = {Delves, Leonard M. and Mohamed, J. L.},
	year = {1988},
	note = {OCLC: 19518622},
	keywords = {Arjun's Library - Physical Copy},
}

@book{vogel_computational_2002,
	address = {Philadelphia},
	series = {Frontiers in applied mathematics},
	title = {Computational methods for inverse problems},
	isbn = {978-0-89871-507-1},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Vogel, Curtis R.},
	year = {2002},
	keywords = {Arjun's Library - Physical Copy, Inverse problems (Differential equations), Numerical solutions},
}

@book{catlin_estimation_1989,
	address = {New York},
	series = {Applied mathematical sciences},
	title = {Estimation, control, and the discrete {Kalman} filter},
	isbn = {978-0-387-96777-6},
	number = {v. 71},
	publisher = {Springer-Verlag},
	author = {Catlin, Donald E.},
	year = {1989},
	keywords = {Arjun's Library - Physical Copy, Control theory, Estimation theory, Kalman filtering},
}

@book{kutz_dynamic_2016,
	address = {Philadelphia},
	title = {Dynamic mode decomposition: data-driven modeling of complex systems},
	isbn = {978-1-61197-450-8},
	shorttitle = {Dynamic mode decomposition},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Kutz, Jose Nathan},
	year = {2016},
	keywords = {Arjun's Library - Physical Copy, Decomposition (Mathematics), Mathematical analysis},
}

@book{schuster_deterministic_1988,
	address = {Weinheim, Federal Republic of Germany : New York, NY, USA},
	edition = {2nd rev. ed},
	title = {Deterministic chaos: an introduction},
	isbn = {978-0-89573-611-6},
	shorttitle = {Deterministic chaos},
	publisher = {VCH ; Distribution, USA and Canada, VCH},
	author = {Schuster, Heinz Georg},
	year = {1988},
	keywords = {Arjun's Library - Physical Copy, Deterministic chaos},
}

@book{sagan_comet_1985,
	address = {New York},
	edition = {1st ed},
	title = {Comet},
	isbn = {978-0-394-54908-8},
	publisher = {Random House},
	author = {Sagan, Carl and Druyan, Ann},
	year = {1985},
	keywords = {Arjun's Library - Physical Copy, Comets, Halley's comet},
}

@book{bollinger_computer_1988,
	address = {Reading, Mass},
	series = {Addison-{Wesley} series in mechanical engineering},
	title = {Computer control of machines and processes},
	isbn = {978-0-201-10645-9},
	publisher = {Addison-Wesley},
	author = {Bollinger, John G. and Duffie, Neil A.},
	year = {1988},
	keywords = {Arjun's Library - Physical Copy, Automatic control, Data processing},
}

@book{gleick_chaos_1988,
	address = {New York},
	title = {Chaos: making a new science},
	isbn = {978-0-14-009250-9},
	shorttitle = {Chaos},
	language = {eng},
	publisher = {Penguin Books},
	author = {Gleick, James},
	year = {1988},
	note = {OCLC: 845143924},
	keywords = {Arjun's Library - Physical Copy},
}

@book{sagan_cosmos_1980,
	address = {New York},
	edition = {1st ed},
	title = {Cosmos},
	isbn = {978-0-394-50294-6},
	publisher = {Random House},
	author = {Sagan, Carl},
	year = {1980},
	keywords = {Arjun's Library - Physical Copy, Astronomy, Popular works},
}

@book{nakamura_applied_1991,
	address = {Englewood Cliffs, N.J},
	title = {Applied numerical methods with software},
	isbn = {978-0-13-041047-4},
	publisher = {Prentice Hall},
	author = {Nakamura, Shoichiro},
	year = {1991},
	keywords = {Arjun's Library - Physical Copy, Data processing, Numerical analysis},
}

@book{bernstein_against_1996,
	address = {New York},
	title = {Against the gods: the remarkable story of risk},
	isbn = {978-0-471-12104-6},
	shorttitle = {Against the gods},
	publisher = {John Wiley \& Sons},
	author = {Bernstein, Peter L.},
	year = {1996},
	keywords = {Arjun's Library - Physical Copy, Decision making, Risk management},
}

@book{kelleher_data_2018,
	address = {Cambridge, Massachusetts},
	series = {The {MIT} {Press} essential knowledge series},
	title = {Data science},
	isbn = {978-0-262-53543-4},
	publisher = {The MIT Press},
	author = {Kelleher, John D. and Tierney, Brendan},
	year = {2018},
	keywords = {Arjun's Library - Physical Copy, Big data, Data mining, Machine learning, Quantitative research},
}

@book{mcdowell_cracking_2014,
	address = {Palo Alto, Calif},
	edition = {5. ed},
	title = {Cracking the coding interview: 150 programming questions and solutions},
	isbn = {978-0-9847828-0-2},
	shorttitle = {Cracking the coding interview},
	language = {eng},
	publisher = {CareerCup},
	author = {McDowell, Gayle Laakmann},
	year = {2014},
	note = {OCLC: 934691366},
	keywords = {Arjun's Library - Physical Copy},
}

@book{patterson_computer_1990,
	address = {San Mateo, Calif},
	title = {Computer architecture: a quantitative approach},
	isbn = {978-1-55860-069-0},
	shorttitle = {Computer architecture},
	publisher = {Morgan Kaufman Publishers},
	author = {Patterson, David A. and Hennessy, John L. and Goldberg, David},
	year = {1990},
	keywords = {Arjun's Library - Physical Copy, Computer architecture, Design and construction, Electronic digital computers},
}

@book{wilkinson_algebraic_1988,
	address = {Oxford : Oxford ; New York},
	series = {Monographs on numerical analysis},
	title = {The algebraic eigenvalue problem},
	isbn = {978-0-19-853418-1},
	publisher = {Clarendon Press ; Oxford University Press},
	author = {Wilkinson, J. H.},
	year = {1988},
	keywords = {Algebras, Linear, Arjun's Library - Physical Copy, Equations, Matrices, Numerical solutions},
}

@book{nifenecker_accelerator_2003,
	address = {Bristol ; Philadelphia},
	series = {Series in fundamental and applied nuclear physics},
	title = {Accelerator driven subcritical reactors},
	isbn = {978-0-7503-0743-7},
	publisher = {Institute of Physics Pub},
	author = {Nifenecker, H. and Meplan, O. and David, S.},
	year = {2003},
	note = {OCLC: ocm52620275},
	keywords = {Arjun's Library - Physical Copy, Nuclear reactors, Particle accelerators},
}

@phdthesis{ekanem_model-based_2013,
	type = {{PhD}},
	title = {A {Model}-{Based} {Human} {Reliability} {Analysis} {Methodology} ({Phoenix} {Method})},
	url = {http://drum.lib.umd.edu/handle/1903/14831},
	abstract = {Despite the advances made so far in developing human reliability analysis (HRA) methods, many issues still exist. Most notable are; the lack of an explicit causal model that incorporates relevant psychological and cognitive theories in its core human performance model, inability to explicitly model interdependencies between human failure events (HFEs) and influencing factors on human performance, lack of consistency, traceability and reproducibility in HRA analysis. 

These issues amongst others have contributed to the variability in results seen in the application of different HRA methods and even in cases where the same method is applied by different analysts. In an attempt to address these issues, a framework for a model-based HRA methodology has been recently proposed which incorporates strong elements of current HRA good practices, leverages lessons learned from empirical studies and the best features of existing and emerging HRA methods. 

This research completely develops this methodology which is aimed at enabling a more credible, consistent, and accurate qualitative and quantitative HRA analysis. The complete qualitative analysis procedure (including a hierarchical performance influencing factor set) and a causal model using Bayesian Belief network (BBN) have been developed to explicitly model the influence and dependencies among HFEs and the different factors that influence human performance. This model has the flexibility to be modified for interfacing with existing methods like Standard-Plant-Analysis-Risk-HRA-method. 

Also, the quantitative analysis procedure has been developed, incorporating a methodology for a cause-based explicit treatment of dependencies among HFEs, which has not been adequately addressed by any other HRA method. As part of this research, information has been gathered from sources (including other HRA methods, NPP operating experience, expert estimates), analyzed and aggregated to provide estimates for the model parameters needed for quantification. While the specific instance of this HRA method is used in nuclear power plants, the methodology itself is generic and can be applied in other environments.},
	language = {en},
	urldate = {2019-01-24},
	author = {Ekanem, Nsimah J.},
	year = {2013},
}

@article{noauthor_nureg-1829_nodate,
	title = {{NUREG}-1829, {Vol}. 2, "{Estimating} {Loss}-{Of}-{Coolant} {Accident} ({LOCA}) {Frequencies} {Through} the {Elicitation} {Process}."},
	language = {en},
	pages = {448},
}

@techreport{tregoning_estimating_nodate,
	title = {Estimating {Loss}-of-{Coolant} {Accident} ({LOCA}) {Frequencies} {Through} the {Elicitation} {Process}},
	shorttitle = {Estimating {Loss}-of-{Coolant} {Accident} ({LOCA}) {Frequencies} {Through} the {Elicitation} {Process}},
	url = {https://nrc.gov/reading-rm/doc-collections/nuregs/staff/sr1829/v1/index.html},
	abstract = {The NRC is establishing a risk-informed revision of the design-basis pipe break size requirements in 10 CFR 50.46, Appendix K to Part 50, and GDC 35 which requires estimates of LOCA frequencies as a function of break size. Separate BWR and PWR piping and non-piping passive system LOCA frequency estimates were developed as a function of effective break size and operating time through the end of the plant license-renewal period. The estimates were based on an expert elicitation process which consolidated operating experience and insights from probabilistic fracture mechanics studies with knowledge of plant design, operation, and material performance. The elicitation required each member of an expert panel to qualitatively and quantitatively assess important LOCA contributing factors and quantify their uncertainty. The quantitative responses were combined to develop BWR and PWR total LOCA frequency estimates for each contributing panelist. The distributions for the six LOCA size categories and three time periods evaluated are represented by four parameters (mean, median, 5th and 95th percentiles). Finally, the individual estimates were aggregated to obtain group estimates, along with measures of panel diversity.

There is general qualitative agreement among the panelists about important technical issues and LOCA contributing factors, but the individual quantitative estimates are much more variable. Sensitivity studies were conducted to examine the effects on the estimated parameters of distribution shape, correlation structure, panelist overconfidence, panel diversity measure, and aggregation method. The group estimates are most sensitive to the method used to aggregate the individual estimates. Geometric-mean aggregation produces frequency estimates that approximate the medians of the panelists’ estimates and also are generally consistent with both operating experience and prior LOCA frequency estimates, except where increases are supported by specific material aging-related concerns. However, arithmetic-mean and mixture-distribution aggregation are alternative methods that lead to significantly higher mean and 95th percentile group estimates. Because the results are sensitive to the aggregation method, a particular set of LOCA frequency estimates is not generically recommended for all risk-informed applications.},
	urldate = {2021-01-22},
	author = {Tregoning, R. and Abramson, L. and Scott, P. and Csontos, A.},
}

@article{noauthor_nureg-1829_nodate-1,
	title = {{NUREG}-1829 {Vol} 1, "{Estimating} {Loss}-of-{Coolant} {Accident} ({LOCA}) {Frequencies} {Through} the {Elicitation} {Process}," {Main} {Report}.},
	language = {en},
	pages = {232},
}

@techreport{mcclymont_atws_1982,
	title = {{ATWS}: a reappraisal. {Part} 3. {Frequency} of anticipated transients},
	shorttitle = {{ATWS}},
	url = {http://inis.iaea.org/Search/search.aspx?orig_q=RN:14767987},
	language = {en},
	number = {EPRI-NP--2230-PT.3},
	urldate = {2021-01-22},
	institution = {Science Applications},
	author = {McClymont, A. S. and Poehlman, B. W.},
	year = {1982},
}

@techreport{mcclymont_atws_1982-1,
	title = {{ATWS}: a reappraisal. {Part} 3. {Frequency} of anticipated transients},
	shorttitle = {{ATWS}},
	url = {https://www.osti.gov/biblio/6469070-atws-reappraisal-part-frequency-anticipated-transients},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {EPRI-NP-2230-Pt.3},
	urldate = {2021-01-22},
	institution = {Science Applications, Inc., Palo Alto, CA (USA)},
	author = {McClymont, A. S. and Poehlman, B. W.},
	month = jan,
	year = {1982},
}

@unpublished{eide_reevaluation_nodate,
	title = {Reevaluation of {Station} {Blackout} {Risk} at {Nuclear} {Power} {Plants} ({NUREG}/{CR}-6890)},
	url = {https://nrc.gov/reading-rm/doc-collections/nuregs/contract/cr6890/index.html},
	abstract = {This report is an update of previous reports analyzing loss of offsite power (LOOP) events and the associated station blackout (SBO) core damage risk at U.S. commercial nuclear power plants. LOOP data for 1986–2004 were collected and analyzed. Frequency and duration estimates for critical and shutdown operations were generated for four categories of LOOPs: plant centered, switchyard centered, grid related, and weather related. Overall, LOOP frequencies during critical operation have decreased significantly in recent years, while LOOP durations have increased. Various additional topics of interest are also addressed, including comparisons with results from other studies, seasonal impacts on LOOP frequencies, and consequential LOOPs. Finally, additional engineering analyses of the LOOP data were performed. To obtain SBO results, updated LOOP frequencies and offsite power nonrecovery curves were input into standardized plant analysis risk (SPAR) models covering the 103 operating commercial nuclear power plants. Core damage frequency results indicating contributions from SBO and other LOOP-initiated scenarios are presented for each of the 103 plants, along with plant class and industry averages. In addition, a comprehensive review of emergency diesel generator performance was performed to obtain current estimates for the SPAR models. Overall, SPAR results indicate that core damage frequencies for LOOP and SBO are lower than previous estimates. Improvements in emergency diesel generator performance contribute to this risk reduction.},
	urldate = {2021-01-22},
	author = {Eide, S. A. and Gentillon, C. D. and Wierman, T. E. and Rasmuson, D. M.},
}

@article{ziegenbein_supply_nodate,
	title = {{SUPPLY} {CHAIN} {RISK} {ASSESSMENT} – {A} {QUANTITATIVE} {APPROACH}},
	abstract = {Since several industrial companies face disruptions in their supply chains that cause high financial losses as a consequence, practitioners and researchers start to look at the risk in the supply chain. It is of importance for the risk management being informed about the magnitude of risk the company or rather the supply chain is subject to. Systematic approaches to quantitatively assess supply chain risks are still missing in practice and science. Therefore, this article introduces a quantitative approach for measuring the probability of occurrence and the financial impact of disruptions in the supply chain. First experiences of the application of the approach are illustrated in an industrial case study.},
	language = {en},
	author = {Ziegenbein, Arne and Baumgart, Jan},
	pages = {14},
}

@article{sherwin_identifying_nodate,
	title = {Identifying and mitigating supply chain risks using fault tree optimization},
	abstract = {Although supply chain risk management and supply chain reliability are topics that have been studied extensively, a gap exists for solutions that take a systems approach to quantitative risk mitigation decision making and especially in industries that present unique risks. In practice, supply chain risk mitigation decisions are made in silos and are reactionary. In this article, we address these gaps by representing a supply chain as a system using a fault tree based on the bill of materials of the product being sourced. Viewing the supply chain as a system provides the basis to develop an approach that considers all suppliers within the supply chain as a portfolio of potential risks to be managed. Next, we propose a set of mathematical models to proactively and quantitatively identify and mitigate at-risk suppliers using enterprise available data with consideration for a firm’s budgetary constraints. Two approaches are investigated and demonstrated on actual problems experienced in industry. The examples presented focus on Low-Volume High-Value (LVHV) supply chains that are characterized by long lead times and a limited number of capable suppliers, which make them especially susceptible to disruption events that may cause delays in delivered products and subsequently increase the financial risk exposure of the firm. Although LVHV supply chains are used to demonstrate the methodology, the approach is applicable to other types of supply chains as well. Results are presented as a Pareto frontier and demonstrate the practical application of the methodology.},
	language = {en},
	author = {Sherwin, Michael D},
	pages = {48},
}

@book{krane_introductory_2000,
	address = {Islamabad},
	title = {Introductory nuclear physics},
	isbn = {978-0-471-85914-7 978-0-471-80553-3},
	language = {English},
	publisher = {National Book Foundation},
	author = {Krane, Kenneth S},
	year = {2000},
	note = {OCLC: 818797467},
}

@techreport{noauthor_part_nodate,
	title = {Part 02 - {Final} {Safety} {Analysis} {Report} ({Rev}. 5) - {Part} 02 - {Tier} 02 - {Chapter} 19 - {Probabilistic} {Risk} {Assessment} and {Severe} {Accident} {Evaluation} - {Sections} 19.00 - 19.05},
	url = {https://www.nrc.gov/docs/ML2022/ML20224A508.pdf},
	urldate = {2021-01-22},
	author = {, NuScale},
}

@techreport{moe_modernization_2019,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Safety} {Classification} and {Performance} {Criteria} for {Structures}, {Systems}, and {Components}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1560535},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-19-55516-Rev000; SC-29980-102.Rev0},
	urldate = {2021-01-22},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company Services, Birmingham, AL (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = aug,
	year = {2019},
	doi = {https://doi.org/10.2172/1560535},
	doi = {https://doi.org/10.2172/1560535},
}

@techreport{moe_modernization_2019-1,
	title = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Risk}-{Informed} and {Performance}-{Based} {Evaluation} of {Defense}-in-{Depth} {Adequacy}},
	shorttitle = {Modernization of {Technical} {Requirements} for {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1560534-modernization-technical-requirements-licensing-advanced-non-light-water-reactors-risk-informed-performance-based-evaluation-defense-depth-adequacy},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-19-55517-Rev000; SC-29980-103.Rev0},
	urldate = {2021-01-22},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = aug,
	year = {2019},
	doi = {https://doi.org/10.2172/1560534},
	doi = {https://doi.org/10.2172/1560534},
}

@techreport{moe_modernization_2019-2,
	title = {Modernization of {Technical} {Requirements} or {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}: {Probabilistic} {Risk} {Assessment} {Approach}},
	shorttitle = {Modernization of {Technical} {Requirements} or {Licensing} of {Advanced} {Non}-{Light} {Water} {Reactors}},
	url = {https://www.osti.gov/biblio/1560527-modernization-technical-requirements-licensing-advanced-non-light-water-reactors-probabilistic-risk-assessment-approach},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-19-55514-Rev000; SC-29980-101.Rev0},
	urldate = {2021-01-22},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Southern Company Services, Birmingham, AL (United States)},
	author = {Moe, Wayne L. and Afzali, Amir},
	month = aug,
	year = {2019},
	doi = {https://doi.org/10.2172/1560527},
	doi = {https://doi.org/10.2172/1560527},
}

@article{draxler_hysplit_nodate,
	title = {{HYSPLIT} {User}'s {Guide}},
	abstract = {The HYSPLIT (Hybrid Single-Particle Lagrangian Integrated Trajectory) Model
installation, configuration, and operating procedures are reviewed.
Examples are given for setting up the model for trajectory and
concentration simulations, graphical displays, and creating
publication quality illustrations. The model requires specially
preformatted meteorological data. Programs that can be used to
create the model's meteorological input data are described. The
User's Guide has been restructured so that the section titles match
the GUI help menu tabs. Although this guide is designed to support
the PC and UNIX versions of the program, the executable of the
on-line web version is identical. The only differences are the
options available through the interface.},
	language = {en},
	author = {Draxler, Roland and Stunder, Barbara and Rolph, Glenn and Stein, Ariel and Taylor, Albion},
	pages = {249},
}

@book{todreas_nuclear_1993,
	address = {New York},
	edition = {2},
	title = {Nuclear systems. 1: {Thermal} hydraulic fundamentals},
	volume = {1},
	isbn = {978-1-56032-051-7 978-0-89116-935-2},
	shorttitle = {Nuclear systems 1},
	language = {English},
	publisher = {Hemisphere Publ. Corp},
	author = {Todreas, Neil E. and Kazimi, Mujid S.},
	year = {1993},
	note = {OCLC: 257710213},
}

@article{noauthor_pilot_2007,
	title = {A {Pilot} {Probabilistic} {Risk} {Assessment} of a {Dry} {Cask} {Storage} {System} at a {Nuclear} {Power} {Plant} ({NUREG}-1864)},
	shorttitle = {{NUREG}-1864},
	url = {https://www.nrc.gov/docs/ML0713/ML071340012.pdf},
	abstract = {In response to a request from the U.S. Nuclear Regulatory Commission (NRC), Office of Nuclear Material Safety and Safeguards (NMSS), the Office of Nuclear Regulatory Research (RES) and the NMSS Spent Fuel Project Office (SFPO) have jointly developed and applied a methodology for performing a pilot probabilistic risk assessment (PRA) of a dry cask storage system at a nuclear power plant site (i.e., an independent spent fuel storage installation). This RES/NMSS report documents the pilot PRA for a specific dry cask system (Holtec International HI-STORM 100) at a specific boiling-water reactor (BWR) site. The methodology developed can serve as a guide for performing similar PRAs in the future. The pilot study can provide guidance for assessing the risk to the public and identifying the dominant contributors to that risk. The cask system consists of a multipurpose canister (MPC) that confines the fuel, a transfer overpack that shields workers from radiation while the cask is being prepared for storage, and a storage overpack that shields people from radiation and mechanically protects the MPC during storage. The study covers various phases of the dry cask storage process, from loading fuel from the spent fuel pool, preparing the cask for storage and transferring it outside the reactor building, moving the cask from the reactor building to the storage pad, and storing the cask for 20 years on the storage pad.

The study develops and assesses a comprehensive list of initiating events, including dropping the cask during handling and external events during onsite storage (such as earthquakes, floods, high winds, lightning strikes, accidental aircraft crashes, and pipeline explosions). Potential cask failures from mechanical and thermal loads are modeled. The study estimates the annual risk for one cask in terms of the individual probability of a prompt fatality within 1.6 km (1 mile) and a latent cancer fatality within 16 km (10 miles) of the site.},
	journal = {US NRC: Washington, DC, USA},
	author = {, US NRC},
	month = mar,
	year = {2007},
}

@misc{noauthor_global_nodate,
	title = {{GLOBAL} {FOREST} {FIRE} {ASSESSMENT} 1990-2000 - {FRA} {WP} 55},
	url = {http://www.fao.org/3/ad653e/ad653e56.htm},
	urldate = {2021-01-07},
}

@misc{noauthor_global_nodate-1,
	title = {{GLOBAL} {FOREST} {FIRE} {ASSESSMENT} 1990-2000 - {FRA} {WP} 55},
	url = {http://www.fao.org/3/ad653e/ad653e00.htm#TopOfPage},
	urldate = {2020-12-30},
}

@article{taira_eight_2019,
	title = {Eight years post-{Fukushima}: is forest decontamination still necessary?},
	volume = {60},
	issn = {0449-3060, 1349-9157},
	shorttitle = {Eight years post-{Fukushima}},
	url = {https://academic.oup.com/jrr/article/60/5/714/5528218},
	doi = {10.1093/jrr/rrz047},
	language = {en},
	number = {5},
	urldate = {2020-12-18},
	journal = {Journal of Radiation Research},
	author = {Taira, Yasuyuki and Inadomi, Yudai and Hirajou, Shota and Fukumoto, Yasuhiro and Orita, Makiko and Yamada, Yumiko and Takamura, Noboru},
	month = oct,
	year = {2019},
	pages = {714--716},
}

@inproceedings{lutz_use_2010,
	title = {Use of {PRA} in the {Design} of the {Westinghouse} {AP1000} {Plant}},
	url = {https://manufacturingscience.asmedigitalcollection.asme.org/ICONE/proceedings/ICONE17/43536/905/356654},
	doi = {10.1115/ICONE17-75408},
	language = {en},
	urldate = {2020-12-17},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Lutz, Robert J. and Scobel, James H. and Anderson, Richard G. and Schulz, Terry},
	month = feb,
	year = {2010},
	pages = {905--909},
}

@article{kashparov_report_2016,
	title = {Report {Chernobyl}: 30 years of radioactive contamination legacy},
	journal = {Ukrainian Institute of Agricultural Radiology},
	author = {Kashparov, Valerii},
	year = {2016},
}

@inproceedings{diaconeasa_model-based_2019,
	title = {Model-{Based} {Resilience} {Assessment} {Framework} for {Autonomous} {Systems}},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2019/83501/V013T13A030/1073568},
	doi = {10.1115/IMECE2019-12288},
	language = {en},
	urldate = {2020-03-02},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Diaconeasa, Mihai A. and Mosleh, Ali and Morozov, Andrey and Tai, Ann T.},
	month = nov,
	year = {2019},
}

@techreport{diaconeasa_human_2019,
	address = {Los Angeles, CA},
	title = {Human reliability analysis for nuclear power plants using the extended {PHOENIX} methodology and software platform},
	number = {GIRS-2019-01/L},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian},
	month = mar,
	year = {2019},
}

@techreport{diaconeasa_first_2017,
	address = {Los Angeles, CA},
	title = {A {First} {Order} {Scalable} {Modeling} {Approach} for {Assessing} the {Resilience} of {Lifeline} {Infrastructure} {Systems}: {From} {Concept} to {Cross}-{Sector} {Case} {Study}},
	number = {GIRS-2017-06/L},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Garrick, B. John and Mosleh, Ali},
	year = {2017},
}

@inproceedings{diaconeasa_branching_2018,
	address = {Trondheim, Norway},
	title = {Branching rules and quantification based on human behavior in the {ADS}-{IDAC} dynamic {PRA} platform},
	language = {en},
	booktitle = {Proceedings of the {European} {Society} for {Reliability} {Annual} {Meeting}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {7},
}

@inproceedings{diaconeasa_discrete_2018,
	address = {Los Angeles, CA},
	title = {Discrete {Dynamic} {Event} {Tree} {Uncertainty} {Quantification} in the {ADS}-{IDAC} {Probabilistic} {Safety} {Assessment} and {Management}},
	abstract = {ADS-IDAC stands for the Accident Dynamics Simulator coupled with the Information, Decision and Action in a Crew context. It contains both a cognitive crew model and a nuclear power plant thermal-hydraulic model to simulate their response behavior and interactions given abnormal conditions and generate a discrete dynamic event tree (DDET). When the probabilities of the initiating events and branching or non-branching events in a DDET are subject to uncertainty, the probabilities can be considered to be random variables described by some probability distribution. The form of their probability distribution depends on the type of events (e.g., hardware failure, human activity, etc.) Therefore, the probability of the end state events in such a DDET will also be a random variable, and the form of its probability distribution will depend both on the DDET structure and the probability distributions of the events. In this paper, the various sampling techniques (i.e., Monte Carlo, Latin Hypercube, quasi-Monte Carlo) that are implemented in an updated version of ADS-IDAC are summarized. They are used for the propagation of uncertainties in the DDET generated by ADSIDAC. These Monte Carlo methods are used to obtain a probability distribution of the end state events in a DDET using available information on the tree structure and the assumed probability distributions of its top events. The same methods can be applied to simulate the fault trees (FTs) used to represent frontline and support systems. For these accident sequences, the propagation of uncertainties is performed on the combined structure of DDET and FTs.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {9},
}

@techreport{diaconeasa_ads-idac_2016,
	address = {Los Angeles, CA},
	title = {The {ADS}-{IDAC}+ {Dynamic} {PRA} {Platform} for {Accident} {Sequence} {Precursor} {Analysis}},
	number = {GIRS-2016-02},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Mosleh, Ali},
	year = {2016},
}

@inproceedings{diaconeasa_ads-idac_2017,
	address = {Pittsburgh, PA},
	title = {The {ADS}-{IDAC} {Dynamic} {PSA} {Platform} with {Dynamically} {Linked} {System} {Fault} {Trees}},
	language = {en},
	booktitle = {American {Nuclear} {Society} {Probabilistic} {Safety} {Assessment}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2017},
	pages = {7},
}

@inproceedings{diaconeasa_development_2018,
	address = {Los Angeles, CA},
	title = {Development of a {Software} {Platform} for {Pipeline} {Health} {Monitoring} and {Management}},
	abstract = {This paper describes the software requirements and architecture of a risk-based pipeline integrity management support tool to aid in decision-making and planning by the pipeline operators. This platform is being developed as the main product of the research project on Pipeline System Integrity Management sponsored by the Petroleum Institute, Abu Dhabi, UAE, in collaboration with a large interdisciplinary team from the sponsoring agency and the University of Maryland, Department of Mechanical Engineering. As such, the platform design is supported by a multi-disciplinary science and engineering approach for a comprehensive, state-of-the-art solution. Where possible, existing technologies and methods are leveraged, and new ones are developed as needed to meet the objectives.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {6},
}

@inproceedings{diaconeasa_performing_2018,
	address = {Los Angeles, CA},
	title = {Performing an {Accident} {Sequence} {Precursor} {Analysis} with the {ADS}-{IDAC} {Dynamic} {PSA} {Software} {Platform}},
	abstract = {An accident sequence precursor is defined as an observed event that combined with one or several postulated events could lead to core damage, while an accident sequence precursor analysis is a probabilistic safety assessment performed to obtain the conditional probability of a core damage accident given an initiating event and identify the dominant event sequences. The current discrete dynamic probabilistic safety assessment techniques are generally used to simulate accident scenarios and their probability of occurrence. They are an appropriate tool for performing an accident sequence precursor analysis that can capture realistic scenarios in a transparent manner. One such platform is ADS-IDAC – the accident Dynamics Simulator coupled with the Information, Decision, and Action in a Crew context cognitive model, and a mature nuclear power plant thermal-hydraulic model. Rich contextual scenarios are algorithmically generated using a relatively small set of branching rules that cover both stochastic and deterministic interactions between the system and the crew evolutions. Moreover, thermal-hydraulic success criteria are explicitly represented in the simulation. This paper provides details about how to perform an accident sequence precursor analysis with ADS-IDAC. Additional information is included regarding the recommended analysis team, the necessary information for performing the analysis, when to use ADS-IDAC, and the advantages and limitations of using it.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {7},
}

@techreport{diaconeasa_modification_2018,
	address = {Los Angeles, CA},
	title = {Modification {Risk} {Assessment} of the {Main} {Generator} {Stator} at {Diablo} {Canyon} {Power} {Plant} {Unit} 2},
	number = {GIRS-2018-06},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Grantom, C. R. and Mosleh, Ali},
	year = {2018},
}

@techreport{diaconeasa_quantification_2018,
	address = {Los Angeles, CA},
	title = {Quantification of {Human} {Failure} {Events} with the {ADS}-{IDAC}+ {Dynamic} {PRA} {Platform}},
	number = {GIRS-2018-02},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Mosleh, Ali},
	year = {2018},
}

@techreport{diaconeasa_assured_2018,
	address = {Los Angeles, CA},
	title = {Assured {Resilience} for {Autonomous} {Systems}},
	number = {GIRS-2018-05},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Tai, Ann and Morozov, Andrey and Masoomi, Hassan and Mosleh, Ali},
	year = {2018},
}

@inproceedings{jafary_survey_2018,
	address = {Los Angeles, CA},
	title = {A {Survey} on {Human} {Interaction} with {Autonomous} {Vehicles} and {Vehicles} to {Vehicles}},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Jafary, Bentolhoda and Rabiei, Elaheh and Masoomi, Hassan and Diaconeasa, Mihai A and Fiondella, Lance and Mosleh, Ali},
	year = {2018},
	pages = {10},
}

@inproceedings{wu_impact_2018,
	address = {Los Angeles, CA},
	title = {The {Impact} of {Time}-{Varying} {Operating} {Parameters} on the {Corrosion} {Rate} and {Depth} of {Gas} {Pipelines} {Depth} of {Gas} {Pipelines}},
	abstract = {Corrosion rate and depth predictions in gas pipelines are significant for both safety and economic reasons. Most of the time, the variations of operating conditions on a daily basis are often overlooked and are approximated with their mean values, resulting in non-negligible deviations of the predicted corrosion depth after a long time of operation. This paper introduces a corrosion rate predictive model for internal uniform corrosion of gas pipelines subject to an aqueous CO2 and H2S environment and applies it to wet gas gathering pipelines in Sichuan Province, China, to study the influence of time-varying operating parameters on the corrosion rate and depth. The results show that the proposed model is capable of predicting instantaneous corrosion rates as a function of time in which the instantaneous corrosion rates can reflect the time-varying operating parameters. In addition, it is found that by using mean values for the operating parameters to calculate the corrosion rate it is likely to underestimate the corrosion depth in the long-term prediction by around a factor 2. The underestimation of the corrosion depth prevents engineers to take appropriate mitigating actions in time and thus exposes the pipeline to the risk of failure.},
	language = {en},
	booktitle = {Probabilistic {Safety} {Assessment} and {Management}},
	author = {Wu, Keo Yuan and Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {10},
}

@inproceedings{chalgham_smart_2019,
	title = {A {Smart} {Pipeline} {Monitoring} and {Emergency} {Response} {System} {Using} {Web} {Services}},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2019/83501/V013T13A016/1073531},
	doi = {10.1115/IMECE2019-11825},
	language = {en},
	urldate = {2020-03-03},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Chalgham, Wadie and Diaconeasa, Mihai and Elgazzar, Khalid and Seibi, Abdennour},
	month = nov,
	year = {2019},
}

@inproceedings{chalgham_numerical_2019,
	title = {A {Numerical} and {Experimental} {Study} {Supporting} a {Methodology} for {Live} {Monitoring}, {Leak} {Detection}, and {Automatic} {Response} in {Water} {Pipelines}},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2019/83501/V013T13A018/1073574},
	doi = {10.1115/IMECE2019-11861},
	language = {en},
	urldate = {2020-03-03},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Chalgham, Wadie and Diaconeasa, Mihai and Gottumukkala, Raju and Seibi, Abdennour},
	month = nov,
	year = {2019},
}

@inproceedings{diaconeasa_hypra_2018,
	address = {Trondheim, Norway},
	title = {{HYPRA}: {A} hybrid static and dynamic {PRA} software platform},
	language = {en},
	booktitle = {Proceedings of the {European} {Society} for {Reliability} {Annual} {Meeting}},
	author = {Diaconeasa, Mihai A and Mosleh, Ali},
	year = {2018},
	pages = {7},
}

@techreport{diaconeasa_part-level_2018,
	address = {Los Angeles, CA},
	title = {Part-{Level} {Bayesian} {Estimation} and {System}-{Level} {Reliability} {Analysis} for {A} {Testing} and {Qualification} {Screening} {Process} of {COTS}},
	number = {GIRS-2018-04},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Rabiei, Elaheh and Mosleh, Ali},
	year = {2018},
}

@techreport{garrick_probabilistic_2019,
	address = {Los Angeles, CA},
	title = {Probabilistic {Risk} {Assessment} of the {Diablo} {Canyon} {Power} {Plant} {Spent} {Fuel} {Handling} and {Storage} {Program}},
	number = {GIRS-2019-04},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Garrick, B. John and Wakefield, Donald J. and Kessler, John and Diaconeasa, Mihai Aurelian},
	month = aug,
	year = {2019},
}

@article{wang_use_2020,
	title = {On the {Use} of the {Hybrid} {Causal} {Logic} {Methodology} in {Ship} {Collision} {Risk} {Assessment}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2077-1312/8/7/485},
	doi = {10.3390/jmse8070485},
	abstract = {A ship collision accident is one of the most dangerous and common types of maritime accidents. Traditional probabilistic risk assessment (PRA) of ship collision accidents is a methodology that can be adopted to ensure maritime safety. Nevertheless, a need for better approaches to model human behavior, such as risk identification, communication, and decision-making, has been identified. Such advanced PRA methods require a more explicit way of taking human factors into consideration than the traditional risk assessment methods. Hybrid causal logic (HCL) is an advanced PRA method due to its unique three-level framework that includes event sequence diagrams, fault trees, and Bayesian networks, which makes it suitable for modeling human behavior that is important to ship collision accidents. This paper discusses the applicability of the HCL methodology for the ship collision accident. Firstly, the event sequences of typical ship collision accidents are summarized based on the study of 50 accident investigation reports. Then, fault trees for mechanical failure events and the Bayesian networks for human error events are constructed to analyze the events in a structured way at a more detailed level. Finally, the three main end-state types of ship collision avoidance scenario have been quantified. The result of the probability of a ship collision accident is verified by estimating the annual frequency of collision accidents in the Singapore Strait. Comparing with the historical data, the estimation results are quite near to the real case. By taking advantage of the HCL methodology, the modeling of ship collision scenarios can be carried out at a deep logical level. At the same time, it is possible to combine a detailed analysis of various primary events with a comprehensive analysis at the system level.},
	language = {en},
	number = {7},
	urldate = {2020-06-30},
	journal = {Journal of Marine Science and Engineering},
	author = {Wang, Tengfei and Wu, Qing and A. Diaconeasa, Mihai and Yan, Xinping and Mosleh, Ali},
	month = jul,
	year = {2020},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {accident investigation reports, hybrid causal logic methodology, maritime safety, ship collision accidents},
	pages = {485},
}

@article{wu_comparative_2020,
	title = {A {Comparative} {Assessment} of {Collision} {Risk} of {Manned} and {Unmanned} {Vessels}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2077-1312/8/11/852},
	doi = {10.3390/jmse8110852},
	abstract = {It is expected that the prototypes of unmanned merchant ships will be deployed in the next few years. However, there is no specific research on whether the introduction of unmanned ships will reduce the risk of ship collision accidents in which communication between vessels is critical. This work constitutes an attempt to bridge the gap identified above by applying the Hybrid Causal Logic (HCL) methodology to model general-level collision scenarios of unmanned ships. The HCL methodology has been selected for its proven applicability to risk assessments, even when empirical data may be insufficient. Collision scenarios involving unmanned ships have been created in which manned ships of the conventional collision scenario HCL model are replaced with unmanned ships. Then, collision scenarios capturing the interactions between a manned ship and an unmanned ship were modeled. By comparing the qualitative and quantitative results of the different scenarios, we can see that the introduction of unmanned ships may effectively reduce the occurrence of ship collision accidents.},
	language = {en},
	number = {11},
	urldate = {2020-10-30},
	journal = {Journal of Marine Science and Engineering},
	author = {Wu, Qing and Wang, Tengfei and Diaconeasa, Mihai A. and Mosleh, Ali and Wang, Yang},
	month = nov,
	year = {2020},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {hybrid causal logic methodology, maritime management, ship collision accidents, unmanned ship},
	pages = {852},
}

@inproceedings{chalgham_dynamic_2019,
	title = {A {Dynamic} {Pipeline} {Network} {Health} {Assessment} {Software} {Platform} for {Optimal} {Risk}-{Based} {Prioritization} of {Inspection}, {Structural} {Health} {Monitoring}, and {Proactive} {Management}},
	url = {https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2019/83501/V013T13A015/1073585},
	doi = {10.1115/IMECE2019-11806},
	language = {en},
	urldate = {2020-03-03},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Chalgham, Wadie and Diaconeasa, Mihai and Wu, Keo-Yuan and Mosleh, Ali},
	month = nov,
	year = {2019},
}

@techreport{diaconeasa_wildfire_2019,
	address = {Los Angeles, CA},
	title = {Wildfire {Risk} {Assessment} and {Management} {Methodology} and {Software} {Capability} {Development}},
	number = {GIRS-2019-05},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Apostolakis, George and Mosleh, Ali},
	month = sep,
	year = {2019},
}

@techreport{diaconeasa_security_2019,
	address = {Los Angeles, CA},
	title = {Security {Probabilistic} {Risk} {Assessment} of the {Vehicle} {Inspection} {Station} ({VIS}) {Relocation} at {Diablo} {Canyon} {Power} {Plant}},
	number = {GIRS-2019-03},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Diaconeasa, Mihai Aurelian and Stewart, Theresa and Mosleh, Ali},
	month = may,
	year = {2019},
}

@inproceedings{wang_distributed_2019,
	title = {A {Distributed} {Artificial} {Potential} {Field} {Method} for {Ship} {Collision} {Avoidance} {Path} {Planning} {Under} {COLREGS}},
	url = {https://trid.trb.org/view/1572489},
	urldate = {2020-04-29},
	author = {Wang, Tengfei and Wu, Qing and Diaconeasa, Mihai and Wang, Yang and Zhang, Mingyang},
	month = jan,
	year = {2019},
	note = {Number: 19-05211},
}

@techreport{garrick_transportation_2020,
	address = {Los Angeles, CA},
	title = {Transportation {Risks} {Associated} with the {Decommissioning} of the {Diablo} {Canyon} {Power} {Plant}},
	number = {GIRS-2020-01},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	author = {Garrick, B. John and Chandra, Roy and Diaconeasa, Mihai Aurelian and Wangler, Michael E.},
	month = mar,
	year = {2020},
}

@incollection{takenaka_radioactive_2019,
	address = {Singapore},
	title = {Radioactive {Contamination} in {Forest} by the {Accident} of {Fukushima} {Daiichi} {Nuclear} {Power} {Plant}: {Comparison} with {Chernobyl}},
	isbn = {9789811386053 9789811386060},
	shorttitle = {Radioactive {Contamination} in {Forest} by the {Accident} of {Fukushima} {Daiichi} {Nuclear} {Power} {Plant}},
	url = {http://link.springer.com/10.1007/978-981-13-8606-0_1},
	abstract = {In this chapter, we compare the compositions and magnitudes of releases 6 of radionuclides during the Chernobyl and Fukushima accidents and summarize the 7 results of the long-term observations of the radionuclide dynamics in the ecosystem 8 compartments in Chernobyl forests. Due to much larger magnitude of atmospheric 9 release, the area contaminated as a result of the Chernobyl accident is larger; 10 moreover, the near zone of the Chernobyl accident is contaminated with 90Sr and 11 other fuel component radionuclides that were not released in any signiﬁcant amounts 12 during the Fukushima accident.},
	language = {en},
	urldate = {2020-12-11},
	booktitle = {Radiocesium {Dynamics} in a {Japanese} {Forest} {Ecosystem}},
	publisher = {Springer Singapore},
	author = {Yoschenko, Vasyl and Kashparov, Valery and Ohkubo, Tatsuhiro},
	editor = {Takenaka, Chisato and Hijii, Naoki and Kaneko, Nobuhiro and Ohkubo, Tatsuhiro},
	year = {2019},
	doi = {10.1007/978-981-13-8606-0_1},
	pages = {3--22},
}

@techreport{everline_probabilistic_1986,
	type = {Report},
	title = {Probabilistic risk assessment of the modular {HTGR} plant. {Revision} 1},
	url = {https://digital.library.unt.edu/ark:/67531/metadc676259/},
	abstract = {A preliminary probabilistic risk assessment (PRA) has been performed for the modular HTGR (MHTGR). This PRA is preliminary in the context that although it updates the PRA issued earlier to include a wider spectrum of events for Licensing Basis Events (LBE) selection, the final version will not be issued until later. The primary function of the assessment was to assure compliance with the NRC interim safety goals imposed by the top-level regulatory criteria, and utility/user requirements regarding public evacuation or sheltering. In addition, the assessment provides a basis for designer feedback regarding reliability allocations and barrier retention requirements as well as providing a basis for the selection of licensing basis events (LBEs) and the safety classification of structures, systems, and components. The assessment demonstrates that both the NRC interim safety goals and utility/user imposed sheltering/evacuation requirements are satisfied. Moreover, it is not anticipated that design changes introduced will jeopardize compliance with the interim safety goals or utility/user requirements. 61 refs., 48 figs., 24 tabs.},
	language = {English},
	urldate = {2020-10-28},
	author = {Everline, C. J. and Bellis, E. A. and Vasquez, J.},
	month = jun,
	year = {1986},
	doi = {10.2172/455545},
	note = {Number: DOE/HTGR--86-011-Rev.1
Publisher: GA Technologies, Inc., San Diego, CA (United States)},
}

@techreport{persensky_guidance_nodate,
	address = {Washington, DC},
	title = {Guidance for {Assessing} {Exemption} {Requests} from the {Nuclear} {Power} {Plant} {Licensed} {Operator} {Staffing} {Requirements} {Specified} in 10 {CFR} 50.54(m)},
	url = {https://www.nrc.gov/docs/ML0520/ML052080125.pdf},
	number = {NUREG-1791},
	urldate = {2020-12-07},
	institution = {U.S. Nuclear Regulatory Commission},
	author = {Persensky, J. and Szabo, A.},
}

@techreport{j_m_ohara_human_nodate,
	address = {Washington, DC},
	title = {Human {Factors} {Engineering} {Program} {Review} {Model}},
	language = {en},
	number = {NUREG-0711, Rev. 3},
	institution = {U.S. Nuclear Regulatory Commission},
	author = {{J. M. OHara} and {J. C. Higgins} and {S. A. Fleger} and {P. A. Pieringer}},
	pages = {147},
}

@article{pirouzmand_atmospheric_2018,
	title = {Atmospheric dispersion assessment of radioactive materials during severe accident conditions for {Bushehr} nuclear power plant using {HYSPLIT} code},
	volume = {108},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197018301409},
	doi = {10.1016/j.pnucene.2018.05.015},
	abstract = {In nuclear power plants and nuclear research reactors, radioactive material release into the environment and the dose received by individuals are the main concerns during a severe accident. Thus, calculation of expected dose at reactor perimeters and surrounding area in the event of an accident is a basic requirement for the safety of these facilities. This study uses the HYSPLIT code to simulate the consequences of the worst hypothetical accident scenario of Station Blackout (SBO) and Large Break Loss-of-Coolant Accident (LBLOCA) in Bushehr nuclear power plant unit-1 (BNPP-1). The concentration of released radioactive material and external eﬀective doses received by populations within 30 km radius of facility are computed. Dispersion of radioactive materials is simulated using of Global Data Assimilation System (GDAS) meteorological data. Particle behavior in diﬀerent stages of dispersion and annual dispersion along each of the 16 geographic directions are obtained from trajectory calculations. The concentration of diﬀerent radionuclides is determined and the resulting annual external eﬀective dose at diﬀerent locations are computed as well. All calculations are performed for four diﬀerent release time durations including 4, 12, 24 and 48 h. Given the distribution of population around the NPP facility, the highest doses are expected at 3 km north and 4 km northwest of the reactor location. The maximum dose for 4, 12, 24, and 48-h long emission at diﬀerent points of Bushehr city is calculated and compared with the allowable dose limits.},
	language = {en},
	urldate = {2020-12-04},
	journal = {Progress in Nuclear Energy},
	author = {Pirouzmand, Ahmad and Kowsar, Zahra and Dehghani, Peyman},
	month = sep,
	year = {2018},
	pages = {169--178},
}

@incollection{brillinger_risk_2003,
	address = {Beachwood, OH},
	title = {Risk assessment: a forest fire example},
	isbn = {978-0-940600-56-0},
	shorttitle = {Risk assessment},
	url = {http://projecteuclid.org/euclid.lnms/1215091142},
	abstract = {The concern of this paper is obtaining baseline values for the number of forest ﬁres as a function of time and location and other explanatories. A model is developed and applied to a large data set from Federal lands in the state of Oregon. To proceed the data are grouped into small spatial-temporal cells (voxels). Fires are rare so there are many of these voxels with no ﬁres. In fact there are so many such cells that in the analyses presented a sample is taken to make the work manageable. The paper sets down a likelihood for the sampled data and ﬁts a generalized additive model involving location, elevation and day of the year as explanatories.},
	language = {en},
	urldate = {2020-12-04},
	booktitle = {Institute of {Mathematical} {Statistics} {Lecture} {Notes} - {Monograph} {Series}},
	publisher = {Institute of Mathematical Statistics},
	author = {Brillinger, David R. and Preisler, Haiganoush K. and Benoit, John W.},
	year = {2003},
	doi = {10.1214/lnms/1215091142},
	pages = {177--196},
}

@incollection{noauthor_chapter-3final_1995,
	series = {Final {Environmental} {Impact} {Statement}},
	title = {Chapter-3/{Final} {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	url = {https://solarsystem.nasa.gov/system/downloadable_items/2615_chap3.pdf},
	language = {English},
	booktitle = {Final {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	publisher = {NASA},
	month = jun,
	year = {1995},
	pages = {76},
}

@incollection{noauthor_chapter-2final_1995,
	series = {Final {Environmental} {Impact} {Statement}},
	title = {Chapter-2/{Final} {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	url = {https://solarsystem.nasa.gov/system/downloadable_items/2614_chap2.pdf},
	language = {English},
	booktitle = {Final {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	publisher = {NASA},
	month = jun,
	year = {1995},
	pages = {76},
}

@book{lewis_technological_1992,
	title = {Technological {Risk}},
	isbn = {978-0-393-30829-7},
	abstract = {Risks seem to abound in our everyday lives, especially the risks flowing from the explosion of our modern technology, with its pesticides, pollution, nuclear power, microwave radiation and chemical trace elements in food of all kinds. Two questions face all of us: how real are these risks and, if real, how do we manage our lives in order to avoid personal damage from them? The book examines these questions, delving into the nature and true seriousness of risk (as opposed to how bad the risk seems to be), into how we measure risk and how we regulate it. Lewis includes the latest scientific information on carcinogens and the greenhouse effect as well as detailed discussion of road safety, the risk of air travel, nuclear power and acid rain.},
	language = {en},
	publisher = {W. W. Norton \& Company},
	author = {Lewis, H. W.},
	year = {1992},
	note = {Google-Books-ID: noFcbT69gBEC},
	keywords = {Science / Environmental Science, Technology \& Engineering / Industrial Health \& Safety},
}

@techreport{international_atomic_energy_agency_project_2012,
	address = {Vienna},
	title = {Project management in nuclear power plant construction: guidelines and experience},
	shorttitle = {Project management in nuclear power plant construction},
	language = {en},
	institution = {IAEA},
	author = {{International Atomic Energy Agency}},
	year = {2012},
	note = {OCLC: 824648314},
}

@incollection{hackel_model_2000,
	address = {Berlin, Heidelberg},
	title = {Model {Protocol} {Additional} to the {Agreement}(s) between {State}(s) and the {International} {Atomic} {Energy} {Agency} for the {Application} of {Safeguards}},
	isbn = {978-3-642-63067-5 978-3-642-57147-3},
	url = {http://link.springer.com/10.1007/978-3-642-57147-3_16},
	language = {en},
	urldate = {2020-07-21},
	booktitle = {Tightening the {Reins}},
	publisher = {Springer Berlin Heidelberg},
	author = {Häckel, Erwin and Stein, Gotthard},
	editor = {Häckel, Erwin and Stein, Gotthard},
	year = {2000},
	doi = {10.1007/978-3-642-57147-3_16},
	pages = {203--267},
}

@article{sitaraman_methodology_2015,
	title = {Methodology and {Software} for {Gross} {Defect} {Detection} of {Spent} {Nuclear} {Fuel} at the {Atucha}-{I} {Reactor}},
	volume = {192},
	issn = {0029-5450, 1943-7471},
	url = {https://www.tandfonline.com/doi/full/10.13182/NT14-63},
	doi = {10.13182/NT14-63},
	language = {en},
	number = {1},
	urldate = {2020-08-15},
	journal = {Nuclear Technology},
	author = {Sitaraman, Shivakumar and Ham, Young S. and Gharibyan, Narek and Peixoto, Orpet J. M. and Diaz, Gustavo},
	month = oct,
	year = {2015},
	pages = {74--83},
}

@article{pozzi_mcnpx-polimi_2012,
	title = {{MCNPX}-{PoliMi} for nuclear nonproliferation applications},
	volume = {694},
	issn = {01689002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900212008224},
	doi = {10.1016/j.nima.2012.07.040},
	abstract = {This paper describes the use of the Monte Carlo code MCNPX-PoliMi for nuclear-nonproliferation applications, with particular emphasis on the simulation of spontaneous and neutron-induced nuclear ﬁssion. New models for the outgoing neutrons and gamma rays emitted in spontaneous and induced ﬁssion are described. For spontaneous ﬁssion, the models include prompt neutron energy distributions that depend on the number of neutrons emitted in the individual ﬁssion events. For neutron-induced ﬁssion, due to lack of data, the prompt neutron energy distributions are independent of the number of neutrons emitted in the individual ﬁssion events. Gamma rays are sampled independently of the neutrons. Code validation is performed on well-characterized mixed-oxide fuel and plutonium-oxide samples.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Pozzi, S.A. and Clarke, S.D. and Walsh, W.J. and Miller, E.C. and Dolan, J.L. and Flaska, M. and Wieger, B.M. and Enqvist, A. and Padovani, E. and Mattingly, J.K. and Chichester, D.L. and Peerani, P.},
	month = dec,
	year = {2012},
	pages = {119--125},
}

@article{wang_designing_2018,
	series = {2017 {Research} {Symposium} on {Information} {Integrity} \& {Information} {Systems} {Assurance}},
	title = {Designing confidentiality-preserving {Blockchain}-based transaction processing systems},
	volume = {30},
	issn = {1467-0895},
	url = {http://www.sciencedirect.com/science/article/pii/S1467089518300794},
	doi = {10.1016/j.accinf.2018.06.001},
	abstract = {Blockchain is one of the most disruptive and promising emerging technologies, and it appears to have the potential for significantly affecting the accounting and auditing fields. Using blockchain technology, zero-knowledge proof, and homomorphic encryption, this paper presents a design for a blockchain-based transaction processing system (TPS) and develops a prototype to demonstrate the functionality of the blockchain-based TPS in real-time accounting, continuous monitoring and fraud prevention. The computational performance of a blockchain-based TPS versus relational databases is evaluated and discussed. In anticipation of the wider applicability of blockchain technology to support enterprise information systems and continuous monitoring systems, this paper presents an innovative design that utilizes the advantages of blockchain technology while overcoming some of the key barriers to its adoption.},
	language = {en},
	urldate = {2020-12-01},
	journal = {International Journal of Accounting Information Systems},
	author = {Wang, Yunsen and Kogan, Alexander},
	month = sep,
	year = {2018},
	keywords = {Blockchain, Continuous monitoring, Information confidentiality, Transaction processing systems},
	pages = {1--18},
}

@article{debs_conflict_2017,
	title = {Conflict and {Cooperation} on {Nuclear} {Nonproliferation}},
	volume = {20},
	issn = {1094-2939, 1545-1577},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-polisci-051215-022839},
	doi = {10.1146/annurev-polisci-051215-022839},
	abstract = {This article critically reviews scholarship on the role of conﬂict and cooperation in conditioning nuclear proliferation. We start by laying out the trajectory of scholarship on the causes of proliferation, organizing it in three waves: (a) security and (b) nonsecurity drivers of proliferation, and (c) supply constraints on nuclear acquisition. We then examine the recent turn in the proliferation literature toward a strategic interaction approach, focusing on how conﬂict and cooperation between proliferators, their adversaries, and their allies shape the spread of nuclear weapons. We argue for an integrated framework for analyzing the tools states can deploy to foster or stymie proliferation. Finally, we sketch an agenda for research on nuclear proliferation. Here, we argue that scholarship should (a) incorporate nonsecurity dynamics into the strategic interaction approach to the study of proliferation and (b) combine rigorous theory with careful historical research to further our understanding of the causes of proliferation.},
	language = {en},
	number = {1},
	urldate = {2020-02-28},
	journal = {Annual Review of Political Science},
	author = {Debs, Alexandre and Monteiro, Nuno P.},
	month = may,
	year = {2017},
	pages = {331--349},
}

@techreport{ramuhalli_concepts_2019,
	title = {Concepts for {Autonomous} {Operation} of {Microreactors}},
	url = {http://www.osti.gov/servlets/purl/1615811/},
	language = {en},
	number = {ORNL/TM--2019/1305, 1615811},
	urldate = {2020-08-24},
	author = {Ramuhalli, Pradeep and Cetiner, Sacit M.},
	month = sep,
	year = {2019},
	doi = {10.2172/1615811},
	pages = {ORNL/TM--2019/1305, 1615811},
}

@article{coe_collusion_2015,
	title = {Collusion and the {Nuclear} {Nonproliferation} {Regime}},
	volume = {77},
	issn = {0022-3816, 1468-2508},
	url = {https://www.journals.uchicago.edu/doi/10.1086/682080},
	doi = {10.1086/682080},
	language = {en},
	number = {4},
	urldate = {2020-02-28},
	journal = {The Journal of Politics},
	author = {Coe, Andrew J. and Vaynman, Jane},
	month = oct,
	year = {2015},
	pages = {983--997},
}

@article{gotcheva_201510_nodate,
	title = {2015:10 {Research} {SafePhase}: {Safety} culture challenges in design, construction, installation and commissioning phases of large nuclear power projects},
	language = {en},
	author = {Gotcheva, Nadezhda and Oedewald, Pia},
	pages = {48},
}

@article{umayam_prospect_nodate,
	title = {{THE} {PROSPECT} {OF} {BLOCKCHAIN} {FOR} {STRENGTHENING} {NUCLEAR} {SECURITY}},
	abstract = {In the last few years, distributed ledger technology (widely recognized in the form of blockchain) has demonstrated practical benefits beyond the development and exchange of cryptocurrencies. Blockchain solutions are being implemented in the fields of international development, healthcare, and education, predominantly as an information-sharing platform that enables parties to interact in a trusted environment. The strength of blockchain stems from its cryptographically-secure properties: when data is recorded onto the blockchain by any user, it is automatically copied onto other connected nodes (or participants) on the chain, as opposed to storing it directly into a centralized database. Consequently, the information has “no single point of failure” in a blockchain; any changes to the information – an attempt to extract or manipulate sensitive data, for instance – will be logged. Thus, blockchain’s ability to preserve the integrity of data could potentially help enhance security measures across businesses, including the nuclear sector. For instance, blockchain technology could make it difficult for a malevolent actor to reconfigure files or install code that could linger in a computer network undetected, among other applications. This paper outlines the exploratory research the Stimson Center conducted in the Fall of 2019 – including expert interviews with blockchain developers and nuclear facility operators – to better understand the possible applications for nuclear security. The paper examines use cases that could potentially prevent or mitigate security vulnerabilities in nuclear facilities that could be exploited by cyber and insider threats. Moreover, the paper discusses potential difficulties in applying blockchain for nuclear security, and the ways in which the use of this technology could alter security considerations -- for better or worse – at the national and operational level.},
	language = {en},
	author = {Umayam, M L and Center, Stimson},
	pages = {7},
}

@article{lamport_byzantine_nodate,
	title = {The {Byzantine} {Generals} {Problem}},
	volume = {4},
	language = {en},
	number = {3},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Lamport, Leslie and Shostak, Robert and Pease, Marshall},
	pages = {20},
}

@article{yoschenko_resuspension_2006,
	title = {Resuspension and redistribution of radionuclides during grassland and forest fires in the {Chernobyl} exclusion zone: part {I}. {Fire} experiments},
	volume = {86},
	issn = {0265931X},
	shorttitle = {Resuspension and redistribution of radionuclides during grassland and forest fires in the {Chernobyl} exclusion zone},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X05002456},
	doi = {10.1016/j.jenvrad.2005.08.003},
	language = {en},
	number = {2},
	urldate = {2020-08-22},
	journal = {Journal of Environmental Radioactivity},
	author = {Yoschenko, V.I. and Kashparov, V.A. and Protsak, V.P. and Lundin, S.M. and Levchuk, S.E. and Kadygrib, A.M. and Zvarich, S.I. and Khomutinin, Yu.V. and Maloshtan, I.M. and Lanshin, V.P. and Kovtun, M.V. and Tschiersch, J.},
	month = jan,
	year = {2006},
	pages = {143--163},
}

@techreport{international_atomic_energy_agency_radioactive_2011,
	type = {{TECDOC}},
	title = {Radioactive particles in the environment: sources, particle characterization and analytical techniques.},
	shorttitle = {Radioactive particles in the environment},
	language = {en},
	number = {IAEA-TECDOC-1663},
	institution = {IAEA},
	author = {{International Atomic Energy Agency}},
	year = {2011},
	note = {OCLC: 1039222705},
}

@article{nguyen_post-cold_2016,
	title = {Post-{Cold} {War} civilian nuclear cooperation and implications for nuclear nonproliferation},
	volume = {93},
	issn = {01491970},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149197016301986},
	doi = {10.1016/j.pnucene.2016.08.019},
	language = {en},
	urldate = {2020-02-28},
	journal = {Progress in Nuclear Energy},
	author = {Nguyen, Viet Phuong and Yim, Man-Sung},
	month = nov,
	year = {2016},
	pages = {246--259},
}

@article{dolan_plutonium_2014,
	title = {Plutonium measurements with a fast-neutron multiplicity counter for nuclear safeguards applications},
	volume = {763},
	issn = {01689002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900214007359},
	doi = {10.1016/j.nima.2014.06.028},
	abstract = {Measurements were performed at the Joint Research Centre in Ispra, Italy to ﬁeld test a fast-neutron multiplicity counter developed at the University of Michigan. The measurements allowed the assessment of the system's photon discrimination abilities, efﬁciency when measuring neutron multiplicity, ability to characterize 240Pueff mass, and performance relative to a currently deployed neutron coincidence counter. This work is motivated by the need to replace and improve upon 3He neutron detection systems for nuclear safeguards applications.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Dolan, Jennifer L. and Flaska, Marek and Poitrasson-Riviere, Alexis and Enqvist, Andreas and Peerani, Paolo and Chichester, David L. and Pozzi, Sara A.},
	month = nov,
	year = {2014},
	pages = {565--574},
}

@article{runkle_neutron_2011,
	title = {Neutron sensors and their role in nuclear nonproliferation},
	volume = {652},
	issn = {01689002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900211002361},
	doi = {10.1016/j.nima.2011.01.134},
	abstract = {Perhaps the most familiar application of neutron detection technology to nonproliferation resides in materials accounting, where the quantiﬁcation of plutonium has a rich history. With a changing dynamic in nuclear security, the application of sensor technology to further other nonproliferation objectives has received considerable attention. This fact, ampliﬁed by a dwindling supply of 3He, has stimulated considerable interest in neutron detection technology development for applications ranging from interdicting smuggled nuclear material to the veriﬁcation of stockpile reductions. This manuscript brieﬂy overviews the application of neutron sensors to nonproliferation and examines three speciﬁc examples that highlight the constraints applied to ﬁeld-deployed technology.},
	language = {en},
	number = {1},
	urldate = {2020-02-28},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Runkle, Robert C.},
	month = oct,
	year = {2011},
	pages = {37--40},
}

@article{elabd_nuclear_2017,
	title = {Nuclear safeguards culture: {Roles} and responsibilities},
	volume = {110},
	issn = {03064549},
	shorttitle = {Nuclear safeguards culture},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306454916312208},
	doi = {10.1016/j.anucene.2017.08.030},
	abstract = {The nuclear and radiological regulatory body [RB] in a State is the ofﬁcial authority in that State to control nuclear materials [NMs] and other radioactive materials [RMs] and all nuclear facilities in that State. In such capacity the RB may use information about the quantity, type and characteristics of every and all NMs and RMs that may exist in nuclear and radiation facilities in the State, and the ﬂow of such materials through those facilities inside or to outside the State. Elements of nuclear safeguards culture [SGC] would not replace these technical criteria. Rather, it would be aimed to raising awareness of nuclear safeguards [SG] requirements and functions, and strengthening technical capacity of staff to meet those requirements. This study proposes a deﬁnition and the task of SGC to the attention of national and international SG communities. The roles, responsibilities of various disciplines and organizations, and the public nuclear awareness could be enforced with SGC. This would improve the effectiveness and efﬁciency of SG implementation in the State.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Annals of Nuclear Energy},
	author = {Elabd, A.A. and Elhefnawy, O.A. and Badawy, I.},
	month = dec,
	year = {2017},
	pages = {1134--1138},
}

@article{dolan_passive_2013,
	title = {Passive measurements of mixed-oxide fuel for nuclear nonproliferation},
	volume = {703},
	issn = {01689002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900212014398},
	doi = {10.1016/j.nima.2012.11.092},
	abstract = {We present new results on passive measurements and simulations of mixed-oxide fuel-pin assemblies. Potential tools for mixed-oxide fuel pin characterization are discussed for future nuclear-nonproliferation applications. Four EJ-309 liquid scintillation detectors coupled with an accurate pulse timing and digital, ofﬂine and optimized pulse-shape discrimination method were used. Measurement analysis included pulse-height distributions to distinguish between purely ﬁssion neutron sources and alpha-n plus ﬁssion neutrons sources. Time-dependent cross-correlation functions were analyzed to measure the ﬁssion neutron contribution to the measured sample’s neutron source. The use of Monte Carlo particle transport code MCNPX-PoliMi is discussed in conjunction with the measurements.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Dolan, Jennifer L. and Flaska, Marek and Pozzi, Sara A. and Chichester, David L.},
	month = mar,
	year = {2013},
	pages = {102--108},
}

@inproceedings{morozov_dual_2011,
	title = {Dual {Graph} {Error} {Propagation} {Model} for {Mechatronic} {System} {Analysis}},
	volume = {44},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667016452018},
	doi = {10.3182/20110828-6-IT-1002.03371},
	language = {en},
	urldate = {2020-12-03},
	booktitle = {{IFAC} {Proceedings} {Volumes}},
	author = {Morozov, Andrey and Janschek, Klaus},
	month = jan,
	year = {2011},
	pages = {9893--9898},
}

@techreport{noauthor_probabilistic_nodate,
	title = {Probabilistic {Risk} {Assessment} {Standard} for {Advanced} {Non}-{LWR} {Nuclear} {Power} {Plants}},
	number = {ASME/ANS RA-S-1.4-2013},
}

@misc{noauthor_rebooting-digital-solution-digitalpdf_nodate,
	title = {rebooting-digital-solution-digital.pdf},
}

@incollection{noauthor_appendix-bprobabilites_1995,
	series = {Final {Environmental} {Impact} {Statement}},
	title = {Appendix-{B}/{Probabilites} and source term methodology for inadvertent reentry during an {Earth} swingby and {Interplanetary}  cruise for the {VVEJGA} and {VEEGA} trajectories},
	url = {https://solarsystem.nasa.gov/system/downloadable_items/2622_appendb.pdf},
	language = {English},
	booktitle = {Final {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	publisher = {NASA},
	month = jun,
	year = {1995},
	pages = {31},
}

@incollection{noauthor_chapter-1final_1995,
	series = {Final {Environmental} {Impact} {Statement}},
	title = {Chapter-1/{Final} {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	url = {https://solarsystem.nasa.gov/system/downloadable_items/2613_chap1.pdf},
	language = {English},
	booktitle = {Final {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	publisher = {NASA},
	month = jun,
	year = {1995},
	pages = {10},
}

@incollection{noauthor_executive_1995,
	series = {Final {Environmental} {Impact} {Statement}},
	title = {Executive {Summary}/{Final} {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	url = {https://solarsystem.nasa.gov/system/downloadable_items/2612_feis.pdf},
	language = {English},
	booktitle = {Final {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	publisher = {NASA},
	month = jun,
	year = {1995},
	pages = {28},
}

@techreport{noauthor_appendix_1994,
	address = {Science Mission Directorate},
	title = {Appendix {B} / {Final} {Environmental} {Impact} {Statement} for the {Cassini} {Mission}},
	shorttitle = {{FEIS} {Cassini}},
	url = {https://mars.nasa.gov/mars2020/files/mep/Mars2020_Final_EIS.pdf},
	abstract = {This Final Environmental Impact Statement (FEIS) has been prepared by the National Aeronautics and Space Administration (NASA) in accordance with the National Environmental Policy Act (NEPA) of 1969, as amended, to assist in the decision-making process for the proposed Mars 2020 mission. This Environmental Impact Statement (EIS) is a tiered document (Tier 2 EIS) under NASA’s Programmatic EIS for the Mars Exploration Program.
The Proposed Action addressed in this FEIS is to continue preparations for and implementation of the Mars 2020 mission. The Mars 2020 spacecraft would be launched on an expendable launch vehicle during a launch opportunity from July through August 2020. The Mars 2020 spacecraft would deliver a large, mobile science laboratory (rover) with advanced instrumentation to a scientifically interesting location on the surface of Mars early in 2021. The design of the Mars 2020 spacecraft and rover would be based upon and similar to that used in the 2011 Mars Science Laboratory Mission, including the use of a Multi-Mission Radioisotope Thermoelectric Generator.
The purpose of the Mars 2020 mission would be to continue NASA’s in-depth exploration of Mars. The mission described by the Mars 2020 Science Definition Team Report provides a basis for the proposed Mars 2020 mission, recommending it consist of a science-focused, highly mobile rover designed to explore and investigate in detail a site on Mars that was likely once habitable. The mission concept includes new scientific instrumentation designed to seek signs of past life in situ. This instrumentation would be used to select a suite of samples that would be stored in a sealable cache that could be returned to Earth by a future mission. The mission would also demonstrate new technology for future exploration of Mars (both robotic and human missions).
This FEIS presents descriptions of the proposed Mars 2020 mission, spacecraft, and candidate launch vehicles; an overview of the affected environment at and near the launch site and globally; and the potential environmental consequences associated with the Proposed Action and Alternatives, including the No Action Alternative.},
	language = {English},
	institution = {National Aeronautics and Space Administration},
	month = sep,
	year = {1994},
	pages = {317},
}

@techreport{noauthor_final_2014,
	address = {Science Mission Directorate},
	title = {Final {Environmental} {Impact} {Statement} for the {Mars} 2020 {Mission}},
	shorttitle = {{FEIS} {Mars} 2020},
	url = {https://mars.nasa.gov/mars2020/files/mep/Mars2020_Final_EIS.pdf},
	abstract = {This Final Environmental Impact Statement (FEIS) has been prepared by the National Aeronautics and Space Administration (NASA) in accordance with the National Environmental Policy Act (NEPA) of 1969, as amended, to assist in the decision-making process for the proposed Mars 2020 mission. This Environmental Impact Statement (EIS) is a tiered document (Tier 2 EIS) under NASA’s Programmatic EIS for the Mars Exploration Program.
The Proposed Action addressed in this FEIS is to continue preparations for and implementation of the Mars 2020 mission. The Mars 2020 spacecraft would be launched on an expendable launch vehicle during a launch opportunity from July through August 2020. The Mars 2020 spacecraft would deliver a large, mobile science laboratory (rover) with advanced instrumentation to a scientifically interesting location on the surface of Mars early in 2021. The design of the Mars 2020 spacecraft and rover would be based upon and similar to that used in the 2011 Mars Science Laboratory Mission, including the use of a Multi-Mission Radioisotope Thermoelectric Generator.
The purpose of the Mars 2020 mission would be to continue NASA’s in-depth exploration of Mars. The mission described by the Mars 2020 Science Definition Team Report provides a basis for the proposed Mars 2020 mission, recommending it consist of a science-focused, highly mobile rover designed to explore and investigate in detail a site on Mars that was likely once habitable. The mission concept includes new scientific instrumentation designed to seek signs of past life in situ. This instrumentation would be used to select a suite of samples that would be stored in a sealable cache that could be returned to Earth by a future mission. The mission would also demonstrate new technology for future exploration of Mars (both robotic and human missions).
This FEIS presents descriptions of the proposed Mars 2020 mission, spacecraft, and candidate launch vehicles; an overview of the affected environment at and near the launch site and globally; and the potential environmental consequences associated with the Proposed Action and Alternatives, including the No Action Alternative.},
	language = {English},
	institution = {National Aeronautics and Space Administration},
	month = nov,
	year = {2014},
	pages = {317},
}

@techreport{noauthor_afman_2019,
	type = {Manual},
	title = {{AFMAN} 91-110/{NUCLEAR} {SAFETY} {REVIEW} {AND} {LAUNCH} {APPROVAL} {FOR} {SPACE} {OR} {MISSILE} {USE} {OF} {RADIOACTIVE} {MATERIAL} {AND} {NUCLEAR} {SYSTEMS}},
	copyright = {Public},
	shorttitle = {{AFMAN} 91-110},
	url = {https://fas.org/irp/doddir/usaf/afman91-110.pdf},
	language = {English},
	number = {91-110},
	institution = {United States Air Force},
	month = may,
	year = {2019},
	pages = {21},
}

@article{miraz_blockchain_2020,
	title = {Blockchain {Enabled} {Smart} {Contract} {Based} {Applications}: {Deficiencies} with the {Software} {Development} {Life} {Cycle} {Models}},
	shorttitle = {Blockchain {Enabled} {Smart} {Contract} {Based} {Applications}},
	url = {http://arxiv.org/abs/2001.10589},
	abstract = {With the recent popularity of Blockchain and other Distributed Ledger Technologies (DLT), blockchain enabled smart contract applications has attracted increased research focus. However, the immutability of the blocks, where the smart contracts are stored, causes conflicts with the traditional Software Development Life Cycle (SDLC) models usually followed by software engineers. This clearly shows the unsuitability of the application of SDLC in designing blockchain enabled smart contract based applications. This research article addresses this current problem by first exploring the six traditional SDLC models, clearly identifying the conflicts in a table with the application of smart contracts and advocates that there is an urgent need to develop new standard model(s) to address the arising issues. The concept of both block immutability and contract is introduced. This is further set in a historical context from legacy smart contracts and blockchain enabled smart contracts extending to the difference between "shallow smart contracts" and "deep smart contracts". To conclude, the traditional SDLC models are unsuitable for blockchain enabled smart contract-based applications.},
	urldate = {2020-12-01},
	journal = {arXiv:2001.10589 [cs]},
	author = {Miraz, Mahdi H. and Ali, Maaruf},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.10589},
	keywords = {Computer Science - Computers and Society, Computer Science - Networking and Internet Architecture, Computer Science - Software Engineering},
}

@article{elisa_consortium_2020,
	title = {Consortium {Blockchain} for {Security} and {Privacy}-{Preserving} in {E}-government {Systems}},
	url = {http://arxiv.org/abs/2006.14234},
	abstract = {Since its inception as a solution for secure cryptocurrencies sharing in 2008, the blockchain technology has now become one of the core technologies for secure data sharing and storage over trustless and decentralised peer-to-peer systems. E-government is amongst the systems that stores sensitive information about citizens, businesses and other affiliates, and therefore becomes the target of cyber attackers. The existing e-government systems are centralised and thus subject to single point of failure. This paper proposes a secure and decentralised e-government system based on the consortium blockchain technology, which is a semi-public and decentralised blockchain system consisting of a group of pre-selected entities or organisations in charge of consensus and decisions making for the benefit of the whole network of peers. In addition, a number of e-government nodes are pre-selected to perform the tasks of user and transaction validation before being added to the blockchain network. Accordingly, e-government users of the consortium blockchain network are given the rights to create, submit, access, and review transactions. Performance evaluation on single transaction time and transactions processed per second demonstrate the practicability of the proposed consortium blockchain-based e-government system for secure information sharing amongst all stakeholders.},
	urldate = {2020-12-01},
	journal = {arXiv:2006.14234 [cs]},
	author = {Elisa, Noe and Yang, Longzhi and Li, Honglei and Chao, Fei and Naik, Nitin},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.14234},
	keywords = {Computer Science - Cryptography and Security},
}

@inproceedings{bellare_multi-signatures_2006,
	address = {Alexandria, Virginia, USA},
	title = {Multi-signatures in the plain public-{Key} model and a general forking lemma},
	isbn = {978-1-59593-518-2},
	url = {http://dl.acm.org/citation.cfm?doid=1180405.1180453},
	doi = {10.1145/1180405.1180453},
	abstract = {A multi-signature scheme enables a group of signers to produce a compact, joint signature on a common document, and has many potential uses. However, existing schemes impose key setup or PKI requirements that make them impractical, such as requiring a dedicated, distributed key generation protocol amongst potential signers, or assuming strong, concurrent zero-knowledge proofs of knowledge of secret keys done to the CA at key registration. These requirements limit the use of the schemes. We provide a new scheme that is proven secure in the plain public-key model, meaning requires nothing more than that each signer has a (certiﬁed) public key. Furthermore, the important simpliﬁcation in key management achieved is not at the cost of eﬃciency or assurance: our scheme matches or surpasses known ones in terms of signing time, veriﬁcation time and signature size, and is proven secure in the random-oracle model under a standard (not bilinear map related) assumption. The proof is based on a simpliﬁed and general Forking Lemma that may be of independent interest.},
	language = {en},
	urldate = {2020-12-01},
	booktitle = {Proceedings of the 13th {ACM} conference on {Computer} and communications security  - {CCS} '06},
	publisher = {ACM Press},
	author = {Bellare, Mihir and Neven, Gregory},
	year = {2006},
	pages = {390--399},
}

@article{poon_bitcoin_nodate,
	title = {The {Bitcoin} {Lightning} {Network}:},
	abstract = {The bitcoin protocol can encompass the global ﬁnancial transaction volume in all electronic payment systems today, without a single custodial third party holding funds or requiring participants to have anything more than a computer using a broadband connection. A decentralized system is proposed whereby transactions are sent over a network of micropayment channels (a.k.a. payment channels or transaction channels) whose transfer of value occurs oﬀ-blockchain. If Bitcoin transactions can be signed with a new sighash type that addresses malleability, these transfers may occur between untrusted parties along the transfer route by contracts which, in the event of uncooperative or hostile participants, are enforceable via broadcast over the bitcoin blockchain in the event of uncooperative or hostile participants, through a series of decrementing timelocks.},
	language = {en},
	author = {Poon, Joseph and Dryja, Thaddeus},
	pages = {59},
}

@article{zheng_overview_2020,
	title = {An {Overview} on {Smart} {Contracts}: {Challenges}, {Advances} and {Platforms}},
	volume = {105},
	issn = {0167739X},
	shorttitle = {An {Overview} on {Smart} {Contracts}},
	url = {http://arxiv.org/abs/1912.10370},
	doi = {10.1016/j.future.2019.12.019},
	abstract = {Smart contract technology is reshaping conventional industry and business processes. Being embedded in blockchains, smart contracts enable the contractual terms of an agreement to be enforced automatically without the intervention of a trusted third party. As a result, smart contracts can cut down administration and save services costs, improve the efficiency of business processes and reduce the risks. Although smart contracts are promising to drive the new wave of innovation in business processes, there are a number of challenges to be tackled.This paper presents a survey on smart contracts. We first introduce blockchains and smart contracts. We then present the challenges in smart contracts as well as recent technical advances. We also compare typical smart contract platforms and give a categorization of smart contract applications along with some representative examples.},
	urldate = {2020-12-01},
	journal = {Future Generation Computer Systems},
	author = {Zheng, Zibin and Xie, Shaoan and Dai, Hong-Ning and Chen, Weili and Chen, Xiangping and Weng, Jian and Imran, Muhammad},
	month = apr,
	year = {2020},
	note = {arXiv: 1912.10370},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Software Engineering},
	pages = {475--491},
}

@article{boudot_fair_2001,
	series = {Coding and {Cryptology}},
	title = {A fair and efficient solution to the socialist millionaires’ problem},
	volume = {111},
	issn = {0166-218X},
	url = {http://www.sciencedirect.com/science/article/pii/S0166218X00003425},
	doi = {10.1016/S0166-218X(00)00342-5},
	abstract = {We present a solution to the Tiercé problem, in which two players want to know whether they have backed the same combination (but neither player wants to disclose its combination to the other one). The problem is also known as the socialist millionaires’ problem, in which two millionaires want to know whether they happen to be equally rich. In our solution, both players will be convinced of the correctness of the equality test between their combinations and will get no additional information on the other player's combination. Our solution is fair: one party cannot get the result of the comparison while preventing the other one from getting it. The protocol requires O(k) exponentiations only, where k is a security parameter.},
	language = {en},
	number = {1},
	urldate = {2020-12-01},
	journal = {Discrete Applied Mathematics},
	author = {Boudot, Fabrice and Schoenmakers, Berry and Traoré, Jacques},
	month = jul,
	year = {2001},
	pages = {23--36},
}

@inproceedings{zhang_protecting_2019,
	title = {Protecting {Data} {Privacy} for {Permissioned} {Blockchains} using {Identity}-{Based} {Encryption}},
	doi = {10.1109/ITNEC.2019.8729244},
	abstract = {Blockchain is an emerging decentralized architecture and distributed public ledger technology underlying Bitcoin, and has recently attracted intensive attention from governments, financial institutions and high-tech enterprises. It is believed that blockchain can improve efficiency, reduce costs and enhance data security, but it is still in the face of serious privacy issues which may hinder the wide application of blockchain. In this paper, We present a practical scheme by adding the Identity-Based encryption system, which effectively improves the data privacy for non-transaction applications. Analyses show that our proposal has a high security level which can prevent both disguise and passive attacks, and is functional, effective and practical in many applications for non-transactional scenarios.},
	booktitle = {2019 {IEEE} 3rd {Information} {Technology}, {Networking}, {Electronic} and {Automation} {Control} {Conference} ({ITNEC})},
	author = {Zhang, M. and Wang, S. and Zhang, P. and He, L. and Li, X. and Zhou, S.},
	month = mar,
	year = {2019},
	keywords = {Bilinear Map, Blockchain, Data privacy, Encryption, Identity-Based Encryption, Identity-based encryption, Permissioned Blockchain, Privacy, Privacy Protection, cryptocurrencies, data privacy, distributed databases, distributed public ledger technology, high security level, identity-based encryption system, nontransaction applications, permissioned blockchains},
	pages = {602--605},
}

@misc{noauthor_ethereum_nodate,
	title = {Ethereum {Whitepaper}},
	url = {https://ethereum.org},
	abstract = {An introductory paper to Ethereum, published in 2013 before its launch.},
	language = {en},
	urldate = {2020-12-01},
	journal = {ethereum.org},
}

@techreport{bowe_recursive_2019,
	title = {Recursive {Proof} {Composition} without a {Trusted} {Setup}},
	url = {http://eprint.iacr.org/2019/1021},
	abstract = {Non-interactive arguments of knowledge are powerful cryptographic tools that can be used to demonstrate the faithful execution of arbitrary computations with publicly verifiable proofs. Increasingly efficient protocols have been described in recent years, with verification time and/or communication complexity that is sublinear in the size of the computation being described. These efficiencies can be exploited to realize recursive proof composition: the concept of proofs that attest to the correctness of other instances of themselves, thereby allowing large computational effort to be incrementally verified. All previously known realizations of recursive proof composition have required a trusted setup and cycles of expensive pairing-friendly elliptic curves. We obtain and implement Halo, the first practical example of recursive proof composition without a trusted setup, using the discrete log assumption over normal cycles of elliptic curves. In the process we develop several novel techniques that may be of independent interest.},
	number = {1021},
	urldate = {2020-11-28},
	author = {Bowe, Sean and Grigg, Jack and Hopwood, Daira},
	year = {2019},
	keywords = {cryptographic protocols, incrementally verifiable computation, recursive proofs, zero knowledge},
}

@article{morais_survey_2019,
	title = {A survey on zero knowledge range proofs and applications},
	volume = {1},
	issn = {2523-3971},
	url = {https://doi.org/10.1007/s42452-019-0989-z},
	doi = {10.1007/s42452-019-0989-z},
	abstract = {In last years, there has been an increasing effort to leverage distributed ledger technology (DLT), including blockchain. One of the main topics of interest, given its importance, is the research and development of privacy mechanisms, as for example is the case of zero knowledge proofs (ZKP). ZKP is a cryptographic technique that can be used to hide information that is put into the ledger, while still allowing to perform validation of this data. In this work we describe different strategies to construct zero knowledge range proofs (ZKRP), as for example the scheme proposed by Boudot (in: Bart (ed) Advances in cryptology—EUROCRYPT 2000, Springer, Berlin, 2000) in 2001; the one proposed by Camenisch et al. (in: Josef (ed) Advances in cryptology—ASIACRYPT 2008, Springer, Berlin, 2008), and bulletproofs (Bünz et al., in: 2018 IEEE symposium on security and privacy (SP), 2018), proposed in 2017. We also compare these strategies and discuss possible use cases. Since bulletproofs (Bünz et al. 2018) is the most efficient construction, we will give a detailed description of its algorithms and optimizations. Bulletproofs is not only more efficient than previous schemes, but also avoids the trusted setup, which is a requirement that is not desirable in the context of DLT and blockchain. In case of cryptocurrencies, if the setup phase is compromised, it would be possible to generate money out of thin air. Interestingly, bulletproofs can also be used to construct generic ZKP, in the sense that it can be used to prove generic statements, and thus it is not only restricted to ZKRP, but it can be used for any kind of proof of knowledge. Hence Bulletproofs leads to a more powerful tool to provide privacy for DLT. Here we describe in detail the algorithms involved in Bulletproofs protocol for ZKRP. Also, we present our implementation, which was open sourced (Morais et al., in: Zero knowledge range proof implementation, 2018. https://github.com/ing-bank/zkrangeproof).},
	language = {en},
	number = {8},
	urldate = {2020-11-28},
	journal = {SN Applied Sciences},
	author = {Morais, Eduardo and Koens, Tommy and van Wijk, Cees and Koren, Aleksei},
	month = jul,
	year = {2019},
	pages = {946},
}

@misc{noauthor_introduction_nodate,
	title = {Introduction — hyperledger-fabricdocs master documentation},
	url = {https://hyperledger-fabric.readthedocs.io/en/latest/blockchain.html},
	urldate = {2020-12-01},
}

@misc{noauthor_bitcoin_nodate,
	title = {Bitcoin and {Cryptocurrency} {Technologies}},
	url = {https://bitcoinbook.cs.princeton.edu/},
	urldate = {2020-12-01},
}

@article{slepak_dcs_2018,
	title = {The {DCS} {Theorem}},
	url = {http://arxiv.org/abs/1801.04335},
	abstract = {Blockchain design involves many tradeoffs, and much debate has focused on tradeoffs related to scaling parameters such as blocksize. To address some of the confusion around this subject, we present a probability proof of the DCS Triangle. We use the triangle to show decentralized consensus systems, like blockchains, can have Decentralization, Consensus, or Scale, but not all three properties simultaneously. We then describe two methods for getting around the limitations suggested by the triangle.},
	urldate = {2020-12-01},
	journal = {arXiv:1801.04335 [cs]},
	author = {Slepak, Greg and Petrova, Anya},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04335},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{gershuni_blockchain_2018,
	title = {Blockchain scaling with layer 2: theory and practice},
	shorttitle = {Blockchain scaling with layer 2},
	abstract = {Scalability, speed and throughput is an inherent problem for any public blockchain. This article examines some of the existing solutions of Second Layer approach to blockchain scaling.},
	author = {Gershuni, Stepan},
	month = dec,
	year = {2018},
}

@techreport{gudgeon_sok_2019,
	title = {{SoK}: {Layer}-{Two} {Blockchain} {Protocols}},
	shorttitle = {{SoK}},
	url = {http://eprint.iacr.org/2019/360},
	abstract = {Blockchains have the potential to revolutionize markets and services. However, they currently exhibit high latencies and fail to handle transaction loads comparable to those managed by traditional financial systems. Layer-two protocols, built on top of layer-one blockchains, avoid disseminating every transaction to the whole network by exchanging authenticated transactions off-chain. Instead, they utilize the expensive and low-rate blockchain only as a recourse for disputes. The promise of layer-two protocols is to complete off-chain transactions in sub-seconds rather than minutes or hours while retaining asset security, reducing fees and allowing blockchains to scale.



We systematize the evolution of layer-two protocols over the period from the inception of cryptocurrencies in 2009 until today, structuring the multifaceted body of research on layer-two transactions. Categorizing the research into payment and state channels, commit-chains and protocols for refereed delegation, we provide a comparison of the protocols and their properties. We provide a systematization of the associated synchronization and routing protocols along with their privacy and security aspects. This Systematization of Knowledge (SoK) clears the layer-two fog, highlights the potential of layer-two solutions and identifies their unsolved challenges, indicating propitious avenues of future work.},
	number = {360},
	urldate = {2020-12-01},
	author = {Gudgeon, Lewis and Moreno-Sanchez, Pedro and Roos, Stefanie and McCorry, Patrick and Gervais, Arthur},
	year = {2019},
	keywords = {applications, blockchain, commit-chains, payment channels, sok, state channels},
}

@article{back_enabling_nodate,
	title = {Enabling {Blockchain} {Innovations} with {Pegged} {Sidechains}},
	abstract = {Since the introduction of Bitcoin[Nak09] in 2009, and the multiple computer science and electronic cash innovations it brought, there has been great interest in the potential of decentralised cryptocurrencies. At the same time, implementation changes to the consensuscritical parts of Bitcoin must necessarily be handled very conservatively. As a result, Bitcoin has greater difﬁculty than other Internet protocols in adapting to new demands and accommodating new innovation.},
	language = {en},
	author = {Back, Adam and Corallo, Matt and Dashjr, Luke and Friedenbach, Mark and Maxwell, Gregory and Miller, Andrew and Poelstra, Andrew and Timón, Jorge and Wuille, Pieter},
	pages = {25},
}

@article{sarkar_quality_nodate,
	title = {Quality {Assurance} in {Blockchain}},
	language = {en},
	author = {Sarkar, Arpan and Mazumder, Jibendu Narayan},
	pages = {22},
}

@techreport{kiayias_proof--work_2018,
	title = {Proof-of-{Work} {Sidechains}},
	url = {http://eprint.iacr.org/2018/1048},
	abstract = {During the last decade, the blockchain space has exploded with a plethora of new cryptocurrencies, covering a wide array of different features, performance and security characteristics. Nevertheless, each of these coins functions in a stand-alone manner, independently. Sidechains have been envisioned as a mechanism to allow blockchains to communicate with one another and, among other applications, allow the transfer of value from one chain to another, but so far there have been no decentralized constructions. In this paper, we put forth the first sidechains construction that allows communication between proof-of-work blockchains without trusted intermediaries. Our construction is generic in that it allows the passing of any information between blockchains. It gives rise to two illustrative examples: the ``remote ICO,'' in which an investor pays in currency on one blockchain to receive tokens in another, and the ``two-way peg,'' in which an asset can be transferred from one chain to another and back. We pinpoint the features needed for two chains to communicate: On the source side, a proof-of-work blockchain that has been interlinked, potentially with a velvet fork; on the destination side, a blockchain with any consensus mechanism that has sufficient expressibility to implement verification. We model our construction mathematically and give a formal proof of security. In the heart of our construction, we use a recently introduced cryptographic primitive, Non-Interactive Proofs of Proof-of-Work (NIPoPoWs). Our security proof uses a standard reduction from our new proof-of-work sidechains protocol to the security of NIPoPoWs, which has, in turn, been shown to be secure in previous work. Our working assumption is honest majority in each of the communicating chains. We demonstrate the feasibility of our construction by providing a pseudocode implementation in the form of a Solidity smart contract.},
	number = {1048},
	urldate = {2020-12-01},
	author = {Kiayias, Aggelos and Zindros, Dionysis},
	year = {2018},
	keywords = {blockchain sidechains nipopows, cryptographic protocols},
}

@article{johnson_sidechains_2019,
	title = {Sidechains and interoperability},
	url = {http://arxiv.org/abs/1903.04077},
	abstract = {There appears to be an insatiable desire for spawning new bespoke blockchains to harness the functionality provided by blockchain technologies, resulting in a constant stream of blockchain start-up companies entering the market with their own unique vision and mission. Some target a particular niche market such as supply chain and financial services, while others strive to differentiate themselves from the increasingly saturated market by offering new functionality. This dynamic and constantly changing blockchain ecosystem makes it very challenging to keep abreast of all the latest breakthroughs and research. It is evident that there is also a growing desire to collaborate with others developing blockchain solutions, which brings new impetus to blockchain interoperability research. We review the strategies that some key players in the blockchain ecosystem have implemented, or are proposing to develop, to satisfy this increasing demand for cross-chain communication and transactions between sidechains. Interoperability presents a complex and challenging stumbling block to the wider uptake of blockchain technology. We find that although there is a plethora of blockchains and interoperability implementations, or proposals, at a higher level of abstraction there is only a handful of approaches. However, the way they are implemented can differ quite substantially. We present a summary of the reviews we conducted in a table for ease of comparing and contrasting.},
	urldate = {2020-12-01},
	journal = {arXiv:1903.04077 [cs]},
	author = {Johnson, Sandra and Robinson, Peter and Brainard, John},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.04077},
	keywords = {Computer Science - Cryptography and Security},
}

@article{joshi_survey_2018,
	title = {A survey on security and privacy issues of blockchain technology},
	volume = {1},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.aimsciences.org/article/doi/10.3934/mfc.2018007},
	doi = {10.3934/mfc.2018007},
	abstract = {{\textless}p style='text-indent:20px;'{\textgreater}Blockchain is gaining traction and can be termed as one of the furthermost prevalent topics nowadays. Although critics question about its scalability, security, and sustainability, it has already transformed many individuals' lifestyle in some areas due to its inordinate influence on industries and businesses. Granting that the features of blockchain technology guarantee more reliable and expedient services, it is important to consider the security and privacy issues and challenges behind the innovative technology. The spectrum of blockchain applications range from financial, healthcare, automobile, risk management, Internet of things (IoT) to public and social services. Several studies focus on utilizing the blockchain data structure in various applications. However, a comprehensive survey on technical and applications perspective has not yet been accomplished. In this paper, we try to conduct a comprehensive survey on the blockchain technology by discussing its structure to different consensus algorithms as well as the challenges and opportunities from the prospective of security and privacy of data in blockchains. Furthermore, we delve into future trends the blockchain technology can adapt in the years to come.{\textless}/p{\textgreater}{\textless}p style='text-indent:20px;'{\textgreater}\textit{Index Terms-} Blockchains, Future Trends of Blockchains, Security, Privacy{\textless}/p{\textgreater}},
	language = {en},
	number = {2},
	urldate = {2020-12-01},
	journal = {Mathematical Foundations of Computing},
	author = {Joshi, Archana Prashanth and Han, Meng and Wang, Yan},
	year = {2018},
	note = {Company: Mathematical Foundations of Computing
Distributor: Mathematical Foundations of Computing
Institution: Mathematical Foundations of Computing
Label: Mathematical Foundations of Computing
Publisher: American Institute of Mathematical Sciences},
	pages = {121},
}

@techreport{noauthor_performance_2017,
	type = {Technical {Report}},
	title = {Performance of {PRA} {Peer} {Reviews} {Using} the {ASME}/{ANS} {PRA} {Standard}},
	url = {https://www.nrc.gov/docs/ML1734/ML17341A548.pdf},
	number = {NEI 17-07},
	urldate = {2020-11-30},
	institution = {Nuclear Energy Institute},
	year = {2017},
}

@incollection{aldemir_dynamic_2018,
	title = {Dynamic {Flowgraph} {Methodology} ({DFM}) {Modeling} of {Nuclear} and {Advanced} {Technology} {System} {Risk} and {Reliability} {Scenarios}},
	volume = {1},
	isbn = {978-981-322-560-2 978-981-322-561-9},
	url = {https://www.worldscientific.com/doi/abs/10.1142/9789813225619_0011},
	language = {en},
	urldate = {2020-11-30},
	booktitle = {Modern {Nuclear} {Energy} {Analysis} {Methods}},
	publisher = {WORLD SCIENTIFIC},
	author = {Guarro, Sergio and Yau, Michael},
	collaborator = {Aldemir, Tunc},
	month = jun,
	year = {2018},
	doi = {10.1142/9789813225619_0011},
	pages = {353--425},
}

@book{aldemir_advanced_2018,
	title = {Advanced concepts in nuclear energy risk assessment and management},
	isbn = {978-981-322-561-9 978-981-322-562-6},
	url = {https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=1803626},
	abstract = {"Over the past 30 years, numerous concerns have been raised in the literature regarding the capability of static modeling approaches such as the event-tree (ET)/fault-tree (FT) methodology to adequately account for the impact of process/hardware/software/firmware/human interactions on nuclear power plant safety assessment, and methodologies to augment the ET/FT approach have been proposed. Often referred to as dynamic probabilistic risk/safety assessment (DPRA/DPSA) methodologies, which use a time-dependent phenomenological model of system evolution along with a model of its stochastic behavior to model for possible dependencies among failure events. The book contains a collection of papers that describe at existing plant level applicable DPRA/DPSA tools, as well as techniques that can be used to augment the ET/FT approach when needed."--Publisher's website.},
	language = {English},
	urldate = {2020-11-30},
	author = {Aldemir, Tunc},
	year = {2018},
	note = {OCLC: 1034562184},
}

@techreport{noauthor_summary_nodate,
	title = {Summary of the {Nuclear} {Risk} {Assessment} for the {Mars} 2020 {Mission} {Environmental} {Impact} {Statement}},
}

@techreport{clayton_nuclear_2019,
	title = {Nuclear {Risk} {Assessment} 2019 {Update} for the {Mars} 2020 {Mission} {Environmental} {Impact} {Statement}.},
	url = {http://www.osti.gov/servlets/purl/1569349/},
	language = {en},
	number = {SAND2019-11148, 1569349},
	urldate = {2020-11-30},
	author = {Clayton, Daniel James and Wilkes, John and Starr, Michael J. and Ehrhart, Brian David and Mendoza, Hector and Ricks, Allen Joseph and Villa, Daniel and Potter, Donald L. and Dinzl, Derek John and Fulton, John and {Clayton, Joe Mark,} and Cochran, Lainy Dromgoole and Brooks, Dusty Marie},
	month = sep,
	year = {2019},
	doi = {10.2172/1569349},
	pages = {SAND2019--11148, 1569349},
}

@techreport{clayton_nuclear_2014,
	title = {Nuclear risk assessment for the {Mars} 2020 mission environmental impact statement.},
	url = {http://www.osti.gov/servlets/purl/1160266/},
	language = {en},
	number = {SAND2013-10589, 1160266},
	urldate = {2020-11-30},
	author = {Clayton, Daniel James and Bignell, John L. and Jones, Christopher Andrew and Rohe, Daniel Peter and Flores, Gregg J. and Bartel, Timothy James and Gelbard, Fred and Le, San and Morrow, Charles. and Potter, Donald L. and Young, Larry W. and Bixler, Nathan E. and Lipinski, Ronald J.},
	month = jan,
	year = {2014},
	doi = {10.2172/1160266},
	pages = {SAND2013--10589, 1160266},
}

@article{guarro_cassini_1995,
	title = {The {Cassini} mission risk assessment framework and application techniques},
	volume = {49},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/095183209500065A},
	doi = {10.1016/0951-8320(95)00065-A},
	language = {en},
	number = {3},
	urldate = {2020-11-30},
	journal = {Reliability Engineering \& System Safety},
	author = {Guarro, Sergio and Bream, Bruce and Rudolph, L.Kevin and Mulvihill, Robert J.},
	month = jan,
	year = {1995},
	pages = {293--302},
}

@article{noauthor_ngnp_nodate,
	title = {{NGNP} and {Hydrogen} {Production} {Conceptual} {Design} {Study} {Reactor} {Building} {Functional} and {Technical} {Requirements} and {Evaluation} of {Reactor} {Embedment}},
}

@article{mcgrayne_theory_nodate,
	title = {Theory {That} {Would} {Not} {Die}},
	abstract = {Bayes’ rule appears to be a straightforward, one-line theorem: by updating our initial beliefs with objective new information, we get a new and improved belief. To its adherents, it is an elegant statement about learning from experience. To its opponents, it is subjectivity run amok. In the ﬁrst-ever account of Bayes’ rule for general readers, Sharon Bertsch McGrayne explores this controversial theorem and the human obsessions surrounding it. She traces its discovery by an amateur mathematician in the 1740s through its development into roughly its modern form by French scientist Pierre Simon Laplace. She reveals why respected statisticians rendered it professionally taboo for 150 years—at the same time that practitioners relied on it to solve crises involving great uncertainty and scanty information, even breaking Germany’s Enigma code during World War II, and explains how the advent of off-the-shelf computer technology in the 1980s proved to be a game-changer. Today, Bayes’ rule is used everywhere from DNA de-coding to Homeland Security. Drawing on primary source material and interviews with statisticians and other scientists, The Theory That Would Not Die is the riveting account of how a seemingly simple theorem ignited one of the greatest controversies of all time”—Provided by publisher. Includes bibliographical references and index. ISBN 978-0-300-16969-0 (hardback) 1. Bayesian statistical decision theory—History. I. Title.},
	language = {en},
	author = {McGrayne, Sharon Bertsch},
	pages = {335},
}

@techreport{noauthor_nureg_nodate,
	title = {Nureg xxx},
	url = {https://www.nrc.gov/docs/ML0713/ML071340012.pdf},
	urldate = {2020-11-06},
}

@article{noauthor_epas_nodate,
	title = {{EPA}'s {Guide} for {Industrial} {Waste} {Management}:  {Introduction}},
	language = {en},
	pages = {478},
}

@misc{noauthor_three_nodate,
	title = {Three {Mile} {Island} {\textbar} {TMI} 2 {\textbar}{Three} {Mile} {Island} {Accident}. - {World} {Nuclear} {Association}},
	url = {https://www.world-nuclear.org/information-library/safety-and-security/safety-of-plants/three-mile-island-accident.aspx},
	urldate = {2020-11-04},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC}: {Backgrounder} on the {Three} {Mile} {Island} {Accident}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/fact-sheets/3mile-isle.html},
	urldate = {2020-11-04},
}

@book{nancy_leveson_stpa_2018,
	title = {{STPA} {Handbook}},
	url = {https://psas.scripts.mit.edu/home/get_file.php?name=STPA_handbook.pdf},
	author = {{Nancy Leveson} and {Thomas, John}},
	month = mar,
	year = {2018},
}

@misc{nancy_g_leveson_stpa_2013,
	title = {An {STPA} {Primer}},
	language = {English},
	author = {{Nancy G. Leveson}},
	month = aug,
	year = {2013},
	keywords = {STPA},
}

@book{nancy_g_leveson_engineering_nodate,
	series = {Engineering {Systems}},
	title = {Engineering a {Safer} {World}: {Systems} {Thinking} {Applied} to {Safety} ({Engineering} {Systems})},
	isbn = {0-262-01662-1},
	abstract = {Engineering has experienced a technological revolution, but the basic engineering techniques applied in safety and reliability engineering, created in a simpler, analog world, have changed very little over the years. In this groundbreaking book, Nancy Leveson proposes a new approach to safety--more suited to today's complex, sociotechnical, software-intensive world--based on modern systems thinking and systems theory. Revisiting and updating ideas pioneered by 1950s aerospace engineers in their System Safety concept, and testing her new model extensively on real-world examples, Leveson has created a new approach to safety that is more effective, less expensive, and easier to use than current techniques. Arguing that traditional models of causality are inadequate, Leveson presents a new, extended model of causation (Systems-Theoretic Accident Model and Processes, or STAMP), then then shows how the new model can be used to create techniques for system safety engineering, including accident analysis, hazard analysis, system design, safety in operations, and management of safety-critical systems. She applies the new techniques to real-world events including the friendly-fire loss of a U.S. Blackhawk helicopter in the first Gulf War; the Vioxx recall; the U.S. Navy SUBSAFE program; and the bacterial contamination of a public water supply in a Canadian town. Leveson's approach is relevant even beyond safety engineering, offering techniques for "reengineering" any large sociotechnical system to improve safety and manage risk.},
	language = {English},
	publisher = {The MIT Press},
	author = {{Nancy G. Leveson}},
	keywords = {STPA},
}

@article{mehralian_developing_2012,
	title = {Developing a {Suitable} {Model} for {Supplier} {Selection} {Based} on {Supply} {Chain} {Risks}: {An} {Empirical} {Study} from {Iranian} {Pharmaceutical} {Companies}},
	volume = {11},
	issn = {1735-0328},
	shorttitle = {Developing a {Suitable} {Model} for {Supplier} {Selection} {Based} on {Supply} {Chain} {Risks}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3813095/},
	abstract = {The supply chain represents the critical link between the development of new product and the market in pharmaceutical industry. Over the years, improvements made in supply chain operations have focused largely on ways to reduce cost and gain efficiencies in scale. In addition, powerful regulatory and market forces have provided new incentives for pharmaceutical firms to basically rethink the way they produce and distribute products, and also to re-imagine the role of the supply chain in driving strategic growth, brand differentiation and economic value in the health continuum. The purpose of this paper is to formulate basic factors involved in risk analysis of pharmaceutical industry, and also determine the effective factors involved in suppliers selection and their priorities. This paper is based on the results of literature review, experts’ opinion acquisition, statistical analysis and also using MADM models on data gathered from distributed questionnaires. The model consists of the following steps and components: first factors involved in to supply chain risks are determined. Based on them a framework is considered. According the result of statistical analysis and MADM models the risk factors are formulated. The paper determines the main components and influenceial factors involving in the supply chain risks. Results showed that delivery risk can make an important contribution to mitigate the risk of pharmaceutical industry.},
	number = {1},
	urldate = {2020-10-30},
	journal = {Iranian Journal of Pharmaceutical Research : IJPR},
	author = {Mehralian, Gholamhossein and Rajabzadeh Gatari, Ali and Morakabati, Mohadese and Vatanpour, Hossein},
	year = {2012},
	pmid = {24250442},
	pmcid = {PMC3813095},
	pages = {209--219},
}

@article{breen_preliminary_2008,
	title = {A {Preliminary} {Examination} of {Risk} in the {Pharmaceutical} {Supply} {Chain} ({PSC}) in the {National} {Health} {Service} ({NHS})},
	volume = {01},
	issn = {1940-9893, 1940-9907},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jssm.2008.12020},
	doi = {10.4236/jssm.2008.12020},
	abstract = {The effective management of pharmaceuticals in the National Health Service (NHS) is critical to patient welfare thus any risks attached to this must be identified and controlled. At a very basic level, risks in the pharmaceutical supply chain are associated with product discontinuity, product shortages, poor performance, patient safety/dispensing errors, and technological errors (causing stock shortages in pharmacies) to name but a few, all of which incur risk through disruption to the system. Current indications suggest that the pharmaceutical industry and NHS practitioners alike have their concerns as to the use of generic supply chain strategies in association with what is perceived to be a specialist product (pharmaceuticals).},
	language = {en},
	number = {02},
	urldate = {2020-10-30},
	journal = {Journal of Service Science and Management},
	author = {Breen, Liz},
	year = {2008},
	pages = {193--199},
}

@article{shah_pharmaceutical_2004,
	title = {Pharmaceutical supply chains: key issues and strategies for optimisation},
	volume = {28},
	issn = {00981354},
	shorttitle = {Pharmaceutical supply chains},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0098135403002333},
	doi = {10.1016/j.compchemeng.2003.09.022},
	abstract = {Supply chain optimisation is now a major research theme in process operations and management. A great deal of research has been undertaken on facility location and design, inventory and distribution planning, capacity and production planning and detailed scheduling. Only a small proportion of this work directly addresses the issues faced in the pharmaceutical sector. On the other hand, this sector is very much ready for and in need of sophisticated supply chain optimisation techniques.},
	language = {en},
	number = {6-7},
	urldate = {2020-10-30},
	journal = {Computers \& Chemical Engineering},
	author = {Shah, Nilay},
	month = jun,
	year = {2004},
	pages = {929--941},
}

@article{enyinda_empirical_2010,
	title = {An empirical analysis of risk mitigation in the pharmaceutical industry supply chain: {A} developing-country perspective},
	volume = {52},
	issn = {10964762, 15206874},
	shorttitle = {An empirical analysis of risk mitigation in the pharmaceutical industry supply chain},
	url = {http://doi.wiley.com/10.1002/tie.20309},
	doi = {10.1002/tie.20309},
	language = {en},
	number = {1},
	urldate = {2020-10-30},
	journal = {Thunderbird International Business Review},
	author = {Enyinda, Chris I. and Mbah, Chris H. N. and Ogbuehi, Alphonso},
	month = jan,
	year = {2010},
	pages = {45--54},
}

@article{kirrmann_fault-tolerant_2020,
	title = {Fault-{Tolerant} {Computers} in {Industrial} {Process} {Control}},
	author = {Kirrmann, Hubert},
	month = oct,
	year = {2020},
}

@misc{noauthor_wayback_2014,
	title = {Wayback {Machine}},
	url = {https://web.archive.org/web/20140326192930/http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94#page=94},
	urldate = {2020-10-28},
	month = mar,
	year = {2014},
}

@book{lamarsh_introduction_nodate,
	title = {Introduction to {Nuclear} {Engineering}},
	isbn = {0-201-82498-1},
	abstract = {This revision is derived from personal experiences in teaching introductory and
advanced level nuclear engineering courses at the undergraduate level. In keeping
with the original intent of John Lamarsh, every attempt is made to retain his style
and approach to nuclear engineering education. Since the last edition, however,
considerable changes have occurred in the industry. The changes include the development of advanced plant designs, the significant scale-back in plant construction,
the extensive use of high speed computers, and the opening of the former Eastern
Block countries and of the Soviet Union. From a pedagogical view, the World Wide
Web allows access to many resources formerly only available in libraries. Attempts
are made to include some of these resources in this edition.
In an attempt to update the text to include these technologies and to make
the text useful for the study of non-western design reactors, extensive changes are
made to Chapter 4, Nuclear Reactors and Nuclear Power. The chapter is revised to
include a discussion of Soviet-design reactors and technology. The use, projection,
and cost of nuclear power worldwide is updated to the latest available information.
In Chapter 11, Reactor Licensing and Safety, the Chemobyl accident is discussed along with the latest reactor safety study, NUREG 1150. A section is also
included that describes non-power nuclear accidents such as Tokai-Mura.
n
The basic material in Chapters2-7 is updated to include newer references and
to reflect the author's experience in teaching nuclear engineering.
Throughout the text, the references are updated were possible to include more
recent publications. In many topic areas, references to books that are dated and
often out of print had to be retained, since there are no newer ones available. Since
these books are usually available in college libraries, they should be available to
most readers.
Chapter 9 is retained in much its same form but is updated to include a more
complete discussion of the SI system of units and of changes in philosophy that
have occurred in radiation protection. Since many of these changes have yet to
reach general usage, however, the older discussions are still included.
As in the second edition, several errors were corrected and undoubtedly new
ones introduced. Gremlins never sleep !},
	publisher = {Prentice Hall PTR},
	author = {Lamarsh, John R. and Anthony J., Baratta},
}

@article{wadoud_physical_2018,
	title = {Physical protection evaluation process for nuclear facility via sabotage scenarios},
	volume = {57},
	issn = {11100168},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016817300625},
	doi = {10.1016/j.aej.2017.01.045},
	abstract = {The function of Physical Protection System (PPS) should meet three basic elements (detection, delay, and response) and it is required to protect the nuclear facility against possibility of bombing, sabotage, and theft. The system must be fast in performance to achieve sufﬁcient time for the arrival of response forces and complete the defense about the property in time, thwarting the adversary and neutralizing the implementation of its mission. The performance of the physical protection system should be designed to oppose and limit the capabilities and tactics of the attacker toward the nuclear facility. And in this ways it works as a barrier to obstruct the attacker against penetration. In this work an evaluation of the physical protection system effectiveness for a hypothetical facility against sabotage is presented. Proposed sabotage scenarios will be used as an input for this evaluation. The evaluation process was carried out using the single path computer model (EASI), for the determination of the probability of interruption (PI) as a ﬁrst metric factor of the PPS effectiveness. The Probability of Neutralization (PN) is computed by the neutralization analysis module as a second metric factor of the PPS effectiveness. The probability of detection and delay time values of detection, delay, communication and response forces action was measured along a speciﬁc sabotage path of the adversary. If the evaluation reveals any vulnerability, the initial system design must be redesigned to correct the vulnerabilities and another analysis of the redesigned system is performed.},
	language = {en},
	number = {2},
	urldate = {2020-10-16},
	journal = {Alexandria Engineering Journal},
	author = {Wadoud, A.A. and Adail, A.S. and Saleh, A.A.},
	month = jun,
	year = {2018},
	pages = {831--839},
}

@techreport{malliakos_pilot_2007,
	title = {A {Pilot} {Probabilistic} {Risk} {Assessment} {Of} a {Dry} {Cask} {Storage} {System} {At} a {Nuclear} {Power} {Plant}},
	number = {NUREG-1864},
	author = {Malliakos, A.},
	year = {2007},
}

@techreport{harvey_unlocking_2019,
	title = {Unlocking the {Potential} of {Emergency} {Savings} {Accounts}},
	url = {https://www.aarp.org/ppi/info-2019/unlocking-the-potential-of-emergency-savings-accounts.html},
	language = {en},
	urldate = {2020-10-10},
	institution = {AARP Public Policy Institute},
	author = {Harvey, Catherine S.},
	month = oct,
	year = {2019},
	doi = {10.26419/ppi.00084.001},
}

@misc{lowrey_great_2017,
	title = {The {Great} {Recession} {Is} {Still} {With} {Us}},
	url = {https://www.theatlantic.com/business/archive/2017/12/great-recession-still-with-us/547268/},
	abstract = {The downturn left the country poorer and more unequal than it would have been otherwise.},
	language = {en-US},
	urldate = {2020-10-10},
	journal = {The Atlantic},
	author = {Lowrey, Annie},
	month = dec,
	year = {2017},
	note = {Section: Business},
}

@book{jaczko_confessions_2019,
	address = {New York},
	title = {Confessions of a rogue nuclear regulator},
	isbn = {978-1-4767-5576-2},
	publisher = {Simon \& Schuster},
	author = {Jaczko, Gregory B.},
	year = {2019},
	keywords = {Nuclear energy, United States},
}

@techreport{curtis_smith_framework_2012,
	title = {A {Framework} to {Expand} and {Advance} {Probabilistic} {Risk} {Assessment} to {Support} {Small} {Modular} {Reactors}},
	url = {http://www.osti.gov/servlets/purl/1060982/},
	language = {en},
	number = {INL/EXT-12-27345, 1060982},
	urldate = {2020-10-02},
	author = {{Curtis Smith} and {David Schwieder} and {Robert Nourgaliev} and {Cherie Phelan} and {Diego Mandelli} and {Kellie Kvarfordt} and {Robert Youngblood}},
	month = sep,
	year = {2012},
	doi = {10.2172/1060982},
	pages = {INL/EXT--12--27345, 1060982},
}

@book{noauthor_nuclear_1980,
	address = {Washington, D.C.},
	title = {Nuclear {Reactors}: {How} {Safe} {Are} {They}?},
	isbn = {978-0-309-33156-2},
	shorttitle = {Nuclear {Reactors}},
	url = {https://www.nap.edu/catalog/19755},
	language = {en},
	urldate = {2020-10-01},
	publisher = {National Academies Press},
	month = jan,
	year = {1980},
	doi = {10.17226/19755},
	note = {Pages: 19755},
}

@book{noauthor_science_2014,
	address = {Washington, D.C.},
	title = {The {Science} of {Responding} to a {Nuclear} {Reactor} {Accident}: {Summary} of a {Symposium}},
	isbn = {978-0-309-31659-0},
	shorttitle = {The {Science} of {Responding} to a {Nuclear} {Reactor} {Accident}},
	url = {http://www.nap.edu/catalog/19002},
	language = {en},
	urldate = {2020-10-01},
	publisher = {National Academies Press},
	month = dec,
	year = {2014},
	doi = {10.17226/19002},
	note = {Pages: 19002},
}

@book{noauthor_lessons_2014,
	address = {Washington, D.C.},
	title = {Lessons {Learned} from the {Fukushima} {Nuclear} {Accident} for {Improving} {Safety} of {U}.{S}. {Nuclear} {Plants}},
	isbn = {978-0-309-27253-7},
	url = {http://www.nap.edu/catalog/18294},
	language = {en},
	urldate = {2020-10-01},
	publisher = {National Academies Press},
	month = oct,
	year = {2014},
	doi = {10.17226/18294},
	note = {Pages: 18294},
}

@book{committee_on_lessons_learned_from_the_fukushima_nuclear_accident_for_improving_safety_and_security_of_us_nuclear_plants_lessons_2016,
	address = {Washington, D.C.},
	title = {Lessons {Learned} from the {Fukushima} {Nuclear} {Accident} for {Improving} {Safety} and {Security} of {U}.{S}. {Nuclear} {Plants}: {Phase} 2},
	isbn = {978-0-309-38888-7},
	shorttitle = {Lessons {Learned} from the {Fukushima} {Nuclear} {Accident} for {Improving} {Safety} and {Security} of {U}.{S}. {Nuclear} {Plants}},
	url = {http://www.nap.edu/catalog/21874},
	language = {en},
	urldate = {2020-10-01},
	publisher = {National Academies Press},
	author = {{Committee on Lessons Learned from the Fukushima Nuclear Accident for Improving Safety and Security of U.S. Nuclear Plants} and {Nuclear and Radiation Studies Board} and {Division on Earth and Life Studies} and {National Academies of Sciences, Engineering, and Medicine}},
	month = may,
	year = {2016},
	doi = {10.17226/21874},
	note = {Pages: 21874},
}

@book{lee_risk_2011,
	address = {Hoboken, New Jersey},
	title = {Risk and {Safety} {Analysis} of {Nuclear} {Systems}},
	isbn = {978-0-470-90756-6},
	language = {en},
	publisher = {Wiley},
	author = {Lee, John C. and McCormick, Norman J.},
	year = {2011},
	keywords = {Nuclear engineering, Nuclear facilities, Risk assessment, Safety measures, Security measures, TECHNOLOGY \& ENGINEERING / Chemical \& Biochemical},
}

@book{robey_parallel_2021,
	title = {Parallel and {High} {Performance} {Computing}},
	isbn = {978-1-61729-646-8},
	url = {https://www.manning.com/books/parallel-and-high-performance-computing},
	abstract = {Complex calculations, like training deep learning models or running large-scale simulations, can take an extremely long time. Efficient parallel programming can save hours\&mdash;or even days\&mdash;of computing time. Parallel and High Performance Computing{\textless}/i{\textgreater} shows you how to deliver faster run-times, greater scalability, and increased energy efficiency to your programs by mastering parallel techniques for multicore processor and GPU hardware.},
	language = {en},
	urldate = {2020-09-25},
	author = {Robey, Robert and Zamora, Yuliana},
	year = {2021},
}

@article{difrancesco_office_nodate,
	title = {Office of {Nuclear} {Regulatory} {Research} {FY} 2020-22 {Planned} {Research} {Activities}.},
	language = {en},
	author = {Difrancesco, Nicholas},
	pages = {126},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC}: {Accident} {Sequence} {Precursor} ({ASP}) {Program}},
	url = {https://www.nrc.gov/about-nrc/regulatory/research/asp.html},
	urldate = {2020-09-14},
}

@misc{noauthor_inpo_nodate,
	title = {{INPO} - {Institute} of {Nuclear} {Power} {Operations}},
	url = {http://www.inpo.info/},
	urldate = {2020-09-14},
}

@misc{noauthor_dangers_nodate,
	title = {Dangers in nuclear industry’s supply chain},
	url = {https://www.iise.org/details.aspx?id=11984},
	urldate = {2020-09-13},
}

@misc{noauthor_supply_nodate,
	title = {Supply chain challenges.pdf},
}

@article{andrews-speed_south_2020,
	title = {South {Korea}’s nuclear power industry: recovering from scandal},
	volume = {13},
	issn = {1754-9957, 1754-9965},
	shorttitle = {South {Korea}’s nuclear power industry},
	url = {https://academic.oup.com/jwelb/article/13/1/47/5837954},
	doi = {10.1093/jwelb/jwaa010},
	abstract = {South Korea has one of the world’s more established nuclear power industries with its ﬁrst commercial reactors being commissioned in 1978. The growth of nuclear power capacity had relied on sustained government support and close coordination with key state-owned enterprises. The tight relationship between politicians, government and companies has resulted in what is colloquially known as the ‘nuclear maﬁa’. One year after the Fukushima Daiichi nuclear accident in Japan, Korea’s nuclear industry suffered its own crises in 2012. The ﬁrst was a station blackout at the Kori 1 reactor, the country’s oldest, which was not reported for over a month. The second set of revelations concerned systematic malfeasance along the nuclear supply chain involving the falsiﬁcation of reports of safety tests on nuclear parts and equipment. Revisions to the Nuclear Safety Act gave greater powers to the newly created Nuclear Safety and Security Commission and placed new reporting obligations on all actors along the nuclear supply chain. These measures were supplemented by more general legislation and regulations on public procurement, the conduct of public ofﬁcials and corruption. Whilst these steps have the potential to improve governance and integrity in the country’s nuclear power industry, some of the underlying causes of the earlier weaknesses remain. As a consequence, the transformation of Korea’s nuclear industry will be a long process.},
	language = {en},
	number = {1},
	urldate = {2020-09-13},
	journal = {The Journal of World Energy Law \& Business},
	author = {Andrews-Speed, Philip},
	month = mar,
	year = {2020},
	pages = {47--57},
}

@book{iaea_procurement_2016,
	address = {Vienna},
	title = {Procurement {Engineering} and {Supply} {Chain} {Guidelines} in {Support} of {Operation} and {Maintenance} of {Nuclear} {Facilities}.},
	isbn = {978-92-0-107315-0},
	url = {https://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=4853406},
	abstract = {"Procurement must be effectively managed to ensure availability of design functions throughout a nuclear facility's service life. Ineffective control of procurement process can jeopardize facility safety, reduce reliability, or can result in increased costs to operating organizations. This publication provides an overview of nuclear procurement processes, issues of special concern, and provides guidance for good practices to set up and manage a high-quality procurement organization. Lessons learned for organizations considering new build nuclear projects are also included."--Publisher's description.},
	language = {en},
	urldate = {2020-09-13},
	publisher = {IAEA},
	author = {{IAEA}},
	year = {2016},
	note = {OCLC: 987097480},
}

@misc{noauthor_decommissioning_nodate,
	title = {Decommissioning {Nuclear} {Power} {Plants}  {NRC}.pdf},
}

@misc{noauthor_nrc_nodate-1,
	title = {{NRC}: {Description} of {Decommissioning} {Processes}},
	url = {https://www.nrc.gov/waste/decommissioning/process.html},
	urldate = {2020-09-12},
}

@misc{noauthor_p1812_webpdf_nodate,
	title = {P1812\_web.pdf},
	url = {https://www-pub.iaea.org/MTCD/Publications/PDF/P1812_web.pdf},
	urldate = {2020-09-12},
}

@techreport{noauthor_decommissioning_nodate-1,
	title = {Decommissioning {IAEA}},
}

@misc{noauthor_decommissionin_nodate,
	title = {decommissionin},
}

@article{chen_study_2010,
	title = {A study of the probabilistic risk assessment to the dry storage system of spent nuclear fuel},
	volume = {87},
	issn = {03080161},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0308016109001756},
	doi = {10.1016/j.ijpvp.2009.11.009},
	abstract = {Due to the large power supply in the energy market since 1960s, the nuclear power planets have been consistently constructed throughout the world in order to maintain and supply sufﬁcient fundamental power generation. Up to now, most of the planets have been operated to a point where the spent fuel pool has reached its design capacity volume. To prevent the plant from shutdown due to the spent fuel pool exceeding the design capacity, the dry cask storage can provides a solution for both the spent fuel pool capacity and the mid-term storage method for the spent fuel bundles at nuclear power planet.},
	language = {en},
	number = {1},
	urldate = {2020-09-12},
	journal = {International Journal of Pressure Vessels and Piping},
	author = {Chen, K.C. and Ting, K. and Li, Y.C. and Chen, Y.Y. and Cheng, W.K. and Chen, W.C. and Liu, C.T.},
	month = jan,
	year = {2010},
	pages = {17--25},
}

@article{almomani_probabilistic_2016,
	title = {{PROBABILISTIC} {RISK} {ASSESSMENT} {OF} {INTERIM} {DRY} {STORAGE} {FACILITY} {SUBJECTED} {TO} {AN} {AIRCRAFT} {IMPACT}},
	language = {en},
	author = {Almomani, Belal and Lee, Sanghoon and Kang, Hyun Gook},
	year = {2016},
	pages = {11},
}

@techreport{noauthor_nuregcr-7039_nodate,
	title = {{NUREG}/{CR}-7039, {Vol}. 7, "{Systems} {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8 {Volume} 7: {Data} {Loading}."},
	language = {en},
	keywords = {SAPHIRE},
	pages = {132},
}

@techreport{noauthor_nuregcr-7039_2011,
	title = {{NUREG}/{CR}-7039, {Vol}. 6, "{Systems} {Analysis} {Programs} for {Hands}-{On} {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8, {Volume} 6: {Quality} {Assurance}."},
	url = {http://www.osti.gov/servlets/purl/130641-fcKmdK/webviewable/},
	language = {en},
	urldate = {2020-08-18},
	year = {2011},
	doi = {10.2172/130641},
	keywords = {SAPHIRE},
}

@techreport{noauthor_nuregcr-7039_2011-1,
	title = {{NUREG}/{CR}-7039, {Vol}. 5, "{Systems} {Analysis} {Programs} for {Hands}-{On} {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8, {Volume} 5: {Workspaces}."},
	language = {en},
	year = {2011},
	keywords = {SAPHIRE},
	pages = {84},
}

@techreport{noauthor_nuregcr-7039_2011-2,
	title = {{NUREG}/{CR}-7039, {Vol}. 4, "{Systems} {Analysis} {Programs} for {Hands}-{On} {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8."},
	language = {en},
	year = {2011},
	keywords = {SAPHIRE},
	pages = {86},
}

@techreport{noauthor_nuregcr-7039_2011-3,
	title = {{NUREG}/{CR}-7039, {Vol}. 3, "{Systems} {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8, {Volume} 3: {User}'s {Guide}."},
	language = {en},
	year = {2011},
	keywords = {SAPHIRE},
	pages = {206},
}

@techreport{noauthor_nuregcr-7039_2011-4,
	title = {{NUREG}/{CR}-7039, {Vol}. 2, "{Systems} {Analysis} {Programs} for {Hands}-on {Integrated} {Reliability} {Evaluations} ({SAPHIRE}) {Version} 8, {Volume} 2: {Technical} {Reference}."},
	language = {en},
	urldate = {2020-08-18},
	year = {2011},
	doi = {10.2172/130641},
	keywords = {SAPHIRE},
}

@misc{noauthor_bentley_nodate,
	title = {Bentley - {Infrastructure} and {Engineering} {Software} and {Solutions}},
	url = {https://www.bentley.com/en},
	abstract = {Providing architects, engineers, constructors, and owner-operators with comprehensive architecture and engineering solutions for advancing infrastructure.},
	urldate = {2020-09-05},
}

@misc{noauthor_engineering_2018,
	title = {Engineering \& {Construction} ({E}\&{C}): {Modeling} {Integration} {Enables} {Optimized} {Execution}},
	shorttitle = {Engineering \& {Construction} ({E}\&{C})},
	url = {https://www.chemengonline.com/engineering-construction-ec-modeling-integration-enables-optimized-execution/},
	abstract = {The engineering and construction (E\&C) industry is undergoing transformational change. Cumbersome document-based project execution is transitioning to robust, data-centric execution, as innovators seize opportunities in emerging technologies and ongoing expansion in cloud-based environments.},
	language = {en},
	urldate = {2020-09-05},
	journal = {IIOT Connection},
	month = dec,
	year = {2018},
	note = {Section: Chemical},
}

@misc{noauthor_how_nodate,
	title = {How to {Build} {Nuclear} {Plants} (1).pdf},
}

@article{alsharif_framework_2016,
	title = {A {Framework} for {Identifying} {Causal} {Factors} of {Delay} in {Nuclear} {Power} {Plant} {Projects}},
	abstract = {Nuclear power plant projects have unique characteristics (e.g., variability of projects portfolio, processes and procedures, security and safety requirements) that affect precise estimation of project schedule and cost. Inaccurate estimation may result in delay and cost overrun, and accordingly jeopardizing the nuclear power plant’s operating license. To reliably estimate projects schedule and cost, the causal factors of delay in nuclear power plant projects need to be carefully investigated and analyzed. This study presents a framework for identifying causal factors of delay for operable nuclear power plants projects. This framework is designed in three main stages: (1) collecting data on projects that experienced delay for various reasons (e.g., missing schedule updates, design errors, scope change); (2) identifying the reasons for delay into standard common causal factors; and (3) analyzing the identified causal factors of delay and their impact on projects schedule and cost performance. This framework will assist decision-makers (e.g., nuclear project managers and project controllers) in identifying and evaluating the nuclear projects causal factors of delay to improve the reliability of projects schedule and cost estimation.},
	language = {en},
	journal = {Procedia Engineering},
	author = {Alsharif, Samer},
	year = {2016},
	pages = {7},
}

@misc{noauthor_development_nodate,
	title = {development of {Safeguards} information},
}

@misc{noauthor_nrc_nodate-2,
	title = {{NRC}: {Nuclear} {Power} {Plant} {Licensing} {Process} ({NUREG}/{BR}-0298, {Revision} 2)},
	url = {https://www.nrc.gov/reading-rm/doc-collections/nuregs/brochures/br0298/index.html},
	urldate = {2020-09-05},
}

@misc{noauthor_nuregpdfpdf_nodate,
	title = {Nureg.pdf.pdf},
}

@misc{noauthor_nrc_nodate-3,
	title = {{NRC}},
	url = {https://www.nrc.gov/docs/ML1924/ML19242D329.pdf},
	urldate = {2020-09-02},
}

@misc{noauthor_nrc_nodate-4,
	title = {{NRC}: 10 {CFR} {Part} 50—{Domestic} {Licensing} of {Production} and {Utilization} {Facilities}},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/},
	urldate = {2020-09-05},
}

@misc{noauthor_nrc_nodate-5,
	title = {{NRC}: {New} {Reactors}},
	url = {https://www.nrc.gov/reactors/new-reactors.html},
	urldate = {2020-09-05},
}

@techreport{noauthor_iaea_nodate,
	title = {{IAEA} {Safety} {Glossary}},
	url = {https://www-ns.iaea.org/downloads/standards/glossary/iaea-safety-glossary-draft-2016.pdf},
	urldate = {2020-09-04},
}

@techreport{international_atomic_energy_agency_leadership_2016,
	address = {Lanham; Lanham},
	title = {Leadership and {Management} for {Safety}: {IAEA} {Safety} {Standards} {Series} {No}. {Gsr} {Part} 2.},
	shorttitle = {Leadership and {Management} for {Safety}},
	url = {https://public.ebookcentral.proquest.com/choice/publicfullrecord.aspx?p=4853354},
	language = {en},
	urldate = {2020-09-04},
	institution = {International Atomic Energy Agency Rowman \& Littlefield Publishers, Incorporated [distributor},
	author = {{International Atomic Energy Agency}},
	year = {2016},
	note = {OCLC: 1088962002},
}

@techreport{condu_managing_2007,
	address = {Vienna},
	title = {Managing the first nuclear power plant project.},
	url = {http://www.myilibrary.com?id=171770},
	abstract = {Experience shows that the time between an initial policy decision by a state to consider nuclear power up to the start of its first nuclear power plant is about 10 to 15 years. The proper management of the wide scope of project activities during this period represents a major challenge for the involved governmental, utility, regulatory, supplier and other supportive organizations. The main focus is to ensure that the project is implemented successfully from a commercial point of view while remaining in accordance with the appropriate engineering and quality requirements, safety standards and security guides. This publication provides an introductory overall description of the main project management activities and gives the references to the related detailed guidance. The target audience are decision makers, advisers and senior managers in the governmental organizations, utilities, industrial organizations and regulatory bodies in the countries desiring to launch the first nuclear power plant project.--Publisher's description.},
	language = {en},
	urldate = {2020-09-04},
	institution = {International Atomic Energy Agency},
	author = {Condu, M and Pieroni, N and Facer, R. I and {International Atomic Energy Agency}},
	year = {2007},
	note = {OCLC: 794271832},
}

@techreport{international_atomic_energy_agency_safety_2016,
	title = {Safety of nuclear power plants: specific safety requirements.},
	shorttitle = {Safety of nuclear power plants},
	url = {http://www-pub.iaea.org/books/IAEABooks/10886/Safety-of-Nuclear-Power-Plants-Commissioning-and-Operation},
	language = {en},
	urldate = {2020-09-04},
	author = {{International Atomic Energy Agency}},
	year = {2016},
	note = {OCLC: 987076081},
}

@inproceedings{kaplan_matrix_1983,
	title = {The {Matrix} {Method} for {Handling} {Model} {Interfaces} - {Risk} {Assembly} and {Decomposition}},
	language = {en},
	author = {Kaplan, S and Garrick, B John and Torri, A},
	year = {1983},
	pages = {6},
}

@misc{plumer_why_2016,
	title = {Why {America} abandoned nuclear power (and what we can learn from {South} {Korea})},
	url = {https://www.vox.com/2016/2/29/11132930/nuclear-power-costs-us-france-korea},
	abstract = {Nuclear power could help us solve climate change — if weren't so absurdly expensive.},
	language = {en},
	urldate = {2020-08-31},
	journal = {Vox},
	author = {Plumer, Brad},
	month = feb,
	year = {2016},
}

@article{nakamoto_bitcoin_nodate,
	title = {Bitcoin: {A} {Peer}-to-{Peer} {Electronic} {Cash} {System}},
	abstract = {A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.},
	language = {en},
	author = {Nakamoto, Satoshi},
	pages = {9},
}

@article{nardi_international_nodate,
	title = {{INTERNATIONAL} {TRAINING} {COURSE} {ON} {IMPLEMENTATION} {OF} {STATE} {SYSTEMS} {OF} {ACCOUNTING} {FOR} {AND} {CONTROL} {OF} {NUCLEAR} {MATERIALS} {October} 17-{November} 4, 1983},
	language = {en},
	author = {Nardi, Joseph},
	pages = {24},
}

@article{shyloski_overcoming_nodate,
	title = {“{Overcoming}” {Challenges} {Facing} {New} {Nuclear} {Build}},
	language = {en},
	author = {Shyloski, Edward C},
	pages = {115},
}

@article{chang_blockchain_2020,
	title = {Blockchain for {Integrated} {Nuclear} {Power} {Plants} {Management} {System}},
	volume = {11},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/11/6/282},
	doi = {10.3390/info11060282},
	abstract = {In nuclear power plants, plant management systems are not only very important for operation and maintenance of the facilities, but also play a very important role in analyzing and reporting the events to the authorities when a failure or accident occurs in the facility. In addition, it is also important to ensure that event records are managed transparently so as not to cause any attempt to cover up events. Therefore, this paper proposes a tamper free plant operation system by applying blockchain technology to the integrated plant management system of Korea hydro and nuclear power (KHNP). As a result, this paper will contribute to improving public acceptance by eliminating distrust in safe operation of nuclear power plants.},
	language = {en},
	number = {6},
	urldate = {2020-08-29},
	journal = {Information},
	author = {Chang, Choong-koo},
	month = may,
	year = {2020},
	pages = {282},
}

@article{pease_reaching_1980,
	title = {Reaching {Agreement} in the {Presence} of {Faults}},
	volume = {27},
	issn = {0004-5411, 1557-735X},
	url = {http://dl.acm.org/doi/10.1145/322186.322188},
	doi = {10.1145/322186.322188},
	language = {en},
	number = {2},
	urldate = {2020-08-29},
	journal = {Journal of the ACM (JACM)},
	author = {Pease, M. and Shostak, R. and Lamport, L.},
	month = apr,
	year = {1980},
	pages = {228--234},
}

@techreport{noauthor_nureg-1855_2009,
	title = {{NUREG}-1855, {Vol}. 1, "{Guidance} on the {Treatment} of {Uncertainties} {Associated} with {PRAs} in {Risk}-{Informed} {Decision} {Making}."},
	language = {en},
	year = {2009},
	pages = {144},
}

@book{hutter_automated_2019,
	address = {Cham},
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {Automated {Machine} {Learning}: {Methods}, {Systems}, {Challenges}},
	isbn = {978-3-030-05317-8 978-3-030-05318-5},
	shorttitle = {Automated {Machine} {Learning}},
	url = {http://link.springer.com/10.1007/978-3-030-05318-5},
	language = {en},
	urldate = {2020-08-24},
	publisher = {Springer International Publishing},
	editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	year = {2019},
	doi = {10.1007/978-3-030-05318-5},
}

@techreport{mascarenas_micro_2019,
	title = {Micro {Reactor} {Instrumentation} and {Control} {FY2019} {Report}},
	url = {http://www.osti.gov/servlets/purl/1566080/},
	language = {en},
	number = {LA-UR-19-29415, 1566080},
	urldate = {2020-08-24},
	author = {Mascarenas, David Dennis Lee and Meyerhofer, Peter David and Ezell, Dianne and Ramuhalli, Pradeep and Unruh, Troy},
	month = sep,
	year = {2019},
	doi = {10.2172/1566080},
	pages = {LA--UR--19--29415, 1566080},
}

@article{sjostrand_average_nodate,
	title = {{ON} {THE} {AVERAGE} {CHORD} {LENGTH}},
	abstract = {A recent discussion on the definition of the average chord length in a convex body is summarized. It is shown that an unclear formulation in the early derivation of it may lead to misunderstandings.},
	language = {en},
	author = {Sjöstrand, N G},
	pages = {6},
}

@techreport{garrick_proceedings_2018,
	address = {Los Angeles, CA},
	title = {Proceedings of the {One} {Day} {Workshop} on {Quantifying} {Global} {Catastrophic} {Risks}},
	number = {GIRS-2018-07},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	editor = {Garrick, B. John},
	year = {2018},
}

@techreport{miller_rd_2020,
	title = {R\&{D} {Roadmap} to {Enhance} {Industry} {Legacy} {Probabilistic} {Risk} {Assessment} {Methods} and {Tools}},
	language = {en},
	number = {INL/EXT-20-59202},
	author = {Miller, Andrew and Hess, Stephen and Smith, Curtis},
	year = {2020},
	pages = {32},
}

@techreport{garrick_proceedings_2017,
	address = {Los Angeles, CA},
	title = {Proceedings of the {First} {International} {Colloquium} on {Catastrophic} and {Existential} {Risk}},
	number = {GIRS-2017-04},
	institution = {The B. John Garrick Institute for the Risk Sciences, University of California Los Angeles},
	editor = {Garrick, B. John},
	year = {2017},
}

@misc{noauthor_untitled_nodate,
	title = {Untitled document},
	url = {https://docs.google.com/document/u/0/d/1il7WoR1dfcE_3V2vofv8yo2EOe_6JDA3mBkD6_P0tX4/edit?usp=embed_facebook},
	language = {en},
	urldate = {2020-08-22},
	journal = {Google Docs},
}

@techreport{hick_prism_nodate,
	title = {{PRISM} {Sodium} {Fast} {Reactor} {Licensing} {Modernization} {Project} {Demonstration}},
	url = {https://www.nrc.gov/docs/ML1903/ML19036A584.pdf},
	urldate = {2020-08-15},
	author = {Hick, Thomas and Warner, Matthew and Miller, Gary and Li, Jonathan},
}

@techreport{brandon_high_nodate,
	title = {High {Temperature}, {Gas}-{Cooled} {Pebble} {Bed} {Reactor} - licensing {Modernization} {Project} {Demonstration}},
	url = {https://www.nrc.gov/docs/ML1822/ML18228A779.pdf},
	urldate = {2020-08-15},
	author = {Brandon, Wa1tes and Fleming, Karl and Silady, Fred and Huning, Alex and Redd, Jason},
}

@techreport{noauthor_molten_nodate,
	title = {Molten {Salt} {Reactor} {Experiment} ({MSRE}) {Case} {Study} {Using} {Risk}‐{Informed}, {Performance}‐{Based} {Technical} {Guidance} to {Inform} {Future} {Licensing} for {Advanced} {Non}‐{Light} {Water} {Reactors}},
	url = {https://www.nrc.gov/docs/ML1924/ML19249B632.pdf},
	urldate = {2020-08-15},
}

@inproceedings{andrews_fault_2008,
	title = {Fault tree conversion to binary decision diagrams},
	isbn = {978-0-9721385-5-0},
	url = {https://repository.lboro.ac.uk/articles/online_resource/Fault_tree_conversion_to_binary_decision_diagrams/9223040},
	abstract = {Fault Tree Analysis is a commonly used technique to predict the causes of a specific system failure mode and to then determine the likelihood of this event. Over recent years the Binary Decision Diagram (BDD) method has been developed for the solution of the fault tree. It can be shown that this approach has advantages in terms of both accuracy and efficiency over the conventional method of analysis formulated in the 1970’s. The BDD expresses the failure logic in a disjoint form which gives it an advantage from the computational viewpoint. Fault Trees, however, remain the better way to represent the system failure causality. Therefore the usual way of taking advantage of the BDD structure is to construct a fault tree and then convert this to a BDD. It is on the fault tree conversion process
that this paper will focus. 

In order to construct a BDD the variables which represent the occurrence of the basic events in the fault tree have to be placed in an ordering. Depending on the ordering selected an efficient representation of the failure logic can be obtained or if a poor ordering is selected a less efficient analysis will result. Once the ordering is established one approach is to utilise a set of rules developed by Rauzy which are repeatedly applied to generate the BDD. An
alternative approach can be used whereby BDD constructs for each of the gate types are first formed and then joined together as specified by the gates in the fault tree. Some comments on the effectiveness of these approaches will be provided.},
	language = {en},
	urldate = {2020-08-22},
	publisher = {Loughborough University},
	author = {Andrews, J.D. and Remenyte, R.},
	month = sep,
	year = {2008},
}

@article{noauthor_nei_nodate,
	title = {{NEI} 00-04, {Rev}. 0, "10 {CFR} 50.69 {SSC} {Categorization} {Guideline}."},
	language = {en},
	pages = {90},
}

@article{yoschenko_resuspension_2006,
	title = {Resuspension and redistribution of radionuclides during grassland and forest fires in the {Chernobyl} exclusion zone: part {II}. {Modeling} the transport process},
	volume = {87},
	issn = {0265931X},
	shorttitle = {Resuspension and redistribution of radionuclides during grassland and forest fires in the {Chernobyl} exclusion zone},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X05003309},
	doi = {10.1016/j.jenvrad.2005.12.003},
	language = {en},
	number = {3},
	urldate = {2020-08-22},
	journal = {Journal of Environmental Radioactivity},
	author = {Yoschenko, V.I. and Kashparov, V.A. and Levchuk, S.E. and Glukhovskiy, A.S. and Khomutinin, Yu.V. and Protsak, V.P. and Lundin, S.M. and Tschiersch, J.},
	month = jan,
	year = {2006},
	pages = {260--278},
}

@article{elsheikh_safety_2013,
	title = {Safety assessment of molten salt reactors in comparison with light water reactors},
	volume = {6},
	issn = {1687-8507},
	url = {http://www.sciencedirect.com/science/article/pii/S1687850713000101},
	doi = {10.1016/j.jrras.2013.10.008},
	abstract = {Molten salt reactors (MSRs) have a long history with the first design studies beginning in the 1950s at the Oak Ridge National Laboratory (ORNL). Traditionally these reactors are thought of as thermal breeder reactors running on the thorium to 233U cycle and the historical competitor to fast breeder reactors. In the recent years, there has been a growing interest in molten salt reactors, which have been considered in the framework of the Generation IV International Forum, because of their several potentialities and favorable features when compared with conventional solid-fueled reactors. MSRs meet many of the future goals of nuclear energy, in particular for what concerns an improved sustainability, an inherent safety with strong negative temperature coefficient of reactivity, stable coolant, low pressure operation that don not require expensive containment, easy to control, passive decay heat cooling and unique characteristics in terms of actinide burning and waste reduction, while benefiting from the past experience acquired with the molten salt technology. As the only liquid-fueled reactor concept, the safety basis, characteristics and licensing of an MSR are different from solid-uranium fueled light water reactors. In this paper, a historical review of the major plant systems in MSR is presented. The features of different safety characteristics of MSR power plant are reviewed and assessment in comparison to other solid fueled light water reactors LWRs.},
	language = {en},
	number = {2},
	urldate = {2020-08-22},
	journal = {Journal of Radiation Research and Applied Sciences},
	author = {Elsheikh, Badawy M.},
	month = oct,
	year = {2013},
	keywords = {LWR safety, Molten salt reactor safety, Nuclear reactor accident, Nuclear safety},
	pages = {63--70},
}

@misc{noauthor_elc_nodate,
	title = {{ELC}: {SpaceX} lessons learned [{LWN}.net]},
	url = {https://lwn.net/Articles/540368/},
	urldate = {2020-08-22},
}

@article{daughan_seawolf_1994,
	title = {Seawolf {Submarine} {Ship} {Control} {System}: {A} {Case} {Study} of a {Fault}-{Tolerant} {Design}},
	volume = {106},
	issn = {00281425, 15593584},
	shorttitle = {Seawolf {Submarine} {Ship} {Control} {System}},
	url = {http://www.ingentaconnect.com/content/asne/nej/1994/00000106/00000001/art00010},
	doi = {10.1111/j.1559-3584.1994.tb02797.x},
	abstract = {During the several decades since the previous U. S. Navy submarine design, the enhanced capabilities of computers and miniaturization of components has permitted the incorporation of more advanced control features in the same or less space than occupied by previous systems. Also during this period, fault-tolerantarchitectures,which typically employ coordinated redundancy to yield highly reliable and available systems, have been deployed on space platforms, aircraft, and other critical applications. The Seawolf submarine utilizes a fault-tolerant ship control system, which will be the most sophisticated ship control system deployed by a U. S. Navy submarine to date.},
	language = {en},
	number = {1},
	urldate = {2020-08-22},
	journal = {Naval Engineers Journal},
	author = {Daughan, Michael G.},
	month = jan,
	year = {1994},
	pages = {54--70},
}

@techreport{scott_wildfire_2013,
	address = {Ft. Collins, CO},
	title = {A wildfire risk assessment framework for land and resource management},
	url = {https://www.fs.usda.gov/treesearch/pubs/56265},
	abstract = {Wildfires can result in significant, long-lasting impacts to ecological, social, and economic systems. It is necessary, therefore, to identify and understand the risks posed by wildland fire, and to develop cost-effective mitigation strategies accordingly. This report presents a general framework with which to assess wildfire risk and explore mitigation options, and illustrates a process for implementing the framework. Two key strengths of the framework are its flexibility—allowing for a multitude of data sources, modeling techniques, and approaches to measuring risk—and its scalability, with potential application for project, forest, regional, and national planning. The specific risk assessment process we introduce is premised on three modeling approaches to characterize wildfire likelihood and intensity, fire effects, and the relative importance of highly valued resources and assets that could be impacted by wildfire. The spatial scope of the process is landscape-scale, and the temporal scope is short-term (that is, the temporal dynamics of succession and disturbance are not simulated). We highlight key information needs, provide guidance for use of fire simulation models and risk geo-processing tools, and demonstrate recent applications of the framework across planning scales. The aim of this report is to provide fire and land managers with a helpful set of guiding principles and tools for assessing and mitigating wildfire risk.},
	language = {en},
	number = {RMRS-GTR-315},
	urldate = {2020-08-22},
	institution = {U.S. Department of Agriculture, Forest Service, Rocky Mountain Research Station},
	author = {Scott, Joe H. and Thompson, Matthew P. and Calkin, David E.},
	year = {2013},
	doi = {10.2737/RMRS-GTR-315},
	pages = {RMRS--GTR--315},
}

@article{kashparov_territory_2003,
	title = {Territory contamination with the radionuclides representing the fuel component of {Chernobyl} fallout},
	volume = {317},
	issn = {00489697},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S004896970300336X},
	doi = {10.1016/S0048-9697(03)00336-X},
	abstract = {The data obtained through a series of experiments were used to specify the correlation of activities of the fuel component radionuclides of Chernobyl fallout and to create the maps of the 30-km Chernobyl zone terrestrial density of contamination with 154Eu, 238Pu, 239q240Pu and 241Am (on 01.01.2000). In the year 2000, total inventories of the fuel component radionuclides in the upper 30-cm soil layer of the 30-km Chernobyl zone in Ukraine (outside the ChNPP industrial site, excluding the activity located in the radioactive waste storages and in the cooling pond) were estimated as: 90Sr—7.7=1014 Bq; 137Cs—2.8=1015 Bq; 154Eu—1.4=1013 Bq; 238Pu—7.2=1012 Bq; 239q240Pu—1.5=1013 Bq; 241Am—1.8=1013 Bq. These values correspond to 0.4–0.5\% of their amounts in the ChNPP unit 4 at the moment of the accident. The current estimate is 3 times lower than the previous widely-cited estimates. Inventories of the fuel component radionuclides were also estimated in other objects within the 30-km zone and outside it. This allowed more accurate data to be obtained on the magnitude of a relative release of radionuclides in the fuel particles (FP) matrix during the Chernobyl accident outside the ChNPP industrial site. It amounts to 1.5"0.5\% of these radionuclides in the reactor, which is 2 times lower than the previous estimates. Two-thirds of the radionuclides release in the FP was deposited on the territory of Ukraine.},
	language = {en},
	number = {1-3},
	urldate = {2020-08-22},
	journal = {Science of The Total Environment},
	author = {Kashparov, V.A and Lundin, S.M and Zvarych, S.I and Yoshchenko, V.I and Levchuk, S.E and Khomutinin, Y.V and Maloshtan, I.M and Protsak, V.P},
	month = dec,
	year = {2003},
	pages = {105--119},
}

@article{takahashi_vertical_2015,
	title = {Vertical distribution and temporal changes of 137 {Cs} in soil profiles under various land uses after the {Fukushima} {Dai}-ichi {Nuclear} {Power} {Plant} accident},
	volume = {139},
	issn = {0265931X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X14002094},
	doi = {10.1016/j.jenvrad.2014.07.004},
	abstract = {We monitored the vertical distribution of 137Cs in soil proﬁles under eight different land uses for the 2 y after the Fukushima Dai-ichi Nuclear Power Plant accident, and discussed the temporal changes in the early-stage of the migration and the determinants of the initial distribution. The soil samples were collected for four surveys using a scraper plate at each study site, which consisted of three forests (mixed forest, mature cedar, and young cedar), two grasslands (pasture and meadow) and three abandoned agricultural ﬁelds (farm land, tobacco ﬁeld, and paddy ﬁeld). The land use patterns have a large inﬂuence on some soil properties and the migration processes of 137Cs above ground, resulting in different distribution of 137Cs in those soil proﬁles. Speciﬁcally, the secondary deposition of 137Cs from the coniferous canopy, retention of 137Cs by litter layer, and the homogenization of 137Cs concentrations in surface soil by natural soil mixing such as the disturbance by cattle grazing, roots growing and the formation of needle ice were important to cause redistribution of the deposited 137Cs. Only in the paddy ﬁeld, the 137Cs inventory in subsurface soils (5e10 cm) gradually increased and comprised 26\% of the total 137Cs in 2 y, showing the downward migration of 137Cs to subsurface soil. In the other sites, it was considered that 137Cs were strongly adsorbed by soil particles and rarely migrated downward as soluble form. Vertical distributions during the ﬁrst survey were able to be used as the initial distributions and were well ﬁtted to the exponential equation. The distribution parameters a (relaxation depth) and b (relaxation mass depth), calculated by the exponential equation were correlated with RIP (r ¼ À0.806, p {\textless} 0.05), macro pore (r ¼ 0.651, p ¼ 0.11), and dispersible ﬁne particle content (r ¼ 0.856, p {\textless} 0.05). It indicated that the initial distribution would be inﬂuenced by the Cs ﬁxation ability of soil, and the penetration process of water and particles in soils.},
	language = {en},
	urldate = {2020-08-22},
	journal = {Journal of Environmental Radioactivity},
	author = {Takahashi, Junko and Tamura, Kenji and Suda, Tomoya and Matsumura, Ryo and Onda, Yuichi},
	month = jan,
	year = {2015},
	pages = {351--361},
}

@article{yoschenko_radioactive_2018,
	title = {Radioactive and stable cesium isotope distributions and dynamics in {Japanese} cedar forests},
	volume = {186},
	issn = {0265931X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X17302849},
	doi = {10.1016/j.jenvrad.2017.09.026},
	abstract = {Dynamics of the Fukushima-derived radiocesium and distribution of the natural stable isotope 133Cs in Japanese cedar (Cryptomeria japonica D. Don) forest ecosystems were studied during 2014–2016. For the experimental site in Yamakiya, Fukushima Prefecture, we present the redistribution of radiocesium among ecosystem compartments during the entire observation period, while the results obtained at another two experimental site were used to demonstrate similarity of the main trends in the Japanese forest ecosystems. Our observations at the Yamakiya site revealed signiﬁcant redistribution of radiocesium between the ecosystem compartments during 2014–2016. During this same period radionuclide inventories in the aboveground tree biomass were relatively stable, however, radiocesium in forest litter decreased from 20 ± 11\% of the total deposition in 2014 to 4.6 ± 2.7\% in 2016. Radiocesium in the soil proﬁle accumulated in the 5-cm topsoil layers. In 2016, more than 80\% of the total radionuclide deposition in the ecosystem resided in the 5-cm topsoil layer.},
	language = {en},
	urldate = {2020-08-22},
	journal = {Journal of Environmental Radioactivity},
	author = {Yoschenko, Vasyl and Takase, Tsugiko and Hinton, Thomas G. and Nanba, Kenji and Onda, Yuichi and Konoplev, Alexei and Goto, Azusa and Yokoyama, Aya and Keitoku, Koji},
	month = jun,
	year = {2018},
	pages = {34--44},
}

@article{sherman_origins_2019,
	title = {On the {Origins} and {Variations} of {Blockchain} {Technologies}},
	volume = {17},
	issn = {1558-4046},
	doi = {10.1109/MSEC.2019.2893730},
	abstract = {We explore the origins of blockchain technologies to better understand the enduring needs they address. We identify the five key elements of a blockchain, show the embodiments of these elements, and examine how these elements come together to yield important properties in selected systems. To facilitate comparing the many variations of blockchains, we also describe the four crucial roles of common blockchain participants. Our historical exploration highlights the 1979 work of David Chaum, whose vault system embodies many of the elements of blockchains.},
	number = {1},
	journal = {IEEE Security Privacy},
	author = {Sherman, Alan T. and Javani, Farid and Zhang, Haibin and Golaszewski, Enis},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Security Privacy},
	keywords = {Bitcoin, Blockchain, Computer security, Fault tolerant systems, Smart contracts, blockchain technologies, blockchain variation, cryptography, financial data processing},
	pages = {72--77},
}

@misc{noauthor_nrc_nodate-6,
	title = {{NRC}: {Inspection}},
	url = {https://www.nrc.gov/about-nrc/regulatory/safety-oversight.html},
	urldate = {2020-08-17},
}

@misc{noauthor_iaea_2018,
	type = {Text},
	title = {{IAEA} {Completes} 3-{Year} {Project} to {Modernize} {Safeguards} {IT} {System}},
	url = {https://www.iaea.org/newscenter/pressreleases/iaea-completes-3-year-project-to-modernize-safeguards-it-system},
	language = {en},
	urldate = {2020-08-17},
	month = may,
	year = {2018},
	note = {Publisher: IAEA},
}

@misc{noauthor_smart_nodate,
	title = {Smart {Contracts} and {Chaincode} — hyperledger-fabricdocs master documentation},
	url = {https://hyperledger-fabric.readthedocs.io/en/release-2.2/smartcontract/smartcontract.html},
	urldate = {2020-08-17},
}

@misc{noauthor_nrc_nodate-7,
	title = {{NRC}: {ADAMS} {Public} {Documents}},
	url = {https://www.nrc.gov/reading-rm/adams.html},
	urldate = {2020-08-17},
}

@misc{noauthor_nrc_nodate-8,
	title = {{NRC}: 10 {CFR} 50.4 {Written} communications},
	url = {https://www.nrc.gov/reading-rm/doc-collections/cfr/part050/part050-0004.html},
	urldate = {2020-08-17},
}

@misc{noauthor_highlighting_nodate,
	title = {Highlighting the need for blockchain :},
	shorttitle = {Highlighting the need for blockchain},
	url = {https://docs.google.com/document/u/1/d/1vjGlsGsh8AtxFP1LY23oyLl_B8wbTPD6F8QXvo8JML0/edit?usp=embed_facebook},
	abstract = {Highlighting the need for blockchain :   Nuclear nonproliferation   The IAEA receive Inspection working paper and reports, Additional Protocol declarations, analytical results of samples taken at the facilities, Inventory Change reports, Material Balance reports, Physical Inventory Listings, Comp...},
	language = {en},
	urldate = {2020-08-15},
	journal = {Google Docs},
}

@techreport{wright_status_2018,
	title = {Status of {Metallic} {Structural} {Materials} for {Molten} {Salt} {Reactors}},
	url = {https://www.osti.gov/biblio/1467482},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/EXT-18-45171-Rev000},
	urldate = {2020-07-29},
	institution = {Idaho National Lab. (INL), Idaho Falls, ID (United States); Argonne National Lab. (ANL), Argonne, IL (United States)},
	author = {Wright, R. N. and Sham, T.-L.},
	month = may,
	year = {2018},
	doi = {10.2172/1467482},
}

@article{koivisto_two-fluid_nodate,
	title = {Two-{Fluid} {Molten} {Salt} {Reactors}: {Design} and {Application} with {Chloride} {Salts}},
	abstract = {The purpose of this thesis was to study neutronics of a two-fluid molten salt reactor. In particular, far more efficient resource utilization and achievable burnups in modified open fuel cycles were examined. Fuel in liquid form and possibility to operate with natural uranium feed would simplify the nuclear fuel cycle. A simple two-fluid reactor model was generated and studied with two different chloride salt (NaCl-UCl3 and NaCl-ThCl4-UCl3). Capability of a reactor to maintain criticality and convert its new fissile fuel were under the main interest. Applied chloride salts moderate neutrons less than fluorides and can accommodate more actinides in a solution. Material problems, such as high corrosion, require meticulous research and refractory metal alloys or composites as reactor materials are necessary. Fuel burnup constitutes a non-linear problem and solutions must be found by iteration between the solvers. In this study, Monte Carlo based Serpent -code was combined with EQL0D procedure. Serpent was used for the neutron flux calculations at discrete timesteps and to determine the microscopic cross sections. Burnup equations and processing of the fuel were modelled with EQL0D. In contrary to solid fuels, liquid fuel is in continuous flow and fuel burnup is rather constant within the core. This homogeneity reduces the computational time as burnup equations can be solved only once for each core region. Thermohydraulic model was not implemented, but could be considered in further studies in order to model the flux more accurately. Disadvantages of a two-fluid reactor are its more complex structure and possibility to extract weapons-grade material from its lower burnup blanket region. Slightly higher achievable burnups and improved resource utilization may not reason a two-fluid reactor type enough. In addition, moderation of the blanket improved the performance only marginally. However, optimization of the moderator geometry and its use in smaller cores may give some gains. Unfortunately, the most widely used moderator material graphite has durability issues. A major challenge is to develop reliable fuel processing systems. For example, noble gases release the fuel salt during operation, having a significant radioactive inventory. Nevertheless, molten salt reactor type is unique with its liquid fuel design. Experimental research projects would be important to launch after decades of inactivity. Many important phenomena can be already simulated, but operational experience is highly needed to validate the models in practice.},
	language = {en},
	author = {Koivisto, Tuomo},
	pages = {97},
}

@article{zheng_thorium-based_2018,
	title = {Thorium-based molten salt {SMR} as the nuclear technology pathway from a market-oriented perspective},
	volume = {116},
	issn = {0306-4549},
	url = {http://www.sciencedirect.com/science/article/pii/S0306454918300586},
	doi = {10.1016/j.anucene.2018.02.004},
	abstract = {In this paper, a market guided design approach is exercised to identify the optimal reactor form in terms of safety, cost, fuel availability, and profitability. Various Gen IV reactor concepts and existing reactor examples have been examined and potential non-power applications of nuclear energy is investigated. The conclusion drawn upon the state-of-the-art reactor designs is that thorium-base molten salt small modular reactor is the most promising technical path to carry nuclear energy into the new era of meeting the market demand while maintaining utmost safety at an affordable capital cost.},
	language = {en},
	urldate = {2020-07-29},
	journal = {Annals of Nuclear Energy},
	author = {Zheng, Gangyang and Wu, Huali and Wang, Jipu and Chen, Sijuan and Zhang, Yunhuang},
	month = jun,
	year = {2018},
	keywords = {Commercial reactor, High temperature process heat, Isotope production, Molten salt reactor, Small modular reactor},
	pages = {177--186},
}

@article{di_lecce_simplified_2019,
	title = {Simplified 0-{D} semi-analytical model for fuel draining in molten salt reactors},
	volume = {5},
	issn = {2491-9292},
	url = {https://www.epj-n.org/10.1051/epjn/2019028},
	doi = {10.1051/epjn/2019028},
	abstract = {A key feature of molten salt reactors is the possibility to reconfigure the fuel geometry (actively or passively driven by gravitational forces) in case of accidents. In this regard, the design of reference molten salt reactor of Generation IV International Forum, the MSFR, foresees the Emergency core Draining System (EDS). Therefore, the research and development of MSFRs move in the direction to study and investigate the dynamics of the fuel salt when it is drained in case of accidental situations. In case of emergency, the salt could be drained out from the core, actively or passively triggered by melting of salt plugs, and stored into a draining tank underneath the core. During the draining transient, it is relevant from a safety point of view that thermal and mechanical damages to core internal surfaces and to EDS structure – caused by the temperature increase due to the decay heat – are avoided. In addition, the subcriticality of the fuel salt should be granted during all the draining transients. A simplified zero-dimensional semi-analytical model is developed in this paper to capture the multiphysics interactions, to separate and analyse the different physical phenomena involved and to focus on time evolutions of temperature and system reactivity. Results demonstrate that the fuel draining occurs in safe conditions, both from the thermal (temperature-related internal surface damages) and neutronic (sub-critical states dominate the transient) view points and show which are the main characteristics of the fuel salt draining transient.},
	language = {en},
	urldate = {2020-07-29},
	journal = {EPJ Nuclear Sciences \& Technologies},
	author = {Di Lecce, Francesco and Cammi, Antonio and Dulla, Sandra and Lorenzi, Stefano and Ravetto, Piero},
	editor = {Kloosterman, Jan Leen and Merle, Elsa and Ragusa, Jean},
	year = {2019},
	pages = {14},
}

@article{noauthor_infcirc153corrected_nodate,
	title = {{INFCIRC}/153({Corrected}) - {The} {Structure} and {Content} of {Agreements} {Between} the {Agency} and {States} {Required} in {Connection} with the {Treaty} on the {Non}-{Proliferation} of {Nuclear} {Weapons}},
	language = {en},
	pages = {34},
}

@article{ronen_242mam_2004,
	title = {{242mAm} fueled nuclear battery},
	volume = {531},
	issn = {0168-9002},
	url = {http://www.sciencedirect.com/science/article/pii/S0168900204011155},
	doi = {10.1016/j.nima.2004.04.238},
	abstract = {A nuclear battery based on the direct energy conversion of the fission products is presented. Such energy conversion is possible by using a nuclear reactor with ultra-thin fuel elements of 0.2μm of 242mAm. The amount of nuclear fuel is 376g and the dimensions of the battery are 2.4×2.4×2.4m3 (including the vacuum spacing), with a BeO moderator and Be electrodes. The total power of the reactor is 10.6MW and the electrical power is 0.652MW.},
	language = {en},
	number = {3},
	urldate = {2020-07-16},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	author = {Ronen, Yigal and Hatav, Amir and Hazenshprung, Nir},
	month = oct,
	year = {2004},
	keywords = {Am, Nuclear battery, Special reactor},
	pages = {639--644},
}

@techreport{collins_assessing_2011,
	title = {Assessing {Risk} and {Driving} {Risk} {Mitigation} for {First}-of-a-{Kind} {Advanced} {Reactors}},
	url = {https://www.osti.gov/biblio/1033880},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/CON-11-21720},
	urldate = {2020-07-11},
	institution = {Idaho National Laboratory (INL)},
	author = {Collins, John W.},
	month = sep,
	year = {2011},
}

@misc{noauthor_inis_nodate,
	title = {{INIS} {Repository} {Search} - {Single} {Result}},
	url = {https://inis.iaea.org/search/searchsinglerecord.aspx?recordsFor=SingleRecord&RN=23058145},
	urldate = {2020-07-11},
}

@article{andre_application_1989,
	title = {Application of probabilistic risk assessment in the design of {Westinghouse} advanced reactors},
	url = {http://inis.iaea.org/Search/search.aspx?orig_q=RN:23058145},
	language = {en},
	urldate = {2020-07-11},
	journal = {Probability, reliability, and safety assessment PSA '89},
	author = {Andre, G. R. and Schulz, T. L. and Iacovino, J. M.},
	year = {1989},
}

@article{nayak_role_2007,
	title = {Role of passive systems in advanced reactors},
	volume = {49},
	issn = {0149-1970},
	url = {http://www.sciencedirect.com/science/article/pii/S0149197007000686},
	doi = {10.1016/j.pnucene.2007.07.007},
	abstract = {In this paper, the role of passive systems in advanced reactor designs has been discussed. With large scale deployment of nuclear power reactors in future, the safety requirements in terms of risk for these future reactors would be different and more stringent than the existing reactors. In fact, some of these reactors are proposed to be built inside a population zone without having an exclusion zone. To achieve the higher safety standards in terms of reduction of risk, passive systems could play an important role by eliminating the requirements of operators or external inputs for their operation. However, it may be difficult or impossible to incorporate passive systems extensively in large size reactors, but could be well fit into small and medium sized reactors. Passive systems have several issues including their reliability, which must be resolved before incorporation of them into advanced designs. These are discussed in this paper.},
	language = {en},
	number = {6},
	urldate = {2020-07-11},
	journal = {Progress in Nuclear Energy},
	author = {Nayak, A. K. and Sinha, R. K.},
	month = aug,
	year = {2007},
	keywords = {Advanced reactors, Passive systems, Reliability, Safety},
	pages = {486--498},
}

@article{liu_design_2009,
	title = {Design and optimization of fuzzy-{PID} controller for the nuclear reactor power control},
	volume = {239},
	issn = {0029-5493},
	url = {http://www.sciencedirect.com/science/article/pii/S0029549309003215},
	doi = {10.1016/j.nucengdes.2009.07.001},
	abstract = {This paper introduces a fuzzy proportional-integral-derivative (fuzzy-PID) control strategy, and applies it to the nuclear reactor power control system. At the fuzzy-PID control strategy, the fuzzy logic controller (FLC) is exploited to extend the finite sets of PID gains to the possible combinations of PID gains in stable region and the genetic algorithm to improve the ‘extending’ precision through quadratic optimization for the membership function (MF) of the FLC. Thus the FLC tunes the gains of PID controller to adapt the model changing with the power. The fuzzy-PID has been designed and simulated to control the reactor power. The simulation results show the favorable performance of the fuzzy-PID controller.},
	language = {en},
	number = {11},
	urldate = {2020-07-06},
	journal = {Nuclear Engineering and Design},
	author = {Liu, Cheng and Peng, Jin-Feng and Zhao, Fu-Yu and Li, Chong},
	month = nov,
	year = {2009},
	pages = {2311--2316},
}

@techreport{donoghue_preapplication_1994,
	title = {Preapplication safety evaluation report for the {Power} {Reactor} {Innovative} {Small} {Module} ({PRISM}) liquid-metal reactor. {Final} report},
	url = {http://www.osti.gov/servlets/purl/10133164-2ZfTJr/native/},
	language = {en},
	number = {NUREG--1368, 10133164},
	urldate = {2020-07-03},
	author = {Donoghue, J.E. and Donohew, J.N. and Golub, G.R. and Kenneally, R.M. and Moore, P.B. and Sands, S.P. and Throm, E.D. and Wetzel, B.A.},
	month = feb,
	year = {1994},
	doi = {10.2172/10133164},
	pages = {NUREG--1368, 10133164},
}

@inproceedings{ohara_human_2011,
	address = {London},
	title = {Human {Performance} and {Plant} {Safety} {Performance}},
	isbn = {978-0-85729-003-8},
	doi = {10.1007/978-0-85729-003-8_6},
	abstract = {New nuclear power plants (NPPs) employ digital instrumentation, control systems and computer-based human–system interfaces (HSIs) that possess tremendous functional capability and an ability to display information that is limited only by the imagination of the designer. Thus the industry is seeing a proliferation of approaches to information system design. A question arises as to how one should decide which approaches to use in control rooms. The purpose of this chapter is to address this question; more specifically to propose an approach to evaluating new and novel HSI in NPP and other complex human–machine systems in the context of human factors and plant safety performance. Our approach provides a decision-making context that considers the design approach as well as its products.},
	language = {en},
	booktitle = {Simulator-based {Human} {Factors} {Studies} {Across} 25 {Years}},
	publisher = {Springer},
	author = {O’Hara, John M. and Persensky, J.},
	editor = {Skjerve, Ann Britt and Bye, Andreas},
	year = {2011},
	keywords = {Control Room, Human Performance, Nuclear Power Plant, Secondary Task, Situation Model},
	pages = {91--106},
}

@techreport{joe_effects_2014,
	title = {Effects of an {Advanced} {Reactor}’s {Design}, {Use} of {Automation}, and {Mission} on {Human} {Operators}},
	url = {https://www.osti.gov/biblio/1149006},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {INL/CON-14-31341},
	urldate = {2020-06-25},
	institution = {Idaho National Laboratory (INL)},
	author = {Joe, Jeffrey C. and Oxstrand, Johanna H.},
	month = jun,
	year = {2014},
}

@article{noauthor_epa_nodate,
	title = {{EPA} {FACTS} {ABOUT} {STRONTIUM}-90},
	language = {en},
	pages = {2},
}

@article{evangeliou_resuspension_2016,
	title = {Resuspension and atmospheric transport of radionuclides due to wildfires near the {Chernobyl} {Nuclear} {Power} {Plant} in 2015: {An} impact assessment},
	volume = {6},
	issn = {2045-2322},
	shorttitle = {Resuspension and atmospheric transport of radionuclides due to wildfires near the {Chernobyl} {Nuclear} {Power} {Plant} in 2015},
	url = {http://www.nature.com/articles/srep26062},
	doi = {10.1038/srep26062},
	language = {en},
	number = {1},
	urldate = {2020-06-13},
	journal = {Scientific Reports},
	author = {Evangeliou, N. and Zibtsev, S. and Myroniuk, V. and Zhurba, M. and Hamburger, T. and Stohl, A. and Balkanski, Y. and Paugam, R. and Mousseau, T. A. and Møller, A. P. and Kireev, S. I.},
	month = may,
	year = {2016},
	pages = {26062},
}

@article{yoschenko_radioactive_2018,
	title = {Radioactive contaminated forests in {Fukushima} and {Chernobyl}},
	volume = {23},
	issn = {1341-6979, 1610-7403},
	url = {https://www.tandfonline.com/doi/full/10.1080/13416979.2017.1356681},
	doi = {10.1080/13416979.2017.1356681},
	abstract = {This paper compares the scale and consequences of radioactive contamination of forest ecosystems following the Chernobyl and Fukushima accidents. The Chernobyl deposition in the zone closest to the reactor site (the “near zone”) presently consists of 137Cs, 90Sr and isotopes of transuranium elements, while the only long-lived radionuclide in the Fukushima release was 137Cs. Radiocesium deposition levels in the near zones of the two accidents are similar. We compare the effects of radiation on forest ecosystems and forestry following the two accidents. Acute radiation after the Chernobyl accident caused death of Scots pine (Pinus sylvestris L.) forests close to the power plant and created zones of sublethal and moderate damage at greater distances. Acute radiation dose rates were much lower after the Fukushima accident, and lethal damage to forest species was not reported. Under chronic radiation conditions, the same morphological abnormalities (cancelling of apical dominance) occurred in young populations of Scots pine in the Chernobyl zone and Japanese red pine (Pinus densiflora Siebold \& Zucc.) and Japanese fir (Abies firma Siebold \& Zucc.) in the Fukushima zone. During the early stages after both accidents, a general trend of gradual decrease of radionuclide inventories in aboveground forest biomass occurred due to leaching with precipitations and removal with litterfall. In Chernobyl forests under certain conditions, this was followed by a period of increase of radionuclide inventories in the biomass due to root uptake. The radiocesium root uptake parameters for a wide variety of forest species, types, and soil conditions must be determined for prognosis of further redistribution in Fukushima forests.},
	language = {en},
	number = {1},
	urldate = {2020-06-06},
	journal = {Journal of Forest Research},
	author = {Yoschenko, Vasyl and Ohkubo, Tatsuhiro and Kashparov, Valery},
	month = jan,
	year = {2018},
	pages = {3--14},
}

@book{sprinkle_international_2013,
	title = {International safeguards in nuclear facility design and construction},
	url = {http://www-pub.iaea.org/MTCD/Publications/PDF/Pub1600_web.pdf},
	abstract = {"This IAEA publication provides guidance on the inclusion of safeguards considerations in nuclear facility design and construction. This first volume introduces the basic principles of Safeguards by design and discusses the goals, costs and rewards, and places the information into the context of nuclear facility design and construction. Benefits and opportunities for all stakeholders are emphasized. The guidance is aimed at enhancing the understanding of nuclear facility vendors and designers regarding the safeguards obligations of both States and the IAEA, at improving the cooperation between all stakeholders in safeguards implementation, and at minimizing the cost of implementation for all stakeholders."--Publisher's description.},
	language = {en},
	urldate = {2020-06-02},
	author = {Sprinkle, J. K and Kovacic, D and {International Atomic Energy Agency}},
	year = {2013},
	note = {OCLC: 857243373},
}

@article{uspuras_safety_2007,
	title = {Safety analysis of beyond design basis accidents in {RBMK}-1500 reactors},
	volume = {34},
	issn = {0306-4549},
	url = {http://www.sciencedirect.com/science/article/pii/S0306454907000357},
	doi = {10.1016/j.anucene.2007.01.011},
	abstract = {At present the design basis accidents for RBMK-1500 are rather thoroughly investigated. The performed analyses helped to develop and implement a number of safety modifications. Further plant safety enhancement requires developing emergency procedures that would enable beyond design basis accidents management by preventing core damage or mitigating consequences of severe accidents. This paper presents results of Ignalina NPP Level 1 and Level 2 probabilistic safety assessment and their use for development of beyond design basis accidents list. The most important phenomena for RBMK type reactor severe accident management are described. The paper also presents physical processes that occur in an overheated reactor core and discusses its cooling capabilities. The discussion also includes processes that occur in the reactor and primary circuit surrounding compartments, i.e. confinement. A number of recommendations on accident processes management are presented.},
	language = {en},
	number = {5},
	urldate = {2020-05-29},
	journal = {Annals of Nuclear Energy},
	author = {Ušpuras, E. and Kaliatka, A. and Augutis, J. and Rimkevičius, S. and Urbonavičius, E. and Kopustinskas, V.},
	month = may,
	year = {2007},
	pages = {356--373},
}

@article{kopustinskas_dynamic_2005,
	title = {Dynamic reliability and risk assessment of the accident localization system of the {Ignalina} {NPP} {RBMK}-1500 reactor},
	volume = {87},
	issn = {0951-8320},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832004001024},
	doi = {10.1016/j.ress.2004.04.010},
	abstract = {The paper presents reliability and risk analysis of the RBMK-1500 reactor accident localization system (ALS) (confinement), which prevents radioactive releases to the environment. Reliability of the system was estimated and compared by two methods: the conventional fault tree method and an innovative dynamic reliability model, based on stochastic differential equations. Frequency of radioactive release through ALS was also estimated. The results of the study indicate that conventional fault tree modeling techniques in this case apply high degree of conservatism in the system reliability estimates. One of the purposes of the ALS reliability study was to demonstrate advantages of the dynamic reliability analysis against the conventional fault/event tree methods. The Markovian framework to deal with dynamic aspects of system behavior is presented. Although not analyzed in detail, the framework is also capable of accounting for non-constant component failure rates. Computational methods are proposed to solve stochastic differential equations, including analytical solution, which is possible only for relatively small and simple systems. Other numerical methods, like Monte Carlo and numerical schemes of differential equations are analyzed and compared. The study is finalized with concluding remarks regarding both the studied system reliability and computational methods used.},
	language = {en},
	number = {1},
	urldate = {2020-05-29},
	journal = {Reliability Engineering \& System Safety},
	author = {Kopustinskas, V. and Augutis, J. and Rimkevičius, S.},
	month = jan,
	year = {2005},
	keywords = {Dynamic reliability, Level 2 PSA, RBMK-1500, Risk assessment, Stochastic differential equations},
	pages = {77--87},
}

@book{meyers_effective_2014,
	title = {Effective {Modern} {C}++: 42 {Specific} {Ways} to {Improve} {Your} {Use} of {C}++11 and {C}++14},
	isbn = {978-1-4919-0399-5},
	shorttitle = {Effective {Modern} {C}++},
	abstract = {Coming to grips with C++11 and C++14 is more than a matter of familiarizing yourself with the features they introduce (e.g., auto type declarations, move semantics, lambda expressions, and concurrency support). The challenge is learning to use those features effectively--so that your software is correct, efficient, maintainable, and portable. That's where this practical book comes in. It describes how to write truly great software using C++11 and C++14--i.e. using modern C++.Topics include: The pros and cons of braced initialization, noexcept specifications, perfect forwarding, and smart pointer make functionsThe relationships among std:: move, std:: forward, rvalue references, and universal referencesTechniques for writing clear, correct, effective lambda expressionsHow std:: atomic differs from volatile, how each should be used, and how they relate to C++'s concurrency APIHow best practices in "old" C++ programming (i.e., C++98) require revision for software development in modern C++Effective Modern C++ follows the proven guideline-based, example-driven format of Scott Meyers' earlier books, but covers entirely new material."After I learned the C++ basics, I then learned how to use C++ in production code from Meyer's series of Effective C++ books. Effective Modern C++ is the most important how-to book for advice on key guidelines, styles, and idioms to use modern C++ effectively and well. Don't own it yet? Buy this one. Now."-- Herb Sutter, Chair of ISO C++ Standards Committee and C++ Software Architect at Microsoft},
	language = {en},
	publisher = {O'Reilly},
	author = {Meyers, Scott},
	year = {2014},
	note = {Google-Books-ID: I5\_joAEACAAJ},
	keywords = {Computers / Computer Engineering, Computers / Programming Languages / C, Computers / Programming Languages / General},
}

@book{stroustrup_tour_2013,
	title = {A {Tour} of {C}++},
	isbn = {978-0-13-354900-3},
	abstract = {The C++11 standard allows programmers to express ideas more clearly, simply, and directly, and to write faster, more efficient code. Bjarne Stroustrup, the designer and original implementer of C++, thoroughly covers the details of this language and its use in his definitive reference, The C++ Programming Language, Fourth Edition.    In  A Tour of C++ , Stroustrup excerpts the overview chapters from that complete reference, expanding and enhancing them to give an experienced programmer–in just a few hours–a clear idea of what constitutes modern C++. In this concise, self-contained guide, Stroustrup covers most major language features and the major standard-library components–not, of course, in great depth, but to a level that gives programmers a meaningful overview of the language, some key examples, and practical help in getting started.    Stroustrup presents the C++ features in the context of the programming styles they support, such as object-oriented and generic programming. His tour is remarkably comprehensive. Coverage begins with the basics, then ranges widely through more advanced topics, including many that are new in C++11, such as move semantics, uniform initialization, lambda expressions, improved containers, random numbers, and concurrency. The tour ends with a discussion of the design and evolution of C++ and the extensions added for C++11.    This guide does not aim to teach you how to program (see Stroustrup’s Programming: Principles and Practice Using C++ for that); nor will it be the only resource you’ll need for C++ mastery (see Stroustrup’s The C++ Programming Language, Fourth Edition, for that). If, however, you are a C or C++ programmer wanting greater familiarity with the current C++ language, or a programmer versed in another language wishing to gain an accurate picture of the nature and benefits of modern C++, you can’t find a shorter or simpler introduction than this tour provides.},
	language = {en},
	publisher = {Addison-Wesley},
	author = {Stroustrup, Bjarne},
	month = sep,
	year = {2013},
	note = {Google-Books-ID: EXfcAAAAQBAJ},
	keywords = {Computers / Programming Languages / C},
}

@book{stroustrup_programming_2014,
	title = {Programming: {Principles} and {Practice} {Using} {C}++},
	isbn = {978-0-321-99278-9},
	shorttitle = {Programming},
	abstract = {An Introduction to Programming by the Inventor of C++   Preparation for Programming in the Real World The book assumes that you aim eventually to write non-trivial programs, whether for work in software development or in some other technical field.   Focus on Fundamental Concepts and Techniques The book explains fundamental concepts and techniques in greater depth than traditional introductions. This approach will give you a solid foundation for writing useful, correct, maintainable, and efficient code.   Programming with Today's C++ (C++11 and C++14) The book is an introduction to programming in general, including object-oriented programming and generic programming. It is also a solid introduction to the C++ programming language, one of the most widely used languages for real-world software. The book presents modern C++ programming techniques from the start, introducing the C++ standard library and C++11 and C++14 features to simplify programming tasks.   For Beginners--And Anyone Who Wants to Learn Something New The book is primarily designed for people who have never programmed before, and it has been tested with many thousands of first-year university students. It has also been extensively used for self-study. Also, practitioners and advanced students have gained new insight and guidance by seeing how a master approaches the elements of his art.   Provides a Broad View The first half of the book covers a wide range of essential concepts, design and programming techniques, language features, and libraries. Those will enable you to write programs involving input, output, computation, and simple graphics. The second half explores more specialized topics (such as text processing, testing, and the C programming language) and provides abundant reference material. Source code and support supplements are available from the author's website.},
	language = {en},
	publisher = {Pearson Education},
	author = {Stroustrup, Bjarne},
	year = {2014},
	note = {Google-Books-ID: hxOpAwAAQBAJ},
	keywords = {Computers / Programming Languages / C},
}

@misc{stroustrup_c_nodate,
	title = {C++ {Core} {Guidelines}},
	url = {http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#main},
	urldate = {2020-05-15},
	author = {Stroustrup, Bjarne and Sutter, Herb},
}

@book{roth_clean_2017,
	title = {Clean {C}++: {Sustainable} {Software} {Development} {Patterns} and {Best} {Practices} with {C}++ 17},
	isbn = {978-1-4842-2793-0},
	shorttitle = {Clean {C}++},
	abstract = {Write maintainable, extensible, and durable software with modern C++. This book is a must for every developer, software architect, or team leader who is interested in good C++ code, and thus also wants to save development costs. If you want to teach yourself about writing clean C++, Clean C++ is exactly what you need. It is written to help C++ developers of all skill levels and shows by example how to write understandable, flexible, maintainable, and efficient C++ code. Even if you are a seasoned C++ developer, there are nuggets and data points in this book that you will find useful in your work.If you don't take care with your code, you can produce a large, messy, and unmaintainable beast in any programming language. However, C++ projects in particular are prone to be messy and tend to slip into bad habits. Lots of C++ code that is written today looks as if it was written in the 1980s.It seems that C++ developers have been forgotten by those who preach Software Craftsmanship and Clean Code principles. The Web is full of bad, but apparently very fast and highly optimized C++ code examples, with cruel syntax that completely ignores elementary principles of good design and well-written code. This book will explain how to avoid this scenario and how to get the most out of your C++ code. You'll find your coding becomes more efficient and, importantly, more fun.What You'll LearnGain sound principles and rules for clean coding in C++Carry out test driven development (TDD)Discover C++ design patterns and idiomsApply these design patternsWho This Book Is ForAny C++ developer and software engineer with an interest in producing better code.},
	language = {en},
	publisher = {Apress},
	author = {Roth, Stephan},
	month = sep,
	year = {2017},
	note = {Google-Books-ID: 9JY3DwAAQBAJ},
	keywords = {Computers / Programming / General, Computers / Programming Languages / General, Computers / Software Development \& Engineering / General},
}

@article{pollanen_transport_1997,
	title = {Transport of radioactive particles from the chernobyl accident},
	volume = {31},
	issn = {13522310},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1352231097001568},
	doi = {10.1016/S1352-2310(97)00156-8},
	abstract = {After the Chernobyl accident large and highly radioactive particles were found in several European countries. Particles {\textgreater} 20 \#m in aerodynamicdiameter were transported hundreds of kilometres from the plant, and they were sufficientlyactive ({\textgreater} 100 kBq) to cause acute health hazards. Here, a particle trajectory model is used to identify the areas of large particle fallout. Effectiverelease height of the particles and atmospheric phenomena related to their transport are investigated by comparing particlefindings with locations given by trajectory calculations. The calculations showed that in the Chernobyl accident either the maximum effective release height must have been considerably higher than previously reported ({\textgreater} 2000 m)or convective warm air currents may have lifted radioactivematerial upwards during transport. Large particles have been transported to other areas than small particles and gaseous species. The particulate nature of the release plume must be taken into account in dispersion and transport analyses. Air parcel trajectoriesalone are not necessarily sufficientfor identifying the fallout area of radioactivematerial. © 1997 Elsevier Science Ltd.},
	language = {en},
	number = {21},
	urldate = {2020-05-15},
	journal = {Atmospheric Environment},
	author = {Pöllänen, Roy and Valkama, Ilkka and Toivonen, Harri},
	month = nov,
	year = {1997},
	pages = {3575--3590},
}

@article{pollanen_transport_nodate,
	title = {Transport of {Large} {Particles} {Released} in a {Nuclear} {Accident}},
	abstract = {Highly radioactive particulate material may be released in a nuclear accident or sometimes during normal operation of a nuclear power plant. However, consequence analyses related to radioactive releases are often performed neglecting the particle nature of the release. The properties of the particles have an important role in the radiological hazard. A particle deposited on the skin may cause a large and highly non-uniform skin beta dose. Skin dose limits may be exceeded although the overall activity concentration in air is below the level of countermeasures. For sheltering purposes it is crucial to find out the transport range, i.e. the travel distance of the particles. A method for estimating the transport range of large particles (aerodynamic diameter da {\textgreater} 20 urn) in simplified meteorological conditions is presented. A user-friendly computer code, known as TROP, is developed for fast range calculations in a nuclear emergency.},
	language = {en},
	author = {Pöllänen, R and Toivonen, H and Lahtinen, J and Ilander, T},
	pages = {42},
}

@book{martin_clean_2009,
	title = {Clean {Code}: {A} {Handbook} of {Agile} {Software} {Craftsmanship}},
	isbn = {978-0-13-235088-4},
	shorttitle = {Clean {Code}},
	abstract = {Even bad code can function. But if code isn't clean, it can bring a development organization to its knees. Every year, countless hours and significant resources are lost because of poorly written code. But it doesn't have to be that way.  Noted software expert Robert C. Martin presents a revolutionary paradigm with Clean Code: A Handbook of Agile Software Craftsmanship . Martin has teamed up with his colleagues from Object Mentor to distill their best agile practice of cleaning code "on the fly" into a book that will instill within you the values of a software craftsman and make you a better programmer--but only if you work at it.  What kind of work will you be doing? You'll be reading code--lots of code. And you will be challenged to think about what's right about that code, and what's wrong with it. More importantly, you will be challenged to reassess your professional values and your commitment to your craft.  Clean Code is divided into three parts. The first describes the principles, patterns, and practices of writing clean code. The second part consists of several case studies of increasing complexity. Each case study is an exercise in cleaning up code--of transforming a code base that has some problems into one that is sound and efficient. The third part is the payoff: a single chapter containing a list of heuristics and "smells" gathered while creating the case studies. The result is a knowledge base that describes the way we think when we write, read, and clean code.  Readers will come away from this book understanding  How to tell the difference between good and bad code How to write good code and how to transform bad code into good code How to create good names, good functions, good objects, and good classes How to format code for maximum readability How to implement complete error handling without obscuring code logic How to unit test and practice test-driven development  This book is a must for any developer, software engineer, project manager, team lead, or systems analyst with an interest in producing better code.},
	language = {en},
	publisher = {Pearson Education},
	author = {Martin, Robert C.},
	year = {2009},
	note = {Google-Books-ID: hjEFCAAAQBAJ},
	keywords = {Computers / Software Development \& Engineering / General},
}

@misc{development_particle_nodate,
	title = {Particle {Transport} of {Radionuclides} {Following} a {Radiological} {Incident}},
	url = {https://cfpub.epa.gov/si/si_public_record_report.cfm?Lab=NHSRC&dirEntryId=308267},
	abstract = {Report The findings of this literature review support is a need for research in the transport of radioactive contaminants in urban areas, coupled with more stringent computer modeling capabilities to better articulate these phenomena.},
	language = {en},
	urldate = {2020-05-12},
	author = {Development, Office of Research \&},
	note = {Library Catalog: cfpub.epa.gov},
}

@inproceedings{noauthor_nmac_nodate,
	title = {{NMAC} systems},
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	isbn = {978-0-262-33737-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	language = {en},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	month = nov,
	year = {2016},
	note = {Google-Books-ID: omivDQAAQBAJ},
	keywords = {Computers / Computer Science, Computers / Intelligence (AI) \& Semantics},
}

@misc{noauthor_introduction_nodate,
	title = {Introduction to {Nuclear} {Engineering} and {Ionizing} {Radiation}},
	url = {https://ocw.mit.edu/courses/nuclear-engineering/22-01-introduction-to-nuclear-engineering-and-ionizing-radiation-fall-2016/},
	abstract = {This course provides an introduction to nuclear science and its engineering applications. It describes basic nuclear models, radioactivity, nuclear reactions, and kinematics; covers the interaction of ionizing radiation with matter, with an emphasis on radiation detection, radiation shielding, and radiation effects on human health; and presents energy systems based on fission and fusion nuclear reactions, as well as industrial and medical applications of nuclear science.},
	language = {en},
	urldate = {2020-04-24},
	journal = {MIT OpenCourseWare},
}

@misc{noauthor_ocw_nodate,
	title = {{OCW} {Course} {Index} {\textbar} {MIT} {OpenCourseWare} {\textbar} {Free} {Online} {Course} {Materials}},
	url = {https://ocw.mit.edu/courses/},
	abstract = {Unlocking knowledge, empowering minds. Free course notes, videos, instructor insights and more from MIT.},
	language = {en},
	urldate = {2020-04-24},
}

@article{dacre_improved_2020,
	title = {Improved representation of particle size and solubility in model simulations of atmospheric dispersion and wet-deposition from {Fukushima}},
	volume = {217},
	issn = {0265931X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0265931X19306691},
	doi = {10.1016/j.jenvrad.2020.106193},
	abstract = {Radionuclides released into the atmosphere following the Fukushima Dai-ichi Nuclear Power Plant (FDNPP) accident were detected by ground-based monitoring stations worldwide. The inter-continental dispersion of radionuclides provides a unique opportunity to evaluate the ability of atmospheric dispersion models to represent the processes controlling their transport and deposition in the atmosphere. Co-located measurements of radioxenon (133Xe) and caesium (137Cs) concentrations enable individual physical processes (dispersion, dry and wet deposition) to be iso­ lated. In this paper we focus on errors in the prediction of 137Cs attributed to the representation of particle size and solubility, in the process of modelling wet deposition. Simulations of 133Xe and 137Cs concentrations using the UK Met Office NAME (Numerical Atmospheric-dispersion Modelling Environment) model are compared with CTBTO (Comprehensive Nuclear-Test-Ban Treaty Organisation) surface station measurements. NAME predictions of 137Cs using a bulk wet deposition parameterisation (which does not account for particle size dependent scavenging or solubility) significantly underestimate observed 137Cs. When a binned wet deposition parameterisation is imple­ mented (which accounts for particle size dependent scavenging) the correlations between modelled and observed air concentrations improve at all 9 of the Northern Hemisphere sites studied and the respective RMSLE (root-meansquare-log-error) decreases by a factor of 7 due to a decrease in the wet-deposition of Aitken and Accumulation mode particles. Finally, NAME simulations were performed in which insoluble submicron particles are represented. Rep­ resenting insoluble particles in the NAME simulations improves the RMSLE at all sites further by a factor of 7. Thus NAME is able to predict 137Cs with good accuracy (within a factor of 10 of observed 137Cs values) at distances greater than 10,000 km from FDNPP only if insoluble submicron particles are considered in the description of the source. This result provides further evidence of the presence of insoluble Cs-rich microparticles in the release following the accident at FDNPP and suggests that these small particles travelled across the Pacific Ocean to the US and further across the North Atlantic Ocean towards Europe.},
	language = {en},
	urldate = {2020-04-17},
	journal = {Journal of Environmental Radioactivity},
	author = {Dacre, H.F. and Bedwell, P. and Hertwig, D. and Leadbetter, S.J. and Loizou, P. and Webster, H.N.},
	month = jun,
	year = {2020},
	pages = {106193},
}

@misc{noauthor_toward_nodate,
	title = {Toward a {National} {Transportation} {Effort}\_article.pdf},
}

@article{brayfindley_automated_2018,
	title = {Automated {Defect} {Detection} in {Spent} {Nuclear} {Fuel} {Using} {Combined} {Cerenkov} {Radiation} and {Gamma} {Emission} {Tomography} {Data}},
	volume = {204},
	issn = {0029-5450},
	url = {https://doi.org/10.1080/00295450.2018.1490123},
	doi = {10.1080/00295450.2018.1490123},
	abstract = {Spent fuel monitoring and characterization has been central to safeguards and nuclear facility monitoring for many years. The Digital Cerenkov Viewing Device (DCVD) has been used since the 1980s as a method of defect detection in spent fuel. In recent years, the accounting for large quantities of spent fuel before storage has renewed interest in this relatively quick and inexpensive method. This has an impact not only in safeguards, but also for nuclear power facilities, as accounting can be a long, arduous, and costly process. Additionally, the DCVD demonstrates limited accuracy in more complex cases such as substitution of a fuel rod with steel or a partial defect detection. A second method, gamma emission tomography (GET) has been explored as an improved defect detection method, but is much more expensive and invasive than DCVD. The present investigation identifies deficiencies in both methods and proposes a combination of data gathered from each method to address these deficiencies for improved spent fuel characterization. Initial results are promising, showing 97\% detection of a single missing fuel rod when the data types are combined, versus approximately 50\% and 70\%, respectively, for DCVD and GET data on their own. These classification results are obtained with algorithms derived from facial recognition and applied to this problem, yielding unique accuracy in near real time while also maintaining the information barrier between output and measurement desired in safeguards.},
	number = {3},
	urldate = {2020-04-11},
	journal = {Nuclear Technology},
	author = {Brayfindley, Eva and Smith, Ralph C. and Mattingly, John and Brigantic, Robert},
	month = dec,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00295450.2018.1490123},
	keywords = {Digital Cerenkov Viewing Device, image analysis, spent fuel characterization, tomography},
	pages = {343--353},
}

@article{rockwood_vienna_nodate,
	title = {Vienna {Center} for {Disarmament} and {Non}-{Proliferation} {Vienna}, {Austria}},
	language = {en},
	author = {Rockwood, Laura and Mayhew, Noah and Lazarev, Artem and Pfneisl, Mara},
	pages = {76},
}

@article{bal_preventing_2018,
	title = {Preventing {Proliferation}: {Tracking} {Uranium} on the {Blockchain}},
	abstract = {Advances in technology, the shifting sands of the global nuclear energy market, and the extant standards and practices surrounding the monitoring of radioactive materials raise important questions about the future of nuclear security. Technological advancements have enabled the retrieval of radioactive materials from unconventional sources and made fuel fabrication easier. The emergence of new players in the nuclear energy market also flags concerns about the ability of these nations to track and secure nuclear material within their borders. As nuclear terrorism becomes an increasingly real threat, newer measures must be introduced to securely monitor the movement of radioactive materials. This brief argues that a blockchain-based tracking system may help overcome current monitoring deficits in the trade of radioactive materials and help check proliferation in the process.},
	language = {en},
	number = {235},
	author = {Bal, Meghna},
	year = {2018},
	pages = {16},
}

@techreport{frazar_exploratory_2017,
	title = {Exploratory study on potential safeguards applications for shared ledger technology},
	url = {http://www.osti.gov/servlets/purl/1413394/},
	language = {en},
	number = {PNNL--26229, 1413394},
	urldate = {2020-04-11},
	author = {Frazar, Sarah L. and Jarman, Kenneth D. and Joslyn, Cliff A. and Kreyling, Sean J. and Sayre, Amanda M. and Schanfein, Mark J. and West, Curtis L. and Winters, Samuel T.},
	month = feb,
	year = {2017},
	doi = {10.2172/1413394},
	pages = {PNNL--26229, 1413394},
}

@article{brady_politics_1973,
	title = {The {Politics} of {Regulation}: the {Case} of the {Atomic} {Energy} {Commission} and the {Nuclear} {Industry}},
	volume = {1},
	issn = {0044-7803},
	shorttitle = {The {Politics} of {Regulation}},
	url = {http://journals.sagepub.com/doi/10.1177/1532673X7300100304},
	doi = {10.1177/1532673X7300100304},
	language = {en},
	number = {3},
	urldate = {2020-04-11},
	journal = {American Politics Quarterly},
	author = {Brady, David and Althoff, Phillip},
	month = jul,
	year = {1973},
	pages = {361--384},
}

@techreport{farley_industrial_2018,
	title = {Industrial {Internet}-of-{Things} \& {Data} {Analytics} for {Nuclear} {Power} \& {Safeguards}.},
	url = {http://www.osti.gov/servlets/purl/1481947/},
	abstract = {Data analytics applied to nuclear power operations and nuclear safeguards is in a nascent state, yet some significant initial efforts are being undertaken by industry and academia. This report highlights our findings as to the current state-of-the-art of such efforts, in particular considering the Industrial Internet-of-Things aspect ofthis work, as well as an investigation into the utility of machine learning tools being developed for other industries. Blockchain applications were also studied. A consideration was undertaken into how to apply data analytics and machine learning to nuclear power and safeguards within the realm of Probabilistic Risk Assessments (PRAs), predictive maintenance \& edge analytics, and proprietary data sharing.},
	language = {en},
	number = {SAND2018-12807, 1481947},
	urldate = {2020-04-11},
	author = {Farley, David Rushton and Negus, Mitch G. and Slaybaugh, Rachel N.},
	month = nov,
	year = {2018},
	doi = {10.2172/1481947},
	pages = {SAND2018--12807, 1481947},
}

@article{locatelli_why_nodate,
	title = {{WHY} {ARE} {MEGAPROJECTS}, {INCLUDING} {NUCLEAR} {POWER} {PLANTS}, {DELIVERED} {OVERBUDGET} {AND} {LATE}? {REASONS} {AND} {REMEDIES}},
	language = {en},
	author = {Locatelli, Dr Giorgio},
	pages = {28},
}

@inproceedings{jung_advanced_2010,
	address = {Bellevue, Washington, USA},
	title = {Advanced {Construction} {Methods} for {New} {Nuclear} {Power} {Plants}},
	isbn = {978-0-7918-4928-6 978-0-7918-3878-5},
	url = {https://asmedigitalcollection.asme.org/PVP/proceedings/PVP2010/49286/55/345124},
	doi = {10.1115/PVP2010-25369},
	abstract = {This paper covers advanced construction technologies that are generally used for nuclear power plants and presents advanced construction methods that can contribute to an efficient and short construction schedule. The construction schedule is driven by the activities of the critical path. The advanced construction methods consist of Modularization, Improvement of Mechanical Rebar splices, Application of 3D-CAD system for information and control, and the installation of RVI and RCL at the same time. Some methods have been applied in actual Nuclear power projects and others have been developing under the research and development program. It incorporates the experiences and insights from recent nuclear construction projects all over the world.},
	language = {en},
	urldate = {2020-04-11},
	booktitle = {{ASME} 2010 {Pressure} {Vessels} and {Piping} {Conference}: {Volume} 9},
	publisher = {ASMEDC},
	author = {Jung, Dae-Yul and Kang, Yoon-Kee and You, Chang-Hyung},
	month = jan,
	year = {2010},
	pages = {55--59},
}

@article{ni_markov_2005,
	title = {Markov {Chain} {Monte} {Carlo} {Multiple} {Imputation} {Using} {Bayesian} {Networks} for {Incomplete} {Intelligent} {Transportation} {Systems} {Data}},
	volume = {1935},
	issn = {0361-1981},
	url = {https://doi.org/10.1177/0361198105193500107},
	doi = {10.1177/0361198105193500107},
	abstract = {The rich data on intelligent transportation systems (ITS) are a precious resource for transportation researchers and practitioners. However, the usability of this resource is greatly limited by missing data. Many imputation methods have been proposed in the past decade. However, some issues are still not addressed or are not sufficiently addressed, for example, the missing of entire records, temporal correlation in observations, natural characteristics in raw data, and unbiased estimates for missing values. This paper proposes an advanced imputation method based on recent development in other disciplines, especially applied statistics. The method uses a Bayesian network to learn from the raw data and a Markov chain Monte Carlo technique to sample from the probability distributions learned by the Bayesian network. It imputes the missing data multiple times and makes statistical inferences about the result. In addition, the method incorporates a time series model so that it allows data missing in entire rows–-an unfavorable missing pattern frequently seen in ITS data. Empirical study shows that the proposed method is robust and accurate. It is ideal for use as a high-quality imputation method for off-line application.},
	language = {en},
	number = {1},
	urldate = {2020-03-28},
	journal = {Transportation Research Record},
	author = {Ni, Daiheng and Leonard, John D.},
	month = jan,
	year = {2005},
	pages = {57--67},
}

@inproceedings{baouya_probabilistic_2015,
	title = {A probabilistic and timed verification approach of {SysML} state machine diagram},
	doi = {10.1109/ISPS.2015.7245001},
	abstract = {Timed-constrained and probabilistic verification approaches gain a great importance in system behavior validation. They enable the evaluation of system behavior according to the design requirements and ensure their correctness before any implementation. In this paper, we propose a probabilistic and timed verification framework of State Machine diagrams extended with time and probability features. The approach consists on mapping the extended State Machine diagram to its equivalent probabilistic timed automata that is expressed in PRISM language. To check the functional correctness of the system under test, the properties are expressed in PCTL temporal logic. We demonstrate the approach efficiency by analyzing performability properties on a Automatic Teller Machine (ATM) case study.},
	booktitle = {2015 12th {International} {Symposium} on {Programming} and {Systems} ({ISPS})},
	author = {Baouya, A. and Bennouar, D. and Mohamed, O. A. and Ouchani, S.},
	month = apr,
	year = {2015},
	keywords = {ATM, Automata, Clocks, Junctions, MARTE, Model Checking, Model checking, PCTL, PCTL temporal logic, PRISM language, Probabilistic Timed Automata, Probabilistic logic, Real-time systems, State Machine Diagram, SysML, SysML state machine diagram, Unified modeling language, automatic teller machine, design requirements, finite state machines, formal verification, functional correctness, probabilistic automata, probabilistic timed automata, probabilistic verification approach, state machine diagram mapping, system behavior evaluation, system behavior validation, temporal logic, timed-constrained verification approaches},
	pages = {1--9},
}

@article{jakjoud_automatic_2014,
	title = {Automatic {Generation} of {Ontology} from {Data} {Source} {Directed} by {Meta} {Models}},
	volume = {8},
	abstract = {Through this paper we present a method for automatic generation of ontological model from any data source using Model Driven Architecture (MDA), this generation is dedicated to the cooperation of the knowledge engineering and software engineering. Indeed, reverse engineering of a data source generates a software model (schema of data) that will undergo transformations to generate the ontological model. This method uses the meta-models to validate software and ontological models.},
	language = {en},
	number = {10},
	author = {Jakjoud, Widad and Bahaj, Mohamed and Bakkas, Jamal},
	year = {2014},
	pages = {6},
}

@phdthesis{leinhos_owl_2006,
	address = {Munich, Germany},
	type = {Diplomarbeit},
	title = {{OWL} ontology extraction from {UML} class diagrams and {UML}-based ontology modelling. {A} practical approach to an automatic transformation.},
	url = {http://diplom.ooyoo.de},
	school = {University of the Federal Armed Forces Munich},
	author = {Leinhos, S.},
	year = {2006},
}

@inproceedings{machida_composing_2013,
	address = {Pasadena, CA, USA},
	title = {Composing hierarchical stochastic model from {SysML} for system availability analysis},
	isbn = {978-1-4799-2366-3},
	url = {http://ieeexplore.ieee.org/document/6698904/},
	doi = {10.1109/ISSRE.2013.6698904},
	abstract = {Comprehensive analytic model for system availability analysis often confronts the largeness issue where a system designer cannot easily handle the model and the solution is not given in a feasible solution time. Hierarchical decomposition of a large state-space model gives a promising solution to the largeness issue when the model is decomposable. However, the decomposability of analytic model is not always manually tractable especially when the model is generated in an automated manner. In this paper, we propose an automated model composition technique from a system design to a hierarchical stochastic model which is the judicious combination of combinatorial and state-space models. In particular, from SysML-based system specifications, a toplevel fault tree and associated stochastic reward nets are automatically generated in hierarchical manner. The obtained hierarchical stochastic model can be solved analytically considerably faster than monolithic state-space models. Through an illustrative example of three-tier web application system on a virtualized infrastructure, the accuracy and efficiency of the solution are evaluated in comparison to a monolithic state space model and a static fault tree.},
	language = {en},
	urldate = {2019-01-21},
	booktitle = {2013 {IEEE} 24th {International} {Symposium} on {Software} {Reliability} {Engineering} ({ISSRE})},
	publisher = {IEEE},
	author = {Machida, Fumio and Xiang, Jianwen and Tadano, Kumiko and Maeno, Yoshiharu},
	month = nov,
	year = {2013},
	pages = {51--60},
}

@article{belghiat_automatic_2012,
	title = {Automatic {Generation} of {OWL} {Ontologies} from {UML} {Class} {Diagrams} {Based} on {Meta}- {Modelling} and {Graph} {Grammars}},
	volume = {6},
	abstract = {Models are placed by modeling paradigm at the center of development process. These models are represented by languages, like UML the language standardized by the OMG which became necessary for development. Moreover the ontology engineering paradigm places ontologies at the center of development process; in this paradigm we find OWL the principal language for knowledge representation. Building ontologies from scratch is generally a difficult task. The bridging between UML and OWL appeared on several regards such as the classes and associations. In this paper, we have to profit from convergence between UML and OWL to propose an approach based on Meta-Modelling and Graph Grammars and registered in the MDA architecture for the automatic generation of OWL ontologies from UML class diagrams. The transformation is based on transformation rules; the level of abstraction in these rules is close to the application in order to have usable ontologies. We illustrate this approach by an example.},
	language = {en},
	number = {8},
	author = {Belghiat, Aissam and Bourahla, Mustapha},
	year = {2012},
	pages = {6},
}

@inproceedings{castet_failure_2018,
	title = {Failure analysis and products in a model-based environment},
	doi = {10.1109/AERO.2018.8396736},
	abstract = {The work presented in this paper describes an approach, including a methodology and tools, which allows system engineers to capture failure-related information in a model and generate automatically key failure analysis products: the Failure Modes, Effects and Criticality Analysis (FMECA) and the Fault Tree Analysis (FTA). The work has been developed by Tietronix Software, Inc. and the NASA's Jet Propulsion Laboratory (JPL), and the resulting auto-generated artifacts shown in this paper demonstrate the ability to obtain powerful reliability and fault management products in a model-based environment.},
	booktitle = {2018 {IEEE} {Aerospace} {Conference}},
	author = {Castet, J. and Bareh, M. and Nunes, J. and Okon, S. and Garner, L. and Chacko, E. and Izygon, M.},
	month = mar,
	year = {2018},
	keywords = {Analytical models, FMECA, Failure analysis, Fault Tree Analysis, Fault trees, NASA's Jet Propulsion Laboratory, Ontologies, Reliability, Software, Standards, aerospace computing, auto-generated artifacts, automatic key failure analysis products, failure modes-effects and criticality analysis, fault management products, fault trees, model-based environment, system engineers},
	pages = {1--13},
}

@book{debbabi_verification_2010,
	address = {Berlin Heidelberg},
	title = {Verification and {Validation} in {Systems} {Engineering}: {Assessing} {UML}/{SysML} {Design} {Models}},
	isbn = {978-3-642-15227-6},
	shorttitle = {Verification and {Validation} in {Systems} {Engineering}},
	url = {//www.springer.com/us/book/9783642152276},
	abstract = {Verification and validation represents an important process used for the quality assessment of engineered systems and their compliance with the requirements established at the beginning of or during the development cycle. Debbabi and his coauthors investigate methodologies and techniques that can be employed for the automatic verification and validation of systems engineering design models expressed in standardized modeling languages. Their presentation includes a bird’s eye view of the most prominent modeling languages for software and systems engineering, namely the Unified Modeling Language (UML) and the more recent Systems Modeling Language (SysML). Moreover, it elaborates on a number of quantitative and qualitative techniques that synergistically combine automatic verification techniques, program analysis, and software engineering quantitative methods applicable to design models described in these modeling languages. Each of these techniques is additionally explained using a case study highlighting the process, its results, and resulting changes in the system design. Researchers in academia and industry as well as students specializing in software and systems engineering will find here an overview of state-of-the-art validation and verification techniques. Due to their close association with the UML standard, the presented approaches are also applicable to industrial software development.},
	language = {en},
	urldate = {2019-01-21},
	publisher = {Springer-Verlag},
	author = {Debbabi, Mourad and Hassaïne, Fawzi and Jarraya, Yosr and Soeanu, Andrei and Alawneh, Luay},
	year = {2010},
}

@inproceedings{gasevic_converting_2004,
	address = {New York, NY, USA},
	series = {{WWW} {Alt}. '04},
	title = {Converting {UML} to {OWL} {Ontologies}},
	isbn = {978-1-58113-912-9},
	url = {http://doi.acm.org/10.1145/1013367.1013539},
	doi = {10.1145/1013367.1013539},
	abstract = {This paper presents automatic generation of the Web Ontology Language (OWL) from an UML model. The solution is based on an MDA-defined architecture for ontology development and the Ontology UML Profile (OUP). A conversion, that we present here, transforms an ontology from its OUP definition (i.e. XML Metadata Interchange -- XMI) into OWL description. Accordingly, we illustrate how an OUP-developed ontology can be shared with ontological engineering tools (i.e. Protégé).},
	urldate = {2019-01-21},
	booktitle = {Proceedings of the 13th {International} {World} {Wide} {Web} {Conference} on {Alternate} {Track} {Papers} \& {Posters}},
	publisher = {ACM},
	author = {Gasevic, Dragan and Djuric, Dragan and Devedzic, Vladan and Damjanovi, Violeta},
	year = {2004},
	keywords = {OWL, UML profiles, XSLT, ontology},
	pages = {488--489},
}

@inproceedings{jarraya_automatic_2007,
	title = {Automatic {Verification} and {Performance} {Analysis} of {Time}-{Constrained} {SysML} {Activity} {Diagrams}},
	doi = {10.1109/ECBS.2007.22},
	abstract = {We present in this paper a new approach for the automatic verification and performance analysis of SysML activity diagrams. Since timeliness is important in the design and analysis of real-time systems, we annotate activity diagrams with time constraints. In order to apply the model checking technique, we use discrete-time Markov chains (DTMC) as a semantic interpretation of such SysML models wherein communication is restricted to synchronization. Thus, we describe a mapping procedure of SysML activity diagrams to their corresponding DTMC and use PRISM model checker for the assessment and evaluation of performance characteristics. Finally, we apply our methodology on a real-life case study meant to assess a systems engineering behavioral model of a photo-camera device},
	booktitle = {14th {Annual} {IEEE} {International} {Conference} and {Workshops} on the {Engineering} of {Computer}-{Based} {Systems} ({ECBS}'07)},
	author = {Jarraya, Y. and Soeanu, A. and Debbabi, M. and Hassaine, F.},
	month = mar,
	year = {2007},
	keywords = {Computer security, Information systems, Laboratories, ML language, Markov processes, Performance analysis, Process design, Real time systems, Research and development, SysML models, Systems engineering and theory, Time factors, Unified modeling language, automatic verification, discrete-time Markov chains, formal verification, model checking, performance analysis, real-time systems, semantic interpretation, software performance evaluation, time constraints, time-constrained SysML activity diagrams},
	pages = {515--522},
}

@inproceedings{mhenni_automatic_2014,
	title = {Automatic fault tree generation from {SysML} system models},
	doi = {10.1109/AIM.2014.6878163},
	abstract = {In this paper, a methodology is proposed to integrate safety analysis within a systems engineering approach. This methodology is based on SysML models and aims at generating (semi-) automatically safety analysis artifacts, mainly FMEA and FTA, from system models. Preliminary functional and component FMEA are automatically generated from the functional and structural models respectively, then completed by safety experts. By representing SysML structural diagram as a directed multi-graph, through a graph traversal algorithm and some identified patterns, generic fault trees are automatically derived with corresponding logic gates and events. The proposed methodology provides the safety expert with assistance during safety analysis. It helps reducing time and error proneness of the safety analysis process. It also helps ensuring consistency since the safety analysis artifacts are automatically generated from the latest system model version. The methodology is applied to a real case study, the electromechanical actuator EMA.},
	booktitle = {2014 {IEEE}/{ASME} {International} {Conference} on {Advanced} {Intelligent} {Mechatronics}},
	author = {Mhenni, F. and Nguyen, N. and Choley, J.},
	month = jul,
	year = {2014},
	keywords = {Analytical models, EMA, FMEA, FTA, Fault trees, Logic gates, Reliability, Safety, SysML, SysML structural diagram, SysML system models, automatic fault tree generation, control engineering computing, directed graphs, directed multigraph, electromechanical actuator, electromechanical actuators, failure mode effect analysis, fault tolerant control, logic events, logic gates, safety analysis, systems engineering, systems engineering approach, trees (mathematics)},
	pages = {715--720},
}

@techreport{noauthor_hazard_2018,
	title = {Hazard and {Accident} {Analysis} {Handbook}},
	number = {DOE-HDBK-1224-2018},
	month = aug,
	year = {2018},
}

@book{noauthor_generic_2001,
	address = {Vienna},
	series = {Safety {Reports} {Series}},
	title = {Generic {Models} for {Use} in {Assessing} the {Impact} of {Discharges} of {Radioactive} {Substances} to the {Environment}},
	isbn = {92-0-100501-6},
	url = {https://www.iaea.org/publications/6024/generic-models-for-use-in-assessing-the-impact-of-discharges-of-radioactive-substances-to-the-environment},
	number = {19},
	publisher = {INTERNATIONAL ATOMIC ENERGY AGENCY},
	year = {2001},
}

@article{wealer_cost_nodate,
	title = {Cost {Estimates} and {Economics} of {Nuclear} {Power} {Plant} {Newbuild}: {Literature} {Survey} and {Some} {Modelling} {Analysis}},
	language = {en},
	author = {Wealer, Ben and Kemfert, Claudia},
	pages = {30},
}

@inproceedings{locatelli_entering_2012,
	address = {Hong Kong, China},
	title = {Entering the nuclear power plant supply chain: {The} {France} case study},
	isbn = {978-1-4673-2945-3},
	shorttitle = {Entering the nuclear power plant supply chain},
	url = {http://ieeexplore.ieee.org/document/6838092/},
	doi = {10.1109/IEEM.2012.6838092},
	abstract = {The so called nuclear renaissance is creating a huge market even though the criticality of the supply chain: few firms have the capabilities to work in this complex and demanding market, whereas many other are investigating the option to enter. The international scientific literature provides information regarding the governmental topics of nuclear power programs in different countries, but the analyses at firm level are almost inexistent. In particular it is unclear how an EPC (Engineering, Procurement and Construction) company can enter the supply chain (or project delivery chain). In order to answer this research question the paper investigates the French case study. First it investigates the pure historical facts and shows how French companies developed the national supply chain thanks to a strong governmental support. Then, the typical pattern used in a French NPP project is described analysing the five most relevant companies.},
	language = {en},
	urldate = {2020-04-01},
	booktitle = {2012 {IEEE} {International} {Conference} on {Industrial} {Engineering} and {Engineering} {Management}},
	publisher = {IEEE},
	author = {Locatelli, G. and Mancini, M. and Cocco, G. and Ruzzon, V.},
	month = dec,
	year = {2012},
	pages = {1976--1980},
}

@article{berthelemy_nuclear_2015,
	title = {Nuclear reactors' construction costs: {The} role of lead-time, standardization and technological progress},
	volume = {82},
	issn = {03014215},
	shorttitle = {Nuclear reactors' construction costs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0301421515001214},
	doi = {10.1016/j.enpol.2015.03.015},
	language = {en},
	urldate = {2020-04-01},
	journal = {Energy Policy},
	author = {Berthélemy, Michel and Escobar Rangel, Lina},
	month = jul,
	year = {2015},
	pages = {118--130},
}

@article{carajilescov_construction_2011,
	title = {{CONSTRUCTION} {TIME} {OF} {PWRs}},
	abstract = {The cost of electricity generated by nuclear power is greatly affected by the capital cost, which is dependent on the construction time of the plant. This work analyses the construction time of PWRs in several countries with different market structure and licensing experience. Countries which succeeded to establish a more collaborative environment among utilities, constructors, regulators, and energy planners through effective partnerships were able to build PWRs in shorter times. The construction time in Germany, France and Russia was around 80 months and in Japan, about 60 months. The envelope of 95\% of the cases includes a range between 50 and 250 months of construction time. The evaluations show that construction time of PWRs has been longer for countries that did not hold the technology to build their own reactors, and depended on contracts with foreign suppliers. The nominal power of the reactors was considered a measure of plant size, technology complexity and standardization. Countries with standardized reactor designs (France, Japan and Russia) were able to build plants in shorter times.},
	language = {en},
	author = {Carajilescov, Pedro and Moreira, João M L},
	year = {2011},
	pages = {13},
}

@article{buongiorno_what_nodate,
	title = {What are the key challenges for nuclear and how to address them},
	language = {en},
	author = {Buongiorno, Jacopo},
	pages = {31},
}

@book{world_nuclear_association_world_2016,
	title = {The world nuclear supply chain: outlook 2035},
	isbn = {978-0-9931019-1-5},
	shorttitle = {The world nuclear supply chain},
	language = {en},
	author = {{World Nuclear Association}},
	year = {2016},
	note = {OCLC: 962407597},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Your} personal research assistant},
	url = {https://www.zotero.org/},
	urldate = {2020-03-25},
}

@techreport{tanner_33_2017,
	title = {33 {Years} of {Interesting} {Projects}.},
	url = {https://www.osti.gov/biblio/1456632},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {SAND2017-4076PE},
	urldate = {2020-03-25},
	institution = {Sandia National Lab. (SNL-NM), Albuquerque, NM (United States)},
	author = {Tanner, Danelle M.},
	month = apr,
	year = {2017},
}

@misc{noauthor_processed_nodate,
	title = {Processed {Information} - {FAFSA} on the {Web} - {Federal} {Student} {Aid}},
	url = {https://fafsa.ed.gov/spa/fafsa/#/CYCLE2021/ESAR;previous=myfafsa},
	urldate = {2020-03-16},
}

@book{noauthor_security_2008,
	address = {Vienna},
	series = {{IAEA} nuclear security series {Implementing} guide},
	title = {Security in the transport of radioactive material},
	isbn = {978-92-0-107908-4},
	abstract = {Literaturverz. S. 37 - 39},
	language = {en},
	number = {9},
	publisher = {Internat. Atomic Energy Agency},
	year = {2008},
	note = {OCLC: 552067465},
}

@book{noauthor_india-united_nodate,
	title = {India-{United} {States} {Cooperation} on {Global} {Security}: {Summary} of a {Workshop} on {Technical} {Aspects} of {Civilian} {Nuclear} {Materials} {Security}},
	shorttitle = {Read "{India}-{United} {States} {Cooperation} on {Global} {Security}},
	url = {https://www.nap.edu/read/18412/chapter/4},
	abstract = {Read chapter 2  Systems Approach to Security at Civilian Nuclear Facilities: The U.S. government has made safeguarding of weapons-grade plutonium and high...},
	language = {en},
	urldate = {2020-03-10},
	doi = {10.17226/18412},
}

@article{apostolakis_concept_1990,
	title = {The concept of probability in safety assessments of technological systems},
	volume = {250},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.2255906},
	doi = {10.1126/science.2255906},
	language = {en},
	number = {4986},
	urldate = {2020-03-06},
	journal = {Science},
	author = {Apostolakis, G},
	month = dec,
	year = {1990},
	pages = {1359--1364},
}

@article{wheatley_reassessing_2016,
	title = {Reassessing the safety of nuclear power},
	volume = {15},
	issn = {22146296},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214629615301067},
	doi = {10.1016/j.erss.2015.12.026},
	abstract = {We summarize the results of a recent statistical analysis of 216 nuclear energy accidents and incidents (events). The dataset is twice as large as the previous best available. We employ cost in US dollars as a severity measure to facilitate the comparison of different types and sizes of events, a method more complete and consistent that the industry-standard approach. Despite signiﬁcant reforms following past disasters, we estimate that, with 388 reactors in operation, there is a 50\% chance that a Fukushima event (or more costly) occurs every 60–150 years. We also ﬁnd that the average cost of events per year is around the cost of the construction of a new plant. This dire outlook necessitates post-Fukushima reforms that will truly minimize extreme nuclear power risks. Nuclear power accidents are decreasing in frequency, but increasing in severity.},
	language = {en},
	urldate = {2020-03-06},
	journal = {Energy Research \& Social Science},
	author = {Wheatley, Spencer and Sovacool, Benjamin K. and Sornette, Didier},
	month = may,
	year = {2016},
	pages = {96--100},
}

@article{jensen_how_2019,
	title = {How {TradeLens} {Delivers} {Business} {Value} {With} {Blockchain} {Technology}},
	volume = {18},
	issn = {15401960},
	url = {https://aisel.aisnet.org/misqe/vol18/iss4/5/},
	doi = {10.17705/2msqe.00018},
	language = {en},
	number = {4},
	urldate = {2020-03-06},
	journal = {MIS Quarterly Executive},
	author = {Jensen, Thomas and Hedman, Jonas and Henningsson, Stefan},
	month = dec,
	year = {2019},
	pages = {221--243},
}

@article{androulaki_hyperledger_2018,
	title = {Hyperledger {Fabric}: {A} {Distributed} {Operating} {System} for {Permissioned} {Blockchains}},
	shorttitle = {Hyperledger {Fabric}},
	url = {http://arxiv.org/abs/1801.10228},
	doi = {10.1145/3190508.3190538},
	abstract = {Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org).},
	language = {en},
	urldate = {2020-03-06},
	journal = {Proceedings of the Thirteenth EuroSys Conference on - EuroSys '18},
	author = {Androulaki, Elli and Barger, Artem and Bortnikov, Vita and Cachin, Christian and Christidis, Konstantinos and De Caro, Angelo and Enyeart, David and Ferris, Christopher and Laventman, Gennady and Manevich, Yacov and Muralidharan, Srinivasan and Murthy, Chet and Nguyen, Binh and Sethi, Manish and Singh, Gari and Smith, Keith and Sorniotti, Alessandro and Stathakopoulou, Chrysoula and Vukolić, Marko and Cocco, Sharon Weed and Yellick, Jason},
	year = {2018},
	note = {arXiv: 1801.10228},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Distributed, Parallel, and Cluster Computing},
	pages = {1--15},
}

@article{ouchi_computer_2007,
	title = {Computer {Modeling} of {Radiation} {Effects}},
	volume = {6},
	issn = {1683-1470},
	url = {http://datascience.codata.org/articles/abstract/10.2481/dsj.6.S278/},
	doi = {10.2481/dsj.6.S278},
	abstract = {Biological effects of low-dose radiation are studied by computational methods. Assessing the risks of low-dose radiation, i.e. radiation-induced cancer, is becoming important in the study of public health because of the many different types of exposures, medical exposures, and from radiation protection viewpoints. In general, radiation effects arise from damage done to DNA by ionizing radiation. Therefore, examining effects from the initial DNA damage to the risk assessment is a problem with a very wide spatiotemporal scale. We are studying this problem by dividing it into three parts: 1) the DNA strand is broken by ionizing radiation, 2) DNA lesion repair, and 3) the process of cell carcinogenesis and tumorigenesis. In this paper, we mainly focus on the third part, the study of modeling and simulation of cell carcinogenesis.},
	language = {en},
	urldate = {2020-03-06},
	journal = {Data Science Journal},
	author = {Ouchi, N. B.},
	year = {2007},
	pages = {S278--S284},
}

@article{zhou_steam_nodate,
	title = {Steam {Turbine} {Operating} {Conditions}, {Chemistry} of {Condensates}, and {Environment} {Assisted} {Cracking} – {A} {Critical} {Review}},
	abstract = {A review of the literature and discussions with plant operators has been undertaken to establish present knowledge and understanding of the chemistry of the condensates formed on steam turbines and the link to system operation. This has been supplemented by an overview of the effect of test variables on environment assisted cracking.},
	language = {en},
	author = {Zhou, Shengqi and Turnbull, Alan},
	pages = {78},
}

@article{locatelli_entering_2012-1,
	title = {Entering the {Nuclear} {Power} {Plant} {Supply} {Chain}: {The} {Japanese} {Case} {Study}},
	abstract = {The so called “nuclear renaissance” is creating a huge market for new nuclear reactors. One of the major criticalities in this field is the supply chain: few firms have the capabilities to work in this complex and highly demanding market, whereas many other are investigating the option to enter. The international scientific literature provides information regarding the high-level governmental aspects of nuclear power programs in different countries, but the analysis at firm and project level are almost inexistent. Moreover, the usual business models for the manufacturing industry are not suitable, since the nuclear market is very peculiar. In particular it is unclear how an EPC (Engineering, Procurement and Construction) company can enter in the project delivery chain. In order to answer this research question this paper investigates the Japanese case study. First it introduces the background of Japanese projects and after it focuses on three major companies that played the most relevant roles in delivering the Japanese reactors: Toshiba, Hitachi and Mitsubishi. The investigation of these case studies provides useful insights for firms willing to participate in projects related to the construction of nuclear power plants.},
	language = {en},
	author = {Locatelli, Giorgio and Mancini, Mauro and Cocco, Gianluca and Ruzzon, Valentino},
	year = {2012},
	pages = {10},
}

@article{noauthor_report_nodate,
	title = {Report on {Drug} {Shortages} for {Calendar} {Year} 2018},
	language = {en},
	pages = {21},
}

@article{gyamfi_radiological_2020,
	title = {Radiological {Safety} {Analysis} for a {Hypothetical} {Accident} of a {Generic} {VVER}-1000 {Nuclear} {Power} {Plant}},
	volume = {2020},
	issn = {1687-6075, 1687-6083},
	url = {https://www.hindawi.com/journals/stni/2020/4721971/},
	doi = {10.1155/2020/4721971},
	abstract = {Atmospheric dispersion modelling and radiological safety analysis have been performed for a postulated accident scenario of a generic VVER-1000 nuclear power plant using the HotSpot Health Physics code. The total effective dose equivalent (TEDE), the respiratory time-integrated air concentration, and the ground deposition concentration are calculated considering site-specific meteorological conditions. The results show that the maximum TEDE and ground deposition concentration values of 3.69
              E
               – 01 Sv and 3.80
              E
               + 06 kBq/m
              2
              occurred at downwind distance of 0.18 km from the release point. This maximum TEDE value is recorded within a distance where public occupation is restricted. The TEDE values at distances of 5.0 km and beyond where public occupation is likely to be found are far below the annual regulatory limits of 1 mSv from public exposure in a year even in the event of worse accident scenario as set in IAEA Safety Standard No. GSR Part 3; no action related specifically to the public exposure is required. The released radionuclides might be transported to long distances but will not have any harmful effect on the public. The direction of the radionuclide emission from the release point is towards the north east. It is observed that the organ with the highest value of committed effective dose equivalent (CEDE) appears to be the thyroid. It was followed by the bone surface, lung, red marrow, and lower large intestine wall in order of decreasing CEDE value. Radionuclides including I-131, I-133, Sr-89, Cs-134, Ba-140, Xe-133, and Xe-135 were found to be the main contributors to the CEDE.},
	language = {en},
	urldate = {2020-02-28},
	journal = {Science and Technology of Nuclear Installations},
	author = {Gyamfi, K. and Birikorang, S. A. and Ampomah-Amoako, E. and Fletcher, J. J.},
	month = jan,
	year = {2020},
	pages = {1--8},
}

@article{sitler_supply_nodate,
	title = {Supply {Chain} {Management} of the {Nuclear} {Energy} {Industry}},
	abstract = {Nuclear energy generation facilities are created from a myriad of sources. Supply chain management for this industry requires someone who is adapt to global sourcing efforts. Each section of the industry falls under strict government guidelines and regulations from federal and national sources. The sourcing of nuclear energy consists of one of the most complex supply chains in the world.},
	language = {en},
	author = {Sitler, Andrea},
	pages = {18},
}

@article{helo_blockchains_2019,
	title = {Blockchains in operations and supply chains: {A} model and reference implementation},
	volume = {136},
	issn = {03608352},
	shorttitle = {Blockchains in operations and supply chains},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0360835219304152},
	doi = {10.1016/j.cie.2019.07.023},
	abstract = {Blockchain is a promising information technology which can provide several potential applications related to operations and supply chains. By using distributed software architecture and advanced computing, blockchain can solve the problem of immutable ledgers distributed to several actors in the chain. This paper reviews blockchain technology and outlines possible uses for immutable distributed ledgers in operations and supply chains. A classification of the applications of blockchain technology in the scope of operations and supply chain management is presented. In order to demonstrate the technical architecture of the blockchain-based logistics monitoring system (BLMS), a reference implementation was programmed and tested based on Ethereum. The purpose of the BLMS is to provide a solution for parcel tracking in a supply chain to support an open and immutable history record for each transaction. The functionality of the system consists of transaction entry for logistics operators. The presented reference architecture demonstrates how blockchain can be implemented in the operations and supply chain context by using software components.},
	language = {en},
	urldate = {2020-02-26},
	journal = {Computers \& Industrial Engineering},
	author = {Helo, Petri and Hao, Yuqiuge},
	month = oct,
	year = {2019},
	pages = {242--251},
}

@article{chang_blockchain_2019,
	title = {Blockchain for {Configuration} {Management} in {Nuclear} {Power} {Plants}},
	language = {en},
	author = {Chang, Choong-koo},
	year = {2019},
	pages = {4},
}

@techreport{research_report_2020,
	title = {Report {\textbar} {Drug} {Shortages}: {Root} {Causes} and {Potential} {Solutions}},
	shorttitle = {Report {\textbar} {Drug} {Shortages}},
	url = {http://www.fda.gov/drugs/drug-shortages/report-drug-shortages-root-causes-and-potential-solutions},
	abstract = {Drug Shortages: Root Causes and Potential Solutions examines the underlying factors responsible for drug shortages and recommends enduring solutions},
	language = {en},
	urldate = {2020-02-25},
	author = {Research, Center for Drug Evaluation and},
	month = feb,
	year = {2020},
	note = {Publisher: FDA},
}

@article{shojaei_development_2019,
	title = {Development of supply chain risk management approaches for construction projects: {A} grounded theory approach},
	volume = {128},
	issn = {0360-8352},
	shorttitle = {Development of supply chain risk management approaches for construction projects},
	url = {http://www.sciencedirect.com/science/article/pii/S0360835218305850},
	doi = {10.1016/j.cie.2018.11.045},
	abstract = {Construction projects face numerous risks during their lifecycle due to their inherent complexities and intricate relationships between different parties involved in the construction process. Accordingly, an effective management of risks throughout the project's supply chain is critical to avoid time and cost overruns, that if not controlled properly, will ultimately result in project failure. Despite the great significance of this issue, there is a gap between the literature and practice of project risk management, where managers mostly prefer to rely on their own experiences rather than using available analytical tools. On the other hand, the application of the best practices (such as supply chain management and supply chain risk management) from the manufacturing industry in the service industry is highly neglected. To this end, these two gaps are bridged by proposing a comprehensive supply chain risk management approach for construction projects that uses, grounded theory, fuzzy cognitive mapping, and grey relational analysis. A real world case study is presented to show the applicability and effectiveness of the proposed approach. Various risk mitigation scenarios are developed and evaluated by the proposed approach. These scenarios are ranked and the best risk mitigation scenarios are identified. By comparing the proposed approach with similar researches in the literature, it is shown that the proposed approach is capable of capturing and representing expert’s perceptions of risks in an effective and time efficient manner. Moreover, decision-makers are enabled to simulate the long term effects of different risk mitigation strategies on the risks and make more informed decisions. Along with the novel approach proposed, the major contribution of this study is setting the stage for a discussion between project management field's scholars and practitioners with those in the manufacturing industry to benefit from an opportunity for mutual growth.},
	language = {en},
	urldate = {2020-01-16},
	journal = {Computers \& Industrial Engineering},
	author = {Shojaei, Payam and Haeri, Seyed Amin Seyed},
	month = feb,
	year = {2019},
	keywords = {Fuzzy cognitive maps, Grey relational analysis, Grounded theory, Project risk management, Supply chain risk management},
	pages = {837--850},
}

@inproceedings{reisman_air_2019,
	address = {San Diego, CA, United States},
	title = {Air {Traffic} {Management} {Blockchain} {Infrastructure} for {Security}, {Authentication}, and {Privacy}},
	url = {https://ntrs.nasa.gov/search.jsp?R=20190000022},
	abstract = {Current radar-based air traffic service providers may preserve privacy for military and corporate operations by procedurally preventing public release of selected flight plans, position, and state data. The FAA mandate for national adoption of Automatic Dependent Surveillance Broadcast  in 2020 does not include provisions for maintaining these same aircraft-privacy options, nor does it address the potential for spoofing, denial of service, and other well-documented risk factors. This paper presents an engineering prototype that embodies a design and method that may be applied to mitigate these ADS-B security issues. The design innovation is the use of an open source permissioned blockchain framework to enable aircraft privacy and anonymity while providing a secure and efficient method for communication with Air Traffic Services, Operations Support, or other authorized entities. This framework features certificate authority, smart contract support, and higher-bandwidth communication channels for private information that may be used for secure communication between any specific aircraft and any particular authorized member, sharing data in accordance with the terms specified in the form of smart contracts. The prototype demonstrates how this method can be economically and rapidly deployed in a scalable modular environment.},
	urldate = {2020-02-25},
	author = {Reisman, Ronald J.},
	month = jan,
	year = {2019},
	keywords = {air traffic control, architecture, chains, computer information security, flight management systems, prototypes},
}

@article{raz_risk_2002,
	title = {Risk management, project success, and technological uncertainty},
	volume = {32},
	issn = {1467-9310},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9310.00243},
	doi = {10.1111/1467-9310.00243},
	abstract = {In times of increased competition and globalization, project success becomes even more critical to business performance, and yet many projects still suffer delays, overruns, and even failure. Ironically, however, risk management tools and techniques, which have been developed to improve project success, are used too little, and many still wonder how helpful they are. In this paper we present the results of an empirical study devoted to this question. Based on data collected on over 100 projects performed in Israel in a variety of industries, we examine the extent of usage of some risk management practices, such as risk identification, probabilistic risk analysis, planning for uncertainty and trade-off analysis, the difference in application across different types of projects, and their impact on various project success dimensions. Our findings suggest that risk management practices are still not widely used. Only a limited number of projects in our study have used any kind of risk management practices and many have only used some, but not all the available tools. When used, risk management practices seem to be working, and appear to be related to project success. We also found that risk management practices were more applicable to higher risk projects. The impact of risk management is mainly on better meeting time and budget goals and less on product performance and specification. In this case, we also found some differences according levels of technological uncertainty. Our conclusion is that risk management is still at its infancy and that at this time, more awareness to the application, training, tool development, and research on risk management is needed.},
	language = {en},
	number = {2},
	urldate = {2020-01-16},
	journal = {R\&D Management},
	author = {Raz, Tzvi and Shenhar, Aaron J. and Dvir, Dov},
	year = {2002},
	pages = {101--109},
}

@article{keshk_special_2018,
	title = {Special studies in management of construction project risks, risk concept, plan building, risk quantitative and qualitative analysis, risk response strategies},
	volume = {57},
	issn = {1110-0168},
	url = {http://www.sciencedirect.com/science/article/pii/S1110016818301133},
	doi = {10.1016/j.aej.2017.12.003},
	abstract = {Project management includes several managements, such as time management, cost management, and quality management…etc. Project risk management is one of the most important management, especially in this time, which has many unexpected events. This management means with classification, analyzing, planning, identification, assessment, and response and avoidance strategies of risks. Therefore, it should be too interested in risk management, to avoid many losses.},
	language = {en},
	number = {4},
	urldate = {2020-01-16},
	journal = {Alexandria Engineering Journal},
	author = {Keshk, Ahmed Mohamed and Maarouf, Ibrahim and Annany, Ysory},
	month = dec,
	year = {2018},
	keywords = {Analyzing, Assessment, Avoidance strategies of risks, Cost management, Project management, Project risk management, Quality management, Response, Time management},
	pages = {3179--3187},
}

@article{buganova_risk_2019,
	series = {{TRANSCOM} 2019 13th {International} {Scientific} {Conference} on {Sustainable}, {Modern} and {Safe} {Transport}},
	title = {Risk management in traditional and agile project management},
	volume = {40},
	issn = {2352-1465},
	url = {http://www.sciencedirect.com/science/article/pii/S2352146519303060},
	doi = {10.1016/j.trpro.2019.07.138},
	abstract = {The dynamic development of the business environment has stimulated the efforts of managers for agile project management. This is mainly due to shortening time limits for project realization as well as vaguely set objectives that change during project implementation. The requirements on project managers and methodological risk management of projects have also changed. Organizations use projects to manage changes and to develop and deploy new products. In a competitive environment, only those who can manage the risks and realize the project more efficiently will succeed. The aim of the article is to highlight the importance of risk management and the possibilities of its implementation in traditional and agile approaches to project management.},
	language = {en},
	urldate = {2020-01-16},
	journal = {Transportation Research Procedia},
	author = {Buganová, Katarína and Šimíčková, Jana},
	month = jan,
	year = {2019},
	keywords = {agile approach, project, risk, risk management, transportation company},
	pages = {986--993},
}

@book{roush_applied_2006,
	title = {Applied {Reliability} {Engineering} {Vol} 2},
	volume = {2},
	isbn = {978-0-9652669-8-7},
	language = {en},
	publisher = {Center for Reliability Engineering, University of Maryland},
	author = {Roush, Marvin L. and Webb, Willie M.},
	year = {2006},
}

@book{roush_applied_2006-1,
	title = {Applied {Reliability} {Engineering} {Vol} 1},
	volume = {1},
	isbn = {978-0-9652669-8-7},
	language = {en},
	publisher = {Center for Reliability Engineering, University of Maryland},
	author = {Roush, Marvin L. and Webb, Willie M.},
	year = {2006},
}

@article{khadam_applicability_2003,
	title = {Applicability of risk-based management and the need for risk-based economic decision analysis at hazardous waste contaminated sites},
	volume = {29},
	issn = {0160-4120},
	url = {http://www.sciencedirect.com/science/article/pii/S0160412003000096},
	doi = {10.1016/S0160-4120(03)00009-6},
	abstract = {Decision analysis in subsurface contamination management is generally carried out through a traditional engineering economic viewpoint. However, new advances in human health risk assessment, namely, the probabilistic risk assessment, and the growing awareness of the importance of soft data in the decision-making process, require decision analysis methodologies that are capable of accommodating non-technical and politically biased qualitative information. In this work, we discuss the major limitations of the currently practiced decision analysis framework, which evolves around the definition of risk and cost of risk, and its poor ability to communicate risk-related information. A demonstration using a numerical example was conducted to provide insight on these limitations of the current decision analysis framework. The results from this simple ground water contamination and remediation scenario were identical to those obtained from studies carried out on existing Superfund sites, which suggests serious flaws in the current risk management framework. In order to provide a perspective on how these limitations may be avoided in future formulation of the management framework, more matured and well-accepted approaches to decision analysis in dam safety and the utility industry, where public health and public investment are of great concern, are presented and their applicability in subsurface remediation management is discussed. Finally, in light of the success of the application of risk-based decision analysis in dam safety and the utility industry, potential options for decision analysis in subsurface contamination management are discussed.},
	language = {en},
	number = {4},
	urldate = {2020-02-21},
	journal = {Environment International},
	author = {Khadam, Ibrahim and Kaluarachchi, Jagath J},
	month = jul,
	year = {2003},
	keywords = {Contaminated sites, Remediation, Risk-based management, Soft data},
	pages = {503--519},
}

@article{modarres_advanced_2009,
	title = {Advanced nuclear power plant regulation using risk-informed and performance-based methods},
	volume = {94},
	issn = {0951-8320},
	url = {http://www.sciencedirect.com/science/article/pii/S0951832008000677},
	doi = {10.1016/j.ress.2008.02.019},
	abstract = {This paper proposes and discusses implications of a largely probabilistic regulatory framework using best-estimate, goal-driven, risk-informed, and performance-based methods. This framework relies on continuous probabilistic assessment of performance of a set of time-dependent, safety-critical systems, structures, components, and procedures that assure attainment of a broad set of overarching technology-neutral protective, mitigative, and preventive goals under all phases of plant operations. In this framework acceptable levels of performance are set through formal apportionment so that they are commensurate with the overarching goals. Regulatory acceptance would be the based on the confidence level with which the plant conforms to these goals and performance objectives. The proposed framework uses the traditional defense-in-depth design and operation regulatory philosophy when uncertainty in conforming to specific goals and objectives is high. Finally, the paper discusses the steps needed to develop a corresponding technology-neutral regulatory approach from the proposed framework.},
	language = {en},
	number = {2},
	urldate = {2020-02-21},
	journal = {Reliability Engineering \& System Safety},
	author = {Modarres, Mohammad},
	month = feb,
	year = {2009},
	keywords = {Goal-driven regulation, Nuclear safety regulation, Performance-based regulation, Probabilistic risk assessment, Risk-informed regulation, Safety goals, Technology-neutral regulation},
	pages = {211--217},
}

@inproceedings{fleming_use_2018,
	title = {Use of {PRA} to {Select} {Licensing} {Basis} {Events}},
	abstract = {The purpose of this paper is to summarize key elements of the risk-informed and performance-based methods developed within the Industry led Licensing Modernization Project (LMP). The LMP is jointly sponsored by the U.S. Department of Energy and the U.S. nuclear industry to assist the U.S. Nuclear Regulatory Commission (NRC) in the development of regulatory guidance for advanced non-light water reactors currently under development in the U.S. The purpose of this paper is to summarize a risk-informed and performance based approach for the selection and evaluation of LBEs for advanced non-LWRs. This paper summarizes the approach which builds on a PRA model that is introduced early in the design process and provides examples for selected advanced non-LWR technologies.},
	language = {en},
	booktitle = {{PSAM14}},
	author = {Fleming, Karl and Wallace, Edward and Afzali, Amir},
	year = {2018},
	pages = {12},
}

@techreport{noauthor_fluoride-cooled_2019,
	title = {Fluoride-{Cooled} {High} {Temperature} {Reactor} {Licensing} {Modernization} {Project} {Demonstration}},
	number = {SC-29980-203},
	month = aug,
	year = {2019},
}

@unpublished{siu_dynamic_nodate,
	title = {Dynamic {PRA} for {Nuclear} {Power} {Plants}: {Not} {If} {But} {When}?},
	author = {Siu, N.},
	note = {ML19066A390},
}

@techreport{noauthor_westinghouse_2019,
	title = {Westinghouse {eVinciTM} {Micro}-{Reactor} {Licensing} {Modernization} {Project} {Demonstration}},
	number = {SC-29980-202},
	month = aug,
	year = {2019},
}

@book{okrent_nuclear_1981,
	title = {Nuclear {Reactor} {Safety}: {On} the {History} of the {Regulatory} {Process}},
	isbn = {978-0-299-08350-2},
	shorttitle = {Nuclear {Reactor} {Safety}},
	language = {en},
	publisher = {University of Wisconsin Press},
	author = {Okrent, David},
	year = {1981},
	note = {Google-Books-ID: dv8iAAAAMAAJ},
	keywords = {Technology \& Engineering / General},
}

@book{holmes_innovations_2008,
	address = {Berlin Heidelberg},
	series = {Studies in {Computational} {Intelligence}},
	title = {Innovations in {Bayesian} {Networks}: {Theory} and {Applications}},
	isbn = {978-3-540-85065-6},
	shorttitle = {Innovations in {Bayesian} {Networks}},
	url = {https://www.springer.com/gp/book/9783540850656},
	abstract = {Bayesian networks currently provide one of the most rapidly growing areas of research in computer science and statistics. In compiling this volume we have brought together contributions from some of the most prestigious researchers in this field. Each of the twelve chapters is self-contained. Both theoreticians and application scientists/engineers in the broad area of artificial intelligence will find this volume valuable. It also provides a useful sourcebook for Graduate students since it shows the direction of current research.},
	language = {en},
	urldate = {2019-09-25},
	publisher = {Springer-Verlag},
	editor = {Holmes, Dawn E.},
	year = {2008},
}

@book{leveson_engineering_2011,
	address = {Cambridge, Mass},
	series = {Engineering systems},
	title = {Engineering a safer world: systems thinking applied to safety},
	isbn = {978-0-262-01662-9},
	shorttitle = {Engineering a safer world},
	language = {en},
	publisher = {MIT Press},
	author = {Leveson, Nancy},
	year = {2011},
	note = {OCLC: ocn719429220},
	keywords = {Industrial safety, System safety},
}

@book{bernstein_against_1998,
	address = {New York, NY},
	edition = {Edition Unstated edition},
	title = {Against the {Gods}: {The} {Remarkable} {Story} of {Risk}},
	isbn = {978-0-471-29563-1},
	shorttitle = {Against the {Gods}},
	abstract = {A Business Week, New York Times Business, and USA Today Bestseller"Ambitious and readable . . . an engaging introduction to the oddsmakers, whom Bernstein regards as true humanists helping to release mankind from the choke holds of superstition and fatalism."—The New York Times"An extraordinarily entertaining and informative book."—The Wall Street Journal"A lively panoramic book . . . Against the Gods sets up an ambitious premise and then delivers on it."—Business Week"Deserves to be, and surely will be, widely read."—The Economist"[A] challenging book, one that may change forever the way people think about the world."—Worth"No one else could have written a book of such central importance with so much charm and excitement."—Robert Heilbroner author, The Worldly Philosophers"With his wonderful knowledge of the history and current manifestations of risk, Peter Bernstein brings us Against the Gods. Nothing like it will come out of the financial world this year or ever. I speak carefully: no one should miss it."—John Kenneth Galbraith Professor of Economics Emeritus, Harvard UniversityIn this unique exploration of the role of risk in our society, Peter Bernstein argues that the notion of bringing risk under control is one of the central ideas that distinguishes modern times from the distant past. Against the Gods chronicles the remarkable intellectual adventure that liberated humanity from oracles and soothsayers by means of the powerful tools of risk management that are available to us today."An extremely readable history of risk."—Barron's"Fascinating . . . this challenging volume will help you understand the uncertainties that every investor must face."—Money"A singular achievement."—Times Literary Supplement"There's a growing market for savants who can render the recondite intelligibly-witness Stephen Jay Gould (natural history), Oliver Sacks (disease), Richard Dawkins (heredity), James Gleick (physics), Paul Krugman (economics)-and Bernstein would mingle well in their company."—The Australian},
	language = {English},
	publisher = {Wiley},
	author = {Bernstein, Peter L.},
	month = aug,
	year = {1998},
}

@book{kelly_bayesian_2011,
	title = {Bayesian {Inference} for {Probabilistic} {Risk} {Assessment}: {A} {Practitioner}'s {Guidebook}},
	isbn = {978-1-84996-187-5},
	shorttitle = {Bayesian {Inference} for {Probabilistic} {Risk} {Assessment}},
	abstract = {Bayesian Inference for Probabilistic Risk Assessment provides a Bayesian foundation for framing probabilistic problems and performing inference on these problems. Inference in the book employs a modern computational approach known as Markov chain Monte Carlo (MCMC). The MCMC approach may be implemented using custom-written routines or existing general purpose commercial or open-source software. This book uses an open-source program called OpenBUGS (commonly referred to as WinBUGS) to solve the inference problems that are described. A powerful feature of OpenBUGS is its automatic selection of an appropriate MCMC sampling scheme for a given problem. The authors provide analysis “building blocks” that can be modified, combined, or used as-is to solve a variety of challenging problems.The MCMC approach used is implemented via textual scripts similar to a macro-type programming language. Accompanying most scripts is a graphical Bayesian network illustrating the elements of the script and the overall inference problem being solved. Bayesian Inference for Probabilistic Risk Assessment also covers the important topics of MCMC convergence and Bayesian model checking.Bayesian Inference for Probabilistic Risk Assessment is aimed at scientists and engineers who perform or review risk analyses. It provides an analytical structure for combining data and information from various sources to generate estimates of the parameters of uncertainty distributions used in risk and reliability models.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Kelly, Dana and Smith, Curtis},
	month = aug,
	year = {2011},
	note = {Google-Books-ID: B6GTgqB3S24C},
	keywords = {Mathematics / Probability \& Statistics / General, Technology \& Engineering / Manufacturing, Technology \& Engineering / Quality Control},
}

@book{garrick_quantifying_2008,
	title = {Quantifying and {Controlling} {Catastrophic} {Risks}},
	isbn = {978-0-08-092345-1},
	abstract = {The perception, assessment and management of risk are increasingly important core principles for determining the development of both policy and strategic responses to civil and environmental catastrophes. Whereas these principles were once confined to some areas of activity i.e. financial and insurance, they are now widely used in civil and environmental engineering. Comprehensive and readable, Civil and Environmental Risk: Mitigation and Control, provides readers with the mathematical tools and quantitative methods for determining the probability of a catastrophic event and mitigating and controlling the aftermath. With this book engineers develop the required skills for accurately assessing risk and formulating appropriate response strategies. The two part treatment starts with a clear and rigorous exposition of the quantitative risk assessment process, followed by self-contained chapters concerning applications. One of the first books to address both natural and human generated disasters, topics include events such as pandemic diseases, climate changes, major hurricanes, super earthquakes, mega tsunamis, volcanic eruptions, industrial accidents and terrorist attacks. Case studies appear at the end of the book allowing engineers to see how these principles are applied to scenarios such as a super hurricane or mega tsunamis, a reactor core melt down in a nuclear plant, a terrorist attack on the national electric grid, and an abrupt climate change brought about by a change in the ocean currents in the North Atlantic. Written by the current Chairman of the U.S. Nuclear Waste Technical Review Board, Environmental risk managers will find this reference a valuable and authoritative guide both in accurately calculating risk and its applications in their work.Mathematical tools for calculating and Controlling Catastrophic RiskPresents a systematic method for ranking the importance of societal threatsIncludes both Natural and Industrial CatastrophesCase studies cover such events as pandemic diseases, climate changes, major hurricanes, super earthquakes, mega tsunamis, volcanic eruptions, industrial accidents, and terrorist attacks},
	language = {en},
	publisher = {Academic Press},
	author = {Garrick, B. John},
	month = oct,
	year = {2008},
	keywords = {Nature / Natural Disasters, Science / Environmental Science, Technology \& Engineering / Civil / General, Technology \& Engineering / Environmental / General},
}

@book{lowrance_acceptable_1976,
	title = {Of {Acceptable} {Risk}: {Science} and the {Determination} of {Safety}},
	isbn = {978-0-913232-30-9},
	shorttitle = {Of {Acceptable} {Risk}},
	abstract = {Analyzes the complex issues and procedures involved in measuring risk, judging safety, and determining standards through regulation. Bibliogs},
	language = {en},
	publisher = {Kaufmann, William, Incorporated, Los Altos, Calif.},
	author = {Lowrance, William W.},
	year = {1976},
	note = {Google-Books-ID: olWaAAAAIAAJ},
}

@book{liu_monte_2013,
	title = {Monte {Carlo} {Strategies} in {Scientific} {Computing}},
	isbn = {978-0-387-76371-2},
	abstract = {This book provides a self-contained and up-to-date treatment of the Monte Carlo method and develops a common framework under which various Monte Carlo techniques can be "standardized" and compared. Given the interdisciplinary nature of the topics and a moderate prerequisite for the reader, this book should be of interest to a broad audience of quantitative researchers such as computational biologists, computer scientists, econometricians, engineers, probabilists, and statisticians. It can also be used as a textbook for a graduate-level course on Monte Carlo methods.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Liu, Jun S.},
	month = nov,
	year = {2013},
	note = {Google-Books-ID: jwrSBwAAQBAJ},
	keywords = {Business \& Economics / Statistics, Mathematics / Counting \& Numeration, Mathematics / Numerical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes, Science / Physics / Mathematical \& Computational},
}

@book{berger_statistical_2013,
	title = {Statistical {Decision} {Theory} and {Bayesian} {Analysis}},
	isbn = {978-1-4757-4286-2},
	abstract = {"The outstanding strengths of the book are its topic coverage, references, exposition, examples and problem sets... This book is an excellent addition to any mathematical statistician's library." -Bulletin of the American Mathematical Society In this new edition the author has added substantial material on Bayesian analysis, including lengthy new sections on such important topics as empirical and hierarchical Bayes analysis, Bayesian calculation, Bayesian communication, and group decision making. With these changes, the book can be used as a self-contained introduction to Bayesian analysis. In addition, much of the decision-theoretic portion of the text was updated, including new sections covering such modern topics as minimax multivariate (Stein) estimation.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Berger, James O.},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: 1CDaBwAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@book{lewis_nuclear_1977,
	title = {Nuclear {Power} {Reactor} {Safety}},
	isbn = {978-0-471-53335-1},
	language = {en},
	publisher = {Wiley},
	author = {Lewis, Elmer Eugene},
	year = {1977},
	note = {Google-Books-ID: QRojAAAAMAAJ},
}

@book{scheaffer_probability_2010,
	title = {Probability and {Statistics} for {Engineers}},
	isbn = {978-0-534-40302-7},
	abstract = {PROBABILITY AND STATISTICS FOR ENGINEERS provides a one-semester, calculus-based introduction to engineering statistics that focuses on making intelligent sense of real engineering data and interpreting results. Traditional topics are presented thorough an accessible modern framework that emphasizes the statistical thinking, data collection and analysis, decision-making, and process improvement skills that engineers need on a daily basis to solve real problems. The text continues to be driven by its hallmark array of engineering applications--thoroughly expanded and modernized for the 5th edition--which tackle timely, interesting, and illuminating scenarios that show students the rich context behind the concepts. Within the presentation of topics and applications the authors continually develop students' intuition for collecting their own real data, analyzing it with the latest graphical tools, and interpreting the results with a goal of improving quality control and problem-solving process. Students will not only gain solid understanding of concepts and their real-life practicality, but will learn to become active statistical practitioners for their own future careers.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
	language = {en},
	publisher = {Cengage Learning},
	author = {Scheaffer, Richard L. and Mulekar, Madhuri and McClave, James T.},
	month = jun,
	year = {2010},
	note = {Google-Books-ID: WDnqNWMd8RIC},
	keywords = {Mathematics / Probability \& Statistics / General},
}

@book{barlow_reliability_1993,
	title = {Reliability and {Decision} {Making}},
	isbn = {978-0-412-53480-5},
	language = {en},
	publisher = {CRC Press},
	author = {Barlow, Richard E. and Claroti, C. A. and Spizzichino, Fabio},
	month = sep,
	year = {1993},
	note = {Google-Books-ID: j4viOBbvnaAC},
	keywords = {Business \& Economics / Production \& Operations Management, Business \& Economics / Quality Control, Mathematics / Probability \& Statistics / General, Technology \& Engineering / Quality Control},
}

@book{verma_reliability_2010,
	title = {Reliability and {Safety} {Engineering}},
	isbn = {978-1-84996-232-2},
	abstract = {Reliability and safety are core issues that must be addressed throughout the life cycle of engineering systems. Reliability and Safety Engineering presents an overview of the basic concepts, together with simple and practical illustrations. The authors present reliability terminology in various engineering fields, viz., • electronics engineering, • software engineering, • mechanical engineering, • structural engineering, and • power systems engineering. They describe the latest applications in the area of probabilistic safety assessment, such as technical specification optimization, risk monitoring and risk informed in-service inspection. Reliability and safety studies must, inevitably, deal with uncertainty, so the book includes uncertainty propagation methods: Monte Carlo simulation, fuzzy arithmetic, Dempster-Shafer theory and probability bounds. Reliability and Safety Engineering also highlights advances in system reliability and safety assessment including dynamic system modeling and uncertainty management. Case studies from typical nuclear power plants, as well as from structural, software, and electronic systems are also discussed. Reliability and Safety Engineering combines discussions of the existing literature on basic concepts and applications with state-of-the-art methods used in reliability and risk assessment of engineering systems. It is designed to assist practicing engineers, students and researchers in the areas of reliability engineering and risk analysis.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Verma, Ajit Kumar and Ajit, Srividya and Karanki, Durga Rao},
	month = aug,
	year = {2010},
	note = {Google-Books-ID: Apx8toLcABIC},
	keywords = {Business \& Economics / Industries / Energy, Technology \& Engineering / Automotive, Technology \& Engineering / Electrical, Technology \& Engineering / Machinery, Technology \& Engineering / Manufacturing, Technology \& Engineering / Power Resources / General, Technology \& Engineering / Power Resources / Nuclear, Technology \& Engineering / Quality Control},
}

@book{saleh_analyses_2007,
	title = {Analyses for {Durability} and {System} {Design} {Lifetime}: {A} {Multidisciplinary} {Approach}},
	isbn = {978-1-139-46803-9},
	shorttitle = {Analyses for {Durability} and {System} {Design} {Lifetime}},
	abstract = {An issue in engineering design is a system's design lifetime. Economists study durability choice problems for consumer goods but seldom address lifetime problem(s) of complex engineering systems. The issues for engineering systems are complex and multidisciplinary and require an understanding of the 'technicalities of durability' and the economic implications of the marginal cost of durability and value maximization. Commonly the design lifetime for an infrastructure is set between 30 and 70 years. Satellite lifetimes are also assigned arbitrarily or with limited analysis. This book provides a systemic qualitative and quantitative approach to these problems addressing, first, the technicality of durability, second, the marginal cost of durability, and third, the durability choice problem for complex engineering systems with network externalities (competition and market uncertainty) and obsolescence effects (technology evolution). Since the analyses are system-specific, a satellite example is used to illustrate the essence and provide a quantitative application of said analyses.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Saleh, Joseph H.},
	month = dec,
	year = {2007},
	note = {Google-Books-ID: 4TY3fnk9hFcC},
	keywords = {Technology \& Engineering / Aeronautics \& Astronautics, Technology \& Engineering / Engineering (General)},
}

@book{ang_probability_2007,
	title = {Probability {Concepts} in {Engineering}: {Emphasis} on {Applications} to {Civil} and {Environmental} {Engineering}},
	isbn = {978-0-471-72064-5},
	shorttitle = {Probability {Concepts} in {Engineering}},
	abstract = {Apply the principles of probability and statistics to realistic engineering problemsThe easiest and most effective way to learn the principles of probabilistic modeling and statistical inference is to apply those principles to a variety of applications. That’s why Ang and Tang’s Second Edition of Probability Concepts in Engineering (previously titled Probability Concepts in Engineering Planning and Design) explains concepts and methods using a wide range of problems related to engineering and the physical sciences, particularly civil and environmental engineering.Now extensively revised with new illustrative problems and new and expanded topics, this Second Edition will help you develop a thorough understanding of probability and statistics and the ability to formulate and solve real-world problems in engineering. The authors present each basic principle using different examples, and give you the opportunity to enhance your understanding with practice problems. The text is ideally suited for students, as well as those wishing to learn and apply the principles and tools of statistics and probability through self-study.Key Features in this 2nd Edition:A new chapter (Chapter 5) covers Computer-Based Numerical and Simulation Methods in Probability, to extend and expand the analytical methods to more complex engineering problems.New and expanded coverage includes distribution of extreme values (Chapter 3), the Anderson-Darling method for goodness-of-fit test (Chapter 6), hypothesis testing  (Chapter 6), the determination of confidence intervals in linear regression (Chapter 8), and Bayesian regression and correlation analyses (Chapter 9).Many new exercise problems in each chapter help you develop a working knowledge of concepts and methods.Provides a wide variety of examples, including many new to this edition, to help you learn and understand specific concepts.Illustrates the formulation and solution of engineering-type probabilistic problems through computer-based methods, including developing computer codes using commercial software such as MATLAB and MATHCAD.Introduces and develops analytical probabilistic models and shows how to formulate engineering problems under uncertainty, and provides the fundamentals for quantitative risk assessment.},
	language = {en},
	publisher = {Wiley},
	author = {Ang, Alfredo H.-S. and Tang, Wilson H.},
	year = {2007},
	note = {Google-Books-ID: G4IoAQAAMAAJ},
	keywords = {Technology \& Engineering / Civil / General, Technology \& Engineering / Environmental / General},
}

@book{ebeling_introduction_2019,
	title = {An {Introduction} to {Reliability} and {Maintainability} {Engineering}: {Third} {Edition}},
	isbn = {978-1-4786-3933-6},
	shorttitle = {An {Introduction} to {Reliability} and {Maintainability} {Engineering}},
	abstract = {Many books on reliability focus on either modeling or statistical analysis and require an extensive background in probability and statistics. Continuing its tradition of excellence as an introductory text for those with limited formal education in the subject, this classroom-tested book introduces the necessary concepts in probability and statistics within the context of their application to reliability. The Third Edition adds brief discussions of the Anderson-Darling test, the Cox proportionate hazards model, the Accelerated Failure Time model, and Monte Carlo simulation. Over 80 new end-of-chapter exercises have been added, as well as solutions to all odd-numbered exercises. Moreover, Excel workbooks, available for download, save students from performing numerous tedious calculations and allow them to focus on reliability concepts. Ebeling has created an exceptional text that enables readers to learn how to analyze failure, repair data, and derive appropriate models for reliability and maintainability as well as apply those models to all levels of design.},
	language = {en},
	publisher = {Waveland Press},
	author = {Ebeling, Charles E.},
	month = apr,
	year = {2019},
	note = {Google-Books-ID: rh2WDwAAQBAJ},
	keywords = {Technology \& Engineering / Industrial Engineering},
}

@book{martino_technological_1972,
	title = {Technological {Forecasting} for {Decisionmaking}},
	isbn = {978-0-444-00122-1},
	language = {en},
	publisher = {American Elsevier Publishing Company},
	author = {Martino, Joseph Paul},
	year = {1972},
	note = {Google-Books-ID: BKF9AAAAIAAJ},
}

@book{margulies_mathematics_2009,
	title = {Mathematics and {Science} {Applications} and {Frontiers}},
	isbn = {978-1-4415-0449-4},
	abstract = {The book presents research and lecture notes from both university teaching and work experiences.},
	language = {en},
	publisher = {Xlibris Corporation},
	author = {Margulies, Timothy S.},
	year = {2009},
	note = {Google-Books-ID: J8haPwAACAAJ},
	keywords = {Mathematics / General, Science / General},
}

@book{kandel_engineering_2018,
	title = {Engineering {Risk} and {Hazard} {Assessment}},
	isbn = {978-1-351-08016-3},
	abstract = {The volumes deal with the newly emerging field of �Risk and Hazard Assessment� and its application to science and engineering. These volumes deal with issues such as short-and long-term hazards, setting priorities in safety, fault analysis for process plants, hazard identification and safety assessment of human- robot systems, plant fault diagnoses expert systems, knowledge based diagnostic systems, fault tree analysis, modelling of computer security systems for risk and reliability analysis, risk analysis of fatigue failure, fault evaluation of complex system, probabilistic risk analysis, and expert systems for fault detection. This volume will provide the reader not only with valuable conceptual and technical information but also with a better view of the field, its problems, accomplishments, and future potentials},
	language = {en},
	publisher = {CRC Press},
	author = {Kandel, Abraham},
	month = jan,
	year = {2018},
	note = {Google-Books-ID: YXqAxwEACAAJ},
}

@book{kandel_engineering_2018-1,
	title = {Engineering {Risk} and {Hazard} {Assessment}},
	isbn = {978-1-351-08860-2},
	abstract = {The volumes deal with the newly emerging field ofRisk and Hazard Assessment and its application to science and engineering. These volumes deal with issues such as short-and long-term hazards, setting priorities in safety, fault analysis for process plants, hazard identification and safety assessment of human- robot systems, plant fault diagnoses expert systems, knowledge based diagnostic systems, fault tree analysis, modelling of computer security systems for risk and reliability analysis, risk analysis of fatigue failure, fault evaluation of complex system, probabilistic risk analysis, and expert systems for fault detection. This volume will provide the reader not only with valuable conceptual and technical information but also with a better view of the field, its problems, accomplishments, and future potentials},
	language = {en},
	publisher = {CRC Press},
	author = {Kandel, Abraham},
	month = jan,
	year = {2018},
	note = {Google-Books-ID: ZLtHDwAAQBAJ},
	keywords = {Technology \& Engineering / Civil / General},
}

@book{klir_fuzzy_1995,
	title = {Fuzzy {Sets} and {Fuzzy} {Logic}: {Theory} and {Applications}},
	isbn = {978-0-13-101171-7},
	shorttitle = {Fuzzy {Sets} and {Fuzzy} {Logic}},
	abstract = {The primary purpose of this book is to provide the reader with a comprehensive coverage of theoretical foundations of fuzzy set theory and fuzzy logic, as well as a broad overview of the increasingly important applications of these novel areas of mathematics. Although it is written as a text for a course at the graduate or upper division undergraduate level, the book is also suitable for self-study and for industry-oriented courses of continuing education.No previous knowledge of fuzzy set theory and fuzzy logic is required for understanding the material covered in the book. Although knowledge of basic ideas of classical (nonfuzzy) set theory and classical (two-valued) logic is useful, fundamentals of these subject areas are briefly overviewed in the book. In addition, basic ideas of neural networks, genetic algorithms, and rough sets are also explained. This makes the book virtually self-contained.Throughout the book, many examples are used to illustrate concepts, methods, and generic applications as they are introduced. Each chapter is followed by a set of exercises, which are intended to enhance readers' understanding of the material presented in the chapter. Extensive and carefully selected bibliography, together with bibliographical notes at the end of each chapter and a bibliographical subject index, is an invaluable resource for further study of fuzzy theory and applications.},
	language = {en},
	publisher = {Prentice Hall PTR},
	author = {Klir, George J. and Yuan, Bo},
	year = {1995},
	note = {Google-Books-ID: AOhQAAAAMAAJ},
	keywords = {Computers / Intelligence (AI) \& Semantics, Mathematics / Logic},
}

@book{ross_polar_1999,
	title = {The {Polar} {Bear} {Strategy}: {Reflections} {On} {Risk} {In} {Modern} {Life}},
	isbn = {978-0-7382-0117-7},
	shorttitle = {The {Polar} {Bear} {Strategy}},
	abstract = {From cholesterol to cancer, asteroids to AIDS, we face more risks than our grandparents ever dreamed of. But most of us are 200 years behind the curve when it comes to making intelligent risk-based decisions: We refuse to fly, but don't wear seat belts in our far more dangerous cars. We panic about toxic waste dumps, but collectively smoke a billion cigarettes a year. In this entertaining and enlightening look at risk in the modern age, John Ross argues that the burgeoning science of risk assessment has given us powerful new tools to cope in a complex world, if we could only learn how to speak the language. Ross examines the building blocks of this new language, and helps us identify and relinquish long-held, often pre-set, biological and psychological responses to risk. Through vivid stories and compelling science, Ross empowers us to take control of our lives and to exercise our most basic democratic freedom—the power to make our own decisions—both as individuals and as a society.},
	language = {en},
	publisher = {Basic Books},
	author = {Ross, John},
	month = apr,
	year = {1999},
	note = {Google-Books-ID: hDVyswEACAAJ},
	keywords = {Psychology / General},
}

@book{bier_effects_2012,
	title = {Effects of {Deregulation} on {Safety}: {Implications} {Drawn} from the {Aviation}, {Rail}, and {United} {Kingdom} {Nuclear} {Power} {Industries}},
	isbn = {978-1-4615-0259-3},
	shorttitle = {Effects of {Deregulation} on {Safety}},
	abstract = {Because of the dramatic changes that economic deregulation has caused in the electricity industry and the widespread social concern about nuclear power safety, Effects of Deregulation on Safety is extremely timely. Effects of Deregulation on Safety uses case studies of the effects of deregulation on the U.S. air and rail industries and the United Kingdom nuclear power industry, as a basis for identifying likely impacts of electricity deregulation on safety of the U.S. commercial nuclear power industry. Effects of Deregulation on Safety provides a comprehensive overview of the safety experiences of these three case study industries and their implications for the U.S. nuclear power industry. The treatment of the subject is not highly technical, and hence is accessible to a wide range of readers with interests in the subject matter. The book draws on literature from roughly 250 references, ranging from brief news articles to book-length studies of deregulation in a particular industry, as well as original in-depth interviews with representatives of all three case study industries. This wealth of empirical background information allows the book to go beyond mere speculation about the possible adverse safety consequences of deregulation, to identify situations in which particular adverse safety consequences actually occurred. The experience of the case study industries indicates that economic deregulation need not be incompatible with a reasonable safety record, especially in those aspects of safety that are positively related to productivity. But that safety also cannot be taken for granted after deregulation. Careful management attention is needed in order to avoid the types of safety problems that were associated with deregulation in the case study industries.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Bier, Vicki and Joosten, James and Glyer, David and Tracey, Jennifer and Welsh, Michael},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: QDGgBQAAQBAJ},
	keywords = {Business \& Economics / Economics / Microeconomics, Business \& Economics / General, Business \& Economics / Operations Research, Medical / Public Health, Nature / Natural Resources, Technology \& Engineering / Environmental / General},
}

@book{waller_low-probability_2013,
	title = {Low-{Probability} {High}-{Consequence} {Risk} {Analysis}: {Issues}, {Methods}, and {Case} {Studies}},
	isbn = {978-1-4757-1818-8},
	shorttitle = {Low-{Probability} {High}-{Consequence} {Risk} {Analysis}},
	abstract = {In recent years public attention has focused on an array of low-probability/high-consequence (LC/HC) events that pose a signif icant threat to human health, safety, and the environment. At the same time, public and private sector responsibilities for the assessment and management of such events have grown because of a perceived need to anticipate, prevent, or reduce the risks. In attempting to meet these responsibilities, legislative, judicial, regulatory, and private sector institutions have had to deal with the extraordinarily complex problem of assessing and balancing LP/ HC risks against the costs and ben if its of risk reduction. The need to help society cope with LP/HC events such as nuclear power plant accidents, toxic spills, chemical plant explosions, and transportation accidents has given rise to the development of a new intellectual endeavor: LP/HC risk analysis. The scope and complexity of these analyses require a high degree of cooperative effort on the part of specialists from many f{\textasciitilde}elds. Analyzing technical, social, and value issues requires the efforts of physicists, biologists, geneticists, statisticians, chemists, engineers, political scientists, sociologists, decision analysts, management scientists, economists, psychologists, ethicists, lawyers, and policy analysts. Included in this volume are papers by authors in each of these disciplines. The papers share in common a focus on one or more of the following questions that are generic to the analysis of LP/HC risks.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Waller, Ray},
	month = nov,
	year = {2013},
	note = {Google-Books-ID: UAbkBwAAQBAJ},
	keywords = {Juvenile Nonfiction / Science \& Nature / General, Philosophy / General, Science / General},
}

@book{tribus_rational_2016,
	title = {Rational {Descriptions}, {Decisions} and {Designs}: {Pergamon} {Unified} {Engineering} {Series}},
	isbn = {978-1-4831-4623-2},
	shorttitle = {Rational {Descriptions}, {Decisions} and {Designs}},
	abstract = {Rational Descriptions, Decisions and Designs is a reference for understanding the aspects of rational decision theory in terms of the basic formalism of information theory. The text provides ways to achieve correct engineering design decisions. The book starts with an understanding for the need to apply rationality, as opposed to uncertainty, in design decision making. Inductive logic in computers is explained where the design of the machine and the accompanying software are considered. The text then explains the functional equations and the problems of arriving at a rational description through some mathematical preliminaries. Bayes' equation and rational inference as tools for adjusting probabilities when something new is encountered in earlier probability distributions are explained. The book presents as well a case study concerning the error made in following specifications of spark plugs. The author also explains the Bernoulli trials, where a probability that a better hypothesis than that already adopted may exist. The rational measure of uncertainty and the principle of maximum entropy with sample calculations are included in the text. After considering the probabilities, the decision theory is taken up where engineering design follows. Examples regarding transmitter and voltmeter designs are presented. The book ends by explaining probabilities of success and failure as applied to reliability engineering, that it is a state of knowledge rather than the state of a thing. The text can serve as a textbook for students in technology engineering and design, and as a useful reference for mathematicians, statisticians, and fabrication engineers.},
	language = {en},
	publisher = {Elsevier},
	author = {Tribus, Myron},
	month = mar,
	year = {2016},
	note = {Google-Books-ID: IbkgBQAAQBAJ},
	keywords = {Technology \& Engineering / Engineering (General), Technology \& Engineering / Reference},
}

@book{mccormick_reliability_1981,
	title = {Reliability and risk analysis: methods and nuclear power applications},
	isbn = {978-0-12-482360-0},
	shorttitle = {Reliability and risk analysis},
	abstract = {A prior knowledge of probability theory would be helpful for the material in Part I; likewise, a previous introduction to the engineered safety features of a nuclear reactor makes portions of Part II easier to understand. For those without this background, introductory material is provided in Chapter 2 and the appendixes.},
	language = {en},
	publisher = {Academic Press},
	author = {McCormick, Norman J.},
	year = {1981},
	note = {Google-Books-ID: 7\_RTAAAAMAAJ},
	keywords = {Accidents, Nuclear engineering, Nuclear facilities, Nuclear facilities/ Accidents, Nuclear facilities/ Reliability, Reliability, Risk, Risk/ Statistical methods, Statistical methods, Technology \& Engineering / Industrial Engineering, Technology \& Engineering / Power Resources / Nuclear},
}

@book{green_reliability_1972,
	title = {Reliability {Technology}},
	isbn = {978-0-471-32480-5},
	language = {en},
	publisher = {Wiley},
	author = {Green, A. E. and Green, Arthur Eric and Bourne, A. J.},
	year = {1972},
	note = {Google-Books-ID: CvJTAAAAMAAJ},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / General},
}

@book{kumamoto_probablistic_2000,
	title = {Probablistic {Risk} {Assessment} and {Management} for {Engineers} and {Scientists}},
	isbn = {978-0-7803-6017-4},
	abstract = {Electrical Engineering Probabilistic Risk Assessment and Management for Engineers and Scientists Second Edition "State of the art in risk analysis...[this book] projects the technology into the next decade. Congratulations to the authors on a virtuoso performance." -Charles Donaghey, University of Houston "A very useful reference to the academic and government communities, and junior engineering staff within nuclear, chemical, transportation, aerospace, and other industries." -Yovan Lukic, Arizona Public Service Company As the demands of government agencies and insurance companies escalate, societal risk assessment and management become increasingly critical to the development and use of engineered systems in the full range of industrial installations. Packed with real-world examples and practical mathematical and statistical methods for large, complex systems, this definitive text and sourcebook gives you the guidance you need for thorough and conclusive study. You'll find new and updated coverage of all the key topics related to risk analysis: * Probabilistic nature of risk * Qualitative and quantitative risk assessments * System decomposition * Legal and regulatory risks * And much more! The authors also provide end-of-chapter problems and a course outline. Complete with a new, automated, fault tree synthesis method using semantic networks. Probabilistic Risk Assessment and Management for Engineers and Scientists, Second Edition will be of value to anyone working with engineered systems. Also of Interest from IEEE Press... Successful Patents and Patenting for Engineers and Scientists edited by Michael A. Lechter, Esq. 1995 Softcover 432 pp IEEE Order No. PP4478 ISBN 0-7803-1086-1 Metric Units and Conversion Charts A Metrication Handbook for Engineers, Technologists, and Scientists Second Edition Theodore Wildi 1995 Softcover 144 pp IEEE Order No. PP4044 ISBN 0-7803-1050-0 The Probability Tutoring Book An Intuitive Course for Engineers and Scientists (And Everyone Else!) Carol Ash 1993 Softcover 480 pp IEEE Order No. PP2881 ISBN 0-7803-1051-9},
	language = {en},
	publisher = {Wiley},
	author = {Kumamoto, Hiromitsu and Henley, Ernest J.},
	month = apr,
	year = {2000},
	note = {Google-Books-ID: 2R8WPQAACAAJ},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Quality Control},
}

@book{borovkov_probability_2013,
	address = {London},
	series = {Universitext},
	title = {Probability {Theory}},
	isbn = {978-1-4471-5200-2},
	url = {https://www.springer.com/gp/book/9781447152002},
	abstract = {This self-contained, comprehensive book tackles the principal problems and advanced questions of probability theory and random processes in 22 chapters, presented in a logical order but also suitable for dipping into. They include both classical and more recent results, such as large deviations theory, factorization identities, information theory, stochastic recursive sequences. The book is further distinguished by the inclusion of clear and illustrative proofs of the fundamental results that comprise many methodological improvements aimed at simplifying the arguments and making them more transparent.The importance of the Russian school in the development of probability theory has long been recognized. This book is the translation of the fifth edition of the highly successful Russian textbook. This edition includes a number of new sections, such as a new chapter on large deviation theory for random walks, which are of both theoretical and applied interest. The frequent references to Russian literature throughout this work lend a fresh dimension and make it an invaluable source of reference for Western researchers and advanced students in probability related subjects.Probability Theory will be of interest to both advanced undergraduate and graduate students studying probability theory and its applications. It can serve as a basis for several one-semester courses on probability theory and random processes as well as self-study.},
	language = {en},
	urldate = {2020-02-18},
	publisher = {Springer-Verlag},
	author = {Borovkov, Alexander A.},
	year = {2013},
	doi = {10.1007/978-1-4471-5201-9},
}

@book{jaynes_probability_2003,
	title = {Probability {Theory}: {The} {Logic} of {Science}},
	isbn = {978-0-521-59271-0},
	shorttitle = {Probability {Theory}},
	abstract = {The standard rules of probability can be interpreted as uniquely valid principles in logic. In this book, E. T. Jaynes dispels the imaginary distinction between 'probability theory' and 'statistical inference', leaving a logical unity and simplicity, which provides greater technical power and flexibility in applications. This book goes beyond the conventional mathematics of probability theory, viewing the subject in a wider context. New results are discussed, along with applications of probability theory to a wide variety of problems in physics, mathematics, economics, chemistry and biology. It contains many exercises and problems, and is suitable for use as a textbook on graduate level courses involving data analysis. The material is aimed at readers who are already familiar with applied mathematics at an advanced undergraduate level or higher. The book will be of interest to scientists working in any area where inference from incomplete information is necessary.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Jaynes, E. T.},
	month = apr,
	year = {2003},
	note = {Google-Books-ID: tTN4HuUNXjgC},
	keywords = {Mathematics / Applied, Mathematics / Probability \& Statistics / General, Science / Physics / General, Science / Physics / Mathematical \& Computational},
}

@book{rowe_anatomy_1977,
	title = {An anatomy of risk},
	isbn = {978-0-471-01994-7},
	language = {en},
	publisher = {Wiley},
	author = {Rowe, William D.},
	year = {1977},
	note = {Google-Books-ID: 9Ko7AQAAIAAJ},
	keywords = {Business \& Economics / Decision-Making \& Problem Solving, Decision making, Decision-making, Education / Decision-Making \& Problem Solving, Health \& Fitness / Safety, Mathematics / Game Theory, Risk, Technology, Technology - Risk assessment, Technology assessment},
}

@article{sengupta_mwcnts_2017,
	title = {{MWCNTs} based sorbents for nuclear waste management: {A} review},
	volume = {5},
	issn = {2213-3437},
	shorttitle = {{MWCNTs} based sorbents for nuclear waste management},
	url = {http://www.sciencedirect.com/science/article/pii/S221334371730492X},
	doi = {10.1016/j.jece.2017.09.054},
	abstract = {Multi walled carbon nanotubes (MWCNTs) based adsorbents have high sorption efficacy, fast sorption rate, selectivity, and reusability. All these features highlight that MWCNTs based adsorbents are excellent sorbents for the removal of toxic pollutants like heavy metals, organic pollutants etc. from industrial waste solutions. On the same line, these adsorbents have been utilized for the preconcentration/separation of the f-elements from nuclear waste solutions. This review outlines various methods that have been employed for the preparation of functionalized MWCNTs and MWCNTs based composites. Importantly, here an overview of applications of MWCNTs based adsorbents for the preconcentration/removal of f-elements from nuclear waste solutions have been discussed in detail. The main objective of this review is to provide valuable information on the developments that have been made so far for the separation of lanthanides and actinides from the nuclear waste solutions.},
	language = {en},
	number = {5},
	urldate = {2020-02-14},
	journal = {Journal of Environmental Chemical Engineering},
	author = {Sengupta, Arijit and Gupta, Nishesh Kumar},
	month = oct,
	year = {2017},
	keywords = {Isotherm, Kinetics, Modified MWCNTs, Sorption},
	pages = {5099--5114},
}

@article{smith_microbial_2017,
	title = {Microbial impacts on {99mTc} migration through sandstone under highly alkaline conditions relevant to radioactive waste disposal},
	volume = {575},
	issn = {0048-9697},
	url = {http://www.sciencedirect.com/science/article/pii/S0048969716318289},
	doi = {10.1016/j.scitotenv.2016.08.126},
	abstract = {Geological disposal of intermediate level radioactive waste in the UK is planned to involve the use of cementitious materials, facilitating the formation of an alkali-disturbed zone within the host rock. The biogeochemical processes that will occur in this environment, and the extent to which they will impact on radionuclide migration, are currently poorly understood. This study investigates the impact of biogeochemical processes on the mobility of the radionuclide technetium, in column experiments designed to be representative of aspects of the alkali-disturbed zone. Results indicate that microbial processes were capable of inhibiting 99mTc migration through columns, and X-ray radiography demonstrated that extensive physical changes had occurred to the material within columns where microbiological activity had been stimulated. The utilisation of organic acids under highly alkaline conditions, generating H2 and CO2, may represent a mechanism by which microbial processes may alter the hydraulic conductivity of a geological environment. Column sediments were dominated by obligately alkaliphilic H2-oxidising bacteria, suggesting that the enrichment of these bacteria may have occurred as a result of H2 generation during organic acid metabolism. The results from these experiments show that microorganisms are able to carry out a number of processes under highly alkaline conditions that could potentially impact on the properties of the host rock surrounding a geological disposal facility for intermediate level radioactive waste.},
	language = {en},
	urldate = {2020-02-14},
	journal = {Science of The Total Environment},
	author = {Smith, Sarah L. and Boothman, Christopher and Williams, Heather A. and Ellis, Beverly L. and Wragg, Joanna and West, Julia M. and Lloyd, Jonathan R.},
	month = jan,
	year = {2017},
	keywords = {Alkaliphile, Microbial impacts on transport, Radioactive waste disposal, Radionuclide transport},
	pages = {485--495},
}

@article{bevara_synthetic_2018,
	title = {Synthetic {Na}/{K}-birnessite for efficient management of {Sr}({II}) from nuclear waste},
	volume = {6},
	issn = {2213-3437},
	url = {http://www.sciencedirect.com/science/article/pii/S2213343718307000},
	doi = {10.1016/j.jece.2018.11.021},
	abstract = {The efficient separation for alternate use and management of 90Sr in nuclear waste is an important research activity in nuclear power industries. Herein we have demonstrated an efficient separation of Sr2+ by birnessite type sodium and potassium phyllomanganates (AxMn2O4-yH2O; A = Na+ and K+). Both the materials were prepared by oxidation of Mn(OH)2 by flowing oxygen atmosphere in presence of large excess of alkali hydroxide. Mn(OH)2 was prepared by precipitation method using solutions of MnCl2 and NaOH or KOH. The XRD studies revealed that both materials have layered monoclinic (C2/m) structures made of sheets of edge shared MnO6 octahedra. The Na+ or K+ ions were located in between these layers and provide charge neutrality to the structure. From thermogravimetric and XRD studies, the compositions of the prepared phyllomanganates are found to be Na0.5Mn2O4-0.96H2O (NMO) and K0.5Mn2O4-0.6H2O (KMO). The ion exchange studies carried out using radioactive 85Sr2+ solutions revealed large distribution constant (Kd) in a wider range of pH (2 to 14). Maximum Kd (27,000 mL/g) for NMO is observed in neutral medium which decreased to ∼19,000 mL/g at pH 14, while the Kd (∼22,000 mL/g) of KMO is relatively insensitive to pH. Higher preference of Sr2+ ions over Na+ and K+ have been concluded from the kinetics of exchange process. Ion exchange capacities of NMO and KMO are: 9.64 mmol/g and 1.09 mmol/g, respectively. Interference studies with several commonly present ions in nuclear waste like Al3+, Ca2+, H+ and Na+ ions, indicated appreciable interference only from Al3+.},
	language = {en},
	number = {6},
	urldate = {2020-02-14},
	journal = {Journal of Environmental Chemical Engineering},
	author = {Bevara, Samatha and Giri, Prema and Achary, S. Nagabhusan and Bhallerao, G. and Mishra, Raman K. and Kumar, Amar and Kaushik, Chetan P. and Tyagi, Avesh Kumar},
	month = dec,
	year = {2018},
	keywords = {Birnessite, High level nuclear waste, Nuclear waste management, Phyllomanganates, Radioactive Sr, Separation process},
	pages = {7200--7213},
}

@article{noauthor_nuclear_1983,
	series = {Oxidant {Air} {Pollutants}},
	title = {Nuclear waste encapsulation in borosilicate glass by chemical polymerization: {Ronald} {W} {Chickering}, {Bulent} {Yoldas}, {Bruce} {Neuman} assigned to {Westinghouse} {Electric} {Corp}},
	volume = {9},
	issn = {0160-4120},
	shorttitle = {Nuclear waste encapsulation in borosilicate glass by chemical polymerization},
	url = {http://www.sciencedirect.com/science/article/pii/0160412083900260},
	doi = {10.1016/0160-4120(83)90026-0},
	language = {en},
	number = {6},
	urldate = {2020-02-14},
	journal = {Environment International},
	month = jan,
	year = {1983},
	pages = {v},
}

@article{gens_clays_2019,
	series = {Geomechanics for nuclear waste storage},
	title = {Clays in natural and engineered barriers for nuclear waste disposal},
	volume = {17},
	issn = {2352-3808},
	url = {http://www.sciencedirect.com/science/article/pii/S2352380818300959},
	doi = {10.1016/j.gete.2018.11.004},
	language = {en},
	urldate = {2020-02-14},
	journal = {Geomechanics for Energy and the Environment},
	author = {Gens, Antonio},
	month = mar,
	year = {2019},
	pages = {1--2},
}

@article{warren_review_1986,
	title = {A review of clay-aromatic interactions with a view to their use in hazardous waste disposal},
	volume = {54},
	issn = {0048-9697},
	url = {http://www.sciencedirect.com/science/article/pii/0048969786902627},
	doi = {10.1016/0048-9697(86)90262-7},
	abstract = {This paper reviews the history of clay-aromatic interactions particularly in the areas of the ‘benzidine-blue’ reaction, pesticides and benzene and its derivatives with a view to the use of clay minerals as an additive to cementitious materials in order to bind organic compounds in hazardous and toxic wastes. It is concluded that these minerals can act as catalysts in a free radical oxidation and that absorption onto the clay surface accelerates the reaction and stabilises products. The extent of hydration of the clay affects the strength of the acid sites on the clay surface which in turn can affect adsorption. Adsorption and reactions are also dependent on the ligand-forming properties of the exchangeable cations in the clay as well as the extent to which they cause the clay layers to expand, transition metals and quaternary ammonium cations being more reactive than alkali and alkali earth cations.},
	language = {en},
	urldate = {2020-02-14},
	journal = {Science of The Total Environment},
	author = {Warren, D. S. and Clark, A. I. and Perry, R.},
	month = oct,
	year = {1986},
	pages = {157--172},
}

@article{bowen_deep_1989,
	title = {A deep knowledge planning decision support system for aiding nuclear waste transportation decisions},
	volume = {13},
	issn = {0198-9715},
	url = {http://www.sciencedirect.com/science/article/pii/0198971589900045},
	doi = {10.1016/0198-9715(89)90004-5},
	abstract = {Planners and public policy makers in recent years have become increasingly concerned with issues related to nuclear waste transportation. Rational planning and policy for nuclear waste transportation depends upon systematically assimilating into a coherent and meaningful whole, diverse information at several levels of analysis. The authors describe and demonstrate the rudiments of a deep knowledge architecture for evaluating alternative nuclear waste transshipment possibilities.},
	language = {en},
	number = {1},
	urldate = {2020-02-14},
	journal = {Computers, Environment and Urban Systems},
	author = {Bowen, William M. and Weeks, Kenneth D. and Batra, Dinesh and Hill, Timothy R.},
	month = jan,
	year = {1989},
	pages = {15--27},
}

@incollection{merkel_16_2012,
	series = {Woodhead {Publishing} {Series} in {Energy}},
	title = {16 - {Remediation} of sites contaminated by radionuclides},
	isbn = {9780857091321},
	url = {http://www.sciencedirect.com/science/article/pii/B978085709132150016X},
	abstract = {The same techniques commonly used for remediation of sites contaminated with metals can also be applied for sites contaminated with radionuclides. However, certain additional aspects have to be considered. Among them are the type of radionuclide, its half-life, and legal issues. Special attention has to be given to health protection of workers and people living close to the site. In certain cases, the noble gas radon can be an important issue requiring attention during remediation. For selecting an appropriate rehabilitation approach, the former use of the site needs to be known because the measures differ much for oil and gas production and treatment, uranium mining and milling, uranium enrichment or reprocessing, nuclear weapon testing or cleaning-up nuclear facilities after severe accidents.},
	language = {en},
	urldate = {2020-02-14},
	booktitle = {Radionuclide {Behaviour} in the {Natural} {Environment}},
	publisher = {Woodhead Publishing},
	author = {Merkel, B. J. and Hoyer, M.},
	editor = {Poinssot, Christophe and Geckeis, Horst},
	month = jan,
	year = {2012},
	doi = {10.1533/9780857097194.3.601},
	keywords = {NORM, clean-up, depleted uranium, dismantling nuclear facilities, nuclear weapon test site, phosphate fertilisers, radioactive contamination, radionuclide, remediation, repository, uranium enrichment or reprocessing, uranium mining and milling site},
	pages = {601--645},
}

@article{campos_venuti_management_1984,
	series = {Energia {Nucleare} e {Energie} {Alternative}},
	title = {Management of risks in the chemical and nuclear areas},
	volume = {10},
	issn = {0160-4120},
	url = {http://www.sciencedirect.com/science/article/pii/0160412084900540},
	doi = {10.1016/0160-4120(84)90054-0},
	abstract = {A comparative overiew is provided of some major aspects concerning assessment and management of chemical and nuclear risks arising as a consequence of accidents. Statutory procedures for constructing and running nuclear and chemical plants in Italy are discussed in detail. Special attention is given to the major changes that are likely to occur after the adoption of the EEC Council Directive 82/501, designed to prevent major accidents which might result from certain industrial activities and to limit their consequences for humans and their environment. Present status and future trends of accident analysis and risk assessment are also been dealt with, and special emphasis is placed on aspects common to both nuclear and chemical plants. Lastly, managerial aspects of contingency planning for, and response to, emergencies and accidents involving toxic chemical and/or ionizing radiations are examined with the aim of identifying more critical steps.},
	language = {en},
	number = {5},
	urldate = {2020-02-14},
	journal = {Environment International},
	author = {Campos Venuti, G. and Frullani, S. and Pocchiari, F. and Rogani, A. and Silano, V. and Tabet, E. and Zapponi, G.},
	month = jan,
	year = {1984},
	pages = {475--482},
}

@article{gupta_biosorption-alternative_2018,
	title = {Biosorption-an alternative method for nuclear waste management: {A} critical review},
	volume = {6},
	issn = {2213-3437},
	shorttitle = {Biosorption-an alternative method for nuclear waste management},
	url = {http://www.sciencedirect.com/science/article/pii/S2213343718301428},
	doi = {10.1016/j.jece.2018.03.021},
	abstract = {Separation scientists and radiochemists aim to recover valuable long-lived radionuclides from high-level nuclear waste solution before its safe geological disposal. In last few years, researchers have exploited biosorption for nuclear waste management as an alternative to conventional liquid–liquid separation techniques. This review outlines various methods employed for the preparation of biosorbents. Importantly, nuclear waste treatment using biosorbents has been discussed in detail along with adsorption mechanisms. The main objective of this review is to provide vital information on the developments that have been made so far in the domain of biosorption, exclusively for nuclear waste management},
	language = {en},
	number = {2},
	urldate = {2020-02-14},
	journal = {Journal of Environmental Chemical Engineering},
	author = {Gupta, Nishesh Kumar and Sengupta, Arijit and Gupta, Anjali and Sonawane, Jagruti Ravindra and Sahoo, Harekrushna},
	month = apr,
	year = {2018},
	keywords = {Biosorbents, Biosorption, Isotherms, Kinetics, Radionuclides, Reusability},
	pages = {2159--2175},
}

@article{yi_assessment_2012,
	title = {Assessment of site conditions for disposal of low- and intermediate-level radioactive wastes: {A} case study in southern {China}},
	volume = {414},
	issn = {0048-9697},
	shorttitle = {Assessment of site conditions for disposal of low- and intermediate-level radioactive wastes},
	url = {http://www.sciencedirect.com/science/article/pii/S004896971101254X},
	doi = {10.1016/j.scitotenv.2011.10.060},
	abstract = {Near surface disposal of low- and intermediate-level radioactive wastes (LILW) requires evaluating the field conditions of the candidate site. However, assessment of the site conditions may be challenging due to the limited prior knowledge of some remote sites, and various multi-disciplinary data requirements at any given site. These situations arise in China as in the rest of the industrialized world, particularly since a regional strategy for LILW disposal has been implemented to protect humans and the environment. This paper presents a demonstration of the site assessment process through a case study focusing mainly on the geologic, hydrogeologic and geochemical characteristics of the candidate site. A joint on-site and laboratory investigation, supplemented by numerical modeling, was implemented in this assessment. Results indicate that no fault is present in the site area, although there are some minor joints and fractures, primarily showing a north–south trend. Most of the joints are filled with quartz deposits and would thus function hydraulically as impervious barriers. Investigation of local hydrologic boundaries has shown that the candidate site represents an essentially isolated hydrogeologic unit, and that little or no groundwater flow occurs across its boundaries on the north or east, or across the hilly areas to the south. Groundwater in the site area is recharged by precipitation and discharges primarily by evapo-transpiration and surface flow through a narrow outlet to the west. Groundwater flows slowly from the hilly area to the foot of the hills and discharges mainly into the inner brooks and marshes. Some groundwater circulates in deeper granite in a slower manner. The vadose zone in the site was investigated specially for their significant capability for restraining the transport of radionuclides. Results indicate that the vadose zone is up to 38m in thickness and is made up of alluvial clay soils and very highly weathered granite. The vadose zone has low saturated hydraulic conductivities on the order of 10-5cm/s and in this respect is well-suited for the disposal of LILW. The saturated formations are primarily made up of silt and moderately-to-slightly weathered granite, which exhibit even lower hydraulic conductivities, on the order of 10−6cm/s, also favorable for restraining the transport of radionuclides. Chemical analyses indicate that the groundwaters at the site are of the HCO3–Na·Ca and HCO3·SO4–Na·Ca types and are weakly corrosive to concrete and steel. Geochemical analyses indicate that the rock and soil materials (particularly weathered granite) at the site contain very small fractions of colloidal particles and exhibit low Cation Exchange Capacities (CEC), and would therefore have limited capacity for sorption of radionuclides. Groundwater flow and solute transport models of the candidate site have been developed using MODFLOW and MT3DMS, incorporating the data obtained during the assessment program. Calibration was based on the available measured groundwater level fluctuations and tracer concentrations from in situ dispersion tests. The longitudinal dispersion coefficient as determined in calibration is equal to 5.0×10−3m2/d. Numerical sensitivity analyses indicate that the hydraulic conductivity and the longitudinal dispersion coefficient are the key parameters controlling the transport of radionuclides, while the numerical model is not sensitive to changes in the effective porosity and the specific yield. Preliminary predictions have been performed with the calibrated model both for the natural setting of the site and the graded site in which the valleys of the site are backfilled with low permeable materials. Results indicate that the proposed site grading increases the safety of the site for disposal of LILW by reducing both the groundwater level and the hydraulic gradient and that radionuclide transport would not likely be a problem or cause groundwater contamination. Although there are some problems remaining to be addressed in future work, the conclusion of the assessment is that the conditions at this site are appropriate for LILW disposal. This study provides an example of the procedures necessary in an assessment of site conditions relevant to the safe disposal of LILW. Such an assessment is crucial to the site selection process and to subsequent environmental impact assessment.},
	language = {en},
	urldate = {2020-02-14},
	journal = {Science of The Total Environment},
	author = {Yi, Shuping and Ma, Haiyi and Zheng, Chunmiao and Zhu, Xiaobin and Wang, Hua'an and Li, Xueshan and Hu, Xueling and Qin, Jianbo},
	month = jan,
	year = {2012},
	keywords = {Disposal of LILW, Geochemistry, Hydrogeology, Numerical groundwater modeling, Site assessment, Solute transport},
	pages = {624--631},
}

@article{arutt_study_2017,
	title = {The study of radiation effects in emerging micro and nano electro mechanical systems ({M} and {NEMs})},
	volume = {32},
	issn = {0268-1242, 1361-6641},
	url = {http://stacks.iop.org/0268-1242/32/i=1/a=013005?key=crossref.9dd7821b7a18451c27ae13050bfd017b},
	doi = {10.1088/1361-6641/32/1/013005},
	language = {en},
	number = {1},
	urldate = {2020-02-14},
	journal = {Semiconductor Science and Technology},
	author = {Arutt, Charles N and Alles, Michael L and Liao, Wenjun and Gong, Huiqi and Davidson, Jim L and Schrimpf, Ronald D and Reed, Robert A and Weller, Robert A and Bolotin, Kirill and Nicholl, Ryan and Pham, Thang Toan and Zettl, Alex and Qingyang, Du and Hu, Juejun and Li, Mo and Alphenaar, Bruce W and Lin, Ji-Tzuoh and Shurva, Pranoy Deb and McNamara, Shamus and Walsh, Kevin M and Feng, Philip X-L and Hutin, Louis and Ernst, Thomas and Homeijer, Brian D and Polcawich, Ronald G and Proie, Robert M and Jones, Jacob L and Glaser, Evan R and Cress, Cory D and Bassiri-Gharb, Nazanin},
	month = jan,
	year = {2017},
	pages = {013005},
}

@inproceedings{bhavnani_utilization_2008,
	title = {Utilization of {Micro}-{Electronic}-{Machine} {Systems} ({MEMS}) to {Possible} {Future} {Use} in the {Enhanced} {Analysis} of {Safety} in {Nuclear} {Power} {Plants}},
	url = {https://asmedigitalcollection.asme.org/PVP/proceedings/PVP2002/4658X/135/291070},
	doi = {10.1115/PVP2002-1527},
	language = {en},
	urldate = {2020-02-07},
	publisher = {American Society of Mechanical Engineers Digital Collection},
	author = {Bhavnani, Anmol},
	month = aug,
	year = {2008},
	pages = {135--136},
}

@article{apostolakis_how_2004,
	title = {How useful is quantitative risk assessment?},
	volume = {24},
	issn = {0272-4332},
	doi = {10.1111/j.0272-4332.2004.00455.x},
	abstract = {This article discusses the use of quantitative risk assessment (QRA) in decision making regarding the safety of complex technological systems. The insights gained by QRA are compared with those from traditional safety methods and it is argued that the two approaches complement each other. It is argued that peer review is an essential part of the QRA process. The importance of risk-informed rather than risk-based decision making is emphasized. Engineering insights derived from QRAs are always used in combination with traditional safety requirements and it is in this context that they should be reviewed and critiqued. Examples from applications in nuclear power, space systems, and an incinerator of chemical agents are given to demonstrate the practical benefits of QRA. Finally, several common criticisms raised against QRA are addressed.},
	language = {eng},
	number = {3},
	journal = {Risk Analysis: An Official Publication of the Society for Risk Analysis},
	author = {Apostolakis, George E.},
	month = jun,
	year = {2004},
	pmid = {15209926},
	pages = {515--520},
}
